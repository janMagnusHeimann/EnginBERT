title,abstract,full_text
Spaces where all bijections are morphisms,"  Here we classify all topological spaces where all bijections to itself are
homeomorphisms. As a consequence, we also classify all topological spaces where
all maps to itself are continuous. Analogously, we classify all measurable
spaces where all bijections to itself are measurable with measurable inverse.
As a consequence, we also classify all measurable spaces where all maps to
itself are measurable.
","4
2
0
2

n
a
J

9

]

N
G
.
h
t
a
m

[

1
v
1
8
3
4
0
.
1
0
4
2
:
v
i
X
r
a

Spaces where all bijections are morphisms

Lucas H. R. de Souza

January 10, 2024

Abstract

Here we classify all topological spaces where all bijections to itself
are homeomorphisms. As a consequence, we also classify all topological
spaces where all maps to itself are continuous.

Analogously, we classify all measurable spaces where all bijections
to itself are measurable with measurable inverse. As a consequence,
we also classify all measurable spaces where all maps to itself are
measurable.

1

Introduction

We have trivially that topological spaces with the trivial or the discrete
topology have the property that all bijections to itself are homeomorphisms.
Consider the following family of topological spaces:

Deﬁnition 1. Let κ be a cardinal number and X a topological space. The
co-κ topology on X is the topology where the open sets are the empty set and
the subsets of X whose complement has cardinality less than κ. We say that
a topological space is cocardinal if it has the co-κ topology for some cardinal
κ.

This topology is not deﬁned for 1 < κ < ℵ0. Note that the co-ℵ0 topology
is the coﬁnite topology (see p. 49 of [3] for more information about these
topological spaces) and the co-ℵ+
0 topology is the cocountable topology (if α

Mathematics Subject Classiﬁcation (2010). Primary: 54F65, 28A05; Secondary:

54A10, 54A25, 54C05.

Keywords: Coﬁnite topology, cocountable topology, cardinal, countable-cocountable

σ-algebra, bijections.

1

 
 
 
 
 
 
is a cardinal, then we denote by α+ its successor cardinal, see Chapters I.10
to I.13 of [1] for cardinal numbers). Note also that the co-1 topology is the
trivial topology and the co-κ topology is the discrete topology if κ is bigger
than the cardinality of X.

It is easy to see that, for cocardinal topologies, all bijective maps are
homeomorphisms. Our objective is to show that this property actually
characterizes the cocardinal topologies:

Theorem 1. Let X be a topological space. Then Homeo(X) = bij(X) if and
only if X is cocardinal.

Here Homeo(X) is the set of all homeomorphisms from X to X and

bij(X) is the set of all bijective maps from X to X.

As a consequence, we have the following:

Corollary 1. Let X be a topological space. Then C(X, X) = Map(X, X) if
and only if X has the trivial topology or the discrete topology.

Here C(X, X) is the set of continuous maps from X to X and Map(X, X)

is the set of all maps from X to X.

We have also an analogous version of this theorem for measurable spaces:

Deﬁnition 2. Let κ be a cardinal number and X a measurable space. The
κ-co-κ algebra on X is the σ-algebra where the measurable sets are the subsets
of X with cardinality less than κ or its complement has cardinality less than
κ. We say that a measurable space is cocardinal if it has the κ-co-κ algebra
for some cardinal κ.

This σ-algebra is not deﬁned for 1 < κ 6 ℵ0. Note that the ℵ+

0 -co-ℵ+
0
algebra is the countable-cocountable algebra (see Examples 3.3 of [2] for the
proof that this is actually a σ-algebra). Note also that the 1-co-1 algebra is
the trivial σ-algebra and the κ-co-κ algebra is the discrete σ-algebra if κ is
bigger than the cardinality of X.

If X is a measurable space, let Iso(X) be the set of all measurable maps

from X to X with measurable inverse.

Theorem 2. Let X be a measurable space. Then Iso(X) = bij(X) if and
only if X is cocardinal.

As a consequence, we have the following:

Corollary 2. Let X be a measurable space. Then Mor(X, X) = Map(X, X)
if and only if X has the trivial σ-algebra or the discrete σ-algebra.

Here Mor(X, X) is the set of measurable maps from X to X.

2

Acknowledgements. The author was partially supported by the joint
FAPEMIG/CNPq program ”Programa de Apoio `a Fixa¸c˜ao de Jovens Doutores
no Brasil”, Grant Number BPD-00721-22 (FAPEMIG), 150784/2023-6 (CNPq).

2 Proof of Theorem 1

For a topological space X, consider Closed(X) as the set of closed sets of X.
For a set X, we denote the cardinality of X by #X.

Lemma 1. Let X be a topological space such that Homeo(X) = bij(X). Let
F ∈ Closed(X) such that #F < #X. If F ′ ⊆ X such that #F = #F ′, then
F ′ ∈ Closed(X).

Proof. If X is inﬁnite and #F < #X, then #(X − F ) = #X. Analogously,
#(X − F ′) = #X. So #(X − F ) = #(X − F ′) (this occurs trivially for a
ﬁnite set X). So there exists a bijection f : X → X such that f (F ) = F ′ and
f (X −F ) = X −F ′. Since Homeo(X) = bij(X), then f is a homeomorphism,
which implies that F ′ is closed.

Lemma 2. Let X be a topological space such that Homeo(X) = bij(X). Let
F ∈ Closed(X) such that #F < #X. If F ′ ⊆ X such that #F > #F ′, then
F ′ ∈ Closed(X).

Proof. Suppose that F is ﬁnite.

Let x ∈ F . Then {x} = T{G ⊆ X : x ∈ G, #G = #F }. By the lemma
above, all subsets G are closed, which implies that {x} is closed and, since
F is ﬁnite, every subset of F is also closed.

Suppose that F is inﬁnite.
Let G ⊆ F such that #G = #F ′. Let x ∈ F − G. We have that
#(F − {x}) = #F . By the lemma above, F − {x} is closed. But G =
Tx∈F −G F − {x}, which implies that G is closed. Since #G = #F ′, then, by
the lemma above, F ′ is closed.

Lemma 3. Let X be an inﬁnite set, x ∈ X and F ⊂ X such that #F = #X.
Then there exists U, V ⊆ X such that U ∩ V = {x}, #U = #V = #(X − F )
and #(X − U) = #(X − V ) = #F .

Proof. Suppose that #(X − F ) < ℵ0.

Since X is inﬁnite, there exists U ′ and V ′ disjoint subsets of X such that

x /∈ U ′ ∪ V ′ and #U ′ = #V ′ = #(X − F ) − 1.
Suppose that ℵ0 6 #(X − F ) < #X.

3

Since X is inﬁnite, there exists U ′ and V ′ disjoint subsets of X such that
#U ′ = #V ′ = #(X − F ). We have that #(X − U ′) = #X = #F (since
#(X − F ) < #X) and, analogously, #(X − V ′) = #X = #F .

Suppose that #(X − F ) = #X.
Take U ′ and V ′ disjoint subsets of X such that U ′ ∪ V ′ = X − (F ∪ {x})
and #U ′ = #V ′ = #(X − F ). We have that #(X − U ′) = #F (since
F ⊂ X − U ′ and #F = #X) and, analogously, #(X − V ′) = #F .

In all cases, take U = U ′ ∪ {x} and V = V ′ ∪ {x}. We have that #U =

#V = #(X −F ), U ∩V = {x} and #(X −U) = #(X −V ) = #X = #F .

Theorem 1. Let X be a topological space. Then Homeo(X) = bij(X) if and
only if X is cocardinal.

Proof. We already know that, for cocardinal spaces, Homeo(X) = bij(X)
holds.

Let κ = sup{κ′ : ∃F ∈ Closed(X) : F 6= X, #F = κ′}.
Suppose that κ = 0.
If F is closed in X with F 6= X, then #F = 0. Then X has the trivial

topology.

Suppose that κ > 0.
Suppose that X is ﬁnite.
There exists F ∈ Closed(X) such that F 6= X and #F = κ. By Lemma
2, every point is a closed set. Since X is ﬁnite, it follows that X has the
discrete topology.

Suppose that X is inﬁnite.
Suppose that κ 6= #X or max{κ′ : ∃F ∈ Closed(X) : F 6= X, #F = κ′} 6=

#X.

Let α < κ. There exists cardinal κ′ such that α 6 κ′ 6 κ and there exists
F ∈ Closed(X) such that F 6= X and #F = κ′. By Lemma 2, every subset
of X with cardinality α is a closed set in X. If there exists a closed set G
with cardinality κ, then κ 6= #X, by the assumptions on κ. Then every
subset of X with cardinality κ is closed (by Lemma 1). Since there is no
closed set G 6= X with cardinality bigger than κ, it follows that X has the
co-κ+ topology. If there is no closed set diﬀerent from X with cardinality κ,
it follows that X has the co-κ topology.

Suppose that κ = max{κ′ : ∃F ∈ Closed(X) : F 6= X, #F = κ′} = #X.
There exists F ∈ Closed(X) such that F 6= X and #F = #X. Let
x ∈ X. By Lemma 3, there exists Ux, Vx ⊆ X such that Ux ∩ Vx = {x},
#Ux = #Vx = #(X − F ) and #(X − Ux) = #(X − Vx) = #F . Then there
exists f, g ∈ bij(X) such that f (Ux) = X − F and g(Vx) = X − F . Since
bij(X) = Homeo(X), Ux and Vx are open sets, which implies that {x} is an
open set as well. Then X has the discrete topology.

4

In all cases we get that X is cocardinal.

Corollary 1. Let X be a topological space. Then C(X, X) = Map(X, X) if
and only if X has the trivial topology or the discrete topology.

Proof. It is easy to see that if X has the trivial topology or the discrete
topology, then C(X, X) = Map(X, X).

Let X with the co-κ topology, for κ a cardinal with ℵ0 6 κ < #X +. Then
there exists F ⊂ X that is not closed. Let x, y ∈ X, with x 6= y. In this
case, take a map f : X → X deﬁned as f (F ) = x, f (X − F ) = y. Since X
has the co-κ topology, with κ > 1, then {x} ∈ Closed(X). But F = f −1(x),
which implies that f is not continuous. Thus C(X, X) 6= Map(X, X).

Since C(X, X) = Map(X, X) implies Homeo(X) = bij(X), then this

corollary follows from the theorem above.

3 Proof of Theorem 2

Lemma 4. Let (X, Σ) be a measurable space such that Iso(X) = bij(X).
Let F ∈ Σ such that #F < #X. If F ′ ⊆ X such that #F = #F ′, then
F ′ ∈ Σ.

Proof. Analogous to Lemma 1.

Lemma 5. Let (X, Σ) be a measurable space such that Iso(X) = bij(X).
Let F ∈ Σ such that #F < #X. If F ′ ⊆ X such that #F > #F ′, then
F ′ ∈ Σ.

Proof. Suppose that F is ﬁnite.

Let x ∈ F and y ∈ X − F . Then {x} = Tz∈F −{x}(F − {z}) ∪ {y}. By
the lemma above, for every z ∈ F − {x}, the set (F − {z}) ∪ {y} ∈ Σ , which
implies that {x} ∈ Σ and, since F is ﬁnite, every subset of F is also in Σ.
By the lemma above, we get that F ′ ∈ Σ.

Suppose that F is inﬁnite.
Let G ⊂ F such that #G = #F ′. We have that #(F - G) = #F. Take U ′
and V ′ disjoint subsets of F such that #U ′ = #V ′ = #F and U ′∪V ′ = F −G.
Take U = U ′ ∪ G and V = V ′ ∪ G. We have that #U = #V = #F . So,
by the lemma above, U, V ∈ Σ. But U ∩ V = G, which implies that G ∈ Σ.
Since #G = #F ′, then, by the lemma above, F ′ ∈ Σ.

Lemma 6. Let (X, Σ) be a measurable space such that Iso(X) = bij(X).
Let F ∈ Σ such that #F = #X and #(X − F ) = #X. If F ′ ⊆ X such that
#F > #F ′, then F ′ ∈ Σ.

5

Proof. Take G ⊆ F such that #G = #F ′. Take G′ = (X − F ) ∪ G. We
have that #G′ = #(X − G′) = #X. Take a bijection f : X → X such that
f (F ) = G′ and f (X − F ) = X − G′. Since Iso(X) = bij(X), then G′ ∈ Σ,
which implies that G = F ∩ G′ ∈ Σ.

Theorem 2. Let (X, Σ) be a measurable space. Then Iso(X) = bij(X) if
and only if X is cocardinal.

Proof. It is easy to see that, for cocardinal spaces, Iso(X) = bij(X) holds.

Let κ = sup{κ′ 6= #X : ∃F ∈ Σ : #F = κ′}.
Suppose that κ = 0.
Let F ∈ Σ with F 6= X.

If #F > 0, then #F = #X. Analogously,
#(X − F ) = #X. By the previous lemma,
if x ∈ X, then {x} ∈ Σ,
contradicting the fact that κ = 0. So #F = 0. Then X has the trivial
σ-algebra.

Suppose that κ > 0.
Suppose that X is ﬁnite.
There exists F ∈ Σ such that F 6= X and #F = κ. By Lemma 5, every
point is a measurable set. Since X is ﬁnite, it follows that X has the discrete
σ-algebra.

Suppose that X is inﬁnite.
Let α < κ. There exists a cardinal κ′ such that α 6 κ′ 6 κ (or α 6 κ′ < κ,
if κ = #X) and there exists F ∈ Σ such that #F = κ′. By Lemma 5, every
subset of X with cardinality α is a measurable set in X.

Suppose that κ 6= #X.
If there exists a measurable set G with cardinality κ, then every subset of
X with cardinality κ is measurable (by the fact that κ 6= #X and Lemma 4).
Let G be a measurable set with cardinality bigger than κ. By the deﬁnition
of κ, #G = #X.

Suppose that there is no measurable set G with #G = #X and
#(X − G) = #X. If there is no measurable set with cardinality κ, then X
has the κ-co-κ algebra. If there is a measurable set with cardinality κ, then
X has the κ+-co-κ+ algebra.

Suppose that there is a measurable set G with #G = #X and #(X−G) =
#X. Let β be a cardinal such that κ 6 β < #X. Take G′ ⊆ G such that
#G′ = β. By Lemma 6, G′ ∈ Σ. By the deﬁnition of κ, we get that β = κ
and then #X = κ+. We also get that all subsets of X with cardinality κ are
measurable. Let H ⊂ X with #H > κ. Then #H = #X. If #(X − H) 6 κ,
then X − H ∈ Σ, which implies that H ∈ Σ. If #(X − H) = #X, then take
a bijection g : X → X such that g(G) = H and g(X − G) = X − H. Since
Iso(X) = bij(X), then H ∈ Σ. So we get that X has the discrete σ-algebra.

6

Suppose that κ = #X.
Suppose that there is no measurable set G with #G = #X and
#(X − G) = #X. Since for every α < κ and every H ⊂ X with #H = α,
H ∈ Σ, then X has the κ-co-κ algebra.

Suppose that there is a measurable set G with #G = #X and #(X−G) =
#X. If H is another subset of X with #H = #X and #(X − H) = #X,
then H ∈ Σ, by the same argument as in the case κ 6= #X. So every subset
of X is in Σ, i. e., X has the discrete σ-algebra.
In all cases we get that X is cocardinal.

Corollary 2. Let X be a measurable space. Then Mor(X, X) = Map(X, X)
if and only if X has the trivial σ-algebra or the discrete σ-algebra.

Proof. Analogous to Corollary 1.

References

[1] K. Kunen, Set Theory. Studies in Logic. College Publications, 2011

[2] R. L. Schilling, Measures,
University Press, 2005.

Integrals and Martingales. Cambridge

[3] L. A. Steen and J. A. Seebach Jr., Counterexamples in Topology. Holt,

Rinehart and Winston Inc., 1970.

7

"
A Note on Computational Complexity of Kill-all Go,"  Kill-all Go is a variant of Go in which Black tries to capture all white
stones, while White tries to survive. We consider computational complexity of
Kill-all Go with two rulesets, Chinese rules and Japanese rules. We prove that:
(i) Kill-all Go with Chinese rules is PSPACE-hard, and (ii) Kill-all Go with
Japanese rules is EXPTIME-complete.
","9
1
0
2

v
o
N
6
2

]

C
C
.
s
c
[

1
v
5
0
4
1
1
.
1
1
9
1
:
v
i
X
r
a

A Note on Computational Complexity of
Kill-all Go

Zhujun Zhang ∗
Water Bureau of Fengxian District, Shanghai

November 26, 2019

Abstract

Kill-all Go is a variant of Go in which Black tries to capture all white
stones, while White tries to survive. We consider computational complexity
of Kill-all Go with two rulesets, Chinese rules and Japanese rules. We prove
that: (i) Kill-all Go with Chinese rules is PSPACE-hard, and (ii) Kill-all Go
with Japanese rules is EXPTIME-complete.

Index terms— Kill-all Go, computational complexity, PSPACE-hard, EXPTIME-

complete

1 Introduction

Kill-all Go is a live-or-die variant of Go. The rules of Kill-all Go are as in
regular Go, but Black is awarded 17 handicap stones. If White can obtain at least
one living group, he wins, while if Black can prevent this, she wins.

There are many rulesets of Go all around the world, while Chinese rules and
Japanese rules are typical rulesets of these. Usually there is no diﬀerence between
using Chinese or Japanese rules in practice, however they are diﬀerent on allowing
cycles. Cycles of length 2 (termed ko) are forbidden in either of these two rulesets.
Longer cycles (termed superko) are forbidden in Chinese rules, while longer cycles
are allowed in Japanese rules. If a board position is repeated, the game has “no
result” in Japanese rules.

In this note, we discuss computational complexity of Kill-all Go with two rule-

sets, Chinese rules (superko rule) and Japanese rules (basic ko rule).

∗E-mail: zhangzhujun1988@163.com

1

 
 
 
 
 
 
2 Related Work

Computational complexity of Go and variants of Go was researched in last
several decades. In 1980, Lichtenstein and Sipser [4] considered complexity of Go
ﬁrst, and they proved Go to be PSPACE-hard. Their reduction is not sensitive to
rulesets, therefore they proved Go with either of Chinese rules or Japanese rules
to be PSPACE-hard in fact. In 1983, Robson [6] proved Go with Japanese rules to
be EXPTIME-complete, and an improvement on Robson’s proof could be found
on Sensei’s Library [1]. In 1998, Crˆa¸smaru [2] researched a kind of life and death
problem of Go (termed tsumego) in which one of the players has always a unique
good move and the other has always only two good moves available to choose
from. Crˆa¸smaru proved this kind of life and death problem to be NP-complete.
In 2000, Crˆa¸smaru and Tromp [3] considered the ladder which is a technique for
capturing stones in Go, and they proved Ladders to be PSPACE-complete.
In
2002, Wolfe [9] proved Go endgames (termed yose) to be PSPACE-hard. In 2015,
Saﬃdine et al. [8] considered a variant of Go, Atari Go, in which the ﬁrst capture
leads to a victory, and they proved Atari Go to be PSPACE-complete. They also
researched complexity of Phantom Go which is a partially observable variant of
Go, and they proved lower and upper bounds for Phantom Go.

Computational complexity of Kill-all Go is still open. Saﬃdine et al. [8] con-
jectured that Kill-all Go with Chinese rules is PSPACE-hard and Kill-all Go with
Japanese rules is EXPTIME-complete. Moreover, they gave a few hints on this
direction, and they suggested using ladders to construct gadgets. However, using
ladders will lead to a large number of vacant points on the game board. It is diﬃ-
cult to rigorously prove that White can not obtain a living group on these vacant
points. Thus we choose to use Lichtenstein and Sipser’s method [4], and we use
capturing races to construct gadgets.

3 Complexity of Kill-all Go with Chinese Rules

3.1 Overview of the Reduction

We reduce True Quantiﬁed Boolean Formula (TQBF) to Kill-all Go with Chi-
nese rules. We need to construct start, pipe, white switch, black switch, merge,
verify and crossover gadgets. We construct a capturing race in a start gadget,
and the result of the capturing race decides who wins the game. In a start gad-
get, White’s only hope is to escape through the small breach. Then he has try
to connect the group in the start gadget with a group which has a large number
of liberties. White can not make any eyes in other gadgets, so that The only
chance for him to win the game is to obtain a living group in a start gadget.

2

White switch gadgets are corresponding to choices of universal player in TQBF,
while black switch gadgets are corresponding to choices of existential player. We
use two verify gadgets to represent the assignment of each variables in TQBF.
Whether the white group in the start gadget can obtain enough liberties depends
on the status of verify gadgets. We use pipe, merge and crossover gadgets to con-
nect other gadgets according to the formula in TQBF. In all following gadgets,
White is to move.

3.2 Gadgets

Start gadget. A start gadget for Kill-all Go is illustrated in Figure 1. In this
gadget, white group a has only one liberty, while black group b has three liberties.
If White connects group a with a group which has a large number of liberties,
White will capture group b, and he will obtain a living group easily. While Black
must try to prevent this. Moreover, as we will see later, White can not make any
eyes in other gadgets. The only chance for White to obtain a living group is to try
to capture group b in the start gadget. Thus White has to move at point 1 in order
to save group a. Then Black must move at point 2, otherwise, White may move at
point 2, and group a will obtain enough liberties so that White can capture group
b in at most six moves. Group a will leave the start gadget through the right exit
ﬁnally if two players move properly.

Figure 1: A start gadget.

Pipe gadget. Pipe gadgets are used to connect other gadgets, and a pipe
gadget for Kill-all Go is illustrated in Figure 2. After leaving the start gadget,
group a might enter a pipe gadget from north. Then White should move at point
1, otherwise Black can capture group a immediately. And then Black must respond
at point 2, otherwise group a will obtain seven liberties at least. Thus group a will
leave this pipe gadget through the right exit ﬁnally. Obviously, in a pipe gadget,
no black stones will be captured, and White can not make any eyes. Moreover,

3

we use pipe gadgets to restrict the number of liberties of white groups at each
entrance and exit of other gadgets.

Figure 2: A pipe gadget.

White switch gadget. A white switch gadget for Kill-all Go is illustrated
in Figure 3. When group a enters a white switch gadget from north, White can
choose to move at point 1 or point 2, and Black must respond. For instance, a
sequence of proper moves might be: W-1, B-2, W-3, B-4. Then group a leaves the
gadget through the left exit. The situation that White chooses to move at point 2
is symmetrical. If White’s ﬁrst move is not at either point 1 or point 2, Black can
capture group a. For instance, the sequence of moves might be: W-3, B-1, W-2,
B-5. If Black does not respond White’s ﬁrst move at point 1 or point 2, group a
will obtain a large number of liberties. For instance, the sequence of moves might
be: W-2, B-5, W-1 (captures one black stone at point 7), B-3, W-7. Note that
group a has at most two liberties all along. Thus if White tries to capture group b
in the start gadget, Black will capture group a ﬁrst. Moreover, in a white switch
gadget, White has at most one false eye at point 7, while Black can destroy this
false eye sooner or later.

Figure 3: A white switch gadget.

4

Black switch gadget. A black switch gadget for Kill-all Go is illustrated in
Figure 4. A black switch gadget is similar to a white switch gadget. When white
group a enters a black switch gadget from north, White should move at point 1,
otherwise Black can capture group a immediately. Then Black can choose to move
at point 2 or point 3, and White must respond. For instance, a sequence of proper
moves might be: W-1, B-3, W-2, B-4. Then group a leaves the gadget through
the left exit. The situation that Black chooses to move at point 2 is symmetrical.
If Black does not move at either point 2 or point 3, group a will obtain a large
number of liberties. For instance, the sequence of moves might be: W-1, B-4,
W-3, B-5, W-2 (captures one black stone at point 6), B-at any legal point (note
that Black can not move at point 6 to capture white stones since pipe gadgets
provide liberties), W-6. Similarly, in a black switch gadget, group a has at most
two liberties all along. If White tries to capture group b, Black will capture group
a ﬁrst. Moreover, White has at most one false eye at point 6.

Figure 4: A black switch gadget.

Merge gadget. A merge gadget for Kill-all Go is illustrated in Figure 5. If
group a enters this gadget from west, White should move at point 1, and then
Black must respond at point 2. If Black does not respond, White may move at
point 2 to capture one black stone at point 3. Since pipe gadgets provide liberties,
Black can not move at point 3 to capture white stones. Thus White can move at
point 3 next, so that group a will obtain a large number of liberties. The situation
that group a enters the gadget from east is symmetrical. Group a will leave the
start gadget through the lower exit ﬁnally if two players move properly. Moreover,
White has at most one false eye at point 3 in a merge gadget.

5

Figure 5: A merge gadget.

Verify gadget. A verify gadget for Kill-all Go is illustrated in Figure 6. When
group a enters this gadget from north, White should move at point 1, otherwise
Black can move at point 1 to capture group a immediately. Then Black must
respond at point 2, otherwise White can move at point 2 so that group a will
obtain a large number of liberties. When group a enters this gadget from east,
there are two cases: (i) If there is one black stone on point 2. Black may capture
group a by moving at point 4 after White moves at point 3; (ii) If there is no stones
on point 2. White may move at point 3, and then he can choose between point
2 or point 4 in next move, so that Black fails to prevent group a from obtaining
a large number of liberties. Moreover, White can not make any eyes in a verify
gadget.

Figure 6: A verify gadget.

Crossover gadget. A crossover gadget is composed of above gadgets, and it
is illustrated in Figure 7. When group a enters the left verify gadget from north, it

6

traverses a verify gadget, a merge gadget and a white switch gadget continuously.
Then White has to make group a enter the right black switch gadget, otherwise
Black may make group a enter the left verify gadget so that group a will be
captured.
In the right black switch gadget, Black can not make group a enter
the right verify gadget. Otherwise group a will obtain a large number of liberties,
since it did not ever traverse the right verify gadget. The situation that group a
enters the right verify gadget from north is symmetrical. Note that, once group
a traverses a crossover gadget through one path, the other path will be locked.
However, as we will see later, each crossover gadget will never be traversed for
more than one time in the instance of Kill-all Go.

Figure 7: A crossover gadget.

3.3 The Example

We use a example to demonstrate how to simulate TQBF by Kill-all Go. For
Boolean formula ∃x1∀x2∃x3∀x4 (x1 ∨ ¬x2 ∨ x3) ∧ (x2 ∨ x3 ∨ ¬x4), the correspond-
ing instance of Kill-all Go with Chinese rules is illustrated in Figure 8.

In the ﬁgure, arrow lines represent pipe gadgets, and each crossroad represents
a crossover gadget. In the instance, black switch gadgets simulate choices of ex-
istential player, and white switch gadgets simulate choices of universal player in
TQBF. Thus the escape path of group a is corresponding to assignment of vari-
ables x1, x2, x3 and x4. The lower one white switch gadget and two black switch
gadgets simulate checking progress. Thus White chooses the clause to be checked,
and Black chooses the literal to be checked.

7

 verify verify merge white switch black switch black switch Figure 8: An instance of Kill-all Go with Chinese rules.

8

 black switch verify ¬x1 merge verify x1 white switch verify ¬x2 merge verify x2 black switch verify ¬x3 merge  verify x3 white switch verify ¬x4 merge verify x4 white switch black switch black switch start merge It is easy to verify that the Boolean formula of TQBF is true if and only if Black
can capture all white stones in Kill-all Go. Since TQBF is PSPACE-complete, we
prove the following theorem:

Theorem 1. Kill-all Go with Chinese rules is PSPACE-hard.

Actually, we can use same method to prove Kill-all Go with Japanese rules to

be PSPACE-hard, however we will obtain stronger result in next section.

4 Complexity of Kill-all Go with Japanese Rules

4.1 Overview of the Reduction

We use Robson’s method [6] to reduce a formula game to Kill-all Go with
Japanese rules. In the formula game, a certain positive Boolean formula is given.
There are two players which are also called White and Black in the formula game,
and they move alternately. In each turn, White changes the assignment of one
variable to true, while Black changes the assignment of one variable to false. A
player can not immediately revert the opponent’s last move, which is similar to
If White is to move, and the current assignment makes
basic ko rule in Go.
the formula true, he wins the game. Robson [5] proved this formula game to be
EXPTIME-complete.

To simulate the formula game, we also need to construct some gadgets for Kill-
all Go with Japanese rules. Fortunately, the gadgets constructed in last section
could be reused here. Moreover, we need to construct ko gadgets corresponding to
variables in the formula game, and we will use a capturing race gadget to replace
the start gadget. There is a large capturing race in a capturing race gadget.
Whether White wins the game depends on whether one of two white groups can
obtain enough liberties in a capturing race gadget. There is one path for each of
these two white groups, and each path is connected with ko gadgets. These two
paths are constructed by previous gadgets, and the structures of the paths are
corresponding to the formula. If White can connect one white group with a ko
gadget in which he takes the ko, the white group will obtain enough liberties so
that White can obtain a living group.

4.2 Gadgets

Ko gadget. A ko gadget for Kill-all Go is illustrated in Figure 9. There is a
ko at point 5 in the ko gadget, and each ko gadget is corresponding to a variable
in the formula game. The gadget in which Black takes the ko is corresponding to
that assignment of the variable is false, while the gadget in which White takes the

9

ko is corresponding to that assignment of the variable is true. When a white group
enters the gadget, White has to move at point 1 or point 2. If the ko is taken by
Black, she can capture the white group by moving at point 3 or point 5. If the
ko is taken by White, the white group can obtain a large number of liberties, and
Black can not prevent this. For instance, the sequence of moves might be: W-2,
B-5, W-4. Moreover, White has at most one false eye at point 5 in a ko gadget.

Figure 9: A ko gadget (Black takes the ko).

Capturing race gadget. A capturing race gadget for Kill-all Go is illustrated
in Figure 10. There is a large capturing race in this gadget. Two exits of this
gadget are connected with two paths, and each path is connected with ko gadgets
according to the formula.
In a capturing race gadget, White’s only hope is to
capture group c or group d. Once group c or group d is captured, White can make
two eyes easily so that he may obtain a living group. If Black captures groups a
and group b, White can not prevent Black from connecting group c and group d
with living black groups, and White can not make any eyes in other gadgets so
that he loses. If Black captures group e, she can connect group f with group c
and group d, so that White can not obtain any living groups.

In a capturing race gadget, each of group a and group b has only one liberty,
and each of group c and group d has three liberties, and group e has seven liberties.
If White immediately tries to capture group c or group d, group a or group b will
be captured ﬁrst. Thus the only way for White to win the game is to connect
group a or group b with a group which has a large number of liberties. Group a
or group b should leave the gadget through the left exit or the right exit at the
right time, and White should try to connect group a or group b with a ko gadget
in which he takes the ko, so that he can capture group c or group d. On the other
hand, if Black immediately captures one of group a or group b, the other group
will leave the gadget through one of two exits, and White may connect it with a
ko gadget in which he takes the ko ﬁnally.

We discuss strategies of two players in a capturing race gadget in detail:

10

Figure 10: A capturing race gadget.

(1) Suppose that White is to move, and the formula is true under the assign-
ment corresponding to current status of ko gadgets. Then White may move at
If Black does not respond,
point 1, which forces Black to respond at point 2.
White can connect group a with group e, and these two groups share at least six
liberties, so that White can capture group c. After Black moves at point 2, White
can move at point 3, which forces Black to move at point 4 similarly. Next, group
a leaves the gadget through the left exit after White moves at point 5. Since the
formula is true, White can connect group a with a ko gadget in which he takes
the ko sooner or later, so that group a will obtain enough liberties. Moreover,
group e has at least ﬁve liberties, therefore, if Black tries to capture group e in
this progress, White will capture group c ﬁrst. Thus White can obtain a living
group, and he will win the game ﬁnally.

(2) Suppose that Black is to move, and the formula is false under the assignment
corresponding to current status of ko gadgets. Then Black may move at point 1
to capture group a, and White has to move at point 7, point 9 and point 11
continuously in order to save group b. After Black responds at point 8, point 10
and point 12, group b leaves the gadget through the right exit. However, since the
formula is false, Black can force group b to enter a ko gadget in which she takes
the ko. Thus White can not prevent Black from capturing group b. Note that,
group d has three liberties, while group b has at most two liberties. If White tries

11

to capture group d in this progress, group b will be captured ﬁrst. Thus Black can
capture group a and group b sooner or later. Since White can not make any eyes
in other gadgets, Black can capture all white stones, and she will win the game
ﬁnally.

(3) Suppose that Black is to move, and the formula is true under the assignment
corresponding to current status of ko gadgets. Then Black must move at a ko
gadget to make the formula false, otherwise she will lose the game since she can
not prevent group a and group b from leaving the gadget at the same time. For
instance, suppose that Black moves at point 1 or point 2 in order to capture group
a. Then group b will obtain a large number of liberties. Since group d has only
three liberties, after White moves at point 7, Black must respond at point 8. Then
White moves at point 9, and Black still has to move at point 10, otherwise, White
can connect group b with group e, so that these two groups share at least four
liberties. Next, White moves at point 11, and Black responds at point 12. Group
b leaves the gadget through the right exit. Since the formula is true, group b will
enter a ko gadget in which White takes the ko sooner or later. Note that, if Black
tries to capture group e in this progress, group d will be captured ﬁrst since group
e has at least four liberties.

(4) Suppose that White is to move, and the formula is false under the assign-
ment corresponding to current status of ko gadgets. Then White must move at a
ko gadget to make the formula true, otherwise he will lose the game. We consider
three types of White’s improper moves:

(4.1) Suppose that White moves at a ko gadget to connect a ko. Since the
status of ko gadgets is unchanged, Black can capture one of group a and group
b. The other white group can not enter a ko gadget in which White takes the ko,
even if it can leave the capturing race gadget.

(4.2) Suppose that White moves at point 1 or point 7. We just discuss the
situation that White moves at point 1, since the situation that White moves at
point 7 is symmetrical. Then Black must respond at point 2. Since the formula is
false, group a can not avoid being captured even if it can leave the gadget through
the left exit. If White tries to save group b, the sequence of moves might be: W-1,
B-2, W-3, B-4, W-5, B-6, ... , W-7, B-8, W-9, B-10. Note that group b has only
one liberty, and group e has only three liberties (point 13, point 14 and point 15)
now. If White moves at point 11 to save group b, Black can try to capture group
e, and White fails to capture group d ﬁrst. Moreover, after White moves at point
1, if he moves at a ko gadgets to make the formula true. Then Black still can move
at point 4, so that neither group a or group b can leave the capturing race gadget
because of shortage of liberties of group e.

(4.3) Suppose that White moves at other points, such as point 2, point 8 or
points in other gadgets. This situation is similar to case (4.1), and Black may

12

capture one of group a and group b immediately. Then the other white group can
not enter a ko gadget in which White takes the ko.

4.3 The Example

We also use a example to demonstrate how to simulate the formula game by
Kill-all Go. For formula (x1 ∨ x2 ∨ x3) ∧ (x2 ∨ x3 ∨ x4), the corresponding instance
of Kill-all Go with Japanese rules is illustrated in Figure 11.

Figure 11: An instance of Kill-all Go with Japanese rules.

Two exits of the capturing race gadget are connected with two symmetrical
paths which are constructed according to the formula. Group a and group b in

13

 capturing race black switch ko x1 ko x2 ko x3 ko x4 white  switch merge merge white  switch black switch white  switch merge merge white  switch the capturing race gadget can enter ko gadgets through these two paths. Suppose
that the formula is true under the current assignment, White can connect group
a or group b with a ko gadget in which he takes the ko. Suppose that the formula
is false under the current assignment, Black can force group a or group b to enter
a ko gadget in which she takes the ko. Thus each of the two players has to move
at the ko gadgets until her or his opponent makes a mistake, and the basic ko rule
should be obeyed, which simulates the formula game.

It is easy to verify that White wins the formula game if and only if White can
obtain at least one living group in Kill-all Go. Moreover, since the number of board
positions of Go is exponential, Kill-all Go with Japanese rules is in EXPTIME.
Thus we prove the following theorem:

Theorem 2. Kill-all Go with Japanese rules is EXPTIME-complete.

5 Conclusion

We reduce TQBF to Kill-all Go with Chinese rules, so that we prove Kill-all
Go with Chinese rules to be PSPACE-hard. We reduce a formula game to Kill-all
Go with Japanese rules, so that we prove Kill-all Go with Japanese rules to be
EXPTIME-complete.

The instances of Kill-all Go constructed in this note could be regarded as huge
life and death problems which are local skill problems of Go usually. The instance
constructed in Section 4 could be regarded as a huge superko which is a interesting
subject of Go.

The open problem is computational complexity of Kill-all Go with Chinese
rules. Since Kill-all Go with Chinese rules is in EXPSPACE, it might be PSPACE-
complete, EXPTIME-complete or even EXPSPACE-complete. Robson [7] intro-
duced a “no-repeat” version of a formula game, and he proved the new formula
game to be EXPSPACE-complete. The no-repeat rule of the formula game is sim-
ilar to superko rule in Go, so we can try to reduce the no-repeat formula game to
Go or Kill-all variant of Go.

References

[1] Robson’s Proof that GO is EXP-time Hard. https://senseis.xmp.net/

?RobsonsProofThatGOIsEXPTimeHard.

[2] Marcel Crˆa¸smaru. On the complexity of Tsume-Go. In International Confer-

ence on Computers and Games, pages 222–231. Springer, 1998.

14

[3] Marcel Crˆa¸smaru and John Tromp. Ladders are PSPACE-complete. In In-
ternational Conference on Computers and Games, pages 241–249. Springer,
2000.

[4] David Lichtenstein and Michael Sipser. Go is polynomial-space hard. Journal

of the ACM (JACM), 27(2):393–401, 1980.

[5] John Michael Robson. Exponential time decision problems relating to ko-like

transition rules. 1982.

[6] John Michael Robson. The complexity of Go. In Proc. 9th World Computer

Congress on Information Processing, 1983, pages 413–417, 1983.

[7] John Michael Robson. Combinatorial games with exponential space complete
decision problems. In International Symposium on Mathematical Foundations
of Computer Science, pages 498–506. Springer, 1984.

[8] Abdallah Saﬃdine, Olivier Teytaud, and Shi-Jim Yen. Go Complexities. In

Advances in Computer Games, pages 76–88. Springer, 2015.

[9] David Wolfe. Go endgames are PSPACE-hard. More Games of No Chance,

42:125–136, 2002.

15

"
Landau--Kolmogorov inequality revisited,"  The Landau-Kolmogorov problem consists of finding the upper bound $M_k$ for
the norm of intermediate derivative $|f^{(k)}|$, when the bounds $|f| \le M_0$
and $|f^{(n)}| \le M_n$, for the norms of the function and of its higher
derivative, are given.
  Here, we consider the case of a finite interval, and when all the norms are
the max-norms. Our interest to that particular case is motivated by the fact
that there are good chances to add this case to a short list of
Landau--Kolmogorov inequalities where a complete solution exists, i.e., a
solution that covers all values of $n,k\in\N$ (and, for a finite interval, all
values of $\sigma = M_n/M_0$).
  The main guideline here is Karlin's conjecture that says that, for all
$n,k\in\N$ and all $\sigma>0$, the maximum of $|f^{(k)}|$ is attained by a
certain Chebyshev or Zolotarev spline. So far, it has been proved only for
small $n \ge 4$ with all $\sigma$, and for all $n$ with particular $\sigma =
\sigma_n$. Here, we prove Karlin's conjecture in several further subcases:
  1) all $n,k\in\N$ and all $0 < \sigma \le \sigma_n$
  2) all $n \in \N$, all $\sigma > 0$, with $k=1,2$
  3) all $\sigma > 0$, with $n < 10$ and $0 < k < n$.
","Landau–Kolmogorov inequality revisited

A. Shadrin

DAMTP, University of Cambridge, UK

1

Introduction

The Landau–Kolmogorov problem consists of ﬁnding the upper bound Mk for the norm of inter-
f (k)
mediate derivative
Mn, for the norms of the
f
k
function and of its higher derivative, are given.

, when the bounds

M0 and

f (n)

k ≤

k ≤

k

k

Here, we consider the case of a ﬁnite interval when f

max-norms,

=

k · k

k · kL∞[−1,1]. Precisely, given n, k
1, 1] ,
f : f

W n

∞(σ) :=

W n
∞[

∈

{

∈

−

≥
f (n)

f

k

k ≤

1,

k

σ

}

k ≤

1, 1] and all the norms are the
−
0, we deﬁne the functional class

k
W n
∞[
∈
N and σ

and consider the problem of ﬁnding the values

mk(x, σ)

:=

sup
f ∈W n

∞(σ) |

f (k)(x)
|

,

x

[

−

∈

1, 1] ,

Mk(σ)

:=

sup
f ∈W n

∞(σ) k

f (k)

k

= sup

mk(x, σ) .

x∈[−1,1]

Our interest to that particular case is motivated by the fact that there are good chances to add
this case to a short list of Landau–Kolmogorov inequalities where a complete solution exists, i.e.,
N (and, for a ﬁnite interval, all values of σ > 0). The
a solution that covers all values of n, k
main guideline in ﬁnding out how good these chances are is the following conjecture.

∈

Conjecture 1.1 (Karlin [4]) For all n, k

N and all σ > 0,

∈

mk(1, σ) = sup

mk(x, σ) .

x∈[−1,1]

(1.1)

If (1.1) is true for particular set

∞(σ) that provides extremum
n, k, σ
{
over W n
∞(σ) is the same as the solution to the pointwise problem at
Mk(σ) to the value
the end-point of the interval. The latter solution is however known to be a certain Chebyshev or
Zolotarev spline Zn(
, σ) (which is just a polynomial for small σ), and thus we have a characteri-
·
zation of the extremal function.

, then the function f

f (k)

∈

k

k

}

W n

2
1
0
2

t
c
O
9
2

]

A
N
.
h
t
a
m

[

1
v
8
0
7
7
.
0
1
2
1
:
v
i
X
r
a

Corollary 1.2 If equality (1.1) is valid for particular
have

n, k, σ

, then for that set of parameters we

}

Mk(σ) =

Z (k)
n (
·

, σ)
k

k

{
= Z (k)

n (1, σ) .

(1.2)

So far, Karlin’s conjecture has been proved for small n with all σ, and for all n with particular

σ, namely in the following cases:

n = 2,

all σ

Chui–Smith [1] (σ

σn), Landau [5] (σ > σn);

≤

n = 3,

all σ,

Sato [8], Zvyagintsev–Lepin [12];

n = 4,
N,

n

∈

all σ,

Zvyagintsev [11] (σ

σn), Naidenov [7] (σ > σn);

≤

σ = σn, Eriksson [3] .

1

 
 
 
 
 
 
Here

where Tn is the Chebyshev polynomial of degree n on the interval [

σn :=

T (n)
n k

k

= 2n−1n! ,

1, 1].

−

≤

The value σ = σn serves as a borderline between two types of the extremal Zolotarev functions
Zn(
σn, then Zn is a polynomial of degree n, while for σ > σn it is a perfect spline of
, σ): if σ
·
degree n with r knots. There are further borderlines σn,r (with σn,1 := σn) which indicate that the
spline Zn(
σn,r+1, but that distinction is hardly of any use,
·
since for n > 3 there are no reasonable estimates for perfect splines even with one knot. In this
respect, we may apply more or less developed polynomial tools to tackle the problem for σ
σn,
and then may try to use polynomial estimates in the spline case, when σ > σn.

, σ) has exactly r knots if σn,r < σ

≤

≤

In this paper, we prove Karlin’s conjecture in several further subcases.
1) The ﬁrst result closes the “polynomial” case and proves that, for σ

σn, the extremum
∞(σ) is provided by the corresponding Zolotarev polynomial.

≤

W n

value of the k-th derivative of f

∈

Theorem 1.3 If

N,

n

∈

1

k

n

−

≤

≤

1 ,

σ

0

≤

≤

σn ,

(1.3)

then Karlin’s conjecture (1.1)-(1.2) is true.

2) For the “spline” case, we managed to advance only up to the second derivative.

Theorem 1.4 If

N,

n

∈

k = 1, 2,

σn < σ <

,
∞

then Karlin’s conjecture (1.1)-(1.2) is true.

The further advance depends mostly on improving the lower bound for the exact constant Cn,k in
Landau-Kolmogorov inequality on the half-line:

f (k)

k

R+ ≤

k

Cn,kk

f

k

1−k/n
R+

f (n)

k/n
R+

k

k

The existing lower bounds for Cn,k, which are due to Stechkin, are not very satisfactory for general
n and k > 2.

3) However, for small n, these bounds can be improved, thus leading to one more extension.

Theorem 1.5 If

n = 5, 6

n = 7, 8, 9

n = 10, 11

k

k

k

1

1

1

≤

≤

≤

≤

≤

≤

2,

3,

−

−

n

n

6,

then Karlin’s conjecture (1.1)-(1.2) is true.

σn < σ <

,
∞

(1.4)

In all the cases, the proof is based on comparing the upper bound for the local extrema of
, σ) with the lower bound for the value mk(1, σ). The technique we use is not
σ < σn,
1, what explains restriction in (1.4). In (1.3), i.e., for 0

the function mk(
·
working for the value k = n
we managed to cover the case k = n

−

1 by diﬀerent means.
The upper bounds are given in terms of Zolotarev polynomials and these estimates may be
viewed as a generalization to higher derivatives of Markov-type results of Schur [9] and Erd˝os-
Szeg˝o [2]. These bounds demonstrate once again, if we borrow the words of Shoenberg said about
cubic splines, “the brave behaviour of Zolotarev polynomials under diﬃcult circumstances”.

−

≤

2

2 Main ingredients of the proof

Karlin’s conjecture states that the function mk(
·
its maximal value at the end-points of the interval [
check that, at any point x0 inside the interval (
have

−

, σ) (which is a positive even function) reaches
1, 1]. To establish this fact it is suﬃcient to
, σ) takes its local maximum, we

−

1, 1) where mk(
·

If f is the function from W n

∞(σ) that attains a locally maximal value mk(x0, σ), then clearly

mk(x0, σ) < mk(1, σ) .

and it makes sense to introduce the following quantity:

mk(x0, σ) =

f (k)(x0)
|

|

,

f (k+1)(x0) = 0 ,

m∗

k(x0, σ) := sup

f (k)(x0)
|

: f

∈

W n

∞(σ), f (k+1)(x0) = 0

,

}

x0 ∈

[

−

1, 1] .

{|

The next statement follows immediately.

Claim 2.1 If, for a given n, k

N and σ > 0, we have

∈

sup
x0∈[−1,1]

m∗

k(x0, σ)

≤

mk(1, σ) ,

then Karlin’s conjecture is true.

In order to verify inequality (2.1), we split it into two parts

m∗

k(x0, σ)

≤

A(n, k, σ) ,

A(n, k, σ)

mk(1, σ) ,

≤

(2.1)

(2.2)

and then check whether A

B. So, we need two diﬀerent estimates:

≤

a) a good lower bound for the end-point value mk(1, σ) = sup
f (k)(x0)
b) a good upper bound for
|
Actually, if x = x0 stays suﬃciently far away from the end-points x =
upper bound for
|
Therefore, for the upper bounds for

, we will consider two cases

, where f is from W n

1, then a reasonable
can be established irrespectively of whether f (k+1)(x0) vanishes or not.

: f
∞(σ) and satisﬁes f (k+1)(x0) = 0.

f (k)(x0)
|

∞(σ)
}

{|

±

∈

|

,

f (k)(1)
|

W n

|
n,k(σ), ωk <

A∗

b1) m∗

k(x, σ)

≤
|
with an appropriately chosen value ωk.

f (k)(x)
|
x0| ≤

1,

b2) mk(x, σ)

An,k(σ),

≤

x

| ≤

|

ωk < 1,

We will distinguish between the cases σ

σn and σ > σn.

≤

1) The case σ

σn.

≤

1a) Lower estimates for mk(1, σ). Clearly, mk(1, σ) is monotoniously increasing with σ, there-

fore, we have the trivial estimate

mk(1, σ)

≥

mk(1, σ0) = T (k)

n−1(1) .

However, this estimate is too rough when k =

(n), so we will use a ﬁner one.

O

Proposition 2.2 We have

mk(1, σ)

≥

Bn,k(σ) :=

1

(cid:16)

σ
σn

−

(cid:17)

T (k)
n−1(1) +

σ
σn

T (k)
n (1),

σ

0

≤

≤

σn.

(2.3)

3

Proof. Let us show that mk(x, σ) as a function of σ is concave. For any x
σ′ < σ′′, let f1 and f2 be the functions such that

[

−

∈

1, 1], and for any

mk(x, σ(i)) = f (k)

i

(x),

W n

∞(σ(i)),

fi ∈

i = 1, 2.

It is clear that, for any σ
(1

∈
t)f1 + tf2 belongs to W n
∞(σ), hence we have

[σ′, σ′′], with t such that σ = (1

−

t)σ′ + tσ′′, the function f :=

−

mk(x, σ)

≥

f (k)(x) = (1

−

t)f (k)
1

(x) + tf (k)

2

(x) = (1

−

t)mk(x, σ′) + tmk(x, σ′′) .

In particular, with σ0 := T (n)

n−1 = 0 and σn = T (n)

n , we have

mk(1, σ)

1

−

≥

σ
σn

mk(1, σ0) +

σ
σn

mk(1, σn) ,

But mk(1, σ0) = T (k)

(cid:17)
n−1(1) and mk(1, σn) = T (k)
n (1), hence the result.

(cid:16)

(cid:3)

1b1) Upper estimate for m∗

k(x0, σ). We will use a comparison lemma of the kind similar to the

one that was used by Matorin [6] in (actually) proving that mk(1, σn)

≤

T (k)
n (1).

Lemma 2.3 Let p

∈ Pn[
p(k+1)(x0) = 0 ,

1, 1] be a polynomial that satisﬁes the following conditions:

−

2)

p has an n-alternance on [

1, 1],

−

3)

p(n)

k

k ≥

σ .

(2.4)

1)

Then, for any f

∈

we have

W n
∞[

1′)

1, 1] and for any x0 ∈
−
2′)
f (k+1)(x0) = 0 ,

1, 1] such that

[

−

f

k

k ≤

1,

3′)

f (n)

k

k ≤

σ,

f (k)(x0)

| ≤ |

p(k)(x0)
|

.

|

Proof. Assume the contrary, i.e., that f (k)(x0) = p(k)(x0)/γ with some γ such that
the function g := γf satisﬁes

γ

|

|

< 1. Then

2′′)

< 1,

g

k

k

3′′)

g(n)

k

k

< σ ,

and moreover

1′′)

g(k)(x0) = p(k)(x0),

g(k+1)(x0) = p(k+1)(x0) = 0.

Consider the diﬀerence h = p
function h has at least n
zeros strictly inside (
−
H ′ = h(k) has at least n

g. By the n-alternation property (2) of p, since

g
k
1, 1], hence H := h(k−1) has at least n

1 distinct zeros on [

−

−
1, 1), and by (1′′), we also have H ′(x0) = H ′′(x0) = 0.
1, 1] counting multiplicities, therefore

k + 1 zeros on [

−

< 1, the
k distinct
It follows that

k
−

−

−

h(n) has at least one sign change on [

1, 1].

−
< σ and

g(n)(x)
|
|
|
1, 1], a contradiction.

p(n)(x)

| ≡

On the other hand, by (3) and (3′′) we have
h(n)(x)
[
|

g(n)(x)
|

> 0 for all x

p(n)(x)

=

−

∈

−

|
|
Corollary 2.4 We have

where p is any polynomial of degree n that satisﬁes conditions (1)-(3) in (2.4).

m∗

k(x0, σ)

p(k)(x0)
|

≤ |

4

const

σ, hence
(cid:3)

≥

(2.5)

Let

Zn(
·

, θ)
}

{

be the family of the Zolotarev polynomials parametrized with respect to the
, θ) (see Sect. 3 for details). Given x0, our choice for p in
(x0, θx0) = 0. An advantage
[ωk, 1], the value of p(k)(x0) can be further bounded in terms

, θx0 ) such that Z (k+1)

n

value of its highest derivative θ := Z (n)
n (
·
(2.5) is the dilated Zolotarev polynomial Zn(
·
of choosing such a p is that, for x0 ∈
of the single Zolotarev polynomial Zn(
·

, θk) such that

Z (k+1)
n

(1, θk) = 0.

Namely, as we show in Sects. 3-4,

sup
x∈[ωk,1]

m∗

k(x0, σ)

max
{

1,

≤

σ
θk }

k/n max

n (ωk), Z (k)
T (k)

n (1, θk)
}

{

In Sects. 5-6, we provide the estimates for the values appeared here on the right-hand side and,
thus, arrive at the following statement.

Proposition 2.5 We have

sup
x∈[ωk,1]

m∗

k(x0, σ)

≤

A∗

n,k(σ) := 


T (k)
n−1(1),
λkT (k)

n (1)

0

≤
ηk ≤

σ
σn ≤
σ
σn ≤

ηk;

1.

1
ηk

σ
σn

k/n

,

(cid:16)

(cid:17)

(2.6)

where

λk =

1
k + 1

n

n

−


1
−
1 + k

,

ηk =

n
−
2(2n

(k + 1)

(k + 1)

−

.

1b2) Upper estimate for mk(x, σ). We use a technique based on the Lagrange interpolation. Let
i=1.

∞(σ) on a mesh ∆ = (ti)n

1 that interpolates f

ℓ∆ ∈ Pn−1 be the polynomial of degree n
From the identity f (k)(x) = ℓ(k)

∆ (x) + (f (k)(x)

−

W n
ℓ(k)
∆ (x)) it follows that

∈

−

where

whence

f (k)(x)

| ≤

|

Λk(x)
k

f

k

+ Ωk(x)
k

f (n)

,

k

Λk(x) = sup

kpk∆=1 |

p(k)(x)
|

,

Ωk(x) = sup

kf (n)k=1 |

f (k)(x)

ℓ(k)
∆ (x)
|

,

−

sup
x∈[0,ωk]

mk(x, σ)

sup
x∈[0,ωk]

≤

Λk(x) + sup

Ωk(x)σ .

x∈[0,ωk]

In Sect. 7, we prove that calculation of the suprema on the right-hand side is reduced to computing
the largest local maxima of two speciﬁc polynomials and that leads to the following estimate.

Proposition 2.6 We have

sup
x∈[0,ωk]

mk(x, σ)

≤

An,k(σ) :=

3

2k+1 T (k)

n−1(1) +

2
2k+1

2(k+1)
n+k T (k)

n (1)

σ
σn

.

(2.7)

The latter estimate is not particularly good for k = 1 and k = 2, so for such k we also use

another one

sup
x∈[0,ωk]

mk(x, σn)

k

1

≤

1

−

(cid:18)

sin k+1

2n (cid:19)

1
2k+1

T (k)
n (1) .

(2.8)

1c) Final step. The constants in estimates (2.3), (2.6) and (2.7) are easy to compare (they are
σn,

simple functions of t = σ/σn) and, in Sect. 8, we prove that if n
then

2 and 0

N, 1

≤

≤

≤

≤

−

∈

n

σ

k

max

An,k(σ), A∗

n,k(σ)

Bn,k(σ) ,

≤

(cid:0)

(cid:1)

5

and that implies

mk(1, σ) = sup

mk(x, σ),

x∈[−1,1]

σ

0

≤

≤

σn,

k

1

≤

≤

n

−

2.

2) The case σ > σn.

For that case, it is more convenient to reformulate the original problem. Namely, instead of

considering functions from the class

W n

∞(σ) :=

f : f

{

∈

W n
∞[

−

1, 1],

f

k

i.e., functions on a ﬁxed interval I1 = [
consider functions from the class

−

1,

f (n)

k[−1,1] ≤
1, 1] with increasing norms

k[−1,1] ≤

k

}

σ

,

σn < σ <

,
∞

f (n)

k

k[−1,1] ≤

σ, we will

W n

∞(Is) :=

f : f

{

∈

W n
∞[

−

s, 1],

f

1,

f (n)

k[−s,1] ≤
k
f (n)
k[−s,1] = σn on the intervals Is := [

k[−s,1] ≤

k

k

−

,

σn}

2 <

Is|

|

<

,
∞

(2.9)

s, 1] of increasing length

= 2. The pointwise Landau-Kolmogorov problem consists then of ﬁnding the value

i.e., functions with a ﬁxed norm
Is|

I1|

>

|

|

mk(x, Is) := sup
f ∈W n

∞(Is) |

f (k)(x)
|

,

and Karlin’s conjecture states that mk(x, Is) is maximal at x = 1.

2a) Lower estimate for mk(1, Is). Denote by B+
inequality on the half-line for the normalized functions:

n,k the best constant in the Landau-Kolmogorov

B+
n,k

:= sup

{|

= sup

f (k)(1)
:
f
|
k
f (k)
||[−∞,1] :
k
= 2 we have

{k
I1|

|

Proposition 2.7 For all

Is|

|

>

1,

f (n)

k[−∞,1] ≤
f

k
k[−∞,1] ≤

1,

k[−∞,1] ≤
f (n)

σn}
k[−∞,1] ≤

k

mk(1, Is)

B+

n,k .

≥

.
σn}

(2.10)

(2.11)

Proof. Clearly, with n and σn ﬁxed, the spaces deﬁned in (2.9) are embedded into each other,
namely W n
over those
∞(It) for s < t, therefore for the suprema mk(1, Is) := sup
spaces, we have the inequalities

f (k)(1)
|

∞(Is)

W n

⊃

|

mk(1, Is)

≥

mk(1, It),

s < t.

(cid:3)

Letting t =

, we obtain (2.11).

−∞

2b). Upper estimates for mk(x, Is) and m∗

bounds for mk(x, Is) and m∗
Namely, moving the interval I = [a, b] of length
hence

|

|

k(x, Is) are majorized by those of mk(x, I1) and m∗

k(x0, Is). Similar arguments show that the upper
k(x, I1), respectively.
∞(I),

= 2 inside any Is, we see that W n

∞(Is)

W n

I

⊂

sup
x∈[ωk,1]

sup
x∈[s0,ωk]

m∗

k(x, Is)

mk(x, Is)

sup
x∈[ωk,1]

sup
x∈[0,ωk]

≤

≤

m∗

k(x, I1)

mk(x, I1) .

where s0 is the middle of the interval [
m(∗)

k (x, σn) and for those we have the upper estimates (2.6)-(2.7).

−

s, 1]. The right-hand sides are equivalent to the values

6

Proposition 2.8 For all

Is|

|

>

= 2 we have

|

I1|
sup
x∈[ωk,1]
sup
x∈[s0,ωk]

m∗

k(x, Is)

mk(x, Is)

≤

≤

A∗

n,k(σn) ,

An,k(σn) .

(2.12)

(2.13)

2c) Final step. In Sect. 11 we prove that the constants in (2.11)-(2.13) satisfy the inequality

max

An,k(σn), A∗

n,k(σn)

B+

n,k ,

≤

k = 1, 2

and that proves that

(cid:0)

(cid:1)

mk(1, Is) = sup

mk(x, Is),

x∈[−s,1]

Is| ≥

|

2,

or, equivalently,

mk(1, σ) = sup

mk(x, σ),

σn < σ <

x∈[−1,1]

.
∞

3 Zolotarev polynomials

Here, we remind some facts about Zolotarev polynomials taking some extracts from our survey
[10, p.240-242]. Note that we use a slightly diﬀerent parametrization for Zn.

Deﬁnition 3.1 A polynomial Zn ∈ Pn is called Zolotarev polynomial if it has at least n equioscil-
lations on [

1, 1], i.e. if there exist n points

−

such that

1

−

≤

τ1 < τ2 <

< τn−1 < τn ≤

1

· · ·

1)n−iZn(τi) =

(
−

Znk

k

= 1.

There are many Zolotarev polynomials, for example the Chebyshev polynomials Tn and Tn−1 of
degree n and n
1, with n + 1 and n equioscillation points, respectively. One needs one parameter
more to get uniqueness. We will use parametrization through the value of the n-th derivative of
Zn:

−

Z (n)
n k

k

= θ

⇔

Zn(x) := Zn(x, θ) :=

θ
n!

n−1

xn +

ai(θ)xi .

i=0
X

By Chebyshev’s result,

p(n)

k

As θ traverses the interval [
tions:

−

T (n)
n

p

, so the range of the parameter is

k

k k
σn,

k ≤ k
σn ≤
σn, σn], Zolotarev polynomials go through the following transforma-

= 2n−1 n! .

T (n)
n k

σn =

≤

k

θ

−

Tn(x)

−

→ −

Tn(ax + b)

→

Zn(x, θ)

→

Tn−1(x)

→

Zn(x, θ)

→

Tn(cx + d)

Tn(x) .

→

Zolotarev polynomials subdivide into 3 groups depending on the stucture of the set

of their alternation points.

:= (τi)

A

1)

2)

3)

contains n + 1 points: then Zn is the Chebyshev polynomial Tn.

A

contains n points but only one of the endpoints: then Zn is a stretched Chebyshev

A
polynomial Tn(ax + b),

< 1.

a

|

|

contains n points including both endpoints: then Zn is called a proper Zolotarev
A
polynomial and it is either of degree n, or the Chebyshev polynomial Tn−1 of degree
n

1.

−

7

For a proper Zolotarev polynomial Zn, besides the interior alternation points (τi)n−1
1, 1] where its ﬁrst derivative vanishes.

a point β = β(θ) outside [

i=2 , there is

V. Markov proved that zeros of Z ′

with β going through the inﬁnity as θ passes the zero.
Z ′
same is true for their derivatives of any order. In particular, the following lemma is true.

σn, σn],
It follows that, for any θ1, θ2, zeros of
, θ2) interlace with each other, hence by the Markov interlacing property the

, θ) are monotonically increasing functions of θ

, θ1) and Z ′

n(
·

n(
·

n(
·

−

∈

[

−

Lemma 3.2 Let (αi)M−1
be the zeros of Z (m)
n (
·

i=1 be the zeros of T (m)
, θ). Then, (αi) and (τi) interlace, i.e.,

n−1 in increasing order, and, for any given θ, let (τi)M
i=1

Another consequence of the interlacing property is the following observation.

τ1 < α1 < τ2 < α2 < τ3 <

< αM−1 < τM .

· · ·

Lemma 3.3 Let ωk be the rightmost zero of T (k+1)
whose (k + 1)st derivative vanishes at x = 1, i.e.,

n

, and let Zn(
·

, θk) be the Zolotarev polynomials

T (k+1)
n

(ωk) = 0,

Z (k+1)
n

(1, θk) = 0 .

Further, for a given x0 ∈

Then

(ωk, 1), let Zn(
·

, θx0 ) be the Zolotarev polynomial such that

Z (k+1)
n

(x0, θx0) = 0,

x0 ∈

[ωk, 1] .

θx0 |
Proof. According to our parametrization, we have
0, the rightmost zero of Z (k+1)

θk|

σn to

<

n

|

|

−
1 for some θ := θk. Therefore

−

(
·

< σn .

Tn(x) = Zn(x,
, θ) increases from ωk to +

−

σn), and as θ increases from
, passing through the value

−
∞

ωk < x0 < 1

σn < θx0 < θk.

⇔ −

2) Here we give some upper estimates for the values T (k)

n (1). The
n (ωk) has been given on several occasions, we summarize what we need in the

n (ωk) relative to the value T (k)

estimates for T (k)
following statement.

Lemma 3.4 Let ωk := ωn,k be the rightmost zero of T (k+1)

n

. Then

1)

2)

3)

T (k)
n (ωk)

| ≤

|

T ′

n(ω1)

| ≤

n (ω2)

| ≤

|
T ′′

|

T (k)
n (1), n

1
2k+1
1
4
8
55 T ′′

T ′

n(1),

n (1),

1

k

1;

n

−

≤

≤

(3.1)

N,

5;

10.

∈

≥

≥

n

n

Proof. The ﬁrst inequality was proved by Eriksson [3] who actually derived a stronger estimate:

where

T (k)
n (ωk)

| ≤

|

Fk(ωk)
2k+1 T (k)

n (1),

Fk(x) :=

2(1 + x)2

(2k + 5)x + 2 ≤

1,

[0, 1].

x

∈

The second inequality is due to Erd¨os–Szeg¨o [2, p.464]. To derive the third one, we note that the
function Fk(
·

) has the single minimum at x∗ = 2k+1

2k+5 = 5

F2(ω2) < F2(1) =

9 , therefore, if x∗ < ω2 < 1, then
8
11

.

(3.2)

But ω2 is the largest zero of the third derivative of Tn, therefore it is greater than the third largest
(cid:3)
zero of T ′

5
9 , and the latter holds for n

n , so (3.2) is valid if cos 3π

n, i.e., ω2 > cos 3π

10.

≥

n ≥

8

Corollary 3.5 We have

max
x∈[0,ωk−1] |

T (k)
n (x)

| ≤

1

2k+1 T (k)

n (1)

Proof. The values of local maxima of
have

T (k)
n (ξi)
|

|

max
x∈[0,ωk] |

T (k)
n (x)

| ≤ |

T (k)
n (ωk)

| ≤

increase with

, and since ωk = maxi |
ξi|
|
2k+1 T (k)
n (1)

1

(3.3)

, we

ξi|

On the interval [ωk, ωk−1] the value
|
n (ωk) to the rightmost zero T (k)
T (k)

decreases monotonically from the rightmost maximum
(cid:3)

n (ωk−1) = 0, hence the inequality for such x.

T (k)
n (x)
|

4 A generalization of Erd¨os–Szeg´o result

By
p

Qn we denote the unit ball in the space
k ≤

1. According to the well-known Markov inequality

k

Pn, i.e., the set of polynomials p

∈ Pn such that

sup
p∈Qn |

p′(x)

| ≤

n2,

x

[

−

∈

1, 1] ,

and equality is attained at x = 1 for p = Tn.

In 1913, Schur [9] considered the problem of ﬁnding the maximum of

under additional
n(x0) be the unit ball of polynomials such that p(k+1)(x0) = 0.
k

p′(x0)
|

|

assumption that p′′(x0) = 0. Let
Shur proved that

Q

sup

p∈Q1

n(x0) |

p′(x0)
|

<

1
2

n2 .

(4.1)

Moreover, he showed that if λn is the least constant in front of n2, then, for λ∞ := lim supn→∞ λn,
we have

λ∞ ≤
In 1942, Erd˝os and Szeg˝o [2] reﬁned Shur’s result by showing that the limit λ∞ = limn→∞ λn

0.217

0.465

· · · ≤

· · ·

.

exists and it is equal to

λ∞ = κ−2(1

−

E/K)2 = 0.3124

· · ·

where E, K are the complete elliptic integrals associated with the modulus κ.
improve the uniform bound (4.1) though.)
[
They also showed that, for any x0 ∈

1, 1], the supremum of

p′(x0|

−

|

, θ), and that the maximum over x0 is attained at x0 = 1 for n

is attained when p is a
4, and

Zolotarev polynomial Zn(
·
at x0 = 0 for n = 3.

≥

(4.2)

(They did not

In this section, we generalize these results to the derivatives of order k

2.

≥

Denote by

∈
the best constant in the pointwise Markov inequality, and by

p∈Qn |

µk(x) := max

p(k)(x)
|

,

x

1, 1],

[

−

µ∗

k(x0) := max

p∈Qk

n(x0) |

p(k)(x0)
|

x0 ∈

[

−

1, 1],

the best constant in the pointwise Schur-type inequality. It is clear that

µ∗

k(x0)

≤

µk(x0),

x0 ∈

[

−

1, 1] ,

k(x0) = 0, i.e. if x0 is a point of local extremum (maximum or

The next two lemmas are straightfroward extensions of the arguments given in [2, pp.461-462],

and that equality occurs only if µ′
minimum) of the function µk(
·

) inside (

1, 1).

−

from k = 1 to k

2.

≥

9

Lemma 4.1 For any θ, if Z (k+1)

n

(x0, θ) = 0, then

Conversely, for any x0 ∈
is true.

[

1, 1], with some θ = θx0 there is a polynomial Zn(
·

−

, θ) such that (4.3)

µ∗
k(x0) = Z (k)

n (x0, θ).

(4.3)

Lemma 4.2 Let x0 be a point such that

k(x0) < µk(x0)
[x0 −
Then, for small δ > 0, there is a point x1 ∈
µ∗
k(x0) < µ∗

µ∗

k(x1) .

=

1 .

and x0 6
δ, x0 + δ], such that

±

Proof. Let µ∗

k(x0) = Z (k)

n (x0), where Z (k+1)

n

(x0) = 0 and let p

∈ Qn be the polynomial such that

Then the polynomial q = (1

k

−
q

k ≤

p(k)(x0) > Z (k)

n (x0) > 0 .

ǫ)Zn + ǫp satisﬁes

1,

q(k)(x0) > Z (k)

n (x0) = µ∗

k(x0) ,

and, for small ǫ, its k-th derivative has a local maximum in the neighbourhood of x0 (because Z (k)
n
has). Let x1 be the point of that maximum, i.e., q(k+1)(x1) = 0. Then q(k)(x1) > q(k)(x0), and
respectively

the latter inequality by deﬁnition of µ∗
k(
·

).

µ∗
k(x0) < q(k)(x0) < q(k)(x1)

µ∗

k(x1) ,

≤

(cid:3)

Corollary 4.3 Let η be a point of local maximum of the function µ∗
k(
·

). Then

µ∗

k(η) = µk(η).

Theorem 4.4 Let Zn(x, θk) be the Zolotarev polynomial such that

Then

Z (k+1)
n

(1, θk) = 0.

max
x0∈[−1,1]

µ∗

k(x0) = max

T (k)
n (ωk)
|

,

|

{|

Z (k)

n (1, θk)

|}

.

Proof. Let ηi be the points of local maxima of of µ∗
k(
·
k(ηi), µ∗
µ∗

k(x0) = max

µ∗

max
x0∈[−1,1]

{

k(1)
}

) inside the interval (

1, 1). Then

−

) coincide with the extrema
The corollary shows that, inside (
(maxima or minima) of µk(
). On the other hand, V. Markov proved that the local maxima of
·
T (k)
) coincide with those of
µk(
n
|
·

1, 1), the local maxima of µ∗
k(
·

. Hence

−

|

max
x0∈[−1,1]

µ∗

k(x0) = max

T (k)
n (ξi)
|

, µ∗

k(1)
}

{|

, where T (k+1)

n

(ξi) = 0 .

Further, it is known that the local maxima of

T (k)
n

|
T (k)
n (ξi)
|

|
=

are increasing as

increases, i.e,

ξi|

|

T (k)
n (ωk)
|

|

,

max
i

|
where ωk is the rightmost zero of T (k+1)

n

. Finally, by Lemma 4.1,

and that completes the proof.

µ∗

k(1) =

Z (k)

n (1, θk)
|

,

|

10

(cid:3)

Theorem 4.5 Let Zn(x, θk) be the Zolotarev polynomial such that

Z (k+1)
n

(1, θk) = 0.

Then

max
x0∈[ωk,1]

m∗

k(x0, σ)

max

1,

{

≤

σ
θk }

k/n max

T (k)
n (ωk)
|

,

|

{|

Proof. According to Corollary 2.4,

where p is any polynomial of degree n such that

m∗

k(x0, σ)

p(k)(x0)
|

,

≤ |

Z (k)

n (1, θk)

|}

.

1) p(k+1)(x0) = 0 ,

2) p has an n-alternance in [

1, 1],

3)

p(n)

σ .

We take p as a dilated Zolotarev polynomial Zn(
·
satisﬁes conditions (1)-(2), and its highest derivative has the value θx0. So, if θx0 ≥
condtion (3) is fulﬁlled with p = Zn(
·
So we set

k ≥
(x0, θx0) = 0. The latter
σ, then
, θx0), but if θx0 < σ, then we have to scale Zn to ensure (3).

, θx0) such that Z (k+1)

−

k

n

p(x) := Zn(x0 + γ1/n

0

(x

−

x0), θx0 ),

γ0 := max

1,

{

σ
θx0 }

,

whence

Finally,

m∗

k(x0, σ)

≤

p(k)(x0) = max

1, (

{

σ
θx0

)k/n

}

Z (k)

n (x0, θx0).

ωk ≤

x0 ≤

1

1)

2)

⇒ 


Z (k)
n (x0, θx0)
|
θx0| ≤
θk| ≤ |

|

| ≤
σn ,

max
{

n (ωk), Z (k)
T (k)

n (1, θk)
}

,

where the ﬁrst inequality us due to Theorem 4.4, and the second one is due to Lemma 3.3.



(cid:3)

5 Upper estimates for Z (k)

n (1, θk) and generalization of Schur

inequality

Recall that by Markov’s inequality

sup
kp(k)k≤1 |

p(k)(x)

| ≤ |

T (k)
n (1),

x

[

−

∈

1, 1],

so we will give some upper estimates for the constant λk such that

We will get those estimates using the following lemma.

Z (k)

n (1, θk)

λkT (k)

n (1)

≤

Lemma 5.1 Let p

∈ Pn be any polynomial that satisﬁes the following conditions:
1)

p has an n-alternance on [

p(k+1)(1) = 0 ,

1, 1].

1)

−

If Z (k+1)
n

(1, θk) = 0, then

|

Z (k)

n (1, θk)

| ≤ |

p(k)(1)
|

.

(5.1)

(5.2)

Proof. The proof is parallel to the proof of Lemma 2.3, since Zn satisﬁes
the contrary to (5.2), we derive that the n-th derivative of h := p
which is impossible as h is a polynomial of degree n

Znk ≤

1. Assuming
γZn should change its sign
(cid:3)

−

k

2a) We will construct several p that satisfy (5.1) using alternation properties of Tn and Tn−1.

We start with the simplest one.

11

Lemma 5.2 We have

|

Proof. Take

Z (k)

n (1, θk)

| ≤

1
k + 1

T (k)
n (1) .

(5.3)

p(x) = Tn(x)

−

cq(x),

q(x) := (x

1)T ′

n(x) ,

−

p(k+1)(1) := 0,

so that p has an n-alternance on [
c := T (k+1)

(1)
q(k+1)(1) . Then

n

cos π

n , 1] for any c, and where the last equality deﬁnes particular

−

p(k)(1) = T (k)

n (1)

cq(k)(1) =

−

T (k+1)
(1)
n
q(k+1)(1)

1

−

q(k)(1)
T (k)
n (1) !

T (k)
n (1) ,

and since q(m)(1) = mT (m)

n

(1), it follows that

p(k)(1) =

1
(cid:18)

−

k
k + 1

(cid:19)

T (k)
n (1) =

1
k + 1

T (k)
n (1) .

2b) The next lemma improves the previous estimate for k =

(n).

O

Lemma 5.3 We have

|

|

Proof. Take

Z (k)

n (1, θk)

| ≤

Z (k)

n (1, θk)

| ≤

T (k)
n−1(1) ,
n
1
k + 1

n

−

1
−
1 + k

T (k)
n (1) .

p(x) = Tn−1(x)

cq(x),

−

q(x) := (x2

1)T ′

n−1(x) ,

−

p(k+1)(1) := 0 .

Then

p(k)(1) = T (k)

n−1(1)

cq(k)(1) =

−

T (k+1)
n−1 (1)
q(k+1)(1)

1

−

q(k)(1)
T (k)
n−1(1) !

T (k)
n−1(1) =:

λn,kT (k)

n−1(1) .

(cid:3)

(5.4)

(5.5)

1)2Tn−1(x), we have

b

Since q′(x) = (x2

−

1)T ′′

n−1(x) + 2xT ′

n−1(x) = xT ′

n−1(x) + (n

and using

q(m)(1) = T (m)

n−1(1) + ((n

1)2 + (m

−

−

T (k+1)
n

(1) =

k2
n2
−
2k + 1

T (k)
n (1),

T (k−1)
n

(1) =

we obtain, after some simpliﬁcations,

−
1))T (m−1)
n−1

2k

1

−
(k

−

n2

−

(1) ,

1)2 T (k)

n (1),

λn,k = 1

b

=

≤

k
k + 1

−
1
k + 1
1
k + 1

+

+

2(n
k
k + 1
k
k + 1

(n

−

1)2

k2

−
−
1)2 + (k + 1)
4k(n
(k

1)2

2(n
(n

1)2 + (k
−
1)2
(k
−
−
1)2 + (k
−
1)2)(2(n

1)
−
1)2
−
1)
−
1)2 + (k + 1))
−

−

((n
1

−

k ≤

n

−

−
1

12

 
 
and that proves the ﬁrst inequality (5.4). Using

T (k)
n−1(1) = γT (k)

n (1),

γ =

n

1

−
n

n

k
−
1 + k

,

n

−

we obtain

λn,k =

λn,kγ

and that proves (5.5).

b

1
k + 1

n

≤

n

−

γ =

k

1
k + 1

n

1
−
1 + k

n

−

2c) In the next lemma, we get further improvements for k = 1 and k = 2.

Lemma 5.4 We have

Z ′

n(1, θ1)

1
3

≤

T ′
n(1),

Z ′′

n(1, θ2)

3
π2

≤

Proof. Set ξ := cos π

n , and let

π2
15

6
π2 < 0.23 T ′′
−
−

n (1) .

r(x) = Tn(x)

cq(x),

−

q(x) := (x + 1)T ′

n(x),

r(k+1)(ξ) := 0 .

(cid:3)

(5.6)

The polynomial r has an n-alternance on [

to the polynomial p(x) := r

−

(cid:16)

−
1 + (x + 1) 1+ξ
2

1, ξ], so that, after ﬁnding r(k)(ξ) we will transform it
1, 1] and satisﬁes

, which has an n-alternance on [

−

p(k)(1) =

(cid:17)
1 + ξ
2

(cid:18)

k

(cid:19)

r(k)(ξ) .

Let us ﬁnd r(k)(ξ). We have

r(k)(ξ) = T (k)

n (ξ)

−

cq(k)(ξ) = T (k)

n (ξ)

q(k)(ξ)
q(k+1)(ξ)

−

T (k+1)
n

(ξ) ,

where

q(m)(ξ) = (1 + ξ)T (m+1)

n

(ξ) + mT (m)

n

(ξ) ,

so that setting ak := T (k)

n (ξ), we obtain

r(k)(ξ) = ak −

(1 + ξ)ak+1 + kak
(1 + ξ)ak+2 + (k + 1)ak+1

ak+1 .

Further, we have

a0 = Tn(ξ) =

1,

a1 = T ′

n(ξ) = 0,

−
2, the values ak can be computed from the recurrence relation

and, for k

≥

(ξ2

−

1)ak+2 + (2k + 1)ξak+1 = (n2

k2)ak .

−

In particular, we ﬁnd

a2 =

For k = 1, this gives

n2

1

−

ξ2 ,

a3 =

3ξ

1

−

ξ2 a2,

a4 =

5ξ

1

−

ξ2 a3 −

n2
1

22
ξ2 a2 .
−
−

r′(ξ) =

(1 + ξ)a2
(1 + ξ)a3 + 2a2

−

a2 =

n2

−

2 + ξ ⇒ |

p′(ξ)
|

=

1 + ξ
2(2 + ξ)

T ′
n(1) <

1
3

T ′
n(1) .

13

For k = 2, we obtain

r′′(ξ) = a2 −

(1 + ξ)a3 + 2a2
(1 + ξ)a4 + 3a3

a3 ⇒

p′′(1) = c(n, ξ)T ′′

n (1) ,

where

c(n, ξ) =

1 + ξ
2

2

6ξ + 3ξ2

(cid:18)

(cid:19)

(cid:18)

(2ξ2 + 9ξ + 4)

n2(1

−

−

1

ξ2) −

1

1

(cid:19)

−

ξ2

n2

3

−

.

1

One can show that c(n, ξ) = c(n, cos π

n ) is increasing with n to its limit value given in (5.6).

(cid:3)

Remark 5.5 We checked two other possibilities to construct p.

1) The option

p(x) = Tn(x)

cq(x),

−

q(x) := (x + 1)T ′

n(x) ,

p(k+1)(1) := 0 ,

results in

p(k)(1)
|

|

=

1
2k + 1

4n2

1

−
(2n2 + (k + 1))

T (k)
n (1) ,

which is slightly worse than (5.3).

2) The option

p(x) =

x
1

γ
γ

Tn−1(x),

p(k+1)(1) := 0 ,

−
−

is very poor for small k, and for large k =

(n) it is slightly worse than (5.5).

O

6 Lower bound for Z (n)
n (

, θk)
·

Lemma 6.1 Let Zn(x, θk) be a Zolotarev polynomial such that

Z (k+1)
n

(
−

1, θk) = 0.

Then

θk :=

Z (n)

n k ≥

k

ηn,kσn,

ηn,k :=

n
−
2(2n

−

(k + 1)

(k + 1))

.

Proof. Set m = k + 1 and M = n

−

−

m, and denote by (τi)M

i=1 the zeros of Z (m)

n

in increasing order:

1 = τ1 < τ1 <

< τM < 1.

· · ·

Then

where

Z (m)

n (x) = A(x + 1)(x

τ2)

(x

−

· · ·

−

τM ) ,

A =

2(1

−

Z (m)
τ2)

n (1)
(1

· · ·

=:

1
2

A1
A2

,

τM )

−

and respectively

A1
A2
Let us ﬁnd lower bounds for the constants A1 and 1/A2.
1) Let (αi)M−1

i=1 be the zeros of T (m)

Z (n)
n k

= A M ! =

M !
2

k

n−1 in increasing order. They interlace with zeros of Z (m)

n , i.e.

.

(6.1)

1 = τ1 < α1 < τ2 < α2 < τ3 <

< αM−1 < τM < 1,

· · ·

−

14

therefore

On the other hand,

T (m)
n−1(x) = k

T (n−1)
n−1 k
1)!
(M
−

and respectively

1
A2

:=

1

(1

−

τ2)

· · ·

(1

−

τM )

>

(1

−

α1)

1
(1

· · ·

αM−1)

−

(x

−

α1)

· · ·

(x

−

αM−1)

⇒

T (m)
n−1(1) = k

T (n−1)
n−1 k
1)!
(M
−

(1

α1)

(1

−

· · ·

−

αM−1) ,

1
A2

>

(1

α1)

1
(1

αM−1)

=

(M

1

−

1)!

T (n−1)
n−1 k
k
T (m)
n−1(1)

.

(6.2)

−
2) The lower bound for A1 is provided by

· · ·

−

A1 := Z (m)

n (1, θk)

T (m)
n−1(1)

≥

θk

σn −
σn

+ T (m)
n

(1)

θk
σn

=

T (m)
n−1(1)
σn  

(σn −

θk) +

(1)

T (m)
n
T (m)
n−1(1)

θk

!

.

(6.3)

3) Combining estimates (6.1)-(6.3), we obtain

m

n

−
2

T (n−1)
n−1 k
σn

k

θk ≥

(σn −

θk) +

(1)

T (m)
n
T (m)
n−1(1)

θk

.

!

From the relations

T (n−1)
n−1 k
σn

k

:= k

it follows that

T (n−1)
n−1 k
T (n)
n

k

k

=

1
2n

,

(1)

T (m)
n
T (m)
n−1(1)

=

n

n

−

1

n

−
n

1 + m
m

−

>

n + m
m
n

−

,

θk >

n

m

−
4n

σn −

θk +

(cid:18)

n + m
m
n

−

θk

=

(cid:19)

n

m

−
4n

σn +

(cid:18)

2m

m

n

−

θk

.

(cid:19)

So, (1

m

2n )θk ≥

−

n−m
4n σn, and ﬁnally

θk >

n
−
2(2n
−

m
m)

σn,

m = k + 1 .

Proposition 6.2 We have

sup
x∈[ωk,1]

m∗

k(x0, σ)

≤

A∗

n,k(σ) := 


T (k)
n−1(1),
λkT (k)

n (1)

0

≤
ηk ≤

σ
σn ≤
σ
σn ≤

ηk;

1.

1
ηk

σ
σn

k/n

,

(cid:16)

(cid:17)

(6.4)

where

λk =

1
k + 1

n

n

−


1
−
1 + k

,

ηk =

n
−
2(2n

(k + 1)

(k + 1)

−

.

7 Upper estimates for mk(x) for x

[0, ωk]

∈

Lemma 7.1 We have

mk(x)

3
2k + 1

≤

T (k)
n−1(1) +

2
2k + 1

2(k + 1)
n + k

T (k)
n (1)

σ
σn

.

15

 
Proof. For f
the points of local extrema of Tn−1 on the interval [

∞(σ), let l

∈ Pn be the Lagrange polynomial of degree n that interpolates f at

1, 1], i.e.

∈

W n

l(x) = f (x),

(x2

n−1(x) = 0 .

−
1)T ′

−

Then

where

f (k)(x) = l(k)(x) + (f (k)(x)

l(k)(x))

Dk(x)
k

f

k

+ Ωk(x)
k

≤

f (n)

,

k

−

Dk(x) := sup

kpn−1k∗=1 |

p(k)
n−1(x)
|

,

Ωk(x) := sup

kf (n)k=1 |

f (k)(x)

l(k)(x)
|

.

−

1) For the ﬁrst constant, we have the estimate

Dk(x)

max
{

U (x), V (x)
}

,

≤

where U (x) :=

T (k)
n−1(x)
|

|

and

V (x)

:=

≤

We have

(x2

1) T (k+1)

n−1 (x) + xT (k)

1
k
(cid:12)
k
(cid:12)
(cid:12)

−
T (k)
n−1(x)
|

1
−
k |

n−1(x)
(cid:12)
(cid:12)
−
(cid:12)

(k

−
k

(n

−

+

1)2

1)2

T (k−1)
n−1 (x)
|

|

.

U (x)

V (x)

≤

≤

=

=

1
2k + 1
1
k

−
k
k

(cid:18)

−
k
3
2k + 1

T (k)
n−1(1) ,

1
2k + 1
1
1
2k + 1

T (k)
n−1(1) .

T (k)
n−1(1) +

1)2

(n

−

1)2

(k

−

−
k

1

2k

1

−

T (k−1)
n−1 (1)

+

1
k

(cid:19)

T (k)
n−1(1)

2) For the second constant, we have

Ωk(x)

max

≤

1
n!

|

ω(k)(x)
|

.

where ω(x) = c(x2

−

1)T ′

n−1(x), with its leading coeﬃcient equal to one, i.e., c = 1
2n−2

1
n−1 . Set

q(x) := (x2

1)T ′

n−1(x) .

−

Then

Since q′(x) = (n

−

Ωk(x)

1
2n−2

1
n!

≤

n
1)2Tn−1(x) + xT ′

1

−

n−1(x), we have

max

q(k)(x)
|

|

=

1

2
σn

n

1

−

1

max

q(k)(x)
|

|

.

q(k)(x) = ((n
(n

−

−

−

1)2 + (k
1)2 + (k
1
2k
1)2 + (k
1)2
(k

−

−

−

(n
(n

(cid:18)

−
−

≤

=

n−1 (x) + xT (k)

n−1(x)

1))T (k−1)
1)

T (k−1)
n−1 (1) +

1
2k + 1

T (k)
n−1(1)

1)
1)2 +
−
−

1
2k + 1

(cid:19)

T (k)
n−1(1) =

cn,k
2k + 1

T (k)
n (1) ,

where

cn,k =

2(k + 1)(n

1)2 + (k + 2)(k
1 + (k

−
1 + k)(n

−
1))

−

−

(n

−

1)

n

1
−
n ≤

2(k + 1)

1
−
1 + k

n

1
−
n ≤

n

−

n

2(k + 1)

n
1
−
n + k

.

16

Thus

Ωk(x)

2
2k + 1

2(k + 1)
n + k

1
σn

≤

T (k)
n (1) .

Corollary 7.2 We have

mk(x, σn)

3
2k + 1

≤

T (k)
n (1) ,

2 .

k

≥

(cid:3)

Proof. We have

where

αn,k =

=

3
2k + 1
3
2k + 1

Lemma 7.3 We have

mk(x, σn)

≤

αn,kT (k)

n (1),

k
−
1 + k

+

2
2k + 1

2(k + 1)

n + k ≤

3
2k + 1

n
k
−
n + k

+

2
2k + 1

2(k + 1)
n + k

n

1

n

−
n

n

−
3n + k + 4

3n + 3k ≤

3
2k + 1

.

max
x∈[0,ωk]

mk(x, σn)

≤

(1

−

1
δk/2)k T (k)

n (ωk) ,

where δk is the maximal distance between two consecutive zeros of T (k+1)

n

.

Proof. We will use the following estimate. Let f
Then

∈

W n

∞(σn), i.e.,

f

1 and

f (n)

k

k ≤ k

T (n)
n

.

k

Let (ξi) be the zeros of T (k+1)

n

T (k+1)
n

(ξi) = 0

f (k)(ξi)

⇒ |
, and let δk = maxi |

| ≤ |
ξi −

Tn(x) = Tn(γx),

γ =

> 1.

k ≤

k
T (k)
n (ωk) .

| ≤
. Set

T (k)
n (ξi)
ξi+1|
1
δk/2)

(1

−

Then

b
(ξ) = 0

T (k+1)
n

Corollary 7.4 We have

b

f (k)(ξ)

| ≤ |

T (k)
n (ξ)

| ≤

γkT (k)

n (ωk) .

⇒ |

max
x∈[0,ωk]

mk(x, σn)

b

1

≤  

1

−

sin π(k+1)

2n !

k

T (k)
n (ωk) .

Proof. Since (cos πi
ξi < cos πi

n ) are zeros of T ′

n, the zeros ξi of T (k+1)

n

are located in the intervals cos π(i+k)

n <

n , and for the distance between two consecutive ξi we have

δk = max

i

ξi −

|

ξi+1| ≤

Corollary 7.5 We have

max
i

(cid:12)
(cid:12)
(cid:12)
(cid:12)
max
x∈[0,ω1]

cos

πi
n −

cos

π(i + (k + 1))
n

2 sin

≤

π(k + 1)
2n

.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(7.1)

m1(x, σn)

1
2

≤

T ′
n(1) .

17

Proof. a) For n = 4, we have

T4(x) = 8x4

−

8x2 + 1,

T ′
4(x) = 16(2x3

x),

−

T ′′
4 (x) = 16(6x2

1),

−

ω1 = 1/√6,

δ1/2 = 1/√6,

4(ω1) = 32/3√6 = 2/3√6T ′
T ′

n(1) ,

so that

hence

α4 =

1

−

1
1/√6

2
3√6

< 0.46

0.5 .

≤

b) For n = 5, we have

Tt(x) = 16x5

−

20x3 + x,

T ′
5(x) = 5(16x4

−

12x2 + 1),

T ′′
5 (x) = 40x(8x3

3),

−

so that

and

ω1 =

3
8

,

r

δ1/2 =

1
2 r

3
8

,

1

1
2

1
4

3
8

T ′
5(ω1) =

25
4

=

1
4

T ′
5(1) ,

< 0.361

1/2 .

≤

α5 =

1

−

c) For n

≥

6, we have T ′

n(ω1)

≤

q
n(1), hence

1

4 T ′

αn ≤

1

−

1
sin π
n

1
4 ≤

1/2 .

(cid:3)

8 Proof of Theorem 1.3, the case k

n

2

−

≤

Theorem 8.1 We have

max
x0∈[ωk,1]

m∗

k(x0, σ)

≤

mk(1, σ),

σ

0

≤

≤

σn.

Proof. 1) The case σ

≤

θk. By Lemma 5.3, we have

while

m∗

k(x0, σ)

T (k)
n−1(1) ,

≤

mk(1, σ) > mk(1, σ0) = T (k)

n−1(1).

2) The case σ > θk. In this case

m∗

k(x0, σ)

1
k + 1

n

≤

1
−
1 + k

n

−

(cid:18)

k/n

σ
θk (cid:19)

T (k)
n (1) = γ

t
α

(cid:18)

k/n

(cid:19)

T (k)
n (1) ,

and

where

α :=

mk(1, σ)

(1

−

≥

t)T (k)

n−1(1) + tT (k)

n (1) = (β(1

t) + t) T (k)

n (1) ,

−

n
−
2(2n

−

(k + 1)

(k + 1))

,

β :=

T (k)
n−1(1)
T (k)
n (1)

n

=

1

−
n

n

k
−
1 + k

,

n

−

t := σ/σn .

18

So, we need to prove that

f (t) := γ

t
α

(cid:18)

k/n

(cid:19)

β(1

−

≤

t) + t =: g(t) ,

[α, 1] .

t

∈

The function f is concave, therefore it is bounded from above by its tangent ℓ at t = 2α, i.e.

So, we are done, once we prove that

f (t)

≤

ℓ(t) = γ2k/n

1 +

(cid:18)

t

k
n

2α

−
2α

.

(cid:19)

ℓ(t)

≤

g(t) on[α, 1].

Both functions are straight lines, so we need to check this inequality only at the end-points.

1) At t = α, we have

ℓ(α) = γ2k/n

k
2n

1
(cid:18)

−

γ

1 +

(cid:18)

≤

(cid:19)

k
n

,

(cid:19)

g(α)

≥

g(0) = β .

So, we need the inequality

γ

n + k

n ≤

β

⇔

1
k + 1

n

amd the latter is valid for k

n

≤

−

2) At t = 1, we have g(1) = 1, while

n

1
−
1 + k

−
2.

n + k

n

n ≤

1

−
n

n

n

−

k

−
1 + k ⇔

n + k
k + 1 ≤

k ,

n

−

ℓ(1) = γ2k/n

1 +

k
n

1

2α

−
2α

=

1
k + 1

n

1
−
1 + k

n

−

2k/n

1 +

(cid:18)

k
n

n
(k + 1))

.

(cid:19)

(n

−

(cid:18)
Expression in the parenthesis is less than 1 + k, so

(cid:19)

Theorem 8.2 We have

ℓ(1)

≤

2k/n n
n
−

1

−
1 + k ≤

n + k
n

n

1
−
1 + k

n

−

< 1.

max
x∈[0,ωk]

mk(x, σ)

≤

mk(1, σ),

σ

0

≤

≤

σn.

Proof. 1) For k

≥

2, we use the estimates

mk(x, σ)

3
2k + 1

≤

T (k)
n−1(1) +

2
2k + 1

2(k + 1)
n + k

t T (k)

n (1) =: ℓ1(t) .

and

To prove that ℓ1(t)

≤

mk(1, σ)

(1

≥

−

t)T (k)

n−1(1) + tT (k)

n (1) =: ℓ2(t),

ℓ2(t) it is suﬃcient to compare their values at the end-points:

ℓ1(0) =

ℓ1(1)

3
2k + 1
5
2k + 1

≤

T (k)
n−1(1)

T (k)
n−1(1) = ℓ2(0) ,

≤

T (k)
n (1)

≤

T (k)
n (1) = ℓ2(1) .

2) For k = 1, we use the following estimates:

mk(1, σ)

≥

mk(1, σ0) = T ′

n−1(1) =

(n

1)2

−
n2

T ′
n(1)

9
16

≥

T ′
n(1) ,

and

mk(x, σ)

≤

mk(x, σn)

1
2

≤

T ′
n(1) .

19

9 Proof of Theorem 1.3: the case k = n

1

−

Here we cover the case k = n

1 for 0

σ

≤

≤

σn.

−

Theorem 9.1 We have

mn−1(x, σ)

≤

mn−1(1, σ) = Z (n−1)

n

(1, σ),

σ

0

≤

≤

σn .

Proof. For f
f at the points of local extrema of Zn(
·

∞(σ), let l

∈

W n

∈ Pn−1 be the Lagrange polynomial of degree n

1 that interpolates

−

, σ) on the interval [

1, 1], i.e.

−
< τn−2 < τn−1 = 1.

l(τi, σ) = f (τi),

1 = τ0 < τ1 <

−

· · ·

Then

f (n−1)(x) = l(n−1)(x, σ) + (f (n−1)(x)

l(n−1)(x, σ))

Dn−1(x, σ)
k

f

k

+ Ωn−1(x, σ)
k

≤

f (n)

,

k

−

where

Dn−1(x, σ) := sup

kpn−1k∗=1 |

p(n−1)
n−1 (x)
|

,

Ωn−1(x, σ) := sup

kf (n)k=1 |

f (n−1)(x)

l(n−1)(x, σ)
|

.

−

Therefore,

mn−1(x, σ)

Dn−1(x, σ) + Ωn−1(x, σ)σ .

≤

1) It is known that the extremum value Dn−1(x, σ) (which is a constant, since p(n−1)

is attained by the polynomial p

∈ Pn−1 such that

It is easy to see that, with

p(τi, σ) = (

−

1)i,

i = 0, . . . , n

1 .

−

ω(x, σ) :=

(x

τi),

−

we have

Y

−
Indeed, (9.2) is clearly fulﬁlled, and p is of degree n
polynomials on the right-hand side are equal to σ/n!. Therefore

−

p(x) = Zn(x, σ)

ω(x, σ) .

σ
n!

1 because the leading coeﬃcients of both

Dn−1(x, σ) = p(n−1)(1, σ) = Z (n−1)

n

(1, σ)

σ
n!

−

ω(n−1)(1, σ) > 0.

(9.3)

2) For Ωn−1(x, σ) we show below that

Ωn−1(x, σ)

≤

Ωn−1(1, σ) =

1
n!

ω(n−1)(1, σ) .

Thus, from (9.1)-(9.4), we obtain

mn−1(x, σ)

Z (n−1)
n

(1, σ)

≤ |

σ
n!

−

ω(n−1)(1, σ)
|

+

σ
n!

|

ω(n−1)(1, σ)
|

= Z (n−1)
n

(1, σ) ,

and theorem is proved.

Lemma 9.2 We have

Ωn−1(x, σ)

≤

Ωn−1(1, σ) =

1
n!

ω(n−1)(1, σ) .

(9.4)

(cid:3)

(9.5)

20

(9.1)

const)

≡

(9.2)

Proof. For Ωn−1(x, σ) we have the convex majorant

Ωn−1(x, σ)

≤

Ω∗

n−1(x, σ) =

1
n

n−1

i=0
X

x

|

τi(σ)
|

,

−

so that

We note that

Ωn−1(x, σ)

max

{

≤

Ω∗

n−1(0, σ), Ω∗

n−1(1, σ)
}

Ω∗

n−1(1, σ) = 1

1
n

−

τi(σ) =

1
n! |

ω(n−1)(1, σ)
|

= Ωn−1(1, σ) ,

so we need to prove that

X

c1(σ) :=

1
n

n

|

i=1
X

τi(σ)

| ≤

1
n

1

−

n

i=1
X

τi(σ) =: c2(σ) .

For large n, this inequality is self-evident because the alternation points τi(σ) are spread suﬃciently
uniform in the interval [

1. But we need it for all n

2.

1, 1], therefore c1(σ) < 1 while c2 →

−

We will use the monotonicity property of τi(σ) as functions of σ. We have

≥

Here, τi(σ0) are zeros of (x2

−

1)T ′

n−1(x) and τi(σn) are zeros of (x

1)T ′

n(x), therefore

−

τi(σ0)

τi(σ)

≤

≤

τi(σn) .

(9.6)

cos

It follows that

π((n
n

i)
−
1 ≤

−

τi(σ)

c2(σ) = 1

On the other hand, with m =

⌊

≤

1
n

n

−
n
,
2 ⌋

cos

π(n
−
n

i)

,

i = 1, . . . , n

1,

−

τn(σ) = 1.

τi(σ)

1

−

≥

1
n

τi(σn) = 1

1
n

.

−

X

X

τi(σ)

| ≤

|

X

m

i=1
X

τi(σ0)
|

|

+

i=m+1
X

τi(σn)
|

|

=

cos

m−1

i=0
X

πi

−

n

+

1

m−1

i=0
X

cos

πi
n ≤

1 +

1
sin π
2n

,

where we used the inequality

m−1

cos ix =

i=0
X
a) For n

1
2

+

1
2

+

m−1

i=1
X

cos ix

!

=

1
2

+

sin(m

1
2 )x
−
2 sin 1
2 x ≤

1
2

+

1
2 sin π
2n

,

x

∈ {

π
n

,

n

π

−

.

1 }

6 we have

≥

c1(σ)

1
n

+

1
n sin π

2n ≤

1
6

+

1
6 sin π
12

≤

= 0.81 <

5
6

< 1

1
n ≤

−

c2(σ) .

b) For n = 5,

c1(σ)

1
5

≤

1 + cos

(cid:18)

π
4

+ 1 + cos

π
5

+ cos

2π
5

(cid:19)

= 0.76 <

4
5

= Ωn−1(1, σ) .

c) For n = 3 and n = 4, we cannot obtain the inequality c1(σ)

(9.6). In these cases we split the interval [σ0, σn] into two parts:

≤

c2(σ) through the estimates

1)

τi(σ0)

τi(σ)

≤

≤

τi(

σn) ,

σ

∈

[σ0,

σn];

2) σ

[

σn, σn] ,

∈

b

b

b

21

 
where the second interval conatins σ such that Zn(
·
from the interval [

n , 1] to a slightly larger interval [

cos π

−

, σ) are the Chebyshev polynomials stretched

cos φ, 1] up to [

−

1, 1], i.e.

−
= cos2 π
2n

.

1 + cos π
n
2

Zn(x, σ) = Tn(1 + s(x

1)) ,

−

[sn, 1],

s

∈

sn :=

The alternation points of such Zn are given by

τi(σ) = (1 + t) cos

i)π

(n

−
n

t,

−

[0, tn],

t

∈

tn = tan2 π
2n

.

c1) Consider ﬁrst the case σ
For n = 2,

∈

[0,

σn].

For n = 3, we have

τ1(σ) =
b

1,

−

τ2(σ) = 1 .

τ1(σ) =

1,

−

τ2(σ)

0

≤

≤

1
3

,

τ3(σ) = 1,

so that

For n = 4,

c1(σ) =

1
3

3

|

i=1
X

τi(σ)

| ≤

7
9

,

c2(σ)

1

−

≥

1
3

τi(

σn) =

8
9

.

X

b

τ1(σ) =

1,

−

1
2 ≤

−

τ2(σ)

(3

−

≤ −

2√2),

1
2 ≤

τ3(σ)

4√2

5,

−

≤

τ4(σ) = 1,

so that

c1(σ)

1
4

≤

c2) In the case σ

[

∈

4

> 0.78,

Ωn−1(1, σ)

τi(σ)
|

|

i=1
X
σn, σ], we have

1

−

≥

1
4

τi(

σn) = 0.87 .

X

b

b
τi(

σ) = (1 + t) cos

i)π

(n

−
n

t,

−

[0, tan2 π
2n

],

t

∈

and, for n = 2,

c1(σ) =

b

4

i=1
X

1
2

τi(σ)
|

|

=

1 + t
2

,

c2(σ) = 1

1
2

−

τi(σ) =

1 + t
2

,

X

while for n = 3,

c1(σ) =

1
3

3

i=1
X

whereas for n = 4,

τi(σ)
|

|

=

2 + t
3

,

c2(σ) = 1

1
3

−

τi(σ) =

2 + 2t
3

,

X

1
4

−

τi(σ) =

3 + 3t
4

.

X

c1(σ) =

τi(σ)
|

|

=

√2 + 1
4

1
4

4

i=1
X

(1 + t),

c2(σ) = 1

22

10 Lower bounds for Bn,k

In Lemma 2.11, we proved that

mk(1, Is)

Bn,k ,

≥

where Bn,k is the best constant in the Landau-Kolmogorov inequality on the half-line subject to
normalization as given below:

Bn,k = sup

{|

f (k)(1)
|

:

f

k[−∞,1] =

,

Tnk

k

k

k

f (n)

k[−∞,1] =

T (n)
n k}

k

.

So, any lower bound for Bn,k serves as a lower bound for mk(1, Is).

If g is an arbitrary function from W n
∞[

, 1], then its linear transfromation

−∞

Tnk
f (x) := k
g
k
k
is a properly normalized function, and

g

x

·

g
k
k
Tnk
k

(cid:16)

1/n

T (n)
n
g(n)

k
k

k
k (cid:17)

!

Bn,k ≥

sup
f |

f (k)(1)
|

= sup

g

g

k

k

where

g(k)(1)
|
g(n)

|
1−k/n

k

k/n k

Tnk

1−k/n

T (n)
n k

k

k/n =: γn,kT (k)

n (1) ,

k

γn,k = Cn,k/Tn,k,

Cn,k := sup

g(k)(1)
|
g(n)

|
1−k/n

g

k/n ,

Tn,k :=

T (k)
n (1)
|
|
T (n)
1−k/n
n

.

k/n

Tnk

k
The constant Cn,k is the best constant in the LK-inequality on the half-line in the homogeneous
form

k

k

k

k

k

k

Stechkin proved that

g(k)(1)

| ≤

|

Cn,kk

g

k

1−k/n

g(n)

k

k

k/n .

Cn,k ≥

k!
(2k)!

(2n)!
n!

(cid:16)

(cid:17)

k/n

and Cn,k ≥

(2n!)1−k/n
k)!

(n

−

,

whichever is preferrable. He also showed that

n
p

a

(cid:16)

Lemma 10.1 We have

where

Proof. We have

p

(cid:17)

Cn,k ≤

Tn,k ≤

≤

p

,

2n
p

A

(cid:16)

(cid:17)

p = min(k, n

k) .

−

Bn,k ≥

γn,kT (k)

n (1),

γn,k ≥

(2/e)2k

Cn,k =

k!
(2k)!

(cid:16)

(2n)!
n!

(cid:17)

k/n

,

Tn,k =

2kk!
(2k)!

n2(n2

−

so that

(n2

12)
−
(2n−1n!)k/n

· · ·

1)2)

(k

−

,

γn,k ≥

Cn,k/Tn,k =

n2(n2

>

n2(n2

−

−

12)

2−k/n
(n2

· · ·

n2k

12)

· · ·

(n2

(2n)!k/n

(10.1)

(2/e)2k > (2/e)2k ,

(10.2)

(k

(k

−

−

−

−

1)2)

1)2)

where we used

(2n)!k/n >

√4πn(2n/e)2n

k/n

> 2k/nn2k(2/e)2k .

(cid:16)

(cid:17)

23

 
Lemma 10.2 For n

15, and 1

k

n

−

≤

≤

≤

1, we have

Cn,k >

T (k)
n+m(1)
T (n)
n+m(1)k/n

,

where

m = 1,

3

6,

n

≤

≤

m = 2,

7

n

≤

≤

10,

m = 3,

11

n

≤

≤

14 .

Proof. For x

[

−

∈

1, 1], consider the function

g(x) := gn,m(x) := φ(x)Tn+m(x),

φ(x) = cn

x

−1

Z

(1

−

t2)n dt, φ(1) = 1 ,

where the last equality deﬁnes the constant cn. We extend it to the half-line [
gn,m(x) = 0 for x <

1. Then

−

, 1] by setting

−∞

W n
∞[

g

∈

, 1],

−∞

g(k)(1) = T (k)

n+m(1),

k = 1, . . . , n ,

and

Cn,k ≥

g

k

g(k)(1)
|
g(n)

|
1−k/n

k

k/n = |
k

k

g(k)(1)
|
k/n
g(n)
[−1,1]

k

.

k
g(n)

So, we are done once we prove that
graph of the function g(n) = g(n)
and m given above, it attains its maximum at x = 1.

k[−1,1] = g(n)(1). The latter is proved numerically: the
1, 1], for the values n

n,m (provided by MAPLE) shows that, on [

−

k

Corollary 10.3 We have

where

mk(1, Is) > γn,kT (k)

n (1)

γn,k =

T (k)
n+m(1)
T (k)
n (1)  

k/n

T (n)
n (1)
T (n)
n+m(1) !

.

11 Proof of Theorem 1.4

1) For k = 1, we have the inequality

where, by (10.1)-(10.2),

m1(1, Is)

≥

Bn,1 = γn,1T ′

n(1),

γn,1 =

2−1/n
n2

(2n)!1/n > (2/e)2 > 0.541,

γ3,1 > 0.79.

(10.3)

We proved in (7.1) that

and we also have

where

αn,1 =

1
3

(cid:18)

2) For k = 2, we have

2(2n
n

−
2

−

m1(x, σn)

1
2

≤

T ′
n(1) ,

[0, ω1] ,

x

∈

m∗

1(x, σn)

≤

αn,1T ′

n(1),

[ω1, 1] ,

x

∈

1/n

2)

(cid:19)

α4,1 =

≤

1
3

61/4 < 0.522, n

4,

≥

α3,1 = 2/3 .

m2(1, Is)

Bn,2 ≥

≥

γn,2T ′′

n (1),

24

where

γn,2 =

For the upper bounds, we have

2−2/n

n2(n2

1)

−

(2n)!2/n > (2/e)4 > 0.293 .

and

where

m∗

2(x, σn)

≤

αn,2T ′′

n (1),

αn,2 = 0.23

(cid:18)

m2(x, σn)

≤

βn,2 T ′′

n (1) ,

2(2n
(n

3)

−
3)

−

2/n

(cid:19)

βn,2 =

1
5

8
11

1
sin 3π

2n )2

(1

−

< 0.28, n

16,

≥

βn,2 =

3
5

, n < 16 .

We put all the values in the table.

n = 4

5

αn,2

βn,2

γn,2

0.72

−
0.79

≤

≤

≤

≥

15

n

≤
0.50

0.60

0.63

16

≥
0.277

0.288

0.293

n

≤

≤

≥

25

12 Proof of Theorem 1.5

The values of γn,k in (10.3):

k/n

4

5

6

7

8

9

10

11

12

13

14

15

1

2

3

4

5

6

7

8

9

10

11

12

13

0.87

0.87

0.87

0.82

0.82

0.82

0.82

0.79

0.79

0.79

0.80

0.80

0.79

0.77

0.77

0.67

0.67

0.68

0.68

0.63

0.63

0.64

0.64

0.65

0.72

0.70

0.57

0.57

0.57

0.57

0.50

0.51

0.51

0.52

0.52

0.66

0.51

0.49

0.49

0.49

0.41

0.41

0.42

0.42

0.43

0.50

0.45

0.43

0.43

0.34

0.34

0.34

0.35

0.35

0.46

0.41

0.39

0.30

0.29

0.29

0.29

0.29

0.43

0.38

0.27

0.26

0.25

0.25

0.25

0.41

0.27

0.25

0.23

0.22

0.22

0.31

0.25

0.22

0.21

0.20

0.29

0.23

0.20

0.19

0.28

0.22

0.19

0.27

0.20

0.26

The values of

αn,k =

1
k + 1

n

k/n

4

5

6

7

n

−
8

1
−
1 + k

(cid:18)

9

2(2n
n

−
−
10

(k + 1))
(k + 1)

11

k/n

(cid:19)
12

13

14

15

1

2

3

4

5

6

7

8

9

10

11

12

13

0.58

0.55

0.54

0.53

0.53

0.52

0.52

0.52

0.51

0.51

0.51

0.51

0.63

0.48

0.43

0.40

0.39

0.38

0.37

0.36

0.36

0.36

0.35

0.35

0.63

0.44

0.37

0.34

0.32

0.30

0.30

0.29

0.28

0.28

0.28

0.64

0.42

0.34

0.30

0.28

0.26

0.25

0.24

0.24

0.23

0.65

0.40

0.32

0.28

0.25

0.24

0.22

0.22

0.21

0.67

0.40

0.31

0.26

0.24

0.22

0.21

0.20

0.68

0.40

0.30

0.25

0.22

0.20

0.19

0.69

0.39

0.29

0.24

0.21

0.19

0.70

0.39

0.29

0.24

0.21

0.71

0.39

0.29

0.23

0.72

0.39

0.28

0.73

0.39

0.74

It is readily seen that, for the values of k

n above and on the shadowed cells, we have

\
αn,k ≤

γn,k .

26

References

[1] C. K. Chui, P. W. Smith, A note on Landau’s problem for bounded intervals, Amer. Math.

Monthly 82 (1975), no. 9, 927–929.

[2] P. Erd¨os, G. Szeg¨o, On a problem of I. Schur, Ann. of Math. (2) 43, (1942). 451–470.

[3] B.-O. Eriksson, Some best constants in the Landau inequality on a ﬁnite interval, J. Approx.

Theory 94 (1998), no. 3, 420–454.

[4] S. Karlin, Oscillatory perfect splines and related extremal problems, in: Studies in spline

functions and approximation theory, pp. 371–460. Academic Press, New York, 1976.

[5] E. Landau, Einige Ungleichungen f¨ur zweimal diﬀerenzierbare Funktionen, Proc. London

Math. Soc. 13 (1913), 43-39.

[6] A. P. Matorin, On inequalities between the maxima of the absolute values of a function and
its derivatives on a half-line, Ukrain. Mat. Zh. 7 (1955), 262–266 = Amer. Math. Soc. Transl.
(2) 8 (1958), 13–17.

[7] N. Naidenov, On an extremal problem of Kolmogorov type for functions from W 4

∞([a, b]), East

J. Approx. 9 (2003), no. 1, 117–135.

[8] M. Sato, The Landau inequality for bounded intervals with f (3) ﬁnite, J. Approx. Theory 34

(1982), no. 2, 159–166.

[9] I. Schur, ¨Uber das Maximum des absoluten Betrages eines Polynoms in einem gegebenen

Intervall, Math. Z. 4 (1919), no. 3-4, 271–287.

[10] A. Shadrin, Twelve proofs of the Markov inequality, in: Approximation theory: a volume
dedicated to Borislav Bojanov, 233–298, Prof. M. Drinov Acad. Publ. House, Soﬁa, 2004.

[11] A. I. Zvyagintsev, Kolmogorov’s inequalities for n = 4, Latv. Mat. Ezhegodnik 26 (1982),

165–175, 282 (in Russian).

[12] A. I. Zvyagintsev, A. Ya. Lepin, Kolmogorov’s inequalities between the upper bounds of

derivatives of functions for n = 3, Latv. Mat. Ezhegodnik 26 (1982), 176–181 (in Russian).

27

"
"All-in-all-out magnetic domain wall conduction in pyrochlore iridate
  heterointerface","  Pyrochlore oxides possessing ""all-in-all-out"" spin ordering have attracted
burgeoning interest as a rich ground of emergent states. This ordering has two
distinct types of magnetic domains (all-in-all-out or all-out-all-in) with
broken time-reversal symmetry, and a non-trivial metallic surface state has
been theoretically demonstrated to appear at their domain wall. Here, we report
on observation of this metallic conduction at the single
all-in-all-out/all-out-all-in magnetic domain wall formed at the
heterointerface of two pyrochlore iridates. By utilizing different
magnetoresponses of them with different lanthanide ions, the domain wall is
controllably inserted at the heterointerface, the surface state being detected
as anomalous conduction enhancement with a ferroic hysteresis. Our
establishment paves the way for further investigation and manipulation of this
new type of surface transport.
","All-in-all-out magnetic domain wall conduction in 

pyrochlore iridate heterointerface 

T. C. Fujita1, M. Uchida1,*, Y. Kozuka1, W. Sano1, A. Tsukazaki1, 2, 3, T. Arima4, 5, M. 

Kawasaki1, 5  

Affiliations  

1Department of Applied Physics and Quantum-Phase Electronics Center (QPEC), University 

of Tokyo, Tokyo 113-8656, Japan 

2Institute for Materials Research, Tohoku University, Sendai 980-8577, Japan 

3PRESTO, Japan Science and Technology Agency (JST), Tokyo 102-0075, Japan 

4Department of Advanced Materials Science, University of Tokyo, Kashiwa 277-8561, Japan 

5RIKEN Center for Emergent Matter Science (CEMS), Wako 351-0198, Japan 

1 

 
 
 
 
 
ABSTRACT 

Pyrochlore oxides possessing “all-in-all-out” spin ordering have attracted burgeoning 

interest as a rich ground of emergent states. This ordering has two distinct types of magnetic 

domains (all-in-all-out or all-out-all-in) with broken time-reversal symmetry, and a non-trivial 

metallic surface state has been theoretically demonstrated to appear at their domain wall. Here, 

we report on observation of this metallic conduction at the single all-in-all-out/all-out-all-in 

magnetic domain wall formed at the heterointerface of two pyrochlore iridates. By utilizing 

different magnetoresponses of them with different lanthanide ions, the domain wall is 

controllably inserted at the heterointerface, the surface state being detected as anomalous 

conduction enhancement with a ferroic hysteresis. Our establishment paves the way for 

further investigation and manipulation of this new type of surface transport. 

2 

 
Topological materials, involving topologically nontrivial band structure due to strong 

spin-orbit coupling (SOC), have been lately one of the central topics in the field of condensed 

matter physics. These materials are characterized by the edge state, which is uniquely 

determined by a type of symmetries inherent in the bulk state [1–10]. Recent theoretical 

studies have proposed that transition metal oxides such as iridates with heavy 5d electrons 

exhibit novel topological phases originating from an interplay of large SOC and electron 

correlation [11–14]. Engineering their band structure has been also suggested in the form of 

thin film or superlattice for realizing further emergent phases [15–22]. 

The pyrochlore oxide is well known as a fertile ground for various magnetic properties 

[23] such as spin ice in titanates [24,25] and large anomalous Hall effect induced by Berry 

phase in molybdates [26]. In the case of pyrochlore iridates (Ln2Ir2O7; Ln: lanthanides), the 

system exhibits a metal-insulator transition accompanied with “all-in-all-out” spin ordering 

[13], where all four spins at the vertices in the tetrahedral cation site pointing inward or 

outward are alternatingly stacked along <111> direction [27,28]. In this antiferromagnetic 

ordering, there exist two distinct spin arrangements [all-in-all-out or all-out-all-in; Fig. 1(a)], 

which are interexchangeable with each other by the time-reversal operation. Hereafter we 

refer these two spin arrangements as “A domain” and “B domain” for simplicity. This 

antiferromagnetic ordering with broken time-reversal symmetry is one of the prerequisites for 

the emergence of the Weyl semimetal (WSM) phase in pyrochlore iridates [13].  

In connection with the WSM phase, the metallic surface state has been theoretically 

demonstrated to appear at the domain wall between the A and B domains, even if the 

respective domains are not in the WSM phase [29–32]. This originates from the continuity of 

the low-energy bands which are classified by a symmetry of the wave functions near the 

Fermi level [Figs. 1(b) and 1(c)]. Actually, huge negative magnetoresistance ascribed to the 

magnetic domain wall conduction has been partly observed in Nd2Ir2O7 (NIO) bulk crystals 

3 

 
[33–35]. However, for bulk crystals containing randomly distributed magnetic domain walls 

in high density, it is highly difficult to investigate and control the domain wall conduction. 

Realizing the single magnetic domain wall at a well-defined surface or interface, as in the 

case of other topological materials, is inevitable for fostering the study of this new type of 

surface transport. 

In this Rapid Communication, we study the metallic conduction emerging at a single 

all-in-all-out/all-out-all-in magnetic domain wall in the pyrochlore iridates. In order to realize 

this, we focus on pyrochlore iridate heterointerface composed of Eu2Ir2O7 (EIO) and Tb2Ir2O7 

(TIO), where A or B domains can be independently controlled as “pinned layer” and “free 

layer”, respectively [Fig. 1(d)]. When Ln3+ has no magnetic moments such as Eu3+ (J = 0), the 

magnetic domain structure of Ir4+ is determined only by cooling magnetic field Bcool and 

highly robust against sweeping magnetic field Bsweep [36]. When Ln3+ has magnetic moments 

such as Tb3+ (J = 6), A or B domain can be switched each other by Bsweep at some coercive 

field Bc [27,34,35]. In this heterointerface, therefore, the magnetic domain wall is controllably 

inserted by the field control, B-EIO/A-TIO for Bsweep > Bc after Bcool < 0 or A-EIO/B-TIO for 

Bsweep < −Bc after Bcool > 0 [Fig. 1(d)]. 

The (111)-oriented pyrochlore iridate thin films and heterostructure were prepared on 

commercial YSZ (111) single crystal substrates by pulsed laser deposition [36]. We used a 

phase-mixed ceramics target with a prescribed ratio of Eu (Tb)/Ir = 1/3 fabricated by a hot-

press method at 950 °C under 25 MPa pressure. The films were deposited at a substrate 

temperature of 500 °C under an atmosphere of 100 mTorr Ar gas containing 1% O2. The KrF 

eximer laser (λ =248 nm) was used for ablating the target, where the fluence and the 

frequency were 6 J/cm2 and 10 Hz, respectively. The films were in an amorphous phase after 

the deposition, and pure pyrochlore phases appeared by annealing in an electrical muffle 

furnace in air at 1000 °C for 1.5 hours. 

4 

 
Magnetotransport measurements were carried out with conventional four-terminal 

method by using a liquid He cryostat equipped with a superconducting magnet (PPMS, 

Quantum Design Co.). Typical channel size was 500  500 m2, and current (I) and magnetic 

field (B) were applied parallel and perpendicular to the film surface, respectively. Here 

longitudinal conductance (Gxx) is obtained as inverse of the sheet resistance (Rxx); Gxx =1 / Rxx 

because contribution from the Hall resistance (Rxy) is negligibly small. For the field cooling 

measurement, cooling magnetic field (Bcool) was applied at 200 K perpendicular to the film 

surface and the sample was cooled to 10 K. Such measurement temperature below 20 K is 

important for switching the magnetic domain structure in TIO since the switching of Ir4+ 

ordering is triggered by that of Tb3+ whose ordering temperature is about 20 K [27,34,35]. 

The magnetotransport was measured as follows: the magnetic field was first set to Bcool, then 

was swept to −Bcool, and finally went back to the initial Bcool. Bcool was ±9 T for EIO and 

heterostructure, and ±14 T for TIO, respectively. 

A EIO (15 nm) / TIO (60 nm) heterostructure was epitaxially grown on an (111)-

oriented Y-stabilized ZrO2 (YSZ) single crystal substrate by combining pulsed laser 

deposition and solid phase epitaxy [See [36] for further detail]. X-ray diffraction (XRD) scan 

along [111] direction for heterostructure in Figs. 2(a) and 2(b) clearly shows separated peaks 

of EIO and TIO, indicating that both of the pyrochlore iridate layers are epitaxially formed. 

While the bottom TIO lattice is relaxed from YSZ, that of top EIO layer is strained by the 

bottom TIO as shown in the reciprocal space mapping in Fig. 2(c). A phase contrast image of 

the transmission electron microscopy (TEM) in Fig. 2(d) clearly shows the formation of the 

designed epitaxial heterostructure. We also performed energy dispersive x-ray spectrometry 

(EDX) in order to exclude a possibility that Eu and Tb atoms are intermixed each other. In 

spite of the solid phase epitaxy technique, interdiffusion of these two elements is fairly 

suppressed as shown in Fig. 2(f). An integrated EDX intensity profile in Fig. 2(e) also 

5 

 
represents a very sharp interface within the resolution of measurement. All of these film 

characterizations ensure high quality of the heterostructure suitable for detecting the 

interfacial carrier transport. 

Let us start by discussing transport property of the single layer films. The respective 

layers exhibit metal-insulator transition accompanied with the all-in-all-out magnetic ordering 

at Néel temperature TN, as shown in Fig. 3(a). Magnetoresponse in the all-in-all-out spin 

ordering is generally described in the form of the third rank tensor [37]. Thus 

magnetoconductance (MC) includes the magnetic field (B)–linear term due to the canting of 

the Ir4+ magnetic moments in the all-in-all-out ordering, the sign of which is opposite 

depending on the domain structure (A or B) [36]. Another distinct point is that, as mentioned 

above, MC is enhanced when the magnetic domain walls are formed in the process of the 

domain switching [33–35]. This response is completely opposite to the conventional magnetic 

materials, where conductance is suppressed due to domain wall scattering when the magnetic 

domains are mixed. 

Bsweep dependences of MC in the EIO and TIO films for various Bcool are shown in 

Figs. 3(b) and 3(c), which are basically consistent with the previous reports [33-36]. In short, 

the domain of EIO is uniquely determined by Bcool, while that of TIO is switchable by Bsweep. 

For EIO [Fig. 3(b)], MC has finite B-linear component after field cooling (Bcool = +9 or −9 T, 

FC), reflecting that the magnetic domain structure is fixed to A or B single domain by Bcool. 

After zero-field cooling (Bcool = 0 T, ZFC), on the other hand, the B-linear component is 

cancelled out due to mixture of the domains. It is worth mentioning that MC does not show 

any hysteresis because the magnetic domain structure is quite robust against Bsweep. In the case 

of TIO [Fig. 3(c)], on the other hand, MC shows hysteresis originating from the domain 

switching at Bc ~ 8 T, triggered by the switching of all-in-all-out ordering in Tb3+ lattice 

formed below about 20 K [27,34,35]. Starting from Bsweep well above Bc, where the magnetic 

6 

 
domain is regulated as A domain (colored by red), Gxx reduces while Bsweep approaching 0 T. 

Then Bsweep being swept to negative, where the magnetic domain is gradually switched to B 

domain and the A and B domains are intermixed, MC gets enhanced compared with the 

reverse sweep. Finally MC reaches its top at −Bc and then suddenly drops to finish the entire 

switching to the B domain (colored by blue). The same process occurs when Bsweep increases 

again and the magnetic domain is switched back from B to A. 

We then move on to discuss magnetotransport of heterointerface between the two 

layers. We note again that the measured conductance is a summation of the contributions 

from EIO, TIO, and interface of them due to the measurement configuration of the 

heterostructure, as written as 

.                                                  (1) 

As shown in Fig. 4(b), for ZFC, symmetric MC is observed in the EIO/TIO heterostructure. A 

similar dip-like structure appears around Bsweep = 6 T, with a hysteresis in the same direction 

as in TIO single layer film [Fig. 3(c)]. This is a clear evidence that the domain switching in 

the TIO layer occurs as in the case of the TIO single layer film, which is also verified by the 

minor-loop magnetotransport measurement (See Supplemental Material [38] ). In the case of 

FC, Gxx exhibits overall gradients with opposite sign for Bcool = +9 or −9 T [Figs. 4(a) and 

4(c)]. The gradient is attributed to the B-linear MC in the EIO layer, whose magnetic domain 

is aligned to the single A (or B) domain depending on positive (or negative) Bcool as in the 

case of the EIO single layer film [Fig. 3(b)]. 

Additional conductance (Gint), indicated by orange bars in Figs. 4(a) and 4(c), appears 

as a ferroic loop between the sweeps upward and downward for −Bc < Bsweep < Bc. This 

additional conductance emerges only when the domain structures are opposite between the 

TIO and EIO layers, suggesting that the theoretically predicted metallic surface state is 

materialized at the single magnetic domain wall induced at the heterointerface. The 

7 

intTIOxxEIOxxxxGGGG 
contribution, the sum of B-linear component in the EIO layer and the additional ferroic 

hysteresis at the heterointerface, can be extracted by subtracting Gxx after ZFC [Fig. 4(b)] 

from those after FCs [Figs. 4(a) and 4(c)] as shown in Figs. 4(d) and 4(e), respectively, 

because any other contributions are commonly contained in ZFC. They can be further divided 

into the B-linear and ferroic terms, as shown in Fig. 4(f) (See Supplemental Material [38] for 

further information about deducing process). The ferroic hysteresis, which has opposite loop 

direction for the opposite cooling field, appears reflecting creation and annihilation of the 

single conduction path at the A/B magnetic domain wall. Here, we have to emphasize again 

that this hysteresis is purely due to the effect of heterointerface, because such additional 

conduction is not observed for single layers of EIO or TIO. The hysteresis height is almost 

independent of the magnetic field, which evidences that the hysteresis does not originate from 

the spin canting in disordered spin structure at the heterointerface. The height of the hysteresis, 

corresponding to the conductance at the interface (Gint), is about 0.4 S., Gint accounts for 

0.2% of the total conductance, this ratio is about 20% for the previously reported bulk NIO. 

This is quite reasonable assuming that polycrystalline NIO contains multiple domain walls 

with a domain size of 50-100 m. 

For further investigation of the interfacial conductance, temperature dependence of 

Gint [Fig. 5(a)] was taken with the following process. First, the sample was cooled down to 10 

K with field cooling (Bcool = +9 T), and at 10 K, the field was swept to 0 T. At this point, both 

the EIO and TIO layers forms the A domain. Then the Gxx was measured from 2 K to 200 K 

under zero field (i). Second, the sample was also cooled down to 10 K with field cooling 

(Bcool = +9 T), and at 10 K, the field was swept to −9 T and then returned to 0 T. At this point 

TIO is switched to the B domain, while EIO remains the A domain. Then the Gxx was 

measured from 2 K to 200 K under zero field (ii). Comparing the case (i) with (ii), the 

8 

 
magnetic domain wall is introduced only in the case (ii), as illustrated in Fig. 4(e), and thus 

the temperature dependence of Gint is derived by subtracting (i) Gxx from (ii) Gxx. 

The obtained Gint emerges below about 110 K, which is in good agreement with the 

all-in-all-out ordering temperature TN of the heterostructure [Fig. 5(b)]. This finding also 

confirms that Gint originates from the surface state between the A and B domains. Decrease in 

Gint below 30 K may be attributed to the electron correlation effect of the 5d electron bands 

[39], or the weak localization as generally expected in the two dimensional case. While the 

bulk conduction accounting for most of Gxx is highly suppressed with decreasing temperature 

below TN ~ 105 K, the interfacial conduction Gint keeps increasing down to 30 K. This 

temperature dependence conclusively demonstrates that the interface conduction at the all-in-

all-out magnetic domain wall is indeed metallic. 

To summarize, we have fabricated pyrochlore iridate heterostructure in order to detect 

metallic conduction expected at the single all-in-all-out/all-out-all-in magnetic domain wall. 

We have demonstrated that the additional metallic conductance emerges only when the 

domain wall is inserted at the heterointerface by the field control. The single magnetic domain 

wall at the heterointerface is controllably induced, and it remains within a wide range of 

sweep magnetic field, different from ones in bulk crystals. Further investigation would verify 

topological nature of the magnetic domain wall state by measuring such as anomalous Hall 

effect or non-local transport properties on this single domain wall. Our establishment will 

promote future exploration of surface transport in the new type of topological phases in 

oxides. 

9 

 
ACKNOWLEDGMENTS 

We thank J. Fujioka, K. Ueda, Y. Tokura, N. Nagaosa, Y. Yamaji, M. Imada, M. 

Udagawa, and Y. Motome for helpful discussions. This work was partly supported by Grant-

in-Aids for Scientific Research (S) No. 24226002 and No. 24224010, by JSPS Fellowship No. 

26·10112 (TCF), and by Challenging Exploratory Research No. 26610098 (MU) from MEXT, 

Japan as well as by Asahi Glass Foundation (YK). 

10 

 
REFERENCES 

[1] 

 M. Z. Hasan and C. L. Kane, Rev. Mod. Phys. 82, 3045–3067 (2010). 

[2] 

 X.-L. Qi and S.-C. Zhang, Rev. Mod. Phys. 83, 1057 (2011) 

[3] 

 M. König, S. Wiedmann, C. Brüne, A. Roth, H. Buhmann, L. W. Molenkamp, X.-L. 
Qi, and S.-C. Zhang, Science 318, 766 (2007). 

[4] 

 D. Hsieh, D. Qian, L. Wray, Y. Xia, Y. S. Hor, R. J. Cava, and M. Z. Hasan, Nature 
452, 970 (2008). 

[5] 

 S. M. Young, S. Zaheer, J. C. Y. Teo, C. L. Kane, E. J. Mele, and A. M. Rappe, Phys. 
Rev. Lett. 108, 140405 (2012). 

[6] 

 Z. Wang, Y. Sun, X.-Q. Chen, C. Franchini, G. Xu, H. Weng, X. Dai, and Z. Fang, 
Phys. Rev. B 85, 195320 (2012). 

[7] 

 S. Murakami, New J. Phys. 9, 356 (2007). 

[8] 

 S. Murakami and S. I. Kuga, Phys. Rev. B 78, 165313 (2008). 

[9] 

 A. A. Burkov and L. Balents, Phys. Rev. Lett. 107, 127205 (2011). 

[10] 

 G. B. Halász and L. Balents, Phys. Rev. B 85, 035103 (2012). 

[11] 

 D. Pesin and L. Balents, Nat. Phys. 6, 376–381 (2010). 

[12] 

 B. J. Yang and Y. B. Kim, Phys. Rev. B 82, 085111  (2010). 

[13] 

 X. Wan, A. M. Turner, A. Vishwanath, and S. Y. Savrasov, Phys. Rev. B 83, 205101 
(2011). 

[14] 

 E.-G. Moon, C. Xu, Y. B. Kim, and L. Balents, Phys. Rev. Lett. 111, 206401 (2013). 

[15] 

 J. M. Carter, V. V Shankar, M. A. Zeb, and H. Y. Kee, Phys. Rev. B 85, 115105 
(2012). 

11 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[16] 

 Y. Chen and H.-Y. Kee, Phys. Rev. B 90, 195145 (2014). 

[17] 

 Y. Chen, Y.-M. Lu, and H.-Y. Kee, Nat. Commun. 6, 6593 (2015). 

[18] 

 J. Matsuno, K. Ihara, S. Yamamura, H. Wadati, K. Ishii, V. V. Shankar, H.-Y. Kee, 
and H. Takagi, Phys. Rev. Lett. 114, 247209 (2015). 

[19] 

 Y. F. Nie, P. D. C. King, C. H. Kim, M. Uchida, H. I. Wei, B. D. Faeth, J. P. Ruf, J. P. 
C. Ruff, L. Xie, X. Pan, C. J. Fennie, D. G. Schlom, and K. M. Shen, Phys. Rev. Lett. 
114, 016401 (2015). 

[20] 

 D. Xiao, W. Zhu, Y. Ran, N. Nagaosa, and S. Okamoto, Nat. Commun. 2, 596 (2011). 

[21] 

 B.-J. Yang and N. Nagaosa, Phys. Rev. Lett. 112, 246402 (2014). 

[22] 

 X. Hu, Z. Zhong, and G. A. Fiete, Sci. Rep. 5, 11072 (2015). 

[23] 

 J. S. Gardner, M. J. P. Gingras, and J. E. Greedan, Rev. Mod. Phys. 82, 53 (2010). 

[24] 

 S. T. Bramwell and M. J. Gingras, Science 294, 1495 (2001). 

[25] 

 L. Bovo, X. Moya, D. Prabhakaran, Y.-A. Soh, A. T. Boothroyd, N. D. Mathur, G. 
Aeppli, and S. T. Bramwell, Nat. Commun. 5, 3439 (2014). 

[26] 

 Y. Taguchi, Y. Oohara, H. Yoshizawa, N. Nagaosa, and Y. Tokura, Science 291, 2573 
(2001). 

[27] 

 K. Tomiyasu, K. Matsuhira, K. Iwasa, M. Watahiki, S. Takagi, M. Wakeshima, Y. 
Hinatsu, M. Yokoyama, K. Ohoyama, and K. Yamada, J. Phys. Soc. Jpn 81, 034709 
(2012). 

[28] 

 H. Sagayama, D. Uematsu, T. Arima, K. Sugimoto, J. J. Ishikawa, E. O’Farrell, and S. 
Nakatsuji, Phys. Rev. B 87, 100403 (2013). 

[29] 

 Y. Yamaji and M. Imada, Phys. Rev. X 4, 021035 (2014). 

[30] 

 K. Ueda, J. Fujioka, B.-J. Yang, J. Shiogai, A. Tsukazaki, S. Nakamura, S. Awaji, N. 
Nagaosa, and Y. Tokura, Phys. Rev. Lett. 115, 056402 (2015). 

12 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[31] 

 Y. Yamaji and M. Imada, arXiv:1507.04153. 

[32] 

 K. Ueda, J. Fujioka, C. Terakura, and Y. Tokura, Phys. Rev. B 92, 121110(R) (2015). 

[33] 

 K. Matsuhira, M. Tokunaga, M. Wakeshima, Y. Hinatsu, and S. Takagi, J. Phys. Soc. 
Jpn 82, 023706 (2013). 

[34] 

 K. Ueda, J. Fujioka, Y. Takahashi, T. Suzuki, S. Ishiwata, Y. Taguchi, M. Kawasaki, 
and Y. Tokura, Phys. Rev. B 89, 075127 (2014). 

[35] 

 E. Y. Ma, Y.-T. Cui, K. Ueda, S. Tang, K. Chen, N. Tamura, P. M. Wu, J. Fujioka, Y. 
Tokura, and Z.-X. Shen, Science 350, 538 (2015). 

[36] 

 T. C. Fujita, Y. Kozuka, M. Uchida, A. Tsukazaki, T. Arima, and M. Kawasaki, Sci. 
Rep. 5, 9711 (2015). 

[37] 

 T. Arima, J. Phys. Soc. Jpn 82, 013705 (2013). 

[38] 

 See Supplemental Material at [URL will be inserted by publisher] for a minor-loop 
magnetotransport measurement and a detailed calculation process for deducing 
interfacial conductance. 

[39] 

 W. Witczak-Krempa, G. Chen, Y. B. Kim, and L. Balents, Annu. Rev. Condens. 
Matter Phys. 5, 57 (2014). 

13 

 
 
 
 
 
 
 
 
 
FIGURES 

FIG. 1 Fujita et al., 

FIG. 1. (Color online) (a) Two distinct all-in-all-out spin structures, named as A (all-in-all-

out) domain and B (all-out-all-in) domain, on pyrochlore lattice. (b), (c) Their eigenstates near 

the Fermi level (EF) have different phase factors (±) and they are switched by time-reversal 

operation, leading to the surface state at the domain wall accompanied with ferromagnetic 

moment indicated by open green arrows. (d) Cross sectional schematics of the heterostructure 

composed of Eu2Ir2O7 (EIO) with J = 0 nonmagnetic Eu3+ and Tb2Ir2O7 (TIO) with J = 6 

Ising-like Tb3+, which are used as “pinned layer” and “free layer” and controlled by Bcool and 

Bsweep, respectively. Their magnetic domain structures are changed depending on Bcool and 

Bsweep. Domain wall conduction path (denoted by yellow lines) emerges when the domain 

structure is opposite in EIO and TIO layers.  

14 

 
 
 
FIG. 2 Fujita et al., 

FIG. 2. (Color online) (a) -2 scan of x-ray diffraction. Peaks from the YSZ substrate are 

marked with asterisks. Magnified view around YSZ (222) is shown in (b). (c) Reciprocal 

space mapping around YSZ (331) peak. Ideal pyrochlore lattice with cubic symmetry follows 

the dashed line. (d) Phase contrast image of high-resolution TEM of the EIO / TIO 

heterostructure on YSZ (111) substrate. (e) Integrated intensity along [111]-direction of the 

energy dispersive x-ray spectrometry (EDX) for Eu and Tb. (f) Magnified HHADF-STEM 

image and cross sectional EDX mappings for Eu, Tb and Ir elements. 

15 

 
 
 
FIG. 3 Fujita et al., 

FIG. 3. (Color online) (a) Temperature dependence of the longitudinal resistivity (xx) for 

15nm Eu2Ir2O7 (EIO) and 60 nm Tb2Ir2O7 (TIO) thin films. Magnetic transition temperature 

TN is indicated by dashed line. (b), (c) Sweeping magnetic field (Bsweep) dependence of 

longitudinal conductance Gxx for EIO (b) and TIO (c) measured at 10 K. Magnetic domain 

structure of EIO is determined by cooling field (Bcool), whereas that of TIO can be switched 

by Bsweep. The direction of hysteresis originating from domain switching is shown by arrows, 

where open (filled) red (blue) one corresponds to the domain structure for A (B) domain. 

16 

 
 
FIG. 4 Fujita et al., 

FIG. 4. (Color online) (a)-(c) Sweeping magnetic field (Bsweep) dependence of longitudinal 

conductance Gxx for EIO / TIO heterostructure measured at 10 K after various cooling field 

(Bcool) conditions. The line colors indicate the magnetic domain structure in TIO layer (red 

(blue) for A (B) domain). The direction of hysteresis is shown by arrows, whose colors also 

indicate the magnetic domain structure in TIO layer. (d), (e) Bsweep dependence of the 

subtracted conductance defined by Gxx (±9 T FC) − Gxx (ZFC) for the heterostructure. These 

results correspond to the summation of linear magnetoconductance in EIO layer and 

additional conductance at the interface (Gint). (f) Bsweep dependence of the linear 

magnetoconductance (upper half) and Gint (lower half) resolved from (d) and (e).

17 

 
 
FIG. 5 Fujita et al., 

FIG. 5. (Color online) (a), (b) Temperature dependence of the interfacial conductance (Gint), 

compared with that of the total longitudinal conductance Gxx of EIO / TIO heterostructure. 

Magnetic transition temperature TN is estimated to be about 105 K from the peak in the 

temperature derivative. 

18 

 
 
Supplementary Material 

All-in-all-out magnetic domain wall conduction in 

pyrochlore iridate heterointerface 

T. C. Fujita1, M. Uchida1,*, Y. Kozuka1, W. Sano1, A. Tsukazaki1, 2, 3, T. Arima4, 5, M. 

Kawasaki1, 5  

Affiliations  

1Department of Applied Physics and Quantum-Phase Electronics Center (QPEC), University 

of Tokyo, Tokyo 113-8656, Japan 

2Institute for Materials Research, Tohoku University, Sendai 980-8577, Japan 

3PRESTO, Japan Science and Technology Agency (JST), Tokyo 102-0075, Japan 

4Department of Advanced Materials Science, University of Tokyo, Kashiwa 277-8561, Japan 

5RIKEN Center for Emergent Matter Science (CEMS), Wako 351-0198, Japan 

19 

 
 
 
 
Minor loop magnetotransport measurement 

Figure S1 shows longitudinal conductance (Gxx) for the Eu2Ir2O7 (EIO) / Tb2Ir2O7 

(TIO) heterostructure as a function of magnetic field (Bsweep) at 10 K after +9 T field cooling. 

For measuring the minor loops of TIO layer, magnetic field was swept as following sequence. 

First, the sample was cooled from 200 K under Bsweep = +9 T. Then, at 10 K magnetic field 

was swept from +9 T to a certain field (Br), which we chose  6 T [Fig. 5(a)],  6.5 T [Fig. 

5(b)],  7.2 T [Fig. 5(c)], and  9 T [Fig. 5(d)], and swept back to +9 T. After the sweep for 

each Br, the sample was heated up to 200 K again for the next measurement for different Br. 

When Br =  6 T, Gxx does not show any hysteresis, indicating there was negligible domain 

reversal. In case of Br =  6.5 T, it shows some finite but smaller hysteresis, indicating 

insufficient domain switching. On the other hand with Br =  7.2 T, hysteresis appears with 

almost the same order of magnitude as in the case of full-loop. It is worth mentioning, 

however, that even in this case of Br =  7.2 T, Gxx does not show the full hysteresis as in Br = 

9 T, which is distinguished by the cross of upward sweep and down ward sweeps at around 

Bsweep =  4 T in Fig S1 (d). This indicates that some part of the magnetic domain is not 

reversed in this Br =  7.2 T sequence. From these observations we conclude that the 

characteristic hysteresis shown in the Gxx originates from the magnetic domain switching in 

TIO layer, and its coercive field for complete switching is around 7.5 T. 

20 

 
FIG. S1. Minor loop measurements for the EIO / TIO heterostructure. Longitudinal 

conductance (Gxx) for the Eu2Ir2O7 (EIO) / Tb2Ir2O7 (TIO) heterostructure as a function of 

magnetic field (Bsweep) at 10 K after +9 T field cooling. The magnetic field is swept as +9 T 

→ Br → +9 T, where Br is the turning back point of the magnetic field. As for Br, we chose 

6 T (a),  6.5 T (b),  7.2 T (c), and  9 T (d). 

21 

 
 
Calculation process for deducing interfacial conductance 

Magnetoconductance in pyrochlore iridates with all-in-all-out magnetic ordering 

generally has linear-term [37], and it is described as 

 (n = 0, 1, 2, …).                                     (S1) 

Here, B is external magnetic field, GDW is a domain wall conductance in single layer film, and 

the coefficient  is negative (positive) for A (B) domain. 

At first, we start from the case without GDW in order to simplify the discussion. The 

magnetic domain in EIO is determined only by Bcool, and robust against Bsweep at low 

temperature once it is formed [36]. Therefore, its magnetoconductance shows gradient  

corresponding to the magnetic domain structure, namely Bcool. However, the domain in TIO is 

switched at certain magnetic field, where the sign of is also inverted, and thus its 

magnetoconductance is seemingly even. In other words, the coercive field of Ir4+ in EIO is 

much larger than that in TIO due to the absence of magnetic moment of Eu3+. Therefore, if we 

were able to apply magnetic field huge enough to switch the magnetic domain in EIO, we 

would observe even magneto conductance as in the case of TIO. 

Next, we consider the contribution from domain wall conductance in single layer film, 

namely GDW. In EIO, magnetic domain is aligned to A (B) single domain with positive 

(negative) Bcool, and thus GDW should disappear. On the other hand, the magnetic domain after 

ZFC is a mixture of A and B domains, and GDW could appear. In TIO, the magnetic domain 

can be switched by Bsweep, and thus GDW is independent of Bcool. 

Finally, we argue the conduction of heterointerface, Gint. It is supposed that Gint 

emerges only when magnetic domains in TIO and EIO layers are different with each other. In 

our present work, we can switch only magnetic domain in TIO, and thus time-reversal 

symmetry is broken, leading to odd (ferroic) field dependence of Gint [FIG. S2(a)]. If we 

22 

)(DW2xxGBbBGnnn 
applied sufficient magnetic field to invert magnetic domain in EIO, time-reversal symmetry 

would be conserved, and Gint would show even field dependence [FIG. S2(b)]. 

Taking into account all the discussions above, the total conductance of the 

heterostructure after ZFC and ±9 T FCs are written as followings: 

Consequently, Gxx shown in FIGs. 4(d) and 4(e) can be deduced as 

.            (S2) 

.   (S3) 

.                           (S4) 

Gxx can be further divided into the B-linear (

) and ferroic (Gint) terms, which are 

shown in upper and lower half of FIG. 4(f), respectively. 

FIG. S2 Schematics of sweep magnetic field (Bsweep) dependence of Gint within feasible (a) 

and unfeasible (b) ranges of magnetic field, respectively. Here, Bc(EIO) and Bc(TIO) denote 

coercive fields of EIO and TIO layers, respectively. 

23 

)()()ZFC(TIODW2EIODW2intTIOxxEIOxxxxGBbBGBbGGGGnnnnnnintTIODW22intTIOxxEIOxxxx)()()TFC 9(GGBbBBbBGGGGnnnnnnintEIODWxxxxxx)()ZFC()FC T 9()FC T 9(GGBGGGEIODWGB 
"
"An Improved One-to-All Broadcasting in Higher Dimensional
  Eisenstein-Jacobi Networks","  Recently, a higher dimensional Eisenstein-Jacobi networks, has been proposed
in [22], which is shown that they have better average distance with more number
of nodes than a single dimensional EJ networks. Some communication algorithms
such as one-to-all and all-to-all communications are well known and used in
interconnection networks. In one-to-all communication, a source node sends a
message to every other node in the network. Whereas, in all-to-all
communication, every node is considered as a source node and sends its message
to every other node in the network. In this paper, an improved one-to-all
communication algorithm in higher dimensional EJ networks is presented. The
paper shows that the proposed algorithm achieves a lower average number of
steps to receiving the broadcasted message. In addition, since the links are
assumed to be half-duplex, the all-to-all broadcasting algorithm is divided
into three phases. The simulation results are discussed and showed that the
improved one-to-all algorithm achieves better traffic performance than the
well-known one-to-all algorithm and has 2.7% less total number of senders
","6
1
0
2
c
e
D
7

]

C
D
.
s
c
[

2
v
2
4
8
1
0
.
2
1
6
1
:
v
i
X
r
a

An Improved One-to-All Broadcasting in Higher
Dimensional Eisenstein-Jacobi Networks

Zaid Hussain
zhussain@cs.ku.edu.kw

Computer Science Department
College of Computing Sciences and Engineering
Kuwait University

June 16, 2018

Abstract
Recently, a higher dimensional Eisenstein-Jacobi (EJ) networks, EJ (n)
α ,
has been proposed in [22], which is shown that they have better average
distance with more number of nodes than a single dimensional EJ net-
works. Some communication algorithms such as one-to-all and all-to-all
communications are well known and used in interconnection networks. In
one-to-all communication, a source node sends a message to every other
node in the network. Whereas, in all-to-all communication, every node
is considered as a source node and sends its message to every other node
In this paper, an improved one-to-all communication
in the network.
algorithm in EJ (n)
α networks is presented. The paper shows that the pro-
posed algorithm achieves a lower average number of steps to receiving the
broadcasted message. In addition, since the links are assumed to be half-
duplex, the all-to-all broadcasting algorithm is divided into three phases.
The simulation results are discussed and showed that the improved one-
to-all algorithm achieves better traﬃc performance than the well-known
one-to-all algorithm and has 2.7% less total number of senders.

Index terms— Parallel Computing, Interconnection Network, Eisenstein-

Jacobi Network, Broadcast, Traﬃc Distribution, One-to-All, All-to-All.

1 Introduction

Multiprocessors are categorized into two types. The ﬁrst type is called dis-
tributed memory multiprocessors system where the communications between the
processors are performed over an interconnection network since every processor
has its own memory unit. The other type is called shared-memory multipro-
cessors system where the processors communicate through a common memory

1

 
 
 
 
 
 
unit. Thus, the topology of interconnection networks plays critical roles in in
achieving high performance in distributed memory multiprocessors. There are
many popular interconnection networks such as Hypercubes [17, 18], General-
ized Hypercubes [8], Twisted Cubes [19], Cube Connected Cycle [25], k–ary
n–cube [9], and Torus [11].

One of the eﬃcient interconnection networks called Eisentein-Jacobi net-
works, simply EJ, introduced in [16, 24]. EJ networks are symmetric and 6-
regular networks where each node in the network is connected to 6 neighbors.
They are based on EJ integers, which are used to implement error-free of radix-3
Fast Fourier Transform (FFT) algorithms and eﬃcient algorithms for complex
multiplication [13]. EJ networks are known to be a generalization of hexagonal
networks developed in [10, 14, 23]. Thus, the applications on hexagonal net-
works can also be applied on EJ networks. As an extension, in [22] a higher
dimensional EJ network has been developed based on the cross products be-
tween the lower dimensional EJ networks. the next section describes the formal
deﬁnition of this network.

The design of eﬃcient communication algorithms for parallel computing sys-
tems has been a hot topic. For instance, the problems related to image pro-
cessing and computer vision [2, 3, 4, 5, 6, 7, 27] are solved based on the imple-
mentation of parallel algorithms. Furthermore, some studies on one-to-all and
all-to-all broadcasting can be found in[15, 21, 26]. In one-to-all broadcasting,
a source node sends its message to every other node in the network. Whereas,
in all-to-all broadcasting, all nodes in the network send their messages to every
other node in the network. Some applications use these types of communica-
tions such as matrix transpose, matrix multiplication, some parallel database
join operations, etc.

In [22], the implementation of one-to-all broadcasting was semi-parallelized.
That is, each node forwards the received message to its neighbors on the same
dimension where the message was received.
In this paper, the broadcasting
algorithms are studied and enhanced to be fully parallelized to achieve better
traﬃc distributions in higher dimensional EJ network.

The structure of the paper is as follows. In Section 2, the topological proper-
ties of EJ network are brieﬂy described. The previous work related to this paper
is discussed in Section 3. Section 4 presents an improved one-to-all broadcast-
ing algorithm and used to implement the all-to-all broadcasting algorithm. In
Section 5, a comparative analysis between the previous and the proposed algo-
rithms is illustrated. Simulation results are illustrated and discussed in Section
6. Finally, the paper is concluded in Section 7.

2 Background

In this section, the important topological properties of Eisenstein-Jacobi net-
works are reviewed in subsection 2.1. Further, the design and the deﬁnition
of higher dimensional Eisenstein-Jacobi networks are summarized in subsection
2.2.

2

2.1 Eisenstein-Jacobi Network (EJα)
Based on the deﬁnitions mentioned in [16, 20], an EJ integer Z[ρ] is the subset
of complex numbers with real and imaginary parts denoted as Z[ρ] =
x + yρ
|
x, y
.
0, 1, 2, . . .
}
−
EJα networks belong to a family of planer graphs, which can be represented as
b where V = Z[ρ]α
graph EJα(V, E) generated by α = a + bρ such that 0
≤
ρ2 mod α
is the node set and E =
is
ρ,
B)
(A, B)
}
≡ ±
the link set represents the connections between the nodes.

where ρ = (1 + i√3)/2, i = √

1 + ρ, and Z =

1, ρ2 =

Z
}

≤
1,

(A

±

×

±

−

−

∈

∈

V

V

a

{

{

{

|

An EJα network generated by α = a + bρ

= 0 is based on quotient rings of
EJ integers and it contains a total number of nodes equal to N (α) = a2 +b2 +ab,
called norm, which is the number of the elements in the residue class modulo
α [20]. EJα networks are 6-regular symmetric networks, i.e., each node in the
network has six neighbors. Each node in the network is labeled as x + yρ, which
represents the location of EJ integer on the grid. Two nodes A and B are
ρ2. The diameter of the network is
neighbors if (A
ρ, or
known as the shortest distance between two most farthest nodes in the network
EJα.

B) mod α is

1,

−

±

±

±

The distance between any two nodes A and B in the network is deﬁned as:

Dα(A, B) = min

z

y

+

{|

x
|

+
(A
−
|
x + yρ + zρ2 (mod α)
}

| |

|

|

≡

B)

(1)

Since EJα is node-symmetric the weight of node A, which is the distance of

this node from node 0, is deﬁned as:

Wα(A) = min

z

y

+

{|

x
|

(A)
+
|
x + yρ + zρ2 (mod α)
}

| |

|

|

≡

(2)

Given a distance s, where s = 0, 1, 2, . . . , M and M is the diameter of the
network deﬁned below, the number of nodes at distance s in EJα is denoted as
WEJ (s) [16]. The following describes the distance distribution of the network.

WEJ (s) =

1
6s
18(M
2

0
N (α)

−

−

≤

s)

s < T

if s = 0
if 1
if T < s < M
if b
≡
and s = M
if s > M
R if s = T

a (mod 3)

(3)






M
where T = (a + b)/2, M = (a + 2b)/3, R =
s=0,s6=T WEJ (s) and the diameter
of the network is at most M . The value of WEJ (T ) depends on whether T ,M
are integers; that is, it depends on the value of a
b (mod 6). The value of
WEJ (T ) can be found by subtracting the sum of the weights already listed from
the total number of nodes a2 + b2 + ab.

P

−

There are two types of links in EJα networks: regular and wraparound links.
The links that connect two nodes within the network grid are called regular links,

3

6
±

±

±

1,

ρ, or

whereas, the wraparound links connect the nodes located within the network
grid with the other node located out of the boundary of the network grid. In
other way, the wraparound links can be understood by using mod α operation
ρ2 to the nodes located at the boundary of the grid
after adding
to get their neighbors located out of the boundary of the grid. In addition, the
wraparound links can be easily seen by placing the EJα network at the origin
of a grid and consider it as a basic EJα network with its center node is 0. Then,
making tiles by copying the basic EJα network and placing its copies around it.
Figure 1 illustrates the EJα network generated by α = 3+4ρ where the solid
lines represent the regular links and the dotted lines represent the wraparound
links. Note that, in Example 2.1, we have removed the straight dotted lines from
node 3 to describe them as wrapped links. Also, we have kept the boundary
nodes of the tiles to represent the nodes located out of the boundary of the grid
and the rest nodes of the tiles are removed. The nodes in diﬀerent tiles of the
network are represented in diﬀerent gray colors.

Example 2.1. Consider the node 3 in Figure 1. The node 3 is connected to
node 3 + ρ through +ρ link, which its corresponding node within the basic grid
ρ2 links of node 3
is
3ρ. That is, 3 + ρ mod α =
−
ρ2, respectively. Note that, in respective
connect the node 3 to nodes 4 and 3
order, their corresponding nodes in the basic grid are 3ρ2 and

3ρ. Similarly, the +1 and

1 + 2ρ2.

−

−

−

−

+3

(cid:0)

2 mod 

(cid:0)

✁

2

(cid:0)

+2

(cid:0)

2 mod 

✁

3

(cid:0)

+

(cid:0)

2 mod 

✁

=

=

4

(cid:0)

2 mod 

✁

=

-3✂

-2✂-✂

2

-✂-2✂

2

=

2

-3✂

-3

= 4

(cid:0)

 mod 

✁

-1+3

(cid:0)

2 mod 

✁

=

3

2

3✂

✂+2✂

2

2✂+✂

2

3✂

-2-✂

= 1+3

(cid:0)

 mod 

✁

-2+2

(cid:0)

2 mod 

✁

=

2

2-

✂

-1+2

✂

2

2

2

✂

2

+

✂

✂

2

✂

1+2

✂

-1-2

✂

= 2+2

(cid:0)

 mod 

✁

-3+

(cid:0)

2 mod 

✁

=

2

1-2

✂

-2+

✂

2

-1+

✂

2

2

✂

✂

1+

✂

2+

✂

-3

✂

= 3+

(cid:0)

 mod 

✁

-4 mod 

✁

=

2

-3

✂

-3

-2

-1

0

1

2

3

2

3

✂

= 4 mod 

✁

-3-

 mod 

(cid:0)

✁

=

3

✂

-2-

✂

-1-

✂

-

✂

2

-

✂

2

1-

✂

2

2-

✂

-1+2

✂

2

= 3-

2 mod 

(cid:0)

✁

-2-2(cid:0) mod ✁ =

1+2

✂

-1-2

✂

-2

✂

-

✂

2

-

✂

2

-2

✂

2

1-2

✂

2

-2+

✂

= 2-2(cid:0)

2 mod ✁

-1-3(cid:0) mod ✁ =

2+

✂

-3

✂

-2

✂

-

✂

2

-

✂

-2

✂

2

2

-3

✂

-3

= 1-3(cid:0)

2 mod ✁

-4(cid:0) mod ✁ =

3

2

3

2

+2

2

+

2

3

✂

✂

✂

✂

✂

✂

= -4(cid:0)

2 mod ✁

=

=

=

-3

(cid:0)

-

(cid:0)

2 mod 

✁

-2

(cid:0)

-2

(cid:0)

2 mod 

✁

-

(cid:0)

-3

(cid:0)

2 mod 

✁

Figure 1: EJ3+4ρ with dotted lines as a wraparound links.

The network can be divided into six sectors. This division is useful in both
one-to-all and all-to-all broadcasting. Figure 2 shows an example of the six sec-
tors in EJ5+6ρ network where the black node is the center node of the network,
usually node 0. A node A = xρj−1 + yρj is in sector j for j = 1, 2, 3, 4, 5, and
6.

4

Sector 2

Sector 5

Figure 2: The six sectors in EJ5+6ρ.

2.2 Higher Dimensional EJ Network EJ (n)
The higher dimensional EJ (n)
α
the higher dimensional EJ (n)
α
between the lower dimensional EJ networks as follows:

α

network was proposed in [22]. It is shown that
network is formed based on the cross product

EJ (n)
α

= EJα

⊗

EJ (n−1)
α

n−1 times

= EJα

(EJα
z

⊗

}|
⊗ · · · ⊗

EJα)
{

(4)

Z[ρ] and n is the number of dimensions of EJ (n)
α .

where 0

= α = a + bρ

∈

|

{

u

∈

∈

V1, v

(u, v)

and E =
.

((u1, v1), (u2, v2))
|

V2}
E2 and u1 = u2)
}

The cross product between two graphs is explained in [12] as follows. Let
G(V, E) be the resultant graph from the cross product between two graphs
G2
G1 = (V1, E1) and G2 = (V2, E2). Then, G(V, E) can be written as G1 ×
where V =
E1
∈
∈
{
and v1 = v2) or ((v1, v2)
The total number of nodes in EJ (n)

is N (α)n, which is the total number
α
of nodes in a single dimensional EJ network power of n. A node in EJ (n)
is
denoted as a set of n-tuples with coordinates in EJα. That is, a node (xn + ynρ,
xn−1 + yn−1ρ, . . . , x1 + y1ρ) is located in the positions xn + ynρ on the ﬁrst
layer (highest or nth-dimension) of EJ (n)
α , xn−1 + yn−1ρ on the second layer of
EJ (n)
α , and so on until x1 + y1ρ on the last layer (lowest or 1st-dimension) of
EJ (n)
α . The degree of each node is 6n. EJ (n)
can be drawn by placing a copy of
EJ (n−1)
2+3 where
α
ρ2, 1 + ρ) is ﬁlled with a black color with all of its edges connected
the node (1

on each node of EJα. For example, Figure 3 illustrates EJ (2)

((u1, u2)

α

α

−

5

6
to its neighbors and the neighbors of node (0,0) are obvious.

Figure 3: EJ (2)
black node is (1

ρ2,1 + ρ).

−

2+3ρ with nodes 0 and (1

ρ2,1 + ρ) and their neighbors. The

−

3 Previous Work

In this section, the known one-to-all broadcasting algorithm is reviewed. After
that, the one-to-all broadcasting algorithm for EJ (n)

is brieﬂy described.

α

Before describing the algorithm, except the node 0 + 0i (simply 0), there are
two types of receiving nodes, the axis nodes xρp, for p = 0, 1, 2 and x is either
positive or negative integer; and the non-axis nodes, i.e., the rest of the nodes.
The one-to-all broadcasting [1, 23] in EJα can be performed in M steps based
on the spanning tree and the six sectors of EJα as described in Figure 2, where
the numbered links illustrates the steps of the broadcasting.

Consider the network EJα. The spanning tree of the network is constructed
during the broadcasting process as follows. In the ﬁrst step, the root node of the
spanning tree, usually node 0, sends its message to the six sectors through all
neighbor nodes (1, ρ, ρ2,
ρ2), where each neighbor node is responsible
to distribute the message to its sector. From steps 2 to M the algorithm works
as follows. In each step, each node receives the message from its parent node
will forward the message to its children within its sector. That is, the axis nodes
forward the message to two neighbor nodes and the non-axis nodes forward the
message to one neighbor node, all located within the same sector.

ρ,

1,

−

−

−

For example, consider the network EJ3+4ρ. Based on the spanning tree
illustrated in Figure 4, in the ﬁrst step, the node 0 sends a message to nodes
1, ρ, ρ2,
ρ2 through the links numbered 1. The rest of the
broadcasting process is explained for sector 6 since all sectors perform the same

ρ, and

1,

−

−

−

6

steps of the algorithm. In the second step, the axis node 1 receives its message
from node 0 and then forwards the message to the axis node 2 and the non-axis
ρ2 via the links numbered 2. Finally, in the third and last step, the
node 1
ρ2
axis node 2 forwards its received message to its neighbor nodes 3 and 2
ρ2 forwards the
through the links numbered 3, whereas, the non-axis node 1
received message to its neighbor node 1

2ρ2 via the links numbered 3.

−

−

−

−

2

3

2

+2

2

+

2

3

✂

✂

✂

✂

✂

✂

3

3

2

2

✂

3

2

+

✂

✂

-1+2

✂

2

3

2

-2+✂

2

-1+✂

2

2

2

2

✂

✂

3

-3

3

-2-

✂

-2

3

-1-2

✂

1

2

-1

2

-1-

✂

2

1

1

0

1

1

2

1

-

✂

2

3

2

✂

2

1

3

1+2

✂

1+✂

3

3

3

2

2+✂

3

3

3

2

-

✂

2

1-

✂

2

2-

✂

2

3

-2

3

3

-3

✂

✂

✂

✂

✂

✂

2

-

-

2

-2

1-2

2

3

3

3

-2

✂

2

-

✂

-

✂

-2

✂

2

2

-3

✂

Figure 4: One-to-all broadcast in EJ3+4ρ.

α

α

In [22], an iterative one-to-all broadcasting algorithm has been developed
for EJ (n)
based on the above described one-to-all broadcasting algorithm for
EJα. The one-to-all broadcasting in EJ (n)
is divided into n rounds such that
each round has M steps. For round 1, the M -steps of one-to-all are applied on
the nth dimension (ﬁrst layer). When the round 1 is ended, each center node
in EJ (n−1)
has received the message. Then, the one-to-all is applied on the
α
1)th dimension in round 2. That is, each of EJ (n−1)
(n
applies the one-to-all
broadcast. Repeating this process for n rounds from the highest layer to the
lowest layer makes all nodes receive the message. That is, for round i + 1, where
in the
i = 0, 1, . . . , n
i)th dimension. Figures 5 and 6, in respective order, illustrate the ﬁrst and
(n
second rounds of the one-to-all broadcasting process in EJ (2)

1, the M -steps of one-to-all are applied on every EJ (n−i)

−

−

−

α

α

2+3ρ.

4 An Improved Broadcasting in EJ (n)
α

This section proposes the improved one-to-all broadcasting algorithm. Further,
the proposed one-to-all algorithm is used in the implementation of all-to-all
broadcasting algorithm. For simplicity, the algorithms below are described for
the EJ (n)
α networks where b = a + 1. The same algorithms with little modiﬁca-
tions could be used to perform the broadcasting on EJ (n)
b.

such that 0

a

α

≤

≤

7

2

2

2

2

2

1

1

1

1

1

1

2

2

2

2

2

2

2

Figure 5: First round of one-to-all broadcast in EJ (2)

2+3ρ.

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

2 2

2

2

2

2

2
2

1

1

1

1

1

1

2

2

22

Figure 6: Second round of one-to-all broadcast in EJ (2)

2+3ρ.

4.1 One-to-All Broadcast

The previous and the proposed one-to-all algorithms have the same number of
rounds and steps, which is nM where M is the diameter of the network and n is
the number of dimensions. The advantage of the proposed one-to-all algorithms
over the previous one is that the proposed algorithms distribute the broadcast
traﬃc over the broadcast steps on a relatively more balanced manner. This
results in a lower average number of steps needed to receive the broadcasted
message.

Algorithms 1 and 2 describe the proposed one-to-all broadcasting algorithm
a+bρ where b = a + 1 and n > 0. Simply, the node 0 sends its message to

on EJ (n)

8

all of its neighboring nodes in all dimensions. Then, as in the previous one-to-all
algorithm, each receiving node sends the received message to the neighboring
nodes in its sector. In addition, the receiving nodes send their message to all
of their neighboring nodes in all dimensions that are lower than the receiving
dimension.

For example, consider the network EJ (2)

ρ2), (1, 0), (ρ, 0), (ρ2, 0), (

2+3ρ. The improved one-to-all broad-
casting works as follows. In step 1, as illustrates in Figure 7, the center node
(node 0) sends its message to all of its neighbors in all dimensions. That is,
the node 0 sends its message to nodes (0, 1), (0, ρ), (0, ρ2), (0,
ρ),
ρ2, 0), i.e., the node
(0,
1, 0), (
0 calls ONE-TO-ALL(n,1). After that, in steps 2 to nM , each receiving node
is responsible in propagating the message to its sector on the same dimension
and to the six sectors in all lower dimensions. It means that the receiving node
applies recursively the one-to-all on the lower dimensions while continuing in
sending the received message to the neighboring nodes in its sector on the same
dimension. The second step of the broadcasting is shown in Figure 8.

ρ, 0), and (

1), (0,

−

−

−

−

−

−

Algorithm 1 One-to-All Broadcast
1: procedure One-to-All(dimension, step)
2: Let n be the number of dimensions and M be the diameter of the network
1, step+1)
3:

1, M

−

−

1 packet SECTOR(

1, +ρ2, dimension, M

Send via +ρ packet SECTOR(+ρ, +1, dimension, M
⊲ S1
Send via +ρ2 packet SECTOR(+ρ2, +ρ, dimension, M
step + 1)
Send via
step + 1)
Send via
step + 1)
Send via
step + 1)
Send via +1 packet SECTOR(+1,
step + 1)
if dimension > 1 then

ρ2 packet SECTOR(

ρ2, dimension, M

ρ packet SECTOR(

1, dimension, M

ρ, dimension, M

ρ2,

ρ2,

−

−

−

−

−

−

−

−

−

1, M

1, M

1, M

1, M

1, M

−

−

−

−

−

1,
−
⊲ S2
1,
−
⊲ S3
1,
−
⊲ S4
1,
−
⊲ S5
1,
−
⊲ S6

4:

5:

6:

7:

8:

9:
10:

ONE-TO-ALL(dimension

1, step)

−

4.2 All-to-All Broadcast

The all-to-all broadcast performs the one-to-all broadcast in every node in the
network. That is, all nodes send their messages to all other nodes in the network.
Note that, all nodes cannot perform the one-to-all broadcast simulatneously
since no node in the network can send and receive at the same time using the
same link. Thus, the all-to-all communications is divided into three phases
in which each phase is responsible to propogate the message to two sectors.
Algorithms 3 and 4 describe the all-to-all broadcast.

9

Algorithm 2 One-to-All Sector
1: procedure Sector(major, minor, dimension, x, y, step)
2: Let n be the number of dimensions and M be the diameter of the network
3:

if step > nM then

4:
5:

6:

7:

8:

9:

10:

return
if x > 0 then

Send via minor packet SECTOR(
major, minor, dimension, x
step + 1)
if y > 0 then

−

1, 0,

Send via major packet SECTOR(
major, minor, dimension, x
step + 1)

−

1, y

1,

−

if dimension > 1 then

ONE-TO-ALL(dimension

1, step)

−

Algorithm 3 All-to-All Broadcast
1: procedure All-to-All(dimension, step, phase)
2: Let n be the number of dimensions and M be the diameter of the network
3:
4:

if phase = 1 then

5:

6:
7:

8:

9:

10:

11:

12:

13:

1, M

−

Send via +1 packet SECTOR(
ρ2, dimension, M
+1,
step + 1, phase)
Send via +ρ packet SECTOR(
+ρ, +1, dimension, M
1, M
step + 1, phase)
if phase = 2 then

−

−

1,

−

1,

−

Send via +ρ2 packet SECTOR(
+ρ2, +ρ, dimension, M
1, M
step + 1, phase)
Send via

1 packet SECTOR(

−

1, +ρ2, dimension, M

−

1,

−

1, M

1,

−

−

−
step + 1, phase)
if phase = 3 then

ρ,

Send via

ρ packet SECTOR(
1, M

1, dimension, M

−

−

−
step + 1, phase)
Send via
ρ2,

ρ2 packet SECTOR(
1, M

ρ, dimension, M

−

−

1,

−

−

1,

−

−

−
step + 1, phase)
if dimension > 1 then

ALL-TO-ALL(dimension

1, step, phase)

−

10

Figure 7: Step 1 of the proposed one-to-all broadcast in EJ (2)

2+3ρ.

Figure 8: Step 2 of the proposed one-to-all broadcast in EJ (2)

2+3ρ.

The all-to-all broadcasting algorithm works as follows. In phase 1, all nodes
call ALL-TO-ALL(n, 1, 1), which means that all nodes perform the one-to-all
broadcasting on sectors 6 and 1 in all dimensions. In order to do that, all nodes
in the network open three of their ports and utilize them to send the messages
In addition, all
to the neighboring nodes over the links (+ρ, +1, and

ρ2).

−

11

Algorithm 4 All-to-All Sector
1: procedure Sector(major, minor, dimension, x, y, step, phase)
2: Let n be the number of dimensions and M be the diameter of the network
3:

if step > nM and phase = 3 then

4:
5:

6:

7:
8:

9:

10:

11:

return

else if step > nM and phase < 3 then

ALL-TO-ALL(n, 1, phase+1)

else

if x > 0 then

Send via minor packet SECTOR(
major, minor, dimension, x
step + 1,
phase)
if y > 0 then

−

1, 0,

Send via major packet SECTOR(
major, minor, dimension, x
step + 1,
phase)

−

1, y

1,

−

12:

if dimension > 1 then

13:
14: phase)

ALL-TO-ALL(dimension

1, step,

−

−

−

ρ,

nodes open the other three ports and utilize them to receive the message from
1, and +ρ2). In phase 2, similar
their neighboring nodes over the links (
to phase 1, but the one-to-all broadcasting is performed on sectors 2 and 3 in
all dimensions. Each node opens three ports for sending the messages to their
1, +ρ2, and +ρ), whereas, the other three ports
neighbors through the links (
ρ2,
are used to receive the messages from the neighbors through the links (+1,
ρ). Finally, in phase 3, the one-to-all broadcasting is applied on sectors 4
and
and 5 in all dimensions. That is, all nodes open and utilize three of their ports
to send the message to their neighbors via the links (
1); and
open and use the other three ports to receive the messages from the neighbors
via the links (+ρ2, +ρ, and +1).

ρ, and

ρ2,

−

−

−

−

−

−

By the end of phase 3, each node has sent its message to all other nodes in
the network. That is, every node in the network has received N (α)n
1 distinct
messages. Figures 9, 10, and 11 illustrates the ports and the links used by the
nodes in a single dimension to send and receive messages in each phase.

−

2

+✂

+✂

-1

+1

-✂

2

-✂

Figure 9: The sending and receiving ports in EJα during phase 1.

12

2

+✂

+✂

-1

+1

-✂

2

-✂

Figure 10: The sending and receiving ports in EJα during phase 2.

2

+✂

+✂

-1

+1

-✂

2

-✂

Figure 11: The sending and receiving ports in EJα during phase 3.

In higher dimensional EJ (n)

α , the links will be more complex. That is, there
will be more links to propagate the messages over the higher and lower dimen-
sions of the network. For clarity, the all-to-all broadcasting in a single dimen-
sional EJα is shown in Figures 12, 13, and 14 for the ﬁrst, second, and third
steps of phase 1, respectively. Note that, the four senders are numbered with
their messages to track the messages in each step and to distinguish between
them.

1

1

1

2
2

2

3

3

3

4
4

4

Figure 12: All-to-all broadcast: The ﬁrst step of phase 1 in part of a single
dimensional EJα.

13

1

1

2

1

2

1,2

1

3

3

4

2,3

2

4

3,4

3

4

4

Figure 13: All-to-all broadcast: The second step of phase 1 in part of a single
dimensional EJα.

1

1

2

1,2

1

2

3

1,2,3

1

4

2,3,4

2

1

3

4

3,4

3

2

4

4

3

4

Figure 14: All-to-all broadcast: The third step of phase 1 in part of a single
dimensional EJα.

5 Performance Analysis

In this section, the performance of the previous and the proposed one-to-all
broadcasting algorithms is analyzed and discussed in term of the number of
senders, receivers, active (senders + receivers), and free (total nodes - active
nodes) nodes in each step of the broadcasting.
α where α

Z[ρ]. Note that, the previous algorithm ﬁnishes
the broadcast in nM steps where n is the number of dimensions and M is the
network diameter (and the number of steps in each round). Then, the number
of receiver nodes in each step for the previous broadcasting algorithm is denoted

Consider EJ (n)

∈

14

Table 1: An analysis of the iterative (previous) One-to-All broadcasting on
EJ (3)

3+4ρ

Round

1

2

3

Total

Step
1
2
3
1
2
3
1
2
3
12

Free
50,646
50,635
50,623
50,394
49,987
49,543
41,070
26,011
9,583

Sending Receiving Active
6
12
18
222
444
666
8,214
16,428
24,642
50,652

1
6
12
37
222
444
1,369
8,214
16,428
26,733

7
18
30
259
666
1,110
9,583
24,642
41,070

numR and expressed as:

numR = 6dN (α)r−1

(5)

where r is the round number such that 0
r < n and d is the distance or
M . Furthermore, the number
step number during round r such that 1
of sender nodes in each step is equal to the number of receiver nodes of the
previous step. That is, the total number of sender nodes in each step is numS
and it is computed as:

≤
d

≤

≤

numS = 6(d

1)N (α)r−1

−

(6)

where r is the round number such that 0
number during round r such that 1

d

≤
M .

r < n and d is the distance or step

≤
Table 1 lists the number of free, sending, receiving, and active nodes in each

≤

step in the network EJ (3)

3+4ρ for the previous one-to-all algorithm.

The following formulas recursively computes the total number of receivers

in each step of the proposed one-to-all broadcasting.

O2A(n) = 




6S(n, M
O2A(n
−
6S(n, M

1, M

−
1)+

1, M

−

1)

1)

−

−

n = 1

n > 1

(7)

15

S(n, x, y) =

S(n, x
S(n, x

S(n, x

1, 0)+
1, y

−

1, 0)

−
−

−

1)

n = 1, x > 0, y > 0

n = 1, x > 0, y = 0

O2A(n
S(n, x
S(n, x

1)+
1, 0)+
1, y

−

−
−
−

O2A(n
S(n, x

1)+
1, 0)

−
−

1)

n > 1, x > 0, y > 0

(8)

n > 1, x > 0, y = 0

O2A(n

1)

n > 1, x = 0, y = 0

−






where n is the number of dimensions, M is the network diameter, and x, y are
steps counters. The number of senders in the ith step of the proposed algorithm
is as follows.

numSi = numRi−1 −

number of S(1, 0, 0)

in (i

1)th step

−

(9)

where numSi is the number of the senders in step i and numRi−1 is the number
1 calculated based on the the above formulas. Or, numSi
of receivers in step i
can be computed as follows.

−

numSi = number of expanded S′s in step i

1

−

(10)

For example, consider EJ (2)

2+3ρ where its diameter is M = 2. Then, the step

1 can be written as:

O2A(2) = O2A(1) + 6S(2, 1, 1)

= 6S(1, 1, 1) + 6S(2, 1, 1)

Consequently, the number of receivers is 12, which is the total number of ex-
panded S’s in a single step, and the number of the senders is 1. Moreover, each
of the S can be expanded in step 2 and it can be written as:

= 6(S(1, 0, 0) + S(1, 0, 0)) +

6(O2A(1) + S(2, 0, 0) + S(2, 0, 0))
= 12S(1, 0, 0) + 6(6S(1, 1, 1) + 2S(2, 0, 0))

As a result, the number of receivers is 60 (since there are 60S’s) and the number
of the senders is 12, which is the number of S’s in the previous step excluding
S(1,0,0)’s. It is possible to get the third step after expanding all S’s and remov-
ing all S(1,0,0)’s from the previous step, i.e., step 2, since the broadcast ends
at S(1,0,0). This can be expressed as:

= 6(6(S(1, 0, 0) + S(1, 0, 0)) + 2
= 6(12S(1, 0, 0) + 12S(1, 1, 1))

∗

O2A(1))

16

Table 2: An analysis of the proposed One-to-All broadcasting on E(J)3

3+4ρ

Free
50,634
50,491
49,807
47,593
42,661
35,425
29,809
31,861
40,933

Step
1
2
3
4
5
6
7
8
9
Total

Sending Receiving Active
18
144
702
2,376
5,832
10,476
13,608
11,664
5,832
50,652

1
18
144
684
2,160
4,752
7,236
7,128
3,888
26,011

19
162
846
3,060
7,992
15,228
20,844
18,792
9,720

Accordingly, the number of receivers is 144 and the number of the senders is 48.
Finally, to get the step 4, which is the last step, all S(1, 1, 1) are expanded and
all S(1,0,0) are eliminated since the broadcast ﬁnishes at this point. Then,

= 6(12(S(1, 0, 0) + S(1, 0, 0)))
= 144S(1, 0, 0)

Thus, the number of receivers is 144 and the number of senders is 72. Since
S(1,0,0) cannot be expanded then the broadcast ends at this step.

Table 2 lists the number of free, sending, receiving, and active nodes in each

step of the proposed algorithm applied on the network EJ (3)

3+4ρ.

6 Performance Evaluation

The simulation results of the comparisons between the previous and the pro-
posed one-to-all broadcasting are discussed in this section. The assumption
made for the simulation is that the communications are half-duplex and utilize
all ports. The number of active nodes, whether sending or receiving, are added
up for the purpose of comparisons in each step of the broadcast.

The simulation ran on EJ (n)

3+4ρ network such that 2

6. In addition,
≤
simulations on EJ (12)
3+4ρ, EJ (3)
4+5ρ, and EJ (2)
6+7ρ networks are done
and taken into consideration since all of these networks have diﬀerent dimensions
but are equal in number of steps. Then, the average of the simulation results is
computed. The following is the discussion about these simulations.

2+3ρ, EJ (4)

1+2ρ, EJ (6)

≤

n

Figure 15 describes the total number of senders in each step of the broad-
casting algorithm in EJ (3)
3+4ρ. From the ﬁgure, the proposed algorithm spreads
the message in the middle steps to larger number of nodes than the previous
algorithm. Also, it can be seen that the total number of sending nodes in the
later steps of the proposed algorithm is less than the previous algorithm. That

17

means, the load on the nodes has been reduced. As a consequence, the proposed
algorithm has less overhead than the previous algorithm in later steps.

s
e
d
o
N

f
o

r
e
b
m
u
N

18000

16000

14000

12000

10000

8000

6000

4000

2000

0

Previous

Proposed

1

2

3

4

6

7

8

9

5
Step 

Figure 15: One-to-All: Number of senders in each step in EJ (3)

3+4ρ.

Figure 16 shows the number of receivers in every step of the broadcasting
algorithm in EJ (3)
3+4ρ. Compared to the previous algorithm, the proposed al-
gorithm makes most of the nodes had received the message during the middle
steps. Thus, the nodes in the middle steps will be available to perform other
tasks whether processing, sending, or receiving more messages in the later steps.
However, the previous algorithm makes most of the nodes have to wait in order
to receive the message during the later steps. Regarding the overhead, it is
obvious that most of the nodes are busy in receiving the messages during the
later steps of the previous algorithm. As a comparison, the proposed algorithm
has less overhead and more free nodes that are available to perform other tasks
during the later steps.

s
e
d
o
N

f
o

r
e
b
m
u
N

30000

25000

20000

15000

10000

5000

0

Previous

Proposed

1

2

3

4

6

7

8

9

5
Step 

Figure 16: One-to-All: Number of receivers in each step in EJ (3)

3+4ρ.

Figure 17 describes the number of free nodes in each step of the broadcast
algorithm in EJ (3)
3+4ρ. It is clear that the proposed algorithm keeps some nodes
busy during the middle steps, which reduces the overhead on the nodes in the
later steps.

From Figures 17 and 18, it can be concluded that the load in the network
is distributed between the middle and later steps in the proposed algorithm

18

 
 
 
 
 
 
s
e
d
o
N

f
o

r
e
b
m
u
N

60000

50000

40000

30000

20000

10000

0

Previous

Proposed

1

2

3

4

5
Step 

6

7

8

9

Figure 17: One-to-All: Number of free nodes in each step in EJ (3)

3+4ρ.

instead of keeping most of the nodes busy in the later steps.

s
e
d
o
N

f
o

r
e
b
m
u
N

45000

40000

35000

30000

25000

20000

15000

10000

5000

0

Previous

Proposed

1

2

3

4

6

7

8

9

5
Step 

Figure 18: One-to-All: Number of active nodes in each step in EJ (3)

3+4ρ.

The previous and the proposed one-to-all broadcasting algorithms have been
ran on the following EJ networks, EJ (12)
1+2ρ, EJ (6)
4+5ρ, and EJ (2)
6+7ρ,
since all of them require 12 steps to ﬁnish the broadcast. In every step, the
average number of sending, receiving, and active nodes have been computed.
Figures 19, 20, and 21 illustrate, in respective order, the average number of
sending, receiving, and active nodes for both algorithms. Compared with the
previous ﬁgures, it can been seen that both algorithms have similar plot. As a
conclusion, the proposed algorithm is better than the previous one.

2+3ρ, EJ (4)

3+4ρ, EJ (3)

s
e
d
o
N

f
o

r
e
b
m
u
N
e
g
a
r
e
v
A

450000000

400000000

350000000

300000000

250000000

200000000

150000000

100000000

50000000

0

Previous

Proposed

1

2

3

4

5

6
7
Step 

8

9

10

11

12

Figure 19: One-to-All: Average number of senders in each step.

19

 
 
 
 
 
 
 
 
 
 
s
e
d
o
N

f
o

r
e
b
m
u
N
e
g
a
r
e
v
A

2.5E+09

2E+09

1.5E+09

1E+09

500000000

0

Previous

Proposed

1

2

3

4

5

6

7
Step 

8

9

10

11

12

Figure 20: One-to-All: Average number of receivers in each step.

s
e
d
o
N

f
o

r
e
b
m
u
N
e
g
a
r
e
v
A

3E+09

2.5E+09

2E+09

1.5E+09

1E+09

500000000

0

Previous

Proposed

1

2

3

4

5

7
6
Step 

8

9

10

11

12

Figure 21: One-to-All: Average number of active nodes in each step.

In Figure 22, the proposed one-to-all shows an improvement in the total
number of senders in EJ (n)
3+4ρ for n = 4 to 6. The diﬀerence is that the sender
node in the proposed algorithm is used once to send the message to all of its
neighbors while it is used several times in the previous one-to-all algorithm in
order to send the message to all of its neighbors.

s
p
e
t
S
l
l

A
r
o
f

s
r
e
d
n
e
S
l
a
t
o
T

1.6E+09

1.4E+09

1.2E+09

1E+09

800000000

600000000

400000000

200000000

0

Previous

Proposed

4D

5D
Dimension 

6D

Figure 22: One-to-All: The total senders in each step in EJ (n)

3+4ρ for n = 4 to 6.

The total number of senders for all steps of the broadcasting in EJ (n)
3+4ρ for
n = 1 to 6 is listed in Table 3 for both, the previous and the proposed, one-to-all
algorithms. Further, the table describes the diﬀerence between both algorithms
in terms of number of senders per dimension. From Figure 22 and Table 3, it can
be seen that the proposed one-to-all shows an improvements of approximately
2.7% for all dimensions. That is, the total number of senders in the proposed
algorithm is less than the previous algorithm since in the proposed algorithm

20

 
 
 
 
 
 
 
 
 
 
 
 
 
2D

1D

Table 3: Total number of senders in all steps after the broadcast is completed
in EJ (n)
3+4ρ
EJ3+4ρ
Previous
One-to-All
Proposed
One-to-all
Diﬀerence
Ratio

722
1.027757487

26,733
1.027777229

19
1.027027027

989,140
1.027777763

36,598,199

35,609,059

989,140

962,407

26,011

26,733

703

722

5D

3D

4D

0
1

19

19

6D

1,354,133,382

1,317,535,183

36,598,199
1.027777777

the sender is used only once.

7 Conclusion

The paper proposes an enhanced one-to-all and all-to-all communication algo-
rithms for higher dimensional Eisenstein-Jacobi (EJ) networks. The proposed
one-to-all algorithm is compared with one-to-all algorithm (previous) used in
[22]. For the comparisons, the author did simulations for both the proposed
and the previous algorithms on diﬀerent sizes of higher dimensional EJ networks
and showed that the proposed algorithm achieves 2.7% less in total number of
senders than the previous algorithm. In addition, the simulation results show
that proposed algorithm transfer the message to larger number of nodes than
the previous algorithm during the middle steps of the broadcasting. As a conse-
quence, the nodes in the middle steps become free and available to process other
tasks since the overhead is reduced in the later steps. Further, the broadcasting
traﬃc load in the proposed algorithm is distributed among the steps while it is
pushed in the later steps of the previous algorithm.

Furthermore, the paper presented the all-to-all broadcasting algorithm, which
is based on the proposed one-to-all algorithm. In all-to-all broadcasting, the
communication is assumed to be half-duplex and because of that the all-to-all
broadcasting algorithm is divided into three phases where in in each phase the
messages are propagated on two sectors.

References

[1] Bader Albader, Bella Bose, and Mary Flahive. Eﬃcient communication al-
gorithms in hexagonal mesh interconnection networks. IEEE Transactions
on Parallel and Distributed Systems, 23(1):69–77, 2012.

[2] Hamid R Arabnia. A parallel algorithm for the arbitrary rotation of dig-
itized images using process-and-data-decomposition approach. Journal of
Parallel and Distributed Computing, 10(2):188–192, 1990.

21

[3] Hamid R Arabnia. A distributed stereocorrelation algorithm. In Computer
Communications and Networks, 1995. Proceedings., Fourth International
Conference on, pages 479–482. IEEE, 1995.

[4] Hamid R Arabnia and Martin A Oliver. Arbitrary rotation of raster images
with simd machine architectures. In Computer Graphics Forum, volume 6,
pages 3–11. Wiley Online Library, 1987.

[5] Hamid R. Arabnia and Martin A Oliver. A transputer network for the
arbitrary rotation of digitised images. The Computer Journal, 30(5):425–
432, 1987.

[6] Hamid R Arabnia and Martin A Oliver. A transputer network for fast
In Computer graphics forum, volume 8,

operations on digitised images.
pages 3–11. Wiley Online Library, 1989.

[7] Suchendra M Bhandarkar and Hamid R Arabnia. The hough transform
on a reconﬁgurable multi-ring network. Journal of Parallel and Distributed
Computing, 24(1):107–114, 1995.

[8] Laxmi N. Bhuyan and Dharma P. Agrawal. Generalized hypercube and
hyperbus structures for a computer network. IEEE Transactions on com-
puters, 100(4):323–333, 1984.

[9] Bella Bose, Bob Broeg, Younggeun Kwon, and Yaagoub Ashir. Lee dis-
tance and topological properties of k-ary n-cubes. IEEE Transactions on
Computers, 44(8):1021–1030, 1995.

[10] M-S Chen, Kang G Shin, and Dilip D. Kandlur. Addressing, routing, and
broadcasting in hexagonal mesh multiprocessors. IEEE Transactions on
Computers, 39(1):10–18, 1990.

[11] William J Dally and Charles L Seitz. The torus routing chip. Distributed

computing, 1(4):187–196, 1986.

[12] Narsingh Deo. Graph theory with applications to engineering and computer

science. Courier Dover Publications, 2016.

[13] V Dimitrov, GA Jullien, and WC Miller. Eisenstein residue number system
with applications to dsp. Computer Standards & Interfaces, 20(6):457,
1999.

[14] James W. Dolter, Parameswaran Ramanathan, and Kang G. Shin. Perfor-
mance analysis of virtual cut-through switching in harts: a hexagonal mesh
multicomputer. IEEE Transactions on Computers, 40(6):669–680, 1991.

[15] Jose Duato, Sudhakar Yalamanchili, and Lionel M Ni.

Interconnection

networks: an engineering approach. Morgan Kaufmann, 2003.

22

[16] Mary Flahive and Bella Bose. The topology of gaussian and eisenstein-
jacobi interconnection networks. IEEE Transactions on Parallel and Dis-
tributed Systems, 21(8):1132–1142, 2010.

[17] John P Hayes and Trevor Mudge. Hypercube supercomputers. Proceedings

of the IEEE, 77(12):1829–1841, 1989.

[18] John P Hayes, Trevor N Mudge, Quentin F Stout, Stephen Colley, and
John Palmer. Architecture of a hypercube supercomputer. In ICPP, pages
653–660, 1986.

[19] Peter AJ Hilbers, Marion RJ Koopman, and Jan LA Van de Snepscheut.
The twisted cube. In International Conference on Parallel Architectures
and Languages Europe, pages 152–159. Springer, 1987.

[20] Klaus Huber. Codes over eisenstein-jacobi integers. Contemporary Mathe-

matics, 168:165–165, 1994.

[21] Zaid A Hussain, Bella Bose, and Abdullah Al-Dhelaan. Edge disjoint hamil-
tonian cycles in eisenstein–jacobi networks. Journal of Parallel and Dis-
tributed Computing, 86:62–70, 2015.

[22] Zaid A. Hussain and Arash Shamaei. Higher dimensional eisenstein-jacobi

networks. Journal of Parallel and Distributed Computing, pages –, 2016.

[23] Dilip D Kandlur and Kang G Shin. Reliable broadcast algorithms for harts.
ACM Transactions on Computer Systems (TOCS), 9(4):374–398, 1991.

[24] Carmen Martinez, Esteban Staﬀord, Ramon Beivide, and E M Gabidulin.
Modeling hexagonal constellations with eisenstein-jacobi graphs. Problems
of Information Transmission, 44(1):1–11, 2008.

[25] Franco P Preparata and Jean Vuillemin. The cube-connected cycles: a
versatile network for parallel computation. Communications of the ACM,
24(5):300–309, 1981.

[26] Abderezak Touzene. All-to-all broadcast in hexagonal torus networks on-
chip. IEEE Transactions on Parallel and Distributed Systems, 26(9):2410–
2420, 2015.

[27] M Arif Wani and Hamid R Arabnia. Parallel edge-region-based segmenta-
tion algorithm targeted at reconﬁgurable multiring network. The Journal
of Supercomputing, 25(1):43–62, 2003.

23

"
"Efficient All-to-All Collective Communication Schedules for
  Direct-Connect Topologies","  The all-to-all collective communications primitive is widely used in machine
learning (ML) and high performance computing (HPC) workloads, and optimizing
its performance is of interest to both ML and HPC communities. All-to-all is a
particularly challenging workload that can severely strain the underlying
interconnect bandwidth at scale. This paper takes a holistic approach to
optimize the performance of all-to-all collective communications on
supercomputer-scale direct-connect interconnects. We address several
algorithmic and practical challenges in developing efficient and
bandwidth-optimal all-to-all schedules for any topology and lowering the
schedules to various runtimes and interconnect technologies. We also propose a
novel topology that delivers near-optimal all-to-all performance.
","4
2
0
2

r
p
A
5
2

]

C
D
.
s
c
[

2
v
1
4
5
3
1
.
9
0
3
2
:
v
i
X
r
a

Efficient all-to-all Collective Communication
Schedules for Direct-connect Topologies∗

Prithwish Basu
RTX BBN Technologies
Cambridge, MA
prithwish.basu@rtx.com

Siddharth Pal
RTX BBN Technologies
Cambridge, MA
siddharth.pal@rtx.com

Liangyu Zhao
University of Washington
Seattle, WA
liangyu@cs.washington.edu

Arvind Krishnamurthy
University of Washington
Seattle, WA
arvind@cs.washington.edu

Jason Fantl
RTX BBN Technologies
Cambridge, MA
jason.fantl@rtx.com

Joud Khoury
RTX BBN Technologies
Cambridge, MA
joud.khoury@rtx.com

Abstract

The all-to-all collective communications primitive is widely
used in machine learning (ML) and high performance com-
puting (HPC) workloads, and optimizing its performance is
of interest to both ML and HPC communities. All-to-all is a
particularly challenging workload that can severely strain
the underlying interconnect bandwidth at scale. This pa-
per takes a holistic approach to optimize the performance
of all-to-all collective communications on supercomputer-
scale direct-connect interconnects. We address several algo-
rithmic and practical challenges in developing efficient and
bandwidth-optimal all-to-all schedules for any topology and
lowering the schedules to various runtimes and interconnect
technologies. We also propose a novel topology that delivers
near-optimal all-to-all performance.

1 Introduction

Collective communications have received significant atten-
tion in both high performance computing (HPC) and ma-
chine learning (ML) disciplines. The all-to-all collective, in
particular, is used in several HPC workloads such as with the
3D Fast Fourier Transform (FFT) [40] used in molecular dy-
namics [4, 12] and direct numerical simulations [35]. It is also
used in ML workloads, for example, to exchange large em-
beddings in the widely deployed Deep Learning Recommen-
dation Model (DLRM) [36, 37], and in the mixture-of-experts
(MoE) models [30]. All-to-all collective communication is
often a bottleneck at scale in these workloads [10, 16, 43].

An emerging approach to meet these challenging demands
has been to employ various forms of optical circuit switching
to achieve higher bandwidths at reasonable capital expen-
diture and energy costs [24, 27, 31, 32, 53, 55, 61]. Hosts
communicate using a limited number of optical circuits that
may be reconfigured at timescales appropriate for the hard-
ware (see §2.1), thus exposing network topology as a config-
urable component. We refer to this setting as direct-connect

∗Distribution Statement “A” (Approved for Public Release, Distribution
Unlimited).

1

with circuits that are configured and fixed for an appropri-
ate duration. Direct-connect fabrics and topologies such as
mesh, Tori, DragonFly [28], and SlimFly [13] have been well
studied in the HPC community and deployed across several
supercomputers, such as with Google’s TPUv4 [24, 31].

Computing bandwidth-optimal all-to-all schedules on a
direct-connect topology with 𝑁 nodes can be formulated
using the Max Concurrent Multi-Commodity Flow problem,
hereafter MCF, and solved in polynomial time using linear
programming (LP) [47]. MCF, however, suffers from high
time complexity even at modest scales since the number
of flow variables in a bounded degree network scales as
O (𝑁 3). At 𝑁 = 1000, for example, even a state-of-the-art LP
solver [8] is unable to generate a schedule on a fast machine
within an entire day. For smaller 𝑁 (< 100), which is typi-
cal of ML applications, it takes tens of minutes to generate
a schedule. This makes it hard for the algorithm to react
quickly to changes in the topology, for example, due to topol-
ogy reconfiguration or failures. We enhance the scalability
of the exact all-to-all MCF by decomposing it into a simpler
master LP and a set of 𝑁 children LPs that are parallelized for
fast computation. We demonstrate a O (𝑝𝑜𝑙𝑦 (𝑁 )) speed up
in time complexity under decomposition and parallelization,
reducing actual runtime on 𝑁 = 1000 by orders of magni-
tude to 40 minutes instead. For 𝑁 in the hundreds, it takes
seconds to generate a schedule. Prior works [20, 26, 29, 47]
try to improve computational complexity by trading off opti-
mality using approximation schemes. These works still end
up significantly underperforming our decomposed MCF in
practice, both in terms of performance and complexity.

Another challenge lies in lowering the MCF solution to
both ML accelerators and HPC runtimes and fabrics. These
fabrics employ different topology, routing, and flow control
mechanisms as they have historically been designed with
different objectives [18]. We devise a general model of the
underlying network, distinguishing between fabrics that sup-
port additional forwarding bandwidth (i.e., forwarding band-
width at the Network Interface Card (NIC) is higher than the
injection bandwidth at the host/accelerator) and those that
do not. Additional forwarding bandwidth increases all-to-all

 
 
 
 
 
 
performance in direct-connect settings as it compensates for
the bandwidth tax [33] (since a node acts as a router and uses
a significant fraction of its total link bandwidth to forward
other node traffic). We develop an algorithmic toolchain for
producing and lowering near bandwidth-optimal all-to-all col-
lective communication schedules to arbitrary supercomputer-
scale topologies and different interconnect technologies. On
host or accelerator runtimes where data movement is “sched-
uled”, we devise a novel time-stepped version of the MCF
problem. On fabrics with hardware “routing” and additional
forwarding bandwidth, we develop scalable algorithms for
computing static routes either by directly extracting the
paths from the MCF solution or by employing path-based
MCF formulations where flow variables are defined on paths
instead of on links. We develop compilers and tools for low-
ering the schedules and the routes to the underlying runtime
and interconnect, and we demonstrate near-optimal all-to-all
performance on a range of topologies at different scales.

Finally, we establish an analytical lower bound for all-to-all
performance on any topology, use it to compare different topolo-
gies and show the superiority of generalized Kautz graphs in
terms of both performance and coverage. It is known that
topologies with higher bisection bandwidth result in higher
all-to-all throughput [13, 24]. Several works in the HPC com-
munity have investigated the all-to-all behavior of different
topologies. Earlier works proposed specialized patterns for
higher dimensional mesh, tori [51] and hypercubes [23],
while later works proposed more complex topologies that
have beneficial graph properties, e.g., high expansion coef-
ficient [54], large spectral gap [58], and low diameter [13].
Many of the proposed topologies, however, do not have suf-
ficient coverage in realizable graph sizes (𝑁 ) and degree
(𝑘). We propose the class of generalized Kautz (GenKautz)
graphs [21], which are known for their expansion properties
and can be constructed for any 𝑁 and 𝑘.

2 Background and Terminology
2.1 Direct-Connect Fabrics for ML and HPC

Our work identifies topologies and schedules helpful for
a broad range of direct-connect interconnects common to
both HPC and ML accelerator fabrics. These include, for
example, switchless physical circuits [3], patch-panel optical
circuits [52], and optical circuit switches (OCS) [24]. These
options differ in cost, scalability, and reconfigurability [56].
For example, commercially available OCSs can perform re-
configurations in ≈10ms, are more expensive than patch pan-
els, but scale to fewer ports (e.g., Polatis 3D-MEMS switch
has 384 ports at $520 per port [41]). With these reconfig-
urable fabrics, topology becomes a degree of freedom, and
ongoing work is demonstrating how to exploit this degree
of freedom for increased performance [24, 27, 55, 59, 61].
Despite supporting faster reconfigurations, OCSes still suf-
fer from relatively high reconfiguration latency, precluding

2

rewiring of the circuits during a typically-sized collective
operation. Accordingly, collectives need to operate over a
set of pre-configured circuits that remain unchanged for the
duration of the collective operation. We refer to this setting
as direct-connect, circuits (and topology) that are configured
and remain static for the duration of the collective algorithm.
Our work additionally targets different interconnect tech-
nologies, broadly ML accelerator and HPC interconnects.
These employ different topologies, routing, and flow con-
trol, as they have historically been designed with different
objectives [18, 37]. Table 1 highlights high-level differences
between the two fabrics. HPC interconnects have generally
focused on reducing latency using low-diameter topologies
with high bisection bandwidth and hardware routing with
cut-through flow control. With hardware routing, where
each node or NIC serves as a router, the total forwarding
bandwidth may exceed the host injection bandwidth to ac-
commodate for the forwarding bandwidth tax. ML accel-
erator interconnects, on the other hand, optimize for high
link bandwidth as they are mostly focused on collectives,
tend not to employ hardware routing, and use synchronized
accelerator schedules with store-and-forward flow control.

2.2 All-to-all Schedules, and Throughput

The network topology is modeled as a directed graph, rep-
resented as the tuple 𝐺 = (𝑉 , 𝐸), where 𝑉 denotes the set
of nodes (|𝑉 | = 𝑁 ) and 𝐸 denotes the set of directed edges.
The direct-connect fabric imposes a constraint that all nodes
have degree 𝑑, which is the number of links/ports on each
host or accelerator and is ideally low and independent of 𝑁 .
The link bandwidth is 𝑏, and the node bandwidth is 𝐵 = 𝑑𝑏.
Each node 𝑖 has a data buffer 𝐵𝑖 comprised of 𝑁 contiguous
and equally sized shards 𝐵𝑖,𝑗 each of size 𝑚 bytes, 0 ≤ 𝑖, 𝑗 <
𝑁 , |𝐵𝑖 | = 𝑁𝑚, |𝐵𝑖,𝑗 | = 𝑚. The all-to-all collective transposes
the buffers, i.e., each node 𝑖 sends shard 𝐵𝑖,𝑗 to node 𝑗.

Communication schedules can operate at a finer granular-
ity than a shard. We define chunk 𝐶𝑖,𝑗 to be a subset of shard
𝐵𝑖,𝑗 , both specified as index sets of elements in a shard with
𝐵𝑖,𝑗 representing the entire shard. For example, the shard can
be an interval [0, 1], and 𝐶𝑖,𝑗 be some subinterval. Chunks
do not need to be the same size. Since each chunk 𝐶𝑖,𝑗 has
a known source node 𝑖 and destination node 𝑗, we omit the
indexes and simply use 𝐶 to denote the chunk. An all-to-
all communication (comm) schedule 𝐴 for 𝐺 with 𝑡max comm
steps specifies which chunk is communicated over which link
or route in any given step. Specifically, 𝐴 is a set of tuples
Table 1: Comparison of HPC and ML accelerator fabrics.

Schedules
Topology focus
Flow Control
Injection BW
Forwarding BW

HPC
Path-based
Bisection bandwidth
Cut-through
𝐵
≥ 𝐵

ML Accelerator
Link-based
Node bandwidth
Store-and-forward
𝐵
𝐵

(𝐶, (𝑢, 𝑤), 𝑡) with 𝑢, 𝑤 ∈𝑉 and 𝑡 ∈ {1, . . . , 𝑡max}. (𝐶, (𝑢, 𝑤), 𝑡)
denotes that node 𝑢 sends chunk 𝐶 to node 𝑤 at comm step
𝑡. Chunking is performed during schedule compilation (§4).
Link-based Schedules: In fabrics without hardware routing,
chunks only flow on directly connected edges (𝑢, 𝑤) ∈ 𝐸𝐺 .
Path-based Schedules: In fabrics with hardware routing,
(𝑢, 𝑤) may not correspond to an edge in 𝐺, i.e., chunks can
flow on end-to-end paths between source and destination as
determined by the routing function.

The throughput of an all-to-all schedule for a shard size
𝑚 is (𝑁 −1)𝑚
, where 𝑇 is the time to complete the all-to-all
schedule (the time for each node to send 𝑁 − 1 shards each
of size 𝑚 bytes).

𝑇

Finally, algorithm runtime is the time taken by the algo-
rithm to compute and lower the schedule for a given network.
2.3 Related work

(cid:17)

(cid:16) 𝑁 3
𝜖 2 logO (1) 𝑁

In the theory community, optimization of the all-to-all col-
lective has been formulated as a maximum concurrent multi-
commodity flow problem (MCF) and solved in polynomial
time using LP [47]. Although the MCF has polynomial time
complexity, it can be hard to solve in practice for large prob-
lem sizes. As a result, several works have proposed fully
polynomial time approximation schemes (FPTAS) [20, 26, 47].
The best known FPTAS schemes [26] have time complexity
and get to a factor of (1 − 𝜖) of the opti-
O
mal throughput. In this paper, we improve the tractability
of LP-based solutions while not sacrificing optimality. We
decompose the original MCF problem into a master LP and
𝑁 simpler parallelizable child LPs. Since the former (which
dominates the time complexity – see Fig. 7) has O (𝑁 2) vari-
ables, one can leverage recent LP solving techniques with
time complexity O (𝑁 2.37) [15] to solve the MCF in O (𝑁 4.74)
time. In practice, our master LP has lower time complexity
owing to its special structure, and MCF is significantly better
in running time than the FPTAS schemes (for small values
of 𝜖) without sacrificing optimality even for moderate 𝑁
(Fig. 7). Moreover, the sequential FPTAS schemes are unable
to exploit the parallelism the way we do.

Early HPC works investigated efficient all-to-all collective
communication on well-known topologies, e.g., hypercubes,
meshes, and tori. Johnsson and Ho [23] proposed optimal
all-to-all collectives for single-port and 𝑛-port models of
hypercubes. Scott [45] proposed optimal all-to-all collectives
on meshes. Suh et al. [51] and Yang et al. [57] proposed all-
to-all collectives for mesh and tori that could leverage virtual
cut-through and wormhole-switched networks.

More recent works have studied all-to-all communica-
tion on topologies that have beneficial graph properties for
supporting datacenter communications. The bisection band-
width of a network (𝜒) is known to be related to all-to-all
throughput in the sense that the latter is bounded from above
by 4𝜒
𝑁 2 . Prior works have therefore used 𝜒 as a proxy for all-to-
all throughput [13, 48, 54], and as a result, expander graphs

3

Figure 1: Generating link- and path-based schedules. Top left exam-
ple shows difference between NIC-based and host-based forwarding
of flow from host H0 to H2.

got significant interest due to their low modularity and hence
high 𝜒. Xpander [54] routes all-to-all traffic along K-shortest
paths on expander graphs with multi-path TCP congestion
control [44] to yield good throughput in switch-based data-
center settings. The all-to-all problem has been formulated as
an MCF in such contexts [25, 42], and it has been shown that
multiple expanders have nearly identical performance for
all-to-all traffic. However, ours is the first study that applies
multiple forms of MCF constructs (link- and path-based) to
optimize all-to-all collective communications on a diverse
set of HPC and ML fabrics and topologies at scale.

Recently, Cai et al. [14] proposed an SMT-logic-based
approach (SCCL) for synthesizing optimal collectives in a
topology-agnostic manner for GPU fabrics. However, their
approach is computationally expensive due to the NP-hard
nature of the SMT formulation. Followup work TACCL [46]
relies on integer programming and suffers from similar com-
putational bottlenecks, as we show in §5. Recently proposed
TE-CCL [9] improves upon TACCL’s performance by com-
bining multi-commodity flow with Mixed Integer Linear
Programming (MILP) and A* search. Their models focus on
link-driven latency, which can be important at small sub-
Megabyte buffer sizes. Our formulations, on the other hand,
maximize network utilization for all-to-all under large buffer
sizes, and we observe that MCF solutions in general attempt
to take short paths through the network anyway. Our ap-
proach is significantly more scalable, generating efficient
schedules for 1K+ nodes in much less time than what TE-
CCL reports it takes to solve all-to-all on 128 node networks.
Finally, the work in [60] optimizes the all-reduce collective.
3 Multi-commodity Flow-based Algorithms

Fig. 1 shows a summary flowchart of the algorithms we em-
ploy for generating all-to-all schedules for direct-connect
fabrics. For ML-style fabrics with host/GPU-based forward-
ing, we generate weighted link-based schedules by solving
the time-stepped version of the MCF. An MCF solution de-
fines what chunks of data corresponding to a certain (𝑠, 𝑑)
pair (or commodity) should be transmitted by an interme-
diate node 𝑢 over each of its outgoing links (𝑢, 𝑣) at time

NoYesGenerated SchedulesNopMCF: path based MCF on initial paths (disjoint, bounded, …)tsMCF: link-based time-stepped MCFby LP decompositionMCF-extP: link-based MCF + widest path extraction heuristic#(s,d) paths large?Weighted path scheduleWeighted link scheduleNIC-based forwarding?N0H0H1H2N1N2NIC-based forwardingYesHost-based forwardingstep 𝑡. A naive solution involves solving a linear program
(LP) on variables defined for each commodity, link, and time
step–in the worst case, the total number of variables grows
as 𝑁 (𝑁 − 1) × 𝑂 (𝑁 ) × 𝑂 (𝑁 ) = 𝑂 (𝑁 4) where 𝑁 is the net-
work size (bounded degree networks have 𝑂 (𝑁 ) links and
the number of time steps, 𝑙𝑚𝑎𝑥 ≥ the diameter, which can
be 𝑂 (𝑁 )). We propose to decompose this LP into a master
source-only LP that first computes aggregate optimal flow
rates leaving each source 𝑠 and then uses this solution to
compute optimal flow rates for each (𝑠, 𝑑) pair. This enables
scaling to networks with thousands of nodes.

For HPC-style fabrics with NIC-based forwarding, we gen-
erate path-based schedules that constitute a set of paths P𝑠,𝑑
for each (𝑠, 𝑑) pair and weights 𝑤𝑝𝑖 associated with each path
𝑝𝑖 ∈ P𝑠,𝑑 controlling the fraction of traffic that should be sent
along 𝑝𝑖 . Optimal path-based schedules can be computed by
solving the path-based version of the MCF, which is a natural
dual of the link-based version mentioned earlier. However,
this involves defining optimization variables for every pos-
sible (𝑠, 𝑑) path, which is prohibitive for many topologies,
even if we restrict the path set to include only shortest paths.
We use good heuristics like sampling good path sets of small
cardinality (e.g., edge-disjoint paths) to mitigate this prob-
lem. We also propose another radically different approach
that instead solves the link-based MCF, and then applies an
iterative “widest path” extraction algorithm to greedily ex-
tract high-flow (𝑠, 𝑑) paths from the optimal per-link flows.
Although potentially suboptimal, this approach is tractable
and has good performance on the topologies we study.
3.1 Problem formulation
3.1.1 Link variable based MCF formulation. Given a
network 𝐺 = (𝑉 , 𝐸, 𝑐𝑎𝑝 : 𝐸 → R+), where 𝑐𝑎𝑝 denotes link
capacities, the problem of maximizing all-to-all throughput
can be modeled as a maximum concurrent multi-commodity
flow (MCF) problem with 𝑁 (𝑁 − 1) commodities of equal
demand. This problem can be formulated using Linear Pro-
gramming [20, 26, 29, 47]. We define variables 𝑓(𝑠,𝑑 ),(𝑢,𝑣) to
denote the amount of flow of commodity 𝑠 → 𝑑 that should
traverse link (𝑢, 𝑣) and concurrent demand variable 𝐹 (i.e.,
the common rate at which all commodities will flow concur-
rently), and solve the LP below.

Link-based max-concurrent MCF formulation:
maximize 𝐹

subject to:

∑︁

𝑠,𝑑

𝑓(𝑠,𝑑 ),(𝑢,𝑣) ≤ 𝑐𝑎𝑝 (𝑢,𝑣), ∀𝑢, 𝑣

𝑓(𝑠,𝑑 ),(𝑢,𝑣) ≤

∑︁

𝑤

𝑓(𝑠,𝑑 ),(𝑤,𝑢 ), ∀𝑠, 𝑑, 𝑢 : 𝑠 ≠ 𝑢, 𝑑 ≠ 𝑢

∑︁

𝑣
∑︁

𝑓(𝑠,𝑑 ),(𝑤,𝑑 ) ≥ 𝐹, ∀𝑠, 𝑑

𝑤
𝑓(𝑠,𝑑 ),(𝑢,𝑣) ≥ 0, ∀𝑠, 𝑑, 𝑢, 𝑣

(1)

(2)

(3)

(4)

(5)

The flow conservation constraint is modeled by inequal-
ity (3). This improves the speed of the LP solver; at the opti-
mal solution, the inequality is enforced with no slack. Also,
enforcing the demand constraint (4) only at the sink node 𝑑 is

4

sufficient since the combined flow conservation and demand
constraints at the sink enforce the same at the source. If how-
ever, a flow 𝑓(𝑠,𝑑 ) with optimal 𝐹 returned by the solver has
extra flow near 𝑠 (due to inequality (3)), a post-processing
step from 𝑑 to 𝑠 is executed to ensure exact flow conserva-
tion. An optimal flow generally follows links along multiple
paths over the network. This LP is solvable in polynomial
time, albeit in high-order polynomial time. To improve solver
efficiency, we use a compact formulation of the LP in which
all the flow conservation and demand constraints are ex-
pressed by a single matrix-vector constraint that relates the
product of the node-to-link incidence matrix and link-flow
vector to the per-commodity demand matrix scaled by 𝐹 .
This eliminates the “pre-solve” canonicalization step.

A key disadvantage of the per-commodity based LP ap-
proach is that the number of link-flow variables for a 𝑘-
regular graph is 𝑘𝑁 2(𝑁 − 1), which gets intractable even at
modest scales (hundreds of nodes).
3.1.2 Decomposing the MCF LP for scalability. Since
the MCF LP approaches discussed above are computation-
ally challenging, we decompose the problem of computing
the optimal flow for 𝑁 (𝑁 − 1) commodities by considering
𝑁 groups of source-rooted flows (each delivered to 𝑁 − 1
destinations). Specifically, we follow the steps below.
(1) Compute source-based grouped commodity flows: Solve a
master LP, defined in (6)-(9), for computing the optimal con-
current rates for 𝑁 source-rooted grouped multicommodity
flows. The source-based flow conservation (8) reflects the
fact that the total amount of flow entering 𝑢 has to be greater
than the sum of the amount of flow leaving 𝑢 and the amount
sunk at 𝑢 (which must equal the concurrent flow value 𝐹 ).
Since we worry about only 𝑁 groups of commodities (instead
of 𝑁 (𝑁 − 1) point-to-point commodities), we only need 𝑘𝑁 2
variables, which is tractable (thousands of nodes).
(2) Compute optimal per-commodity flows: Once the per-
source optimal flow has been computed, solve 𝑁 additional
simpler Child LPs, one per source as defined in (10)-(14), to
determine the flow values per link for each (𝑠, 𝑑) commodity.
Each such LP (say for source 𝑠) will set the link capacities to
the flow values computed by the master LP, and will solve
a standard maximum concurrent multicommodity flow (on
a thusly capacity-adjusted graph) for 𝑁 − 1 commodities
{𝑠 → 𝑣 |𝑣 ∈ 𝑉 \ {𝑠}}. These LPs can be run in parallel on
multi-core processors, have 𝑘𝑁 (𝑁 − 1) flow variables to
optimize, and are generally simpler in complexity than the
original LP. Solving 𝑁 + 1 LPs with 𝑂 (𝑁 2) variables each is
much more tractable than solving a single LP with 𝑂 (𝑁 3)
variables since the computation complexity of LP is generally
much higher than linear in the number of variables.

Decomposed link-based MCF (for scalability):

tsMCF: for ML fabrics with host/GPU forwarding

Master LP to compute source-based grouped commodity flows:

maximize 𝐹

subject to:

∑︁

𝑠

𝑓 ′
𝑠,(𝑢,𝑣)

𝑓 ′
𝑠,(𝑢,𝑣)

∑︁

𝐹 +

𝑣

𝑓 ′
𝑠,(𝑢,𝑣)

≤ 𝑐𝑎𝑝 (𝑢,𝑣), ∀𝑢, 𝑣

𝑓 ′
𝑠,(𝑤,𝑢 )

, ∀𝑠, 𝑢 : 𝑠 ≠ 𝑢

∑︁

≤

𝑤
≥ 0, ∀𝑠, 𝑢, 𝑣

Child LPs to extract link flows from source-based flows:

minimize

∑︁

𝑓(𝑠,𝑑 ),(𝑢,𝑣)

𝑑,𝑢,𝑣
∑︁

subject to:

∑︁

𝑣
∑︁

𝑑
𝑓(𝑠,𝑑 ),(𝑢,𝑣)

𝑓(𝑠,𝑑 ),(𝑤,𝑑 )

𝑤
𝑓(𝑠,𝑑 ),(𝑢,𝑣)

𝑓(𝑠,𝑑 ),(𝑢,𝑣)

≤

𝑓 ′
𝑠,(𝑢,𝑣)

, ∀𝑢, 𝑣

≤

≥

𝑓(𝑠,𝑑 ),(𝑤,𝑢 ), ∀𝑑, 𝑢 : 𝑠 ≠ 𝑢, 𝑑 ≠ 𝑢

∑︁

𝑤
𝐹, ∀𝑑

≥

0, ∀𝑠, 𝑑, 𝑢, 𝑣

(6)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

The decomposed LP approach yields the optimal MCF value
𝐹 as the standard approach (in §3.1.1) although the actual
flow values 𝑓 returned may be different.
3.1.3 Time-stepped MCF (tsMCF) formulation. The
MCF formulation presented in §3.1.1 yields the optimal rates
at which each commodity should be transmitted by con-
sidering the flow of data to mimic that of infinitesimally
divisible fluids. This is inadequate for ML network fabrics
where accelerators send finite data chunks in a finite number
of fixed-length time steps. This necessitates the generation
of time-stepped schedules. To this end, we extend the no-
tion of MCF to the temporal domain by computing flows
on a time-expanded stacked graph [11] representation of
𝐺. It has 𝑙max + 1 time-indexed instances 𝑢𝑡 of each node
𝑢 ∈ 𝐺 and directed edges 𝑢𝑡 → 𝑣𝑡 +1 with 𝑐𝑎𝑝𝑎𝑐𝑖𝑡𝑦 = 1
whenever (𝑢, 𝑣) ∈ 𝐺 as well as “self"" edges 𝑢𝑡 → 𝑢𝑡 +1 with
𝑐𝑎𝑝𝑎𝑐𝑖𝑡𝑦 = ∞ denoting potential buffering at 𝑢 over time.
𝑙max is set to a value ≥ 𝑑𝑖𝑎𝑚𝑒𝑡𝑒𝑟 (𝐺). We compute flows on
this time-expanded graph essentially following the proce-
dure described in §3.1.1. The main difference is in the size of
the input graph. In this case, it has (𝑙max + 1)|𝑉 | nodes and
𝑙max (|𝑉 | + |𝐸|) links, and hence the LPs take somewhat longer
to solve. However, the time-expanded graphs are directed
acyclic graphs and are hence less complex. This tends to help
mitigate the running time issues of the LPs. Another key dif-
ference is that all nodes do not source/sink traffic; instead,
the nodes 𝑢0 source traffic for nodes 𝑣𝑙max+1 and non-zero
flow along an infinite capacity “self” edge essentially simu-
lates waiting for a time slot. The equivalent time-stepped LP
formulation is given below.

5

minimize

∑︁

𝑈𝑡

𝑡
∑︁

subject to:

𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 ≤ 𝑈𝑡 , ∀𝑢, 𝑣, 𝑡

𝑠,𝑑
𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 ′ ≤

∑︁

𝑡 ′ ≤𝑡,𝑣

∑︁

𝑡 ′′<𝑡,𝑤

𝑓(𝑠,𝑑 ),(𝑤,𝑢 ),𝑡 ′′,

∀𝑠, 𝑑, 𝑢, 𝑡 : 𝑠 ≠ 𝑢, 𝑑 ≠ 𝑢, 𝑡 > 1
𝑓(𝑠,𝑑 ),(𝑤,𝑢 ),𝑡 ′′, ∀𝑠, 𝑑

∑︁

𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 ′ =

𝑡 ′′,𝑤
∑︁

𝑓(𝑠,𝑑 ),(𝑠,𝑣),𝑡 ′ =

𝑓(𝑠,𝑑 ),(𝑤,𝑑 ),𝑡 ′′ = 1, ∀𝑠, 𝑑

∑︁

𝑡 ′,𝑣
∑︁

𝑡 ′,𝑣
0 ≤ 𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 ≤ 1, ∀𝑠, 𝑑, 𝑢, 𝑣

𝑡 ′′,𝑤

(15)

(16)

(17)

(18)

(19)

(20)

The objective (15) minimizes the utilization of bandwidth
at every time step, while the constraint (16) ensures that the
total utilization at every edge is less than the bandwidth.
The constraint (17) enforces the amount of data received by
node 𝑢 must be greater than or equal to the amount of data
sent by node 𝑢 from comm step 1 to every other comm step
(the difference is reserved for future send). Constraint (18)
enforces the total amount received by node 𝑢 is equal to the
total amount sent by node 𝑢. Constraint (19) enforces that
the total amount sent by the source and received by the desti-
nation is equal to 1. One can add a multiplier to 𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 in
the first constraint if link bandwidth is not uniform among
all links. This time-stepped LP can be decomposed into a
source-based LP + child LPs as described in §3.1.2.

3.1.4 Path-variable based MCF (pMCF) formulation.
In networks supporting multi-hop routing, we need to com-
pute the optimal rates of flows along multiple paths from
each source 𝑠 to each target node 𝑑. We first compute a set of
paths P for each commodity/(𝑠, 𝑑) pair. Next, for each path
𝑝 ∈ P and (𝑠, 𝑑) pair, define flow variable 𝑓(𝑠,𝑑 ),𝑝 ∈ R+ ∪ {0}.
As in the link-based formulation, we ensure that the link
capacity constraints are obeyed at each link. The flow con-
servation constraints are automatically obeyed at each node
since data will be flowing along simple paths (in-degree and
out-degree are 1). The LP formulation is shown in (21)-(24).
If the set P is allowed to consist of all paths of unbounded
length, then path-based MCF is a natural dual of link-based
MCF and hence provides the same optimal MCF value. How-
ever, solving such a dual problem is impractical since |P |
typically grows exponentially with 𝑁 . We make the path-
based MCF in practical scenarios tractable by curtailing the
number of paths in P to 𝑂 (𝑝𝑜𝑙𝑦 (𝑁 )). Restricting the path
lengths to below 𝑙max drastically reduces |P |. This approach
works for many networks of interest (per our empirical obser-
vation), e.g., expander graphs like Generalized Kautz graphs,
where |P | is polynomial in 𝑁 , 𝑙max. However, in several other
graphs that possess a high degree of symmetry, e.g., the torus,
the number of paths of length 𝑙max grows exponentially in
𝑁
(cid:1),
𝑙max since the diameter is
𝑁

𝑁 ; therefore |P | ≥ 1√

√
(cid:0)2
√

√

𝑁 +1

which grows super-exponentially in 𝑁 ; this makes the ap-
proach intractable for large tori. One tractable heuristic that
we have empirically observed to achieve the optimal MCF so-
lution is to choose P to be a maximal set of link-disjoint (𝑠, 𝑑)
paths, which can be found efficiently and whose cardinality
is upper bounded by 𝑘𝑁 (𝑁 − 1) for 𝑘-regular graphs.

pMCF: for fabrics with NIC forwarding

maximize 𝐹

subject to:

∑︁

∑︁

𝑠,𝑑

𝑝 ∋𝑒

𝑓(𝑠,𝑑 ),𝑝 ≤ 𝑐𝑎𝑝𝑒, ∀𝑒 ∈ 𝐸

∑︁

𝑓(𝑠,𝑑 ),𝑝 ≥ 𝐹, ∀𝑠, 𝑑

𝑝 ∋ P(𝑠,𝑑 )
𝑓(𝑠,𝑑 ),𝑝 ≥ 0, ∀𝑠, 𝑑, 𝑢, 𝑣

(21)

(22)

(23)

(24)

Handling host-to-NIC bottlenecks In scenarios where the
host-to-NIC bandwidth 𝐵ℎ𝑜𝑠𝑡 is less than the net egress/ingress
link bandwidth at the NIC, i.e., 𝐵ℎ𝑜𝑠𝑡 < 𝑑 · 𝑏, the host-to-NIC
bandwidth becomes a bottleneck. Figure 2 shows how to aug-
ment the original NIC topology to model this host-to-NIC
bottleneck. We augment the graph in a manner that forces
data to flow through the host even when the node is not
the destination. The MCF computed between the host nodes
on the augmented graph yields the optimal throughput. We
apply §3.1.3’s tsMCF formulation to generate schedules.

3.2 Applying MCF to the different fabrics
3.2.1 Source-routed fabrics. The paths along which (cer-
tain fractions of) each commodity would flow must be pro-
vided at the respective sources of the commodity. We propose
two different approaches below based on whether a topology
has low or high path diversity (see Fig. 1).
pMCF: Directly applying path-variable based MCF (low
path diversity). The path-variable based MCF formulation
described in (21)-(24) can be applied to source-routed fab-
rics for graphs in which the path diversity does not grow
exponentially in 𝑁 , as is the case with expander graphs.
However, this approach is not tractable for graphs like the
multi-dimensional torus where the number of paths (with
length ≤ 𝑙max) grows super-exponentially in 𝑁 .
MCF-extP: Applying link-based MCF and extracting paths
(high path diversity). We first solve the decomposed link-
based MCF described in §3.1.2. However, for source-routed
fabrics, we need to obtain the paths on which the differ-
ent commodities should flow. Therefore, as a final step, we
greedily extract paths from the link-based MCF solution.
Widest path extraction. Given the MCF flow values on
each link corresponding to each (𝑠, 𝑑) commodity, we con-
struct a weighted subgraph DAG 𝐺𝑠,𝑑 of the original graph
𝐺 induced by the edges with non-zero (𝑠, 𝑑) flow (weights
= MCF flows). We then iteratively extract (𝑠, 𝑑) paths from
𝐺𝑠,𝑑 by greedily solving the widest path problem, by making
minor modifications to Dijkstra’s shortest path algorithm:
1. Find (𝑠, 𝑑) path 𝑝 in 𝐺𝑠,𝑑 with maximum flow rate (𝑟 ).
2. Subtract 𝑟 from the capacities of all the links in 𝑝.
3. Repeat the two previous steps until 𝑠 no longer has a

non-zero capacity path to 𝑑.

4. Upon termination, the algorithm finds a set of (𝑠, 𝑑) paths
with decreasing flow rates, which are ready for lowering.
3.2.2 Non source-routed fabrics (tsMCF). When for-
warding and flow control are performed by the host/GPU (no
hardware routing), we use the time-stepped link-based MCF
formulation described in §3.1.3 to obtain chunk schedules
that exactly specify what data needs to be sent (or received)
by each GPU at every time step.

Figure 2: Topology augmentation to model host-to-NIC bottleneck

4 Schedule Compilation

We implement compilers and interpreters to lower the sched-
ules and paths, and execute them on CPU and GPU runtimes.
Link-based Schedules: The link-based MCF algorithm pro-
duces schedules that are chunked and lowered to both Mi-
crosoft’s MSCCL [34] and Intel’s oneCCL [22]. MSCCL is
an open-source collective communication library that ex-
tends NCCL [38] and RCCL [7] with an interpreter pro-
viding the ability to program custom collectives on GPUs.
Collective schedules are defined in XML as instructions
(send/receive/reduce/copy) within GPU thread blocks that
the interpreter executes. We additionally lower the same
schedules to oneCCL+libfabric [22], an open-source collec-
tive communications library by Intel that supports CPUs.

We extended oneCCL with an interpreter, in a similar way
that MSCCL extended NCCL, that executes the XMLs. The
oneCCL XMLs similarly specify instructions (send, receive,
reduce, copy, sync) and add scratch buffers for chunk for-
warding. The primary challenge in creating both MSCCL
and oneCCL schedules was chunking. The MCF solution
produces the fractional rates 𝑓(𝑠,𝑑 ),(𝑢,𝑣),𝑡 for each commodity
(𝑠, 𝑑) on each link (𝑢, 𝑣) at each time step 𝑡. The lowering
algorithm determines the smallest chunk size to support the
lowest such rate, which guides how granularly a shard is
chunked and how chunks are combined and forwarded by
intermediate ranks. At each time step, a rank then sends the
total outgoing flow (the chunks received in the previous time
step), receives the total incoming flow (chunks to receive
in the current time step), and performs synchronization. In
both MSCCL and oneCCL, we have the ability to increase the
number of channels by duplicating the schedule and running

6

0123Original topology01234567891011Optimal MCF is  computed between hosts {8,9,10,11}Host→NICNIC→HostHostAugmentedgraph representationbw= Bbw= BNIC-NIC bw= bNIC-NIC bw= bNo forwarding bandwidth available(Force data to pass through the host)NIC(out)NIC(in)a parallel copy on different threads. All sends and receives
are asynchronous with no data dependencies.
Path-based Schedules. Recall that the weighted path-based
MCF algorithm produces a set of weighted paths for each
commodity (shard) 𝐵𝑖,𝑗 (source 𝑖, dest 𝑗). Weighted multi-path
routing and flow control should ideally be performed by the
hardware, to which we would lower the MCF schedules (the
per-commodity routes and weights). In our testbeds, we use
the Cerio (Rockport) NC1225 network card [3] (described in
§5.1). While the current version of the Cerio card natively
supports multi-path routing on user-specified routes, it does
not expose the capability to program the weights per route.
This means we cannot directly use the native multi-path
capability, which we disable. We instead approximate the
weighted paths MCF by: (1) lowering the routes for each
commodity 𝐵𝑖,𝑗 to the underlying fabric, (2) dividing each
shard/commodity into a set of equal-sized chunks, and (3)
steering chunks onto routes as defined in our schedule.

Specifically, the Cerio card exposes a utility for lowering
our computed source routes to the hardware, where a route
specifies the egress ports on the traversed links from source
to destination as well as the layer identifier for the route; the
layer identifier is used to assign routes to different virtual
channels in order to eliminate deadlocks [50]. The card also
allows us to steer flows to routes at the application layer.
This is possible in ROCE v2 by setting the UDP source port
when creating the RDMA Queue Pair (QP), such that the tu-
ple (src port, src IP, dst IP, QP number) hashes to the desired
route id. We implemented the scheduling and flow steering
functionality in Open MPI+UCX [39]. The chunked schedule
specification is lowered to an XML that is executed by our
interpreter. The latter is implemented in OMPI as part of the
tuned collectives component within the Modular Compo-
nent Architecture (MCA). The schedule defines the chunks
and path each should take, and the extended OMPI+UCX
runtime creates the right number of QPs and performs the
steering. A shard is divided into a set of equal-sized chunks
as follows: we compute the highest common factor across
all path weights in the MCF solution and use that as the
base chunk size (call it 𝑐). Each shard of size 𝑚 bytes is then
divided into ⌈𝑚/𝑐⌉ chunks, and the right number of chunks
is assigned to each path based on the path weight. This ap-
proach ensures all chunks (flows) fairly share the bandwidth,
approximating the ideal MCF in practice on the Cerio fabric.
We discuss the scalability limitations of this approach in §5.5.

5 Evaluation

We evaluate schedule performance and algorithm runtime
at increasing scales on different hardware and on different
direct-connect optical topologies, some of which are well-
studied (complete bipartite, hypercube, twisted hypercube,
Torus) while others are non-standard such as punctured tori

7

with non-homogenous degree per node. We also present per-
formance results at a large scale in simulation. We summarize
our performance results next.

Performance of link-based schedules: Our lowered
tsMCF schedules deliver near-optimal throughput perfor-
mance on different topologies and scales, outperforming
state-of-the-art baselines by up to 1.6× (§5.2 Fig. 3).

Performance of path-based schedules: Our lowered
MCF-extP and pMCF schedules deliver near-optimal through-
put performance on different standard and non-standard
topologies and scales, outperforming state-of-the-art scal-
able baselines by up to 30% (§5.2, Fig. 4 and Fig. 5), and the
all-to-all speedups directly translate to speedups in the 3D
FFT workload (§5.2, Fig. 6). MCF outperforms other scalable
baselines at large scale in simulation (§5.3, Fig. 8, Fig 9).

Algorithm runtime. Through large-scale simulations
going up to 1000 nodes, our MCF decomposition approach
yields orders of magnitude improvement in algorithm run-
time over the original MCF and all other baseline schedule
generation approaches (§5.3, Fig 7).

Topology. We identify GenKautz as a family of expander
topologies that have near-optimal all-to-all performance
while also having complete coverage in 𝑁 and 𝑑, outperform-
ing other well-known expander topologies (§5.4, Fig. 10).

5.1 Direct-connect testbed and cluster

We evaluate the all-to-all schedules on two testbeds: an inter-
nal 8 server (1 NVIDIA A100 GPU [1] per server) testbed that
supports topology reconfiguration, and an external 27 server
(1 CPU per server) cluster at the Texas Advanced Computing
Center (TACC) [2, 5] where topology is fixed to the Torus.
Cerio Card. In both testbeds, each server is equipped with
a Cerio NC1225 network card [3]. The card supports source
routing with multi-path and cut-through flow control, and
stores up to 8 routes per destination. It offers up to 300 Gbps
of total forwarding bandwidth using 12x 25 Gbps links (𝑏 =
25 Gbps or 3.125 GB/s), and supports 100 Gbps of injection
bandwidth from the host or GPU using x16 PCIe gen3. We
can accordingly evaluate both link and path-based schedules
on both testbeds.
Internal GPU Testbed. The network cards are directly con-
nected via a Telescent optical patch panel [52]. Our testbed
can realize different topologies by reconfiguring the patch
panel. We limit our evaluation to bidirectional topologies,
specifically hypercube and twisted hypercube both with
degree 3 (i.e., 𝐵=75 Gbps), and complete bipartite with de-
gree 4 (𝐵=100 Gbps). While unidirectional topologies (e.g.,
GenKautz) can be realized by configuring the patch panel
in simplex mode, we cannot accurately evaluate their per-
formance since the requisite overlay routing for the reverse
path traffic (acks) is currently only supported using routing
rules performed by the kernel leading to unpredictable RTTs.
TACC HPC Cluster. A cluster of CPU servers at TACC are
connected in a fixed torus topology using the Cerio fabric [2,

Figure 3: Throughput of link-based all-to-all schedules on different topologies and runtimes. Appended /G indicates the schedule is lowered to
GPUs and the MSCCL [34] runtime, whereas /C means the schedule is lowered to CPUs and the oneCCL [22] runtime. Averaged over 20 iters.

Figure 4: Throughput of route-based all-to-all schedules on different topologies and runtimes. Appended /G indicates the schedule is lowered to
GPUs and the NCCL [34] runtime, whereas /C means the schedule is lowered to CPUs and the Open MPI [39] runtime. Averaged over 20 iters.

5]. We use a 3x3x3 torus (27 nodes, degree=6) from the cluster
to run our experiments. The host injection bandwidth of
100 Gbps is less than 𝐵=150 Gbps for degree 6; hence, we
evaluate the benefits of path based schedules to exploit the
extra forwarding bandwidth for all-to-all.

5.2 Evaluation of optimized collectives
Time-stepped tsMCF schedules: Fig. 3 shows our low-
ered link-based tsMCF schedules deliver near-optimal per-
formance at large message sizes on different topologies and
scales. State-of-the-art scheduling algorithms such as SCCL [14]
do not scale, failing to terminate even at a modest 27-node
scale (Fig. 3, right). TACCL [46] schedules, on the other hand,
underperform on the Hypercube by 22% and on the 3D Torus
by up to 1.6× at large buffer sizes (Fig. 3, right). Since our
GPU testbed is constrained to an 8-node scale, we resort to
the CPU cluster to evaluate at larger 27-node scale. In Fig. 3,
we append the algorithm name with /C to indicate that we
lowered to oneCCL and ran on CPUs, whereas /G refers to
lowering to MSCCL and running on the A100 GPUs. Recall

the link-based schedule experiments in Fig. 3 do not use
the routing capability from the underlying fabric; all trans-
fers are on point-to-point links controlled by the scheduling
thread(s) on the host GPU or CPU.

On the 3D Torus (Fig. 3, right), tsMCF uses the bottle-
neck model (§3.2.2 Fig. 2) to produce the schedule since
the host injection bandwidth (100 Gbps) is lower than the
NIC bandwidth (150 Gbps for degree 6). The flow value
produced by MCF on this bottlenecked 3D Torus topology
is 𝑓 = 2
27 , which dictates the theoretical upper bound of
(𝑁 − 1) 𝑓 𝑏 = (26)( 2
27 )(3.125) = 6.01 GB/s. On the other
hand, the flow value in the non-bottlenecked setting, as we
discuss shortly in Fig. 4 (right), is 1
9 which is 57% higher. The
theoretical upper bound on throughput is (𝑁 − 1) 𝑓 𝑏, where
𝑓 is the optimal flow value given by MCF (each commodity
gets a max flow value of 𝑓 assuming link capacity is 1, so
when link capacity is 𝑏, the max achievable flow out of a
node sourcing 𝑁 − 1 flows is (𝑁 − 1) 𝑓 𝑏).

In summary, our experiments show that the optimized
tsMCF schedules are ideal for both GPU and HPC fabrics where

8

21321822322802468Throughput (GB/s)Complete Bipartite (N=8)213218223228Buffer Size (B)0123453D Hypercube (N=8)Upper BoundtsMCF/GSCCL/GTACCL/G2132182232280123453D Twisted Hypercube (N=8)21622022422801234563D Torus (N=27)Upper BoundtsMCF/CTACCL/C21722222723202468Throughput (GB/s)Complete Bipartite (N=8)217222227232Buffer Size (B)0123453D Hypercube (N=8)Upper BoundMCF-extP/CEwSP/CILP-disjoint/CNCCL/G2172222272320123453D Twisted Hypercube (N=8)218223228233024683D Torus (N=27)Upper BoundMCF-extP/CILP-disjoint/CDOR/COMPI-alg0/CSSSP/CEwSP/Cadditional forwarding bandwidth is not available while being
generalizable to a wide range of topologies.
Path-based schedules utilizing forwarding bandwidth
We implement two link-load-minimizing single-path base-
lines. The first is based on Integer Linear Programming (ILP)
which is tractable only at small scales. It selects a subset of
a candidate set of (𝑠, 𝑡) paths such that the maximum load
on any link is minimized. Low maximum load leads to high
all-to-all throughput. We experiment with both link-disjoint
(ILP-disjoint) and shortest paths (ILP-shortest) in the candi-
date set. The second baseline is Single Source Shortest Path
(SSSP) [19] heuristic that iteratively computes shortest paths
through a graph whose link weights reflect the additional
congestion caused due to each iteration.

Fig. 4 shows our lowered MCF-extP schedules deliver near-
optimal bandwidth performance in practice as we see at
small scale (N=8) for the complete bipartite topology (left),
and both the hypercube and twisted hypercube topologies
(middle). On the complete bipartite, we see MCF-extP out-
performs ILP-disjoint, which matches the theoretical results
since the latter, which is constrained to a single path per
commodity, is not bandwidth optimal on this topology. On
the 27 node 3D Torus (right) on the supercomputer, our MCF-
extP slightly underperforms due to practical limitations with
injection rate control in the current fabric (more in §5.5).
Both dimension ordered routing (DOR) [17] and ILP-disjoint
are theoretically bandwidth optimal on the 3D Torus and are
strong baselines. However, DOR does not work on non-Tori
topologies, and ILP-disjoint does not produce optimal solu-
tions in general and becomes intractable for larger topologies.
SSSP is both scalable and general, but it produces sub-optimal
solutions and is more than 50% worse than MCF-extP on the
3D Torus at large buffers.

MCF-extP also far outperforms NCCL and OMPI’s na-
tive all-to-all algorithms up to 2.3× on Bipartite, and 55%
on 3D Torus. NCCL/OMPI native schedules perform N-1
point-to-point send/recv operations (flows) per rank. These
flows utilize the deadlock-free routes underneath which are
computed by the Cerio fabric [50]. We also implement and
evaluate the Equal weight Shortest Path (EwSP) baseline that
distributes each commodity equally on all the shortest paths
between source and destination. While EwSP performs very
well on all the four topologies in Fig. 4, this is not the case
in general, as we show later in §5.3, Fig. 8.

Comparing path-based schedules of Fig. 4 to link-based
schedules of Fig. 3 on the same topologies, we see that the
bandwidth performance of MCF-extP is comparable to that
of tsMCF at large buffer sizes for the Bipartite (degree=4), Hy-
perCube and Twisted Hypercube (degree=3). This is expected
on these low-degree topologies since there is no additional
forwarding bandwidth that path-based MCF can exploit, and
both approaches have the same theoretical upper bound. On
the other hand, MCF-extP significantly outperforms tsMCF
on the larger 27 node 3D Torus (by about 3.4× at 1MB, and

9

15% at larger buffers) since it is able to exploit the additional
forwarding bandwidth in this case (degree=6, 𝐵 =150 Gbps≥
100 Gbps injection bandwidth)–here MCF-extP is unable to
reach its theoretical expected performance due to practical
limitations on the current fabric (more in §5.5). In general, we
also see MCF-extP has a significant performance advantage
at smaller buffers due to the superior latency performance of
cut-through routing as compared to having to incur a global
synchronization per timestep with tsMCF.
Performance on non-standard topologies We assess the
topology-agnostic quality of MCF-extP on heterogeneous
degree topologies produced by sampling sub-graphs from
the 3D Torus. Specifically, we sample 10 different instances
of the 3D Torus to create edge-punctured (3 random edges re-
moved) and node-punctured (3 random nodes removed) Tori.
Baselines such as DOR are not defined for such punctured
Tori. Fig. 5 shows the throughput of MCF-extP compared to
ILP-disjoint and SSSP. The results are consistent with those
of Fig. 4, where MCF-extP significantly outperforms SSSP
but underperforms ILP-disjoint due to practical limitations
with injection rate control we discuss shortly in §5.5. The
results also match the empirical results, where we observe
similar maximum link load for both ILP-disjoint and MCF
(which is ∼ 30% lower than SSSP). Puncturing the Torus is a
way to emulate failures of links and/or nodes, which would
be expected in a cloud setting, and to show the superior per-
formance of MCF in such scenarios. When combined with
the superior algorithm runtime (Fig. 7), this shows that our
approach is able to more quickly react to failures in networks
of hundreds of nodes without compromising on performance.
Workload speedups We implement distributed 3D Fast
Fourier Transform (FFT), and run it on the 27 node 3D Torus,
and on the edge-punctured 3D Torus on up to 12963 grid
size, corresponding to all-to-all buffer size up to 1.29 GB.
Fig. 6 shows the speedups in the 3D FFT on the 3D Torus
(top, corresponding to all-to-all speedups from Fig. 4, right)
and the punctured 3D Torus (bottom, corresponding to all-
to-all speedups from Fig. 5). We observe up to 20% (14.9%)
total speedup in the FFT time using our MCF schedules com-
pared to SSSP schedules on the 3D Torus (edge-punctured 3D
Torus). The speedups are a direct result of the faster all-to-all
MCF schedules, consistent with Fig. 4 and Fig. 5. We use the
latest version of the FFTW library [6] with multi-threading
and with OMPI running our all-to-all schedules. We use slab
decomposition, where each process (1 multi-threaded pro-
cess per node) performs three steps: first computes 2D FFTs
on its slabs and packs the data, then runs all-to-all with all
other processes, and finally unpacks and computes 1D FFTs
to complete the 3D FFT. These three steps involved in the
FFT computation are shown with bands in the bars of Fig. 6
with the first step corresponding to the bottom band.

Figure 5: Performance on punctured 3D Torus, removing 3 links (left) or 3 edges
(right) at random. Envelope min/max/average (line) over 10 instances (20 iters per)

Figure 6: 3D FFT Times (𝑁 =27 processes, 32 threads each)

5.3 Large scale numerical simulations
Benefits of MCF decomposition: Fig. 7 shows that our
MCF decomposition approach (MCF-decomp) yields orders
of magnitude improvement in algorithm runtime over the
original MCF (MCF-original), and the other highly unscal-
able topology-agnostic schedule generation approaches such
as SCCL [14], TACCL [46], Karakostas’ Fully Polynomial
Time Approximation Scheme (FPTAS) [26], and ILP-disjoint.
We show the computation time required for MCF-original
(link-based) on 𝑁 3 variables and MCF-decomp on 𝑁 2 vari-
ables for the Generalized Kautz graph [21] (also see §5.4)
for various choices of 𝑁 . We observe that even at the scales
of 𝑁 = 50, 100, MCF-decomp is two orders of magnitude
faster, while MCF-original fails to produce a solution for
𝑁 > 100 nodes in a reasonable time. In contrast, SCCL [14]
is unable to generate all-to-all schedules for 𝑁 = 16 even in
104 seconds. TACCL [46], a heuristic designed to be more
scalable than SCCL, takes over 30 minutes to generate all-
to-all schedules for even 32-node networks. Furthermore,
for slightly larger networks, it is unable to produce even
an approximate solution in 30 minutes. Even ILP-disjoint is
only able to generate optimal schedules up to 𝑁 = 44. While

we evaluate on the GenKautz topology in Fig. 7, the scaling
trends apply to other topologies (expanders, tori) as well.

The algorithm runtime of MCF-decomp follows a polyno-
mial trend, and it is dominated by the time taken to solve
the “Master LP"", which is a source-based MCF leading to
a solution in 40 minutes for 𝑁 = 1000 provided all “Child
LPs” and subsequent “Widest path"" extraction functions are
run in parallel on 𝑁 cores. The exact degree of the poly-
nomial governing the speedup factor over original MCF is
determined by that of the polynomial that determines the
time complexity of solving such network flow LP problems.
For example, if a state-of-the-art LP solver takes O (𝑁 2.37)
time to solve 𝑁 -variable problems, the speedup factor can
be estimated to be O (𝑁 3×2.37/𝑁 2×2.37) = O (𝑁 2.37).

Fig. 7 also shows the runtime performance of a state-of-
the-art FPTAS by Karakostas [26] at 𝜖 = 0.05. While it shows
a polynomial scaling trend unlike the other baseline schemes
mentioned earlier, it significantly underperforms the MCF
(decomposed) algorithm in running time even after sacri-
ficing optimality, thus making it impractical for networks
larger than a couple of hundred nodes. The FPTAS, being
an inherently sequential algorithm, cannot exploit the high
degree of parallelism that is exploited by decomposed MCF.

Figure 7: Scaling on GenKautz (degree=4); MCF-decomp is master LP
+ 𝑁 parallel child LPs + widest path extraction heuristic

Figure 8: Performance on degree 4 Generalized Kautz graphs nor-
malized by Link-based MCF

10

217221225229233Buffer Size (B)23456Throughput (GB/s)Edge-punctured 3D TorusMCF-extP/CILP-disjoint/CSSSP/C217221225229233Buffer Size (B)23456Throughput (GB/s)Node-punctured 3D Torus0.00.20.4Time (s)3D Torus (N=27)EwSP/COMPI/CDOR/CSSSP/CMCF-extP/CILP_disjoint/C7291296Grid Width (complex doubles)0.00.20.4Time (s)Edge-punctured 3D Torus05001000Number of nodes (N)10−210−1100101102103104Algorithm runtime (sec)Scalability of decomposed MCFMCF-originalMCF-decompMaster LPChild LPWidest pathSCCL5% FPTASILP-disjointTACCL255075100125150175200Number of nodes (N)1.01.21.41.61.82.02.2All-to-all time (normalized)Performance of MCF vs. baselinesLink-based MCFpMCF-disjointpMCF-shortestEwSPSSSPILP-disjointILP-shortestPerformance of schedules that utilize NIC forwarding
bandwidth: Fig. 8 (and Fig. 9) shows the all-to-all time (the
time to concurrently transmit the workload assuming unit
commodity demand and link capacities; it is equal to 1/𝑀𝐶𝐹
and the maximum link load) of various path-based schemes
normalized by optimal link-based MCF. Comparing single
path schemes, mainly ILP and SSSP, although SSSP is fast, it is
up to 1.6× worse than the theoretically optimal MCF solution.
On the other hand, the ILP schemes, although performant,
do not scale well (Fig. 7).

Although multipath schemes exploit the path diversity of
the network well, naive multipath approaches such as Equal
Weight Shortest Path that distribute the workload evenly
along all available (𝑠, 𝑡) shortest paths do not perform well.
Its performance is similar to that of SSSP. However, weighted
multipath schemes such as pMCF (Path-based MCF (disjoint))
and MCF-extP (Link-based MCF with path extraction) can
achieve optimal or near-optimal performance. pMCF is opti-
mal in theory if the number of (𝑠, 𝑡) paths in the initial set is
not restricted. However, this set can be extremely large, thus
necessitating the development of decomposed MCF-extP,
whose scalability has been illustrated in Fig. 7. However,
in practice, if the (𝑠, 𝑡) path set is restricted to link-disjoint
paths, pMCF can almost match the optimal performance
of pure link-based MCF. Interestingly, pMCF run with all
shortest (𝑠, 𝑡) paths exhibits suboptimal performance, espe-
cially for expander graphs (Fig. 8) since the latter do not
have too many shortest paths. While pMCF (with shortest
paths) performs well on topologies such as tori, the starting
path set is often exponentially large in size, thus making the
scheme impractical. In contrast, link-disjoint (𝑠, 𝑡) paths can
be computed in polynomial time for arbitrary topologies.
Since there are at most 𝑑 disjoint paths for any (𝑠, 𝑡) pair, the
number of LP variables is O (𝑁 2), making it comparable to
decomposed Link-based MCF in terms of time complexity.
Fig. 9 illustrates the generality and good performance of
MCF schemes (when compared to baselines like SSSP) since
they perform optimally/near-optimally on heterogeneous
degree-irregular subgraphs, e.g., formed by disabling random
links. At the 𝑁 = 81 scale considered (𝑑 = 8), interestingly,
ILP-disjoint shows performance close to link-based MCF’s if
we allow it a tolerance factor (𝜖 = 0.1); but it does not scale
to large 𝑁 owing to it being NP-hard.

5.4 Near throughput-optimal all-to-all topologies
We ask which topologies with 𝑁 nodes and degree 𝑑 yield
the best all-to-all performance? This is an important design
question for supercomputing clusters and is becoming more
important with increased deployments of reconfigurable fab-
rics [24, 31, 55]. We derive an upper bound for all-to-all
throughput (equivalently, lower bound the all-to-all collec-
tive time) for arbitrary 𝑑-regular graphs with 𝑁 nodes, and
then highlight an expander graph that achieves performance
close to this bound. Since the bound is reasonably tight, it

allows us to compare the performance of various topologies
with respect to the theoretical optimal.

Theorem 1 (Lower bound on all-to-all time.). The time taken
to accomplish all-to-all communication in a 𝑑-regular graph
𝐺 on 𝑁 nodes scales as Ω(𝑁 log𝑑 𝑁 ).

Proof sketch. First, consider a single source node 𝑟 and an ar-
borescence (outgoing rooted directed tree) of 𝐺 (denoted by
𝑇𝑑,𝑁 ), which has 𝑁 nodes and maximum out-degree 𝑑. It has
𝑑𝑘 number of nodes at all levels 𝑘 except when 𝑘 is equal to its
height. If 𝑟 needs to send 𝑁 − 1 flows of value 𝑓 to each of the
other 𝑁 − 1 nodes along 𝑇𝑑,𝑁 , the minimum capacity needed
is 𝑓 × (cid:205)𝑢 ∈𝑉𝑇𝑑,𝑁
𝐷 (𝑟, 𝑢), where 𝐷 (𝑠, 𝑡) is the distance (hop
count) between 𝑠 and 𝑡 along 𝑇𝑑,𝑁 . Thus, the minimum capac-
ity needed for sending commodities from all nodes (along 𝑁
respective rooted arborescences) is 𝑁 × 𝑓 × (cid:205)𝑢 ∈𝑉𝑇𝑑,𝑁
𝐷 (𝑟, 𝑢).
Assuming that a 𝑑-regular di-graph has 𝑑 outgoing unit ca-
pacity links per node, the total capacity available in the
network is 𝑑 × 𝑁 . It follows that 𝑓 × (cid:205)𝑢 ∈𝑉𝑇𝑑,𝑁
𝐷 (𝑟, 𝑢) ≤ 𝑑.
The all-to-all workload completion time/latency is given by:

1/𝑓 ≥

∑︁

𝑢 ∈𝑉𝑇𝑑,𝑁

𝐷 (𝑟, 𝑢)/𝑑.

(25)

𝑖 × 𝑑𝑖 =

Also, in a 𝑑-regular graph where each arborescence is a full
𝑑𝑖 = 𝑑𝑘 −1
𝑘 layer tree, 𝑁 = (cid:205)𝑘 −1
𝑑 −1 and (cid:205)𝑢 ∈𝑉𝑇𝑑,𝑁
𝐷 (𝑟, 𝑢) =
𝑖=0
𝑑𝑘+1 (𝑘 −1) −𝑑𝑘𝑘+𝑑
(cid:205)𝑘 −1
= Θ(𝑘 𝑑𝑘 −1). The RHS of Eq.
𝑖=0
(𝑑 −1) 2
(25) then becomes Θ(𝑘𝑑𝑘 −2) = Θ(𝑁 log𝑑 𝑁 ). This establishes
the scaling law for the lower bound on all-to-all time in any
□
𝑑-regular 𝑁 -node topology.

Graphs achieving all-to-all time bound Generalized
Kautz graphs [21] constitute a family of expander graphs
that comes close to achieving the bound in Theorem 1. A
benefit of these graphs is that we can generate an instance
for any value of 𝑁 and 𝑑. Such coverage in 𝑁 and 𝑑 is not
possible for most graph families popular in the HPC commu-
nity, such as mesh, tori, SlimFly [13], SpectralFly [58], etc.
Fig. 10(left) shows the simulated all-to-all performance of
the GenKautz graph for 𝑑 = 4 with respect to the derived
lower bound. We observe that these graphs get very close
to the all-to-all lower bound for any 𝑑-regular graph (with
the ratio between the two approaching 1 for large 𝑁 ) thus
making them optimal expanders for all-to-all collectives.

Fig. 10 (right) compares the performance of GenKautz
with non-expanders (e.g., 2D-tori) and other well-known
expander graphs, e.g., Xpander [54] and random regular
graphs /Jellyfish [48]. The last two are also known to exhibit
good coverage in 𝑁 and 𝑑. While the expanders significantly
outperform non-expanders (for 𝑑 = 4, GenKautz has about
2.4× lower latency than 2D-tori for large 𝑁 ), GenKautz has
the best performance among the expanders (e.g., it is 10%
better than Xpander and random regular graphs). Similar
trends are observed for higher degrees.

11

Figure 9: Performance on 𝑁 =81 Gen Kautz w/
links disabled normalized by Link-based MCF

Figure 10: GenKautz topology performance relative to lower bound (left), and expanders and
2D-Tori (right, normalized by lower bound)

5.5 Conclusion and Discussion

We develop efficient schedules and topologies for all-to-
all collective communications geared for large-scale direct-
connect fabrics. Our results demonstrate that the time-stepped
MCF approach and compiler are highly scalable and achieve
near-optimal bandwidth performance in practice. This is
valuable for many applications that rely on all-to-all when
run on GPU (or CPU) clusters, such as deep learning training
and inference. For path-based MCF-extP and pMCF, our re-
sults similarly demonstrate excellent performance in practice
at the smaller 8 and 27-node scales. Path-based MCF is able
to exploit additional forwarding bandwidth to speed up the
collective. Our experiments with MCF, however, uncovered
additional theoretical and practical challenges, which we are
addressing as part of our ongoing (and future) work.
Deadlock-free routing: When lowering path-based MCF
routes to fabrics with wormhole (flit-based) routing such as
Cerio, routes must be deadlock-free [17]. We implemented
several variants of common algorithms for breaking dead-
locks, such as DF-SSSP [19] and LASH [49], which assign
virtual channels to routes after the routes are computed. We
found that a variant of LASH [49], which we call LASH-
sequential performed best in terms of requiring the least
number of layers; specifically, it required no more than 4
layers across all the algorithms (MCF, ILP, EwSP, etc.) and
topologies we evaluated. Minimizing the number of VCs to
make a given set of routes deadlock free is NP-hard [19].
An open question is how to generate all-to-all schedules that
optimize throughput while ensuring deadlock freedom.
Injection rate control: On the practical front, a limitation
of path-based MCF solutions when lowered to existing fab-
rics is support for injection rate control. As described in §4, we
implemented an approximation of injection rate control by
splitting shards into granular equal-sized chunks/flows and
steering them on routes. While this approach worked very
well at an 8-node scale as a proof of concept, and achieved
reasonable performance at a larger 27-node scale, it is in gen-
eral not scalable. Granular chunking significantly increases
the total number of active Queue Pairs (QPs) in the network.
And our all-to-all micro-benchmarking experiments clearly

showed a reduction in the achievable per-flow bandwidth as
the number of QPs increased on the Cerio fabric, likely due
to increased contention. We are pursuing two approaches
to address this challenge: (1) introduce time steps into the
routed MCF schedules and partition the flows across multi-
ple timesteps, and (2) work with the Cerio vendor on options
to expose injection rate control in the hardware.
Clustered/Hybrid Configurations: We are extending the
general MCF formulation and the implementation to handle
hybrid clustered settings with possibly severe imbalance be-
tween internal link bandwidth within a server, and external
bandwidth (e.g., several Tbps internal bandwidth vs several
Gbps external bandwidth in GPU servers from NVIDIA and
AMD), and with possibly internal switching.
Future work: Our solution computes a static schedule that
assumes dedicated underlying link bandwidth for the du-
ration of the all-to-all collective. This is a reasonable as-
sumption in several direct-connect settings where a cluster
manager allocates circuits to jobs on a non-interfering basis.
Handling more dynamic environments with multiple jobs
contending for bandwidth is left for future work.
6 Acknowledgement

We thank the Rockport Networks team, Matthew Williams,
Doug Taylor, Nick Tkotz, and Shaun Hennesey for their help
and insights with the Rockport fabric experiments, and with
making their slice of the TACC supercomputer available to
us. We also thank Amit Ruhela for his help and insights.
This research was developed with funding from the Defense
Advanced Research Projects Agency (DARPA) under con-
tract number HR001120C0089. The views, opinions and/or
findings expressed are those of the authors and should not
be interpreted as representing the official views or policies
of the Department of Defense or the U.S. Government.

References

[1] 2021. NVIDIA A100 Tensor Core GPU. https://www.nvidia.com/en-

us/data-center/a100/.

[2] 2021. TACC establishes new Center of Excellence with Rockport Net-
works. https://rockportnetworks.com/tacc-establishes-new-center-
of-excellence-with-rockport-networks/.

[3] 2023. Cerio. https://www.cerio.io/

12

0102030405060Number of disabled links1.01.11.21.31.41.51.61.71.8All-to-all time (normalized)Generalized Kautz (81 nodes, 648 edges)Link-based MCFpMCF-disjointSSSPILP-disjoint (10% tolerance)02004006008001000Number of nodes (N)02505007501000All-to-all timeGenKautz (d=4) vs lower boundGenKautzLower Bound0100200300400Number of nodes (N)1.01.52.02.53.03.5All-to-all time (normalized)GenKautz vs. expanders, Tori (d=4)GenKautz2D-ToriXpandersRandom Regular[4] 2023. Parallelization of Particle-mesh Ewald (PME) in GROMACS
for Molecular Dynamics.
Available at https://manual.gromacs.
org/documentation/current/user-guide/mdrun-performance.html, ac-
cessed on 7.15.2023.

[5] 2023. Texas Advanced Computing Center. https://www.tacc.utexas.

edu/.

[6] 2024. Fastest Fourier Transform in the West. https://fftw.org/.
[7] AMD. 2023. ROCm Communication Collectives Library.

Avail-
able at https://github.com/ROCmSoftwarePlatform/rccl, accessed on
7.15.2023.

[8] MOSEK ApS. 2023. MOSEK Solver version 10.1. https://www.mosek.

com/

[9] Behnaz Arzani, Siva Kesava Reddy Kakarla, Miguel Castro, Srikanth
Kandula, Saeed Maleki, and Luke Marshall. 2023. Rethinking Machine
Learning Collective Communication as a Multi-Commodity Flow Prob-
lem. arXiv:2305.13479 [cs.NI]

[10] Alan Ayala, Stanimire Tomov, Xi Luo, Hejer Shaeik, Azzam Haidar,
George Bosilca, and Jack Dongarra. 2019. Impacts of multi-gpu mpi
collective communications on large fft computation. In 2019 IEEE/ACM
Workshop on Exascale MPI (ExaMPI). IEEE, 12–18.

983–991.

[11] Prithwish Basu, Feng Yu, Amotz Bar-Noy, and Dror Rawitz. [n. d.]. To
Sample or To Smash? Estimating reachability in large time-varying
graphs.
https://doi.org/10.1137/1.9781611973440.112
arXiv:https://epubs.siam.org/doi/pdf/10.1137/1.9781611973440.112
[12] Herman JC Berendsen, David van der Spoel, and Rudi van Drunen.
1995. GROMACS: A message-passing parallel molecular dynamics
implementation. Computer physics communications 91, 1-3 (1995),
43–56.

[13] Maciej Besta and Torsten Hoefler. 2014. Slim fly: A cost effective low-
diameter network topology. In SC’14: proceedings of the international
conference for high performance computing, networking, storage and
analysis. IEEE, 348–359.

[14] Zixian Cai, Zhengyang Liu, Saeed Maleki, Madanlal Musuvathi, Todd
Mytkowicz, Jacob Nelson, and Olli Saarikivi. 2021. Synthesizing op-
timal collective algorithms. In Proceedings of the 26th ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming. 62–75.
[15] Michael B. Cohen, Yin Tat Lee, and Zhao Song. 2019. Solving Linear
Programs in the Current Matrix Multiplication Time. In Proceedings
of the 51st Annual ACM SIGACT Symposium on Theory of Computing
(Phoenix, AZ, USA) (STOC 2019). Association for Computing Machin-
ery, New York, NY, USA, 938?942. https://doi.org/10.1145/3313276.
3316303

[16] Kenneth Czechowski, Casey Battaglino, Chris McClanahan, Kartik
Iyer, P-K Yeung, and Richard Vuduc. 2012. On the communication
complexity of 3D FFTs and its implications for exascale. In Proceedings
of the 26th ACM international conference on Supercomputing. 205–214.
[17] William J. Dally and Charles L. Seitz. 1987. Deadlock-free message
routing in multiprocessor interconnection networks. IEEE Transactions
on computers 100, 5 (1987), 547–553.

[18] William James Dally and Brian Patrick Towles. 2004. Principles and

practices of interconnection networks. Elsevier.

[19] Jens Domke, Torsten Hoefler, and Wolfgang E. Nagel. 2011. Deadlock-
Free Oblivious Routing for Arbitrary Topologies. In 2011 IEEE In-
ternational Parallel & Distributed Processing Symposium. 616–627.
https://doi.org/10.1109/IPDPS.2011.65

[20] Lisa K Fleischer. 2000. Approximating fractional multicommodity flow
independent of the number of commodities. SIAM Journal on Discrete
Mathematics 13, 4 (2000), 505–520.

[21] Imase and Itoh. 1983. A Design for Directed Graphs with Minimum
Diameter. IEEE Trans. Comput. C-32, 8 (1983), 782–784. https://doi.
org/10.1109/TC.1983.1676323

[22] Intel. 2023. oneAPI Collective Communications Library (oneCCL).
Available at https://github.com/oneapi-src/oneCCL, accessed on
07.15.2023.

13

[23] S Lennart Johnsson and C-T Ho. 1989. Optimum broadcasting and
IEEE Transactions on

personalized communication in hypercubes.
computers 38, 9 (1989), 1249–1268.

[24] Norm Jouppi, George Kurian, Sheng Li, Peter Ma, Rahul Nagarajan,
Lifeng Nai, Nishant Patil, Suvinay Subramanian, Andy Swing, Brian
Towles, et al. 2023. Tpu v4: An optically reconfigurable supercom-
puter for machine learning with hardware support for embeddings. In
Proceedings of the 50th Annual International Symposium on Computer
Architecture. 1–14.

[25] Sangeetha Abdu Jyothi, Ankit Singla, P Brighten Godfrey, and Alexan-
dra Kolla. 2016. Measuring and understanding throughput of network
topologies. In SC’16: Proceedings of the International Conference for
High Performance Computing, Networking, Storage and Analysis. IEEE,
761–772.

[26] George Karakostas. 2008. Faster approximation schemes for fractional
multicommodity flow problems. ACM Transactions on Algorithms
(TALG) 4, 1 (2008), 1–17.

[27] Mehrdad Khani, Manya Ghobadi, Mohammad Alizadeh, Ziyi Zhu,
Madeleine Glick, Keren Bergman, Amin Vahdat, Benjamin Klenk, and
Eiman Ebrahimi. 2021. SiP-ML: High-Bandwidth Optical Network
Interconnects for Machine Learning Training. In Proceedings of the 2021
ACM SIGCOMM 2021 Conference (Virtual Event, USA) (SIGCOMM ’21).
Association for Computing Machinery, New York, NY, USA, 657–675.
https://doi.org/10.1145/3452296.3472900

[28] John Kim, Wiliam J Dally, Steve Scott, and Dennis Abts. 2008.
ACM

Technology-driven, highly-scalable dragonfly topology.
SIGARCH Computer Architecture News 36, 3 (2008), 77–88.

[29] Tom Leighton and Satish Rao. 1989. An approximate max-flow min-cut
theorem for uniform multicommodity flow problems with applications
to approximation algorithms. Technical Report. Massachusetts Inst Of
Tech Cambridge Microsystems Research Center.

[30] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen,
Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and
Zhifeng Chen. 2020. Gshard: Scaling giant models with conditional
computation and automatic sharding. arXiv preprint arXiv:2006.16668
(2020).

[31] Hong Liu, Ryohei Urata, Kevin Yasumura, Xiang Zhou, Roy Bannon,
Jill Berger, Pedram Dashti, Norm Jouppi, Cedric Lam, Sheng Li, Erji
Mao, Daniel Nelson, George Papen, Mukarram Tariq, and Amin Vah-
dat. 2023. Lightwave Fabrics: At-Scale Optical Circuit Switching for
Datacenter and Machine Learning Systems. In Proceedings of the 2021
ACM SIGCOMM 2021 Conference (SIGCOMM ’23). Association for Com-
puting Machinery, New York, NY, USA.

[32] Yunfeng Lu, Huaxi Gu, Xiaoshan Yu, and Peng Li. 2021. X-NEST: A
Scalable, Flexible, and High-Performance Network Architecture for
Distributed Machine Learning. Journal of Lightwave Technology 39, 13
(2021), 4247–4254. https://doi.org/10.1109/JLT.2021.3073277

[33] William M Mellette, Rajdeep Das, Yibo Guo, Rob McGuinness, Alex C
Snoeren, and George Porter. 2020. Expanding across time to deliver
bandwidth efficiency and low latency. In 17th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 20). 1–18.
[34] Microsoft. 2022. Microsoft Collective Communication Library. Avail-

able at https://github.com/microsoft/msccl.

[35] Parviz Moin and Krishnan Mahesh. 1998. Direct numerical simulation:
a tool in turbulence research. Annual review of fluid mechanics 30, 1
(1998), 539–578.

[36] Dheevatsa Mudigere, Yuchen Hao, Jianyu Huang, Zhihao Jia, Andrew
Tulloch, Srinivas Sridharan, Xing Liu, Mustafa Ozdal, Jade Nie, Jongsoo
Park, et al. 2022. Software-hardware co-design for fast and scalable
training of deep learning recommendation models. In Proceedings of
the 49th Annual International Symposium on Computer Architecture.
993–1011.

[37] Maxim Naumov, John Kim, Dheevatsa Mudigere, Srinivas Sridharan,
Xiaodong Wang, Whitney Zhao, Serhat Yilmaz, Changkyu Kim, Hector

[54] Asaf Valadarsky, Gal Shahaf, Michael Dinitz, and Michael Schapira.
2016. Xpander: Towards optimal-performance datacenters. In Proceed-
ings of the 12th International on Conference on emerging Networking
EXperiments and Technologies. 205–219.

[55] Weiyang Wang, Moein Khazraee, Zhizhen Zhong, Manya Ghobadi,
Zhihao Jia, Dheevatsa Mudigere, Ying Zhang, and Anthony Kewitsch.
2023. {TopoOpt}: Co-optimizing Network Topology and Paralleliza-
tion Strategy for Distributed Training Jobs. In 20th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 23). 739–767.
[56] Weiyang Wang, Moein Khazraee, Zhizhen Zhong, Manya Ghobadi,
Zhihao Jia, Dheevatsa Mudigere, Ying Zhang, and Anthony Kewitsch.
2023. {TopoOpt}: Co-optimizing Network Topology and Paralleliza-
tion Strategy for Distributed Training Jobs. In 20th USENIX Symposium
on Networked Systems Design and Implementation (NSDI 23). 739–767.
[57] Yuanyuan Yang and Jianchao Wang. 1999. Efficient all-to-all broadcast
in all-port mesh and torus networks. In Proceedings Fifth International
Symposium on High-Performance Computer Architecture. IEEE, 290–
299.

[58] Stephen Young, Sinan Aksoy, Jesun Firoz, Roberto Gioiosa, Tobias
Hagge, Mark Kempton, Juan Escobedo, and Mark Raugas. 2022. Spec-
tralfly: Ramanujan graphs as flexible and efficient interconnection
networks. In 2022 IEEE International Parallel and Distributed Processing
Symposium (IPDPS). IEEE, 1040–1050.

[59] Liangyu Zhao, Siddharth Pal, Tapan Chugh, Weiyang Wang, Prithwish
Basu, Joud Khoury, and Arvind Krishnamurthy. 2022. Optimal Direct-
Connect Topologies for Collective Communications. arXiv preprint
arXiv:2202.03356 (2022).

[60] Liangyu Zhao, Siddharth Pal, Tapan Chugh, Weiyang Wang, Jason
Fantl, Prithwish Basu, Joud Khoury, and Arvind Krishnamurthy. 2022.
Efficient Direct-Connect Topologies for Collective Communications.
arXiv preprint arXiv:2202.03356 (2022).

[61] Ziyi Zhu, Min Yee Teh, Zhenguo Wu, Madeleine Strom Glick, Shijia
Yan, Maarten Hattink, and Keren Bergman. 2022. Distributed deep
learning training using silicon photonic switched architectures. APL
Photonics 7, 3 (2022), 030901. https://doi.org/10.1063/5.0070711

Yuen, Mustafa Ozdal, et al. 2020. Deep learning training in facebook
data centers: Design of scale-up and scale-out systems. arXiv preprint
arXiv:2003.09518 (2020).

[38] NVIDIA. 2023. NVIDIA Collective Communication Library (NCCL).

Available at https://github.com/NVIDIA/nccl, accessed on 7.15.2023.
[39] Open MPI. [n. d.]. Open Source High Performance Computing. https:

//www.open-mpi.org/.

[40] Dmitry Pekurovsky. 2012. P3DFFT: A Framework for Parallel Compu-
tations of Fourier Transforms in Three Dimensions. SIAM Journal on
Scientific Computing 34, 4 (2012), C192–C209. https://doi.org/10.1137/
11082748X arXiv:https://doi.org/10.1137/11082748X
Avail-
Polatis Optical Circuit Switch.
able at https://www.polatis.com/series-7000-384x384-port-software-
controlled-optical-circuitswitch-sdn-enabled.asp.

[41] Polatis 2023.

[42] Leon Poutievski, Omid Mashayekhi, Joon Ong, Arjun Singh, Mukarram
Tariq, Rui Wang, Jianan Zhang, Virginia Beauregard, Patrick Conner,
Steve Gribble, et al. 2022.
Jupiter evolving: transforming google’s
datacenter network via optical circuit switches and software-defined
networking. In Proceedings of the ACM SIGCOMM 2022 Conference.
66–85.

[43] Sarunya Pumma and Abhinav Vishnu. 2021. Semantic-Aware Lossless
Data Compression for Deep Learning Recommendation Model (DLRM).
In 2021 IEEE/ACM Workshop on Machine Learning in High Performance
Computing Environments (MLHPC). IEEE, 1–8.

[44] Costin Raiciu, Sebastien Barre, Christopher Pluntke, Adam Green-
halgh, Damon Wischik, and Mark Handley. 2011. Improving Datacen-
ter Performance and Robustness with Multipath TCP. In Proceedings
of the ACM SIGCOMM 2011 Conference (Toronto, Ontario, Canada)
(SIGCOMM ’11). Association for Computing Machinery, New York, NY,
USA, 266?277. https://doi.org/10.1145/2018436.2018467

[45] David S Scott. 1991. Efficient all-to-all communication patterns in
hypercube and mesh topologies. In The Sixth Distributed Memory
Computing Conference, 1991. Proceedings. IEEE Computer Society, 398–
399.

[46] Aashaka Shah, Vijay Chidambaram, Meghan Cowan, Saeed Maleki,
Madan Musuvathi, Todd Mytkowicz, Jacob Nelson, Olli Saarikivi, and
Rachee Singh. 2023. TACCL: Guiding Collective Algorithm Synthe-
sis using Communication Sketches. In 20th USENIX Symposium on
Networked Systems Design and Implementation (NSDI 23). USENIX As-
sociation, Boston, MA, 593–612. https://www.usenix.org/conference/
nsdi23/presentation/shah

[47] Farhad Shahrokhi and David W Matula. 1990. The maximum concur-
rent flow problem. Journal of the ACM (JACM) 37, 2 (1990), 318–334.
[48] Ankit Singla, Chi-Yao Hong, Lucian Popa, and P Brighten Godfrey.
2012. Jellyfish: Networking data centers randomly. In Presented as part
of the 9th {USENIX} Symposium on Networked Systems Design and
Implementation ({NSDI} 12). 225–238.

[49] Tor Skeie, Olav Lysne, and Ingebjørg Theiss. 2002. Layered Shortest
Path (LASH) Routing in Irregular System Area Networks.. In ipdps,
Vol. 2. 194.

[50] Evandro DE SOUZA. 2022. Deadlock-free multipath routing for di-
rect interconnect networks. Available at https://patents.google.com/
patent/WO2022269357A1/en.

[51] Young-Joo Suh and S Valamanchili. 1998. All to-all communication
with minimum start-up costs in 2d/3d tori and meshes. IEEE Transac-
tions on Parallel and Distributed Systems 9, 5 (1998), 442–458.

[52] Telescent. 2021. G4 Network Topology Manager.

https://www.

telescent.com/products

[53] Thao-Nguyen TRUONG and Ryousei TAKANO. 2021. Hybrid Elec-
trical/Optical Switch Architectures for Training Distributed Deep
Learning in Large-Scale. IEICE Transactions on Information and Sys-
tems E104.D, 8 (2021), 1332–1339. https://doi.org/10.1587/transinf.
2020EDP7201

14

"
On partial endomorphisms of a star graph,"  In this paper we consider the monoids of all partial endomorphisms, of all
partial weak endomorphisms, of all injective partial endomorphisms, of all
partial strong endomorphisms and of all partial strong weak endomorphisms of a
star graph with a finite number of vertices. Our main objective is to determine
their ranks. We also describe their Green's relations, calculate their
cardinalities and study their regularity.
","4
2
0
2

n
a
J

2
2

]

A
R
.
h
t
a
m

[

1
v
1
4
7
1
1
.
1
0
4
2
:
v
i
X
r
a

On partial endomorphisms of a star graph

Ilinka Dimitrova∗, V´ıtor H. Fernandes∗,† and J¨org Koppitz

January 23, 2024

Abstract

In this paper we consider the monoids of all partial endomorphisms, of all partial weak endomorphisms,
of all injective partial endomorphisms, of all partial strong endomorphisms and of all partial strong weak
endomorphisms of a star graph with a ﬁnite number of vertices. Our main objective is to determine their
ranks. We also describe their Green’s relations, calculate their cardinalities and study their regularity.

2020 Mathematics subject classiﬁcation: 20M20, 20M10, 05C12, 05C25.
Keywords: transformations, partial endomorphisms, star graphs, rank.

Introduction

Let Ω be a ﬁnite set. We denote by PT (Ω) the monoid (under composition) of all partial transformations on Ω,
by I(Ω) the symmetric inverse monoid on Ω, i.e. the inverse submonoid of PT (Ω) of all partial permutations
on Ω, and by S(Ω) the symmetric group on Ω, i.e. the subgroup of PT (Ω) of all permutations on Ω.

Recall that the rank of a (ﬁnite) monoid M is the minimum size of a generating set of M . The ranks of the
monoids S(Ω), I(Ω) and PT (Ω) are well-known since a long time ago. They are 2, 3 and 4, respectively, for a
ﬁnite set Ω with at least 3 elements. See the survey [6] for more details on these results and similar ones for
other classes of transformation monoids, in particular, for monoids of monotone and oriented transformations.

Let G = (V, E) be a simple graph (i.e. undirected, without loops or multiple edges). We say that α ∈ PT (V )

is:

– a partial endomorphism of G if {u, v} ∈ E implies {uα, vα} ∈ E, for all u, v ∈ Dom(α);

– a partial weak endomorphism of G if {u, v} ∈ E and uα 6= vα imply {uα, vα} ∈ E, for all u, v ∈ Dom(α);

– a partial strong endomorphism of G if {u, v} ∈ E if and only if {uα, vα} ∈ E, for all u, v ∈ Dom(α);

– a partial strong weak endomorphism of G if {u, v} ∈ E and uα 6= vα if and only if {uα, vα} ∈ E, for all

u, v ∈ Dom(α);

– a partial automorphism of G if α is an injective mapping (i.e. a partial permutation) and α and α−1 are
both partial endomorphisms. Clearly, α ∈ I(V ) is a partial automorphism of G if and only if α is a partial
strong endomorphism of G.

Denote by:

∗This work was supported by the project BG05M2OP001-2.016-0018 “MODERN-A: Modernization in partnership through

digitalization of the Academic ecosystem”.
funded by national

†This work is

the scope of

under
(https://doi.org/10.54499/UIDP/00297/2020) (Center for Mathematics and Applications).

I.P.,
the projects UIDB/00297/2020 (https://doi.org/10.54499/UIDB/00297/2020) and UIDP/00297/2020

through the FCT - Funda¸c˜ao para a Ciˆencia e a Tecnologia,

funds

1

 
 
 
 
 
 
– PEnd(G) the set of all partial endomorphisms of G;

– IEnd(G) the set of all injective partial endomorphisms of G;

– PwEnd(G) the set of all partial weak endomorphisms of G;

– PsEnd(G) the set of all partial strong endomorphisms of G;

– PswEnd(G) the set of all partial strong weak endomorphisms of G;

– PAut(G) the set of all partial automorphisms of G.

It is clear that PEnd(G), IEnd(G), PwEnd(G), PsEnd(G), PswEnd(G) and PAut(G) are submonoids of

PT (V ). Moreover, we have the following Hasse diagram for the set inclusion relation:

•

PwEnd(G)

PswEnd(G)

•

•

PEnd(G)

PsEnd(G)

•

•

IEnd(G)

PAut(G)

•

(these inclusions may not be strict). Notice that PAut(G) is also an inverse submonoid of I(V ).

Monoids of endomorphisms of graphs have many relevant applications, among which are those related to
automata theory (see [12]). Many authors have paid attention to endomorphism monoids of graphs and a large
number of interesting results concerning graphs and algebraic properties of their endomorphism monoids have
been obtained (see, for example, [1, 5, 9, 10, 13, 14, 15, 16, 17]). In recent years, the authors together with
T. Quinteiro, also have studied such kinds of monoids, in particular by considering ﬁnite undirected paths and
cycles (see [2, 3, 4]).

Now, for any non negative integer n, let Ωn = {1, 2, . . . , n} and Ω0

Ω0 = ∅ and Ω0

0 = {0}. For an integer n > 1, consider the star graph

n = {0, 1, . . . , n} = {0} ∪ Ωn. Notice that,

with n vertices.

Sn = (Ω0

n−1, {{0, i} | 1 6 i 6 n − 1})

n−1

•

n−2

•

1
•

•0

•
5

•

2

•

3

•

4

These very elementary graphs, which are a particular kind of trees and also of complete bipartite graphs,
play a signiﬁcant role in Graph Theory. For example, through the notions of star chromatic number or star
arboricity. We may also ﬁnd important applications of star graphs in Computer Science. For instance, in
Distributed Computing the star network is one of the most common computer network topologies.

Recently, Fernandes and Paulista [7] considered the monoid DPS n of all partial isometries of the star graph
Sn. They determined the rank and size of DPS n as well as described its Green’s relations and exhibited a
presentation.

This paper is devoted to studying the monoids of all partial endomorphisms, of all partial weak endomor-
phisms, of all injective partial endomorphisms, of all partial strong endomorphisms and of all partial strong
weak endomorphisms of a star graph Sn. The cardinalities of these monoids are presented in Section 1 and we
describe their Green’s relations and study the regularity in Section 2. Our main objective is to determine their
ranks, what we accomplish in Section 3.

2

For general background on Semigroup Theory and standard notations, we would like to refer the reader to
Howie’s book [11]. Regarding Algebraic Graph Theory, we refer to Knauer’s book [14]. We would also like to
point out that we made use of computational tools, namely GAP [8].

1 Cardinalities

We start this section by noticing that

PwEnd(S1) = PEnd(S1) = IEnd(S1) = PAut(S1) = PsEnd(S1) = PswEnd(S1) = {∅, ( 0

0 )} = PT (Ω0
0),

PEnd(S2) = IEnd(S2) = PAut(S2) = PsEnd(S2) = I(Ω0

1) = {∅, ( 0

0 ) , ( 0

1 ) , ( 1

0 ) , ( 1

1 ) , ( 0 1

0 1 ) , ( 0 1

1 0 )}

and

PwEnd(S2) = PswEnd(S2) = PT (Ω0

1) = I(Ω0

1) ∪ {( 0 1

0 0 ) , ( 0 1

1 1 )},

where ∅ denotes the empty transformation. On the other hand, for n > 3, as will be evident below, the situation
for the monoids PwEnd(Sn), PEnd(Sn), IEnd(Sn), PAut(Sn), PsEnd(Sn) and PswEnd(Sn) is very diﬀerent. In
fact, all these monoids (including I(Ω0

n−1)) are pairwise distinct.

n−1) and PT (Ω0

We have the following description of the elements of PwEnd(Sn), which is a routine matter to prove.

Proposition 1.1. For an integer n > 1, let α ∈ PT (Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ PwEnd(Sn) if and only if one of the

1. 0 6∈ Dom(α);

2. 0 ∈ Dom(α) and 0α = 0;

3. 0 ∈ Dom(α), 0α 6= 0 and Im(α) ⊆ {0, 0α}.

In view of Proposition 1.1, it is easy to deduce the cardinality of PwEnd(Sn):

Corollary 1.2. For n > 1, |PwEnd(Sn)| = 2(n + 1)n−1 + (n − 1)3n−1.

Proof. Clearly, we have (n + 1)n−1, (n + 1)n−1 and (n − 1)3n−1 elements of PwEnd(Sn) satisfying Conditions
1, 2 and 3, respectively, from which the result follows immediately.

A description of their group of units also follows immediately.

Corollary 1.3. For n > 3,

{α ∈ S(Ω0

n−1) | 0α = 0} ≃ S(Ωn−1)

is the group of units of PwEnd(Sn). Consequently, it is also the group of units of PEnd(Sn), PsEnd(Sn),
PswEnd(Sn), IEnd(Sn) and PAut(Sn).

Observe that the group of units of PwEnd(Sn) is S({0}), for n = 1, and S({0, 1}), for n = 2.
Regarding the elements of PEnd(Sn), it is easy to show the following description:

Proposition 1.4. For an integer n > 1, let α ∈ PT (Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ PEnd(Sn) if and only if one of the

1. 0 6∈ Dom(α);

2. 0 ∈ Dom(α), 0α = 0 and Ωn−1α ⊆ Ωn−1;

3. 0 ∈ Dom(α), 0α 6= 0 and Ωn−1α ⊆ {0}.

3

Since we have (n + 1)n−1, nn−1 and (n − 1)2n−1 elements of PEnd(Sn) satisfying Conditions 1, 2 and 3,

respectively, of Proposition 1.4, a formula for the cardinality of PEnd(Sn) follows immediately.
Corollary 1.5. For n > 1, |PEnd(Sn)| = (n + 1)n−1 + nn−1 + (n − 1)2n−1.

Next, we characterize the strong elements of PwEnd(Sn) and PEnd(Sn). We start with the last ones.
It is clear that all elements of PEnd(Sn) satisfying Conditions 2 and 3 of Proposition 1.4 are strong endo-
morphisms. On the other hand, it is easy to check that, if α ∈ PEnd(Sn) is such that 0 6∈ Dom(α), then α is a
strong endomorphism of Sn if and only if Im(α) = {0} or Im(α) ⊆ Ωn−1. Thus, we have:

Proposition 1.6. For an integer n > 1, let α ∈ PT (Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ PsEnd(Sn) if and only if one of the

1. 0 6∈ Dom(α) and either Im(α) = {0} or Im(α) ⊆ Ωn−1;

2. 0 ∈ Dom(α), 0α = 0 and Ωn−1α ⊆ Ωn−1;

3. 0 ∈ Dom(α), 0α 6= 0 and Ωn−1α ⊆ {0}.
As for PEnd(Sn), we have nn−1 and (n − 1)2n−1 elements of PsEnd(Sn) satisfying Conditions 2 and 3,
respectively, of Proposition 1.6. On the other hand, satisfying Condition 1, we clearly have nn−1 + 2n−1 − 1
elements of PsEnd(Sn). Hence, we obtain:
Corollary 1.7. For n > 1, |PsEnd(Sn)| = 2nn−1 + n2n−1 − 1.

By Proposition 1.4, a weak endomorphism α of Sn such that 0 6∈ Dom(α) is also an endomorphism of Sn.
Hence, as mentioned above, if α ∈ PwEnd(Sn) is such that 0 6∈ Dom(α), then α is a strong week endomorphism
of Sn if and only if Im(α) = {0} or Im(α) ⊆ Ωn−1. On the other hand, if α ∈ PwEnd(Sn) is such that
0 ∈ Dom(α) and 0α = 0, then it is easy to show that α is a strong week endomorphism of Sn if and only
if Im(α) = {0} or Ωn−1α ⊆ Ωn−1. Finally, if α ∈ PwEnd(Sn) satisﬁes Condition 3 of Proposition 1.1, then,
clearly, α is a strong week endomorphism of Sn if and only if Im(α) = {0α} or Ωn−1α = {0}. Therefore, we
may characterize the elements of PswEnd(Sn) as follows.

Proposition 1.8. For an integer n > 1, let α ∈ PT (Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ PswEnd(Sn) if and only if one of the

1. 0 6∈ Dom(α) and either Im(α) = {0} or Im(α) ⊆ Ωn−1;

2. 0 ∈ Dom(α), 0α = 0 and either Im(α) = {0} or Ωn−1α ⊆ Ωn−1;

3. 0 ∈ Dom(α), 0α 6= 0 and either Im(α) = {0α} or Ωn−1α = {0}.
As for PsEnd(Sn), we have nn−1 + 2n−1 − 1 elements of PswEnd(Sn) satisfying Condition 1 of Proposition
1.8. Noticing that ( 0
0 ) is the only element of PswEnd(Sn) such that 0 ∈ Dom(α), 0α = 0, Im(α) = {0} and
Ωn−1α ⊆ Ωn−1, we have nn−1 + 2n−1 − 1 elements of PswEnd(Sn) satisfying Condition 2 of Proposition 1.8.
Finally, regarding Condition 3, we have (n−1)(2n−1 +2n−1 −1) = (n−1)(2n −1) elements of PswEnd(Sn) under
this case (observe that ( 0
0α ) is the only element α of PswEnd(Sn) such that 0 ∈ Dom(α), 0α 6= 0, Im(α) = {0α}
and Ωn−1α = {0}). All together, we get:
Corollary 1.9. For n > 1, |PswEnd(Sn)| = 2nn−1 + n2n − n − 1.

Now, from Proposition 1.6, we have immediately:

Proposition 1.10. For an integer n > 1, let α ∈ I(Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ PAut(Sn) if and only if one of the

1. 0 6∈ Dom(α) and either Im(α) = {0} or Im(α) ⊆ Ωn−1;

4

2. 0 ∈ Dom(α) and 0α = 0;

3. 0 ∈ Dom(α), 0α 6= 0 and Ωn−1α ⊆ {0}.

On the other hand, as an immediate corollary of Proposition 1.4, we have:

Proposition 1.11. For an integer n > 1, let α ∈ I(Ω0
following (mutually disjoint) conditions holds:

n−1). Then, α ∈ IEnd(Sn) if and only if one of the

1. 0 6∈ Dom(α);

2. 0 ∈ Dom(α) and 0α = 0;

3. 0 ∈ Dom(α), 0α 6= 0 and Ωn−1α ⊆ {0}.

Let ζ : PT (Ω0

n−1) −→ PT (Ω0

and ζα|Ωn−1 = α|Ωn−1 , for any α ∈ PT (Ω0
mapping. However, ζ|PT (Ωn−1) and ζ|I(Ωn−1) are injective homomorphisms and so

n−1), α 7−→ ζα, be the mapping deﬁned by Dom(ζα) = Dom(α) ∪ {0}, 0ζα = 0
n−1). Notice that ζ is neither a homomorphism nor an injective

PT (Ωn−1) ≃ PT (Ωn−1)ζ = {α ∈ PT (Ω0

n−1) | 0 ∈ Dom(α), 0α = 0 and Ωn−1α ⊆ Ωn−1}

and

I(Ωn−1) ≃ I(Ωn−1)ζ = {α ∈ I(Ω0

n−1) | 0 ∈ Dom(α), 0α = 0}

Let us consider J2,0 = {
(cid:0)

n−1) | 1 6 i 6 n − 1}
n−1) | 0 6∈ Dom(α), 0 ∈ Im(α) and | Im(α)| > 2}. Then, it is not diﬃcult to conclude that

n−1) | 1 6 i, j 6 n − 1}, J1,0 = {( 0

and R0 = {α ∈ I(Ω0

0 ) ∈ I(Ω0

∈ I(Ω0

i ) , ( i

(cid:1)

0 i
j 0

and

PAut(Sn) = I(Ωn−1) ∪ I(Ωn−1)ζ ∪ J2,0 ∪ J1,0

IEnd(Sn) = PAut(Sn) ∪ R0.

We can then recognize that PAut(Sn) is the monoid DPS n studied in [7]. Observe that, as the above unions
k!, as
k!.

are all pairwise disjoint, we immediately have |PAut(Sn)| = 2|I(Ωn−1)| + n2 − 1 = 1 + n2 + 2
already observed in [7, Theorem 2.3]. On the other hand, it is easy to conclude that |R0| =
So, we have:

n−1
k
n−1
(cid:0)
k

n−1
(cid:1)
k−1
(cid:1)(cid:0)

n−1
P
k=2

n−1
k=1

(cid:1)

(cid:0)

2

P

Corollary 1.12. For n > 1, |IEnd(Sn)| = 3 + 3n2 − 4n +

n−1
k=2

n
k

+

n−1
k

P

(cid:0)(cid:0)

(cid:1)

(cid:0)

(cid:1)(cid:1) (cid:0)

n−1
k

k!.
(cid:1)

2 Regularity and Green’s relations

Regularity

We begin this section by presenting a characterization of the regular elements of the monoids PsEnd(Sn),
PswEnd(Sn), IEnd(Sn), PEnd(Sn) and PwEnd(Sn). First, we prove two lemmas.

Lemma 2.1. If α ∈ PwEnd(Sn) is a regular element of PwEnd(Sn), then 0 ∈ Dom(α) or Im(α) = {0} or
0 6∈ Im(α).

Proof. Let us suppose, by contradiction, that 0 6∈ Dom(α), Im(α) 6= {0} and 0 ∈ Im(α). Let β ∈ PwEnd(Sn)
be such that α = αβα. Hence, Im(α) ⊆ Dom(β) and Im(αβ) ⊆ Dom(α). Since 0 ∈ Im(α) and 0 6∈ Dom(α),
then 0 ∈ Dom(β) and 0β 6= 0. Hence, by Proposition 1.1, we get Im(β) ⊆ {0, 0β}. Take i ∈ Dom(α) such that
iα 6= 0. Then, iα ∈ Dom(β) and so iαβ = 0 or iαβ = 0β. Since Im(αβ) ⊆ Dom(α) and 0 6∈ Dom(α), we must
have iαβ = 0β. Now, take i0 ∈ Dom(α) such that i0α = 0. Then, 0 = i0α = i0αβα = 0βα = iαβα = iα 6= 0,
which is a contradiction, as required.

5

Lemma 2.2. If α ∈ PwEnd(Sn) be such that 0 ∈ Dom(α) or Im(α) = {0} or 0 6∈ Im(α). Then, there exists
β ∈ PAut(Sn) such that α = αβα.

0 i1 ··· ik
0 j1 ··· jk

Proof. We will proceed by considering each of the cases for α.
case 0 ∈ Dom(α): in this case, α satisﬁes Condition 2 or Condition 3 of Proposition 1.1.

We begin by supposing that α satisﬁes Condition 2. So, we also have 0α = 0. Suppose that α =

(cid:16)

(cid:16)

(cid:17)
for some 1 6 i1 < · · · < ik 6 n − 1, 0 6 j1, . . . , jk 6 n − 1 and k > 0. Let {0, iℓ1 , . . . , iℓt} be a set of
representatives of Ker(α) (0 6 t 6 k) and take β =
. Then, clearly, β ∈ I(Ωn−1)ζ ⊆ PAut(Sn) and
α = αβα.

0 jℓ1 ··· jℓt
0 iℓ1 ··· iℓt (cid:17)
Next, suppose that α satisﬁes Condition 3. Then, 0α 6= 0 and Im(α) ⊆ {0, 0α}. If Im(α) = {0α}, then being
0 ), we have β ∈ PAut(Sn) and α = αβα. On the other hand, if Im(α) = {0, 0α}, then being β = ( 0 0α
i 0 )

β = ( 0α
for some i ∈ 0α−1, we have β ∈ PAut(Sn) and α = αβα.
case Im(α) = {0}: in this case, α satisﬁes Condition 1 or Condition 2 of Proposition 1.1. If α satisﬁes Condition
2, then 0 ∈ Dom(α) and so, by the ﬁrst case, there exists β ∈ PAut(Sn) such that α = αβα. On the other hand,
if α satisﬁes Condition 1, i.e. 0 6∈ Dom(α), then Dom(α) ∩ Ωn−1 6= ∅ and, being β = ( 0
i ) for some i ∈ Dom(α),
we have β ∈ PAut(Sn) and α = αβα.
case 0 6∈ Im(α): in this case, α satisﬁes Condition 1 or Condition 3 of Proposition 1.1. If α satisﬁes Condition
3, then 0 ∈ Dom(α) and so, by the ﬁrst case, there exists β ∈ PAut(Sn) such that α = αβα. On the other
hand, if α satisﬁes Condition 1, i.e. 0 6∈ Dom(α), then α ∈ I(Ωn−1) ⊆ PAut(Sn) and so, as PAut(Sn) is an
inverse monoid, there exists β ∈ PAut(Sn) such that α = αβα.

Let M ∈ {PwEnd(Sn), PEnd(Sn), IEnd(Sn), PsEnd(Sn), PswEnd(Sn)}. As PAut(Sn) ⊆ M ⊆ PwEnd(Sn),

the previous two lemmas allow us to deduce immediately the following theorem:

Theorem 2.3. Let M ∈ {PsEnd(Sn), PswEnd(Sn), IEnd(Sn), PEnd(Sn), PwEnd(Sn)} and α ∈ M . Then, α is
a regular element of M if and only if 0 ∈ Dom(α) or Im(α) = {0} or 0 6∈ Im(α).

As PT (Ω) and I(Ω) are regular monoids, for any nonempty set Ω, for n ∈ {1, 2}, all the monoids PwEnd(Sn),
PEnd(Sn), IEnd(Sn), PsEnd(Sn) and PswEnd(Sn) are regular. For n > 3, Theorem 2.3 allow us to conclude,
on the one hand, that PwEnd(Sn), PEnd(Sn) and IEnd(Sn) are not regular monoids (for instance, ( 1 2
1 0 ) is not
a regular element of them) and, on the other hand, that PsEnd(Sn) and PswEnd(Sn) are regular monoids.

In fact, more generally, it is easy to show that PsEnd(G) and PswEnd(G) are regular monoids, for every
graph G: for α ∈ PswEnd(G), if we deﬁne a partial transformation β by Dom(β) = Im(α) and xβ as being any
ﬁxed element of xα−1, for all x ∈ Dom(β), then it is a routine matter to prove that β ∈ PAut(G) and α = αβα.

Green’s relations

Next, we will give descriptions of Green’s relations for the monoids PsEnd(Sn), PswEnd(Sn), IEnd(Sn),
PEnd(Sn) and PwEnd(Sn). As already observed, the inverse monoid PAut(Sn) was studied in [7].
In par-
ticular, its Green’s relations were described in this paper.

Given a regular submonoid M of PT (Ω0

n−1), it is well known that Green’s relations L, R and H of M can

be described as following: for α, β ∈ M ,

• αLβ if and only if Im(α) = Im(β),

• αRβ if and only if Ker(α) = Ker(β), and

• αHβ if and only if Im(α) = Im(β) and Ker(α) = Ker(β).

In PT (Ω0

n−1) we also have

• αJβ if and only if | Im(α)| = | Im(β)|.

6

Recall that for a ﬁnite monoid, we always have J = D(= L ◦ R = R ◦ L).
Before we move on to the descriptions of Green’s relations, let us observe the following note.

Note 2.4. For x, y ∈ Ω0

n−1 and a nonempty subset X of Ω0

n−1, we have:

1. ( x

y ) ∈ PAut(Sn), by Proposition 1.10, and so ( x

y ) ∈ IEnd(Sn);

∈ PswEnd(Sn), by Proposition 1.8, and so

X
y

∈ PwEnd(Sn);

∈ PsEnd(Sn) if and only if 0 6∈ X or |X| = 1 if and only if

(cid:0)

(cid:1)

2.

3.

X
y

X
y

(cid:0)

(cid:1)

and 1.4.
(cid:1)
(cid:0)

∈ PEnd(Sn), by Propositions 1.6

X
y

(cid:0)

(cid:1)

Since PsEnd(Sn) and PswEnd(Sn) are regular submonoids of PT (Ω0

n−1), it remains to give a description
of Green’s relation J for these two monoids. The following are descriptions of Green’s relations R for the other
monoids.

Proposition 2.5. Let M ∈ {IEnd(Sn), PEnd(Sn), PwEnd(Sn)} and let α, β ∈ M . Then, αRβ in M if and
only if one of the following properties is satisﬁed:

1. Ker(α) = Ker(β) and | Im(α)| 6 1;

2. Ker(α) = Ker(β), | Im(α)| > 2, 0 ∈ Im(α) if and only if 0 ∈ Im(β), and if 0 ∈ Im(α), then either

0α−1 = 0β−1 or 0α−1 and 0β−1 are the only kernel classes of α.

Proof. First, let us suppose that α, β ∈ PwEnd(Sn) and αRβ in PwEnd(Sn). Then, αRβ in PT (Ω0
n−1) and so
Ker(α) = Ker(β). Hence, in particular, Dom(α) = Dom(β) and | Im(α)| = | Im(β)|. If | Im(α)| 6 1, then there
is nothing left to prove. Thus, suppose that | Im(α)| > 2.

Suppose that 0 ∈ Im(α) and let λ ∈ PwEnd(Sn) be such that β = αλ. Since PwEnd(Sn) contains all partial
identities of Ω0
n−1, we can assume, without loss of generality, that Im(λ) = Im(β). As Dom(α) = Dom(β), we
must have 0 ∈ Dom(λ) and so, by Proposition 1.1, 0 ∈ Im(λ) = Im(β), since | Im(λ)| = | Im(β)| = | Im(α)| > 2.
Similarly, if we suppose that 0 ∈ Im(β), then we get 0 ∈ Im(α). Thus, 0 ∈ Im(α) if and only if 0 ∈ Im(β).

Next, suppose again that 0 ∈ Im(α). Then, from what we just proved, we also have 0 ∈ Im(β). Let
γ ∈ PwEnd(Sn) be such that α = βγ. Then, (0β−1)α = (0β−1)βγ = {0γ}. If 0γ = 0 then 0α−1 = 0β−1. So,
suppose that 0γ 6= 0. As | Im(γ)| > | Im(α)| > 2, by Proposition 1.1, it follows that Im(γ) = {0, 0γ} and so
| Im(α)| = 2. Thus, either 0α−1 = 0β−1 or 0α−1 and 0β−1 are the (only) two kernel classes of α.

Now, let α, β ∈ M be such αRβ in M , then αRβ in PwEnd(Sn) and so Property 1 or 2 is satisﬁed.
Conversely, suppose that Property 1 or 2 is satisﬁed. If Ker(α) = Ker(β) and | Im(α)| = 0, then α = β = ∅
A
and
p
p ) ∈ PAut(Sn).
(cid:0)

and so, trivially, αRβ in M . Next, supose that Ker(α) = Ker(β) and | Im(α)| = 1. Then, α =
β =
Hence, αRβ in M .
(cid:1)

n−1, and so α = β ( q

n−1 and ∅ ( A ⊆ Ω0

, for some p, q ∈ Ω0

p ), β = α ( p

q ) with ( p

q ) , ( q

A
q

(cid:1)

(cid:0)

Now, suppose that Property 2 holds. Take α =

, with k = | Im(α)| > 2.
and β =
n−1). Then, α = βγ and β = αγ−1. We will show that γ ∈ PAut(Sn) and thus αRβ

(cid:16)

(cid:17)

(cid:0)

(cid:1)

A1 A2 ··· Ak
a1 a2 ··· ak

A1 A2 ··· Ak
b1 b2 ··· bk

∈ I(Ω0

Let γ =
in M .

(cid:0)

b1 b2 ··· bk
a1 a2 ··· ak

(cid:1)

By hypothesis, 0 ∈ Im(α) = Im(γ) if and only if 0 ∈ Im(β) = Dom(γ). Hence, if 0 6∈ Im(α), then
0 6∈ Dom(γ) ∪ Im(γ) and so, by Proposition 1.10, γ ∈ PAut(Sn). Therefore, suppose that 0 ∈ Im(α). So,
0 ∈ Dom(γ) ∩ Im(γ). If 0γ = 0, then γ ∈ PAut(Sn), by Proposition 1.10. Hence, suppose that 0γ 6= 0. Then,
as α = βγ, we have 0α−1 6= 0β−1, whence 0α−1 and 0β−1 are the only kernel classes of α, by hypothesis. Thus,
k = 2 and so γ =
, from which we conclude, by Proposition 1.10, that γ ∈ PAut(Sn), as
required.

or γ =

0 b1
a2 0

0 b2
a1 0

(cid:0)

(cid:1)

(cid:1)

(cid:0)

Notice that, if α ∈ I(Ω0

n−1), then | Im(α)| = | Dom(α)| and the kernel classes of α are all singletons formed
by elements of Dom(α). Therefore, Ker(α) = Ker(β) if and only if Dom(α) = Dom(β), and | Im(α)| = | Im(β)|
if and only if | Dom(α)| = | Dom(β)|, for all α, β ∈ I(Ω0
n−1) and y ∈ Im(α),

n−1). Notice also that, for α ∈ PT (Ω0

7

yα−1 denotes the kernel class {x ∈ Dom(α) | xα = y} of α, while if α ∈ I(Ω0
n−1), then it is generally more
convenient for yα−1 to denote the image of y by the transformation α−1. Therefore, for IEnd(Sn), we can
rewrite the previous proposition as follows.

Corollary 2.6. Let α, β ∈ IEnd(Sn). Then, αRβ in IEnd(Sn) if and only if one of the following properties is
satisﬁed:

1. Dom(α) = Dom(β) and | Dom(α)| 6 1;

2. Dom(α) = Dom(β), | Dom(α)| > 2, 0 ∈ Im(α) if and only if 0 ∈ Im(β), and if 0 ∈ Im(α), then either

0α−1 = 0β−1 or Dom(α) = {0α−1, 0β−1}.

Now, we present descriptions of Green’s relations L.

Proposition 2.7. Let M ∈ {IEnd(Sn), PEnd(Sn), PwEnd(Sn)} and let α, β ∈ M . Then, αLβ in M if and
only if one of the following properties is satisﬁed:

1. Im(α) = Im(β) and | Im(α)| 6 1;

2. Im(α) = Im(β), | Im(α)| > 2, and 0 ∈ Dom(α) if and only if 0 ∈ Dom(β).

Proof. First, suppose that αLβ in PwEnd(Sn). Then, αLβ in PT (Ω0
then there is nothing left to prove. Thus, suppose that | Im(α)| > 2.

n−1) and so Im(α) = Im(β). If | Im(α)| 6 1,

Suppose that 0 ∈ Dom(α) and let γ ∈ PwEnd(Sn) be such that α = γβ. Then, | Im(γ)| > | Im(α)| > 2,
Dom(α) ⊆ Dom(γ) and Dom(α)γ ⊆ Dom(β). In particular, 0 ∈ Dom(γ). If 0γ = 0, then 0 ∈ Dom(β). So,
suppose that 0γ 6= 0. Hence, by Proposition 1.1, Im(γ) = {0, 0γ} and so Im(γ) must be a transversal of Ker(β),
since | Im(γ)| = | Im(β)|. Therefore, 0 ∈ Dom(β). Similarly, if we suppose that 0 ∈ Dom(β), then we get
0 ∈ Dom(α). Thus, 0 ∈ Dom(α) if and only if 0 ∈ Dom(β).

Now, let α, β ∈ M be such αLβ in M , then αLβ in PwEnd(Sn) and so Property 1 or 2 is satisﬁed.
Conversely, suppose that Property 1 or 2 is satisﬁed. If Im(α) = Im(β) and | Im(α)| = 0, then α = β = ∅
and so, trivially, αLβ in M . Next, suppose that Im(α) = Im(β) and | Im(α)| = 1. Take p ∈ Dom(α) and
q ∈ Dom(β). Then, by Note 2.4,
β and

∈ M , since α, β ∈ M . Moreover, α =

,

Dom(α)
q

Dom(β)
p

Dom(α)
q

(cid:16)

(cid:17)

β =

Dom(β)
p

(cid:16)
α, whence αLβ in M .

(cid:17)

(cid:16)

(cid:17)

, where
(cid:1)

(cid:16)
In what follows, suppose that Property 2 holds. Take α =

(cid:17)

A1 A2 ··· Ak
p1 p2 ··· pk

and β =

B1 B2 ··· Bk
p1 p2 ··· pk

(cid:0)
B1 B2 ··· Bk
k = | Im(α)| > 2, and let γ =
n−1) be such that bi ∈ Bi and ai ∈ Ai,
a1 a2 ··· ak
for all 1 6 i 6 k. Furthermore, if 0 ∈ Dom(α), then 0 ∈ Dom(β). In this case, suppose that 0 ∈ A1 ∩ B1 and
choose a1 = b1 = 0. Notice that, clearly, α = γβ, β = λα. We will show that γ, λ ∈ M and thus αLβ in M .

∈ PT (Ω0

A1 A2 ··· Ak
b1 b2 ··· bk

, λ =

(cid:17)

(cid:16)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

If 0 /∈ Dom(α), then 0 /∈ Dom(β), whence 0 /∈ Dom(γ)∪Dom(λ) and so, by Propositions 1.4 and 1.11, we can
conclude that γ, λ ∈ M . On the other hand, suppose that 0 ∈ Dom(α). Then, 0 ∈ Dom(β) and 0γ = 0 = 0λ,
whence γ, λ ∈ PwEnd(Sn), by Proposition 1.1. On the other hand, if we assume that α, β ∈ PEnd(Sn), then
A1 = B1 = {0}, by Proposition 1.4. Thus, if α, β ∈ PEnd(Sn) or α, β ∈ IEnd(Sn), then Ωn−1γ ⊆ Ωn−1 and
Ωn−1λ ⊆ Ωn−1, whence γ, λ ∈ PEnd(Sn) or γ, λ ∈ IEnd(Sn), respectively, by Propositions 1.4 and 1.11, as
required.

Naturally, descriptions of the Green’s relation H of IEnd(Sn), PEnd(Sn) and PwEnd(Sn) follow immediately

from Propositions 2.5 and 2.7. However, we can give simpler descriptions, as follows.

Proposition 2.8. Let M ∈ {IEnd(Sn), PEnd(Sn), PwEnd(Sn)} and let α, β ∈ M . Then, αHβ in M if and
only if Ker(α) = Ker(β) and Im(α) = Im(β).

8

Proof. It is clear that, if αHβ in M , then αHβ in PT (Ω0

n−1) and thus Ker(α) = Ker(β) and Im(α) = Im(β).
Conversely, suppose that Ker(α) = Ker(β) and Im(α) = Im(β). If | Im(α)| 6 1, then αRβ and αLβ, by
Propositions 2.5 and 2.7, whence αHβ. So, suppose that | Im(α)| > 2. As Ker(α) = Ker(β), then 0 ∈ Dom(α)
if and only if 0 ∈ Dom(β), whence αLβ, by Proposition 2.7. On the other hand, as Im(α) = Im(β), then
0 ∈ Im(α) if and only if 0 ∈ Im(β). Next, suppose that 0 ∈ Im(α). Then, 0 ∈ Im(β) and so 0α−1 and 0β−1 are
kernel classes of α. Suppose that 0α−1 6= 0β−1. Then, 0 6∈ 0α−1 or 0 6∈ 0β−1. If 0 6∈ 0α−1, then Im(α) = {0, 0α},
by Proposition 1.1, whence 0α−1 and 0β−1 are the only kernel classes of α. Thus, by Proposition 2.5, we have
αRβ, and so αHβ, as required.

We now focus on the Green’s relation J.

Proposition 2.9. Let M ∈ {PsEnd(Sn), PswEnd(Sn), IEnd(Sn), PEnd(Sn), PwEnd(Sn)} and let α, β ∈ M .
Then, αJβ in M if and only if one of the following properties is satisﬁed:

1. | Im(α)| = | Im(β)| 6 1;

2. | Im(α)| = | Im(β)| > 2, 0 ∈ Dom(α) if and only if 0 ∈ Dom(β), and 0 ∈ Im(α) if and only if 0 ∈ Im(β).

Proof. First, suppose that αJβ in M . Then, αJβ in PT (Ω0
n−1) and so | Im(α)| = | Im(β)|. If | Im(α)| 6 1,
then there is nothing left to prove. So, suppose that | Im(α)| > 2. Let γ ∈ PwEnd(Sn) be such that αLγRβ
(in PwEnd(Sn)). Then, by Propositions 2.5 and 2.7, we have Ker(γ) = Ker(β) and Im(γ) = Im(α), as well
as, 0 ∈ Dom(α) if and only if 0 ∈ Dom(γ), and 0 ∈ Im(γ) if and only if 0 ∈ Im(β). Thus, it follows that
0 ∈ Dom(α) if and only if 0 ∈ Dom(β), and 0 ∈ Im(α) if and only if 0 ∈ Im(β), whence Property 2 is proved.

Conversely, suppose that Property 1 or 2 is satisﬁed.

If | Im(α)| = | Im(β)| = 0, then α = β = ∅ and
so, trivially, αJβ in M . Next, suppose that | Im(α)| = | Im(β)| = 1. Then, α =
, for some
p, q ∈ Ω0
. Hence, by Note 2.4, we can conclude that γ ∈ M , since β ∈ M .
(cid:1)
Moreover, Im(γ) = Im(α) and Ker(γ) = Ker(β). Thus, by the regularity of PsEnd(Sn) and of PswEnd(Sn) and
(cid:1)
by Propositions 2.5 and 2.7, we get αLγRβ in M and so αJβ in M .

n−1 and ∅ ( A, B ⊆ Ω0

n−1. Let γ =

and β =

B
q

B
p

A
p

(cid:0)

(cid:0)

(cid:0)

(cid:1)

Now, suppose that Property 2 holds. Take α =

A1 A2 ··· Ak
p1 p2 ··· pk

and β =

B1 B2 ··· Bk
q1 q2 ··· qk

, where k = | Im(α)| > 2,

B1 B2 ··· Bk
p1 p2 ··· pk

∈ PT (Ω0

(cid:0)

(cid:1)

(cid:1)

(cid:1)

(cid:0)

(cid:0)
n−1). We will consider two cases.

and let γ =
case 0 6∈ Dom(α). Then, 0 6∈ Dom(β) and so, by Propositions 1.6 and 1.11, we can conclude that γ ∈ M
(notice that, if α ∈ PswEnd(Sn) and | Im(α)| > 2, then 0 6∈ Im(α)). If 0 ∈ Im(α) ∩ Im(β), without loss of
generality, we can assume that p1 = 0 = q1. On the one hand, we have Im(α) = Im(γ), with 0 6∈ Dom(α)
and 0 6∈ Dom(β) = Dom(γ), whence αLγ in M , by Proposition 2.7 and by the regularity of PsEnd(Sn) and
of PswEnd(Sn). On the other hand, Ker(γ) = Ker(β) and, by hypothesis, 0 ∈ Im(γ) = Im(α) if and only if
0 ∈ Im(β). Moreover, if 0 ∈ Im(γ), then 0γ−1 = B1 = 0β−1. Hence, by Proposition 2.5 and by the regularity
of PsEnd(Sn) and of PswEnd(Sn), γRβ in M and so αJβ in M .
case 0 ∈ Dom(α). Then, 0 ∈ Dom(β). Without loss of generality, assume that 0 ∈ A1 ∩ B1. Observe that, if
α, β ∈ PswEnd(Sn) ∪ PEnd(Sn), then A1 = B1 = {0}, by Propositions 1.4 and 1.8. Within this case, we will
consider three subcases.
subcase 0α 6= 0. Then, by Proposition 1.1, k = 2 and α =
, with q2 = 0 if and only
(cid:1)
if 0β 6= 0, and γ =
. Moreover, by Proposition 1.1, γ ∈ PwEnd(Sn) and, if M 6= PwEnd(Sn), then
β ∈ PswEnd(Sn) ∪ PEnd(Sn), whence B1 = {0} and so, by Propositions 1.6 and 1.11, we can conclude that
γ ∈ M . Since Im(α) = Im(γ) and 0 ∈ Dom(α) ∩ Dom(γ), we have αLγ in M , by Proposition 2.7 and by the
regularity of PsEnd(Sn) and of PswEnd(Sn). On the other hand, Ker(γ) = Ker(β) and 0 ∈ Im(γ) ∩ Im(β).
Moreover, if 0β 6= 0, then 0γ−1 = B2 = 0β−1; if 0β = 0, then 0γ−1 = B2 and 0β−1 = B1 are the only kernel
classes of γ. Hence, by Proposition 2.5 and by the regularity of PsEnd(Sn) and of PswEnd(Sn), γRβ in M and
so αJβ in M .
subcase 0β 6= 0. Considering λ =
M . Hence, αJβ in M .

, similarly to the previous subcase, we have λ ∈ M and αRλLβ in

B1 B2
0β q2

A1 A2
0β 0

B1 B2
0α 0

A1 A2
0α 0

, β =

(cid:17)

(cid:16)

(cid:17)

(cid:16)

(cid:0)

(cid:1)

(cid:0)

9

subcase 0α = 0β = 0. Since Dom(γ) = Dom(β) and 0γ = 0α = 0, by Proposition 1.1, γ ∈ PwEnd(Sn). On the
other hand, if M 6= PwEnd(Sn), then β ∈ PswEnd(Sn) ∪ PEnd(Sn), whence B1 = {0} and so, by Propositions
1.6 and 1.11, we can conclude that γ ∈ M . We have Im(α) = Im(γ) and 0 ∈ Dom(α) ∩ Dom(γ), whence αLγ
in M , by Proposition 2.7 and by the regularity of PsEnd(Sn) and of PswEnd(Sn). Also, Ker(γ) = Ker(β),
0 ∈ Im(γ) ∩ Im(β) and 0γ−1 = B1 = 0β−1, whence γRβ in M , by Proposition 2.5 and by the regularity of
PsEnd(Sn) and of PswEnd(Sn). Thus, αJβ in M .

For the monoids PsEnd(Sn) and PswEnd(Sn), we can still give simpler descriptions, as follows.

Corollary 2.10. Let M ∈ {PsEnd(Sn), PswEnd(Sn)} and let α, β ∈ M . Then, αJβ in M if and only if one of
the following properties is satisﬁed:

1. | Im(α)| = | Im(β)| 6 1;

2. | Im(α)| = | Im(β)| > 2, 0 ∈ Dom(α) if and only if 0 ∈ Dom(β).

Proof. If αJβ in M then, by Proposition 2.9, it is immediate that Property 1 or 2 is satisﬁed.

Conversely, if Property 1 is satisﬁed, then trivially αJβ in M , by Proposition 2.9. Therefore, suppose that
Property 2 is satisﬁed. Hence, by Proposition 2.9, it remains to show that 0 ∈ Im(α) if and only if 0 ∈ Im(β).
Suppose that 0 ∈ Im(α). Then, as | Im(α)| > 2, by Proposition 1.8, we must have 0 ∈ Dom(α). Hence,
by hypothesis, 0 ∈ Dom(β). If 0β = 0, then trivially 0 ∈ Im(β). On the other hand, since | Im(α)| > 2, by
Proposition 1.8, if 0β 6= 0, then 0 ∈ Ωn−1β ⊆ Im(β). Similarly, we can prove that 0 ∈ Im(β) implies 0 ∈ Im(α),
as required.

3 Generators and ranks

In this section, we present a set of generators with minimum size for each of the monoids PsEnd(Sn), PEnd(Sn),
PswEnd(Sn), PwEnd(Sn), PAut(Sn) and IEnd(Sn), thus computing their ranks.
Let n > 3. Let us consider the following transformations of PT (Ωn−1):

a =

1 2 3 · · · n − 1
2 1 3 · · · n − 1(cid:19)

,

(cid:18)

b =

1 2 · · · n − 2 n − 1
2 3 · · · n − 1

1 (cid:19)

,

(cid:18)

e =

1 2 3 · · · n − 1
1 1 3 · · · n − 1(cid:19)

(cid:18)

and

f =

2 3 · · · n − 1
2 3 · · · n − 1(cid:19)

.

(cid:18)

Then, it is well known that {a, b, e, f } is a set of generators of PT (Ωn−1) (with minimum size for n > 4).

At this stage, recall the mapping ζ : PT (Ω0

n−1) −→ PT (Ω0

n−1), α 7−→ ζα, such that Dom(ζα) = Dom(α) ∪

{0}, 0ζα = 0 and ζα|Ωn−1 = α|Ωn−1 , for any α ∈ PT (Ω0

n−1).

Deﬁne

a0 = ζa =

0 1 2 3 · · · n − 1
0 2 1 3 · · · n − 1(cid:19)

,

(cid:18)

b0 = ζb =

0 1 2 · · · n − 2 n − 1
0 2 3 · · · n − 1

1 (cid:19)

,

(cid:18)

e0 = ζe =

0 1 2 3 · · · n − 1
0 1 1 3 · · · n − 1(cid:19)

(cid:18)

and f0 = ζf =

0 2 3 · · · n − 1
0 2 3 · · · n − 1(cid:19)

.

(cid:18)

Then, {a0, b0, e0, f0} is a set of generators of PT (Ωn−1)ζ (with minimum size for n > 4). Moreover, we have
a0, b0, e0, f0 ∈ PwEnd(Sn). Let us also consider the following transformations of PwEnd(Sn):

c =

1 2 · · · n − 1
0 2 · · · n − 1(cid:19)

,

(cid:18)

c0 = ζc =

0 1 2 · · · n − 1
0 0 2 · · · n − 1(cid:19)

,

(cid:18)

10

d =

1 2 · · · n − 1
1 2 · · · n − 1(cid:19)

,

(cid:18)

z =

0 1 2 · · · n − 1
1 0 0 · · ·

0 (cid:19)

(cid:18)

and z0 = ζz =

0 1 2 · · · n − 1
0 0 0 · · ·

0 (cid:19)

.

(cid:18)

Let 2PT n−1 = PT (Ωn−1)ζ ∪ PT (Ωn−1). As PT (Ωn−1)ζ ∩ PT (Ωn−1) = ∅, we have

|2PT n−1| = 2|PT (Ωn−1)| = 2nn−1.

Furthermore, 2PT n−1 is the submonoid of PT (Ω0
n−1) generated by {a0, b0, e0, f0, d}. In fact, it is clear that
2PT n−1 is a submonoid of PT (Ω0
n−1) and, on the other hand, as {a0, b0, e0, f0} generates PT (Ωn−1)ζ and
{a0d = a, b0d = b, e0d = e, f0d = f } generates PT (Ωn−1), it follows that {a0, b0, e0, f0, d} generates 2PT n−1.
In addition, for n > 4, it is easy to conclude that {a0, b0, e0, f0, d} is a generating set of 2PT n−1 with minimum
size (since {a0, b0, e0, f0} is a generating set of PT (Ωn−1)ζ with minimum size and the product of an element of
PT (Ωn−1)ζ by an element of PT (Ωn−1), or vice-versa, is an element of PT (Ωn−1)) and so the monoid 2PT n−1
has rank 5.

Now, notice that

PsEnd(Sn) = 2PT n−1 ∪ {α ∈ PT (Ω0

∪ {α ∈ PT (Ω0

n−1) | 0 6∈ Dom(α) and Im(α) = {0}}
n−1) | 0 ∈ Dom(α), 0α 6= 0 and Ωn−1α ⊆ {0}}

and a0, b0, e0, f0, d, z ∈ PsEnd(Sn). Moreover, we have:

Proposition 3.1. The set {a0, b0, e0, f0, d, z} generates the monoid PsEnd(Sn).

Proof. Let α =
2PT n−1, we have α = βz. Hence, α ∈ ha0, b0, e0, f0, d, zi.

(cid:0)

(cid:1)

i1 ··· ik
0 ··· 0

, with 1 6 i1 < · · · < ik 6 n − 1 and k > 1. Then, for instance, taking β =

i1 ··· ik
i1 ··· ik

∈

(cid:17)

(cid:16)

On the other hand, let α =

for example, β =
(cid:16)
concludes the proof.

0 i1 ··· ik
0 i1 ··· ik

(cid:17)

(cid:16)
, γ =

0 i1 ··· ik
i0 0 ··· 0

0 1
0 i0

(cid:0)

(cid:1)

, with 1 6 i1 < · · · < ik 6 n − 1, 1 6 i0 6 n − 1 and k > 0. Take,

(cid:17)
∈ 2PT n−1. Then, α = βzγ and so α ∈ ha0, b0, e0, f0, d, zi, which

Theorem 3.2. For n > 4, the monoid PsEnd(Sn) has rank 6.

Proof. Since elements of PsEnd(Sn) \ 2PT n−1 have ranks less than or equal to 2, we can only write a0, b0,
e0, f0 and d as products of elements of 2PT n−1. Therefore, as 2PT n−1 has rank 5 and {a0, b0, e0, f0, d}
generates 2PT n−1, any generating set of PsEnd(Sn) must have at least 5 elements of 2PT n−1 plus one element
of PsEnd(Sn) \ 2PT n−1, whence PsEnd(Sn) has rank at least 6. By Proposition 3.1, we can conclude that the
rank of PsEnd(Sn) is 6, as required.

Notice that, we can easily verify that {a0, f0, d, z} is a generating set of PsEnd(S3) with minimum size and

so PsEnd(S3) has rank 4.
Next, observe that

PswEnd(Sn) = PsEnd(Sn) ∪ {α ∈ PT (Ω0

n−1) | 0 ∈ Dom(α) and | Im(α)| = 1}

and a0, b0, e0, f0, d, z, z0 ∈ PswEnd(Sn). So, we have:

Proposition 3.3. The set {a0, b0, e0, f0, d, z, z0} generates the monoid PswEnd(Sn).

Proof. Let α ∈ PswEnd(Sn) \ PsEnd(Sn). Then, α =

i0 6 n − 1 and k > 1. For example, take β =
α ∈ ha0, b0, e0, f0, d, z, z0i, as required.

(cid:16)

(cid:16)
0 i1 ··· ik
0 i1 ··· ik

0 i1 ··· ik
i0 i0 ··· i0

, γ =

(cid:17)

(cid:0)

(cid:1)

, with 1 6 i1 < · · · < ik 6 n − 1, 0 6
(cid:17)
0
i0

∈ PsEnd(Sn). Then, α = βz0γ and so

Theorem 3.4. For n > 4, the monoid PswEnd(Sn) has rank 7.

11

Proof. A similar reasoning to the proof of Theorem 3.2 applies here. Indeed, since any element of PswEnd(Sn) \
PsEnd(Sn) has rank 1, we can only write a0, b0, e0, f0, d and z as products of elements of PsEnd(Sn). Therefore,
as PsEnd(Sn) has rank 6 and {a0, b0, e0, f0, d, z} generates PsEnd(Sn), any generating set of PswEnd(Sn) must
have at least 6 elements of PsEnd(Sn) plus one element of PswEnd(Sn) \ PsEnd(Sn), whence PswEnd(Sn) has
rank at least 7 and so, by Proposition 3.3, we conclude that the rank of PswEnd(Sn) is 7, as required.

Concerning n = 3, it is easy to check that {a0, f0, d, z, z0} is a generating set of PswEnd(S3) with minimum

size and so PswEnd(S3) has rank 5.

Now, we focus our attention on the monoid PEnd(Sn). Clearly,

PEnd(Sn) = PsEnd(Sn) ∪ {α ∈ PT (Ω0

n−1) | 0 6∈ Dom(α), 0 ∈ Im(α) and Im(α) ∩ Ωn−1 6= ∅}

and a0, b0, e0, f0, c, d, z ∈ PEnd(Sn). Besides, we get:

Proposition 3.5. The set {a0, b0, e0, f0, c, d, z} generates the monoid PEnd(Sn).

Proof. Let α ∈ PEnd(Sn) \ PsEnd(Sn). Then, in particular, 0 6∈ Dom(α) and 0 ∈ Im(α). So, | Dom(α)| 6 n − 1.
Since 0 ∈ Im(α), it follows that | Im(α) \ {0}| 6 n − 2. Hence, there exists j ∈ Ωn−1 such that j 6∈ Im(α). Let
n−1) be such that Dom(β) = Dom(α) and, for i ∈ Dom(β),
τ =
iβ = iατ , if iα 6= 0, and iβ = 1, if iα = 0. Clearly, τ, β ∈ PsEnd(Sn) and it is a routine matter to show that
α = βcτ . Thus, α ∈ ha0, b0, e0, f0, c, d, zi, as required.

0 1 2 ··· j−1 j j+1 ··· n−1
0 j 2 ··· j−1 1 j+1 ··· n−1

and let β ∈ PT (Ω0

(cid:16)

(cid:17)

Theorem 3.6. For n > 4, the monoid PEnd(Sn) has rank 7.

Proof. A similar reasoning to the proofs of Theorems 3.2 and 3.4, although a little more complex, also applies
in this proof. In fact, we will show that we can only write a0, b0, e0, f0, d and z as products of elements of
PsEnd(Sn), which allows us to deduce, in the same exact way as in the proof of Theorem 3.4, that PEnd(Sn)
has rank at least 7 and so conclude, by Proposition 3.5, that the rank of PEnd(Sn) is 7.

Let α ∈ {a0, b0, e0, f0, d}. Then, | Im(α)| > n − 1. Suppose that α = βγλ for some β ∈ PsEnd(Sn),
| Im(β)|, | Im(γ)|, | Im(βγ)|, | Im(λ)| > n − 1 and
γ ∈ PEnd(Sn) \ PsEnd(Sn) and λ ∈ PEnd(Sn). Hence,
0 ∈ Im(γ). Therefore, as 0 6∈ Dom(γ), we must have Dom(γ) = Ωn−1 and | Im(γ)| = n − 1. On the other hand,
either 0 6∈ Dom(β) or 0 ∈ Dom(β) and 0β = 0, whence 0 6∈ Dom(βγ). It follows that Dom(βγ) = Ωn−1 and
Im(βγ) = Im(γ). In particular, there exists i ∈ Ωn−1 such that iβγ = 0. If α 6= d, then 0 ∈ Dom(α) and so
0 ∈ Dom(βγ), which is a contradiction. If α = d, then i = id = iβγλ = 0λ, whence Im(λ) ⊆ {0, i}, which is a
contradiction. Thus, we can only write α as a product of elements of PsEnd(Sn).

Now, suppose that z = βγλ for some β ∈ PsEnd(Sn), γ ∈ PEnd(Sn) \ PsEnd(Sn) and λ ∈ PEnd(Sn). Then,
as 0 ∈ Dom(z), we get 0 ∈ Dom(β) and 0 ∈ Dom(βγ). As 0 6∈ Dom(γ), if 0β = 0, then 0 6∈ Dom(βγ), which
is a contradiction. Hence, 0β 6= 0 and so Ωn−1β ⊆ {0}. As 0 6∈ Dom(γ), it follows that Ω0
n−1 = Dom(z) ⊆
Dom(βγ) = {0}, which again is a contradiction. Thus, we can only also write z as a product of elements of
PsEnd(Sn), as required.

For n = 3, it is easy to show that {a0, f0, d, z, c} is a generating set of PEnd(S3) with minimum size and so

PEnd(S3) has rank 5.

Next, we consider the monoid PwEnd(Sn). Observe that

PwEnd(Sn) = PEnd(Sn) ∪ {α ∈ PT (Ω0

n−1) | 0 ∈ Dom(α), 0α = 0 and 0 ∈ Ωn−1α}

∪ {α ∈ PT (Ω0

n−1) | {0} ( Dom(α), 0α 6= 0 and 0α ∈ Ωn−1α ⊆ {0, 0α}}.

So, we have:

Proposition 3.7. The set {a0, b0, e0, f0, c0, d, z} generates the monoid PwEnd(Sn).

12

Proof. First, observe that, since c = dc0, we have PEnd(Sn) = ha0, b0, e0, f0, c, d, zi ⊆ ha0, b0, e0, f0, c0, d, zi.
0 1 ··· j−1 j j+1 ··· n−1
0 1 ··· j−1 0 j+1 ··· n−1

Next, for 1 6 j 6 n − 1, let c0,j =

0 1 2 ··· j−1 j j+1 ··· n−1
0 j 2 ··· j−1 1 j+1 ··· n−1

and τj =

. Then,

τj ∈ ha0, b0i and c0,j = τjc0τj, whence c0,j ∈ ha0, b0, c0i, for all 1 6 j 6 n − 1. Notice that c0,1 = c0.

(cid:16)

(cid:17)

(cid:16)

(cid:17)

Let α ∈ PwEnd(Sn) be such that 0 ∈ Dom(α), 0α = 0 and 0 ∈ Ωn−1α. Then, there exists j ∈ Ωn−1 \ Ωn−1α,
n−1) by Dom(β) = Dom(α), 0β = 0 and, for i ∈ Dom(β) ∩ Ωn−1, iβ = iα, if

since 0 ∈ Ωn−1α. Deﬁne β ∈ PT (Ω0
iα 6= 0, and iβ = j, if iα = 0. Therefore, β ∈ PEnd(Sn) and α = βc0,j, whence α ∈ ha0, b0, e0, f0, c0, d, zi.

Now, let α ∈ PwEnd(Sn) be such that {0} ( Dom(α), 0α 6= 0 and 0α ∈ Ωn−1α ⊆ {0, 0α}. Let us take α′ =
n−1). Then, 0 ∈ Dom(α′), 0α′ = 0 and 0 ∈ Ωn−1α′, whence α′ ∈ ha0, b0, e0, f0, c0, d, zi, by the
0α 0 ) ∈ PT (Ω0
α ( 0 0α
previous case. On the other hand, it is a routine matter to show that α = α′zτ0α and so α ∈ ha0, b0, e0, f0, c0, d, zi,
which ﬁnishes the proof.

Theorem 3.8. For n > 4, the monoid PwEnd(Sn) has rank 7.

Proof. In view of Proposition 3.7, it suﬃces to show that any generating set of the monoid PwEnd(Sn) has at
least 7 distinct elements. So, let us take an arbitrary generating set X of PwEnd(Sn).

As the group of units U of PwEnd(Sn) is isomorphic to S(Ωn−1) (Corollary 1.3), which has rank 2 (for

n > 4), then X must have at least two elements of U and so at least two permutations of Ω0

n−1.

Take α ∈ {e0, f0, c0, d, z} and let α1, . . . , αk ∈ X (k > 1) be such that α = α1 · · · αk. Observe that, if α 6= z,

then | Im(α)| = n − 1, whence | Im(αi)| > n − 1, and so | Dom(αi)| > n − 1, for all 1 6 i 6 k.

Suppose that α ∈ {e0, c0}. Since α 6∈ U , there exists 0 6 i 6 k − 1 such that α1, . . . , αi ∈ U and αi+1 6∈ U .
Then, α1 · · · αi ∈ U and β = (α1 · · · αi)−1α = αi+1 · · · αk. Moreover, Ω0
n−1 = Dom(α) = Dom(β) ⊆ Dom(αi+1),
whence Dom(αi+1) = Ω0
n−1. Besides, since Ker(αi+1) ⊆ Ker(β) and | Im(β)| = | Im(α)| = n − 1 = | Im(αi+1)|,
we get Ker(αi+1) = Ker(β). On the other hand, like α, the transformation β, and thus αi+1, has a unique
non-singleton kernel class, which is formed by two elements of Ωn−1, namely 1α1 · · · αi and 2α1 · · · αi, if α = e0,
and 0 and one element of Ωn−1, namely 1α1 · · · αi, if α = c0. Therefore, the set X contains at least two distinct
transformations with domain Ω0

n−1 and rank n − 1.

Next, suppose that α = d. If 0 ∈ Dom(αi) for all 1 6 i 6 k, then 0αi = 0 for all 1 6 i 6 k and so 0 ∈
Dom(α1 · · · αk) = Dom(d), which is a contradiction. Hence, there exists 1 6 i 6 k such that Dom(αi) = Ωn−1
and | Im(αi)| = n − 1.

Now, suppose that α = f0. If Dom(αi) = Ω0

n−1 for all 1 6 i 6 k, then Dom(f0) = Dom(α1 · · · αk) = Ω0
which is a contradiction. Hence, there exists 0 6 i 6 k − 1 such that Dom(α1) = · · · = Dom(αi) = Ω0
and Dom(αi+1) 6= Ω0
Dom(α1 · · · αk) = Dom(f0), which is a contradiction. Hence, 0 ∈ Dom(αi+1) and so Dom(αi+1) = Ω0
for some 1 6 t 6 n − 1, and | Im(αi+1)| = n − 1.

n−1,
n−1
n−1. As 0α1 · · · αi = 0 (for i > 0), if 0 6∈ Dom(αi+1), then 0 6∈ Dom(α1 · · · αiαi+1) ⊇
n−1 \ {t},

Finally, suppose that α = z. Then, 0 ∈ Dom(z) ⊆ Dom(α1 · · · αi) for all 1 6 i 6 k. As 0α1 · · · αk = 0z 6= 0,
there exists 0 6 i 6 k − 1 such that 0α1 = · · · = 0α1 · · · αi = 0 (i > 0) and 0α1 · · · αiαi+1 6= 0. Hence,
0 = 0α1 · · · αi ∈ Dom(αi+1) and 0αi+1 = 0(α1 · · · αi)αi+1 6= 0, which implies that Im(αi+1) ⊆ {0, 0αi+1} and so
| Im(αi+1)| 6 2.

Therefore, we proved that X has at least 7 distinct elements, as required.

Observe that, we may easily prove that {a0, f0, d, z, c0} is a generating set of PwEnd(S3) with minimum

size and so PwEnd(S3) has rank 5.

We ﬁnish this paper by considering the monoids of injective partial endomorphisms of Sn.
Let

e1 =

(cid:18)

0 1 · · · n − 2
0 1 · · · n − 2(cid:19)

and z1 =

(cid:18)

0 1
1 0(cid:19)

.

It is well known that
is a generating set of I(Ωn−1)ζ. Moreover, the following result was proved in [7]:

generates I(Ωn−1) (see [11]). Then, {a0, b0, e1} =

a, b,

(cid:1)(cid:9)

(cid:8)

(cid:0)

1 2 ··· n−2
1 2 ··· n−2

ζa, ζb,

1 2 ··· n−2
1 2 ··· n−2

ζ

(cid:8)

(cid:0)

(cid:1)

(cid:9)

Theorem 3.9 ([7, Proposition 3.1 and Theorem 3.2]). For n > 4, PAut(Sn) = ha0, b0, e1, d, z1i and PAut(Sn)
has rank 5.

13

For n = 3, we have that {a0, d, z1} is a generating set of PAut(S3) with minimum size and so PAut(S3) has

rank 3.

For the monoid IEnd(Sn), we have:

Theorem 3.10. For n > 4, IEnd(Sn) = ha0, b0, e1, c, d, z1i and IEnd(Sn) has rank 6.

Proof. Observe that IEnd(Sn) = PAut(Sn) ∪ {α ∈ I(Ω0
n−1) | 0 6∈ Dom(α), 0 ∈ Im(α) and Im(α) ∩ Ωn−1 6= ∅}.
Let α ∈ IEnd(Sn) \ PAut(Sn). Then, in particular, 0 6∈ Dom(α) and 0 ∈ Im(α), whence | Dom(α)| 6 n − 1
and | Im(α) \ {0}| 6 n − 2. So, there exists j ∈ Ωn−1 such that j 6∈ Im(α). Let τ and β be deﬁned as in the
proof of Proposition 3.5. Then, like in the referred proof, we have α = βcτ and, in this case, it is clear that
τ, β ∈ PAut(Sn). Hence, by Theorem 3.9, α ∈ ha0, b0, e1, c, d, z1i. Thus, IEnd(Sn) = ha0, b0, e1, c, d, z1i.
To conclude this proof, it remains to show that we need at least 6 elements to generate IEnd(Sn).
Using, with the obvious adaptations, the same argumentation as in the proof of Theorem 3.6, it can be
shown that we can only write a0, b0, e1, d and z1 as products of elements of PAut(Sn). Thus, in view of
Theorem 3.9, we need at least 6 elements to generate IEnd(Sn), as required.

Regarding n = 3, it is easy to check that {a0, d, c, z1} is a generating set of IEnd(S3) with minimum size

and so IEnd(S3) has rank 4.

References

[1] M. B¨ottcher and U. Knauer, Endomorphism spectra of graphs, Discrete Mathematics, 109 (1992), 45–57.

[2] I. Dimitrova, V. H. Fernandes, J. Koppitz and T. M. Quinteiro, Ranks of monoids of endomorphisms of a

ﬁnite undirected path, Bull. Malaysian Math. Sci. Soc., 43(2) (2020), 1623–1645.

[3] I. Dimitrova, V. H. Fernandes, J. Koppitz and T. M. Quinteiro, Partial Automorphisms and Injective

Partial Endomorphisms of a Finite Undirected Path, Semigroup Forum, 103(1), (2021), 87–105.

[4] I. Dimitrova, V. H. Fernandes, J. Koppitz and T. M. Quinteiro, On monoids of endomorphisms of a cycle

graph, arXiv:2310.04149 [math.RA] https://doi.org/10.48550/arXiv.2310.04149 (2023).

[5] S. Fan, On End-regular graphs, Discrete Mathematics, 159 (1996), 95–102.

[6] V.H. Fernandes, Presentations for some monoids of partial transformations on a ﬁnite chain: a survey,
Semigroups, Algorithms, Automata and Languages, eds. Gracinda M. S. Gomes & Jean-´Eric Pin & Pedro
V. Silva, World Scientiﬁc (2002), 363–378.

[7] V.H. Fernandes and T. Paulista, On the monoid of partial isometries of a ﬁnite star graph, Commun.

Algebra, 51 (2023), 1028–1048.

[8] The GAP Group, GAP – Groups, Algorithms, and Programming, Version 4.11.1 ; 2021.

(https://www.gap-system.org)

[9] R. Gu and H. Hou, End-regular and End-orthodox generalized lexicographic products of bipartite graphs,

Open Math., 14 (2016), 229–236.

[10] H. Hou, Y. Luo and S. Fan, End-regular and End-orthodox joins of split graphs, Ars Combinatoria, 105

(2012), 305–318.

[11] J.M. Howie, Fundamentals of Semigroup Theory, Clarendon Press, Oxford, 1995.

[12] A.V. Kelarev, Graph Algebras and Automata, Marcel Dekker, New York, NY, USA, 2003.

14

[13] A.V. Kelarev and C.E. Praeger, On transitive Cayley graphs of groups and semigroups, Eur. J. Combin.,

24 (2003), 59–72.

[14] U. Knauer, Algebraic graph theory: morphisms, monoids, and matrices, De Gruyter, Berlin, 2011.

[15] U. Knauer and A. Wanichsombat, Completely Regular Endomorphisms of Split Graphs, Ars Combinatoria,

115 (2014), 357–366.

[16] W. Li, Graphs with regular monoids, Discrete Mathematics, 265 (2003), 105–118.

[17] E. Wilkeit, Graphs with a regular endomorphism monoid, Arch. Math., 66 (1996), 344–352.

Ilinka Dimitrova, Department of Mathematics, Faculty of Mathematics and Natural Science, South-West University ”Neoﬁt
Rilski”, 2700 Blagoevgrad, Bulgaria; e-mail: ilinka dimitrova@swu.bg.
V´ıtor H. Fernandes, Center for Mathematics and Applications (NOVA Math) and Department of Mathematics, Faculdade
de Ciˆencias e Tecnologia, Universidade Nova de Lisboa, Monte da Caparica, 2829-516 Caparica, Portugal; e-mail: vhf@fct.unl.pt.
J¨org Koppitz, Institute of Mathematics and Informatics, Bulgarian Academy of Sciences, 1113 Soﬁa, Bulgaria; e-mail:
koppitz@math.bas.bg.

15

"
Distance Antimagic Labeling of Zero-Divisor Graphs,"  In this paper, we prove that for all $m\geq 1$ and $n=1$, the graph $
m\Gamma(\mathbb{Z}_9)+n\Gamma(\mathbb{Z}_4)$, for all $n\geq 1$, and $m=1$, the
graph $m\overline{\Gamma(\mathbb{Z}_6)}+n\Gamma(\mathbb{Z}_9)$, for all
$m\geq1$, $[m\Gamma(\mathbb{Z}_9)+\Gamma(\mathbb{Z}_4)]\times
\Gamma(\mathbb{Z}_9)$, for all prime $m\geq3$,
$\Gamma(\mathbb{Z}_6)\times\Gamma(\mathbb{Z}_{2m})$ and
$\Gamma(\mathbb{Z}_6)\times\Gamma(\mathbb{Z}_{m^2})$ are all admit distance
antimagic labeling.
","Distance Antimagic Labeling of Zero-Divisor

Graphs

4
2
0
2

l
u
J

1
1

V. Sivakumaran1,∗, K. Sankar2, S. Prabhu1

1Department of Mathematics, Rajalakshmi Engineering College, Thandalam, Chennai 602105, India

2Department of Mathematics, Anna University, Chennai 600025, India

]

O
C
.
h
t
a
m

[

1
v
1
1
2
8
0
.
7
0
4
2
:
v
i
X
r
a

Abstract

In this paper, we prove that for all m ≥ 1 and n = 1, the graph mΓ(Z9) + nΓ(Z4), for all
n ≥ 1, and m = 1, the graph mΓ(Z6) + nΓ(Z9), for all m ≥ 1, [mΓ(Z9) + Γ(Z4)] × Γ(Z9),
for all prime m ≥ 3, Γ(Z6) × Γ(Z2m) and Γ(Z6) × Γ(Z

m2) are all admit distance antimagic

labeling.

Keywords: Distance antimagic labeling, Zero-divisor graph, Join of graphs, Cartesian

product of graphs.

Mathematics Subject Classiﬁcation: 05C78.

1

Introduction

In the year 1990, Beck [3] introduced Zero-divisor graph of a commutative ring. Anderson and

Livingston studied and developed the relation between theoretical properties of the ring and graph

theoretical properties of zero-divisor graph Γ(R) in [1].

Consider a commutative ring R with unity and assume set of all zero-divisor of R be Z(R) and
Z∗(R) = Z(R)\{0} be the vertex set such that any two distinct vertices u, v ∈ Z∗(R) are said to be

adjacent if and only if uv = 0. This condition provides zero-divisor graph and is denoted by Γ(R).
A graph Γ(Z10) with V [Γ(Z10)] = {2, 4, 6, 8, 5} and edge set E[Γ(Z10)] = {(2, 5), (4, 5), (6, 5), (8, 5)}
is given in Figure 1. A graph Γ(Z15) with V [Γ(Z15)] = {3, 6, 9, 12, 5, 10} and edge set E[Γ(Z15)] =

{(3, 5), (6, 5), (9, 5), (12, 5), (3, 10), (6, 10), (9, 10), (12, 10)} is given in Figure 2.

∗Corresponding author: anukumar675@gmail.com

1

 
 
 
 
 
 
2

4

6

8

3

6

9

12

5

5

10

Figure 1: Γ(Z10)

Figure 2: Γ(Z15)

Deﬁnition 1.1. [9] Let H1, H2, . . . , Hm be the given m copies of disjoint graphs. Then a set of

k disjoint graphs. Then H1 + H2 + · · · + Hm is obtained from H1, H2, . . . , Hm by joining every

vertex of Hi with every vertex Hj, whenever i 6= j. join graph G1 + G2 + . . . + Gk is obtained from

G1, G2, . . . , Gk by joining every vertex of Gi with every vertex of Gj, whenever i 6= j.

Deﬁnition 1.2. [9] The Cartesian product of the graphs G and H, denoted G × H, is the graph
with V (G × H) = {(u, v) : u ∈ V (G) and v ∈ V (H)} and E(G × H) = {< (u, v), (u′, v′) >: u =
u′ and vv′ ∈ E(H) or v = v′ and uu′ ∈ E(G)}

If a graph G is said to follow a DAML if for any two distinct vertices u1, u2 ∈ V (G) such that

N(u1) 6= N(u2).

2 Main Results

In the main result, we show that some join of zero-divisor this paper, we prove that some join

of zero-divisor graphs and some Cartesian product of zero-divisor graphs are distance antimagic

graphs.

Theorem 2.1. The join graph Γ(Z2m) + Γ(Z4) does not have DAML for all prime m ≥ 3.

2

Proof. Consider the graphs Γ(Z2m) and Γ(Z4) for all prime numbers m ≥ 3.
Let G = Γ(Z2m) + Γ(Z4) be the join of graphs as shown in Figure 3.

There exist u, v ∈ V (G) with N(u) = N(v). By the necessary condition for distance antimagic

graphs, the graph Γ(Z2m) + Γ(Z4) does not have DAML for all prime m ≥ 3.

u

v

.

.

.

Figure 3: The graph Γ(Z2m) + Γ(Z4)

We state the following few theorems without proof. The proof of those theorems can be done

as the proof of Theorem 2.1.

Theorem 2.2. For every prime m ≥ 3, Γ(Z2m) + G, G ∈ {Γ(Z6), Γ(Z9), Γ(Z6), Γ(Z9)} does not

admit DAML.

Theorem 2.3. For every prime m ≥ 5, Γ(Z3m) + G, G ∈ {Γ(Z4), Γ(Z6), Γ(Z9), Γ(Z6), Γ(Z9)} does

not admit DAML.

Theorem 2.4. For all m ≥ 1 and n = 1 if and only if the graph mΓ(Z9) + nΓ(Z4) admits DAML.

Proof. Consider the zero-divisor graphs Γ(Z9) and Γ(Z4).
Let G = mΓ(Z9) + nΓ(Z4) with |V (G)| = 2m + n for all m ≥ 1, and n ≥ 1.

Case (i): For n = 1 and m ≥ 1.
Consider the graph mΓ(Z9) + Γ(Z4) with |V (mΓ(Z9) + Γ(Z4))| = 2m + 1.
We label the vertices of mΓ(Z9) + Γ(Z4) as shown in Figure 4.
Deﬁne f : V (mΓ(Z9) + Γ(Z4)) → {1, 2, . . . , 2m + 1} by

f (vi) = i, whenever i ∈ {1, 2, . . . , 2m + 1} .

3

 
 
v2m+1

v1

v2

v3

v4

.

.

.

v2m−1

v2m

Figure 4: The graph mΓ(Z9) + Γ(Z4)

The weight of each vertex is determined by:

w(vi) =




2m + 2 + i,

if i is odd

2m + i,
and w(v2m+1) = m(2m + 1)



if i is even

It follows that w(vi) 6= w(vj) for all i 6= j.

Hence, the graph mΓ(Z9) + Γ(Z4) admits DAML for all m ≥ 1.

Case (ii): For n > 1 and m ≥ 1.
Consider the graph mΓ(Z9) + nΓ(Z4) with |V (mΓ(Z9) + nΓ(Z4))| = 2m + n. We label the vertices
of mΓ(Z9) + nΓ(Z4) as shown in Figure 5.

v1

v2

v3

vn

.

.

.

u1

u2

u3

u4

.

.

.

u2m−1

u2m

Figure 5: mΓ(Z9) + nΓ(Z4)

Clearly, we have N(v1) = N(v2) = · · · = N(vm).

Hence, the graph mΓ(Z9) + nΓ(Z4) does not have DAML for all m ≥ 1 and n > 1.

Therefore, the graph mΓ(Z9) + nΓ(Z4) admits DAML if and only if for m ≥ 1 and n = 1.

Theorem 2.5. For all m ≥ 1, and n ≥ 1, the graph mΓ(Z6) + nΓ(Z4) does not admit DAML.

4

 
 
 
 
 
 
Proof. Consider the zero-divisor graphs Γ(Z6) and Γ(Z4).
Let G = mΓ(Z6) + nΓ(Z4) with |V (G)| = 3m + n, for m ≥ 1 and n ≥ 1.

We label the vertices of G as in Figure 6.

v1

v2

v3

vn

.

.

.

u1

u2

u3

u4

u5

u6

.

.

.

u3m−2

u3m−1

u3m

Figure 6: mΓ(Z6) + nΓ(Z4)

We observe that N(u1) = N(u3), N(u4) = N(u6), . . . , N(u3m−2) = N(u3m).
Hence, the graph mΓ(Z6) + nΓ(Z4) does not admit DAML for all m ≥ 1 and n ≥ 1.

Theorem 2.6. For all m ≥ 1 and n ≥ 1, mΓ(Z6) + nΓ(Z9) does not admit DAML.

v1

v2

v3

v4

.

.

.

v2n−1

v2n

u1

u2

u3

u4

u5

u6

.

.

.

u3m−2

u3m−1

u3m

Figure 7: mΓ(Z6) + nΓ(Z9)

5

 
 
 
 
 
 
 
 
Proof. Consider the zero-divisor graphs Γ(Z6) and Γ(Z9). Let G = mΓ(Z6)+nΓ(Z9) with |V (G)| =

3m + 2n, for m, n ≥ 1. The vertices of G labeled as in Figure 7. We have N(u1) = N(u3), . . . ,
N(u3m−2) = N(u3m). Hence, the graph mΓ(Z6) + nΓ(Z9) does not admit DAML for all m ≥ 1

and n ≥ 1.

Corollary 2.1. For all m ≥ 1, mΓ(Z6) + Γ(Z9) does not admit DAML.

Proof. Let G = mΓ(Z6)+Γ(Z9) be a join graph and |V (G)| = 3m+2. There exist u, v ∈ Γ(Z9)(G),
we have N(u) = N(v) = 3m. Hence, the graph mΓ(Z6) + Γ(Z9) does not admit distance antimagic

labeling.

Theorem 2.7. The join graph mΓ(Z6) + nΓ(Z9) admits DAML if and only if m = 1 and n ≥ 1.

Proof. Consider the zero-divisor graphs Γ(Z6) and Γ(Z9).
Let G = mΓ(Z6) + nΓ(Z9) with |V (G)| = 3m + 2n for all m ≥ 1 and n ≥ 1.

For m > 1 and n ≥ 1, Consider the graph mΓ(Z6) + nΓ(Z9) with |V (mΓ(Z6) + nΓ(Z9))| =

3m + 2n. We label the vertices of the graph mΓ(Z6) + nΓ(Z9) as in Figure 8.

v1

v2

v3

v4

.

.

.

v2n−1

v2n

u1

u2

u3

u4

u5

u6

.

.

.

u3m−2

u3m−1

u3m

Figure 8: The graph mΓ(Z6) + nΓ(Z9)

It is observed that N(u3) = N(u6) = · · · = N(u3m). Hence, the graph mΓ(Z6) + nΓ(Z9) does

not admit DAML, for all m > 1 & n ≥ 1.

For m = 1 and n ≥ 1, consider the graph Γ(Z6) + nΓ(Z9) with |V (Γ(Z6) + nΓ(Z9))| = 2n + 3.

Let N = 2n and the vertices of G is labeled as shown in Figure 9.

6

 
 
 
 
v1

v2

v3

v4

.

.

.

vN −1

vN

vN +1

vN +2

vN +3

Figure 9: The graph Γ(Z6) + nΓ(Z9)

Let f : V (G) → {1, 2, . . . , N + 3} be a labeling function and is deﬁned by f (vi) = i, if

1 ≤ i ≤ N + 3. The weight of each vertex is determined by

w(vi) =




3N + i + 7,

if i odd and 1 ≤ i ≤ N − 1

3N + i + 5,

if i even and 2 ≤ i ≤ N

w(vN +1) = (N 2 + 3N + 4)/2,



w(vN +2) = (N 2 + 3N + 2)/2 and

w(vN +3) = (N 2 + N)/2.

It follows that w(vi) 6= w(vj) for all i 6= j.
Then the graph Γ(Z6) + nΓ(Z9) admits DAML for all n ≥ 1.
Hence, the graph mΓ(Z6) + nΓ(Z9) admits DAML if and only if m = 1 and n ≥ 1.

Theorem 2.8. The graph [mΓ(Z9) + Γ(Z4)] × Γ(Z9) has distance antimagic labeling for all m ≥ 1.

Proof. Let G = [mΓ(Z9) + Γ(Z4)] × Γ(Z9) be a cartesian product graph with |V (G)| = 4m + 2 for

m ≥ 1. We prove this theorem in two cases:
Case 1. Let m = 1, then the graph [Γ(Z9) + Γ(Z4)] × Γ(Z9) be a Cartesian product graph of order
6. We label the vertices of [Γ(Z9) + Γ(Z4)] × Γ(Z9) as given in Figure 10.

Let f : V ([Γ(Z9) + Γ(Z4)] × Γ(Z9)) → {1, 2, 3, 4, 5, 6} be a labeling function and deﬁned by

f (v1) = 1, f (v2) = 2, f (v3) = 3, f (v4) = 4, f (v5) = 5, f (v6) = 6

The weight of each vertex is determined by

w(v1) = 12, w(v2) = 10, w(v3) = 11, w(v4) = 9, w(v5) = 13, w(v6) = 8

7

 
 
v1

v2

v6

v3

v5

v4

Figure 10: The Cartesian product graph [Γ(Z9) + Γ(Z4)] × Γ(Z9)

It follows that the graph [Γ(Z9) + Γ(Z4)] × Γ(Z9) has distance antimagic labeling. Also we

observe that the graph [Γ(Z9) + Γ(Z4)] × Γ(Z9) is a (8,1)-distance antimagic graph.
Case 2. Let m ≥ 2, then the graph [mΓ(Z9) + Γ(Z4)] × Γ(Z9) be a Cartesian product graph of

order 4m + 2.
We label the vertices of [mΓ(Z9) + Γ(Z4)] × Γ(Z9) as depicted in Figure 11.

v4m+1

v1

v4m

v2

v4m−1

.

.

.

vm−1

v3m+2

vm

v3m+1

v2m

v2m+1

v2m−1

v2m+2

.

.

.

vm+2

v3m−1

vm+1

v3m

v4m+2

Figure 11: The Cartesian product graph [mΓ(Z9) + Γ(Z4)] × Γ(Z9)

Let f : V ([mΓ(Z9) + Γ(Z4)] × Γ(Z9)) → {1, 2, . . . , 4m + 2} be a labeling function and deﬁned

by

f (vi) = i, if 1 ≤ i ≤ 4m + 2.

The weight of each vertex is determined by

w(vi) = 10m + 3 − 2i, if 1 ≤ i ≤ m

w(vi) = 10m + 4 − 2i, if m + 1 ≤ i ≤ 2m

w(vi) = 14m + 4 − 2i, if 2m + 1 ≤ i ≤ 3m

w(vi) = 14m + 3 − 2i, if 3m + 1 ≤ i ≤ 4m

8

 
 
 
 
w(v4m+1) = 4m2 + 5m + 2

w(v4m+2) = 4m2 + 5m + 1, for m ≥ 2

Observe that w(vi) 6= w(vj), for all i 6= j.
Therefore, the graph [mΓ(Z9) + Γ(Z4)] × Γ(Z9) has distance antimagic labeling for all m ≥ 2.
Hence, from Case 1 and 2, the graph [mΓ(Z9) + Γ(Z4)] × Γ(Z9) has distance antimagic labeling

for all m ≥ 1.

Theorem 2.9. The graph Γ(Z6) × Γ(Z2m) admits DAML for all prime m 6= 2.

Proof. Consider the zero-divisor graphs Γ(Z6) and Γ(Z2m).
Let G = Γ(Z6) × Γ(Z2m) with |V (G)| = 3m, for all prime m 6= 2.
Case (i): For m = 3, |V (Γ(Z6) × Γ(Z6))| = 9.

We label the vertices of Γ(Z6) × Γ(Z6) as shown in Figure 12.

v1

v8

v3

v7

v2

v9

v4

v5

v6

Figure 12: The graph Γ(Z6) × Γ(Z6)

Let f : V (G) → {1, 2, . . . , 9} be a labeling function and is deﬁned by

f (v1) = 1, f (v2) = 2, f (v3) = 3, f (v4) = 4, f (v5) = 5,

f (v6) = 6, f (v7) = 7, f (v8) = 8, f (v9) = 9.

The weight of each vertex is determined by:

w(v1) = 19, w(v2) = 24, w(v3) = 23,

w(v4) = 6, w(v5) = 18, w(v6) = 8,

w(v7) = 3, w(v8) = 11, w(v9) = 5.
It follows that the graph Γ(Z6) × Γ(Z6) admits DAML.

9

Case (ii): Let m > 3 and prime.
We assume the graph Γ(Z6) × Γ(Z2m) with |V (Γ(Z6) × Γ(Z2m))| = 3m.
We label the vertices of Γ(Z6) × Γ(Z2m) as shown in Figure 13.

v(1)
1

v(3)
m

v(2)
1

v(1)
m

v(3)
1

v(2)
m

...
v(1)
3

...
v(3)
m−2

...
v(2)
3

v(1)
2

v(3)
m−1

v(2)
2

Figure 13: The graph Γ(Z6) × Γ(Z2m)

f : V (G) → {1, 2, . . . , 3m} be a labeling function deﬁned by

f (v(j)

i ) =

i,

where j = 1 and 1 ≤ i ≤ m

m + i,

where j = 2 and 1 ≤ i ≤ m

2m + i, where j = 3 and 1 ≤ i ≤ m






1 ) = (m2 + 7m − 2)/2,

i ) = 3m − i + 2, if 2 ≤ i ≤ m,
1 ) = (3m2 + 5m − 2)/2,

The weight of each vertex is given by:
w(v(1)
w(v(1)
w(v(2)
w(v(2)
w(v(3)
w(v(3)
Therefore, the graph Γ(Z6) × Γ(Z2m) admits DAML for all prime m > 3.
Hence, the graph Γ(Z6) × Γ(Z2m) admits DAML for all prime m 6= 2.

i ) = 6m − 2i + 2, if 1 ≤ i ≤ m − 1 and
m ) = (5m2 − 3m + 4)/2.

i ) = 4m − i + 2, if 2 ≤ i ≤ m,

Theorem 2.10. The graph Γ(Z9) × Γ(Zm2) admits DAML for all prime m > 3.

Proof. It is observed that the graph Γ(Z9) × Γ(Zm2) ∼= P2 × Km−1 for all prime m ≥ 3.

10

Already Sankar et al. [8] proved that, for all n ≥ 3, P2 × Kn admits DAML.
Therefore, the graph Γ(Z9) × Γ(Zm2) admits DAML for all prime m > 3.

Theorem 2.11. The graph Γ(Z6) × Γ(Zm2) admits DAML for all prime m ≥ 3.

the

zero-divisor

Γ(Z6)
Proof. Consider
m ≥ 3. Let G = Γ(Z6) × Γ(Zm2) with |V (G)| = 3m − 3.
Case (i): Let m = 3. The graph Γ(Z6) × Γ(Z9) admits DAML with the labels as in Figure 14. It
is clear that Γ(Z6) × Γ(Z9) admits DAML.

Γ(Zm2)

graphs

prime

and

for

all

1

2

4

3

5

6

Figure 14: The graph Γ(Z6) × Γ(Z9)

Case (ii): Let m > 3 and prime. Consider the graph Γ(Z6) × Γ(Zm2) with |V (Γ(Z6) × Γ(Zm2))| =
3m − 3. We label the vertices of Γ(Z6) × Γ(Zm2) as shown in Figure 15.

v1

v2

v3

.
.
.

vm−2

vm−1

v3m−3

v3m−4

v3m−5

.
.
.

v2m

v2m−1

vm

vm+1

vm+2

.
.
.

v2m−3

v2m−2

Figure 15: The graph Γ(Z6) × Γ(Zm2)

Deﬁne a labeling function f : V (G) → {1, 2, ..., 3m − 3} by

f (vi) = i, if 1 ≤ i ≤ 3m − 3.

Then the weight of each vertex is given by:

w(vi) =






1

2[m2 + 5m − 4] − 2i,

1

2[3m2 + 3m − 4] − 2i,

if 1 ≤ i ≤ m − 1

if m ≤ i ≤ 2m − 2

1

2[5m2 − 9m + 4] − i + [3m − (2j − 1)],

if 2m − 1 ≤ i ≤ 3m − 3 and j = 3 + i − 2m.

11

It follows that w(vi) 6= w(vj), for all i 6= j.
Therefore, the graph Γ(Z6) × Γ(Zm2) admits DAML for all m > 3.

Hence, the graph Γ(Z6) × Γ(Zm2) admits DAML for all prime m ≥ 3.

Theorem 2.12. The graph Γ(Z9) × Γ(Z3m) admits DAML for all odd m and m 6≡ 0 (mod 3).

Proof. Let G = Γ(Z9) × Γ(Z3m) with |V (G)| = 2m + 2 for all odd m and m 6≡ 0 (mod 3).

We label the vertices of G as given in Figure 16.

v3

v4

. . .

v5

v2m+2

vm+1

. . .

vm+6

vm+5

vm+4

v2

v1

vm+2

vm+3

Figure 16: The graph Γ(Z9) × Γ(Z3m)

Let f : V (G) → {1, 2, ..., 2m + 2} be a labeling function deﬁned by

f (vi) = i, for 1 ≤ i ≤ 2m + 2.

Then the weight of each vertex is given by:

1

2(m2 + 5m),

for i = 1

1

2(m2 + 5m + 2),

for i = 2

m + i + 4,

for 3 ≤ i ≤ m + 1

w(vi) =

1

2(3m2 + 3m − 4),

for i = m + 2

1

2(3m2 + 3m − 2),

for i = m + 3

m + i + 4,

for m + 4 ≤ i ≤ 2m + 2






It follows that w(vi) 6= w(vj), for all i 6= j.

Hence, the graph Γ(Z9) × Γ(Z3m) admits DAML for all odd m and

m 6≡ 0 (mod 3).

12

3 Conclusion

In this paper, we found the distance antimagic labeling of [mΓ(Z9) + Γ(Z4)] × Γ(Z9) for all m ≥ 1,
Γ(Z6) × Γ(Z2m) for all primes m ≥ 3 and Γ(Z6) × Γ(Zm2) for all primes m ≥ 3. The distance
antimagic labeling of Γ(Zm) × Γ(Zn) for all values of m and n and Γ(Zp) × [Γ(Zm) × Γ(Zn)] for all

values of p, m and n are left for future research.

References

[1] D.F. Anderson, P.S. Livingston, The zero divisor graph of a commutative ring, Journal of

Algebra 217 (1999) 434–447.

[2] S. Arumugam, N. Kamatchi, On (a, d) distance antimagic graphs, The Australasian Journal

of Combinatorics 54 (2012) 279–287.

[3] I. Beck, Coloring of commutative rings, Journal of Algebra, 116 (1988) 208–226.

[4] G. Chartrand, L. Lesniak, Graphs and Digraphs, Chapman and Hall, CRC, 4th edition (2005).

[5] J.A. Gallian, A dynamic survey of graph labeling, The Electronic Journal of Combinatorics

(2017) #DS6.

[6] N. Hartsﬁeld and G. Ringel, Pearls in Graph Theory: A Comprehensive introduction,

Academic Press, Boston (1990), 108–110.

[7] M. Baca, M. Miller, Super edge-antimagic graphs - A wealth of problems and some solutions,

Brown Walker Press (2008).

[8] K. Sankar, V. Sivakumaran, Distance antimagic labeling of product of graphs, Communicated

to Iranian Journal of Science and Technology Transactions A: Science.

[9] D. West, Introduction to graph theory, Second ed. Prentice Hall, 2001.

13

"
"Integer symmetric matrices having all their eigenvalues in the interval
  [-2,2]","  We completely describe all integer symmetric matrices that have all their
eigenvalues in the interval [-2,2]. Along the way we classify all signed
graphs, and then all charged signed graphs, having all their eigenvalues in
this same interval. We then classify subsets of the above for which the integer
symmetric matrices, signed graphs and charged signed graphs have all their
eigenvalues in the open interval (-2,2).
","INTEGER SYMMETRIC MATRICES HAVING ALL THEIR

EIGENVALUES IN THE INTERVAL [

2, 2]

−

7
0
0
2

y
a
M
4
2

JAMES MCKEE AND CHRIS SMYTH

Abstract. We completely describe all integer symmetric matrices that have all their
2, 2]. Along the way we classify all signed graphs, and then
eigenvalues in the interval [
all charged signed graphs, having all their eigenvalues in this same interval. We then
classify subsets of the above for which the integer symmetric matrices, signed graphs and
charged signed graphs have all their eigenvalues in the open interval (

2, 2).

−

−

]

O
C
.
h
t
a
m

[

1
v
9
9
5
3
.
5
0
7
0
:
v
i
X
r
a

1. Introduction

×

−

0, 1

Let A be an n

n integer symmetric matrix with characteristic polynomial χA(x) =
det(xI
A). The aim of this paper is to describe all such matrices A that have the maximum
modulus of their eigenvalues at most 2. The signiﬁcance of the bound 2 is that, by a result
of Kronecker [K], every eigenvalue of such a matrix A is then of the form ω + ω−1, for some
root of unity ω. Thus znχA(z + 1/z) is a cyclotomic polynomial. For this reason we call
such integer symmetric matrices cyclotomic matrices.
In 1970 J.H. Smith [Smi] classiﬁed all cyclotomic

-matrices with zeros on the di-
agonal, regarding them as adjacency matrices of graphs (see Figure 9). Such graphs were
called cyclotomic graphs in [MS]. It turns out that a full description of cyclotomic matrices
is conveniently stated using more general graphs. So if we allow the oﬀ-diagonal elements of
our matrix to be chosen from the set
, we obtain a signed graph (see [CST],[Z2]),
}
a non-zero (i, j)th entry denoting a ‘sign’ of
1 or 1 on the edge between vertices i and j.
−
Further, for a general symmetric
matrix, where now the diagonal entries may be
nonzero, we obtain what we call a charged signed graph; we regard a nonzero (i, i)th entry
of A as corresponding to a ‘charge’ on its ith vertex. If none of the edges of a charged
signed graph in fact have sign
1, then we have a charged (unsigned) graph. However, a
graph is also a signed graph, and a signed graph is also a charged signed graph. The notion
of a charged signed graph is a convenient device for picturing and discussing symmetric
integer matrices with entries in
. These are the most important matrices in our
}
description of general cyclotomic matrices.

1, 0, 1

1, 0, 1

1, 0, 1

{−

{−

{−

−

}

}

{

In this paper we extend Smith’s result to cyclotomic charged signed graphs (Theorem 2),
and then, with little further work, to all cyclotomic matrices (Theorem 3). Along the way
we ﬁnd all cyclotomic signed graphs (Theorem 1). As a consequence, we can also describe
all cyclotomic charged graphs (Theorem 7) and all cyclotomic matrices whose entries are
non-negative (Theorem 9).

1

 
 
 
 
 
 
2

CYCLOTOMIC MATRICES

2, 2], it is then very natural to
Having obtained our results for the closed interval [
2, 2). We give a complete classi-
consider restricting the eigenvalues to the open interval (
ﬁcation of symmetric integer matrices with eigenvalues in this restricted set (Theorem 6).
As in the case of the closed interval, there are corresponding results for cyclotomic signed
graphs (Theorem 4), cyclotomic charged signed graphs (Theorem 5), cyclotomic charged
graphs (Theorem 8) and cyclotomic matrices whose entries are non-negative (Theorem 10).
Having dealt with the general cyclotomic case, this is a relatively straightforward problem.
There is a connection here with the theory of ﬁnite reﬂection groups and their Coxeter
graphs, and we conclude with a discussion of this.

−
−

In [MS], cyclotomic graphs were used to construct Salem numbers and Pisot numbers.
The original motivation for this current work was that it provides one of the ingredients
necessary to extend the work in [MS]. But we think that our results may be of independent
interest.

Throughout the paper, a subgraph of the (charged, signed) graph under consideration
will always mean a vertex-deleted subgraph, that is, an induced subgraph on a subset of
the vertices.

2. Interlacing, and reduction to maximal indecomposable matrices

In order to state our results, we need some preliminaries. The matrix A will be called
indecomposable if and only if the underlying graph is connected. (In the underlying graph,
vertices i and j are adjacent if and only if the (i, j)th entry of A is nonzero.) If A is not
indecomposable, then there is a reordering of the rows (and columns) such that the matrix
has block diagonal form with more than one block, and its list of eigenvalues is found
by pooling the lists of the eigenvalues of the blocks. For our classiﬁcation of cyclotomic
matrices, it is clearly suﬃcient to consider indecomposable ones.

A repeatedly useful tool for us is Cauchy’s interlacing theorem (for a short proof, see

[Fis]).

λ2

Lemma 1 (Interlacing Theorem). Let A be a real symmetric matrix, with eigenvalues
λ1
λn. Pick any row i, and let B be the matrix formed by deleting row i and
column i from A. Then the eigenvalues of B interlace with those of A: if B has eigenvalues
µ1

µn−1, then

. . .

. . .

≤

≤

≤

≤

≤

λ1

µ1

λ2

µ2

. . .

µn−1

λn .

≤

≤

≤

≤

≤

≤
In view of this Lemma, if A is cyclotomic, then so is any matrix obtained by deleting
from A any number of its rows, along with the corresponding columns: we then speak of
the smaller matrix as being contained in the larger one (the smaller graph is an induced
subgraph of the larger graph). We call an indecomposable cyclotomic matrix (or its graph)
maximal if it is not contained in a strictly-larger indecomposable cyclotomic matrix: the
corresponding cyclotomic graph is not an induced subgraph of a strictly larger connected
cyclotomic graph. We shall see that every non-maximal indecomposable cyclotomic ma-
trix is contained in a maximal one. It is therefore enough for us to classify all maximal
indecomposable cyclotomic matrices.

CYCLOTOMIC MATRICES

3

When we consider matrices that have all their eigenvalues in the open interval (

2, 2), we
shall see that it is no longer always true that every such matrix is contained in a maximal
one: there is an inﬁnite family of indecomposable exceptions.

−

3. Equivalence, strong equivalence and switching

×

Denote by On(Z) the orthogonal group of n

n signed permutation matrices. Then
conjugation of a cyclotomic matrix by a matrix in On(Z) gives a cyclotomic matrix with
the same eigenvalues. We say that two n
n cyclotomic matrices are strongly equivalent if
they are related in this way. Further, we say that two indecomposable cyclotomic matrices
A and A′ are merely equivalent if A′ is strongly equivalent to A or
A. This notion then
extends easily to decomposable cyclotomic matrices. Both of these notions are equivalence
relations on the set of all cyclotomic matrices. For indecomposable cyclotomic matrices,
the equivalence classes for the weaker notion are the union of one or two strong equivalence
A is in the same strong equivalence class as A. It
classes, depending on whether or not
is clearly suﬃcient to classify all cyclotomic matrices up to equivalence.

×

−

−

For a charged signed graph, the notions of strong equivalence and equivalence of course
carry over via the adjacency matrix. Now On(Z) is generated by diagonal matrices of
the form diag(1, 1, . . . , 1,
1, 1, . . . , 1) and by permutation matrices. Conjugation by these
diagonal matrices corresponds to reversing the signs of all edges incident at a certain vertex
v; we call this switching at v. Conjugation by a permutation matrix merely means that
we can ignore vertex labels; we therefore do not label the vertices of our graphs. Thus for
unlabelled charged signed graphs, strong equivalence classes are generated only by such
switching operations. The concept of switching, and signed switching classes, appeared
earlier for signed graphs in [CST].

−

Equivalence of charged signed graphs is generated both by switching, and by the oper-

ation of reversing all the edge signs and vertex charges of a component of a graph.

Since most of our graphs will in fact be signed graphs, we avoid clutter by drawing edges
1 as dashed lines - - - - - -.
−
respectively, with the vertices

with sign 1 as unbroken lines ———, and edges with sign
, –
For vertices, those of charge 1, 0,
(cid:13)

1 will be drawn +
(cid:13)

without a charge being called neutral vertices.

,
•

−

•

4. Main results

Theorem 1 (“Uncharged, signed, [
graph is equivalent to one of the following:

−

2, 2]”). Every maximal connected cyclotomic signed

(i) For some k = 3, 4, . . . , the 2k-vertex toral tesselation T2k shown in Figure 1;
(ii) The 14-vertex signed graph S14 shown in Figure 3;
(iii) The 16-vertex signed hypercube S16 shown in Figure 4.

Further, every connected cyclotomic signed graph is contained in a maximal one.

In particular, k = 3 of case (i) gives an octahedron T6, shown in Figure 5, while a more

typical example T24 is shown in Figure 2.

4

CYCLOTOMIC MATRICES

PSfrag replacements

A

B

......

A

B

Figure 1. The family T2k of 2k-vertex maximal connected cyclotomic toral
tesselations, for k
(The two copies of vertices A and B should be
identiﬁed, as in Figure 2 below.)

≥

3.

Figure 2. A typical toral tesselation T2k: the signed graph T24.

Figure 3. The 14-vertex sporadic maximal connected cyclotomic signed
graph S14. See also Section 14.2.

CYCLOTOMIC MATRICES

5

Figure 4. The hypercube sporadic maximal connected cyclotomic signed
graph S16.

Figure 5. The octahedral maximal connected cyclotomic signed graph T6.

Theorem 2 (“Charged, signed, [
signed graph not included in Theorem 1 is equivalent to one of the following:

2, 2]”). Every maximal connected cyclotomic charged

−

(i) For some k = 2, 3, 4, . . . , one of the two 2k-vertex cylindrical tesselations C ++

2k , C +−

2k

shown in Figure 6;

(ii) One of the three sporadic charged signed graphs S7, S8, S′

8 shown in Figure 7;

Further, every connected cyclotomic charged signed graph is contained in a maximal one.

In particular, k = 2 of case (i) gives two charged tetrahedra C ++

4

, C +−
4

, shown in Figure

8.

We remark that all the maximal cyclotomic graphs of Theorems 1 and 2 are ‘visibly’
2.

cyclotomic: their adjacency matrices A all satisfy A2 = 4I, so all their eigenvalues are
The exact multiplicity of these eigenvalues is given in Table 1 at the end of the paper.

±

Our most general result is readily deduced from the previous two theorems.

6

CYCLOTOMIC MATRICES

C ++
2k

C +−
2k

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

............

............

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

PSfrag replacements

Figure 6. The families of 2k-vertex maximal connected cyclotomic cylin-
drical tesselations C ++

2k and C +−

2k , for k

2.

≥

PSfrag replacements

(cid:0)(cid:1)

(cid:0)(cid:1)

S7

(cid:0)(cid:1)

S8

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

(cid:0)(cid:1)

S′
8

Figure 7. The three sporadic maximal connected cyclotomic charged
signed graphs S7, S8, S′
8.

PSfrag replacements

C ++
4

C +−
4

Figure 8. The two maximal connected cyclotomic charged signed tetrahe-
dra C ++

and C +−

.

4

4

Theorem 3 (“Integer matrix, [
is equivalent to one of the following:

−

2, 2]”). Every maximal indecomposable cyclotomic matrix

(i) The adjacency matrix of a maximal connected charged cyclotomic signed graph

(given by Theorems 1 and 2);

(ii) The 1

×

1 matrix (2) or the matrix

0 2
2 0(cid:19)

.

(cid:18)

Further, every indecomposable cyclotomic matrix is contained in a maximal one.

5. Simplifications

A signed graph G is called bipartite if its vertices can be split into two disjoint parts
such that every edge of G joins a vertex in one part to a vertex in the other ([Z3]). The
eigenvalues of G are then symmetric about 0, counted with multiplicity; we record this fact
as a Lemma.

Lemma 2. Let G be a bipartite signed graph with n vertices. Then

CYCLOTOMIC MATRICES

7

χG(

x) = (

1)nχG(x) .

−
Proof. One can mimic a standard proof for graphs (as in [Big, p. 11]; this result ﬁrst
appeared in a Chemistry paper [CoR]), or simply note that if one changes the signs of all
edges incident with vertices in one part then χG is unchanged, yet every edge has then
(cid:3)
changed sign so that χG(x) is changed to (

1)nχG(

x).

−

−

−

It will be convenient to extend the deﬁnition of bipartite to cover any charged signed
graph such that changing the sign of every edge and charge produces a graph that is
strongly equivalent to the original. For (neutral) signed graphs, this captures the usual
deﬁnition of being bipartite. The extension of Lemma 2 holds true for this larger class of
bipartite charged signed graphs, with the same proof.

A cycle of length r in a charged signed graph G is a list of distinct vertices v1, . . . , vr
such that there is an edge in G between vi and vi+1 (1
i < r) and between v1 and vr. A
charged signed graph without cycles is called a (charged signed) forest. A connected forest
is called a tree.

≤

Lemma 3 ([CST, Theorem 2.2]). Any charged signed forest is equivalent to one for which
all the edges are positive.

Proof. An easy induction on the number of vertices: for the inductive step consider remov-
(cid:3)
ing a leaf (a vertex with exactly one neighbour), unless there are no edges.

For detecting noncyclotomic integer symmetric matrices, the following trivial and obvi-

ous suﬃcient condition can be useful.

Lemma 4. Let A be an n
0, then A is not cyclotomic.

×

n integer symmetric matrix. If either χA(2) < 0 or (

1)nχA(

−

2) <

−

Lemma 5. Up to equivalence, the only indecomposable 1-by-1 or 2-by-2 cyclotomic matrices
are

(0) , (1) , (2) ,

0 1
1 0 (cid:19)

,

(cid:18)

1 1
1 0 (cid:19)

,

(cid:18)

1 1
1 1 (cid:19)

,

(cid:18)

1
1

(cid:18)

1
1 (cid:19)

−

and

0 2
2 0 (cid:19)

.

(cid:18)

Of these, the only maximal ones are (2) and

0 2
2 0 (cid:19)

.

(cid:18)

Proof. This is an easy computation, using Lemma 4 to constrain the matrix entries. For

example, to show that

0 2
2 0 (cid:19)

(cid:18)

is maximal, suppose that

0 2 a
2 0 b
c
a b

A = 






0 requires both

is cyclotomic. To achieve χ(2)
2(b

a)2

≥

0 and χ(

2)

−

≤

0, giving a = b = 0, so that A is not indecomposable.

2(a + b)2

−

0 and
(cid:3)

≥

−

≤

8

CYCLOTOMIC MATRICES

Lemma 6. Apart from matrices equivalent to either (2) or

0 2
2 0 (cid:19)

, any indecomposable

(cid:18)

cyclotomic matrix has all entries from the set
matrix of a cyclotomic charged signed graph.

{

0, 1,

1
−

}

. In other words, it is the adjacency

Proof. Let A = (aij) be an indecomposable cyclotomic matrix, not equivalent to either (2)

or

(cid:18)

0 2
2 0 (cid:19)

. Suppose ﬁrst that some diagonal entry of A had modulus at least 2, say

aii
|
Lemma 5 it equals

2. By interlacing (Lemma 1), the 1-by-1 matrix (aii) is cyclotomic, and then by
(2) and is maximal, so equals A, giving a contradiction.

| ≥

Next suppose that some oﬀ-diagonal entry aij had modulus at least 2. By interlacing, the

±

2-by-2 matrix

aii aij
aij ajj (cid:19)

(cid:18)

is cyclotomic, and by Lemma 5 this must equal

and is maximal, so equals A. Again we have a contradiction.

Thus no entry of A has modulus greater than 1.

0 2
,
2 0 (cid:19)

± (cid:18)

(cid:3)

We conclude that, apart from two (up to equivalence) trivial examples, all indecom-
posable cyclotomic matrices are the adjacency matrices of connected cyclotomic charged
signed graphs. Thus Theorem 3 follows from Theorems 1 and 2, and we can restrict our
attention to charged signed graphs.

6. Representation via Gram matrices

6.1. Gram matrices and line systems. Let A be the adjacency matrix of a cyclotomic
charged signed graph with n vertices.
2.
Hence A + 2I is positive semi-deﬁnite. This implies that we can ﬁnd vectors w1, . . . , wn in
real n-dimensional space such that A + 2I is their Gram matrix: the (i, j)-entry of A + 2I
is the dot product of wi and wj. The dimension of the space spanned by the wi might of
course be smaller than n.

In particular, A has all eigenvalues at least

−

A particularly simple case is that of a signed graph, where there are no charges. Then the
diagonal entries of A + 2I all equal 2, so that the vectors wi all have length √2. Moreover
the lines spanned by the wi meet each other with angles π/3 or π/2. In the language of
[CvL] we have represented our signed graph in a line system, and if the graph is connected
then the line system is indecomposable. If we change the sign of one of our Gram vectors,
then the line that it spans is unchanged, and the new Gram matrix is equivalent to the old
one: we have just changed the sign of all edges incident with the vertex that corresponds
to our Gram vector. Since we are working up to equivalence, we can ﬁx (at our discretion)
the direction of each line in our system.

Indecomposable line systems have been classiﬁed. Every such line system is contained
in a maximal one. It follows that every cyclotomic connected signed graph is contained in
a maximal one. Moreover we can hunt for these by looking inside the maximal indecom-
4) and
posable line systems. These are

8, which we now describe.

n (n

6.2. The line system and signed graph
orthonormal basis for Rn. The signed graph

D

≥

E
n. Fix n
D
n has n(n

D

2, and let e1, . . . , en be an
1) vertices, represented by the

≥
−

vectors

CYCLOTOMIC MATRICES

9

ei

ej

(1

i < j

n) .

≤
Adjacency of unequal vertices is given by the dot product of the corresponding vectors,
n, then A + 2I is
which always equals one of 0, 1,
the Gram matrix of the set of vectors.

1. If A is the adjacency matrix of

−

±

≤

D

6.3. The line system and signed graph
8. Let e1, . . . , e8 be an orthogonal basis for
E
R8, where, in contrast to the previous subsection, each ei has length √2. The signed graph
8 has 120 vertices, represented by the vectors e1, . . . , e8 and 112 vectors of the form

E

1
2(ei

ej

±

±

ek

±

eℓ) ,

where ijkℓ is one of the 14 strings

1234 , 1256 , 1278 , 1357 , 1368 , 1458 , 1467 ,
2358 , 2367 , 2457 , 2468 , 3456 , 3478 , 5678 .

(The referee has pointed out that these strings are the supports of the nontrivial words in
the extended binary Hamming code of length 8.)

D

n, adjacency of unequal vertices is given by the dot product (one of 0, 1,

As for
As a notational convenience, the vertices of

1).
8 will be written as strings of digits, some
of them overlined. Single digits 1, . . . , 8 refer to the basis vectors e1, . . . , e8. Strings of
eℓ)/2,
four digits, with any of the last three overlined, refer to the vectors (ei
with overlining indicating a minus sign. For example, 14¯6¯7 indicates the vector (e1 + e4
e6

−
We sum up this discussion with the following result. For the proof one trivially adapts
to signed graphs the argument for graphs in Chapter 3 of [CvL], noting that the fact that
we can have negative edges makes the argument signiﬁcantly easier.

e7)/2.

ek

ej

−

±

−

±

±

E

Proposition 7. Up to equivalence, the only (neutral) connected signed graphs that have
all their eigenvalues in [

) are the connected subgraphs of

2) and of

2,

8.

n (n

−
Signed graphs with all their eigenvalues in [

∞

) have been studied earlier by Vi-
jayakumar [V], Singhi and Vijayakumar [VS] and Ray-Chaudhuri, Singhi and Vijayakumar
[RSV].

∞

−

2,

≥

D

E

7. Cyclotomic signed graphs

In this section we prove Theorem 1, and so classify all cyclotomic signed graphs. The
plan is as follows. First we ﬁnd all the connected cyclotomic signed graphs that contain
triangles (triples of vertices with each pair being adjacent). Then, in view of Proposition 7,
8. We ﬁnd all maximal triangle-
it suﬃces to consider triangle-free subgraphs of
n, and observe the remarkable fact that they are all cyclotomic. We
free subgraphs of
then ﬁnd all maximal triangle-free subgraphs of
8: these are not all cyclotomic, and so we
need to search among their subgraphs for any new maximal connected cyclotomic signed
graphs that had not already been found as subgraphs of some

n and

D

D

E

E

n.

D

10

CYCLOTOMIC MATRICES

7.1. Reduction to triangle-free graphs.

Lemma 8. Suppose that G is a cyclotomic signed graph that contains a triangle on vertices
v, w, x (the signs of the three edges being arbitrary). If z is a fourth vertex in G then z is
a neighbour of an even number of v, w, x.

Proof. Direct computation of the small number of cases. One ﬁnds that if z is a neighbour
of one or three of v, w, x then the subgraph induced by v, w, x, z is not cyclotomic,
(cid:3)
contradicting G being cyclotomic, by interlacing.

If z is a neighbour of exactly two of v, w, x, then the subgraph induced by v, w, x, z is
not always cyclotomic, and the next lemma describes the extra condition on the signs of
the edges that is required for a cyclotomic graph.

Lemma 9. If G is a cyclotomic signed graph containing two triangles that share an edge,
then one triangle has an even number of negative edges, and the other has an odd number
of negative edges.

Proof. If two triangles share an edge and the parities of the numbers of negative edges
in the two triangles are equal, then one quickly checks that a suitable equivalence will
make all the edges on both triangles positive. But then the subgraph induced by the two
triangles is not cyclotomic (it has (1 + √17)/2 as an eigenvalue), and by interlacing neither
(cid:3)
is G.

Corollary 10. If G is a cyclotomic signed graph, then no three triangles can share a single
edge.

Corollary 11. If G is a cyclotomic signed graph, then it does not contain a tetrahedron
as an induced subgraph.

This latter Corollary also follows from Lemma 8.

Lemma 12. If G is a connected cyclotomic signed graph that contains a triangle, then it
is equivalent to a subgraph of the signed octahedron T6 of Figure 5.

Proof. Suppose that G is a connected cyclotomic signed graph that contains a triangle, on
vertices v1, v2, v3. By a suitable equivalence, we may suppose that the three edges of this
triangle are all positive. If G contains no other vertices then we are done.

Otherwise suppose that v4 is another vertex of G, joined to v1, say. By Lemma 8, v4
is adjacent to exactly one other of the vi. Relabelling if necessary, we suppose that v4 is
adjacent to v1 and v2. If G contains no other vertices then we are done.

Otherwise G contains a ﬁfth vertex v5, adjacent to at least one of v1, v2, v3, v4. By
Lemma 8, v5 is adjacent to two vertices on one of the triangles v1v2v3, v1v2v4, and hence
is adjacent to one of v1 or v2. By Corollary 10, v5 cannot be adjacent to both v1 and v2.
Without loss of generality, v5 is adjacent to v1. By Lemma 8 (using triangles v1v2v3 and
v1v2v4), v5 is also adjacent to both v3 and v4. If G contains no other vertices then we are
done.

CYCLOTOMIC MATRICES

11

Otherwise G contains a sixth vertex, v6, adjacent to one of v2, v3, v4, v5 (it cannot be
adjacent to v1, or else by Lemma 8 it would be adjacent to one of the others, producing
three triangles sharing an edge, contrary to Corollary 10). Applying Lemma 8 repeatedly,
we see that v6 must be adjacent to all of v2, v3, v4, v5.

We now have a subgraph of G that is equivalent to the signed octahedron pictured in
the Lemma (by Lemma 9 the parity of the number of negative edges on faces sharing an
edge must diﬀer, and up to equivalence one sees that there is just one choice of signs).

Finally, G can have no more vertices, as each existing triangle shares each of its edges
with another: we cannot adjoin a new vertex in a way that is compatible with both Lemma
(cid:3)
8 and Corollary 10.

Corollary 13. In a cyclotomic signed graph G, each vertex has degree at most 4.

Proof. If G contains a triangle then it is equivalent to a subgraph of the signed octahedron,
and hence has maximal degree at most 4. We may therefore assume that G is triangle-free.
If G has a vertex v of degree at least 5, then v has neighbours v1, . . . , v5 say (and
possibly others), and since G is triangle-free there are no edges between any pair of v1,
. . . , v5. By computation the starlike subgraph induced by v, v1, . . . , v5 is not cyclotomic
(up to equivalence all the edges are positive, so there is only one case to compute). This
(cid:3)
contradicts G being cyclotomic, by interlacing.

n. After Lemma 12, our search for
7.2. The maximal triangle-free subgraphs of
connected cyclotomic signed graphs can be restricted to triangle-free connected cyclotomic
signed graphs. After Proposition 7 we can hunt for these triangle-frees as subgraphs of
one of the
n, classifying all the maximal triangle-
free subgraphs. Fortunately for us (in view of our ultimate goal) these subgraphs are all
cyclotomic.

8. Here we deal with the

n, or of

D

D

D

E

ej

ej.
ej, then we say that v includes ei and ej. Note that v and v∗ have the same

n — so that i < j — deﬁne the conjugate vertex v∗ to be ei

∈ D

±

∓

For v = ei

If v = ei
neighbours in

±

n.

D

Lemma 14. Let G be a maximal triangle-free subgraph of
so is v∗.
Proof. If v∗ab is a triangle in G, then so is vab. Hence if G contained v but not v∗ we
could add v∗ to the vertex set and get a larger triangle-free signed graph, contradicting the
(cid:3)
maximality of G.

n. If v is a vertex of G, then

D

Lemma 15. Let G be a maximal triangle-free subgraph of
most four vertices of G.

D

n. Each ei is included in at

Proof. If ei is included at all, then take a vertex v including ei and ej (j

= i).

= i, k

Suppose ﬁrst that there exists a vertex w in G that includes ei and ek for some other
k (k
= i) we must have
either ℓ = j or ℓ = k, or else vwx would be a triangle. Hence ei is included exactly four
times, in v, w, v∗, w∗.

= j). Then if x is a vertex of G that includes ei and eℓ (ℓ

If no such w exists, then ei is included in exactly two vertices, v and v∗.

(cid:3)

6
6
6
6
12

CYCLOTOMIC MATRICES

D

n. The maximum degree of G
= b∗, then

Lemma 16. Let G be a maximal triangle-free subgraph of
is at most 4. Moreover if a vertex v in G has distinct neighbours a and b with a
v has four neighbours, a, b, a∗, b∗.
Proof. Take any vertex v in G. By relabelling, and moving to v∗ if necessary, we can
suppose that v = e1 + e2. Let w be a neighbour of v. Again after relabelling, and so on, we
can suppose that w = e2 + e3. Then w∗ is also a neighbour of v. If v has a third neighbour
x, then, in the same way, we can suppose that x = e1 + e4. Note that x cannot include e2,
by Lemma 15. Then x∗ is a fourth neighbour of v. By Lemma 15 again, there can be no
more neighbours, as these would have to include either e1 or e2, both of which have been
included four times already (in v, v∗, x, x∗ and in v, v∗, w, w∗ respectively).
(cid:3)

Recall that a path v1v2 . . . vm in G is a sequence of distinct vertices vi in G with vi

adjacent to vi+1 for i = 1, . . . , m

1.

−
Lemma 17. Let G be a maximal connected triangle-free subgraph of
P = v1v2 . . . vm be a path in G, maximal subject to no vi equalling any v∗

D

n, where n
j . Then

4. Let

≥

•
•

v1 and vm are adjacent, so that the induced subgraph on the vertices of P is a cycle.
P ∗ := v∗
m is a path in G disjoint from P , and G is the subgraph spanned by
P and P ∗.

1 . . . v∗

Proof. First suppose that v1 and vm are not adjacent. By Lemma 14, P ∗ is a subgraph of G.
No vertex in P can have more than two neighbours in P , else together with its neighbours
in P ∗ it would have more than four neighbours in G, contradicting Lemma 16. Without
loss of generality, v1 = e1 + e2, v2 = e2 + e3, . . . , vm−1 = em−1 + em, vm = em + em+1.

1, vi has neighbours vi−1, vi+1, v∗

i+1, so has no other neighbours
in G, by Lemma 16. By maximality of P , v1 and vm have no neighbours in G that are not
in P or P ∗, so P and P ∗ span a component of G, and hence span G. But then we could
add e1 + em+1 to G without introducing triangles, contradicting maximality of G.

Now for 2

i−1, v∗

m

−

≤

≤

i

Thus v1 and vm are adjacent, and without loss of generality v1 = e1 + e2, v2 = e2 + e3,
P ∗ has four neighbours
(cid:3)

. . . , vm−1 = em−1 + em, vm = e1 + em. Now each element of P
in P

∪
P ∗, so no others, and again P and P ∗ span the whole of G.

The proof of Lemma 17 establishes the ﬁrst sentence of the next result.

Proposition 18. Every maximal connected triangle-free signed graph that is a subgraph of
some

4) is equivalent to one with vertex set of the form

n (n

e1 + e2, e2 + e3, . . . , em−1 + em, e1 + em, e1

e2, e2

e3, . . . , em−1

em, e1

em ,

n. Moreover, every such graph is cyclotomic, and is a

−

−

−

−

for some m in the range 4
maximal connected cyclotomic signed graph.

m

≤

≤

Proof. It remains to prove that such a graph G is cyclotomic (maximality as a connected
cyclotomic signed graph follows from Corollary 13). For n = 4 one gets this by computation
= v∗
(or an easy adaptation of the following argument). For n > 4, note that if v and w
are distance 2 apart in G, then there are exactly two 2-paths from v to w, one along edges
of the same sign, and one along edges of opposite sign. There are four 2-paths from v to

∪

D

≥

6
6
CYCLOTOMIC MATRICES

13

v∗, two along edges of the same sign, and two along edges of opposite sign. Hence (with
A the adjacency matrix of G) all oﬀ-diagonal entries of A2 are zero. Since each vertex has
degree 4, we deduce that A2 = 4I. Hence all the eigenvalues are either 2 or
2, so G is
(cid:3)
cyclotomic.

−

e1. Then one of the n-cycles (say v1v2
en by en
−
n) has all negative edges. The linking edges of the form viv∗
v∗
1v∗
2 · · ·

A nice representative of the equivalence class of the maximal cyclotomic signed graph,
denoted T2n in the Theorem, described in Proposition 18 is obtained by replacing the vertex
vn) has all positive edges, and the
e1
−
other (v∗
i+1 (interpreted
cyclically) are all positive, and those of the form viv∗
i−1 are all negative. One gets a nice
picture if the two cycles are viewed as the ends of a cylinder. Alternatively, the graph can
be drawn on a torus without crossings, wrapping each cycle round the torus in such a way
that it cannot be shrunk to a point (as in Figure 2).

· · ·

E

8. The search for triangle-free sub-
7.3. The maximal triangle-free subgraphs of
graphs of
8 (up to equivalence) was done by computer, using moderately intelligent back-
tracking. A lexicographical ordering was given to the 120 vertices, and a set of equivalences
8 was precomputed (each as an explicit permutation of the 120 vertices), as follows.
of

E
We can change the sign of any ei: for any i

, we can swap the roles
of i and ¯i, which preserves all dot products. Then ﬂip the sign of any vector that is no
8, then
longer a vertex of
applying this process gives an equivalent (but perhaps diﬀerent) subgraph.

8. If G is a signed subgraph of

8 to induce an equivalence of

1, 2, 3, 4, 5, 6, 7, 8

∈ {

E

E

E

E

}

{

{

E

i, j, k, ℓ

1, 2, 3, 4, 5, 6, 7, 8

Some, but not all, permutations of

to induce a permutation of the vertices of

}
8 (and hence induce a permutation of the vertices of

induce a permutation of the lines
spanned by the vertices of
8). For
any string ijkℓ that appears as a vertex, we can apply elements of the Klein 4-group acting
on
8. For example, if we apply
(12)(56) to the vertex 1¯23¯4 we get the vector ¯123¯4, which spans the same line as the vertex
1¯2¯34, so the image of 1¯23¯4 under (12)(56) is 1¯2¯34. Note that such a transformation might
not be an isomorphism of signed graphs (since some of the vertices may be switched) but
will be an equivalence. Again, applying this to a subgraph of
8 will give an equivalent
subgraph.

E

E

E

}

Also, if ijkℓ is a vertex of

8, then we can perform a change of basis by the following
i¯j¯kℓ. This induces an equivalence on E. (It
four swaps: i
↔
is enough to check that this works for ijkℓ = 1234, and then use the previous symmetries
to reduce to this case.)

E
ij¯k ¯ℓ, k

i¯jk ¯ℓ, l

ijkℓ, j

↔

↔

↔

Starting with S being empty, the search grew S by adding the smallest possible ver-
tices (with respect to the chosen ordering) whilst (i) maintaining triangle-freeness, and
8 would map the enlarged S to a
(ii) checking that none of the above equivalences of
lexicographically earlier set. The use of equivalences was hugely powerful in cutting down
on the number of sets S considered by rejecting most sets at an early stage. When no more
vertices could be added, the set S was tested for maximality, and maximal triangle-frees
were written to a ﬁle. Then backtracking was done to ﬁnd the next candidate for S.
The following twenty inequivalent maximal triangle-free subgraphs were found.

E

14

CYCLOTOMIC MATRICES

G1 1, 2, 3, 4, 5, 6, 7, 8, 1234, 12¯3¯4, 1¯23¯4, 1¯2¯34, 5678, 56¯7¯8, 5¯67¯8, 5¯6¯78.

This is two copies of the toral tesselation T8.

G2 1, 2, 3, 4, 5, 6, 7, 8, 1234, 12¯3¯4, 1¯25¯6, 1¯2¯56, 3¯456, 3¯4¯5¯6.

This comprises two isolated vertices plus T12.

G3 1, 2, 3, 4, 5, 6, 7, 8, 1234, 12¯3¯4, 1¯25¯6, 1¯2¯56, 3¯47¯8, 3¯4¯78, 5678, 56¯7¯8.

This is T16.

G4 1, 2, 3, 4, 5, 6, 7, 8, 1234, 1¯25¯6, 1¯3¯57, 1¯46¯7, 2¯35¯8, 2¯4¯68, 3¯47¯8, 5678.

This is the hypercube S16.

G5 1, 2, 3, 4, 5, 6, 7, 8, 1234, 1¯25¯6, 1¯3¯57, 1¯46¯7, 2¯3¯6¯7, 2¯457, 3¯4¯5¯6.

This is an isolated vertex plus S14.

G6 1, 2, 3, 4, 5, 6, 1234, 12¯3¯4, 1¯25¯6, 1¯2¯56, 3¯47¯8, 3¯4¯78, 567¯8, 56¯78.

This is T14.

G7 1, 2, 3, 4, 5, 6, 1234, 12¯3¯4, 1¯27¯8, 1¯2¯78, 3¯47¯8, 3¯4¯78, 5678, 56¯7¯8.

This is a square plus T10.

G8 1, 2, 3, 5, 1278, 14¯6¯7, 2¯46¯8, 3456, 3¯4¯78, 5¯67¯8.

10 vertices, 2 cyclotomic components (both are 5-cycles).

By Corollary 13, S14 and S16 are maximal.
In the remaining cases, the larger component was noncyclotomic.
G9 1, 2, 3, 4, 5, 6, 1234, 1¯25¯6, 1¯3¯57, 1¯46¯7, 3¯47¯8, 567¯8.

12 vertices, 1 component, 29 maximal cyclotomic subgraphs (maximal in the

sense that no larger subgraph of G9 is cyclotomic).

G10 1, 2, 3, 4, 5, 6, 1234, 1¯27¯8, 1¯35¯7, 1¯4¯58, 3¯4¯7¯8, 5678.

12 vertices, 1 component, 13 maximal cyclotomic subgraphs.

G11 1, 2, 3, 4, 5, 6, 1234, 1¯27¯8, 1¯35¯7, 2¯457, 3¯4¯78.

11 vertices, 2 components (one being a single vertex), 15 maximal cyclotomic

subgraphs.

G12 1, 2, 3, 4, 5, 6, 1234, 1¯27¯8, 1¯35¯7, 2¯46¯8, 3¯4¯78, 5678.

12 vertices, 1 component, 15 maximal cyclotomic subgraphs.

G13 1, 2, 3, 4, 5, 6, 1234, 1¯27¯8, 1¯35¯7, 2¯46¯8, 5678, 5¯67¯8.

12 vertices, 1 component, 19 maximal cyclotomic subgraphs.

G14 1, 2, 3, 4, 5, 6, 1278, 1¯27¯8, 13¯5¯7, 235¯8, 3478, 5¯6¯78.

12 vertices, 1 component, 17 maximal cyclotomic subgraphs.

G15 1, 2, 3, 4, 5, 6, 1278, 1¯27¯8, 13¯5¯7, 24¯6¯8, 3478, 5¯6¯78.

12 vertices, 1 component, 37 maximal cyclotomic subgraphs.

G16 1, 2, 3, 4, 5, 1234, 1¯25¯6, 1¯36¯8, 2¯4¯68, 3¯47¯8, 56¯78.

11 vertices, 1 component, 44 maximal cyclotomic subgraphs.

G17 1, 2, 3, 4, 5, 1234, 1¯27¯8, 1¯3¯68, 2¯46¯8, 3¯4¯78, 5678.

11 vertices, 2 components: K2 plus a 9-vertex component; 36 maximal cyclotomic

subgraphs.

G18 1, 2, 3, 4, 5, 1256, 1¯27¯8, 13¯5¯7, 24¯6¯8, 3478, 3¯47¯8, 5¯6¯7¯8.

12 vertices, 1 component, 3-regular, 45 maximal cyclotomic subgraphs.

G19 1, 2, 3, 4, 5, 1278, 13¯6¯8, 1¯46¯7, 236¯7, 2¯4¯6¯8, 3¯478, 5¯6¯78.

CYCLOTOMIC MATRICES

15

12 vertices, 2 components: K2 plus a 3-regular 10-vertex component, equiva-
lent to the Petersen graph (switch at vertex 4 to get it) 57 maximal cyclotomic
subgraphs.

G20 1, 2, 3, 5, 1234, 1¯25¯6, 1¯36¯8, 2¯45¯7, 3¯4¯7¯8, 567¯8.

10 vertices, 1 component, 23 maximal cyclotomic subgraphs.

For each of the noncyclotomic components listed above, it was checked by computer that

none of their cyclotomic subgraphs are maximal cyclotomic graphs.

This completes the proof of Theorem 1.

E

8 that is not equivalent to a subgraph of any

8. Let G be a cyclotomic
7.4. An alternative view of the cyclotomic subgraphs of
E
r, with vertices given by
subgraph of
D
G, obtained from G by
vectors v1, . . . , vn, contained in 8-dimensional real space. Then
−
G is equivalent to G,
changing the signs of all edges and charges, is also cyclotomic. Now
−
r, so must be represented in the line system
so cannot be represented in any line system
G can be represented as vectors w1, . . . , wn, where for each

8, and hence the vertices of

D

E
i either wi or

−
wi is in the signed graph

8.

E

We can view the concatenated vectors [v1, w1], . . . , [vn, wn] as elements of 16-dimensional
8. Moreover, since

real space, a subset of the 28800 vectors [v, w] where v
the wi represent

G, we have

∈ E

∈ E

w

±

8,

−

−

for all i

= j. This implies that

wj =

wi

·

vi

−

·

vj

[vi, wi]

[vj, wj] = 0

·

= j: our concatenated vectors [v1, w1], . . . , [vn, wn] are pairwise orthogonal. Since
16, as is conﬁrmed by the

for all i
these vectors lie in 16-dimensional space, we must have n
examples computed in Section 7.3.

≤

Conversely, suppose that we take any orthogonal subset [v1, w1], . . . , [vn, wn] of the
28800 vectors considered above, with the constraint that v1, . . . , vn are distinct. Then the
signed graph G with vertices v1, . . . , vn (and adjacency of unequal vertices given by the
dot product) is cyclotomic, for both G and
8, with
−
w1, . . . , wn spanning the lines that represent

G are represented in the line system

G.

E

−

7.5. Remark on maximal cyclotomic (unsigned) graphs. The maximal cyclotomic
graphs classiﬁed by Smith are shown in Figure 9. The n-cycle ˜An−1 and the graph ˜Dn
are subgraphs of T2n, while the sporadic examples are all subgraphs of the hypercube S16.
Unlike in the signed case, however, the maximal unsigned graphs are not visibly cyclotomic.
We can deduce Smith’s classiﬁcation as a corollary of Theorem 1, by checking that these
graphs are the only maximal (unsigned) subgraphs of the signed graphs of the Theorem.
A useful fact to use in this check is that the graphs ˜D4 and ˜D5, since they have 2 as an
eigenvalue, cannot be a proper subgraph of any such graph. This is because otherwise the
graph would have an eigenvalue greater than 2 — see [CvR, p. 4].

We also note in passing that the classiﬁcation of all graphs having all their eigenvalues
2, 2) follows from Smith’s result. Such a graph is either a subgraph

in the open interval (

−

6
6
16

CYCLOTOMIC MATRICES

PSfrag replacements

˜E6

˜E7

˜E8

˜An
..

.

.

˜Dn
. . . .
. . . .

Figure 9. The maximal connected cyclotomic graphs ˜E6, ˜E7, ˜E8, ˜An(n
and ˜Dn(n
[MS]).

2)
4). The number of vertices is 1 more than the index. (From

≥

≥

8 (Figure 18). Here, E8 is ˜E8 (Figure 9) with its rightmost
of E8 or of some Dn for n
vertex removed (same as U5 in Figure 12), and Dn is ˜Dn with a leaf removed. See also
Theorem 10 below for a generalisation of this result.

≥

8. Cyclotomic charged signed graphs

We now embark upon the trickier task of proving Theorem 2, and so classifying all
cyclotomic charged signed graphs. The addition of charges means that we can no longer
appeal to Proposition 7, although the Gram matrix approach will still prove extremely
powerful.

8.1. Excluded subgraphs I. By interlacing, every subgraph of a cyclotomic charged
signed graph is cyclotomic. We can therefore exclude as subgraphs any that are not cyclo-
tomic. In particular, the following eight non-cyclotomic charged signed graphs X1, . . . , X8
of Figure 10 (or anything equivalent to any of them) cannot be subgraphs of any cylotomic
charged signed graph.
PSfrag replacements

X3

X2

X6

X7

X4

X8

X1

X5

Figure 10. Excluded subgraphs I: some noncyclotomic charged signed graphs.

8.2. Excluded subgraphs II. Certain cyclotomic charged signed graphs have the prop-
erty that if one tries to grow them to give larger connected cyclotomic graphs then one
always stays inside one of the maximal examples on the following list: S7, S8, S′
8, C ++
,
4

CYCLOTOMIC MATRICES

17

, C ++
6

, C +−
6

C +−
, T6. The process of proving that a cyclotomic graph has this property
4
is in principle simple, although perhaps tedious, to carry out. Starting from the given
graph, one considers all possible ways of adding a vertex (up to equivalence) such that the
graph remains connected and cyclotomic. Check that the resulting graphs are (equivalent
to) subgraphs of one of graphs on this list. Repeat with all the larger graphs found. If
the checks in this process are always valid, then, since the process terminates, the original
graph is suitable for exclusion.

By this technique, the six cyclotomic graphs Y1, . . . , Y6 of Figure 11 (and anything equiv-

PSfrag replacements

alent to them) can be excluded from future consideration.

Y1

Y2

Y3

Y4

Y5

Y6

Figure 11. Excluded subgraphs II: Some cyclotomic charged signed graphs
that are contained as subgraphs of a maximal connected cyclotomic charged
signed graph only in one of the maximal graphs S7, S8, S′
, C ++
,
6
C +−
6

8, C ++
4

, C +−
4

, T6.

8.3. Charged and neutral components. Let G be a charged signed graph. We deﬁne
the charged subgraph of G to be the subgraph induced by all its charged vertices, and
the neutral subgraph of G to be the subgraph induced by all its neutral vertices. The
components of the charged (respectively neutral) subgraph of G will be called the charged
components of G (respectively the neutral components of G).

Our next task will be to show that the charged components of a cyclotomic charged
signed graph are tiny, provided that G does not contain Y1, Y6, or any equivalent subgraph.

Lemma 19. Let G be a cyclotomic charged signed graph that does not contain any subgraph
equivalent to Y1 or Y6 of Section 8.2. Then each charged component of G contains at most
two vertices, necessarily of the same charge.

Proof. The last phrase is clear, since Y1 is excluded as a subgraph. Moreover the exclusion
of Y1 forces every charged component to have all charges of the same sign, which by
equivalence we may assume to be all positive. Since graphs X2 and X3 of Section 8.1 are
not cyclotomic, and Y6 is excluded by assumption, no charged component of G can have
(cid:3)
as many as three vertices.

8.4. Local geometric constraints.

Lemma 20. Let G be a cyclotomic charged signed graph. Suppose that G contains two
nonadjacent neutral vertices v and w that have a charged vertex x as a common neighbour.
Then v and w have the same neighbours.

18

CYCLOTOMIC MATRICES

Proof. Adjacency being unchanged by equivalence, we may suppose that the charge on x
has negative sign, and that the edges joining v and w to x are positive. The subgraph

PSfrag replacements

induced by v, w, x is then

v

x

w

.

Since G is cyclotomic, all eigenvalues of its adjacency matrix A are in [

), so A + 2I
is the Gram matrix of some set of vectors. Let v, w, x be the Gram vectors corresponding
to v, w, x. Since v and w are neutral, v and w have length √2. Since x has a negative
charge, x has length 1. The angle between v and x is π/4, the angle between w and x is
π/4, and the angle between v and w is π/2. Hence v, w, x are coplanar, with x in the
direction of v + w. By consideration of their lengths we have

∞

−

2,

Now let y be any other vertex of G, with corresponding Gram vector y. Taking dot

products with (1) gives

2x = v + w .

(1)

·
The left hand side of (2) is an even integer, hence the parities of the two integers on the
(cid:3)
right must agree. Hence y is adjacent to v if and only if it is adjacent to w.

·

·

2y

x = y

v + y

w .

(2)

Lemma 21. Let G be a cyclotomic charged signed graph containing adjacent charged ver-
tices v and w, where the signs on the charges for v and w agree. Then v and w have the
same neighbours.

Proof. Adjacency is preserved by equivalence, so we may suppose that the charges on v
and w are both negative, and that the edge between v and w is positive.
In the usual
way, let v and w be Gram vectors corresponding to v, w. These have length 1, and the
= w. Hence v and w have the same
angle between them is zero, so v = w, although v
(cid:3)
neighbours.

8.5. Removing charged components I. We now show that if a connected cyclotomic
charged signed graph does not contain a subgraph equivalent to any of the excluded sub-
graphs of Section 8.2, then it has a single neutral component. As a ﬁrst step, we show that
certain charged vertices can be deleted without disconnecting the graph.

Lemma 22. Suppose that a connected cyclotomic charged signed graph G has two adjacent
charged vertices v and w, with the charges on v and w having the same sign. Then the
vertex w can be deleted without disconnecting G.

Proof. By Lemma 21 every neighbour of v is a neighbour of w (and vice versa). Let x and
y be any distinct vertices in G, with neither of them being w. We must show that there is
a walk in G from x to y that does not pass through w. Certainly there is a path v1v2 . . . vr
in G from x to y (v1 = x, vr = y). Suppose that this path contains w, say vi = w. If either
vi−1 or vi+1 is v, then we can simply remove w from the path, since v shares its neighbours.
Otherwise we can replace w by v in the path (producing a walk, but perhaps no longer a
(cid:3)
path), again since v and w share their neighbours.

6
CYCLOTOMIC MATRICES

19

Lemma 23. Let G be a connected cyclotomic charged signed graph, with more than three
vertices, that contains no subgraph equivalent to either Y1 or Y4 of Section 8.2. Suppose
that G contains two nonadjacent neutral vertices v and w that share a common charged
neighbour x (as in Lemma 20). Then x can be deleted from G without disconnecting the
graph.

Proof. By the hypothesis on the number of vertices in G, there is some fourth vertex y in
G that is adjacent to one of v, w, x.

First we dispose of the cases where y is adjacent to x. If y has a charge, then since Y1 is
an excluded subgraph, y and x have charges of the same sign. Then Lemma 22 shows that
x can be removed without disconnecting G. If y is neutral, then since subgraphs equivalent
to Y4 are excluded, and a subgraph equivalent to X1 of Section 8.1 is impossible, y cannot
be adjacent to either v or w. But then G would contain a subgraph equivalent to X4 of
Section 8.1, which is not possible.

We may now suppose that y is not adjacent to x, and more strongly may suppose that
v and w are the only neighbours of x. By Lemma 20, v and w share all their neighbours.
In particular, y is adjacent to both v and w.

Let z1 and z2 be any vertices in G other than x. It is enough to show that there is a
walk in G from z1 to z2 that does not pass through x. Certainly there is a path v1v2 . . . vr
from z1 to z2 (v1 = z1, vr = z2). Suppose that x is on this path: say x = vi. We know that
vi−1 and vi+1 each equal one of v and w. We can therefore replace x by y in our path to
(cid:3)
produce the desired walk.

The requirement that G has more than three vertices is clearly necessary: if v, w, x are

the only vertices in G then deleting x disconnects G.

8.6. Removing charged components II.

Lemma 24. Let G be a connected cyclotomic charged signed graph that does not contain a
subgraph equivalent to Y1, Y4 or Y6 of Section 8.2. Suppose further that G has at least four
vertices. Then G contains a single neutral component: all charged vertices can be deleted
without disconnecting G.

Proof. By Lemma 19, all charged components have at most two vertices, and do not equal
Y1. By Lemma 22, we can remove a charged vertex from any charged component that
has two vertices, without disconnecting G. We are thus reduced to charged components
containing only one vertex.

If a charged vertex is a leaf, it can be removed without disconnecting G.
If a charged vertex has two neutral neighbours, then since subgraphs equivalent to X1
and Y4 are excluded we can appeal to Lemma 23 to see that this vertex can be removed
without disconnecting G.

No charged vertex can have three or more neutral neighbours, or G would contain a
(cid:3)

subgraph equivalent to one of X1, X4 or Y4.

20

CYCLOTOMIC MATRICES

8.7. Growing the neutral component. Let G be a connected cyclotomic charged signed
graph that contains at least four vertices, at least one of which is charged, but does not
contain any of the excluded subgraphs Y1, . . . , Y6. Then Lemma 24 tells us that G has a
single neutral component, H say. By interlacing, H is cyclotomic, and from the classiﬁca-
tion of all cyclotomic signed graphs we know that H is (equivalent to) a subgraph of one
of

r (for some r), S14 or S16. We treat each of these cases in turn.

D

≥

r. We may suppose that r is minimal such that

8.7.1. H is equivalent to a subgraph of
r
D
contains a subgraph equivalent to H. Cases with r
4 can be dealt with exhaustively by
growing each possible H in all possible ways, adding only charged vertices, and checking
that each maximal connected cyclotomic charged signed graph (maximal subject to the
neutral component being H) is contained in some C ++
2k . We may therefore suppose
that r

2k or C +−

≤

D

5.

D

≤

±

≤

i < j

ej for 1

Working up to equivalence, we identify H with some subgraph of

r (which has vertices
r, where e1, . . . , er is an orthonormal set of vectors). From our
ei
knowledge of the structure of cyclotomic signed graphs, we see that by relabelling and
changing signs of basis vectors (thereby inducing an equivalence), we can suppose that H
contains e1 + e2, e2 + e3, . . . , er−1 + er, and that all other vertices of H are of the form
ei

ei+1 (for some i in the range 1

−
Now suppose that w is a charged vertex in G. Since (i) G is connected, (ii) Y1 is an
excluded subgraph, and (iii) adjacent charged vertices that have the same charge share all
their neighbours (Lemma 21), we deduce that w is adjacent to one or more vertices in H.
We treat ﬁrst the case where w has charge
1. We have represented (a graph equivalent
−
to) H by a set of Gram vectors, where adjacency of unequal vertices is given by the dot
, where w is represented
product, and we can extend this to (a graph equivalent to) H
r+1
i=1 λiei. If w is in the span of e1, . . . , er, then we may set
by the Gram vector w =
er+1 = 0; otherwise we need an extra dimension for w, and take er+1 of length 1 and
orthogonal to all of e1, . . . , er. Since w has charge

1, w has length 1.

1), or e1

∪{

er.

P

≤

−

≤

±

w

}

r

i

We consider two subcases. Case 1 (which we shall prove to be impossible): H contains
er, so that H contains a cycle of length r containing no pair of conjugate

one or both of e1
vertices. Case 2: H contains neither of the vertices e1

±

er.

In Case 1, H contains at least one cycle of length r containing no pair of conjugate
vertices. Suppose that w were adjacent to at least two vertices on such a cycle, say x and
y (and perhaps others). Since subgraphs of G equivalent to Y4 have been excluded, and
G cannot contain a subgraph equivalent to X1, the vertices x and y are not adjacent. By
Lemma 20, every neighbour of x is a neighbour of y. But in a cycle of length at least 5
containing unadjacent vertices x and y and containing no pair of conjugate vertices, there
will be a neighbour of x that is not a neighbour of y.

±

−

Still in Case 1, suppose next that w is adjacent to exactly one vertex in some cycle
of length r containing no pair of conjugate vertices. Then G would contain a subgraph
equivalent to X6, giving a contradiction.

To kill oﬀ Case 1, we now consider the remaining subcase where w is adjacent to none
er. Then H must contain

of the vertices in the cycle e1 + e2, e2 + e3, . . . , er−1 + er, e1

±

CYCLOTOMIC MATRICES

21

at least one more vertex, and after some relabelling and equivalence we can assume that
w is adjacent to e1

e2, with a positive edge. Then

where the ‘

’ if r = 5. This gives

λ1 + λ2 = λ2 + λ3 = λ3 + λ4 = λ4

λ5 = 0 ,

±

−
λ2 = 1 ,

λ1

−
’ might be ‘

±
λ1 = 1/2 , λ2 =

−

1/2 ,

λ3 = 1/2 , λ4 =

1/2 ,

−

λ5 =

1/2 ,

±

−

and hence

w

> 1, giving a contradiction.

|

|

We now move to Case 2, where H contains the path formed by the vertices e1 + e2,
ei+1 (for some i in

e2 + e3, . . . , er−1 + er, and all other vertices in H are of the form ei
the range 1

1).

−

r

i

If w were adjacent to more than one vertex in our path, say x and y, then as in Case 1
we would have x and y unadjacent, implying that they share all their neighbours, giving a
contradiction.

≤

≤

−

If w were not adjacent to any vertex in our path, then it would be adjacent to some

ei+1, and from

ei

−

λi

λi+1 =

1 ,

λ1 + λ2 = λ2 + λ3 = . . . = λr−1 + λr = 0 ,

−

±

−

we would get at least ﬁve distinct j such that

λj

= 1/2, contradicting

w

= 1.

|

|
We are reduced to the case where w is adjacent to exactly one vertex in our path. Since
X6 is excluded as a subgraph, this neighbour of w must be an endvertex of our path.
Relabelling, we can suppose that w is attached to e1 + e2 by a positive edge, but to none
of e2 + e3, . . . , er−1 + er. If H also contained e1
e2, then w would necessarily be adjacent
to it, or else G would contain a subgraph equivalent to X7. Moreover, as e2 + e3 is joined
e2 by a negative edge, exclusion of subgraphs equivalent to X8 implies that w must
to e1
then be connected to e1

e2 by a positive edge.

−

−

|

|

±

To sum up, if the minimal value of r is at least 5, then we can assume that H contains the
ei+1.
−
er. If both
e2 are in H and w is adjacent to one of them, then it is adjacent to both; similarly
er. The excluded graph X8 constrains the signs of the edges that connect w to

vertices e1 + e2, e2 + e3, . . . , er−1 + er, and that all other vertices are of the form ei
Any negatively charged vertex w in G is adjacent to one of e1
of e1
±
for er−1
H. In short, H

2k or C +−
2k .
By equivalence, similar remarks hold for positively-charged vertices in G.
If more than one charged vertex in G is adjacent to the same vertex in H, then the
exclusion of subgraphs equivalent to Y2 and Y3 implies that these charged vertices are
adjacent to each other; the exclusion of subgraph Y1 implies that they all have the same
sign; Lemma 21 implies that there are at most two such. We conclude that G is equivalent
to a subgraph of one of the C ++

is equivalent to a subgraph of one of the C ++

e2 or er−1

∪ {

2k or C +−
2k .

±

±

w

}

8.7.2. H is equivalent to a subgraph of S16. We shall show that H is in fact equivalent to
r for some r, so that we are reduced to the previous case.
a subgraph of
Recalling previous notation, the vertices of S16 are labelled 1, 2, 3, 4, 5, 6, 7, 8, 1234,
1¯256, 1¯3¯57, 1¯4¯6¯7, 2¯358, 2¯46¯8, 3¯478, 5¯67¯8 (a trivial relabelling of G4). These are vectors
in 8-dimensional real space, with adjacency of unequal vectors given by the dot product.

D

22

CYCLOTOMIC MATRICES

Each vector has length √2. Our restrictions on G imply that it has no triangles except
perhaps involving two charged vertices and one neutral vertex.
1, 2, 3, 4, 5, 6, 7, 8

1234, 1¯256, 1¯3¯57,
. There is an equivalence of S16 that interchanges these two

Note that S16 is bipartite, with parts

1¯4¯6¯7, 2¯358, 2¯46¯8, 3¯478, 5¯67¯8
}
parts, induced by the orthogonal map with matrix

1 =

2 =

V

V

}

{

{

,



1
2











with respect to e1, . . . , e8.

1
1
1
1
0
0
0
0

1
1
−
0
0
1
1
0
0

1
0
1
−
0
1
−
0
1
0

1
0
0
1
−
0
1
−
1
−
0

0
1
1
−
0
1
0
0
1

0
0
1
1
−
0
0
1
1

0
1
0
1
−
0
1
0
1
−

0
0
0
0
1
1
−
1
1
−














Let w be a charged vertex in G. Arguing as before, w is adjacent to at least one vertex
in H. First we treat the case where w is adjacent to at least two vertices in H, say x and
y. Now x and y cannot be adjacent in G, or we would have a forbidden triangle equivalent
to X1 or Y4. Then by Lemma 20 the vertices x and y share all their neighbours (and they
must have at least one neighbour in H or H would not be connected).
It follows that
x and y are either both in
2. Working up to equivalence, and swapping
1 or both in
1. We may
V
also suppose that w is negatively charged, so that if we extend our set of Gram vectors
representing H (some subset of the vectors/vertices in
2) to a set of Gram vectors
V
representing H
, the vector w representing w will have length 1. We may write
9
i=1 λiei , where e9 (length √2, orthogonal to e1, . . . , e8) is included in case we need
w =
w
an extra dimension to make room for w. Since

V
2 as above if necessary, we may suppose that x and y are both in

= 1, we have

1 and

∪ V

∪ {

w

V

V

V

}

9

1

i=1 λ2

i = 1/2 .

P

If x and y correspond to i and j in our labelling of the vertices of S16, then from

|

|

P

w.ei =

1, w.ej =

±

1,

±

, and hence all other λk are zero.

(3)

we have λi, λj

1/2,

1/2

−

}

∈ {

,

}

{

}

}

}

{

{

=

i, j

1, 2

1, 8

and

3, 4, 5, 6

2, 4, 5, 7

1, 2, 7, 8

There are now essentially two cases (up to equivalence):

{
acting on any of the six ‘missing’ quartets

=
. Indeed there are self-equivalences of S16 induced by elements of the Klein 4-group
,
}
{
(one then needs to apply appropriate further transpositions of the
{
form (i i), and some changes of signs of certain vertices, to map S16 to itself). We see that
1 can be mapped to 1 by a self-equivalence of S16, and that with 1 ﬁxed,
any vertex in
V
any vertex in
1
\{
V
i, j
, since 1 and 2 are not adjacent, Lemma 20 implies that they
In the case
}
{
have the same neighbours in G, and hence also in H, whence 1¯3¯57, 1¯4¯6¯7, 2¯358, 2¯46¯8
H.
One of 1234 and 1¯256 has dot product
1 with w, and hence must be excluded from H (or
else together with w and 1 (or 2) we would have a forbidden triangle). Hence the vertices

can be mapped to 2.
1, 2

1, 3, 6, 8

1, 4, 5, 8

2, 3, 6, 7

1, 8
=

}
{

i, j

±

6∈

}

}

{

{

}

{

}

{

}

}

,

,

,

V

CYCLOTOMIC MATRICES

23

in H are a subset of

1
W

∪ W

2, where

1 =

W

{

1, 2, 3, 4, 5, 6, 7, 8, 3¯478, 5¯67¯8

,

}

2 =

W

1234

or

}

{

{

1¯256

,

}

depending on the signs of λ1 and λ2. Then H is readily seen to be equivalent to a subgraph
of

8.

D
For the other essentially distinct case,

1, 8
1, contradicting the connectedness of H.

a subset of

i, j

=

}

{

{

, similar reasoning shows that H is

}

We are left with the possibility that w is adjacent to exactly one vertex in H. Let us
temporarily call a signed charged graph K friendly if it is cyclotomic, contains exactly one
charged vertex w, the vertex w is joined to exactly one neutral vertex, and the neutral
vertices in K form a single component. In our current case, H
is friendly. It will be
enough to show that any friendly graph with neutral component equivalent to a subgraph
of either S16 or S14 is contained in a larger friendly graph (where the neutral component of
the larger friendly graph might or might not be equivalent to a subgraph of either S16 or
S14). For then we can grow our friendly graph H
w
}
with H ′ not equivalent to a subgraph of either S16 or S14. Then H ′ must be equivalent to
a subgraph of some

to a larger friendly graph H ′

r, and hence the same is true for H.

∪ {

∪ {

∪ {

w

w

}

}

A computer search checked that all friendly graphs with up to 14 neutral vertices are
contained in larger friendly graphs. As an indication of the work involved, some 377
friendly graphs with 15 vertices (14 neutral vertices) were considered; these would not all
have been inequivalent, as it proved more eﬃcient to perform a fast but imperfect weeding
out of equivalent graphs, allowing some repeats through. The search could have been
pushed further, but it was easier simply to check that there are no friendly graphs with 15
or 16 neutral vertices for which the neutral component is equivalent to a subgraph of S16.

D

8.7.3. H is equivalent to a subgraph of S14. The argument here is very similar to that
for S16, but in fact slightly simpler, as S14 has fewer vertices. Analogously, we have
. In the ‘unfriendly’
2
∪ W

V
case we ﬁnd that the vertices in H are (after a suitable equivalence) a subset of
where

1234, 1¯25¯6, 1¯3¯57, 1¯46¯7, 2¯3¯6¯7, 2¯457, 3¯4¯5¯6

1, 2, 3, 4, 5, 6, 7

1
W

2 =

1 =

V

{

}

{

}

,

1 =

1, 2, 3, 4, 5, 6

,

W

{

}

Then H is equivalent to a subgraph of

6.
D
This completes the proof of Theorem 2.

2 =

W

{

1234

or

1¯25¯6
}

{

.

}

9. Eigenvalues in the open interval (

2, 2)

−

9.1. Introduction to the next three sections. Sections 9,10 and 11 are devoted to re-
sults for matrices and graphs under further restrictions. These follow more or less straight-
forwardly from Theorems 1 and 2. We consider ﬁrst restricting to eigenvalues in the open
2, 2) (Section 9), deferring the proofs to Section 12. Then we consider charged
interval (
(unsigned) graphs, treating both the open and closed intervals (Section 10). Finally we
treat symmetric matrices that have non-negative integer entries (Section 11).

−

24

CYCLOTOMIC MATRICES

2, 2). Having classiﬁed all
9.2. Cyclotomic signed graphs with all eigenvalues in (
2, 2], a natural
integer symmetric matrices having all their eigenvalues in the interval [
2, 2). From
question is what happens if we restrict the eigenvalues to the open interval (
our knowledge of the closed interval case, we can immediately restrict to cyclotomic signed
graphs and cyclotomic charged signed graphs, and need only consider subgraphs of the
maximal ones.

−

−

−

2, 2)”). Up to equivalence, the connected signed graphs
Theorem 4 (“Uncharged, signed, (
2, 2) are the eleven 8-vertex
maximal with respect to having all their eigenvalues in (
sporadic examples U1, . . . , U11 shown in Figure 12, and the inﬁnite family O2k of 2k-cycles
with one edge of sign

8, shown in Figure 13.

1, for 2k

−

−

Further, every connected cyclotomic signed graph having all its eigenvalues in (

2, 2) is
either contained in a maximal one, or is a subgraph of one of the signed graphs Qhk of
Figure 14 for h + k

4.

−

−

≥

We note in passing that the graphs Ui can all be obtained from the cube U1 by deleting
certain edges. Not every choice of edge-deletion produces a Ui, however. For instance no
edge-deleted subgraph of U1 containing an induced subgraph equivalent to ˜D5 can have all
its eigenvalues in (

2, 2).

≥

−

U1

U2

U3

PSfrag replacements

U4

U6

U7

U5

U8

U9

U10

U11

Figure 12. The sporadic connected cyclotomic signed graphs maximal with
respect to having all eigenvalues in (

2, 2).

−

9.3. Cyclotomic charged signed graphs with all eigenvalues in (
have a corresponding result for charged signed graphs.

2, 2). Next we

−

CYCLOTOMIC MATRICES

25

Figure 13. The 2k-vertex connected cyclotomic signed graph O2k, maximal
with respect to having all eigenvalues in (

2, 2), shown here for k = 5.

PSfrag replacements

h

}|

z

......

−

k

{

z

}|
......

{

Figure 14. The doubly inﬁnite family Qhk of connected cyclotomic signed
2, 2) but not contained in a maximal one.
graphs having all eigenvalues in (

−

2, 2)”). Up to equivalence, the connected charged signed
Theorem 5 (“Charged, signed, (
2, 2), and not covered
graphs maximal with respect to having all their eigenvalues in (
by the Theorem 4 above, are the eight 4-vertex sporadic examples V1, V2, . . . , V8 shown in
Figure 17, and the inﬁnite family P ±

n of n-vertex charged paths of Figure 18 for n

4.

−

−

Further, every connected cyclotomic charged signed graph not covered by the previous

≥

theorem is contained in such a maximal one.

9.4. Cyclotomic matrices with all eigenvalues in (
vious two theorems, translated into matrix language, to obtain the following.

2, 2). We can combine the pre-

−

Theorem 6 (“Integer matrix, (
−
with repect to having all its eigenvalues in the open interval (
adjacency matrix of one of the graphs U1, U2, . . . , U11, O2k(2k
4) (given by Theorems 4 and 5).

2, 2)”). Every indecomposable cyclotomic matrix maximal
2, 2) is equivalent to the
−
8), V1, V2, . . . , V8, P ±

n (n

≥

≥

Further, every indecomposable cyclotomic matrix having all its eigenvalues in (

2, 2) is
either contained in a maximal one, or is contained in the adjacency matrix of one of the
signed graphs Qhk of Figure 14 for h + k
4.

−

≥

10. Maximal cyclotomic charged graphs

10.1. Cyclotomic charged unsigned graphs. We now restrict our attention to cyclo-
tomic charged graphs, looking for those that are maximal with respect to having all their
2, 2]. For such a graph G we need to deﬁne G as the graph whose edges
eigenvalues in [
are the same as those of G, with the same signs, but with the charges on vertices being
the opposite of those on G. For example, graphs V1 and V1 are shown in Figure 17. It is
clear that when G is a tree, G is equivalent to G.

−

One diﬀerence for this kind of maximality is that it is not a property of equivalence
classes of charged graphs: two of them may be equivalent with one of them maximal and

PSfrag replacements

26

CYCLOTOMIC MATRICES

the other not. For instance, one consequence of the next result is that for the maximal
graphs W5 and W6 the graphs W5 and W6, being subgraphs of W7, are not maximal.

However, we have the following.

2, 2]”). The maximal connected cyclotomic charged
Theorem 7 (“Charged, unsigned, [
graphs not covered by Smith’s result (i.e. not graphs), are the sporadic examples W1, . . . , W13
from Figure 15, along with W1, W11,W12, and the seven families Fn(n
5),
2) and In(n
Hn(n

2) from Figure 16.

5), Gn(n

3), Jn(n

3), Jn(n

3), In(n

−

≥

≥

≥

≥

≥

≥

≥

Further, every connected cyclotomic charged graph is contained in such a maximal one.

W1

W2

W3

W8

W9

W4

W10

W1
W10
W11
W12

W7

W5
W6

W11
W12
W13

Figure 15. The sporadic maximal connected cyclotomic charged graphs W1, . . . , W13.

PSfrag replacementsF5

F6

G6

H4

I4

G5

H3

I3

J2

J3

......

Fn

......
Gn

......
Hn

......
In

......
Jn

Figure 16. Five families of maximal connected cyclotomic charged graphs.
The smallest two members of each family are also shown.

The proof of this theorem is by inspection of the maximal connected cyclotomic charged
signed graphs of Theorem 2 to ﬁnd their maximal connected charged (unsigned) subgraphs.

CYCLOTOMIC MATRICES

10.2. Cyclotomic charged unsigned graphs with all eigenvalues in (
next have a corresponding result for eigenvalues in the open interval (

2, 2).

−

27

2, 2). We

−

Theorem 8 (“Charged, unsigned, (
maximal with respect to having all their eigenvalues in (
graphs V1, V1, V2, . . . , V5, from Figure 17, and P ±
for n

2, 2)”). The connected charged (unsigned) graphs
2, 2), are the graph U5, the charged
n of n-vertex charged paths of Figure 18

4.

−

−

Further, every connected cyclotomic charged graph not covered by Theorem 4 is contained

≥

in one of the above graphs.

Note that for n
its eigenvalues in (
graph maximal with respect to having all its eigenvalues in (

8 the graph Dn (Figure 18) is a subgraph of some Qhk. So it has all
2, 2) and is covered by Theorem 4. It is not contained in any charged

≥
−

2, 2).

−

PSfrag replacements

V4

V5

V6

V7

V8

V1

V1

V2

V3

Figure 17. The sporadic connected cyclotomic charged signed graphs max-
imal with respect to having all eigenvalues in (

2, 2).

−

PSfrag replacements

P ±
n
P +
n
P −
n
Pn

Dn

...........

...........

...........

...........

...........

Figure 18. The n-vertex charged paths P ±
(Theorem 10), P −

n , Pn (Section 13) and Dn (Theorem 10).

n (for Theorems 5, 6 and 8), P +

n

11. maximal cyclotomic symmetric non-negative integer matrices

In this section we record our results for non-negative cyclotomic matrices, i.e., those

integer symmetric matrices that are cyclotomic and have only non-negative entries.

28

CYCLOTOMIC MATRICES

2, 2]”). Up to conjugation by permutation
Theorem 9 (“Non-negative integer matrix, [
matrices, the only maximal indecomposable non-negative cyclotomic matrices are the ma-

−

trices (2) and

0 2
2 0(cid:19)

(cid:18)

, adjacency matrices of ˜E6, ˜E7, ˜E8, ˜An(n

2), ˜Dn(n

≥

≥

4) (Figure

9) along with the two families In(n

3) and Jn(n

2) (Figure 16).

≥

≥

Further, every indecomposable non-negative cyclotomic matrix is contained in such a

maximal one.

This result is readily deduced from Theorems 3,7 and Smith’s results (Figure 9).

2, 2)”). Up to conjugation by permutation
Theorem 10 (“Non-negative integer matrix, (
matrices, the only indecomposable non-negative cyclotomic matrix maximal with respect to
having all its eigenvalues in (

2, 2) is the adjacency matrix of U5 (Figure 12).

Further, every indecomposable non-negative cyclotomic matrix is either contained in the
n or Dn (Figure 18) for some

−
adjacency matrix of U5 or in the adjacency matrix of either P +
n.

−

12. Proofs of Theorems 4 and 5

To prove Theorem 4, we ﬁrst we show that the two inﬁnite families O2k, Qhk have their

eigenvalues in the open interval.

Suitable sets of Gram vectors, for the two cases, are:
For O2k, the columns of the (2k)

(2k) matrix (cij), where

×

cij = 


1 if i = j or i = j + 1
1 if (i, j) = (1, 2k)

−
0 otherwise .

For Qhk, the columns of the (h + k + 4)



(h + k + 4) matrix (qij), where

×

1 if i = j (j = 1, . . . , h + k + 4) or i = j + 1 (j = 1, 2, 3) or (i, j) = (2, k + 5)

1 (j = 5, . . . , k + 4, k + 6, . . . , h + k + 4)

qij =

1 if (i, j) = (1, 4)

−

or i = j



−
0 otherwise.


Note that both of these sets of columns are easily seen to be linearly independent. Hence,
in each case, for the adjacency matrix A of these signed graphs, A + 2I is non-singular, so
2 is not an eigenvalue. Since these families comprise bipartite graphs (in the extended
−
sense), 2 is not an eigenvalue. The families are cyclotomic, being subgraphs of Tn for some
n, so we are done.

Now we ﬁnd the remaining graphs.
For subgraphs of the sporadic graphs S14 and S16, we know that these are subgraphs of
8, and so can be embedded in R8, with A + 2I nonsingular. Hence such a subgraph can
E
have at most 8 vertices. These can be found by exhaustive search; the maximal ones are
U1, . . . , U11 and O8.

There remain the subgraphs of the inﬁnite families.

We observe that:

CYCLOTOMIC MATRICES

29

an hour-glass
the classical ˜Dn graphs (see Figure 9) have 2 as an eigenvalue.

, equivalent to an unsigned square, has 2 as an eigenvalue;

•
•

Hence the subgraph can contain at most one pair of conjugate vertices. So it is either a
path, a cycle, some Qhk or Q′
k, deﬁned to be Q1k with its two leaves identiﬁed. A path is
a subgraph of some Qhk, while a cycle must be equivalent to some O2k, for otherwise it is
equivalent to a cycle with all positive edges for which 2 is an eigenvalue. For Q′
k, we can
delete one of its pair of conjugate vertices to obtain a graph equivalent to a cycle with all
positive edges.

This completes the proof of Theorem 4.
The proof of Theorem 5 is similar. We can assume that the charged graphs we seek do
indeed have at least one charged vertex. The relevant subgraphs of S7, S8 and S′
8 are found
by exhaustive search. For the subgraphs of C ++
2k , we see by the same argument
as above that the neutral component can contain at most one pair of conjugate vertices.
Hence the neutral component is a path, or some Qhk.
Two adjacent charges of the same sign have one of

2 as an eigenvalue, so each charged
component has exactly one charge. Putting charges of the same sign at each end of a
path would give one of
2 as an eigenvalue, as one can see by writing down an obvious
eigenvector.

2k and C +−

±

±

Putting a charge on either end of some Qhk gives one of

2 as an eigenvalue. To see this it
suﬃces to consider adding a negative charge to one end, with corresponding column vector
(0, . . . , 0, 1)T to add to (qij), and adding a row of zeroes to (qij) to make it square, giving
n (and its subgraphs) as
a singular matrix, and hence
the only possibilities.

2 as an eigenvalue. This leaves P ±

−

±

For P ±

n , the columns of the n

n matrix (pij), where

×
√2 if (i, j) = (1, 1)
1 if i = j or i = j + 1 (i
0 otherwise ,

2)

≥

pij = 


are easily seen to be linearly independent. Again, for the adjacency matrix A of this
bipartite charged signed graph, A + 2I is non-singular, so
2 is not an eigenvalue, and
hence neither is 2.

−



This completes the proof of Theorem 5. Theorem 8 then follows easily.

13. The cyclotomic polynomials of charged signed graphs

Table 1 gives the reciprocal polynomials of the maximal connected cyclotomic charged
signed graphs that appear in our results. All are maximal in the sense explained where
they appear, apart from the Qhk which, as we have seen, do not belong to any connected
2, 2).
cyclotomic charged signed graph maximal with respect to having all eigenvalues in (
Note, however, that the polynomials associated to C ++
2k and S7 will need changes of variable

−

30

x, z

x
7→ −
another.

CYCLOTOMIC MATRICES

z when going from one equivalent, but not strongly equivalent, graph to

7→ −

(z2

T2k
S14
S16
C ++
2k
C +−
2k
S7
S8, S′
8

Charged signed graph Characteristic polynomial Associated cyclotomic polynomial
2)k
2)7
2)8
2)k+1
2)k
2)4
2)4
Table 1. The characteristic and cyclotomic polynomials of maximal cyclo-
tomic charged signed graphs.

1)2k
(k
−
1)14
(z2
−
1)16
(z2
−
1)2k+2(z + 1)2k−2
1)2k
(z2
(z + 1)6(z
(z2

(x + 2)k(x
(x + 2)7(x
(x + 2)8(x
(x + 2)k−1(x
(x + 2)k(x
(x + 2)3(x
(x + 2)4(x

−
−
−
−
−
−
−

(k
2)

−
1)8

≥
1)8

(k

2)

3)

(z

−

≥

−

−

≥

Table 2 gives the reciprocal polynomials of the cyclotomic signed graphs of Theorems 4
and 5, shown in Figures 12, 14, 17, 13 and 18. In the table, Φn denotes the nth cyclotomic
polynomial.

For a single sporadic graph with adjacency matrix A, the reciprocal polynomial znχA(z +
1/z) can be easily calculated. For the inﬁnite families, more work is required. Here, for
convenience, we use the same notation for a graph and its associated cyclotomic polynomial.
For computing formulae for families of associated cyclotomic polynomials, a standard
A), where A is the
tool will be to use induction on the determinant det((z + 1/z)I
adjacency matrix of the graph under consideration. In this way it is easy ﬁrst to compute
the the n-vertex (unsigned) path Pn, giving Pn = (z2n+2
1), as in the table (see also
[MS]). Then expansion by the ﬁrst row of the determinant gives P −
1).
Also P ±

n is readily calculated, again expanding in the same way.

n = (z2n+1

1)/(z2

1)/(z

−

−

−

−

−

For O2k, determinant expansion ﬁrstly along the top row, and then down the left rows
2z2P2k−2 + 2z2k, and hence the

of the resulting determinants gives O2k = (z2 + 1)P2k−1
result.

−

For Qhk, the formulae for Q1k and Q2k can be proved by induction, using the determinant,
n . These can then be used as the base cases for an inductive

in a similar way to that for P −
proof of the Qhk formula.

−

2, and (1,

For T2k, label its top vertices 1, 3, 5, . . . , 2k
with 2 the conjugate vertex to vertex 1. Then (
T2k with eigenvalue
both associated to the hourglass [1, 2, 3, 4]. From the symmetry of T2k that acts by i
mod 2k on its vertices, we get two eigenvectors, with eigenvalues
hourglasses [3, 4, 5, 6], [5, 6, 7, 8], . . . , [2k
so that T2k has characteristic polynomial (x + 2)k(x
gives the result.

1 and the bottom vertices 2, 4, 6, . . . , 2k,
1, 1, 1, 1, 0, . . . , 0) is an eigenvector of
1, 1, 1, 0, . . . , 0) is an eigenvector of T2k with eigenvalue 2,
i+2
2 and 2 for each of the
−
1, 2k, 1, 2]. These eigenvectors are independent,
2)k, which, on putting x = z + 1/z,

7→

−

−

−

−

−

CYCLOTOMIC MATRICES

31

Charged signed graph Associated cyclotomic polynomial

O2k
Qhk
U1
U2
U3
U4
U5
U6, U9
U7, U11
U8
U10
V1
V1, V4
V3, V6
V2, V5
V7, V8
Pn
P −
n
P ±
n

(h + k

4)

≥

(z2k + 1)2
(z2h+4 + 1)(z2k+4 + 1)
Φ4
6(z2)
Φ20(z2)
Φ24(z2)
Φ6(z2)Φ18(z2)
Φ30(z2)
12(z2)
Φ2
Φ15(z2)
Φ12(z2)Φ2
Φ2
10(z2)
Φ15(z)
Φ30(z)
Φ20(z)
Φ24(z)
Φ2
12(z)
(z2n+2
1)/(z2
−
(z2n+1
1)/(z
−
z2n + 1 (n

6(z2)

1)
1)

−
−
4)

≥

Table 2. The cyclotomic polynomials of some charged signed graphs having
all their eigenvalues in (

2, 2).

−

−

−

For C ++
2k , label the vertices as for T2k. For the hourglasses [3, 4, 5, 6], . . . , [2k
3, 2k

−
2] (those without charged vertices), we get the same eigenvectors as for T2k,
4, 2k
1, 2k] give the
with the same eigenvalues. The hourglasses [1, 2, 3, 4] and [2k
−
same eigenvectors as for T2k with eigenvalue
2. For the hourglass [1, 2, 3, 4], however, we
−
also get two independent eigenvectors (1, 1, 0, . . . , 0) and (2, 0, 1, 1, 0, . . . , 0) with eigenvalue
1, 2k] we get two more independent eigenvectors
2, and from the hourglass [2k
(0, . . . , 0,
2k has characteristic
polynomial (x + 2)k−1(x

−
2)k+1, giving the result.

−
1, 0, 2) with eigenvalue 2. Thus C ++

1, 1) and (0, . . . , 0, 1,

2, 2k

3, 2k

2, 2k

5, 2k

3, 2k

−

−

−

−

−

2k , note that this is bipartite in the extended sense, so that the eigenvalues 2 and

−
For C +−
2 have equal multiplicities.

−

−

14. Final remarks

14.1. Finite reﬂection groups. Given the root system Φ of a ﬁnite reﬂection group, one
classically looks for a subset ∆ that is a simple system, namely one that is a basis for
the R-span of Φ and such that every element of Φ is a linear combination of elements of
∆ with all coeﬃcients weakly of the same sign. The Coxeter graph of a simple system

32

CYCLOTOMIC MATRICES

is determined by the reﬂection group, and provides a means of classifying ﬁnite reﬂection
groups.

If we have a signed graph with all eigenvalues in (

2, 2) then (as we have seen) its
vertices can be associated with a linearly independent set ∆′ of vectors, and the reﬂection
group generated by the hyperplanes orthogonal to those vectors is a ﬁnite reﬂection group.
The closure of ∆′ under this reﬂection group is a root system Φ: in the language of [CvL]
we are taking the star closure of the lines spanned by the elements of ∆′.

Our set ∆′ will not generally be a simple system for Φ, but it will be a basis for the
R-span of Φ. The unsigned version of our graph (making all edges positive) is the Coxeter
graph of ∆′.

−

The neutral signed graphs of Theorem 4 therefore provide a classiﬁcation of all Coxeter
4)
8 using eight reﬂections whose Coxeter graph is the

graphs coming from bases for the R-span of root systems contained in either
or
cube U1 of Figure 12.

8. For example, one can generate

n (n

≥

D

E

E

For other connections between signed graphs and Coxeter graphs and roots systems see

[CST] and [Z1].

14.2. The graph S14. Robin Chapman has pointed out that, up to equivalence, the signed
label the vertices 0, 1, . . . , 6, 0′, 1′, . . . , 6′
graph S14 of Figure 3 can be deﬁned as follows:
and, working modulo 7, for each i join i to each of i′, (i + 1)′ and (i + 3)′ by positive edges,
1)′ by a negative edge. The representation of S14 in the ﬁgure is based
and join i to (i
on this observation.

−

14.3. Chebyshev polynomials and cyclotomic matrices. Let
Chebyshev polynomial of the ﬁrst kind, deﬁned on the interval [
coeﬃcients and satisﬁes

−

T
2, 2]. So

n(x) denote the nth
n(x) has integer

T

z +

n
T

(cid:18)

1
z (cid:19)

= zn +

1
zn .

(4)

Then for any cyclotomic matrix A, the matrix

from diagonalizing A and using (4).

n(A) is again cyclotomic. This follows

T

14.4. Acknowledgments. The authors are grateful for the hospitality provided by the
University of Bristol during the time that this paper was written. We thank John Byatt-
Smith for producing Figure 2.

References

[Big] Biggs, Norman. Algebraic graph theory. Second edition. Cambridge University Press, Cambridge,

1993.

[CST] Cameron, P. J.; Seidel, J. J.; Tsaranov, S. V. Signed graphs, root lattices, and Coxeter groups. J.

Algebra 164 (1994), no. 1, 173–209.

[CvL] Cameron, P. J.; van Lint, J. H. Designs, graphs, codes and their links. Cambridge University Press,

Cambridge, 1991.

[CoR] Coulson, C.A. and Rushbrooke, G.S., Note on the method of molecular orbitals, Proc. Camb. Phil.

Soc. 36 (1940), 193-200.

CYCLOTOMIC MATRICES

33

[CvR] Cvetkovi´c, D.; Rowlinson, P. The largest eigenvalue of a graph: a survey. Linear and Multilinear

Algebra 28 (1990), no. 1-2, 3–33.

[Fis] S. Fisk, A very short proof of Cauchy’s interlace theorem, Amer. Math. Monthly 112 (2005), 118.

Also arXiv:math.CA/0502408v1.

[K] Kronecker, Leopold.: Zwei s¨atse ¨uber Gleichungen mit ganzzahligen Coeﬃcienten, J. Reine Angew.
Math. 53 (1857), 173–175. See also Werke. Vol. 1, 103–108, Chelsea Publishing Co., New York, 1968.
[MS] McKee, James; Smyth, Chris. Salem numbers, Pisot numbers, Mahler measure, and graphs. Exper-

iment. Math. 14 (2005), no. 2, 211–229.

[RSV] Ray-Chaudhuri, D. K.; Singhi, N. M.; Vijayakumar, G. R. Signed graphs having least eigenvalue

around

2. J. Combin. Inform. System Sci. 17 (1992), no. 1-2, 148–165.

−

[SV] Vijayakumar, G. R.; Singhi, N. M. Some recent results on signed graphs with least eigenvalues

2.
Coding theory and design theory, Part I, 213–218, IMA Vol. Math. Appl., 20, Springer, New York,
1990.

≥ −

[Smi] Smith John H. Some properties of the spectrum of a graph. 1970 Combinatorial Structures and their
Applications (Proc. Calgary Internat. Conf., Calgary, Alta., 1969), pp. 403–406, Gordon and Breach,
New York.

[V] Vijayakumar, G. R. Algebraic equivalence of signed graphs with all eigenvalues

35 (1993), 173–191.

2. Ars Combin.

≥ −

[VS] Vijayakumar, G. R.; Singhi, N. M. Some recent results on signed graphs with least eigenvalues

2.
Coding theory and design theory, Part I, 213–218, IMA Vol. Math. Appl., 20, Springer, New York,
1990.

≥ −

[Z1] Zaslavsky, Thomas. The geometry of root systems and signed graphs. Amer. Math. Monthly 88 (1981),

no. 2, 88–105.

[Z2] Zaslavsky, Thomas. Signed graphs. Discrete Appl. Math. 4 (1982), 47–74. Erratum 5 (1983), no. 2,

248.

[Z3] Zaslavsky, Thomas. Signed analogs of bipartite graphs. Discrete Math. 179 (1998), no. 1-3, 205–216.

Department of Mathematics, Royal Holloway, University of London, Egham Hill, Egham,

Surrey TW20 0EX, UK

School of Mathematics and Maxwell Institute for Mathematical Sciences, University
of Edinburgh, James Clerk Maxwell Building, King’s Buildings, Mayfield Road, Edin-
burgh EH9 3JZ, UK

"
On mappings of terms determined by hypersubstitutions,"  The extensions of hypersubstitutions are mappings on the set of all terms. In
the present paper we characterize all hypersubstitutions which provide
bijections on the set of all terms. The set of all such hypersubstitutions
forms a monoid. On the other hand, one can modify each hypersubstitution to any
mapping on the set of terms. For this we can consider mappings from the set of
all hypersubstitutions into the set of all mappings on the set of all terms.
","8
0
0
2

v
o
N
0
2

]

A
R
.
h
t
a
m

[

1
v
5
2
3
3
.
1
1
8
0
:
v
i
X
r
a

ON MAPPINGS OF TERMS DETERMINED BY
HYPERSUBSTITUTIONS

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

Abstract. The extensions of hypersubstitutions are mappings on the
set of all terms. In the present paper we characterize all hypersubsti-
tutions which provide bijections on the set of all terms. The set of all
such hypersubstitutions forms a monoid.

On the other hand, one can modify each hypersubstitution to any
mapping on the set of terms. For this we can consider mappings ρ from
the set of all hypersubstitutions into the set of all mappings on the set of
all terms. If for each hypersubstitution σ the application of ρ(σ) to any
identity in a given variety V is again an identity in V , so that variety is
called ρ-solid. The concept of a ρ-solid variety generalizes the concept
of a solid variety. In the present paper, we determine all ρ-solid varieties
of semigroups for particular mappings ρ.

1. Basic Definitions and Notations

We ﬁx a type τ = (ni)i∈I , ni > 0 for all i ∈ I, and a set of operation
symbols Ω := {fi | i ∈ I} where fi is ni-ary. Let Wτ (X) be the set of
all terms of type τ over some ﬁxed alphabet X = {x1, x2, . . .}. Terms in
Wτ (Xn) with Xn = {x1, . . . , xn}, n ≥ 1, are called n-ary. For natural
numbers m, n ≥ 1 we deﬁne a mapping Sn
m : Wτ (Xn) × Wτ (Xm)n →
Wτ (Xm) in the following way: For (t1, . . . , tn) ∈ Wτ (Xm)n we put:
(i) Sn
(ii) Sn

m(xi, t1, . . . , tn) := ti for 1 ≤ i ≤ n;
m(fi(s1, . . . , sni), t1, . . . , tn) := fi(Sn
. . . , tn)) for i ∈ I, s1, . . . , sni ∈ Wτ (Xn) where Sn
. . . , Sn

m(sni, t1, . . . , tn) will be assumed to be already deﬁned.
If it is obvious what m is, we write Sn. For t ∈ Wτ (X) we deﬁne the

m(s1, t1, . . . , tn), . . . , Sn

m(s1, t1, . . . , tn),

m(sni, t1,

depth of t in the following inductive way:
(i)
(ii) depth(t) := max{depth(t1), . . . , depth(tni)} + 1

depth(t) := 0 for t ∈ X;

for t = fi(t1, . . . , tni)with i ∈ I, t1, . . . , tni ∈ Wτ (X) where
depth(t1), . . . , depth(tni) will be assumed to be already deﬁned.
By c(t) we denote the length of a term t (i.e. the number of the variables
occurring in t), var(t) denotes the set of all variables occurring in t and cv(t)
means the number of elements in the set var(t). Instead of x1, x2, x3, . . . we
write also x, y, z, . . ..

2000 Mathematics Subject Classiﬁcation. Primary: 20M14; Secondary: 20M07.
Key words and phrases. ρ-solid, hypersubstitution, bijection.

1

 
 
 
 
 
 
2

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

The concept of a hypersubstitution was introduced in [2].

Deﬁnition 1. A mapping σ : Ω → Wτ (X) which assigns to every ni-ary
operation symbol fi, i ∈ I, an ni-ary term is called a hypersubstitution of
type τ (shortly hypersubstitution). The set of all hypersubstitutions of type
τ will be denoted by Hyp(τ ).

To each hypersubstitution σ there belongs a mapping from the set of all
terms of the form fi(x1, . . . , xni) to the terms σ(fi). It follows that every
σ : Wτ (X) → Wτ (X)
hypersubstitution of type τ then induces a mapping
b
as follows:
(i)
(ii)

σ[t1], . . . ,
b

σ[tni]) for i ∈ I, t1, . . . , tni
b

σ[tni] will be assumed to be already
b

σ[w] := w for w ∈ X;
b
σ[fi(t1, . . . , tni)] := Sn(σ(fi),
b
∈ Wτ (X) where
deﬁned.
By σ1 ◦h σ2 :=

σ[t1], . . . ,
b

σ1 ◦ σ2 is deﬁned an associative operation on Hyp(τ )
b
where ◦ denotes the usual composition of mappings. By ε we denote the
hypersubstitution with ε(fi) = fi(x1, . . . , xni) for i ∈ I, where ε deals as
identity element. Then (Hyp(τ ); ◦h, ε) forms a monoid, denoted by Hyp(τ ).

2. Bijections on Wτ (X)

By Bij(τ ) we denote the set of all σ ∈ Hyp(τ ) such that

σ : Wτ (X) →
b
Wτ (X) is a bijection on Wτ (X). Such hypersubstitutions have a high im-
portance in computer science.

The product of two bijections is again a bijection. Further, for two hy-

persubstitutions σ1 and σ2 we have

σ1 ◦
b
(see [3]). So we have the following result.

(σ1 ◦h σ2)
b

=

σ2
b

Proposition 1. (Bij(τ ); ◦h, ε) forms a submonoid of Hyp(τ ).

For the characterization of Bij(τ ) we need the following notations:
(i) B denotes the set of all bijections on Ω preserving the arity.
(ii) Let Sn be the set of all permutations of the set {1, . . . , n}

for 1 ≤ n ∈ N.

(iii) A := S

1≤n∈N

Sn.

(iv) P := {p ∈ AI | p(i) ∈ Sni for i ∈ I}.
The following theorem characterizes Bij(τ ) for any type τ .

Theorem 1. Let τ = (ni)i∈I , ni > 0 for all i ∈ I, be any type. For each
σ ∈ Hyp(τ ) the following statements are equivalent:

σ ∈ Bij(τ ).

(i)
(ii) There are h ∈ B and p ∈ P such that

σ(fi) = h(fi)(xp(i)(1), . . . , xp(i)(ni)) for all i ∈ I.

with

σ[
b

s] = s.
e

ON MAPPINGS OF TERMS DETERMINED BY HYPERSUBSTITUTIONS

3

Proof. (ii) ⇒ (i) : We show by induction that

Injectivity: Let s, t ∈ Wτ (X) with
σ[s] =
b
Suppose that the depth(s) = 0. Then depth(t) = 0 and s, t are variables

σ is injective and surjective.
b
σ[t].
b

with s =

σ[s] =
b
Suppose that from

σ[t] = t.
b

with depth(s‘) ≤ n.

σ[s‘] =
b

σ[t‘] there follows s‘ = t‘ for any s‘, t‘ ∈ Wτ (X)
b

Let depth(s) = n + 1. Then depth(t) ≥ 1 and there are i, j ∈ I with

s = fi(s1, . . . , sni) and t = fj(t1, . . . , tnj ). Now we have

σ[s] = Sni(h(fi)(xp(i)(1), . . . , xp(i)(ni)),
σ[s1], . . . ,
σ[sni]) and
b
b
b
σ[t] = Snj (h(fj)(xp(j)(1), . . . , xp(j)(nj )),
σ[tnj ]). From
σ[t1], . . . ,
b
b
b

it follows that h(fi) = h(fj) and thus fi = fj, i.e.
bijection. Hence Sni(h(fi)(xp(i)(1), . . . , xp(i)(ni)),

= Sni(h(fi)(xp(i)(1), . . . , xp(i)(ni)),
σ[sk] =
b

consequently,
for 1 ≤ k ≤ ni. Consequently, s = fi(s1, . . . , sni) = fj(t1, . . . , tnj ) = t.

σ[tk] for 1 ≤ k ≤ ni. By our hypothesis we get sk = tk
b

σ[t1], . . . ,
b

σ[s1], . . . ,
b
σ[tnj ]) and,
b

σ[sni])
b

σ[t]
σ[s] =
b
b
i = j, since h is a

Surjectivity: For w ∈ X we have
Suppose that for any s ∈ Wτ (X) with depth(s) ≤ n there is an

σ[w] = w.
b

s ∈ Wτ (X)
e

Let now t ∈ Wτ (X) be a term with depth(t) = n+1. Then there is an i ∈ I
tni ∈ Wτ (X)
e
tk] = tk for 1 ≤ k ≤ ni. Further there is a j ∈ I with h(fj) = fi
e
tp(j)−1(ni)).
e

with t = fi(t1, . . . , tni) and by our hypothesis there are
such that
and ni = nj. Now we consider the term
There holds

tp(j)−1(1), . . . ,
e

t := fj(
e

t1, . . . ,
e

σ[
b

t] = Sni(h(fj)(xp(j)(1), . . . , xp(j)(nj )),
e

σ[
b

σ[
b

tp(j)−1(1)], . . . ,
e

σ[
b

tp(j)−1(ni)])
e

= Sni(fi(xp(j)(1), . . . , xp(j)(ni)), tp(j)−1(1), . . . , tp(j)−1(ni))

(by hypothesis)

= fi(t1, . . . , tni) = t.

(i) ⇒ (ii) : Since

σ is surjective for each j ∈ I there is an sj ∈ Wτ (X)
b
with
σ[sj] = fj(x1, . . . , xnj ) which is minimal with respect to the depth.
b
Obviously, the case depth(sj ) = 0 is impossible. Thus there are a k ∈ I and
r1, . . . , rnk ∈ Wτ (X) with sj = fk(r1, . . . , rnk ). So
σ[fk(r1, . . . , rnk )] = Snk (σ(fk),
σ[r1], . . . ,
σ[sj] =
b
b
b
This is only possible if σ(fk) ∈ X or σ(fk) = fj(a1, . . . , anj ) with

σ[rnk ]) = fj(x1, . . . , xnj ).
b

a1, . . . , anj ∈ {x1, . . . , xnk }, | {a1, . . . , anj } |= nj,

and thus nk ≥ nj. But the case σ(fk) ∈ X is impossible. Otherwise there
σ[ri] where depth(sj) >
is an i ∈ {1, . . . , nk} with σ(fk) = xi and
b
depth(ri), this contradicts the minimallity of sj. This shows that for all
j ∈ I there are a k(j) ∈ I with nk(j) ≥ nj and a1, . . . , anj ∈ Xnk(j) with
| {a1, . . . , anj } |= nj such that σ(fk(j)) = fj(a1, . . . , anj ).

σ[sj] =
b

Assume that nk(j) > nj for some j ∈ I. Then there is an x ∈ Xnk(j) \
σ is not a bijection
b

var(σ(fk(j))), i.e. x is not essential in σ(fk(j)) and thus

4

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

on Wτ (X) (see [1], [6]), a contradiction. Thus nk(j) = nj and σ(fk(j)) =
fj(xπj(1), . . . , xπj(nj )) for some πj ∈ Snj .

Assume that there are j, l ∈ I with l 6= k(j) such that fj is the ﬁrst opera-
σ[fl(x1, . . . , xnl)]. Then t = fj(t1, . . . , tnj )
b
σ is surjective, there are s1, . . . , snj ∈
b

tion symbol in σ(fl). We put t :=
for some t1, . . . , tnj ∈ Wτ (X). Since
Wτ (X) with

(1), . . . , sπ

(nj ))]

−1
j

σ[fk(j)(sπ
b

−1
j

σ[si] = ti for 1 ≤ i ≤ nj. Then
b
= Snj (σ(fk(j)),
(nj )])
σ[sπ
(1)], . . . ,
σ[sπ
−1
b
b
j
= Snj (fj(xπj(1), . . . , xπj (nj )), tπ
(1), . . . , tπ
−1
j
= fj(t1, . . . , tnj ).
Since fk(j)(sπ

(1), . . . , sπ

−1
j

−1
j

(nj ))

−1
j

(nj )) 6= fl(x1, . . . , xnl),

−1
j

σ is no injective, a con-
b

tradiction. Altogether this shows that the mapping h : Ω → Ω where h(f )
is the ﬁrst operation symbol in σ(f ) is a bijection on Ω preserving the arity.
Further, let p ∈ AI with p(i) := πi for i ∈ I. Then p ∈ P.

Consequently, we have σ(fi) = h(fi)(xp(i)(1), . . . , xp(i)(ni)) for all i ∈ I. (cid:3)
Let us give the following examples.

Example 1. Let 2 ≤ n ∈ N. We consider the type τn = (n), where f
denotes the n-ary operation symbol. For π ∈ Sn we deﬁne:

σπ : f 7→ f (xπ(1), . . . , xπ(n)).
These hypersubstitutions are precisely the bijections, i.e. Bij(τn) = {σπ |

π ∈ Sn}.

In particular, if n = 2 then Bij(τ2) = {ε, σd} where σd is deﬁned by

σd : f 7→ f (x2, x1).

Example 2. Let now τ = (2, 2) where f and g are the both binary operation
symbols. Then we deﬁne the following eight hypersubstitutions σ1, . . . , σ8 by:

f 7→

g 7→

σ1 : f (x1, x2) g(x1, x2)
σ2 : f (x1, x2) g(x2, x1)
σ3 : f (x2, x1) g(x1, x2)
σ4 : f (x2, x1) g(x2, x1)
f (x1, x2)
σ5 : g(x1, x2)
f (x2, x1)
σ6 : g(x1, x2)
f (x1, x2)
σ7 : g(x2, x1)
f (x2, x1)
σ8 : g(x2, x1)

These hypersubstitutions are precisely the bijections, so

Bij(τ ) = {σ1, . . . , σ8}.

3. ρ-solid varieties

In Section 1, we mentioned that any hypersubstitution σ can be uniquely
σ ∈ Wτ (X)Wτ (X)). Thus a
b

σ : Wτ (X) → Wτ (X) (
b

extended to a mapping

ON MAPPINGS OF TERMS DETERMINED BY HYPERSUBSTITUTIONS

5

mapping ρ : Hyp(τ ) → Wτ (X)Wτ (X) is deﬁned by setting ρ(σ) =
σ ∈ Hyp(τ ).

σ for all
b

In [4], the concept of a solid variety was introduced. By Birkhoﬀ, a
variety V is a class of algebras of type τ satisfying a set Σ of identities, i.e.
V = M odΣ. For a variety V of type τ we denote by IdV the set of all
identities in V . The variety V is said to be solid iﬀ
σ[t] ∈ IdV for
b
all s ≈ t ∈ IdV and all σ ∈ Hyp(τ ). For a submonoid M of Hyp(τ ), the
variety V is said to be M -solid iﬀ
σ[t] ∈ IdV for all s ≈ t ∈ IdV and
σ[s] ≈
b
b
all σ ∈ M (see [3]). If M = Hyp(τ ) then we have solid varieties.

σ[s] ≈
b

In this section we will study mappings ρ : Hyp(τ ) → Wτ (X)Wτ (X) and
generalize the concept of an M -solid variety to the concept of an M -ρ-solid
variety. For convenience, we put σρ := ρ(σ) for σ ∈ Hyp(τ ).
Deﬁnition 2. Let ρ : Hyp(τ ) → Wτ (X)Wτ (X) be a mapping and V be a
variety of type τ and M be a submonoid of Hyp(τ ). V is called M -ρ-solid
iﬀ σρ(s) ≈ σρ(t) ∈ IdV for all s ≈ t ∈ IdV and all σ ∈ M .

If M = Hyp(τ ) then V is said to be ρ-solid.

Example 3. Let ρ : Hyp(τ ) → Wτ (X)Wτ (X) be deﬁned by ρ(σ) =
σ for all
b
σ ∈ Hyp(τ ). Then the ρ-solid varieties are exactly the solid varieties, which
is clear by the appropriate deﬁnitions. L. Pol´ak has determined all solid
varieties of semigroups in [5]. Besides the trivial variety, exactly the self-
dual varieties in the interval between the normalization Z ∨RB of the variety
of all rectangular bands and the variety deﬁned by the identities x2 ≈ x4,
x2y2z ≈ x2yx2yz, xy2z2 ≈ xyz2yz2, and xyzyx ≈ xyxzxyx as well as the
varieties RB of all rectangular, N B of all normal, and RegB of all regular
bands are solid.

In Section 2 we have checked that Bij(τ ) forms a monoid. For particular
mappings ρ : Hyp(τ ) → Wτ (X)Wτ (X) the Bij(τ )-ρ-solid varieties are of
special interest, in particular for type τ = (2) and semigroup varieties.
They realize substitutions of operations in terms which are useful in some
calculational aspects of computer algebra systems. In the following we will
consider such mappings ρ : Hyp(τ ) → Wτ (X)Wτ (X).

Deﬁnition 3. Let

f a : Hyp(τ ) → Wτ (X)Wτ (X) and sa : Hyp(τ ) → Wτ (X)Wτ (X)

be the following mappings: For σ ∈ Hyp(τ ) we put
(i)
(ii) σf a(fi(t1, . . . , tni)) := Sni(σ(fi), σsa(t1), . . . , σsa(tni)) and

σf a(x) := σsa(x) := x for x ∈ X;

σsa(fi(t1, . . . , tni)) := fi(σf a(t1), . . . , σf a(tni)) for i ∈ I and
t1, . . . , tni ∈ Wτ (X) where σsa(t1), . . . , σsa(tni), σf a(t1), . . . , σf a(tni)
will be assumed to be already deﬁned.

If we consider M -ρ-solid varieties of semigroups we have the type τ = (2)
If

and thus ρ : Hyp(2) → W(2)(X)W(2)(X) (where Hyp(2) := Hyp((2))).

6

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

one considers semigroup identities, we have the associative law and we can
renounce of the operation symbol f and the brackets, i.e. we write semigroup
words only as sequences of variables.

Theorem 2. The trivial variety T R and the variety Z of all zero semigroups
(deﬁned by xy ≈ zt) are the only sa-solid varieties of semigroups.

Proof. Clearly, T R is sa-solid.

We show that for any σ ∈ Hyp(2) and any t ∈ W(2)(X) there holds

σsa(t) ≈ t ∈ IdZ.

If t ∈ X then σsa(t) = t.
If t /∈ X then t = f (t1, t2) for some t1, t2 ∈ W(2)(X). Thus c(t) ≥ 2 and
t ≈ xy ∈ IdZ. Further, there holds σsa(t) = f (σf a(t1), σf a(t2)) ≈ xy ∈ IdZ.
Consequently, σsa(t) ≈ t ∈ IdZ.

This shows that σsa(s) ≈ s ≈ t ≈ σsa(t) holds in Z for all s ≈ t ∈ IdZ

and all σ ∈ Hyp(2), i.e. Z is sa-solid.

Conversely, let V be an sa-solid variety of semigroups. By σx (σy) we will
denote the hypersubstitution which maps the binary operation symbol f to
x (f (f (x, y), z)) ≈ σsa
the term x1 (x2). Then σsa
x (f (x, f (y, z))) ∈ IdV . This
provides xz ≈ xy ∈ IdV . From σsa
y (f (x, f (y, z))) ∈
IdV it follows yz ≈ xz ∈ IdV . Both identities xz ≈ xy and yz ≈ xz provide
(cid:3)
yz ≈ xt, i.e. V ⊆ Z. But T R and Z are the only subvarieties of Z.

y (f (f (x, y), z)) ≈ σsa

Proposition 2. A variety V of semigroups is Bij(2)-sa-solid iﬀ

(i) V ⊆ M od{x(yz) ≈ (xy)z, xyz ≈ zxy} and
(ii) V ⊆ M od{x(yz) ≈ (xy)z, xyz ≈ xzy ≈ zxy} if there is an identity
s ≈ t ∈ IdV with cv(s) = c(s) = 3 and c(t) 6= 3 or cv(t) 6= 3 or var(t) 6=
var(s).

Proof. We have already mentioned that Bij(2) = {ε, σd}.

Suppose that V is Bij(2)-sa-solid. Then

d (f (f (x, y), z)) ≈ σsa
σsa

d (f (x, f (y, z))) ∈ IdV,

so yxz ≈ xzy ∈ IdV . Let now s ≈ t ∈ IdV with cv(s) = c(s) = 3.

d (t) = t.
d (t) ≈ t ∈ IdV is easy to check using yxz ≈ xzy ∈ IdV .
d (t) ≈ t ∈ IdV is obvious.

If c(t) ≤ 2 then σsa
If c(t) ≥ 4 then σsa
If c(t) = 3 and cv(t) = 1 then σsa
If c(t) = 3 and cv(t) = 2 then there are w1, w2 ∈ X such that t =
(w1w2)w2 or
t = (w2w1)w2 or t = (w2w2)w1 or t = w1(w2w2) or t =
w2(w1w2) or t = w2(w2w1). Using yxz ≈ xzy ∈ IdV we get that w1w2w2 ≈
w2w1w2 ≈ w2w2w1 in V . This shows that σsa

d (t) ≈ t ∈ IdV .

From cv(s) = c(s) = 3 it follows s = (w1w2)w3 or s = w1(w2w3) for
some w1, w2, w3 ∈ X. Without loss of generality let s = w1(w2w3), so
σsa
d (s) = w1w3w2.
If c(t) 6= 3 or cv(t) 6= 3, from σsa

d (t) ∈ IdV it follows w1w3w2 ≈

d (s) ≈ σsa

t ∈ IdV . Consequently, w1w3w2 ≈ w1w2w3 ∈ IdV .

ON MAPPINGS OF TERMS DETERMINED BY HYPERSUBSTITUTIONS

7

If cv(t) = c(t) = 3 and var(t) 6= var(s) then there is a w ∈ var(t)\var(s).
Substituting w by w2 we get s ≈ r ∈ IdV from s ≈ t ∈ IdV where c(r) = 4.
Then we get xyz ≈ zxy ∈ IdV as above.

Suppose that (i) and (ii) are satisﬁed. Let s ≈ t ∈ IdV . Then εsa(s) ≈
d (t) ∈ IdV and consider

εsa(t) ∈ IdV . We have to show that σsa
the following cases:

d (s) ≈ σsa

1) If c(s) 6= 3 or cv(s) 6= 3 and c(t) 6= 3 or cv(t) 6= 3 then we have
σsa
d (s) ≈ s ∈ IdV and σsa
d (t) ≈ t ∈ IdV as we have shown already. This
provides σsa

d (s) ≈ σsa

d (t) ∈ IdV .

2.1) If cv(s) = c(s) = 3 and c(t) 6= 3 or cv(t) 6= 3 or var(t) 6= var(s)
then xyz ≈ xzy ≈ zxy holds in V (by (ii)) and it is easy to see that
d (s) ≈ s ∈ IdV and σsa
σsa
2.2) If cv(s) = c(s) = 3 and c(t) = 3 and cv(t) = 3 and var(t) = var(s)

d (t) ≈ t ∈ IdV , so σsa

d (s) ≈ σsa

d (t) ∈ IdV .

then there are w1, w2, w3 ∈ X such that s, t ∈ {r1, . . . , r12} where

r4 = (w3w2)w1
r8 = (w2w3)w1
r12 = (w1w2)w3.

r1 = w2(w1w3)
r5 = w1(w3w2)
r9 = w3(w1w2)
Then σsa

r2 = (w2w1)w3
r6 = (w1w3)w2
r10 = (w3w1)w2

r3 = w3(w2w1)
r7 = w2(w3w1)
r11 = w1(w2w3)
d (r3) = r9, σsa

d (r4) = r8, σsa

d (r1) = r7, σsa

d (r2) = r12, σsa

d (r8) = r4, σsa

d (r5) =
d (r7) = r1, σsa
d (r6) = r10, σsa
r11, σsa
d (r10) = r6,
d (r12) = r2. This shows that σsa
d (r11) = r5, and σsa
σsa
d (rj) ∈ IdV
for 1 ≤ i, j ≤ 6 or 7 ≤ i, j ≤ 12 by xyz ≈ zxy ∈ IdV . If ri ≈ rj ∈ IdV with
1 ≤ i ≤ 6 or 7 ≤ j ≤ 12 or conversely, then xyz ≈ xzy ∈ IdV . Together
with xyz ≈ zxy ∈ IdV it is easy to check that then σsa
d (ri) ≈ ri ∈ IdV and
d (rj) ≈ rj ∈ IdV , i.e. σsa
σsa
d (rj) ∈ IdV . Altogether this shows
that σsa

d (r9) = r3, σsa
d (ri) ≈ σsa

d (ri) ≈ σsa

d (s) ≈ σsa

d (t) ∈ IdV .

3) If cv(t) = c(t) = 3 then we get dually σsa

d (s) ≈ σsa

d (t) ∈ IdV .

(cid:3)

Theorem 3. T R is the only f a-solid variety of semigroups.

x (f (f (x, y), z)) ≈ σf a

Proof. Clearly, T R is f a-solid. Let V be an f a-solid variety of semigroups.
From σf a
x (f (x, f (y, z))) ∈ IdV it follows xy ≈ x ∈ IdV .
Moreover, σf a
y (f (x, f (y, z))) ∈ IdV provides z ≈ yz ∈
(cid:3)
IdV . Both identities xy ≈ x and z ≈ yz give z ≈ y, i.e. V = T R.

y (f (f (x, y), z)) ≈ σf a

Proposition 3. A variety V of semigroups is Bij(2)-f a-solid iﬀ

(i) V ⊆ M od{x(yz) ≈ (xy)z, xyz ≈ zxy} and
(ii) V is a variety of commutative semigroups if there is an identity s ≈
t ∈ IdV with cv(s) = c(s) = 2 and c(t) 6= 2 or cv(t) 6= 2 or var(t) 6= var(s).

Proof. We have already mentioned that Bij(2) = {ε, σd}.

Suppose that V is Bij(2)-f a-solid. Then

d (f (f (x, y), z)) ≈ σf a
σf a

d (f (x, f (y, z))) ∈ IdV,

so zxy ≈ yzx ∈ IdV . Let now s ≈ t ∈ IdV with cv(s) = c(s) = 2.

If c(t) = 1 then σf a
If c(t) ≥ 3 then σf a
If c(t) = 2 and cv(t) = 1 then σf a

d (t) = t.
d (t) ≈ t ∈ IdV is easy to check using zxy ≈ yzx ∈ IdV .
d (t) ≈ t ∈ IdV is obvious.

8

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

From cv(s) = c(s) = 2 it follows s = w1w2, so σf a
If c(t) 6= 2 or cv(t) 6= 2 from σf a

d (s) ≈ σf a
IdV and, consequently, w1w2 ≈ w2w1 ∈ IdV .

d (s) = w2w1.
d (t) ∈ IdV it follows w2w1 ≈ t ∈

If cv(t) = c(t) = 2 and var(t) 6= var(s) then there is a w ∈ var(t)\var(s).
Substituting w by w2 we get s ≈ r ∈ IdV from s ≈ t ∈ IdV where c(r) = 3.
Then we get xy ≈ yx ∈ IdV as above.

Suppose that (i) and (ii) are satisﬁed. Let s ≈ t ∈ IdV . Then εf a(s) ≈
d (t) ∈ IdV and consider

εf a(t) ∈ IdV . We have to show that σf a
the following cases:

d (s) ≈ σf a

1) If c(s) 6= 2 or cv(s) 6= 2 and c(t) 6= 2 or cv(t) 6= 2 then we have
σf a
d (s) ≈ s ∈ IdV and σf a
d (t) ≈ t ∈ IdV as we have shown already. This
provides σf a

d (s) ≈ σf a

d (t) ∈ IdV .

2.1) If cv(s) = c(s) = 2 and c(t) 6= 2 or cv(t) 6= 2 or var(t) 6= var(s) then
V is a variety of commutative semigroups (by (ii)) and it is easy to see that
d (s) ≈ s ∈ IdV and σf a
σf a
2.2) If cv(s) = c(s) = 2 and c(t) = cv(t) = 2 and var(t) = var(s) then
there are w1, w2 ∈ X such that s = w1w2 or s = w2w1 and t = w1w2 or
t = w2w1.

d (t) ≈ t ∈ IdV , so σf a

d (s) ≈ σf a

d (t) ∈ IdV .

If s = t then σf a
If s 6= t then s ≈ t is the commutative law and we have σf a

d (s) = σf a

d (t).

d (s) ≈ σf a

d (t) ∈

IdV .

3) If cv(t) = c(t) = 2 then we get dually σf a

d (s) ≈ σf a

d (t) ∈ IdV .

(cid:3)

Deﬁnition 4. We deﬁne a mapping γn : Hyp(τ ) → Wτ (X)Wτ (X) for each
natural number n as follows: For σ ∈ Hyp(τ ) we put
(i)
(ii)
(iii) σγn(fi(t1, . . . , tni)) := fi(σγn−1 (t1), . . . , σγn−1 (tni)) for 1 ≤ n ∈ N,

σγ0 :=
σγn(x) := x for x ∈ X and 1 ≤ n ∈ N;

σ;
b

i ∈ I, and t1, . . . , tni ∈ Wτ (X).

We put Hyp(n)(τ ) := {σγn | σ ∈ Hyp(τ )} for n ∈ N.

For the hypersubstitution ε ∈ Hyp(τ ) (the identity element in Hyp(τ ))
ε for all n ∈ N. This becomes clear by the following
there holds εγn =
b
considerations: We have εγ0 =
ε for some natural
b
ε[x] and εγn+1 (fi(t1, . . . , tni))
number n then there holds εγn+1(x) = x =
b

ε and suppose that εγn =
b

= fi(εγn (t1), . . . , εγn (tni))
= fi(
ε[tni])
b
= fi(t1, . . . , tni)
=

ε[t1], . . . ,
b

ε[fi(t1, . . . , tni)].
b

Proposition 4. The monoids (Hyp(n)(τ ); ◦,
for each natural number n.

ε) and Hyp(τ ) are isomorphic
b

Proof. Let n be a natural number. We deﬁne a mapping h : Hyp(τ ) →
Hyp(n)(τ ) by h(σ) := σγn for σ ∈ Hyp(τ ). We show that h is injective.
For this let σ1, σ2 ∈ Hyp(τ ) with σγn
2 . Assume that σ1 6= σ2. Then

1 = σγn

ON MAPPINGS OF TERMS DETERMINED BY HYPERSUBSTITUTIONS

9

there is an i ∈ I with σ1(fi) 6= σ2(fi) and we have
σ2[fi(x1, . . . , xni)]. Then we deﬁne:
b
t0 := fi(x1, . . . , xni);
tp+1 := fi(tp, x2, . . . , xni) for p ∈ N.

(i)
(ii)
It is easy to check that σγn

1 (tn) 6= σγn

2 (tn) because of
2 . This shows that h is injective.

contradicts σγn

1 = σγn

σ1[fi(x1, . . . , xni)] 6=
b

σ1[t0] 6=
b

σ2[t0], which
b

Clearly, h is surjective. Consequently, h is a bijective mapping.
It is left to show that h satisﬁes the homomorphic property. We will show
(σ1 ◦h σ2)γn =

by induction on n that h(σ1 ◦h σ2) = h(σ1) ◦ h(σ2), i.e.
σγn
1 ◦ σγn
2 .
If n = 0 then we have σγ0

= (σ1 ◦h σ2)γ0 (see

1 ◦ σγ0

For n = m we suppose that σγm
Let now n = m + 1. Obviously, we have (σγm+1

2 =

σ1 ◦
b
1 ◦ σγm

σ2 = (σ1 ◦h σ2)
b
b
2 = (σ1 ◦h σ2)γm .

◦ σγm+1
2

)(x) = x =

1

[3]).

(σ1 ◦h σ2)γm+1 (x).

◦ σγm+1
2
1 ◦ σγm

Let i ∈ I and t1, . . . , tni ∈ Wτ (X). Then there holds
(σγm+1
)(fi(t1, . . . , tni)) = σγm+1
1
2 )(t1), . . . , (σγm
= fi((σγm
= fi((σ1 ◦h σ2)γm (t1), . . . , (σ1 ◦h σ2)γm (tni)) (by hypothesis)
= (σ1 ◦h σ2)γm+1 (fi(t1, . . . , tni)).
Altogether, this shows that σγm+1

2 (t1), . . . , σγm

1
2 )(tni))

= (σ1 ◦h σ2)γm+1 .

1 ◦ σγm

(fi(σγm

◦ σγm+1
2

1

2 (tni)))

(cid:3)

By deﬁnition, a variety V of type τ is M -γ0-solid iﬀ V is M -solid. The
class of all solid varieties of semigroups was determined in [5]. We will now
characterize the γn-solid varieties of semigroups for 1 ≤ n ∈ N. Here we
need some else notations. For a ﬁxed variable w ∈ X we put:

F0 := {f (f (x, y), z) ≈ f (x, f (y, z))} and
Fm+1 := {f (s, w) ≈ f (t, w) | s ≈ t ∈ Fm} ∪ {f (w, s) ≈ f (w, t) | s ≈ t ∈

Fm} for m ∈ N.
Theorem 4. Let 1 ≤ n ∈ N and V be a variety of semigroups. Then V is
γn-solid iﬀ

x1 . . . xn+1 ≈ y1 . . . yn+1 ∈ IdV .

Proof. Suppose that V is γn-solid.

Since the associative law is satisﬁed in V there holds Fn−1 ⊆ IdV . Since
to the identities of Fn−1 gives again

V is γn-solid the application of σγn
x
identities in V :

I1 := {waxzwb ≈ waxywb | a, b ∈ N, a + b = n − 1} ⊆ IdV .

The application of σγn
y

to the identities of Fn−1 provides

I2 := {wayzwb ≈ waxzwb | a, b ∈ N, a + b = n − 1} ⊆ IdV .

It is easy to check that one can derive x1 . . . xn+1 ≈ y1 . . . yn+1 from I1 ∪ I2.
Thus x1 . . . xn+1 ≈ y1 . . . yn+1 ∈ IdV .

10

J ¨ORG KOPPITZ AND SLAVCHO SHTRAKOV

Suppose now that x1 . . . xn+1 ≈ y1 . . . yn+1 ∈ IdV . We show that for any

σ ∈ Hyp(2) and any t ∈ W(2)(X) there holds σγn (t) ≈ t ∈ IdV.

If t contains at most n operation symbols then σγn (t) = t by deﬁnition of

the mapping σγn.

If t contains more than n operation symbols then c(t) ≥ n + 1 and
t ≈ x1 . . . xn+1 ∈ IdV because of x1 . . . xn+1 ≈ y1 . . . yn+1 ∈ IdV. Since t con-
tains more than n operation symbols, by deﬁnition of the mapping σγn, the
term σγn(t) contains at least n operation symbols and thus c(σγn (t)) ≥ n+1.
Using x1 . . . xn+1 ≈ y1 . . . yn+1 ∈ IdV we get σγn (t) ≈ x1 . . . xn+1 ∈ IdV .
Consequently, σγn(t) ≈ t ∈ IdV .

This shows that σγn (s) ≈ s ≈ t ≈ σγn(t) holds in V for s ≈ t ∈ IdV and
(cid:3)

σ ∈ Hyp(2), i.e. V is γn-solid.

Corollary 5. T R and Z are the only γ1-solid varieties of semigroups.

Proof. By Theorem 4, a variety V of semigroups is γ1-solid iﬀ x1x2 ≈ y1y2 ∈
(cid:3)
IdV, i.e. V ⊆ Z. But T R and Z are the only subvarieties of Z.

References

[1] Denecke, K., Koppitz, J., Essential variables in Hypersubstitutions, Algebra Univer-

salis 46(2001), 443-454.

[2] Denecke, K., Lau, D., P¨oschel, R., Schweigert, D., Hyperidentities, hyperequational
classes, and clone congruences, Contributions to General Algebra 7, Verlag H¨older-
Pichler-Tempsky, Wien 1991, 97-118.

[3] Denecke, K., Wismath, S.L., Hyperidentities and clones, Gordon and Breach Scientiﬁc

Publisher, 2000.

[4] Gracz´ynska, E., Schweigert, D., Hypervarieties of a given type, Algebra Universalis

27(1990), 111-127.

[5] Pol´ak, L., All solid varieties of semigroups, J. of Algebra 219 (1999), 421-436.
[6] Shtrakov, Sl., Denecke, K., Essential variables and separable sets in Universal Algebra,
Multiple-Valued Logic in Eastern Europe, Multiple-Valued Logic 8(2002), no 2, 165-
181.

J¨org Koppitz, University of Potsdam, Institute of Mathematics, Postfach

601553, 14415 Potsdam, Germany

E-mail address: koppitz@rz.uni-potsdam.de

Slavcho Shtrakov, South-West-University Blagoevgrad, Faculty of Math-

ematics and Natural Sciences, 2700 Blagoevgrad, Bulgaria

E-mail address: shtrakov@aix.swu.bg.

"
