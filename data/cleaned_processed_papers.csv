title,abstract,pdf_url,labels,full_text
"A Human - machine interface for teleoperation of arm manipulators in a
  complex environment","  This paper discusses the feasibility of using configuration space (C-space)
as a means of visualization and control in operator-guided real-time motion of
a robot arm manipulator. The motivation is to improve performance of the human
operator in tasks involving the manipulator motion in an environment with
obstacles. Unlike some other motion planning tasks, operators are known to make
expensive mistakes in such tasks, even in a simpler two-dimensional case. They
have difficulty learning better procedures and their performance improves very
little with practice. Using an example of a two-dimensional arm manipulator, we
show that translating the problem into C-space improves the operator
performance rather remarkably, on the order of magnitude compared to the usual
work space control. An interface that makes the transfer possible is described,
and an example of its use in a virtual environment is shown.
",http://arxiv.org/pdf/cs/9811029v1,1,"8
9
9
1

v
o
N
0
2

]

O
R
.
s
c
[

1
v
9
2
0
1
1
8
9
/
s
c
:
v
i
X
r
a

A Human - machine interface for teleoperation of
arm manipulators in a complex environment

I. Ivanisevic and V. Lumelsky
University of Wisconsin-Madison
Madison, Wisconsin 53706, USA

Abstract

This paper discusses the feasibility of using conﬁguration space (C-space) as a
means of visualization and control in operator-guided real-time motion of a robot
arm manipulator. The motivation is to improve performance of the human operator
in tasks involving the manipulator motion in an environment with obstacles. Unlike
some other motion planning tasks, operators are known to make expensive mistakes
in such tasks, even in a simpler two-dimensional case. They have diﬃculty learning
better procedures and their performance improves very little with practice. Using an
example of a two-dimensional arm manipulator, we show that translating the problem
into C-space improves the operator performance rather remarkably, on the order of
magnitude compared to the usual work space control. An interface that makes the
transfer possible is described, and an example of its use in a virtual environment is
shown.

1

Introduction

The goal in this project is to improve the performance of human operators in tasks that in-
volve motion planning and control of complex objects in environments with obstacles. The
human performance in such tasks is known to be patently inferior. Our focus is on develop-
ing a visual computer interface that would allow the operator to visualize and perform the
work in the task conﬁguration space (C-space) rather than in the work space (W-space) as
usually done. To make it feasible, a computer intelligence is provided that works alongside
with human intelligence in real time. To this eﬀect, we combine the “desirable” features of
human and machine intelligence and exploit their individual strengths. This area belongs
to the ﬁeld of human-centered systems, which has seen growing interest in recent years.
The intent of this work is to be applicable to many existing research [1] and commercial
problems [2, 3].

There is a large and rapidly developing class of technical systems that are dependent on
human contribution for their operation. In various teleoperated systems (such as in space,

1

 
 
 
 
 
 
nuclear reactors, chemical cleanup sites, underwater probes) human operators plan and
guide the motion of remotely situated devices through interaction with computer displays
or three-dimensional models of the device. Familiar examples include control of the NASA
Shuttle arm and of the Titanic exploration probe. In such tasks operators are known to
make mistakes of overlooking collisions with surrounding objects; this results in expensive
repairs and limits the system eﬀectiveness. People seem to be unable to navigate and
manipulate remote equipment without colliding with objects in the environment.

Similar problems occur in other settings. Guiding the position of a robotic welding gun
or spray painting device with a simultaneous translation and orientation adjustment seems
to be particularly diﬃcult for people, even when visual feedback is provided. Performance
is very poor in a variety of these movement planning tasks when time is not a constraint
(the Shuttle arm, for example); it becomes progressively worse in real-time operation, in
three-dimensional (3D) vs 2D tasks, and when system dynamics are involved (masses,
inertia etc.). (Underwater exploration probes, for example, cannot stop while the operator
considers the next move).

Experiments with human subjects [4, 5] suggest that the problem is in the peculiarities
of human spatial reasoning: humans have diﬃculty handling simultaneous interaction with
objects at multiple points of the device’s body, or motion that involves mechanical joints
(such as in arm manipulators), or dynamic tasks. Learning and practice improve the per-
formance rather little. Furthermore, the performance pattern is the same when operating
a physical rig or performing the task on a computer screen and moving the arm links with
a mouse (see more on this in Section 5).

On the other hand, these experiments conﬁrm the expected fact that in a maze-searching
problem, if information is provided about the whole maze (a bird’s-eye view), human per-
formance is well above the fastest computer with the best known algorithms [6]. Figure
1 gives an example of human performance in a maze: after inspecting the maze for a few
seconds, the subjects grasp the problem and produce an almost optimal path from point
S to point T. This contrast in the subjects’ performance in the two tasks above poses a
question as to whether a human-machine interface, perhaps with adequate machine intelli-
gence, can be developed to improve human performance is such applications. The current
work is an attempt to answer this question. The system we chose to model the problem is
a two-dimensional (2D) revolute-revolute (RR) arm manipulator operating in an environ-
ment with unknown stationary obstacles (see Figure 2). The arm has two links moving in
a plane, and two revolute joints (degrees of freedom). The idea it to present the problem
to the human as one of moving a point in a maze (a task that humans are good at) rather
than the actual problem of moving a jointed kinematic structure (which humans are not
good at). We exploit the fact that for today’s computer algorithms, which are based on
spatial geometry and topology tools, both tasks present essentially the same maze-searching
problem [7]. By transforming the problem to the arm conﬁguration space (C-space), the
arm is shrunk to a point in the space of its control variables.

Below, the properties of work space control are discussed in Section 2, and those of the
conﬁguration space – in Section 3. The proposed interface is then presented in Section 4,

2

Figure 1: Human performance in a maze.

followed by some experimental results in Section 5 and discussion in Section 5.2.

2 Work Space Control

The revolute-revolute (RR) planar arm considered is as follows, Figure 2: Joint J1 (the
shoulder) is attached to the ﬂoor, and is the origin of a ﬁxed reference system. Joint J2 (the
elbow) connects the two links, l1 and l2. The Cartesian coordinates of the endpoint (point
P) are (x, y). Moving the arm involves changing the joint angles θ1 and θ2. There are ﬁxed
obstacles in the arm environment (O1 and O2, Figure 2). There are no constraints on the
shape of the obstacles or the arm links. The task is to move the arm from a position S
(Start) to the position T (Target), Figure 3.

3

Figure 2: The 2D two-link arm manipulator in an environment with unknown stationary obsta-
cles.

2.1 Motion Control in W-space

Arm motion is controlled with the computer mouse, in two separate modes - joint-mode
and tip-mode [7]. The former allows control of individual joints by positioning the pointer
closer to one of the joints and pressing the left mouse button, which causes the selected joint
to move and align with the pointer. The tip-mode allows control of the endpoint through
the use of the middle mouse button; computer software then calculates the corresponding
joint angles of the links and positions them accordingly.

In the joint-mode, the algorithm computes a unit vector which describes the straight-
line direction from current conﬁguration to speciﬁed target conﬁguration. Assuming the
conﬁguration does not violate step constraints (if the distance to it is larger than the
conﬁgured step size, a new target is computed by multiplying the direction vector by step
size), the new conﬁguration becomes the speciﬁed conﬁguration. In tip-mode, the direction
vector describes the new position of the arm endpoint (again, subject to step constraints),
and so one needs to recover the new arm conﬁguration from the endpoint position (x, y).
This is done via the inverse kinematics equations:
x2 + y2 − l2
2l1l2
) − arctan(

θ1 = arctan(

θ2 = arccos(

1 − l2
2

(1)

(2)

)

)

y
x

l2 sin θ2
l1 + l2 cos θ2

The current arm conﬁguration is used to resolve multiple solutions that are given by the
inverse kinematics. The ﬁnal step in either motion mode is to determine if the new conﬁg-
uration would place the arm in contact with the obstacle and, if so, disallow the movement

4

Figure 3: A sample task.

and wait for further operator input. Figure 4 shows an example of average human per-
formance in W-space motion control; the dotted line is the trajectory of the arm endpoint
along the way from S to T. The path length is the integral of changes in both joint angles
along the way.

2.2 Characteristics of the Work Space Control

Aside from being the traditional method used, W-space control has some desirable prop-
erties:

• Interaction with the physical arm and its environment makes it easier for the operator
to visualize the global navigation, such as to determine the next target conﬁguration
based on some scene property; e.g. the operator may decide to move the arm such
that its left side will be in proximity of some object.

• If the obstacles layout is not of much constraint on the arm motion, this approach
can yield very good (near optimal in terms of path length and time taken) results.

5

Figure 4: An example of average human performance in W-space motion control.

• Given the familiar physical layout, it may be easier for the operator to beneﬁt from

memorization of motion and improve with training.

However, this type of control also has some serious drawbacks which may outweigh its

positive sides:

• In tip-mode, calculating the inverse kinematics becomes progressively more complex

and time-consuming as the number of joints increases.

• In a complex environment, the operator may have hard time determining which di-
rection of local motion is better, or whether a given direction leads to a “dead-end”.
This is a serious drawback: for example, in Figure 4 one can pass obstacle O3 with
the elbow to the left or to the right; one of those turns out to be wrong as it leades
to a dead end, and this would become clear only signiﬁcantly later.

• From the standpoint of motion planning, a complex environment is not necessarily
one with many or with large obstacles; this is much clearer in C-space (see Section
3) than in W-space.

6

Consequently, W-space control is likely to produce redundant motion: as illustrated in
Figure 4, the operator will often try, backtrack, try again, backtrack again, and so on until
the passage is found, not rarely through blind luck. This also endangers the arm, as all
such motion multiplies potential collisions with surrounding objects. While most people
do beneﬁt from a training period in such systems, the training can be costly (in terms of
equipment use and damage inﬂicted on the arm) and time consuming.

3 Conﬁguration Space Control

The arm is the same 2D RR arm manipulator described in Section 2 (Figure 2). Assume
that the arm is capable of gathering information about the objects in its environment via
its sensors. To simplify the discussion, assume that those are tactile sensors - i.e. the arm
can detect an obstacle when it comes in contact with one. The human operator can of
course view the entire workspace, Figure 3. The task is as before - to move the arm from
position S to position T in the arm’s work space.

The arm can be deﬁned in terms of the shoulder angle θ1 and the elbow angle θ2. The
set of all conﬁgurations (θ1, θ2) deﬁne the arm’s conﬁguration space (C-space), which can
be represented as the surface of a common two-torus. An arm conﬁguration in W-space
corresponds to a point in C-space. This mapping preserves continuity; small change in
W-space position corresponds to a small change in the C-space position. A geodesic line
between two points on the torus (a straight line in the plane (θ1, θ2)) is the “shortest path”
between the points: four such paths can actually appear [6].

3.1 Motion Control in C-space

We will now attempt to control the arm motion indirectly, via its point image in C-space (C-
point). Each time the operator moves the C-point slightly, the algorithm recovers a new set
of conﬁguration variables (θ1, θ2) from the C-point coordinates and automatically translates
it into the actual motion in W-space. That is, after the direction vector is calculated and
step size is taken into account, similar to the joint-mode in W-space control, angles θ1
and θ2 become available, and they are used to control the arm’s next step. Though not
necessary for control purposes, for convenience a W-space window with the arm real-time
motion is shown next to the C-space window used by the operator.

Recall that the Cartesian position (x, y) of the arm endpoint is the tip-mode parameter
in W-space control. Certain applications, e.g. grasping, may require knowledge of this
parameter. If necessary, (x, y) values can be recovered from C-space information via the
direct kinematics equations:

x = l1 cos θ1 + l2 cos(θ1 + θ2)
y = l1 sin θ1 + l2 sin(θ1 + θ2)

(3)
(4)

7

We are now one step away from converting the complex problem of W-space control to a
simpler problem of navigating a point in the maze (C-space). What is missing is the maze
itself. This is done by computing the C-space obstacles, also called virtual obstacles. Each
point of a virtual obstacle corresponds to an arm conﬁguration that is not attainable because
of interference with the corresponding physical obstacle. The related (x, y) positions in W-
space may or may not be occupied by an obstacle - in the latter case such pieces of an
obstacle are called its shadows. A ﬁnite number of obstacles in W-space produce a ﬁnite set
of virtual obstacles in C-space. The boundaries of virtual obstacles are known to consist of
simple closed curves [6]. Since virtual obstacles are deﬁned in terms of arm variables (θ1,
θ2), their shape is visually unrelated to the shape of the W-space obstacles [7, 8].

3.2 Construction of C-space Obstacles

The greatest improvement in the operator performance comes when full information (the
bird’s-eye view) about C-space is available (on the issue of operating with uncertainty,
see the discussion in Section 5.2). We thus need to compute and display all the virtual
obstacles. An intuitive approach proposed in [8] is to treat each link separately. First,
link l2 is ignored, and all free space points for the whole range of values θ1 are computed.
Points of the arm contact with physical (W-space) obstacles are recorded and become part
of the corresponding virtual obstacle. Then, for each value of θ1 within its appropriately
digitized range, free space points for the whole range of values θ2 are computed in the same
fashion, by rotating link l2 around positions of joint 2 determined by the current value θ1.
Depending on the representation chosen for the virtual obstacles, their “insides” may have
to be ﬁlled using a polygon-ﬁlling algorithm.

For the two-dimensional problem in question, C-obstacle calculation can be greatly sim-
pliﬁed by tracing the obstacle boundaries with arm links and thus immediately creating
their C-space images. Note that two or more W-space obstacles can produce a single virtual
obstacle; that is, for the purposes of motion control, they would indeed be one obstacle.
Our simulation uses an eﬃcient variation of this procedure [7], which makes use of the
Bug1 [6] algorithm.

In brief, procedure Bug1 operates as follows: the point robot starts moving along the
straight line towards target point T. If it encounters an obstacle, a hit point H is deﬁned at
the encounter location, and the robot turns and moves in a prespeciﬁed direction (say, left)
along the obstacle boundary. Once the obstacle is circled, and H is once again encountered,
a leave point L is deﬁned on the obstacle, which is the point closest to T. The robot then
takes the shortest path to L and then proceeds to T in straight-line fashion, repeating the
procedure whenever an obstacle is encountered. The procedure converges to T or informs
that this is impossible if true. The algorithm’s computational complexity is linear in the
perimeters of the W-obstacles.

Figure 5 gives the C-space representation of W-space of Figure 3. Angle θ1 is along
the horizontal axis, θ2 - along the vertical axis. The range of change of each angle is 2π,
making C-space a square. The dark areas represent the virtual obstacles. The C-space

8

Figure 5: The sample task of Fig. 3; C-space representation.

correspondence to a two-torus means in that all four corners of the square are identiﬁed
(i.e. correspond to the same point). Similarly, the top and bottom edges of the square are
identiﬁed, and so are the left and right edges. Given this last fact, note that the C-space
in Figure 5 contains only one virtual obstacle which corresponds to four physical obstacles
in W-space, Figure 3. Point T is chosen as the corner point of the C-space square; in
principle, therefore, one’s moving from point S to any corner will produce a legitimate (if
not necessarily the shortest) path for the arm in W-space.

3.3 Characteristics of the Conﬁguration Space Control

This mode of control has several distinct advantages (see also Results, Section 5):

• From the operator standpoint, the task is simpliﬁed greatly: instead of dealing with
a complex jointed kinematic structure, the operator has to solve a simple maze-

9

searching problem with complete information, which humans are very good at.

• One explanation for the task simpliﬁcation is that the responsibilities are divided in
this mode - the operator can think of the motion planning only, while the computer
takes on the problem of collision analysis.

• The arm’s actual motion is quickly and easily calculable from user input, guaranteeing

good real-time performance.

• Unlike in W-space, performance here does not seem to depend much on the obstacle
layout. Indeed, this mode has consistently yielded near optimal performances by the
human operator in a variety of settings. This is consistent with the fact that humans
can easily “see” the path in a bird-eye view of a fairly complex maze, while they have
diﬃculty visualizing a path in a simple scene with an arm manipulator (see Figure 3).
The operator easily discards many “dead-end” directions in the maze representation,
but ﬁnd it diﬃcult to identify them in Figure 3.

• The mode requires very little training, mostly to get used to the peculiarities of ﬂat
presentation of two-torus - e.g. to the fact that once the point reaches the top edge
of the C-space square, it appears at the bottom edge. In fact, performance has been
just as good for an inexperienced user as for an experienced one.

• Unlike the W-space control, the subject can often easily see if a solution (a path)
exists. In fact, it is this kind of decision-making that the operator uses extensively
along the way to discard potential dead-ends.

A few drawbacks deserve to be noted of this mode, although their impact is not nearly

as great as those in W-space control:

• The fact of dealing with an abstract (C-) rather than physical (W-) space may make
it diﬃcult for the operator to address some global navigation tasks, such as choosing
targets for the arm to reach. This problem is easily avoided if the corresponding
W-space view is drawn in parallel with the C-space used by the operator (see Figures
3 and 5).

• While extremely helpful in 2D, the mode is not likely to easily generalize to more

complex multi-link systems see discussion in Section 5.2).

• Computation of C-space is an expensive operation which must be performed to sat-
isfy the complete information model (see Section 5.2 for details on the proposed
uncertainty model).

4 The Interface

The current version of the user interface has several interesting features:

10

• The user can generate - e.g., for practice - custom or random obstacle environments

around the arm.

• Both C-space and W-space displays are provided. As mentioned above, the W-space
window is a good tool for visualizing global navigation tasks, such as deciding on a
target position for the arm endpoint. The user can, for example, deﬁne the target in
terms of the arm endpoint Cartesian coordinates (x, y), and the computer will recover
the corresponding arm conﬁguration through inverse kinematic equations (1, 2).

• Motion control in C-space is done via mouse interaction; joystick control is being

considered, especially in the future 3D extension.

• For experimental purposes, the user can switch back and forth between C-space and

W-space control.

• The simulation keeps track of the time elapsed and path traversed, to help compare

the two control methods.

5 Results and Discussion

5.1 Results

Overall, the proposed C-space control mode performed admirably when compared to the
traditional W-space control. Current results (achieved with a C-space interface version
that is still under development) show improvement in performance on the order of mag-
nitude when switching from W-space control to the proposed C-space control. The path
produced approaches the optimal (shortest) path and time to complete the task. Further,
the cognitive part of the time spent in the case considered is negligible, since the 2D mazes
produced by the virtual obstacles are simple to navigate and to learn. This remarkable fact
puts the human operator ahead of the existing computer algorithms, contrary to the W-
space control where human performance has been much worse. It also suggests interesting
questions and extensions to more diﬃcult 3D cases.

Table 1 summarizes information from a series of controlled experiments performed in
1996-97 at the UW Robotics Lab, to test human performance in motion planning tasks.
One of the tasks given to the human subjects was to move a two-link arm, very similar to
the one considered in this paper, from the start to target conﬁgurations. Only W-space
control was available (Section 2). In the table, the path length is the integral of both joint
angle changes during the motion; also given is the time ((in seconds) taken by subjects to
complete the task. The data given represents the performance of 12 subjects on the second
day of tests, after training and practice on the previous day. (The results on 48 untrained
subjects, in tests with a simulated as well as physical arm manipulator, were quite similar).
A full analysis of this work can be found in [5].

11

Variable

Table 1: Descriptive Statistics
Mean Minimum Maximum Stand. Dev

path length 129.04
504.83

time

15.13
90.00

393.90
900.00

107.99
365.89

No similar study was carried out for the C-space control mode. However, based on
the observations and tests by these authors, the study is not necessary: the performance
improvement is very clear and consistent. Further, it is clear that in the task of Figure 3
diﬀerent subjects are likely to produce almost the same (nearly optimal) path, with the
mean path length of about 12, the standard deviation of about zero, and the mean time
below 1 min. The path length and time values in Table 2 show an order of magnitude
improvement compared to the data on W-space control in Table 1. Sample results from
5 consecutive runs of C-space control are given in Table 2. One of these runs is shown in
Figures 5 and 6.

Table 2: Sample Runs

Variable
path length
time

Run 1 Run 2 Run 3 Run 4 Run 5
12.28
12.24
12.67
54
53
56

12.27
53

12.39
54

The consistency between these runs - both in path length and completion time - is very
similar to the subjects performance in a common maze-searching problem. It also stands
in contrast to the wide range of results produced in the W-space model. This suggests that
the proposed transformation to C-space control does indeed make the task at hand similar
to the maze-searching task.

5.2 Discussion

This paper proposes an approach to human-guided teleoperation of a robot arm manipu-
lator based on the conﬁguration space (C-space) rather than on the common work space
(W-space) control. Instead of directly confronting the problem of collision analysis, which
is known to be extremely challenging for the human spatial reasoning, the task is oﬀered to
the operator in C-space where one can concentrate on global navigation, leaving collision
analysis to the computer. Thus reduced task becomes a maze-searching problem in which
humans are known to be very good. Designing such a system takes, ﬁrst, calculation of the
C-space, and second, an adequate user interface.

While this approach can be immediately useful even in its two-dimensional version de-
scribed, in order to become a truly universal tool it needs to be extended to the three-
dimensional case and to more degrees of freedom. The advantage for the operator of dealing
with a point rather than a complex jointed kinematic structure is obvious. The challenge is
to produce an adequate user interface (speciﬁcally, develop ways of visualizing and guiding

12

Figure 6: The sample task of Fig. 3: C-space motion control. The corresponding W-space in
Fig. 7.

a point in a higher-dimensional space) and to do C-space calculation and collision analysis
fast enough to keep the operator active at the control station. One possibility here is to
help the operator handle the environment with incomplete, rather than complete, informa-
tion; this would mean a signiﬁcant reduction in the C-space computation costs. Success
in this area will also mean applicability of the approach to a dynamic environment with
moving obstacles. Computer algorithms for motion planning with incomplete information
are available (e.g. [6]). Experiments with human subjects operating in an unknown maze
[4, 5] suggest that humans might be able to handle this case as well.

The immediate problem is to determine if the resulting three dimensional C-space will
still be as helpful to the human in performing the task as the two dimensional case was.
Also necessary will be: algorithms for computing C-space for a multi-link arm; algorithms
for collision analysis in 3D space; procedures for C-space visualization, and for arm motion
control in W-space. These are likely to raise issues of computational complexity and real-
time control.

13

Figure 7: The W-space view of the task in Fig.
6. The path produced does not contain
unnecessary “detours” common to W-space control (see Fig 4), and approaches optimal path for
this task.

References

[1] Q. Lin, C. Kuo, Virtual Teleoperation of Underwater Robots, Proceedings of the 1997

IEEE International Conference on Robotics and Automation, April 1997.

[2] P. Schenker et al., Development of a telemanipulator for dexterity enhanced micro-
surgery, Proceedings of the 2nd International Symposium on Medical Robotics and
Computer Assisted Surgery, pp. 81-88, 1995.

[3] I. Hunter et al., A Teleoperated Microsurgical Robot and Associated Virtual Environ-

ment for Eye Surgery, Presence, Vol. 2, pp. 265-280, Fall 1993.

[4] V. Lumelsky, S. Rogers, J. Watson, F. Liu, An Experimental Study of Human Per-
formance in Planning Object Motion. Final Report. University of Wisconsin Robotics
Lab. July 1997.

14

[5] F. Liu, Multivariate Analysis of Human Performance in Motion Planning. M.S. Thesis,

University of Wisconsin-Madison, Mechanical Engineering, May 1997.

[6] V. Lumelsky, Algorithmic and Complexity Issues of Robot Motion in an Uncertain

Environment, Journal of Complexity, No.3, 1987.

[7] T. Skewis, V. Lumelsky, Simulation of Sensor-Based Robot and Human Motion Plan-

ning, International Journal of Robotics and Automation, Vol.8, No. 4.

[8] T. Lozano-Perez, A Simple Motion-Planning Algorithm for General Robot Manipu-
lators, IEEE Journal of Robotics and Automation, Vol. RA-3, No. 3, pp. 224-238,
1987.

15"
Safe cooperative robot dynamics on graphs,"  This paper initiates the use of vector fields to design, optimize, and
implement reactive schedules for safe cooperative robot patterns on planar
graphs. We consider Automated Guided Vehicles (AGV's) operating upon a
predefined network of pathways. In contrast to the case of locally Euclidean
configuration spaces, regularization of collisions is no longer a local
procedure, and issues concerning the global topology of configuration spaces
must be addressed. The focus of the present inquiry is the achievement of safe,
efficient, cooperative patterns in the simplest nontrivial example (a pair of
robots on a Y-network) by means of a state-event heirarchical controller.
",http://arxiv.org/pdf/cs/0002014v1,1,"0
0
0
2

b
e
F
4
2

]

O
R
.
s
c
[

1
v
4
1
0
2
0
0
0
/
s
c
:
v
i
X
r
a

Safe Cooperative Robot Dynamics on Graphs∗

Robert W. Ghrist†

Daniel E. Koditschek‡

October 25, 2018

Abstract

This paper initiates the use of vector ﬁelds to design, optimize, and implement reactive schedules
for safe cooperative robot patterns on planar graphs. We consider Automated Guided Vehicles (AGV’s)
operating upon a predeﬁned network of pathways. In contrast to the case of locally Euclidean conﬁgu-
ration spaces, regularization of collisions is no longer a local procedure, and issues concerning the global
topology of conﬁguration spaces must be addressed. The focus of the present inquiry is the achievement
of safe, eﬃcient, cooperative patterns in the simplest nontrivial example (a pair of robots on a Y-network)
by means of a state-event heirarchical controller.

1

Introduction

Recent literature suggests the growing awareness of a need for “reactive” scheduling wherein one desires not
merely a single deployment of resources but a plan for successive re-deployments against a changing environ-
ment [19]. But scheduling problems have been traditionally solved by appeal to a discrete representation of
the domain at hand. Thus the need for “tracking” changing goals introduces a conceptual dilemma: there is
no obvious topology by which proximity to the target of a given deployment can be measured. In contrast
to problems entailing the management of information alone, problems in many robotics and automation set-
tings involve the management of work — the exchange of energy in the presence of geometric constraints.
In these settings, it may be desirable to postpone the imposition of a discrete representation long enough to
gain the beneﬁt of the natural topology that accompanies the original domain.

This paper explores the use of vector ﬁelds for reactive scheduling of safe cooperative robot patterns on
graphs. The word “safe” means that obstacles — designated illegal portions of the conﬁguration space — are
avoided. The word “cooperative” connotes situations wherein physically distributed agents are collectively
responsible for executing the schedule. The word “pattern” refers to tasks that cannot be encoded simply in
terms of a point goal in the conﬁguration space. The word “reactive” will be interpreted as requiring that
the desired pattern reject perturbations: conditions close but slightly removed from those desired remain
close and, indeed, converge toward the exactly desired pattern.

1.1 Setting: AGV’s on a Guidepath Network of Wires

An automated guided vehicle (AGV) is an unmanned powered cart “capable of following an external guidance
signal to deliver a unit load from destination to destination” where, in most common applications, the
guidepath signal is buried in the ﬂoor [5]. Thus, the AGV’s workspace is a network of wires — a graph. The
motivation to choose AGV based materials handling systems over more conventional ﬁxed conveyors rests not
simply in their ease of reconﬁgurability but in the potential they oﬀer for graceful response to perturbations in
normal plant operation. In real production facilities, the ﬂow of work in process ﬂuctuates constantly in the

∗Supported in part by National Science Foundation Grant IRI-9510673 [DK] and by National Science Foundation Grant

DMS-9971629 [RG]. A sketch of these ideas appeared as a conference proceedings [11].

†School of Mathematics, Georgia Institute of Technology, Atlanta, GA 30017, USA. ghrist@math.gatech.edu
‡Department of Electrical Engineering and Computer Science, The University of Michigan, Ann Arbor, MI 48109-2110,

USA. kod@eecs.umich.edu

1

 
 
 
 
 
 
SAFE ROBOT DYNAMICS

2

face of unanticipated workstation downtime, variations in process rate, and, indeed, variations in materials
transport and delivery rates [7]. Of course, realizing their potential robustness against these ﬂuctuations in
work ﬂow remains an only partially fulﬁlled goal of contemporary AGV systems.

Choreographing the interacting routes of multiple AGVs in a non-conﬂicting manner presents a novel,
complicated, and necessarily on-line planning problem. Nominal routes might be designed oﬄine but they
can never truly be traversed with the nominal timing, for all the reasons described above. Even under normal
operating conditions, no single nominal schedule can suﬃce to coordinate the workﬂow as the production
volume or product mix changes over time: new vehicles need to be added or deleted and the routing scheme
adapted. In any case, abnormal conditions — unscheduled process down times; blocked work stations; failed
vehicles — continually arise, demanding altered routes.

The traﬃc control schemes deployed in contemporary AGV systems are designed to simplify the real-time
route planning and adaptation process by “blocking zone control” strategies. The workspace is partitioned
into a small number of cells and, regardless of the details of their source and destination tasks, no two AGVs
are ever allowed into the same cell at the same time [5]. Clearly, this simpliﬁcation results in signiﬁcant loss
of a network’s traﬃc capacity.

In this paper, we will consider a centralized approach that employs dynamical systems theory to focus
on real-time responsiveness and eﬃciency as opposed to computational complexity or average throughput.
No doubt, beyond a certain maximum number of vehicles, the necessity to compute in the high dimensional
conﬁguration space will limit the applicability of any algorithms that arise. However, this point of view
seems not to have been carefully explored in the literature. Indeed, we will sketch some ideas about how
an approach that starts from the coupled version of the problem may lend suﬃcient insight to move back
and forth between the individuals’ and the group’s conﬁguration spaces even in real time. For the sake
of concreteness we will work in the so-called “pickup and delivery” (as opposed to the “stop and go” [2])
paradigm of assembly or fabrication, and we will not be concerned with warehousing style AGV applications.

1.2 Contributions of the Paper

The paper is organized as follows. In §2, we review fundamental facts about the topology of graphs, with
which we deﬁne the class of edge point ﬁelds — locally deﬁned dynamics that realize single letter patterns.
These act collectively as a toolbox from which to build a hybrid controller for achieving arbitrary patterns
with a single AGV. This represents a slight generalization of the scheme the second author and colleagues
have proposed in [4].

The problem of dynamics and control on non-trivial graphs is then considered in §3, beginning with a
detailed discussion of a natural intrinsic coordinate system in which to frame the conﬁguration space. We
present a topological analysis of the conﬁguration space for a pair of AGV’s on a Y-shaped graph — the
simplest nontrivial situation. Here, a clariﬁcation of the conﬁguration space presentation leads easily to a
vector ﬁeld construction that brings all initial conditions of two robots on the graph to any desired pair of
goal points while guaranteeing safety (i.e., no collisions along the way). The desire for a more decoupled
controller — the hope of an “interleaving” of otherwise independent individual patterns — impels a revised
approach to safe navigation leading to the construction of a vector ﬁeld that enables the AGV’s to “dance”
about one other at a vertex.

The dynamical features of this circulating ﬁeld are suggestive of a hybrid construction that would allow
multiple independent patterns to be safely interleaved. We proceed in §4 to construct a 12-symbol grammar
of so-called “monotone” cycles: those patterns which exclude multiple robots on a single edge of the graph.
The goal of this excursion is to tune limit cycles visiting various docking stations in such a way as to be
optimal with respect to certain notions of distance or performance.

We complete our treatment of this fundamental example by synthesizing the grammar results into a
state-event controlled hybrid system for achieving cooperative patterns. Appendix A is included to place on
a rigorous foundation the use of vector ﬁelds on graphs and conﬁguration spaces thereof.

2 Notation and Background

SAFE ROBOT DYNAMICS

2.1 Graph Topology

3

A graph, Γ, consists of a ﬁnite collection of 0-dimensional vertices V:={vi}N
1 , and 1-dimensional edges
E:={ej}M
1 assembled as follows. Each edge is homeomorphic to the closed interval [0, 1] attached to V along its
boundary points {0} and {1}.1 We place upon Γ the quotient topology given by the endpoint identiﬁcations:
Neighborhoods of a point in the interior of ej are homeomorphic images of interval neighborhoods of the
corresponding point in [0, 1], and neighborhoods of a vertex vi consist of the union of homeomorphic images
of half-open neighborhoods of the endpoints for all incident edges.

The conﬁguration spaces we consider in §3 and following are self-products of graphs. The topology of
Γ × Γ is easily understood in terms of the topology of Γ as follows [17]. Let (x, y) ∈ Γ × Γ denote an ordered
pair in the product. Then any small neighborhood of (x, y) within Γ × Γ is the union of neighborhoods
In other words, the products of
of the form N (u) × N (v), where N (·) denotes neighborhood within Γ.
neighborhoods form a basis of neighborhoods in the product space.

Given a graph, Γ, outﬁtted with a ﬁnite number N of non-colliding AGV’s constrained to move on Γ,

the (labeled) conﬁguration space of safe motions is deﬁned as

C:= (Γ × . . . × Γ) − N (∆),

(1)

where ∆:={(xi) ∈ Γ × . . . × Γ : xj = xk for some j 6= k} denotes the pairwise diagonal and N (·) denotes
(small) neighborhood.

For general graphs, the topological features of C can be extremely complicated. We do not treat the
general aspects of this problem comprehensively in this paper; rather, we restrict attention to the simplest
nontrivial example which illustrates nicely the relevant features present in the more general situation. The
topological characteristics of general conﬁguration spaces on graphs is treated in [8, 9]. Mathematically, it is
usually most interesting to pass to the quotient of C by the action of the permutation group on N elements,
thus forgetting the identities of the AGV elements; however, as such spaces are almost completely divorced
from any applications involving coordinated transport, we work on the “full” conﬁguration space C.

In order to proceed, it is necessary to clarify what we mean by a vector ﬁeld on a simplicial complex that
fails to be a manifold. This is a nontrivial issue: for example, in the case of a graph, the tangent space to a
vertex with incidence number greater than two is not well-deﬁned. We defer a more detailed discussion of
these statements to Appendix A. The essential diﬀerence is that we construct semiﬂows: ﬂows which possess
unique forward orbits.

2.2 Edge Point Fields for Single AGV Control

In the context of describing and executing patterns or periodic motions on a graph, one desires a set of
building blocks for moving from one goal to the next. We introduce the terminology and philosophy for
constructing patterns by way of the simplest possible examples: a single AGV on a graph. This avoids the
additional topological complications present in the context of cooperative motion.

We thus introduce the class of edge point ﬁelds as a dynamical toolbox for a hybrid controller. Given a
speciﬁed goal point g ∈ ej within an edge of Γ, an edge point ﬁeld is a locally deﬁned vector ﬁeld Xg on Γ
with the following properties:

Locally Deﬁned: Xg is deﬁned on a neighborhood N (ej ) of the goal-edge ej within the graph topology.

Furthermore, forward orbits under Xg are uniquely deﬁned.

Point Attractor: every forward orbit of Xg asymptotically approaches the unique ﬁxed point g ∈ ej.2

Navigation-Like: Xg admits a C0 Lyapunov function, Φg : Γ → R.

The following existence lemma (whose trivial proof we omit) holds.
1 We will assume away in the sequel the possibility of “homoclinic” edges whose boundary points are attached to the same

vertex.

2 When it is not clear from the context, we shall denote the goal point achieved by an edge point ﬂow as g(Xg ) = {g}.

SAFE ROBOT DYNAMICS

4

Lemma 1 Given any edge ej ⊂ Γ which is contractible within Γ, there exists an edge point ﬁeld Xg for any
desired goal g ∈ ej.

The only occasion for which an edge ej is not contractible in Γ is in the “homoclinic case” when both
endpoints of ej are attached to the same vertex, forming a loop.
In such instances, one may avoid the
problem by subdividing the edge to include more vertices, which is very natural in the setting of this paper,
since vertices correspond to workstations along a path.

2.3 Discrete Regulation of Patterns

We adopt the standard framework of symbolic dynamics [13]. By an excursion on a graph is meant a (possibly
inﬁnite) sequence of edges from the graph, E = ei1 . . . eiN . . . ∈ E Z, having the property that each pair of
contiguous edges, eij and eij+1 share a vertex in common. The set of excursions forms a language, L: the
so-called subshift on the alphabet deﬁned by the named edges (we assume each name is unique) [13]. The
shift operator, σ, deﬁnes a discrete dynamical system on the set of excursions, mapping the set of inﬁnite
sequences into itself by decrementing the time index. An M -block extension of the original language arises
in the obvious way from grouping together each successive block of M contiguous letters from an original
sequence, and it is clear how σ induces a shift operator, σM on this derived set of sequences.

Given a legal block, B = ei1 . . . eiM ∈ L, we will say that an excursion realizes that pattern if its M -block
extension eventually reaches the “goal” BBBBB . . . under the iterates of σM . In other words, after some
ﬁnite number of applications of σ, the excursion consists of repetitions of the block B (terminating possibly
with the empty edge).

In a previous paper [4], the second author and colleagues introduced a very simple but eﬀective discrete
event controller for regulating patterns on graphs from all reachable initial edges by pruning the graph back
to a tree (imposing an ordering). Of course, this simple idea has a much longer history. In robotics it was
introduced in [14] as “pre-image backchaining;” pursued in [15] as a method for building veriﬁable hardened
automation via the metaphor of a funneling; and in [6] as a means of prescribing sensor speciﬁcations from
goals and action sets. In the discrete event systems literature an optimal version of this procedure has been
introduced in [3] and a generalization recently has been proposed in [18].

Let E 0:=B ⊂ E denote the edges of Γ that appear in the block of letters specifying the desired pattern.

Denote by

E n+1 ⊂ E −

E k

[k≤n

those edges that share a vertex with an edge in E n but are not in any of the previously deﬁned subsets. This
yields a ﬁnite partition of E into “levels,” {E p}P
i ∈ E p, there can be found
a legal successor edge, ep−1
∈ E p−1, such that ep
∈ L is a legal block in the language. Note that we
have implicitly assumed E 0 is reachable from the entire graph — otherwise, there will be some “leftover”
component of E forming the last cell in the partition starting within which it is not possible to achieve the
pattern. Note as well that we impose some ordering of each cell E p = {ep
i=1: the edges of E 0 = B are
ordered by their appearance in the block; the ordering of edges in higher level cells is arbitrary.

p=0, such that for each edge, ep
i ep−1

i }Mp

j

j

We may now deﬁne a “graph controller” law, G:E → E as follows. From the nature of the partition {E p}

above, it is clear that the least legal successor function,

L(ep

i ):=

(cid:26)

min{j ≤ Mp : ep

i + 1 mod M
i ep−1

j

is well-deﬁned. From this, we construct the graph controller:

G(ep

i ):=ep−1

L(p,i).

: p = 0
: p > 0

,

∈ L}

(2)

(3)

It follows almost directly from the deﬁnition of this function that its successive application to any edge leads
eventually to a repetition of the desired pattern:

Proposition 2 The iterates of G on E achieve the pattern B.

SAFE ROBOT DYNAMICS

2.4 Hybrid Edge Point Fields

5

A semiﬂow, (X)t, on the graph induces excursions in L parametrized by an initial condition as follows. The
ﬁrst letter corresponds to the edge in which the initial condition is located (initial conditions at vertices are
assigned to the incident edge along which the semiﬂow points). The next letter is added to the sequence by
motion through a vertex from one edge to the next.

We will say of two edge point ﬁelds, X1, X2 on a graph, Γ, that X1 prepares X2, denoted X1 ≻ X2, if the
goal of the ﬁrst is in the domain of attraction of the second, g(X1) ⊂ N (X2). Given any ﬁnite collection of
edge point ﬁelds on Γ, we will choose some 0 < α < 1 and assume that their associated Lyapunov functions
have been scaled in such a fashion that X1 ≻ X2, implies (Φ1)−1[0, α] ⊂ N (X2). In other words, an α
crossing of the trajectory Φ1 ◦ (X1)t signals arrival in N (X2).
Suppose now that for every edge in some pattern block, e0

i ∈ E 0, there has been designated a goal point,
g0
i , along with an edge point ﬁeld X 0
i . Assume as well that the edge point ﬁeld
associated with each previous edge in the pattern prepares the ﬂow associated with the next edge, in other
words, using the successor function (2) we have,

i taking that goal, g(X 0

i ) = g0

g

X 0
j

⊂ N

X 0

L(j)

.

Now construct edge point ﬁelds on all the edges of Γ such that the tree representation of their ≻ relations
is exactly the tree pruned from the original graph above — namely we have

(cid:0)

(cid:1)

(cid:16)

(cid:17)

g

X p
j

⊂ N

X p−1
L(j)

.

(cid:16)
We are ﬁnally in a position to construct a hybrid semi-ﬂow on Γ. This feedback controller will run the

(cid:17)

(cid:1)

(cid:0)

piece-wise smooth vector ﬁeld, ˙x = X, as follows

X p
j
X p−1
L(j)

X:=

(

:x ∈ ep
:x ∈ ep−1

j and Φp
L(j) or Φp

j > α
j ≤ α

.

(4)

It is clear from the construction that progress from edge to edge of the state of this ﬂow echoes the graph
transition rule G, constructed above.

Proposition 3 The edge transitions induced by the hybrid controller (4) are precisely the iterates of the
graph map, G, (3) in the language, L.

3 The Y-Graph

We now turn our attention to the safe control of multiple AGV’s on a graph work-space via vector ﬁelds.
For the remainder of this work, we consider the simplest example of a non-trivial conﬁguration space: that
associated to the Y-graph, Υ, having four vertices {vi}3
1, as illustrated in Figure 1.
Although this is a simple scenario compared to what one ﬁnds in a typical setting, there are several reasons
why this example is in many respects canonical.

0 and three edges {ei}3

1. Simplicity: Any graph may be constructed by gluing K-prong graphs together for various K. The
K = 3 model we consider is the simplest nontrivial case and is instructive for understanding the
richness and challenges of local cooperative dynamics on graphs.

2. Genericity with respect to graphs: Graphs which consist of copies of Υ glued together, the trivalent
graphs, are generic in the sense that any nontrivial graph may be perturbed in a neighborhood of the
vertex set so as to be trivalent. For example, the 4-valent graph resembling the letter ‘X’ may be
perturbed slightly to resemble the letter ‘H’ — a trivalent graph. An induction argument shows that
this is true for all graphs. Hence, the dynamics on an arbitrary graph are approximated by patching
together dynamics on copies of Υ.

SAFE ROBOT DYNAMICS

6

3. Genericity with respect to local dynamics: Finally, pairwise local AGV interactions on an ar-
bitrary graph restrict precisely to the dynamics of two agents on Υ as follows. Given a vertex v of a
graph Γ, assume that two AGV’s, x and y, are on diﬀerent edges e1 and e2 incident to v and moving
towards v with the goal of switching positions. A collision is imminent unless one AGV “moves out of
the way” onto some other edge e3 incident to v. The local interactions thus restrict to dynamics of a
pair of AGV’s on the subgraph deﬁned by {v; e1, e2, e3}. Hence, the case we treat in this paper is the
generic scenario for the local resolution of collision singularities in cooperative dynamics on graphs.

3.1

Intrinsic Coordinates

The conﬁguration space of N points on Υ is a subset of the N -fold cartesian product Υ × Υ × · · · × Υ.
Since each graph which is physically relevant to the setting of this paper is embedded in a factory ﬂoor
or ceiling and thus planar, the conﬁguration space CN (Υ) embeds naturally in R2N . We wish to modify
this embedding to facilitate both analysis on and visualization of the conﬁguration space. We will present
alternate embeddings in both higher and lower dimensional Euclidean spaces for these purposes.

We begin with representing the conﬁguration space within a higher-dimensional Euclidean space via a
coordinate system which is intrinsic: it is independent of how the graph is embedded in space. We illustrate
this coordinate system with the Y-graph Υ, noting that a few simple modiﬁcations yields a coordinate scheme
for more general graphs.

Let {ei}3

1 denote the three edges in Υ, parametrized so that ei is identiﬁed with [0, 1] with each {0} at
the center v0 of Υ. Any point in Υ is thus given by a vector x in the {ei} basis whose magnitude |x| ∈ [0, 1]
determines the position of the point in the ei direction. Denote by ι(x) the value of i so that x = |x|eι(x).
This parametrization embeds Υ as the positive unit axis frame in R3. Likewise, a point in C is given as a pair
of distinct vectors (x, y), i.e., as the positive unit axis frame in R3 cross itself sitting inside of R3 × R3 ∼= R6.
We have thus embedded the conﬁguration space of two distinct points on Υ in the positive orthant of R6. It
is clear that one can embed the more general conﬁguration space of N points on Υ in R3N in this manner.
This coordinate system is particularly well-suited to describing vector ﬁelds on C and in implementing
numerical simulations of dynamics, as the coordinates explicitly keep track of the physical position of each
point on the graph.

3.2 A Topological Analysis

More useful for visualization purposes, however, is the following construction which embeds C within R3.

PSfrag replacements

e3

v3

v1

e1

PSfrag replacements
v0
v1
v2
v3
e1
e2
e3

v2

v0

e2

Figure 1: [left] The Y -graph Υ; [right] the conﬁguration space C embedded in R3.

Theorem 1 The conﬁguration space C associated to a pair of AGV’s restricted to the Y -graph Υ is home-
omorphic to a punctured disc with six 2-simplices attached as in Figure 1.

SAFE ROBOT DYNAMICS

7

Proof: Recall that C consists of pairs of distinct vectors (x, y) in intrinsic coordinates. Restrict attention

to the subspace D ⊂ C deﬁned by

D := {(x, y) ∈ C : ι(x) 6= ι(y)},

(5)

where an undeﬁned index is considered to be diﬀerent than one which is deﬁned. Thus, D consists of those
conﬁgurations for which both AGV’s do not occupy the same edge interior.

The set D has a natural cellular decomposition as follows. There are 2 AGV’s and 3 edges in Υ; hence,
there are 3 · 2 = 6 cells Di,j ⊂ D where i := ι(x) 6= ι(y) =: j. Since (the closure of) each edge in Υ is
homeomorphic to [0, 1] (determined by | · |), the cell Di,j is homeomorphic to ([0, 1] × [0, 1]) − {(0, 0)}, where,
of course, the origin (0, 0) is removed as it belongs to the diagonal ∆. A path in D can move from cell to
cell only along the subsets where the index of one AGV changes: e.g., |x| = 0 or |y| = 0. Thus, the edges
{0} × (0, 1] and (0, 1] × {0} of the punctured square Di,j are attached respectively to Dk,j and Di,k, where
k is the unique index not equal to i or j.

(cid:16)

(cid:17)

|y|
|x|

Furthermore, each 2-cell Di,j has a product structure as follows: decompose Di,j along lines of constant
θ := tan−1
. It is clear that θ is the angle in the unit ﬁrst quadrant in which Di,j sits. Hence, each
Di,j is decomposed into a product of a closed interval Si,j := θ ∈ [0, π/2] (an ‘angular’ coordinate) with the
half-open interval (0, 1] (a ‘radial’ coordinate). As this product decomposition is respected along the gluing
edges, we have a decomposition of all of D into the product of (0, 1] × S, where S is a cellular complex
given by gluing the six segments Si,j end-to-end cyclically along their endpoints. The set S is a 1-manifold
without boundary since each Si,j is a closed interval, each of whose endpoints is glued to precisely one other
Si,j. Hence, by the classiﬁcation of 1-manifolds, S is homeomorphic to a circle. We have thus decomposed
D as the cross product of a circle with (0, 1] — a punctured unit disc.

The complement of D in C consists of those regions where ι(x) = ι(y). For each i = 1..3, the subset
of C where ι(x) = ι(y) = i is homeomorphic to ((0, 1] × (0, 1]) − {|x| = |y|}: this consists of two disjoint
triangular “ﬁns.” A total of six such ﬁns are thus attached to D along the six edges where |x| or |y| = 0. In
the coordinates of the product decomposition for D, these ﬁns emanate along the radial lines where θ equals
⋄
zero or π/2, yielding the topological space illustrated in Figure 1.

The precise drawing of Figure 1 represents this punctured disc D as a hexagon-shaped complex with a
punctured center: this follows from the cellular structure of D as being built from six squares sewn together.

Corollary 4 Given any pair of goals g:=(g1, g2) where g1 and g2 live on diﬀerent branches of Υ, there
exists a navigation function (of class piecewise real-analytic) generating a semiﬂow which sends all but a
measure-zero set of initial conditions to g under the gradient semiﬂow.

Proof: The subset D ⊂ C is homeomorphic to a punctured disc S×(0, 1], and may be easily compactiﬁed
to an annulus S × [0, 1] by removing an open neighborhood of the diagonal. Then, the conditions for the
theorems of Koditschek and Rimon [12] are met, since an annulus is a sphereworld. Hence, not only does a
navigation function Φ on this subspace exist, but an explicit procedure for determining Φ is given [12]. One
may then extend Φ to the remainder of C as follows: choose a point (x, y) on the ﬁn and deﬁne

Φ(x, y) :=

1
1 − |x|
1
1 − |y|




Φ(0, y)

Φ(x, 0)

;

;

|x| < |y|

|y| < |x|

,

(6)

so that Φ increases sharply along the ﬁns. This directs the gradient ﬂow to monotonically “descend” away
from the diagonal and onto D. Note that D is forward-invariant under the dynamics, and, that upon
prescribing the vector ﬁeld on the ﬁns to point transversally into D, we have deﬁned a semiﬂow, and hence
⋄
a well-deﬁned navigational procedure.



This result is very satisfying in the sense that it guarantees a navigation function by applying existing
theory to a situation which, from the deﬁnition alone, would not appear to be remotely related to a sphere-
world. However, a deeper analysis of conﬁguration spaces of graphs [9] reveals that for more than two AGV’s,
the conﬁguration space is never a sphereworld.3 Hence, we consider an alternate solution to the problem of
3The conﬁguration space of a graph turns out to be aspherical: there are no essential closed spheres of dimension larger

than one.

SAFE ROBOT DYNAMICS

8

realizing compatible goals by means of a vector ﬁeld on the conﬁguration space. This method is adaptable
to more complicated settings.

3.3 Example: a Circulating Flow

Before proceeding with a general scheme for controlling two agents on the Y-graph, we present a simple
example of a vector ﬁeld on the conﬁguration space which can be used to regularize collisions about a
generic trivalent vertex. Theorem 1 and Figure 1 suggest a natural circulating ﬂow on the conﬁguration
space C which has the eﬀect of inducing a “dance” between the pair of AGV’s which cycles through all
combinations of distinct point goals.

Theorem 2 There exists a piecewise-smooth vector ﬁeld X on C which has the following properties:

1. X deﬁnes a nonsingular semiﬂow on C;

2. The diagonal ∆ is repelling with respect to X; and

3. Every orbit of X approaches a unique attracting limit cycle on C which cycles through all possible

ordered pairs of distinct edge-states.

Proof:
Denote by D that portion of the conﬁguration space which corresponds to the AGV’s being
on distinct edges of the graph: as proven earlier, D is homeomorphic to a punctured disc. The intrinsic
coordinates on the conﬁguration space C is illustrated in Figure 2, where only D is shown for illustration
purposes. The reader should think of this as a collection of six square coordinate planes, attached together
pairwise along axes with the origin removed (this is actually an isometry for the natural product metric).
The six triangular ﬁns are then attached as per Figure 1.

(e3, 0)

(0, e2)

(0, e1)
PSfrag replacements

(e2, 0)

(e1, 0)

PSfrag replacements
(e1, 0)
(0, e3)
(e2, 0)
(0, e1)
(e3, 0)
(0, e2)

(0, e3)

Figure 2:
typical orbit.

[left] The coordinate system on the unﬁnned region D of C; [right] The circulating ﬂow with a

Recal that any point in the graph is represented as a vector x = |x|ei for some i. Denote by ˆei the unit
tangent vector in each tangent space Txei pointing in the positive (outward) direction towards the endpoint
vi. The vector ﬁeld we propose is the following: given (x, y) ∈ C,

1. If ι(x) = ι(y) then

˙x = −|y|ˆeι(x)
˙y = |y|(1 − |y|)ˆeι(y) (cid:27)
˙x = |x|(1 − |x|)ˆeι(x)
˙y = −|x|ˆeι(y)

(cid:27)

(cid:26)

(cid:26)

0 < |x| < |y|

0 < |y| < |x|

(7)

SAFE ROBOT DYNAMICS

2. If ι(x) = ι(y) + 1 or |x| = 0 then

˙x = |y|ˆe(ι(y)+1)
˙y = |y|(1 − |y|)ˆeι(y) (cid:27)
˙x = |x|(1 − |x|)ˆeι(x)
˙y = −|x|ˆeι(y)

(cid:27)

(cid:26)

(cid:26)

0 ≤ |x| < |y|

0 < |y| ≤ |x|

3. If ι(y) = ι(x) + 1 or |y| = 0 then

˙x = −|y|ˆeι(x)
˙y = |y|(1 − |y|)ˆeι(y) (cid:27)
˙x = |x|(1 − |x|)ˆeι(x)
˙y = |x|ˆe(ι(x)+1)

(cid:27)

(cid:26)

(cid:26)

0 < |x| ≤ |y|

0 ≤ |y| < |x|

9

(8)

(9)

Note that all addition operations on ι(x) and ι(y) are performed mod three.

The vector ﬁeld is nonsingular as follows: if |x||y| 6= 0, then the vector ﬁeld is by inspection nonsingular.
If |x| = 0, then |y| > 0 = |x| since the points are distinct. It then follows from Equation (8) that the vector
ﬁeld on this region has d|x|/dt = |y| 6= 0. A similar argument holds for the case where |y| = 0.

The vector ﬁeld deﬁnes a semiﬂow as follows: on those regions where 0 6= |x| 6= |y| 6= 0, the vector ﬁeld
is smooth and hence deﬁnes a true ﬂow. Along the lines where |x| = |y|, the vector ﬁeld is only C0, but
nevertheless is constructed so as to deﬁne unique solution curves; hence the region D, where ι(x) 6= ι(y),
is invariant under the ﬂow. Finally, along the branch line curves where |x| = 0 or |y| = 0, the vector ﬁeld
points into the the branch lines from the ﬁns, implying that the dynamics is a semiﬂow (see the remarks in
Appendix A).

This vector ﬁeld admits a C0 Lyapunov function Φ : C → [0, 1) of the form

Φ(x, y):=

(cid:26)

1 − |(|x| − |y|)|
1 − max {|x|, |y|}

: ι(x) = ι(y)
: ι(x) 6= ι(y)

.

From Equation (7), one computes that on the ﬁns (ι(x) = ι(y)),

since here |x| 6= |y|. Furthermore, on the disc D (ι(x) 6= ι(y)), Φ changes as

dΦ
dt

= −

d|x|
dt

−

d|y|
dt

< 0,

(
(cid:12)
(cid:12)
(cid:12)
(cid:12)

)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

dΦ
dt

= Φ(Φ − 1).

Hence, Φ strictly decreases oﬀ of the boundary of the disc

∂D:= {(x, y) : |x| = 1 or |y| = 1} = Φ−1(0).

(10)

(11)

(12)

(13)

It follows from the computation of dΦ/dt that the diagonal set ∆ of Υ×Υ is repelling, and that the boundary
⋄
cycle ∂D is an attracting limit cycle.

The action of the vector ﬁeld is to descend oﬀ of the “ﬁns” of C onto the region D, and then to circulate

about while pushing out to the boundary cycle ∂D, as in Figure 2.

This example illustrates how one can use a relatively simple vector ﬁeld on the conﬁguration space to
construct a pattern which is free from collisions. In fact, one could use this circulating ﬂow to regularize
potential collisions between AGV’s in a general graph setting by localizing the dynamics near a pairwise
collision to those on a trivalent subgraph.

SAFE ROBOT DYNAMICS

10

4 Patterns and Vector Fields for Monotone Cycles

Optimization of patterns in the workspace is deeply entwined with the geometry of the conﬁguration space:
in [10], it is shown that various Finsler structures on C can be chosen to optimize total distance traveled or
net time elapsed. The net result of this inquiry is that minimizing Euclidean distance (in the product of
the graph metric) on the cells of the conﬁguration space yields locally optimal conﬁguration sequences with
respect to both distance traversed and elapsed time. In this section, we consider the problem of constructing
vector ﬁelds which are tuned to trace out speciﬁc patterns of cooperative dynamics. We begin with a
speciﬁcation of a suitable language for describing patterns.

4.1 A Grammar for Patterns

The setting we envisage is as follows: the three ends of the graph Υ are stations at which an AGV can
perform some function. The AGV pair is required to execute an ordered sequence of functions, requiring an
interleaved sequence of visitations. In order to proceed with vector ﬁeld controls for cooperative patterns, it
is helpful to construct the appropriate symbolic language, as done in §2 for single AGV systems. Denote the
pair of AGV states as x and y respectively. Also, denote the three docking stations as vertices v1 through
v3 as in Figure 1. The grammar G we use is deﬁned as follows:

• (xi): These represent conﬁgurations for which the AGV x is docked at the vertex vi, i = 1..3. The

AGV y is at an unspeciﬁed undocked position.

• (yi): These represent conﬁgurations for which the AGV y is docked at the vertex vi, i = 1..3. The

AGV x is at an unspeciﬁed undocked position.

• (xiyj): These represent conﬁgurations for which the AGV x is docked at vertex vi while the AGV y is

simultaneously docked at the vertex vj, j 6= i.

For example, the word (x1)(y2)(x3y2) executes a sequence in which the ﬁrst AGV docks at Station v1, then
undocks while the second AGV docks at Station v2. Finally, the AGV’s simultaneously dock at Stations v3
and v2 respectively.

As we have assumed from the beginning, the one-dimensional nature of the graph-constraints precludes
the presence of multiple agents at a single docking station; hence, there are exactly twelve symbols in the
grammar G. From this assumption, it follows that particular attention is to be paid to those trajectories
which do not make excursions onto the “ﬁns” of the conﬁguration space. It is obvious from the physical nature
of the problem that planning paths which involve traveling on the ﬁns is not a locally optimal trajectory
with respect to minimizing distance or elapsed time. Suﬃce to say that we restrict attention for the moment
to trajectories, and limit cycles for patterns in particular, which are constrained to the region D ⊂ C.

We identify each symbol with a region of the boundary of the unbranched portion of C; namely, ∂D is
partitioned into twelve docking zones as in Figure 3. Note further that there is a cyclic ordering, <∂, on G
induced by the orientation on the boundary of the disc along which the zones lie. By a cyclic ordering, we
mean a way of determining whether a point q lies between any ordered pair of points (p1, p2).

We proceed with the analysis of limit cycles on C. Consider the class of pattern vector ﬁelds, XP , on C:

for every X ∈ XP ,

1. X deﬁnes a semiﬂow on C and a genuine ﬂow oﬀ of the non-manifold set of C;

2. There is a unique limit cycle γ which is attracting and which traces out a nonempty word in the

grammar G;

3. The diagonal set ∆ is a repellor with respect to X;

4. There are no ﬁxed invariant sets of X which attract a subset of positive measure save γ.

Then, the class of monotone vector ﬁelds, XM , is that subset of XP for which the limit cycle, γ, lies in D.
A word w composed of elements w = w1w2...wn in the grammar G said to be monotone with respect to the

SAFE ROBOT DYNAMICS

11

(x3y2)

PSfrag replacements

(x3y1)

(x3)

(y2)

(x1y2)

(y1)

(x1)

(x2y1)

(x2)

(y3)

(x1y3)

(x2y3)

Figure 3: The six pairs of contiguous edges in ∂D each corresponds to a conﬁguration where one AGV is
docked at an extreme vertex of the graph. Outermost vertices of ∂D are points where both AGV’s are
docked. Labelling the edges (xi) and (yj) and the vertices (xiyj) yieldsd the cyclically ordered grammar G.

cyclic ordering <∂ if wi−1<wi<wi+1 for every i (index operations all mod n). The following result justiﬁes
our use of the term monotone in describing those limit cycles which lie on the disc.

Theorem 3 Within the class of vector ﬁelds XM , the limit cycles trace out monotone words in the cyclically
ordered grammar (G, <∂).

Proof: Any limit cycle of the ﬂow must be embedded (the curve does not intersect itself). After a
small perturbation, one may assume that the boundary zone ∂D is visited by γ in a ﬁnite number of points,
Q := γ ∩ ∂D. There is a cyclic order <t, deﬁned via time with respect to the dynamics of the limit cycle: i.e.,
the order in which points are visited by γ. This is contrasted with the induced cyclic ordering <∂ on the set
Q given by the orientation of the boundary curve ∂D, up to a choice between clockwise and counterclockwise.
The theorem follows from showing that <t = <∂ up to a cyclic permutation and a choice of orientation of
∂D.

Induct on J the number of points in Q. For J = 1, the theorem is trivially true, so assume that the
orderings are equivalent for all embedded curves on a disc with less than J boundary-intersections. Consider
two points p, q ∈ Q which are consecutive in the <t ordering. There is an embedded sub-arc α ⊂ γ which
connects p to q within the interior of D. By the Jordan Curve Theorem [17], α separates D into two topological
discs; hence, γ must lie entirely within the closure of one of these discs. Consider the open subdisc whose
intersection with γ is empty and collapse the closure of this disc to a point: this yields a modiﬁed curve ˜γ
which is still embedded in a disc having J − 1 intersections with the boundary, as illustrated in Figure 4.
By induction, the ordering <t equals <∂ up to orientation on this subdisc. Reinserting the distinct points p
and q by “blowing up” the crushed disc does not change the ordering properties, since these were chosen to
⋄
be adjacent.

Hence, the ony admissible words in the grammar G are those which are monotone. It is, however, possible
to realize many if not all of the non-monotone cycles as limit cycles for a semiﬂow on the full conﬁguration
space C; one must design the semiﬂow so as to utilize the ﬁns for “jumping” over regions of D cut oﬀ by
the limit cycle. Such vector ﬁelds quickly become very convoluted, even for relatively simple non-monotone
limit cycles.

SAFE ROBOT DYNAMICS

12

p

q

x

PSfrag replacements

x

α

PSfrag replacements
p
q

α

Figure 4: The embedded arc α divides D (pictured as a smooth disc) into two discs, one of which is collapsed
to a point x.

4.2

Isotopy Classes of Limit Cycles

Given a limit cycle γ which traces out a pattern by visiting the boundary zone ∂D in the ordered set Q ⊂ ∂D,
one wants to know which other limit cycles minimize a given performance functional while still visiting Q
in the proper sequence. The mathematical framework for dealing with this problem is the notion of isotopy
classes of curves.

Two subsets A0 and A1 of a set B are said to be (ambiently) isotopic rel C (where C ⊂ B) if there exists

a continuous 1-parameter family of homeomorphisms, ft : B→B such that

1. f0 is the identity map on B;

2. f1(A0) = A1; and

3. ft|C is the identity map on C for all t.

As t increases, ft deforms B, pushing A0 to A1 without cutting or tearing the spaces and without disturbing
C.

There are two ways in which optimization questions relate to isotopy classes of limit cycles: (1) Given
an element of the grammar G, in which isotopy class (rel the docking zones) of curves does an optimal limit
cycle reside? (2) Within a given isotopy class of cycles rel Q, which particular cycle is optimal?

For a monotone limit cycle on D, the above question (1) focuses on the location of the cycle with respect
to the central point (0, 0), which is deleted from the disc D.
It is a standard fact from planar topology
that every curve in the punctured disc has a well-deﬁned winding number, which measures how many times
the cycle goes about the origin, and, furthermore, that this number is either -1, 0, or 1 if the cycle is an
embedded curve. This winding number determines the isotopy class of the curve in D. Hence, the problem
presents itself: given an element of the grammar G, which isotopy class rel the docking zones is optimal (with
respect to any/all of the functionals deﬁned)? Is the winding number zero or nonzero?4

To brieﬂy address this question, we deﬁne the gap angles associated to a limit cycle. Given the docking
zones Q = {q1, q2, . . . , qJ } ordered with respect to time, we deﬁne the gap angles to be the successive
diﬀerences in the angular coordinates of the qj: thus gaj := P (qj+1) − P (qj), where P denotes projection of
points in D onto their angular coordinates and subtraction is performed with respect to the orientation on
∂D.

For simplicity, we consider the optimization–isotopy problem in the case of a discrete cost functional Wd,
deﬁned to be the intersection number of the path with the branch locus of C — i.e., the number of times an
AGV occupies the central vertex (the shared resource in the problem). Similar arguments are possible for
other natural performance metrics [10].

Proposition 5 There is a Wd-minimizing embedded monotone cycle on D (rel a given docking zone Q)
having winding number zero with respect to the origin if there is a gap angle greater than π. Conversely, if
there are no gap angles greater than π, then there is a Wd-minimizing embedded cycle of index ±1.

4The diﬀerence between +1 and -1 is the orientation of time.

SAFE ROBOT DYNAMICS

13

Proof:

Let Q consist of the points {qj}J

1 are the
diﬀerences of the angles between the points qj and qj+1 (indices mod J). Since
j gaj = 2π, there can be
at most one gap angle greater than π. To simplify the problem, use a 1-parameter family Pt of maps from
the identity P0 to the projection P = P1 which deforms D to the boundary circle S := ∂D by projecting
continuously along radial lines. The index of a curve on D is invariant under this deformation, as is the
function Wd.

1 on the boundary circle. The gap angles {gaj}J

P

Denote by γj, the subarc of γ between points qj and qj+1 (all indices mod J). Denote by αj the subarc
of the boundary S between points qj and qj+1, where the arc is chosen to subtend the gap angle gaj. Since
the boundary curve S = ∪jαj is a curve of index ±1, the arcs γj and αj are isotopic in D rel their endpoints
for all j if and only if γ is a curve of index ±1.

Assume ﬁrst that there is a gap angle gaj > π with γ an index ±1 curve on S which intersects the branch
angles Θ = {nπ/3 : n ∈ Z} in a minimal number of points among all other closed curves on S which visit
the points Q in the speciﬁed order. It follows that the arc P (γj) subtends an angle greater than π and thus
increments Wd by at least three. One may replace γj by a curve γ′
j which substitutes for the arc γj one
which wraps around ‘the other way’ monotonically. This changes the index of γ from nonzero to zero, since
the arc γ′
j is no longer isotopic to αj. Also, it is clear that this either decreases the number of intersections
with Θ or leaves this number unchanged.

We must show that the replacement arc γ′

j can be chosen in such a way that is does not intersect the
remainder of γ. However, since γ is a curve of index ±1, we may isotope each arc γi to the boundary curve
αi without changing the value of Wd. Thus, we may remove γj and replace it with the curve which is, say,
a geodesic (in the natural metric geometry) from qj to qj+1. As this curve does not approach the boundary
S apart from its ends, the new curve γ′ is an embedded curve of index zero without an increase in Wd.

Assume now, on the contrary, that γ is a Wd minimizer of index zero which has all gap angles strictly
less than π. Then each arc from γi must intersect the branch set Θ in at most three components, since,
otherwise, the subtended arc would be in excess of 4π/3. In the case where there exists an arc with exactly
three intersections with the branch set, this arc may be replaced by an arc which goes around the singularity
in the other direction without changing the number of intersections with the branch set (since there are a
total of six branch lines); however, the index of the curve is toggled between zero and nonzero.

The ﬁnal case is that in which each arc intersects the branch set in at most two places. However, since γ
is a curve of index zero, some arc γj must not be isotopic to αj. Hence, the projection deformations Pt must
push γj to a curve in the boundary which S whose subtended gap angle is 2π − gaj > π. Thus, γj intersects
the branch set in at least three places, yielding a contradiction. Replacing γj by the appropriate arc which
is isotopic to αj yields a Wd-minimal cycle of nonzero index.
⋄

4.3 Tuning Cycles

In order to proceed with the construction of vector ﬁelds which realize monotone cycles, we work with vector
ﬁelds on the smooth unit disc in R2 and map these to the annular region D of the conﬁguration space via the
push-forward induced by the natural homeomorphism. It will be convenient to keep track of which “wedge”
of the annular region a point (r, θ) is. To do so, we introduce a parity function

P (θ) := (−1){⌊3θ/π⌋+⌊6θ/π⌋},

(14)

where ⌊t⌋ is the integer-valued ﬂoor function. Recall the notation for the intrinsic coordinates for a point x
on the graph Υ: x = |x|ˆeι(x), where |x| ∈ [0, 1] is the distance from x to the central vertex, and ˆeι(x) is the
unit tangent vector pointing along the direction of the ι(x)-edge. Here the index, ι(x) is an integer (deﬁned
modulo 3) and will be undeﬁned in the case when |x| = 0, i.e., x is at the central vertex.

Lemma 6 The following is a piecewise-linear homeomorphism from the punctured unit disc in R2 to the

SAFE ROBOT DYNAMICS

subset D: F (r, θ) = (x, y) where,

|x| =

P(θ) = +1

P(θ) = −1

P(θ) = +1
P(θ) = −1

(

r

r

r
cot 3
2 θ
tan 3
(cid:12)
(cid:12)
2 θ
(cid:12)
(cid:12)
(cid:12)
(cid:12)
r
(cid:12)
(cid:12)
(cid:12)
(cid:12)
− 3
(cid:12)
(cid:12)
2π (θ − π)
− 3
k
j
2π θ

|y| =

(
ι(x) =

ι(y) =

14

.

(15)

The inverse of this homeomorphism is given by F −1(x, y) = (r, θ), where,

j

k

2

3 tan−1 |y|
3 tan−1 |y|
− 2

|x|

|x|

− 2π

3 (ι(y) + 1)

− 2π

3 (ι(x) − 1)

ι(y) = ι(x) + 1
or |x| = 0
ι(x) = ι(y) + 1
or |y| = 0

.

(16)

|x| P(θ) = +1
|y| P(θ) = −1

θ = 


(cid:26)

r =

Note that all θ values are deﬁned modulo 2π and all index values are integers deﬁned modulo 3.

Proof: Begin by working on the region D1,2 ⊂ D where ι(x) = 1 and ι(y) = 2. As noted earlier, this
subspace is isometric to the positive unit square in R2 with the origin removed. We need to map this to
the subset {(r, θ) : r ∈ (0, 1], θ ∈ [0, π/3]}. The simplest such homeomorphism is to ﬁrst shrink along radial
lines, leaving the angle invariant; hence

|x|
|y|

: |x| ≤ |y|
: |y| ≤ |x|

r =

(cid:26)

(17)

Next, we squeeze the quarter-circle into a sixth of a circle by multiplying the angle by 2/3, leaving the radial
coordinate invariant:

θ =

2
3

tan−1 |y|
|x|

.

(18)

This gives the basic form of F −1 as per Equation (16). To extend this to the remainder of D, it is necessary to
carefully keep track of ι(x) and ι(y) and subtract oﬀ the appropriate angle from the computation of θ. Also,
the condition of |x| ≤ |y|, etc., in Equation (17) is incorrect on other domains of D, since the inequalities
ﬂip as one traverses from square to square: the parity function P(θ) keeps track of which “wedge” one is
working on.

To determine F from F −1 is a tedious but unenlightening calculation, made more unpleasant by the
various indices to be kept track of. Brieﬂy, given r and θ on the ﬁrst sixth of the unit disc, one knows from
Equation (17) that either |x| = r or |y| = r, depending on whether θ is above or below π/4. To solve for
respectively. To
the other magnitude, one inverts Equation (18) to obtain |y| = r
generalize this to the other Di,j domains of D, it is necessary to take absolute values and to use the parity
function P(θ) as before. Finally, the computation of the index is obtainable from the combinatorics of the
⋄
coordinate system as illustrated in Figure 2.

tan 3
2 θ

cot 3
2 θ

or |x| = r

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

(cid:12)
(cid:12)
(cid:12)

Hence, by taking the push-forward of a vector ﬁeld X = ( ˙r, ˙θ) with respect to F , one obtains the piecewise

smooth vector ﬁeld,

˙|x| = ˙r
˙|y| = ˙r
˙|x| = ˙r
˙|y| = ˙r

tan( 3
cot( 3
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

2 θ)
(cid:12)
2 θ)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)






+ 3
+ 3

2 r ˙θ sec2( 3
2 r ˙θ csc2( 3

2 θ) !
2 θ)

!

P(θ) = +1

P(θ) = −1

,

(19)

 
 
SAFE ROBOT DYNAMICS

which simpliﬁes to:

15

2 

P(θ) = +1







P(θ) = −1

.

(20)

˙|x| = ˙r
˙|y| = ˙r

|y|
|x|

+ 3
2

˙θ

˙|x| = ˙r

|x|
|y|

+ 3
2

˙θ









˙|y| = ˙r










|x|

|y|
|x|

(cid:18)
|y|

|x|
|y|

(cid:18)

1 +

1 +

(cid:19)
2

(cid:19)





Given a simple closed curve γ in R2 which has nonzero winding number with respect to the origin, γ
may be parametrized as {(r, θ) : r = f (θ)} for some periodic positive function f . To construct a vector
ﬁeld on R2 whose limit sets consist of the origin as a source and γ as an attracting limit cycle, it suﬃces
˙θ = ω under the planar homeomorphism
to take the push-forward of the vector ﬁeld ˙r = r(1 − r)
φ : (r, θ) 7→ (f (θ)r, θ), which rescales linearly in the angular component. The calculations follow:

˙r
˙θ

φ∗

(cid:18)

(cid:19)

= Dφ

˙r
˙θ

(cid:18)

r

r7→ r
(cid:19)(cid:12)
f
(cid:12)
(cid:12)
r − f ′ω
(cid:12)
f

1 −

ω

=



(cid:18)



(cid:19)





=

f
0

rf ′
1

(cid:20)

(cid:21) (cid:18)

r(1 − r)
ω

r7→ r
(cid:19)(cid:12)
f
(cid:12)
(cid:12)
(cid:12)

.

(21)

Hence, given f (θ), we may tune a vector ﬁeld to trace out the desired limit cycle and then use Equations (15)
and (16) to map it into intrinsic coordinates.

4.4 Optimal Chords within a Hybrid Controller

To design optimal cycles with winding number zero, then, we turn to constructing customized portions of
limit cycles, or chords which can be pieced together via a state-actuated hybrid controller, much as in §2. In
other words, instead of building a simple ﬁxed vector ﬁeld with a limit cycle, we will use a set of vector ﬁelds
which vary discretely in time and which may be pieced together so as to tune a limit cycle to the desired
speciﬁcations. There is nothing in this construction which relies on the index-zero property and thus these
chords can be used to generate all monotone limit cycles on C.

Let G denote a word representing a desired monotone limit cycle on the conﬁgurations space C. Choose
points {qi} on the boundary of D which correspond to the docking zones for the cycle given by G. Choose
arcs αi on D which connect qi to qi+1 (using cyclic index notation). The arcs αi are assumed given in the
intrinsic coordinates on D, as would be the case if one were determining a length-minimizing curve.

In the case where the limit cycle α := ∪iαi is an embedded curve of nonzero index, the procedure of the
previous subsection determines a vector ﬁeld Xα on C which realizes α as an attracting limit cycle with the
appropriate dynamics on the complementary region. Recall: one translates α to a curve on the disc model
via the homeomorphism of Equation (16). Then, representing the limit cycle α as a function fα(θ), one takes
the vector ﬁeld of Equation (21) and, if desired, takes the image of this vector ﬁeld under Equation (20).

i which has docking zones {qi} such that βj

If, however, this is not the case, consider the arc αj for a ﬁxed j and construct an index ±1 cycle
βj = ∪iβj
j = αj . Then the vector ﬁeld X j as constructed above
has β as an attracting limit cycle. Denote by Φj the Lyapunov function which measures proximity to β:
Φj(p) :=
(with distance measured in say the product metric on C). Then, consider the modiﬁed
Lyapunov function Ψj(p) := Φj(p) + kp − qj+1k , which measures the distance to the endpoint of the arc βj
(cid:13)
j
(cid:13)
in addition to the proximity to βj.

p − βj

(cid:13)
(cid:13)

Repeat this procedure for each j, yielding the vector ﬁelds {X j} which attract respectively to limit cycles
βj. It follows that X j prepares X j+1 since the goal point of X j, qj+1 lies on the attracting set of X j+1.
The Lyapunov functions {Ψj} serve as a set of funnels which channel the orbit into the sequence of arcs αj,

SAFE ROBOT DYNAMICS

16

forming α. One scales the Ψj so that a Ψj < ǫ event triggers the switching in the hybrid controller from X j
to X j+1:

X 1
X j

: Φj > ǫ ∀ j
: Φj < ǫ and Ψj > ǫ

X :=

(cid:26)

(22)

By construction, the hybrid controller (22) realizes a limit cycle within ǫ of α as the attracting set.

5 Future Directions

A point of primary concern is the adaptability of the global topological approach to systems which increase
in complexity, either through more intricate graphs or through increased numbers of AGV’s. The latter
is of greater diﬃculty than the former, since the dimension of the resulting conﬁguration space is equal to
the number of AGV’s. Hence, no matter how simple the underlying graph is, a system with ten indepen-
dent AGV’s will require a dynamical controller on a (topologically complicated) ten-dimensional space: a
formidable problem both from the topological, dynamical, and computational viewpoints.

However, there are some approaches which may facilitate working with such spaces. Consider the model
space C with which this paper is concerned: although a two-dimensional space, C can be realized as the
product of a graph (a circle with six radial edges attached) with the interval (0, 1]. In fact, if we consider the
circulating ﬂow of Equations (7)-(9), one can view this as a product ﬁeld of a semiﬂow on the graph (which
“circulates”) with a vector ﬁeld on the factor (0, 1] (which “pushes out” to the boundary).

A similar approach is feasible for arbitrary graphs. The following result has recently been proven [8]:

Theorem 4 Given a graph Γ, the conﬁguration space of N distinct points on Γ can be deformation retracted
to a subcomplex whose dimension is bounded above by the number of vertices of Γ of valency greater than
two.5

This theorem implies the existence of low-dimensional spines which carry all of the topology of the
conﬁguration space. For example, the above theorem implies that the conﬁguration space of N points on
the Y-graph can be continuously deformed to a one-dimensional graph, regardless of the size of N . Since
the full space can be deformation retracted onto the spine, a vector ﬁeld deﬁned on the spine can be pulled
back continuously to the full conﬁguration space, thus opening up the possibility of reducing the control
problem to that on a simpler space. Addtional results about the topology of conﬁguration spaces on graphs
may yield computationally tractible means of dealing with complex path planning: for example, having a
presentation for the fundamental group of a conﬁguration space of a graph in terms of a suitably simple
set of cycles would be extremely well-suited to a hybrid control algorithm based on “localized” vector ﬁelds
supported on small portions of the full conﬁguration space.

The optimization problem is another avenue for inquiry. The fact that a dynamical approach allows
for increased density of AGV’s on a graph (as compared with blocking-zone strategies) would indicate an
increased eﬃciency with respect to, say, elapsed time-of-ﬂight. However, a more careful investigation of the
tuning of optimal cycles is warranted.

We believe that the beneﬁts associated with using the full conﬁguration space to tune optimal dynamical

cycles justiﬁes a careful exploration of these challenging spaces.

A The Topology and Dynamics of Graphs

In this appendix, we provide a careful basis for the use of vector ﬁelds on conﬁguration spaces of graphs.
In the setting of manifolds, all of the constructions used in this paper are entirely natural and well-deﬁned.
However, on spaces like C, the most fundamental of notions (like the Existence and Uniqueness Theorems
for ODEs) are not in general valid.

We begin by deﬁning vector ﬁelds on graphs. For present purposes, we ﬁnd it convenient to work with
an intrinsic formulation (i.e., directly in the graph rather than via an embedding in a Euclidean space) of
5We have since learned of two others who have independently proved this result: [16], having learned of these spaces fron

[11]; and [1], who discovered these spaces while working on the topology of Brownian motion on graphs.

SAFE ROBOT DYNAMICS

17

these objects. To this end, denote by v a vertex with K incident edges {ei}K
1 a collection
of nonsingular vector ﬁelds locally deﬁned on a neighborhood of the endpoint of each ei (homeomorphic to
[0, 1)).

1 , and by {Xi}K

Lemma 7 A set of nonsingular vector ﬁelds {Xi} on the local edge set of a graph Γ generates a well-deﬁned
semiﬂow on Γ if

1. Each edge ﬁeld Xi generates a well-deﬁned local semiﬂow on (0,1); and

2. The magnitude of the endpoint vectors kXi(0)k (taken with respect to the attaching homeomorphisms)

are all identical; and

3. Among the signs of the endpoint vectors Xi(0) (either positive if pointing into [0, ǫ) or negative if

pointing out) there is a single positive sign.

Proof:

Since the vector ﬁeld is well-deﬁned away from the vertex, it is only necessary to have the
magnitudes kXi(0)k agree in order to have a well-deﬁned function kXk on Γ.
In order to make this a
well-deﬁned ﬁeld of directions, we must also consider in which direction the vector is pointing. Again, this
is determined oﬀ of the vertex by (1). Condition (3) means that at the vertex, there is a unique direction
along which the vector ﬁeld is pointing out: all other edges point in. Hence, the direction ﬁeld, as well as
the magnitude ﬁeld, is well-deﬁned.

The semiﬂow property follows naturally from this. Assume that the N th edge of Γ has the positive sign.
Then, given an initial point x ∈ Γ, if x ∈ eN , then the orbit of x under the local ﬁeld XN remains in eN and
is well-deﬁned. If x ∈ ej for some j 6= N , then the union of the edges ej ∪ eN is a manifold homeomorphic
to R on which the vector ﬁelds Xj and XN combine to yield a well-deﬁned vector ﬁeld, since the directions
are “opposite.” As we are now on a manifold, the standard Existence Theorem implies that x has a forward
orbit (which passes through the vertex and continues into eN ). Thus every point on Γ has a well-deﬁned
⋄
forward orbit.

In the case where the vector ﬁelds have singularities, it is a simpler matter. If the singularities are not at
the vertex, then there is no diﬀerence. If there is a singularity at the vertex, then condition (3) in Lemma 7
is void — all such vector ﬁelds are well-deﬁned.

In order to extend these results to the conﬁguration space of this paper, consider the space C = Υ × Υ − ∆
and let (x, y) ∈ C denote a point on the branch set of C. Because of the structure of Υ and the fact that the
diagonal points are deleted, it follows that at most one AGV may occupy a non-manifold point of Υ. Hence,
a neighborhood of (x, y) in C has a natural product structure N ∼= Υ × R. Let P : N → Υ denote projection
onto the ﬁrst factor.

Lemma 8 A nonsingular vector ﬁeld X on the individual cells of C generates a well-deﬁned semiﬂow if (1)
the projection of the local vector ﬁelds onto the graph factor, P∗( X|{x}×Υ), satisﬁes Lemma 7 for each point
x in the branch set of C; and (2) the projections of the vector ﬁelds on the branch set to the R-factor are
equal up to the attaching maps.

Proof: Oﬀ of the branch set, the space is a manifold and hence the vector ﬁeld gives a well-deﬁned ﬂow.
If p is a point on the branch line, condition (2) implieds that the vector ﬁeld is well-deﬁned with respect
to the attaching maps and the net eﬀect in the R-factor is a drift in this direction. In the graph factor,
⋄
condition (1) and the proof of Lemma 7 implies that there is a unique forward orbit through p.

Heuristically, this condition means that, as in the case of a graph, the vector ﬁeld must point “in” on all
but one sheet of the conﬁguration space in order to have well-deﬁned orbits. We may thus lift the criteria
of Lemma 7 to the product conﬁguration space. All of the vector ﬁelds in this paper are so constructed.

References

[1] A. Abrams. Conﬁguration spaces of graphs and Brownian motion(?). PhD thesis, UC Berkeley, 2000.

In preparation.

SAFE ROBOT DYNAMICS

18

[2] Y. A. Bozer and M. M. Srinivasan. Tandem conﬁgurations for automated guided vehicle systems and

the analysis of single vehicle loops. IIE Transactions, 23(1):72–82, 1991.

[3] Y. Brave and M. Heymann. On optimal attraction of discrete-event processes. Information Science,

67(3):245–276, 1993.

[4] R. R. Burridge, A. A. Rizzi, and D. E. Koditschek. Sequential composition of dynamically dexterous

robot behaviors. Int. J. Rob. Res., (to appear).

[5] G. A. Castleberry. The AGV Handbook. Braun-Brumﬁeld, Ann Arbor, MI, 1991.

[6] M. Erdmann. Understanding action and sensing by designing actions-based sensors. Int. J. Rob. Res.,

14(5):483–509, 1995.

[7] S. B. Gershwin. Manufacturing Systems Engineering. Prentice Hall, Englewood Cliﬀs, NJ, 1994.

[8] R. Ghrist. Conﬁguration spaces and braid groups on graphs in robotics. To appear, Braids, Links, and

Mapping Class Groups: the Proceedings of Joan Birman’s 70th Birthday, 2000.

[9] R. Ghrist. Conﬁguration spaces of graphs. Preprint, 2000.

[10] R. Ghrist. Geometric optimization on conﬁguration spaces of networks. Preprint, 2000.

[11] R. Ghrist and D. E. Koditschek. Safe cooperative robot dynamics on graphs. In Y. Nakayama, editor,

Eighth Intl. Symp. on Robotic Research, pages 81–92. Springer-Verlag, 1998.

[12] D. E. Koditschek and E. Rimon. Robot navigation functions on manifolds with boundary. Advances in

Applied Mathematics, 11:412–442, 1990.

[13] D. Lind and B. Marcus. Introduction to Symbolic Dynamics and Coding Theory. Cambridge, 1995.

[14] T. Lozano-Perez, M. T. Mason, and R. H. Taylor. Automatic synthesis of ﬁne-motion strategies for

robots. Int. J. Rob. Res., 3(1):3–23, 1984.

[15] M. T. Mason. The mechanics of manipulation.

In Proc. International Conference on Robotics and

Automation, pages 544–548, March 1985.

[16] R. J. Milgram and S. Kaufman. Topological characterization of safe coordinated vehicle motion. In

preparation, November 1999.

[17] J. R. Munkres. Topology, A First Course. Prentice Hall, 1975.

[18] R. Sengupta. An optimal control theory for discrete event control systems. SIAM J. Control and

Optimization, 36(2):488–541, 1998.

[19] S. F. Smith. Reactive scheduling systems. In D. E. Brown and W. T. Schering, editors, Intelligent

Scheduling Systems, pages 155–192. Kluwer Academic Publishers, Boston, MA, 1995."
Robust Global Localization Using Clustered Particle Filtering,"  Global mobile robot localization is the problem of determining a robot's pose
in an environment, using sensor data, when the starting position is unknown. A
family of probabilistic algorithms known as Monte Carlo Localization (MCL) is
currently among the most popular methods for solving this problem. MCL
algorithms represent a robot's belief by a set of weighted samples, which
approximate the posterior probability of where the robot is located by using a
Bayesian formulation of the localization problem. This article presents an
extension to the MCL algorithm, which addresses its problems when localizing in
highly symmetrical environments; a situation where MCL is often unable to
correctly track equally probable poses for the robot. The problem arises from
the fact that sample sets in MCL often become impoverished, when samples are
generated according to their posterior likelihood. Our approach incorporates
the idea of clusters of samples and modifies the proposal distribution
considering the probability mass of those clusters. Experimental results are
presented that show that this new extension to the MCL algorithm successfully
localizes in symmetric environments where ordinary MCL often fails.
",http://arxiv.org/pdf/cs/0204044v1,1,"Robust Global Localization Using Clustered Particle Filtering 

Adam Milstein, Javier NicolÆs SÆnchez, Evan Tang Williamson 

Computer Science Department 
Stanford University 
Stanford, CA 
{ahpmilst, jsanchez, etang} @cs.stanford.edu 

is 

Abstract 
Global  mobile  robot 
the  problem  of 
localization 
determining a robot’s pose in an environment, using sensor 
data,  when  the  starting  position  is  unknown.  A  family  of 
probabilistic algorithms known as Monte Carlo Localization 
(MCL)  is  currently  among  the  most  popular  methods  for 
solving  this  problem.  MCL  algorithms  represent  a  robot’s 
belief by a set of weighted samples, which approximate the 
posterior probability of where the robot is located by using 
a  Bayesian  formulation  of  the  localization  problem.  This 
article  presents  an  extension  to  the  MCL  algorithm,  which 
addresses 
in  highly 
symmetrical environments; a situation where MCL is often 
unable  to  correctly  track  equally  probable  poses  for  the 
robot.  The problem arises from the fact that sample sets in 
MCL  often  become  impoverished,  when  samples  are 
generated  according  to  their  posterior  likelihood.  Our 
approach  incorporates  the  idea  of  clusters  of  samples  and 
modifies 
the 
probability mass of those clusters. Experimental results are 
presented  that  show  that  this  new  extension  to  the  MCL 
algorithm successfully localizes in symmetric environments 
where ordinary MCL often fails.    

the  proposal  distribution  considering 

its  problems  when 

localizing 

1. Introduction 

In  mobile  robotics,  the  task  of  navigation  requires  the 
ability for robots to identify where they are.  Given a map 
of  the  environment  and  a  starting  pose  (x-y  position, 
orientation) in relation to the map, the task of localization 
is a tracking task. With unknown initial location, the task 
is  known  as  global  localization,  in  which  a  robot  has  to 
recover  its  pose  from  scratch  [9,10].    The  problem  of 
localization is to compensate for sensor noise and errors in 
odometry readings.  
  One  popular  approach  to  robot  localization  is  to  use  
Kalman 
filters  are  computationally 
efficient, but they require that the initial localization error 
be  bounded---which  makes  them  inapplicable  to  global 
localization problems. Additionally, Kalman filters assume 
linear-Gaussian  measurement  and  motion  dynamics.  To 
overcome  these  limitations,  a  class  of  solutions  was 
recently proposed that uses particle filters to represent the 
probability  that  the  robot  is  in  a  particular  location.    This 
approach is commonly known as Monte Carlo Localization 
(MCL) [1]. 

filters.  Kalman 

In global localization, the robot starts off with no idea of 
where it is relative to its map.  With a reasonably accurate 
map  of  the  environment,  MCL  has  been  shown  to  be 
effective  in  many  situations.  However,  MCL  suffers  an 
important 
limitation:  When  samples  are  generated 
according  to  their  posterior  probability  (as  is  the  case  in 
MCL),  they  often  too  quickly  converge  to  a  single,  high-
likelihood  pose.  This  might  be  undesirable  in  symmetric 
environments,  where  multiple  distinct  hypotheses  have  to 
be  tracked  for  extended  periods  of  time.  MCL  often 
converges to one single location too quickly, ignoring the 
possibility  that  the  robot  might  be  somewhere  else.  This 
problem  leads  to  suboptimal  behavior  if  there  are  two  or 
more similarly likely poses. In symmetric environments, it 
is  desirable  to maintain  a  higher diversity  of  the  samples, 
despite  the  fact  that  likelihood-weighted  sampling  will 
favor a single robot pose. 
  The  approach  we  present  in  this  article  introduces  the 
idea  of  clusters  of  particles  and  modifies  the  proposal 
distribution to take into account the probability of a cluster 
of  similar  poses.  Each  cluster  is  considered  to  be  a 
hypothesis  of  where  the  robot  might  be  located  and  is 
independently  developed  using  the  MCL  algorithm.  The 
update of the probability of each cluster is done using the 
same Bayesian formulation used in MCL, thus effectively 
leading  to  a  particle  filter  that  works  at  two  levels,  the 
particle  level  and  the  cluster  level.  While  each  cluster 
possesses  a  probability  that  represents  the  belief  of  the 
robot  being  at  that  location,  the  cluster  with  the  highest 
probability would be used to determine the robot(cid:146)s location 
at that instant in time. 
  Experiments  have  been  conducted  with  both  simulated 
data  as  well  as  data  obtained  from  a  robot,  using  laser 
range  finder  data  collected  at  multiple  sites.  The 
environments are highly symmetric and the corresponding 
datasets  possess  only  a  very 
small  number  of 
distinguishing  features  that  allow  for  global  localization. 
Thus,  they  are  good  testbeds  for  our  proposed  algorithm. 
Results  show  that  the  Cluster-MCL  algorithm  is  able  to 
successfully  determine  the  position  of  the  robot  in  these 
datasets, while ordinary MCL often fails.   

 
 
2. Background 

Bel x
( )
t

=

η

p z x
(
|
t
t

∫
)

p x u x p x
(
) (
,
t
t

−
1

|

t

t

|

t
z

−
1

t
u

,

−
1

dx
)
t

−
1

−
1

(8) 

Monte Carlo Localization and Bayes filter 
MCL is a recursive Bayes filter that estimates the posterior 
distribution  of  robot  poses  conditioned  on  sensor  data. 
Central  to  the  idea  of  Bayes  filters  is  the  assumption  that 
the environment is Markovian, that is, past and future are 
conditionally independent given knowledge of the current 
state.  
  The  key  idea  of  Bayes  filtering  is  to  estimate  a 
probability density over the state space conditioned on the 
data.  This  posterior  is  typically  called  the  belief  and  is 
denoted by 

=

t

2

0

−

|

,

,

)

)

z

−
1

−
1

u
t

p x
(
t

Bel x
(
,
z u
,...,
t
t
t
tx   denotes  the  state  at  time  t, 

 (1) 
z
tz   is  the  perceptual 
Here 
data (such as laser range finder or sonar measurements) at 
tu is  the  odometry  data  (i.e.  the  information 
time  t,  and 
about the robot’s motion) between time t-1 and time t. 
  Bayes  filters  estimate  the  belief  recursively.  The  initial 
belief characterizes the initial knowledge about the system 
state, which in the case of global localization, corresponds 
to a uniform distribution over the state space as the initial 
pose is unknown. 
  To  derive  a  recursive  update  equation,  we  observe  that 
Expression (1) can be transformed by Bayes rule:  

Bel x
(

)

t

=

p z
(

t

|

x u
,
t

,...,
z
u
|

−
t
1
p z
(

,...,

z

)

0

−

1

t

)

0

−

1

p x
(
t
z
,...,

u
)

|

0

(2) 

t

t

  Because  the  denominator  is  a  normalizer  constant 
relative to the variable 
=

tx  we can write equation (2) as 

η

|

x u
,
t
t

−
1

,...,

z p x u
0
t

) (

|

t

−
1

,...,

z
0

)

Bel x
(
t

)

p z
(
t

(3) 

where 

=
η

p z u
t
t

(

|

,...,

z

)

0

−
1

−

1

(4) 

  As  stated  previously,  Bayes  filters  make  the  Markov 
independence  assumption.  This  assumption  simplifies 
equation (3) to the following expression 

Bel x
( )
t

=

η

p z x p x u
(
) (
t
t

|

|

t

t

,...,

z
0

)

−
1

(5) 

  The  rightmost  term  in  the  previous  equation  can  be 
expanded by integrating over the state at time t-1: 

Bel x
(
t

)

=

η

p z x
(
|
t
t

)

p x u x
(
|
t
t

,

t

∫

,...,

z p x
) (
0
t

−
1

|

u
t

−
1

,...,

z dx
)
0
t

−
1

−
1

(6) 

  And by application of the Markov assumption it can be 
simplified to  

Bel x
(
t

)

=

η

p z
(
t

|

x
t

)

p x u x
|
t

(

,

t

t

∫

p x
) (
t

−
1

|

u
t

−
1

,...,

z dx
)
t
0

−
1

−
1

(7) 

=
u
  Defining 
equation (7) can then be expressed as: 

z
{ ,...,
0

  and 

}

−
1

z

z

t

t

−
1

−
1

t

=

u
{ ,...,
0

u
t

−
1

}

)

(

Bel x −
(
1
t

    It can be seen from equation (8) that the rightmost term 
is 
. Therefore, this equation is recursive and is the 
update  equation  for  Bayes  filters.  To  calculate  (8)  one 
needs  to  know  two  conditional  densities:  the  probability 
,  which  is  called  the  motion  model,  and  the 
p x u x −
|
,
1
t
t
t
x , which is called the sensor model.  The 
density 
p z
(
t
motion  model  is  a  probabilistic  generalization  of  robot 
dynamics. The sensor model depends on the type of sensor 
being  used  and  considers  the  noise  that  can  appear  in  the 
sensor readings.  

)
|

)

t

localization, 

Particle approximation 
If  the  state  space  is  continuous,  as  is  the  case  in  mobile 
trivial, 
robot 
particularly  if  one  is  concerned  with  efficiency.  The  idea 
of  MCL  is  to  represent  the  belief 
Bel x   by  a  set  of  N 
)t
weighted samples distributed according to 
Bel x : 
)t
(
{

implementing  (8) 

is  not 

}

≈

(

Bel x
(
t

)

,i
[ ]
i
[ ]
x w
t
t

=

i

1,...,

N

[ ]n

tx

  Here  each 
  is  a  sample  of  the  random  variable  x, 
that  is,  a  hypothesized  state  (pose).  The  non-negative 
tw , are called importance factors 
numerical parameters, 
and they determine the importance of each sample. The set 
of samples thus define a discrete probability function that 
approximates the continuous belief 

Bel x .  
(

[ ]n

  In  the  case  of  global  localization,  the  initial  pose  is 
unknown,  thus  the  prior  is  uniform  over  the  space  of 
.  Let 
possible  poses,  and  therefore  each  weight 
1tX −   be  a  set  of  particles  representing  the  estimate 
tX , is 
tp x
(
then obtained via the following sampling routine: 

1t − . The t-th particle set, 

 at time 

tw =

u−
,

n
[ ]

−
1

−
1

z

)

N

|

1

1

t

t

)t

n
[ ]
1

1.  First,  draw  a  random  particle 

1tX − .    By 
assumption,  this  particle  is  distributed  according  to 
.    Strictly  speaking,  this  is  only  true 
tp x
(
as  N  goes  to  infinity,  but  we  ignore  the  bias  in  the 
finite case. 

tx −   from 

u−
,

−
1

−
1

z

)

|

1

t

t

[ ]
n
2.  Next, draw a state 
x
−
1
t
calculate 
3.  Finally, 
n
[ ]
n
[ ]
x
w
)
t
t
particle and its importance factor. 

[ ]
n
p x u x
|
−
t
1
t
the 

~ (

p z
(

=

|

t

t

factor 
  for  this  particle,  and  memorize  the 

)

. 
,
importance 

  This  routine  is  repeated  N  times.  The  final  set  of 
particles, 
tX   is  obtained  by  randomly  drawing  (with 
replacement) N memorized particles 
 with probability 
[ ]n
proportional to the respective importance factor, 
tw .  The 
then  an  approximate 
resulting  set  of  particles 
=
t
.      For  a  more 
representation  for 
z u
,
|
detailed  discussion  on  the  implementation  of  MCL  and 
examples see [6]. 

is 
p x
(
t

Bel x
(
t

tx

[ ]n

)

)

t

       
          
    
      
 
  
 
 
         
 
 
 
 
 
 
 
 
 
t

z

1

u−
,

−
1

t

)

that 

c x
( )

k= ,  it  is  sufficient  to  define 

[ ]
)n
f x
(
t

=

1

B

k t
,

3. Global Localization using clustered particle 
filtering 

We  will  now  analyze  how  particle  filters  work  and  from 
that we will motivate our approach.  To understand particle 
filters, it is worthwhile to analyze the specific choice of the 
importance  factor.    In  general,  the  importance  factor 
accounts 
target 
distribution  and  the  proposal  distribution.    The  target 
t
distribution  is 
z u .    The  proposal  distribution  is 
)
|
tp x
(
z u−
1
given by 
. This is the distribution of 
|
,
|
p x u x p x
(
) (
,
−
−
1
1
t
t
t
]n
[
  before  the  re-sampling  step.    The 
the  samples  values 
tx
importance factor is calculated as follows: 

the  (cid:147)difference(cid:148)  between 

the 

for 

−
1
)

,

t

t

t

t

n
[ ]

tw =

target distribution
proposal distribution

[ ]
n
w
t

=

[ ]
n
w
t

=

n
[ ]
(
p x
t
η
p z
(

t

[ ]
n
w
t

η=

p z
(

t

t

)
|

t
|
z u
,
p x
(
t
|

)

|

[ ]
n
(
p x
t
u x
,
t
t
[ ]
n
x
)
|
t
n
[ ]
p x
(
t
[ ]
n
x
t

)

|

−
1
[ ]
n
p x
(
t
u x
,
|
t
t

−
1

−
1
u x
,
−
1
t
t
p x
(
)
t

)

−
1

−
1

,

u

−
1

t

)

p x
(
t
−
1
t
z
|

−
1
,

|
u

t

z
−
1
t

)

(9) 

[ ]
)n
p z x
(
|
t
t

  The  constant  η  can  easily  be  ignored,  since  the 
importance  weights  are  normalized  in  the  re-sampling 
step.  This  leaves  the  term 
,  which  is  the 
importance factor used in MCL. 
  Our analysis above suggests that a much broader range 
of  functions  may  be  used  as  proposal  distributions.    In 
particular,  let 
f x   be  a  positive  function  over  the  state 
t
the  following  particle  filter  algorithm 
space.  Then 
generates 
samples 
distribution 
a 
∝
t
t
.  Initially,  samples  are  drawn  from 
)
z u
f x p x
)
,
(
t
t
t
. 
f x
0(
0

from 

(

(

)

)

|

t

New  sample  sets  are  then  calculated  via  the  following 
procedure: 

1.  First,  draw  a  random  particle 

this 

assumption, 
distributed  according  to 
large N. 

particle 
f
t

−
1

n
[ ]
1

tx −   from 
is 
x p x
(
) (
−
1
t
t

1tX − .  By 
(asymptotically) 
z u−
t
1
  for  very 
,

−
1

−
1

)

|

t

2.  Next, draw a state 

~ (
In  this  case  the  resulting  importance  factor  is  easily 
computed as: 

[ ]
n
p x u x −
|
t
1

[ ]
n
x
t

. 

)

,

t

t

n
[ ]

tw =

target distribution
proposal distribution

  The  clustering  particle  filter  proposed  employs  such  a 
modified proposal distribution.  In particular, each particle 
is associated with one out of K clusters.  We will use the 
function 
)tc x  to denote the cluster number.  The function 
(
tf   assigns  to  each  particle  in  the  same  cluster  the  same 
value;  but  this  value  may  differ  among  different  clusters.  
tf   is  such  that  the  cumulative  weight  over  all 
Moreover, 
the particles in each cluster is the same for each cluster. 

n

]

∈

[
t

x
=

∑

X c x
: (

t

n

]

=

)

k

[
t

n

]

f x
(

[
t

)

p x
(

n

]

[
t

|

t
z u
,

t

)

∑

X c x
: (

t

n

]

=

)

k

’

[
t

n

]

f x
(

[
t

)

p x
(

n

]

[
t

|

t
z u
,

t

)

n

]

∈

x

[
t

               (11)  

for  k

k′≠

. 

need to define 

From above we see that this is valid, however, we 
.  Since these are equal for all x such 

[ ]
)n
f x
(
t

=

[ ]
)n
c x
(
t

k

 and 

where 

,k tB  is the probability, at time t, that 
cluster  k  contains  the  actual  robot  position.    We  can 
,k tB   values  using  standard  Bayes  filters.  
estimate  the 
Here,  we  use  k  to  represent  the  probability  distribution 
over the clusters: 

|

t

t
z u
,

)

B

k t
,

=

p k
(
t
η
= ∫

p z k p k u k
) (
t

(

,

|

|

t

t

t

t

p k
) (
t

−
1

−
1

|

z

−
1

t

−
1

t

,

u

)

dk
t

−
1

(12) 

  Since we use a finite number of samples to approximate 
the distribution, this becomes: 

= ∑
η

p z
(

t

|

k p k u k
t
t

)

(

,

|

t

)

p k
(

−
1

t

−
1

t

|

z

−
1

t

,

u

−
1

t

)

B

k t
,

n
  Now  we  note  that,  although  the  robot  can  move  from 
one  point  to  another,  particles  cannot  change  clusters.  
That  is,  each  particle  starts  in  one  cluster  and  remains  in 
that cluster.  This being the case,  

(13) 

p k u k
|

(

,

t

t

)

−
1

t

k
0  if 
= 
k
1  if 


t

t

≠
=

k
k

−
1

t

−
1

t

 (14) 

Therefore, 

B

k t
,

∝

p z
(

t

|

k p k
)
(
t

−
1

t

t

z

1

u−
,

|

−
1

t

)

         (15) 

  We  also  note  that  a  cluster  is  composed  of  a  set  of 
points.  Therefore, 
p z x . In fact, 
p z k  is related to 
(
(
the  distribution  of  sensor  readings  for  a  cluster  must  be 
the  sum  of  the  distributions  of  sensor  readings  for  all 
points in the cluster.  That is: 

)

)

|

|

t

t

t

t

[ ]
n
w
t

=

[ ]
n
w
t

=

f

(

[ ]
n
x
)
−
1
t
η
)

−
1
t
[ ]
n
f x
(
t
t

f

−
1

t

[ ]
n
w
t

∝

p z
(

t

|

[ ]
n
x
t

t

t

)
|

|
)

[ ]
n
)
p x
(
t
u x
,
−
1
t
t
[ ]
n
p x
(
|
t
u x
,
|
t
t

t
,
z u
p x
(
−
t
1
u x
,
−
1
t
t
p x
(
)
t

−
1

z

[ ]
n
(
f x
t
t
[ ]
n
p x
(
t

|

t

|
)

[ ]
n
p z
(
x
)
t
n
n
[ ]
[ ]
x
p x
(
(
−
t
t
1
n
[ ]
(
f x
)
t
t
[ ]
n
x−
(
)
−
1
1
t

)

f

t

−
1

t

1

u−
,

)

)

−
1

p x
(
t
t
z
|

−
1
−
1

z
|
t
u

,

−
1

t

u

)

p z
(

t

|

k

t

)

∝

p k
(

−
1

t

|

z

−
1

t

,

u

−
1

t

)

n

]

∈

[
x
t

∑

[
X c x
: (
t

t

p z
(

t

|

[ ]
n
x
t

)

(16) 

n

]

=

)

k

  Given equations (12) and (16) we can write 

−
1

t

−
1

,
)

                                        (10) 

=

B

k t
,

γ −
B

2
, 1

k t

n

]

∈

[
x
t

∑

[
X c x
: (
t

t

p z
(

t

|

[ ]
n
x
t

)

n

]

=

)

k

(17) 

where  γ is a normalization factor. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
 
 
  
 
 
  Having  defined 

[ ]
)n
(
f x
t

=

1

,  we  maintain 

the 

B

k t
,

condition stated in equation (11) by normalizing after each 
iteration.    Therefore,  we  have  shown  that  our  modified 
proposal distribution is sound. 

4. Cluster-MCL 

Algorithm: 
Based  on  the  mathematical  derivation  above,  we  have 
implemented  an  extension  to  MCL,  called  Cluster-MCL. 
Cluster-MCL  tracks  multiple  hypotheses  organized  in 
clusters.  The first task is to identify probable clusters.  By 
iterating  several  steps  through  ordinary  MCL,  with  an 
initial  uniform  distribution  of  a  large  number  of  points, 
clusters develop in several locations.  We then use a simple 
clustering  algorithm  to  separate  the  points  into  different 
clusters.  We match each point with a cluster based on the 
distance,  in  all  three  dimensions,  between  that  point  and 
the source point of the cluster.  The initial probability of a 
cluster is based on the number of points it contains.  There 
are  more  robust  clustering  algorithms,  based  on  the  EM 
algorithm;  however,  these  methods  rely  on  knowing  the 
number of clusters a priori.  Our method generates sets of 
clusters  of  arbitrary  size.    The  drawback  is  that  several 
clusters  may  be  created  in  almost  the  same  location.    We 
solve 
for 
this  problem  by  occasionally  checking 
overlapping  clusters  and  combining  them.    Once  clusters 
are  generated,  we  select  the  most  probable  ones  and 
discard the others.   
  Each  cluster  is  then  independently  evolved  using 
ordinary MCL, thus points selected for a particular cluster 
can  only  be  drawn  from  that  cluster.    The  probability  of 
each cluster is tracked by multiplying the prior probability 
of the cluster by the average of the likelihood of the points 
in that cluster.  These probabilities are kept normalized and 
correspond to the 
  There is the problem that, if there is an error in the map 
in the initial location, there may be no cluster generated at 
the correct location.  We solve this problem, and also the 
kidnapped  robot  problem,  by  taking  advantage  of  the 
independence  of  our  clusters.    The  kidnapped  robot 
problem  is  where  the  robot  is  moved  by  an  outside  force 
after being localized.  Since clusters do not interfere with 
each other, we can add a cluster in a new location without 
affecting  our  existing  clusters.    After  a  predetermined 
number of steps, we restart a new instance of global MCL 
with a higher convergence rate, with the purpose of finding 
the  most  likely  cluster  based  on  the  current  sensor  data.  
Once  global  MCL  has  converged  to  a  location,  we  check 
whether this new location overlaps an existing cluster.  If it 
does  not,  we  initialize  it  to  have  a  small  probability  and 
begin tracking it.  Otherwise, we discard it and repeat the 
process. By doing this, we remain open to consideration of 
a  completely  new  location  for  the  robot  based  on  the 
current sensor data. 

,k tB  values as defined above.   

  To  limit  the  number  of  clusters  from  growing  out  of 
bounds  and  to  remain  computationally  efficient,  we  limit 
the  number  of  clusters  to  a  maximum  pre-defined  value. 
Additionally, by keeping the number of clusters fixed at all 
points  in  time,  we  prevent  a  cluster  from  gaining  a  high 
probability  by  competing  with  only  few  other  clusters, 
which  would  tend  to  prevent  that  cluster  from  being 
overtaken  when  there  are  many  other  clusters.    When 
adding a new cluster, the least probable cluster is removed, 
in order to keep the size fixed.   
  The robot(cid:146)s estimate of its own location is based on the 
most  likely  cluster,  and  obtained  by  fitting  a  Gaussian 
through the corresponding particles. 

5. Experimental Results 

Experimentation: 
The  Cluster-MCL  algorithm  was  implemented  and  tested 
in both simulated and real environments. In these tests, we 
compare  the  performance  of  our  Cluster-MCL  algorithm 
with  that  of  ordinary  MCL.    In  all  cases,  we  found  that 
Cluster-MCL performed as well as ordinary MCL, and in 
several  cases  where  ordinary  MCL  failed,  Cluster-MCL 
succeeded.   
Simulated  Data.  For  simulated  environments,  we 
generated two highly symmetrical maps to test on.  Testing 
MCL  and  Cluster-MCL  using  these  maps,  we  observed 
that Cluster-MCL correctly maintains all equally probable 
clusters, while ordinary MCL incorrectly and prematurely 
converges to a single cluster.  In Figure 2, we display the 
results of Cluster-MCL using one of the maps, and we can 
clearly see that there are multiple distinct clusters.  Notice 
that  Cluster-MCL  maintains  a  posterior  belief  comprised 
of four distinctive poses, in contrast to conventional MCL, 
whose  outcome  is  shown  in  Figure  1.  Moreover,  the 
clusters in Figure 2 are all just about equally probable, as 
demonstrated  by  our  observation  of  the  constant  trading 
off of which cluster is most probable.  We obtained similar 
results on the second map, which was a simple rectangle. 

1(a) 
Figure 1:  Global localization using ordinary MCL.  

            1(b) 

 
 
 
 
 
 
 
 
                         2(b) 

   2(a) 
Figure  2:    Global  localization  using  Cluster-MCL.    The  extra 
cluster  (circled)  is  a  randomly  drawn  cluster,  used  to  make 
Cluster-MCL robust to the kidnapped robot problem. 

some 

  Our 

symmetry. 

Real Data. To elucidate the workings of our algorithm in 
practice,  additional  tests  were  performed  using  data 
collected  from  two  real  world  environments.    Our  first 
environment consisted of a long corridor in Wean Hall at 
Carnegie  Mellon  University,  with  equally  spaced  doors 
thus  providing  an 
and  few  distinguishing  features, 
second 
environment  with 
environment  consists  of  a  room  in  the  Gates  Building  at 
Stanford  University,  with  two  entrances  opposite  each 
other, two benches symmetrically placed and a file cabinet 
in each corner of the room.  The datasets in both locations 
were  collected  using  a  robot  equipped  with  a  laser  range 
finder.  
  From  these  environments  we  collected  nine  datasets.  
From  Wean  Hall,  we  collected  four  datasets.    In  each 
dataset, the robot was given a different path with different 
features  of  the  environment  observed.    Of  the  four  cases, 
MCL was only able to correctly localize in three of them, 
while Cluster-MCL correctly identified the robot’s position 
in  all  cases.    In  Figure  3,  a  comparison  is  given  between 
MCL and Cluster-MCL on a particular dataset, number 3, 
from  Wean  Hall.    On  multiple  executions  over  that 
particular  dataset,  ordinary  MCL  failed  100%  of  the  time 
while  Cluster-MCL  had  a  100%  success  rate.    We  show 
that ordinary MCL converges to the wrong location, while 
Cluster-MCL correctly identifies the robot(cid:146)s position.   

In the Gates Building environment, five datasets on two 
different  maps  were  collected.   In  all  cases,  Cluster-MCL 
performs at least as well as ordinary MCL.  In four of the 
datasets,  MCL  and  Cluster-MCL  both  correctly  identify 
the  robot(cid:146)s  location.    However,  in  the  final  dataset,  MCL 
failed  to  consistently  identify  the  correct  location  of  the 
robot,  while  Cluster-MCL  was  able  to  localize  to  the 
correct  position.  The  difference  between  the  Wean  Hall 
and  Gates  datasets  is  in  the  level  of  symmetry.  To 
demonstrate the benefits of Cluster-MCL, we chose a more 
highly symmetrical environment in Gates and attempted to 
collect datasets, which had two possible localizations until 
the final segment of them.  We ran MCL and Cluster-MCL 
several  times  on  those  datasets  and  the  results  show  that 
MCL  had  50%  accuracy  in  determining  the  correct 
position, while Cluster-MCL had 100% accuracy.   

 3(a) 
Figure  3:    Results  of  MCL  and  Cluster-MCL  on  Wean  Hall 
dataset  3.  MCL  converges  to  an  incorrect  cluster  in  3(a),  while 
Cluster-MCL converges to the correct location in 3(b). 

        3(b) 

      4(b) 
   4(a) 
Figure 4:  Results  of  MCL  and  Cluster-MCL  on  Gates  data.  
Cluster-MCL  tracks  multiple  possible  clusters  in  4(a)  while 
ordinary MCL converges to a single, incorrect, cluster in 4(b). 

6. Related Work 

Related  work  in  this  area  involves  the  use  of  multi-
hypothesis  Kalman  filters  to  represent  multiple  beliefs.  
This  however  inherits  Kalman  filters  limitations  in  that  it 
requires noise to be Gaussian.  A common solution to this 
problem  is  to  perform  low-dimension  feature  extraction, 
which  ignores  much  of  the  information  acquired  by  the 
robot(cid:146)s  sensors  [4,5].    Most  of  the  work  involving  multi-
hypothesis  Kalman  filters  surrounds  the  tracking  of 
multiple  targets  and  feature  detection,  whereas  we  apply 
the concept of multiple hypotheses to represent our belief 
of the position of the robot.   
  Other  improvements  to  MCL  like,  dual-MCL  and 
Mixture  MCL  [6,11,12]  attempt  to  improve  the  proposal 

 
 
 
 
 
 
 
 
 
 
 
 
4. 

Conference  on  Robotics  and  Automation,  Seoul, 
Korea. 
Jensfelt,  P.,  and  Kristensen,  S.  1999.  Active  Global 
Localisation  for  a  Mobile  Robot  Using  Multiple 
Hypothesis  Tracking.  Workshop  on  Reasoning  with 
Uncertainty 
(IJCAI(cid:146)99).  
in  Robot  Navigation. 
Stockholm, Sweden. 

5.  Austin,  D.,  and  Jensfelt,  P.  2000.  Using  Multiple 
Gaussian  Hypotheses 
to  Represent  Probability 
Distributions  for  Mobile  Robot  Localization.    In 
Proceedings  of  IEEE  International  Conference  on 
Robotics and Automation, San Francisco, CA.   

6.  Thrun, S.; Fox, D.; Burgard, W.; and Dellaert, F. 2001. 
Robust  Monte  Carlo  Localization  for  Mobile  Robots.  
Artificial Intelligence Magazine. 

7.  Doucet,  A.  1998.  On  Sequential  simulation-based 
methods  for  Bayesian  filtering.  Technical  Report 
CUED/F-INFENG/TR  310,  Cambridge  University, 
Department of Engineering, Cambridge, UK. 
J.Liu  and  R.  Chen.  1998.  Sequential  monte  carlo 
methods for dynamic systems. Journal of the American 
Statistical Association 93:1032-1044. 

8. 

9.  Borenstein,  J.;  Everett,  B.;  and  Feng,  L.  1996.  
Navigating  Mobile  Robots:  Systems  and  Techniques.  
A.K. Peters, Ltd. Wellesley, MA. 

10.  Weib,  G.;  Wetzler,  C.;  and  von  Puttkamer,  E.  1994.  
Keeping  Track  of  Position  and  Orientation of  Moving 
Indoor Systems by Correlation of Range-finder Scans.  
In  Proceedings  of  the  International  Conference  on 
Intelligent Robots and Systems,  595-601. 

11.  Lenser,  S.;  and    Veloso,  M.  2000.  Sensor  Resetting 
Localization  for  Poorly  Modeled  Mobile  Robots.    In 
Proceedings  of 
International  Conference  on 
Robotics and Automation, San Francisco, CA. 

the 

12.  Thrun,  S.;  Fox,  D.;  and  Burgard,  W.    2000.    Monte 
Carlo Localization with Mixture Proposal Distribution. 
In  Proceedings  of  the  AAAI  National  Conference  on 
Artificial Intelligence, Austin, TX. 

13.  Thrun,  S.;  Langford,  L.;  and  Verma,  V.  2002.  Risk-
sensitive  particle  filters.  In  Proceedings  of  the  Neural 
Information 
Conference, 
Vancouver, CA. 

Processing 

Systems 

distribution.  Likewise, we attempt to improve the proposal 
distribution by way of tracking multiple hypotheses.   

7.  Conclusions and Future Work 

Conclusion 
In  this  paper  we  introduced  a  cluster-based  extension  to 
MCL  localization.    Ordinary  MCL  can  fail  if  the  map  is 
symmetrical, however, we proposed a method that retains 
multiple  hypotheses  for  where  the  robot  is  located, 
consistent  with  our  sensor  data.    Our  method  involves 
clustering  the  points,  and  then  tracking  the  clusters 
independently,  so  as  to  avoid  discarding  other  possible 
locations  in  favor  of  the  most  probable  cluster  at  the 
current  time  step.    By  considering  the  probability  of 
multiple  clusters  over  a  longer  time,  we  are  able  to  get  a 
more  accurate  idea  of  their  likelihood.    We  have  shown 
that this method is valid and that the additional information 
we  take  into  account  allows  us  to  eliminate  some  of  the 
bias from MCL and better approximate the true posterior.  
Our experiments show that Cluster-MCL performs at least 
as  well  as  ordinary  MCL  on  several  real  datasets,  and  in 
cases where MCL fails, Cluster-MCL still finds the correct 
location.    Finally,  we  have  shown  that  Cluster-MCL 
maintains  all  of 
in 
symmetrical  environments,  while  MCL  converges  to  a 
single cluster.   

the  correct  possible 

locations 

Future Work 
Future  work  might  involve  dynamically  re-clustering  the 
points on every time step in order to provide a true second-
order  MCL  algorithm.    We  might  also  consider  dropping 
clusters automatically when their probability drops below a 
certain threshold, instead of keeping a constant number of 
them.  Since our algorithm retains less probable locations, 
it  might  be  useful  for  a  robot  to  consider  less  probable 
clusters when planning a motion.  It might not be desirable 
for a robot to take an action that would be dangerous even 
if  the  corresponding  cluster(cid:146)s  likelihood  is  low.  See  [13] 
for  an  attempt  to  achieve  this  in  the  context  of  particle 
filtering.  

References 

1.  Thrun,  S.  2000.  Probabilistic  Algorithms  in  Robotics.  
School  of  Computer  Science,  Carnegie  Mellon 
University.  Pittsburgh, PA.   

2.  Thrun, S.; Montemerlo, M.;  and Whittaker, W.  2002.  
Conditional  Particle  filters  for  Simultaneous  Mobile 
People-Tracking.  
Robot 
Forthcoming. 

Localization 

and 

3.  Schulz D.; Burgard W.; Fox D.; and Cremers A. 2001. 
Tracking  Multiple  Moving  Targets  with  a  Mobile 
Robot  Using  Particles  Filters  and  Statistical  Data 
Association.  In  Proceedings  of  the  IEEE  International"
"Artificial Intelligence and Systems Theory: Applied to Cooperative
  Robots","  This paper describes an approach to the design of a population of cooperative
robots based on concepts borrowed from Systems Theory and Artificial
Intelligence. The research has been developed under the SocRob project, carried
out by the Intelligent Systems Laboratory at the Institute for Systems and
Robotics - Instituto Superior Tecnico (ISR/IST) in Lisbon. The acronym of the
project stands both for ""Society of Robots"" and ""Soccer Robots"", the case study
where we are testing our population of robots. Designing soccer robots is a
very challenging problem, where the robots must act not only to shoot a ball
towards the goal, but also to detect and avoid static (walls, stopped robots)
and dynamic (moving robots) obstacles. Furthermore, they must cooperate to
defeat an opposing team. Our past and current research in soccer robotics
includes cooperative sensor fusion for world modeling, object recognition and
tracking, robot navigation, multi-robot distributed task planning and
coordination, including cooperative reinforcement learning in cooperative and
adversarial environments, and behavior-based architectures for real time task
execution of cooperating robot teams.
",http://arxiv.org/pdf/cs/0411018v1,1,"Lima, P. U. & Custodio, L. M. M. / Artificial Intelligence and Systems Theory: Applied to Cooperative Robots, pp. 141 -
148, International Journal of Advanced Robotic Systems, Volume 1, Number 3 (2004), ISSN 1729-8806 

Artificial Intelligence and Systems Theory: 

Applied to Cooperative Robots 

Pedro U. Lima & Luis M. M. Custodio 
Institute for Systems and Robotics 
Instituto Superior Técnico 
Av. Rovisco Pais, 1 
1049-001 Lisboa, PORTUGAL 
{pal,lmmc}@isr.ist.utl.pt 

Abstract:  This  paper  describes  an  approach  to  the  design  of  a  population  of  cooperative  robots  based  on  concepts 
borrowed from Systems Theory and Artificial Intelligence. The research has been developed under the SocRob project, 
carried out by the Intelligent Systems Laboratory at the Institute for Systems and Robotics - Instituto Superior Técnico 
(ISR/IST) in Lisbon. The acronym of the project stands both for ""Society of Robots"" and ""Soccer Robots"", the case study 
where we are testing our population of robots. Designing soccer robots is a very challenging problem, where the robots 
must  act  not  only  to  shoot  a  ball  towards  the  goal,  but  also  to  detect  and  avoid  static  (walls,  stopped  robots)  and 
dynamic  (moving  robots)  obstacles.  Furthermore,  they  must  cooperate  to  defeat  an  opposing  team.  Our  past  and 
current  research  in  soccer  robotics  includes  cooperative  sensor  fusion  for  world  modeling,  object  recognition  and 
tracking, robot navigation, multi-robot distributed task planning and coordination, including cooperative reinforcement 
learning in cooperative and adversarial environments, and behavior-based architectures for real time task execution of 
cooperating robot teams. 
Keywords: multi-robot systems, sensor fusion, distributed task planning, robot navigation, soccer robots.  

1. Introduction 

Cooperative  Robotics  is  a  modern  research  field,  with 
applications  to  areas  such  as  building  surveillance, 
transportation  of  large  objects,  air  and  underwater 
pollution monitoring, forest fire detection, transportation 
systems, or search and rescue after large-scale disasters. 
In short, a population of cooperative robots behaves like 
a  distributed  robot  to  accomplish  tasks  that  would  be 
difficult,  if  not  impossible,  for  a  single  robot.  Many 
lessons important for this domain can be learned from the 
Multi-Agent Systems field of Artificial Intelligence (AI) 
concerning  relevant  topics  for  Cooperative  Robotics, 
such as distributed continual planning (desJardins, M. E., 
et  al,  1999), 
(Ferber,  J.,  1999), 
communication  languages  or  coordination  mechanisms 
(Decker, K. S., & Lesser, V. R., 1995). Robotic soccer is 
a  very  challenging  problem,  where  the  robots  must 
cooperate not only to push and/or kick an object (a ball) 
towards a target region (the goal), but also to detect and 
avoid static (walls, stopped robots) and dynamic (moving 
robots) obstacles while moving towards, moving with or 
following  the  ball.  Furthermore,  they  must  cooperate  to 

task  allocation 

defeat an opposing team. All these are features common 
to many other cooperative robotics problems. This paper 
surveys  the  several  research  problems  addressed  by  the 
SocRob  project,  building  a  Systems  Theory  standpoint 
on AI concepts. In Section 2  we describe our view of the 
general  problem  involving  multiple  robots  that  act  as  a 
team, cooperating and coordinating their actions to attain 
the team goal. Needless to say, single-robot ''traditional'' 
research problems are covered, both from the sub-system 
and  the  integration  standpoints.  Natural  extensions  to 
cooperative  multi-robot  teams  are  also  detailed.  The 
problems addressed so far and the solutions we obtained 
for  them  are  described  in  Section  3.  Open  problems  of 
interest  for  the  project  and  clues  on  how  we  intend  to 
approach  their  solution  are  discussed  in  Section  4.  We 
end the paper drawing some conclusions in Section 5. 

2.  A  General  Multi-Robot  Cooperation  and 
Coordination Problem 

Many researchers around the world are designing mobile 
robots  capable  to  display  increasing  autonomy  and 
machine intelligence properties. Most groups concentrate 

141 

 
 
 
 
 
its 

to  perceive  correctly 

in specific subsystems of a robot, such as the planner, the 
navigator,  or  the  sensor  fusion.  What  usually  is  missing 
in  their  design  is  a  systematic  way  to  glue  together  all 
these  subsystems  in  a  consistent  fashion.  Such  a 
methodology,  should  one  be  available,  would  help 
engineering the mobile robots of the future. 
One  of  the  key  factors  of  success  for  a  robot  lies  on  its 
capability 
surrounding 
environment,  and  to  build  models  of  the  environment 
adequate for the task the robot is in charge of, from the 
information  provided  by  its  sensors.  Different  sensors 
(e.g.,  vision, 
laser,  sonar,  encoders)  can  provide 
alternative or complementary information about the same 
object,  or  information  about  different  objects.  Sensor 
fusion  is  the  usual  designation  for  methods  of  different 
types to merge the data from the several sensors available 
and provide improved information about the environment 
(e.g.,  about  the  geometry,  color,  shape  and  relevance  of 
team  composed  of  several 
its  objects).  When  a 
cooperating  robots  is  concerned,  the  sensors  are  spread 
over  the  different  robots,  with  the  important  advantage 
that  the  robots  can  move  (thus  moving  its  sensors)  to 
actively  improve  the  cooperative  perception  of  the 
environment  by  the  team.  The  information  about  the 
environment  so  obtained  can  be  made  available  and 
regularly  updated  by  different  means  (e.g.,  memory 
sharing,  message  passing,  using  for  instance  wireless 
communications) to all the team robots, so as to be used 
by the other sub-systems.  
Once  the  information  about  the  world  is  available,  one 
may  think  of  using  it  to  make  the  team  behave 
autonomously  and  machine-wise  intelligently.  Three 
main questions arise for the team: 
Where  and  which  a  priori  knowledge  about 
the 
environment,  team,  tasks  and  goals,  and  perceptual 
information  gathered  from  sensors,  should  be  kept, 
updated  and  maintained?  This  involves  the  issue  of 
distributed  knowledge 
to 
consistently handle different and even opposite views of 
the world. 
What  must  be  done  to  achieve  a  given  goal,  given  the 
constraints on time, available resources and distinct skills 
of the team robots? The answer to this should provide a 
team plan. 
How  is  the  actual  implementation  of  a  plan  handled, 
ensuring  the  consistency  of  individual  and  team  (sub)-
goals and the coordinated execution of the plan? 
So far, a bottom-up approach to the implementation of a 
cooperative  multi-robot  team  has  been  followed  in  the 
SocRob project, starting from the development of single 
robot sub-systems (e.g., perception, navigation, decision-
making)  and  moving 
towards  relational  behaviors, 
comprehending more than one robot.  
However, a key point is a top-down approach to system 
design.  The  design  phase  establishes  the  specifications 
for  the  system:  qualitative  specifications  -  concerning 
formal  logical  task  design  so  as  to  avoid  deadlocks, 
livelocks, unbounded resource usage and/or sharing non-
sharable resources, and to choose the primitive tasks that 
will span the desired task space; 

representation  adequate 

142 

-  concerning  performance 
quantitative  properties 
features, such as accuracy (e.g., the spatial and temporal 
resolution,  as  well  as  the  tolerance  interval  around  the 
goal,  at  each  abstraction 
level),  reliability  and/or  
minimization  of  task  execution  time  given  a  maximum 
allowed cost.  
To  support 
top-down  design  and  bottom-up 
implementation  philosophy,  suitable  functional  and 
software  architectures,  respectively,  must  be  conceived 
prior to the development of all the sub-systems. 

this 

fashion, 

i.e.,  each  sub-system 

2.1. Single-Robot Research Problems 
Most  of  the  problems  tackled  so  far  within  the  SocRob 
project concern the sub-systems of the individual robots 
composing  a  team.  From  our  standpoint,  relevant  topics 
are: 
Functional and Software Architectures: Modern robots 
should  be  designed  based  on  a  top-down  design  from 
specifications to ensure desired performance levels (both 
qualitative  and  quantitative).  Therefore,  the  designers 
should start by specifying a functional architecture which 
will  guide  the  design  of  the  robot  sub-systems  in  an 
is  not 
integrated 
necessarily  designed  to  optimize  its  performance  but 
rather  aiming  at  optimizing 
the  overall  system 
performance.  Another  important  issue  is  to  determine, 
given the desired task space (i.e., the set of tasks that will 
have  to  be  carried  out  by  the  robot  in  a  particular 
application),  the  minimal  set  of  primitive  tasks  that  will 
span that task space. Moreover, the final implementation 
should  be  supported  on  a  suitable  software  architecture 
to  allow  real-time  multi-processing,  data 
designed 
sharing  and  mutually  exclusive  allocation  of  shared 
resources among the robot sub-systems. 
Single-Robot  Task  Planning:  Given  the  primitive  task 
set referred in the previous item, the robot must be able, 
given the current and past world states (including its own 
internal state), to compose primitive tasks so as to come 
up with a plan that carries out a given desired task. There 
may be more than one plan that accomplishes a task, but 
a posterior decision system should be able to determine, 
eventually  based  on  machine  learning,  the  one  that 
achieves  the  best  performance,  based  on  the  available 
information and prediction horizon. 
Single-Robot  Task  Coordination:  Plans  must  be  such 
that  they  allow  continuous  handling  of  the  environment 
uncertainties  and  unexpected  events.  Once  a  plan  is 
determined,  task  coordination  deals  with  its  execution. 
Plan  execution  must,  at  least,  take  into  account  the 
detection of events, smooth transitions between primitive 
tasks,  synchronization  of  primitive 
tasks  executed 
concurrently,  mutual  exclusion  when  two  or  more  tasks 
attempt to access shared resources, iterative estimation of 
primitive  task  performance,  learning  how  to  improve  a 
plan  over  time  by  choosing  more  convenient  algorithms 
among those available for each primitive task, and so on. 
Navigation: The navigation system is an important sub-
system  of  a  mobile  robot.  In  many  applications  one 
important  feature  of  the  navigation  system  concerns  the 

 
ability of the robot to self-localize, i.e., to autonomously 
determine  its  position  and  orientation  (posture).  Using 
posture estimates, the robot can move towards a desired 
posture,  i.e.,  by  following  a  pre-planned  virtual  path  or 
by stabilizing its posture smoothly (Canudas de Wit, C., 
et  al,  1996).  If  the  robot  is  part  of  a  cooperative  multi-
robot team, it can also exchange the posture information 
with  its  teammates  so  that  appropriate  relational  and 
organizational behaviors  may  be  established.    In robotic 
soccer,  these  are  crucial  issues.  If  a  robot  knows  its 
posture,  it  can  move  towards  a  desired  posture  (e.g., 
facing  the  goal  with  the  ball  in  between).  It  can  also 
know  its  teammate  postures  and  prepare  a  pass,  or 
evaluate  the  game  state  from  the  team  locations.  Most 
approaches  to  Navigation  determine  with  high  accuracy 
the  posture  of  the  robot  with  respect  to  a  given 
coordinate  frame.  However,  this  approach  is  typically 
resource-consuming,  requiring  the  robot  to  spend  a 
significant  percentage  of  its  processing  time  with  the 
navigation sub-system, disregarding other important sub-
systems,  such  as  perception  or  planning,  to  name  but  a 
few.  Furthermore,  high  accuracy  is  not  always  required 
for  navigation  purposes.  One  may  be  just  interested  to 
move closer to an object, rotate to see a given landmark, 
or  move  to  another  region.  In  those  cases,  another 
topological  (or 
approach 
relative) navigation, is advisable. 
Object  Recognition  and  Tracking  Using  Sensor 
Fusion:  The  ability  to  discriminate  and  recognize  its 
surrounding objects, to distinguish the relevant ones and 
to track, among them, those that are relevant, is a major 
problem for any robot. For soccer robots, this problem is 
simplified since the relevant objects are distinguished by 
their  colors  (e.g.,  the  ball  is  orange,  the  goals  are  blue 
and  yellow).  Nevertheless,  fast  and  reliable  color 
segmentation  is  not  a  trivial  problem  and  requires  some 
attention  too.  Furthermore,  object  detection  may  be 
performed  by  more  than  one  sensor,  such  as  different 
virtual sensors based on the vision transducer (e.g., mass 
center,  edge  detector,  color  segmentation),  sonars, 
infrared and others. Therefore, sensor fusion arises as an 
important topic.  

to  navigation,  known  as 

is 

the 

robots 

involved, 

2.2. Cooperative Multi-Robot Research Problems 
Functional  and  Software  Architectures:  If  a  team  of 
cooperative 
single-robot 
architectures  of  each  of  the  team  members  must  be 
integrated  in  the  overall  team  architecture.  The  most 
usual solutions concerning the software architecture are: 
centralized,  where  one  of  the  robots  (or  an  external 
machine) processes the data acquired and sent by all the 
team  members,  takes  all  the  team  decisions  and  sends 
commands  to  the  others;  distributed,  where  local  data 
processing  is  made  at  each  of  the  robots  but  then 
information is sent to one of them to take the decisions; 
fully  decentralized,  where  each  robot  takes  its  own 
decisions  based  on  its  own  data  and  on  information 
exchanged with its teammates. 

to 

related 

knowledge 

distribution 

The  functional  architecture  of  a  behaviour-based  multi-
robot  team  must  also  classify  behaviours  according  to 
their  functionality.  One  such  division  consists  of 
considering  organizational,  relational  and  individual 
behaviours (Drogoul, A., and Collinot, A., 1998), further 
described below. 
Multi-Robot  Task  Planning  and  Allocation:  In  the 
multiple-robot  case,  plans  must  take  into  account  the 
distributed  nature  of  the  task  at  hand.  Different  tasks 
must  be  allocated  to  the  different  robots  in  the  team, 
according  to  their  skills  and  performance.  So,  the 
planning and allocation system must be able to establish 
(sub)groups of robots within a team, and the robots must 
have and know how to deal with the notion of “belonging 
include 
to  a  group”.  Therefore,  plans  must  also 
synchronization  and  communication  among 
team 
members  involved  in  the  task.  Moreover,  if  a  robot 
cannot fulfill its assigned task, the task may simply be re-
assigned to a robot within the group, a new robot may be 
integrated  in  the  group  to  perform  that  task,  or  in  the 
worst case a re-planning strategy has to be applied. 
Multi-Robot Task Coordination: The extension of task 
coordination  to  a  team  of  multiple  robots  introduces 
issues 
and 
maintenance,  as  well  as  communications  and  related 
problems  (e.g.,  noise,  protocols,  limited  bandwidth). 
Furthermore,  communication  can  be  explicit  (e.g., 
through  wireless  radio-frequency  channels)  or  implicit 
(e.g.,  through  the  observation  of  teammate  actions, 
should  an  a  priori  model  of  the  teammates  behaviour 
exist). The coordination of a task carried out by a team of 
cooperating robots involves signalling events detected by 
one  robot  which  are  relevant  for  some  or  all  of  its 
teammates  and/or  to  exchange  information  obtained 
locally  by  the  different  robots  of  the  team.  Whenever  a 
formation  is  required,  several  formation  topologies  are 
possible and the one suitable for the task at hand must be 
chosen as part of the coordination process. Although not 
inevitable,  communications  among  team  members  are 
also required to keep the formation under control. 
When  the  population  is  composed  of  heterogeneous 
robots,  if  a  robot  has  to  perform  a  particular  task  for 
which  it  does  not  have  the  necessary  skills,  it  may  ask 
another  robot  with  the  adequate  skills  to  carry  it  out.  In 
the particular case of the SocRob robotic team, where the 
robots  are  homogeneous,  examples  of  cooperative 
behaviour are the cooperative localization of the ball, the 
execution  of  a  pass,  the  dynamical  exchange  of  player 
roles  or  the  decision  of  which  robot  should  go  for  the 
ball.  All  of  them  require  some  form  of  inter-robot 
coordination and underlying teamwork methodologies. 
Distributed  World  Modeling:  A  team  composed  of 
multiple  robots,  possibly  heterogeneous  concerning  on 
board  sensing,  can  benefit  from  the  availability  of  a 
world  model,  obtained  from  the  observations  made  by 
the  different  team  members  and  its  on  board  sensors. 
This world model can be richer that if it were obtained by 
a single robot, due to the coverage of a broader area by a 

143 

 
 
more diversified set of sensors. It can also be distributed 
through the teammates, e.g., by keeping in a single robot 
information  which  is  only  relevant  locally  and  by 
broadcasting information gathered locally but which is of 
interest  for  the  team  as  a  whole.  The  sensor  fusion 
problem  is  similar  to  the  single-robot  case,  with  the 
important  difference  that  the  sensor  subsets  are  now 
independently  mobile  and  can  be  actively  positioned  to 
improve the determination of object characteristics. 

maintain  and  update  over  time  information  on  the 
relevant  objects,  such  as  ball  position  and  velocity, 
teammates  pose  and  velocity,  opponents  pose  and 
velocity,  or  position  of  the  goals  with  respect  to  the 
robot.  Such  information  is  obtained  by  each  robot  from 
the  observations  of  its  front  and  up  cameras  and  then 
fused among all the team robots (Pinheiro, P. & Lima, P., 
2004),  using  a  Bayesian  approach  to  sensor  fusion,  as 
depicted  in  Fig.  2.  Currently  this  approach  is  used  to 
provide  information  on  ball  position  to  all  the  team 
members,  therefore  enabling  robots  that  do  not  see  the 
ball  to  know  where  it  is,  besides  improving  ball 
localization  reliability.  Fusion  is  not  used  when  two 
robots  disagree  (in  probabilistic  terms)  on  the  ball 
localization. 

Fig.1 – Three robots of the current SocRob team. 

3.  Problems Already Addressed 

sonar 

sixteen 

A  key  issue  of  the  research  work  developed  under  the 
SocRob project is the application of conceptual results to 
real  robots  participating  in  the  Middle  Size  League 
(MSL) of RoboCup. The current robot team, displayed in 
Fig.  1,  is  composed  of  4  Nomadic  Super  Scout  II 
commercial platforms, later significantly modified by our 
group,  each  of  them  including:  two-wheel  differential 
drive  kinematics, 
radially 
distributed  around  the  robot,  equally  spaced,  Motorola 
MC68332  based  daughter  board  with  three-axis  motor 
controller, sonar and bumper interface, and battery level 
meters,  two  12V  batteries,  18Ah  capacity,  Pentium  III 
1000MHz  based  motherboard,  with  512MB  RAM,  8GB 
disk,  two  Philips  USB  WebCam  740K  Pro,  IEEE 
802.11b  wireless  Ethernet  PCMCIA  card,  pneumatic 
kicking  device,  based  on  Festo  components,  plus  one 
bottle  for  pressurized  air  storage.  In  the  remaining 
subsections,  we  describe  some  of  the  research  problems 
addressed and solved for this team of robots. 

sensors 

3.1.  Color  Segmentation  and  Cooperative  Object 
Recognition 
A color segmentation interface was developed, providing 
two alternatives to discriminate the relevant MSL colors 
in  HSV  (Hue-Saturation-Value)  color  space  (Gonzalez, 
R.,  &  Woods,  R.,  1992):  adjusting  HSV  intervals  and 
graphically  selecting  regions  with  a  given  pixel  color. 
The two approaches are cumulative. Furthermore, object 
segmentation  is  a  topic  directly  related  to  the  previous 
one, as we discriminate objects, namely the ball and the 
goals,  not  only  based  on  their  color,  but  also  on  their 
shape  (e.g.,  by  fitting  circles  to  observed  orange  bulbs 
and identifying the ball with the closest and more circular 
bulb). A topic of current research within the project is the 
use  of  sensor  fusion  for  world  modeling.  The  goal  is  to 

144 

  a) 

  b) 

Fig.  2  –  a)  local  (internal  to  each  robot)  sensor  fusion 
enabled  and  global  (among  team  robots)  sensor  fusion 
disabled; b) both local and global sensor fusion enabled 

from 

to  a  given  coordinate  system, 

3.2. Vision-Based Self-Localization 
An algorithm that determines the posture of a robot, with 
respect 
the 
observation of natural landmarks of the soccer field, such 
as  the  field  lines  and  goals,  as  well  as  from  a  priori 
knowledge  of  the  field  geometry,  has  been  developed 
within  the  SocRob  project  (Marques,  C.,  &  Lima,  P., 
2001). The algorithm is a particular implementation of a 
to  other  well-structured 
general  method  applicable 
environments, also introduced in (Marques, C., & Lima, 
P.,  2001).  The  landmarks  are  processed  from  an  image 
taken  by  an  omni-directional  vision  system,  based  on  a 
camera plus a convex mirror (catadioptric system image 
in  Fig.  3)  designed  to  directly  obtain  the  soccer  field 
bird's eye view, thus preserving the field geometry in the 
image.  The  image  green-white-green  color  transitions 
over  a  pre-determined  number  of  circles  centered  with 
the robot are collected as the set of transition pixels.  The 
Hough Transform is applied to the set of transition pixels 
in a given image, using the polar representation of a line 
(Gonzalez, R., & Woods, R., 1992): 
t
(1) 
.
φ
=
ρ
i
t) are the image coordinates of transition pixel 
where (xi
pt  and ρ, φ  are  the  line parameters.    The q  straight  lines 

cos
t,yi

sin.

φ

+

x

y

t
i

 
 
 
 
 
 
 
  
(ρq, φq)  corresponding 

top  q 
(ρl, φl),  …, 
accumulator cells in Hough space are picked and, for all 
pairs  {  (ρj, φj),  (ρk, φk),  j,k=1,  ...,q,  j  ≠  k  }  made  out  of 
those  q  straight  lines  the  following  distances  in  Hough 
space are computed: 

the 

to 

=∆

φφφ
j
k

−

=∆

ρρρ
j
k

−

(2) 

Note  that  a  small  φ∆ denotes  almost  parallel  straight 
lines, while  ρ∆  is the distance between 2 parallel lines. 
The  φ∆ and  ρ∆   values  are  subsequently  classified  by 
relevance  functions  which,  based  on  the  knowledge  of 
the  field  geometry,  will  filter  out  lines  whose  relative 
orientation and/or distances do not match the actual field 
relative orientation and/or distances. The remaining lines 
are  correlated,  in  Hough  space,  with  the  geometric  field 
model,  so  as  to  obtain  the  robot  posture  estimate.  An 
additional  step  must  be  taken  to  disambiguate  the  robot 
orientation.  In  the  application  to  soccer  robots,  the 
ambiguity is due to the soccer field symmetry. The goal 
colors  are  used  to  remove  such  ambiguity  and  to  detect 
situations where the localization values obtained are not 
trustable. 
Currently, an efficiently coded version of the algorithm is 
used  by  each  of  the  ISocRob  team  robots  to  obtain  its 
self-localization  during  a  game  every  second.  The 
algorithm runs in parallel with all the other processes and 
can  compute  self-localization  in  about  13  ms  on  the 
average, using Intel IPP library. The knowledge of each 
robot 
robot 
navigation,  but  it  is  also  used  by  the  robot  to  share 
information  with  its  teammates  regarding  team  postures 
and ball location. 

localization 

is  useful 

individual 

for 

Fig. 3 – Bird’s eye-view of the field obtained by the top 
catadioptric systems of the robots in Fig. 1. 

3.3. Multi-Sensor Guidance with Obstacle Avoidance 
The ability to navigate at relatively high speeds through 
an  environment  cluttered  with  static  and  dynamic 
obstacles  is  a  crucial  issue  for  a  mobile  robot.  Most 
robotic  tasks  require  a  robot  to  move  to  target  postures 
adequate  to  carry  out  its  planned  activities.  In  robotic 
soccer,  relevant  activities  include  facing  the  opponent 
goal with  the ball  in  between  or  covering the  team  goal 
by positioning itself between the ball and the goal, while 
avoiding  the  field  walls  and  the  other  (stopped  and 
moving)  robots.  Also  relevant  is  the  capability  to  move 
towards  a  given  posture  while  avoiding  obstacles  and 
keeping  the  ball  (also  known  as  dribbling).  A  guidance 
control  method  for  non-holonomic  (differential  drive) 

vehicles,  using  odometry,  regularly  reset  by  the  vision-
based  self-localization  algorithm  described  before,  was 
first  introduced  in  (Marques,  C.,  and  Lima,  P.,  2002). 
The vehicle uses a sonar ring for obstacle avoidance. An 
alternative  guidance  method  has  been  introduced  in 
(Damas,  B.,  et  al,  2002),  consisting  of  a  modified 
potential  fields  method  for  robot  navigation,  especially 
suited 
for  differential-drive  non-holonomic  mobile 
robots.  The  potential  field  is  modified  so  as  to  enhance 
the  relevance  of  obstacles  in  the  direction  of  the  robot 
motion.  The  relative  weight  assigned  to  front  and  side 
obstacles  can  be  modified  by  the  adjustment  of  one 
physically interpretable parameter. The resulting angular 
speed  and  linear  acceleration  of  the  robot  can  be 
expressed  as  functions  of  the  linear  speed,  distance  and 
relative  orientation  to  the  obstacles.  This  formulation 
enables  the  assignment  of  angular  and  linear  velocities 
for the robot in a natural fashion. Moreover, it leads to an 
elegant  formulation  of  the  constraints  on  angular  speed, 
linear speed and acceleration, that enable a soccer robot 
to  dribble  a  ball,  i.e.,  to  move  while  avoiding  obstacles 
and  pushing  the  ball  without  losing  it,  under  severe 
restrictions  to  ball  holding  capabilities.  It  is  shown  that, 
under  reasonable  physical  considerations,  the  angular 
speed  must  be  less  than  a  non-linear  function  of  the 
linear speed and acceleration, which reduces to an affine 
function of the acceleration/speed ratio when a simplified 
model  of  the  friction  forces  on  the  ball  is  used  and  the 
curvature of the robot trajectory is small. 

resulting 

3.4. Behavior-Based Architectures 
The  basic  functional  architecture  of  the  SocRob  team  is 
organized  in  three  levels  of  decision  and  responsibility, 
similar  to  those  proposed  in  (Drogoul,  A.,  and  Collinot, 
A.,  1998):  individual,  which  is  responsible  for  all 
functionalities  that  involve  only  one  agent;  relational, 
which  is  responsible  for  the  relationships  between  the 
robot  and  its  teammates;  and  organizational,  which  is 
responsible  for  the  strategic  decisions  that  involve  the 
team  as  a  whole.  The  current  instantiation  of  this 
functional architecture considers that: 
there is, at the organizational level, a mapping from the 
environment  state,  including the  team  state,  to  a  tactical 
in  an  organizational  behavior 
decision, 
displayed  by  the  team.  The  tactics  consists  of  the  set  of 
role assignments to each team member. In robotic soccer, 
basic 
roles  can  be  Goalkeeper,  Defender, 
Attacker  and  Full  Player  (both  defender  and 
attacker). Only the captain robot will have the organizer 
enabled. Should the captain “die”, the next robot in a pre-
specified  list  will  have  its  organizer  level  enabled  and 
become the captain. 
there are, at the relational level, operators which control 
relations  between  two  or  more  team  members  (e.g.,  to 
pass  a  ball,  to  avoid  moving  simultaneously  towards  a 
ball, to cover a field region while the  teammate advances 
in  the  field  through  role  exchanges).  Any  team  member 
has relational operators running. Each operator has a pre-
conditions  set and,  when  this  set  is  satisfied,  establishes 

145 

 
 
 
 
 
 
the  SocRob  project, 

the  relational  operator(s)  of 
communications  with 
designated teammates, asking them to start a negotiation 
process which may end up in a coordinated action among 
this  temporary  sub-team.  As  a  result,  a  relational 
behavior is displayed. 
there are, at the individual level, operators consisting of 
single  primitive  tasks  or  of  composite  tasks  (primitive 
tasks linked by logical conditions on events).  
The software architecture is the practical implementation 
of  the  functional  architecture,  which  could  be  done  in 
any programming  language  and  using different  software 
the  software 
technologies.  In 
architecture  was  defined  based  on 
three  essential 
concepts:  micro-agents  (µA  for  short),  blackboard  and 
plugins. 
Inspired  by  the  idea  of  Society  of  Agents,  proposed  by 
Minsky  (Minsky,  M.,  1988),  each  functional  module  of 
the  SocRob  architecture  was  implemented  by  a  separate 
process,  using  the  parallel  programming  technology  of 
threads. In this context a functional module is named µA. 
In the current implementation of the SocRob architecture 
there  are  nine  different  threads,  but  only  the  three  most 
important  ones  are  mentioned  here:  µA  Vision, 
responsible  for  processing  the  data  acquired  from  the 
cameras, µA Fusion, which fuses information concerning 
the  same  object  from  different  sensors,  µA  Machine, 
responsible for deciding which behavior should the robot 
display, and µA Control, responsible for the execution of 
the corresponding operator. 
The  concept  of  threads  was  chosen  to  improve  module 
performance and simplify the information passing among 
the  threads.  This  was  accomplished  by  the  blackboard 
concept  (memory  space  shared  by  several  threads), 
further  sophisticated  here  by  the  development  of  a 
distributed  blackboard,  in  what  information  availability 
is  concerned.  Instead  of  being  centralized  in  one  agent, 
the  information  is  distributed  among  all  team  members 
and communicated when needed. 
As  mentioned  before,  the  decision  making  involved  for 
each  agent  is  twofold:  which  behavior  should  be 
displayed,  and  how  the  operator  which  displays  such 
behavior  is  executed.  This  separation  between  behavior 
decision and operator execution allows the µA Machine, 
the  one  responsible  for  behavior  decision,  to  work  with 
abstract definitions of behaviors, and choose among them 
without  knowing  details  about  their  execution.  So,  new 
operators  could  be  easily  added  and  removed  without 
affecting  the  existing  ones,  and  these  can  also  be  easily 
replaced  by  others  with 
the  simple  restriction  of 
maintaining  the  name.  This was  accomplished  using  the 
concept of plugin, in the sense that each new operator is 
added  to  the  software  architecture  as  a  plugin,  and 
therefore the µA Control can be seen as a multiplexer of 
plugins. Examples of already implemented operators are: 
dribble,  score,  go,  standby,  to  name  but  a  few. 
The  same  idea  of  plugins  was  also  used  for  the  µA 
Vision,  as  each  particular  functionality  related  to  vision 
data is defined as a different plugin, and multiplexed by 
the  µA  Vision  (e.g.,  a  plugin  for  the  front  camera,  a 

146 

the 

implementation  of 

plugin  for  the  up  camera,  a  plugin  for  the  self-
localization algorithm, etc.). 
The individual operators have been implemented as state 
machines,  where  the  states  represent  primitive  tasks, 
while the arcs between states (if any) are traversed upon 
the  validation  of  given  logical  conditions  over  events 
(e.g.,  see  ball,  distance  <  x).  The  relational 
operator  state  machines  could  also  be  defined  similarly, 
but  events  include  synchronization  signals  between  the 
state machines running in the sub-team robots.  
However,  the  way  the  functional  architecture  was 
conceptualized  allows 
these 
operators  and  the  switching among  them  using  different 
approaches, as for example AI production systems. So, in 
order to have a more abstract way to deal with behaviour 
switching, the µA machine has been implemented using a 
distributed  decision-making  architecture  supported  on  a 
logical approach to modeling dynamical systems (Reiter, 
2001),  based  on  situation  calculus,  a  first  order  logic 
dialect. This architecture includes two main modules: i) a 
basic  logic  decision  unit,  and  ii)  an  advanced  logic 
decision unit. Both run in parallel; the former intends to 
quickly  suggest,  using  simple  logical  decision  rules,  the 
next  behavior  to  be  executed,  whereas  the  latter  uses 
more  sophisticated  reasoning  tools  (situation  calculus) 
capable of planning, learning and decision-making, both 
for  individual  and  cooperative  (teamwork)  situations. 
This  configures  an  hybrid  architecture  where  the  basic 
(reactive)  unit  only  controls  the  robot  if  the  advanced 
(deliberative)  unit  takes  too  long  to  make  a  decision, 
assuming  a  situation  urgency  evaluation.  A  partial 
implementation  of  this  architecture,  the  basic  logic 
decision  unit,  was  already  performed  using  Prolog 
(Arroz,  M.,  et  al,  2004).    Its  modeling  convenience 
allowed the quick development of different roles for field 
players (Attacker, Defender, Full-Player), as 
well  as  dynamic  role  change  between  field  players 
(defenders switch with attackers, depending on who is in 
a  better  position 
the  ball).  The  advanced 
(deliberative) unit, Advanced Logic Based Unit, has been 
developed using an action programming language called 
Golog Golog (Levesque, H., et al, 1997) and it is based 
on  situational  calculus.  This  unit  is  responsible  to 
determine plans (sequences of behaviours) that allow the 
team to achieve something (like scoring on the opposite 
goal).  Situational  calculus  is  an  extension  to  first-order 
logic,  specially  suited  to  handle  dynamic  worlds.  The 
changes in the world are the results of actions, that have 
pre-conditions and effects. Our objective is to develop a 
tool  capable  of  planning  and  performing  task  control 
execution  in  a  distributed  environment.  To  do  so  we 
assume that: the agents (robots) can generate, change and 
execute plans; a plan can be generated, and executed by 
one  or  more  agents;  decisions  over  the  generated  plans 
are  based  on  hypotheses,  i.e.,  assumptions  over  future 
states that cannot be guaranteed; and the agents have the 
capacity 
them,  and  share 
to  communicate  among 
information about plans or environment states.  
Another recent topic in the project research is the design 
implementation  of  relational  behaviors,  where 
and 

to  get 

to  an 

the  other  switches 

teamwork  between  two  or  more  robots  is  required  to 
perform  a  certain  task,  like  a  ball  pass  (Vecht,  B.,  & 
Lima,  P.,  2004).  These  behaviors  have  a  general 
formulation based on Joint Commitment Theory (Cohen, 
P.  R.,  &  Levesque,  H.  J.,  1991),  and  use  the  navigation 
methods already developed in the project. Currently, the 
robots  are  capable  of  committing  to  a  relational  pass 
behavior  where  one  of  the  robots  is  the  kicker  and  the 
other  the  receiver.  If  any  of  the  robots  ends  the 
individual 
commitment, 
behavior.  One  cooperation  mechanism,  implemented  in 
2000, consists of avoiding that two or more robots from 
the  same  team  attempt  to  get  the  ball.  A  relational 
operator was developed to determine which robot should 
go to the ball and which one(s) should not. In the current 
implementation,  each  robot  that  sees  the  ball  and  wants 
to go for it uses a heuristic function to determine a fitness 
value.  This  heuristic  penalizes  robots  that  are  far  from 
the  ball,  are  between  the  ball  and  the  opposite  goal  and 
need  to  perform  a  angular  correction  to  center  the  ball 
with  its  kicking  device.  Each  robot  broadcasts  its  own 
heuristic  value,  and  the  robot  with  the  smallest  value  is 
allowed  to  go  for  the  ball  whereas  the  others  execute  a 
Standby behavior. Though not tested yet in real robots, 
formal  work  on  Stochastic  Discrete-Event  Systems 
modeling of a multi-robot team has been recently carried 
out within the project with interesting results (Damas, B., 
&  Lima,  P.,  2004).  The  environment  space  and  each 
player  (opponent  and  teammate)  actions  are  discretized 
and  modeled  by  a  Finite  State  Automaton  (FSA)  2  vs  2 
players  game  model.  Then,  all  FSA  are  composed  to 
obtain  the  complete  model  of  a  team  situated  in  its 
adversarial  game. 
environment 
Controllable 
and 
Uncontrollable  (e.g.,  lost_ball,  see_ball)  events 
(i.e.,  our  robots  actions)  are  identified  and  exponential 
distributions  are  assigned  to  their  inter-event  times. 
Dynamic programming is applied to the optimal selection 
of  the  controllable  events,  with  the  goal  of  minimizing 
the cost function 
∞

and  playing 
an 
(e.g.,  shoot_p1,  stop_p2) 

min
π

⎡
⎢
⎣

∫

0

tutXC
(
)(

),

[

]
dt

⎤
⎥
⎦

 (3) 

where π is a policy, X(t) the game state at time t, and u(t) 
is a controllable event, with the cost of unmarked states 
equal to 1, and all the other states have zero cost. If the 
only  marked  states  are  those  where  a  goal  is  scored  for 
our  team,  and  there  are  no  transitions  from  marked  to 
unmarked states, this method obtains the minimum (in a 
stochastic  sense)  time  to  goal  for  our  team,  constrained 
by  the  opponent  actions  and  the  uncertainty  of  our  own 
actions. Some of the chosen actions result in cooperation 
between the two robots of the team. 

4. Problems To Be Addressed 

Naturally,  several  interesting  problems  remain  to  be 
tackled  and  solved  within  the  project  research.  We  will 
only mention the currently most important ones. 

is 

in 

the 

is  required 

limited  modeling 

Behavior  Modeling:  A  consistent  model  for  individual 
and  relational  behaviors 
to  provide  a 
systematic  methodology  for  behavior  synthesis  and 
analysis. FSA have been used for this purpose up to now. 
They  have  the  advantage  of  the  availability  of  several 
tools  for  analysis  and  synthesis 
literature 
(Cassandras,  C.  G.,  &  Lafortune,  S,  1999),  but  suffer 
from 
capabilities.  Petri  nets 
(Cassandras,  C.  G.,  &  Lafortune,  S,  1999)  extend  the 
modeling  capabilities  of  FSA  and  provide  a  more 
convenient  modeling  methodology  starting  from  the 
identification  of  the  system  components  and  events.  A 
wide  range  of  analysis  (e.g.,  concerning  boundedness, 
liveness, stochastic and deterministic time) and synthesis 
(e.g.,  concerning  admissible  marked  languages)  tools  is 
also available, and the non-decidability of some analysis 
problems can be overcome with no significant expenses. 
Furthermore,  modularity  and  system  design  can  be 
achieved  by  interconnecting  several  sub-systems,  each 
modeled as a Petri net. This is particularly convenient to 
model  relational  behaviors,  where  more 
than  one 
involved.  So,  Petri  nets  are  being 
teammate 
investigated as an alternative tool for behavior modeling. 
Behavior  switching  can  also  be  modeled  as  discrete-
event  systems  supervision,  for  which  there  are  results 
available  regarding  FSA  and  Petri  nets.  Production 
systems  also  have  modeling  characteristics  that  make 
them  suitable  for  this  purpose.  However,  further  work 
must be done to study its design and analysis properties. 
Distributed  Planning:  The  available  behaviors  among 
which  switching  is  possible  are  currently  designed  “by 
hand”. However, a more appropriate approach would be 
to  develop  a  planner  capable  of  periodically  (or  when 
invoked)  analyzing  the  world  state  and providing  a new 
set of individual and relational behaviors appropriate for 
the current conditions. A suitable approach should be the 
continuous interleaving of plan generation and execution. 
Task  allocation  among  the  team  robots  and  distributed 
to  be  further 
world  modeling  are  relevant 
investigated under this topic. 
Cooperative  Learning:  One  possible  way  of  designing 
plans which continuously adapt to new situations and are 
fine tuned to the actual surrounding environment is to use 
reinforcement learning (RL) algorithms, especially those 
which guarantee convergence properties (Sutton, R., and 
Barto, A., 1998). However, learning is usually slow. An 
envisaged  approach  that  overcomes  this  problem  is  to 
provide plans with alternative paths among which the RL 
algorithms  can  learn  to  switch  over  time.  Cooperative 
learning  arises  when  a  robot  takes  its  decisions  from 
information learned and provided to it by its teammates. 
Control  as  a  Game:  Modern  views  of  control  state  the 
control problem as a game against an adversary (i.e., the 
disturbances). In the particular case of soccer, there is an 
actual opponent whose modeled behavior, once estimated 
(e.g.,  using  Hidden  Markov  Models),  can  be  used  as 
information  for  game-playing  algorithms,  as  part  of  the 
planning process. 

issues 

147 

 
 
 
 
 
5. Conclusion 

from  different 

This  paper  described  the  SocRob  project  (on  the 
development  of  methodologies  for  analysis,  design  and 
implementation  of  multi-robot  cooperative  systems),  its 
objectives,  past,  current  and  intended  future  work.  One 
interesting  feature  of  the  project  is  that  it  enables 
different  approaches  to  the  solution  of  the  problem  at 
hand.  This  naturally  motivates  competing  research 
approaches,  as  well  as  research  on  analysis  methods  to 
compare  the  different  results.  Furthermore,  the  project 
fosters  education  in  AI  and  Robotics  related  topics, 
because  so  many  issues  must  be  solved  to  handle  the 
levels 
overall  problem.  Students 
(undergraduate,  graduate,  post-doctorate)  can  get 
involved  at  different  difficulty  levels  and  accomplish 
project  sub-goals.  They  also  learn  how  to  accomplish 
teamwork  under  hard  time  deadlines.  The  SocRob 
project  has  involved  so  far  10  undergraduate  and  4 
graduate  (MSc  and  PhD)  students,  besides  2  doctorates 
who have been supervising the project. All these students 
have participated regularly in RoboCup - The World Cup 
of Soccer Robots, since 1998. We believe that RoboCup 
is  a  very  attractive  long-term  scientific  challenge  that 
brings  together  people  from  several  different  scientific 
fields  in  an  exciting  fusion  of  research,  education  and 
science  promotion  which  are  actually  the  driving  forces 
of our project too. 
Some of the methodologies developed within the project, 
namely  its  software  and  functional  architectures,  have 
been  applied  meanwhile  to  other  projects,  such  as  an 
European Space Agency project on Formation Guidance 
and  Navigation  of  Distributed  Spacecraft,  and  a 
Cooperative  Navigation  for  Rescue  Robots  project 
currently underway at ISR/IST. 
The  project  team  is  now  developing  new  robots,  in  the 
framework  of  a  national  research  project,  in  partnership 
with two Portuguese small companies. These new robots 
are omnidirectional, with a new modular construction, so 
that it will be easily modified, e.g., the up camera module 
can  switch  between  a  catadioptric  system  and  a  stereo 
image  system.  The  new  robots  will  also  incorporate  a 
controlled kicker mechanism, so that one can choose the 
kicking force, using an electromechanical solution with a 
DC  motor  pulling  a  spring  and  an  infrared  sensor  to 
measure the pulled distance, both coupled to the kicking 
device.  In  order  to  make  new  and  more  complex 
behaviors and for ball handling, there is a ball reception 
mechanism,  that  will  allow  the  implementation  of  ball 
passes behaviors. Two new sensors will be used: a rate-
gyro  for  angular  velocity  measurements,  and  an  optical 
mouse  to  track  the  robot  position  in  the  field.  Both  will 
provide data to be fused with odometry and vision-based 
self-localization, so as to improve navigation. 

6. References 
Canudas  de  Wit,  C.  and  Siciliano  B.,  and  Bastin  G.  (Eds) 
(1996), Theory of Robot Control, CCE Series, Kluwer 
Cassandras, C. G. and Lafortune, S. (1999), Introduction to 
Discrete Event Systems, Kluwer Academic Publishers 
Cohen,  P.  R.,  and  Levesque,  H.  J.  (1991),  ""Teamwork"". 

148 

Nous, Vol 35, pp. 487-512 

Damas, B.  and  Lima P. and Custódio (2002), “A Modified 
Potential  Fields  Method  for  Robot  Navigation  Applied 
to  Dribbling 
in  Robotic  Soccer”,  Proceedings  of 
RoboCup-2002 Symposium, Fukuoka, Japan 

Damas, B., and Lima, P., (2004), ""Stochastic Discrete Event 
Model  of  a  Multi-Robot  Team  Playing  an  Adversarial 
Game"",  5th  IFAC/EURON  Symposium  on  Intelligent 
Autonomous Vehicles - IAV2004, Lisboa, Portugal 

Decker,  K.  S.,  and  Lesser,  V.  R.  (1995),  “Designing  a 
Family  of  Coordination  Algorithms”,  Technical  Report 
No. 94-14, Department of Computer Science, University 
of Massachussets, Amherst, MA01003 

desJardins, M. E., and Durfee, E. H., and Ortiz Jr, C. L., and 
Wolverton,  M.  J.  (1999),  “A  Survey  of  Research  in 
Distributed, Continual Planning”, AI Magazine, Winter, 
pp. 13-22 

Drogoul, A., and Collinot, A. (1998), “Applying an Agent-
Oriented  Methodology  to  the  Design  of  Artificial 
Organizations:  A  Case  Study  in  Robotic    Soccer”, 
Autonomous  Agents  and  Multi-Agent  Systems  Journal, 
Vol. 1, pp. 113-129 

Ferber,  J.  (1999),  Multi-Agent  Systems:  An  Introduction  to 
Distributed Artificial Intelligence, Addison-Wesley 
Gonzalez,  R.,  and  Woods,  R.  (1992),  Digital  Image 

Processing, Addison-Wesley 

Levesque, H., and Reiter, R., and Lesprance, Y., and Lin, F., 
and  Scherl,  R.  (1997),  “Golog:  A  Logic  Programming 
Language  for  Dynamics  Domains”.  Journal  of  Logic 
Programming  

Marques, C., and Lima, P. (2001), “A Localization Method 
for  a  Soccer  Robot  Using  a  Vision-Based  Omni-
Directional  Sensor”,  RoboCup-2000:  Robot  Soccer 
World  Cup  IV,  P.  Stone,  T.  Balch,  G.  Kraetzschmar 
(Eds.), Springer-Verlag, Berlin 

Marques, C., and Lima, P. (2002), “Multi-sensor Navigation 
for  Soccer  Robots”,  RoboCup-2001:  Robot  Soccer 
World  Cup  V,  A.  Birk,  S.  Coradeschi,  S.  Tadokoro 
(Eds.), Springer-Verlag, Berlin  

Minsky,  M.  (1988),  The  Society  of  Mind,  Touchstone 

Publishers 

Pinheiro, P., and Lima, P. (2004), ""Bayesian Sensor Fusion 
for  Cooperative  Object  Localization  and  World 
Modeling"",  8th  Conference  on  Intelligent  Autonomous 
Systems  (IAS-8),  Amsterdam,  The  Netherlands,  May 
2004. 

Pires, V., Arroz, M., and Custódio, L. (2004), “Logic Based 
Hybrid Decision System for a Multi-robot Team”, 
Proceedings of the 8th Conference on Intelligent 
Autonomous Systems (IAS-8), Amsterdam, The 
Netherlands. 

Pires, V., Arroz, M., Lima, P., Ribeiro, M. I., and Custódio 
(2004), L., “Distributed Deliberative Decision System 
for a Multi-Robot Team”, Proceedings of the 
ROBÓTICA 2004 Symposium, Porto, Portugal, Abril 
2004. 

Reiter, R. (2001), Knowledge in Action. MIT Press  
Sutton,  R.,  and  Barto,  A.  (1998),  Reinforcement  Learning, 

MIT Press, Cambridge, MA 

Vecht,  B.,  Lima,  P., 

and 
Implementation of Relational Behaviors for Multi-Robot 
Cooperative  Systems”.  Proceedings  of  RoboCup  2004 
Symposium, Lisbon, Portugal 

“Formulation 

2004,"
Topological Navigation of Simulated Robots using Occupancy Grid,"  Formerly I presented a metric navigation method in the Webots mobile robot
simulator. The navigating Khepera-like robot builds an occupancy grid of the
environment and explores the square-shaped room around with a value iteration
algorithm. Now I created a topological navigation procedure based on the
occupancy grid process. The extension by a skeletonization algorithm results a
graph of important places and the connecting routes among them. I also show the
significant time profit gained during the process.
",http://arxiv.org/pdf/cs/0411022v1,1,"Szabo, R. / Topological Navigation of Simulated Robots using Occupancy Grid, pp. 201 - 206, International Journal of 
Advanced Robotic Systems, Volume 1, Number 3 (2004), ISSN 1729-8806 

Topological Navigation of Simulated Robots using Occupancy Grid 

Richard Szabo 
Eotvos Lorand University , Budapest, Hungary 
Department of General Computer Science, 
Department of History and Philosophy of Science, 
rics@inf.elte.hu 

Abstract:  Formerly  I  presented  a  metric  navigation  method  in  the  Webots  mobile  robot  simulator.  The  navigating 
Khepera-like robot builds an occupancy grid of the environment and explores the square-shaped room around with a 
value iteration algorithm. Now I created a topological navigation procedure based on the occupancy grid process. The 
extension by a skeletonization algorithm results a graph of important places and the connecting routes among them. I 
also show the significant time profit gained during the process. 
Keywords: robot simulation, occupancy grid, metric/topological navigation 

simulation  environment,  that  is  to say I focus on metric 
like  distances,  and 
spatial  properties  of  objects 
to  build  a 
coordinates.  The  developed  robot  has 
cognitive  map  —  “a  view  from  above”  —  of  small 
rooms while it visits every reachable location (Szabó, R. 
2003).  Fig.  1.,  Fig.  2.  show  some  typical  experimental 
area. 

1. Introduction 

Mobile  robotics  and  robot  navigation  is  a  growing  area 
of scientific research. Without navigation the creation of 
self-propelled,  household  machines,  guard  robots,  or 
planet surveyors is beyond imagination.  
Robot  simulators  are  useful  designing  and  analizing 
tools  of  the  navigation  research  area  since  learning  can 
be more effective in the computer than in the real world.  
In this paper I present a method for building topological 
navigation  graph  on  the  top  of  an  occupancy  grid.  First 
of  all  I  show  in  brief  the  creation  of  an  occupancy  grid 
and the exploration with value iteration. Then I focus on 
the necessary steps of the composition of the graph and 
the environment exploration utilizing the evolved graph.  
The  primary  tool  for  the  experiments  is  the  Webots 
mobile robot simulator. This tool is capable of imitating 
almost  any  type  of  mobile  robots  including  wheeled, 
legged, and flying models (Michel, O., 2004). 
This  project  is  part of my Ph.D. research with the main 
aim  of  the  investigation  of  mobile  robot  navigation. 
After  I  was  the  runner  up  of  the  1st  Artificial  Life 
Creators Contest organized by Cyberbotics Ltd. in 1999, 
I  won  the  second  contest  in  2000  and  obtained  the 
simulator  license  as  the  first  prize.  Details  of  the 
competitions are discussed in (Szabó, R., 2001). 

2. Previous work 

Fig. 1. Radial maze 

My  former  goal  was  to  create  a  metric  navigation 
module  for  a  modified  Khepera  robot  in  the  Webots 

In this experiment I modified the selected Khepera robot. 
The  8  infra-red  distance  sensors  were  changed  to  24 

201 

 
 
 
 
 
 
sonars  with  a  sensing  range  of  15  cm  to  facilitate  the 
perception of the environment.   

occupancy  grid  values  is  possible,  sonar  scans  can  be 
“concatenated” to previous experiences. 
After the local grid is created around the robot its values 
have  to  be  merged  into  the  global  grid.  Beyond  the 
coordinate  transformation  between  the  grids  we  need  a  
global  position  where  the  local  grid  can  be  integrated. 
Robot position estimation is not an immanent property of 
the  occupancy  grid  technique  so  an  accepted  method  is 
to  use  a  position  estimation  method  like  odometry  — 
continuous  calculation  of  changes  of  the  robot  pose  — 
combined  with  correction  of  errors  accumulated  by 
sensor and motor noise (Borenstein, J., 1995). Since my 
main focus is the occupancy grid the simulator provides 
the position to step across this problem.  
Fig.  3.  shows  the  occupancy  grid  of  a  maze  during  the 
process of the exploration. 

Fig. 2. AAAI contest maze  

The adopted method of metric navigation is based on the 
occupancy  grid  model  pioneered  by  Moravec  and  Elfes 
(Moravec, H. P. & Elfes, A., 1985 and Elfes, A., 1989). 
This  general  structure  in  two  dimension  manages  a 
tesselation  of  the  plane  in  cells.  Each  cell  of  the 
occupancy grid contains a probability value which is an 
estimation  that  the  represented  position  is  occupied  by 
some object. After the investigation of other probabilistic 
navigation possibilities like Kalman-filter or expectation 
maximization (Thrun, S., 2002), I have chosen this grid 
technique  because  it  is  relatively  simple  to  implement 
and because of its iterative nature. 
The  important  steps  of  the  map  building,  in  accordance 
with Thrun's work (Thrun, S., 1998), are the following: 
•  sensor interpretation 
• 
integration over time 
•  pose estimation  
•  global grid building 
•  exploration 

2.1. Occupancy grid creation 

The sensor interpretation is the first phase in the creation 
of  the  occupancy  grid  based  navigation.  During  this 
process the 24 sonar scalar values are converted to local 
occupancy  values  around  the  robot.  The  conditional 
probabilities of grid cells are determined by a predefined 
conversion function: probabilities are high at the point of 
a measurement, and are low closer to the robot. 
Since different sonar measurements give different values 
for a grid cell because of noise and changing viewpoint, 
it is important to integrate the conditional probabilites of 
distinct moments. Using the assumption of the indepence 
of measurements — that generally does not hold — and 
incremental  calculation  of 
the  Bayes 

theorem, 

202 

Fig. 3. Occupancy grid of a maze  

2.2. Iterative evaluation 

After the robot is ready to create the environment map, a 
driving  force  is  needed  to  urge  the  robot  to  explore  all 
it  would  wander 
the  reachable  places,  otherwise 
randomly.  For  this  reason  we  implemented  a  variant  of 
value iteration. This method is well-known in the domain 
of reinforcement learning (Sutton, R. & Barto, A., 1998). 

Fig. 4. Cost matrix of the maze  

 
 
 
 
 
 
 
         
 
 
 
 
       
 
 
The  selected  algorithm  helps  to find the minimum cost-
path to unexplored regions of the occupancy grid. A cost 
matrix is calculated iteratively and after convergence for 
every  occupancy  grid  cell  the  cost  of  travelling  to  an 
unexplored grid cell from the actual cell is given (Fig. 4). 
Exploration  direction  is  then  a  resultant  of  the  cost 
matrix, the actual direction of the robot, and an obstacle-
avoidance behaviour. 

3. Building a topological graph from occupancy grid 

Exploration  using  value  iteration  is  a  very  time-
consuming task. Values of the cells of the cost matrix are 
calculated  by  a  process  which  scans  through  the  whole 
matrix  many  times.  Furthermore  the  next  exploration 
direction  is  based  on  this  gradient  map  and  it  does  not 
take  into  account  the  constraint  of  the  robot  dynamism, 
sometimes resulting a fairly clumsy movement. 
Accordingly  it  seems  a  natural  improvement  to  replace 
the value iteration module with a topological graph. This 
graph  emphasizes  the  links  between  landmarks,  the 
possibility  to  move  from  one  place  to  another.  Edges 
represent  traversable  corridors  of  the  environment  and 
nodes  are  the  crossings  or  end  points.  Navigation  using 
the  graph  is  much  faster  since  its  size  is  some  order  of 
magnitude smaller than of the cost matrix. Chapter 2 of 
my  book  (Szabó,  R.  2001)  compares  metric  and 
topological navigation in detail. 
There  are  many  different  ways  of  creating  a  navigation 
graph  using  a  metric  map.  Skeletonization,  Voronoi-
diagrams,  matching  opposite  contours,  sparse  pixel 
approaches are among the possibilities (Thrun, S., 1998 
and Tombre, K. & Ah-Soon, C. & Dosch, P. & Masini, 
G.  &  Tabbone,  S.,  2000).  In  any  case,  the  occupancy 
grid  can  be  viewed  as  a  two-dimensional  greyscale 
image  of 
image 
processing  methods  are  valid  approaches  (Elfes,  A. 
1989). 
Since  I  selected  skeletonization,  steps  of  topological 
navigation using the occupancy grid are the following: 

the  environment,  hence  digital 

•  skeletonization 
•  chaining the skeleton to form edges 
•  graph optimization 
•  navigation using the graph 

3.1. Skeletonization 
I  decided  to  produce  the  skeleton  of  the  explored  and 
unoccupied region of the environment. At the end of the 
process skeleton points are those places where the robot 
is hopefully not blocked by any obstacles. 
For  this  reason  I  utilized  medial  axis  transform  (MAT) 
(Borgefors,  G.,  1986).  An  interior  point  of  the  shape 
belongs  to  the  medial  axis  if  this  point  lies  at  the  same 
distance  from  two  or  more  nearest  contour  points. 
Unfortunately  one  drawback  of  MAT  appeared  during 
my  tests:  medial  axis  of  discrete  objects  and  shapes  — 
like the discrete occupancy grid to be projected — may 

be disconnected. This deficiency is not acceptable in our 
case  since  the  resulting  skeleton  has  to  contain  all 
connected routes among landmarks of the environment.  
As  a  second  attempt  instead  of  using  medial  axis 
transform  I  applied  a  thinning  algorithm  to  “peel  the 
union”, in other words I iteratively shrinked the object to 
its  one  pixel  wide  skeleton  (Jain,  A.  K.,  1989).  During 
this  process  the  border  pixels  are  deleted  successively 
while 
is 
preserved, that is to say no pixels are deleted at the end 
of a line or at the connection of two regions. 
The  thinning  algorithm  works  as  it  is  described  in 
Algorithm  1.  Labeling  of  pixels  around  the  actual  pixel 
(P1) advances counter-clockwise. 

topology  and  morphology  of 

the  object 

Z0(P1)  -  the  number  of  zero  to  nonzero  translations  in  the 
sequence P2, P3, P4, P5, P6, P7, P8, P9, P2 
NZ(P1) - the number of nonzero neighbours of P1 
Steps: 
1. Scan through all the points of the image. 
2. Calculate Z0(P1), NZ(P1), Z0(P2), Z0(P4), for 
all points. 
3. Delete P1 if the conditions simultaneously satisfied: 

2 <= NZ(P1) <= 6, 
Z0(P1)  = 1, 
P2 * P4 * P8 = 0 or Z0(P2) <> 1 
P2 * P4 * P6 = 0 or Z0(P4) <> 1 

Algorithm 1. The thinning algorithm 

Fig. 5. is an example of the result of the skeletonization 
process using the thinning algorithm. 

Fig. 5. Skeleton of an office  

3.2. Chaining 

thinning 

the  skeleton  of 

iteration  because 

Navigation  on 
the  explored  and 
unoccupied  territory  is  possible  and  can  be  more 
effective  than  the  calculation  of  the  cost  matrix  of  the 
results  a  data 
value 
compression.  Nevertheless  it  is  advisable  to  use  the 
skeleton as a basis for further processing.  
Skeleton  of  the  explored  region  is  a  set  of  pixels,  this 
structure can be transformed to a graph. First of all, those 
points  have  to  be  determined  where  skeleton  branches 
meet. These pixels are the nodes, otherwise they are the 
crossing  points  of  corridors.  After  I  have  selected  the 

203 

 
 
 
 
 
 
 
 
 
 
 
nodes  I  cycle  through  the  skeleton  branches.  This 
procedure  issues  in  chains,  what  are  pixel  sequences 
from  node  to  node  or  from  node  to  skeleton  end  point 
(Tombre,  K.  &  Ah-Soon,  C.  &  Dosch, P. & Masini, G. 
&  Tabbone,  S.,  2000).  Algorithm  2.  reveals  the  main 
structure of the procedure. 

while there are nodes left do 
  c = newChain() 
  while there are non-null neighours left do 
    if not found getNonNode4Neighbour(q) then 
      if not found getNode4Neighbour(q) then 
        if not found getNonNode8Neighbour(q) then 
          if found getNode8Neighbour(q) then 
            append(q,c) 
          end 
          endChain(c) 
        else 
          append(q,c) 
        end 
      else 
        append(q,c) 
        endChain(c) 
      end 
    else 
      append(q,c) 
    end 
  end 
end 

Algorithm 2. Excerpt of the chaining algorithm 

The  first  draft  of  the  graph  is  calculated  during  the 
chaining  process.  Skeleton  nodes  and  end  points  take 
part  in  the  graph  as  nodes.  Graph  edges  connect  those 
nodes between which a chain exists.  
During  my  investigation  it  turned  out  that  the  cited 
algorithm has two minor problems that, in special cases, 
corrupts the graph.  On Fig. 6. and Fig. 7. chain creation 
starts from nodes (marked by 'o') and cycles through all 
the  neighbours  of  the  node  (marked  by  'x').  Non-node 
elements are cancelled after they take part in a chain. 
First problem rises in situations similar to the one shown 
on Fig. 6. Pixel x marked by 1 (x-1) is cancelled during 
the chain creation starting from x-2. In the next step — 
since  all  the  neighbours  of  nodes  have  to  be  processed 
— chain creation tries to start from an already cancelled 
node: x-1. 

   Fig. 6. Chain problem 1       Fig. 7. Chain problem 2  

Another  problem  is  indicated  on  Fig.  7.  If  the  chain 
creation  starts  from  x-2  then  in  the  next  step  the  search 

204 

should  turn  to  x-3  and  chain  the  pixels  downwards. 
However  there  is  no  explicit  constraint  in  the algorithm 
to prevent the continuation after x-2 in the direction of x-
1, what is obviously wrong, since it leaves x-3 without a 
connection to the node. After I corrected these mistakes 
the chaining algorithm created the draft of the navigation 
graph. 

3.3. Graph optimization 
First  version  of  the  graph  is  not  applicable  to  navigate 
because  chains  may  ramble  far  away  from  edges  and  if 
the  robot  simply  follows  the  way  of  an  edge  it  could 
meet with obstacles. 
To  cope  with  this  problem  it  is  possible  to  recursively 
split  the  edge  in  question  and  ensure  that  the  new 
particles track the slues of the chain better. There are two 
different algorithm-family for this approximation. 
Wall  and  Danielsson  calculate  the  algebraic  surface 
between the edge and the chain (Wall, K. & Danielsson, 
P.-E.,  1984).  The  iterative  computation  is  performed  by 
determining  the  sum  of  successive  triangles.  If  the  size 
of  the  surface  exceeds  a  certain  threshold  then  splitting 
of the edge is necessary. 
Rosin  and  West's  algorithm  measures  the  maximal 
distance between the edge and the chain (Rosin, P. L. & 
West,  G.  A.,  1989).  This  method  splits  the  edge  at  its 
maximum deviation point recursively until all the created 
new  edges  are  acceptable  approximations  of  the  chain 
(Fig. 8.). 

Fig. 8. Splitting (taken from the slides of Tombre, K. & 
Ah-Soon, C. & Dosch, P. & Masini, G. & Tabbone, S., 
2000)  

As a comparison of the methods Tombre, K. & Ah-Soon, 
C. & Dosch, P. & Masini, G. & Tabbone, S., 2000 states 
that  Wall  and  Danielsson  can  be  implemented  very 
efficiently but, on the other hand, it is less accurate than 
Rosin  and  West's  method.  Additionally,  the  second 
mentioned  algorithm  may  split  up  edges  into  small 
pieces near junctions. 
Since  I  would  like  to  use  the  topological  graph  for 
navigation  at  the  end,  it  is  important  that  edges  do  not 
cross  or  reach  obstacles  and  walls.  In  other  words, 
fidelity of the graph to the calculated chain is important 
so  I  have  chosen  and  implemented  Rosin  and  West's 
algorithm. The procedure is described in Algorithm 3. 
When the recursive splitting is finished pruning of edges 
regions. 
is  useful  especially  near 
Otherwise,  if  the  robot  simply  moves  to  an  end  node 
where unexplored territory is nearby, then accidentaly it 
could run into a wall. 

to  unexplored 

 
 
 
    
                      
 
 
 
 
 
 
split_edge(graph,start_point,end_point) { 
  while chain is not finished do 
    act_point  = get_act_point(chain) 
    h = height(start_point,end_point,act_point) 
    if h > LIMIT then 
       delete_edge_from_graph(graph,start_point,end_point)     
       add_node_to_graph(graph,act_point) 
       add_edge_to_graph(graph,start_point,act_point) 
       add_edge_to_graph(graph,act_point,end_point) 
       split_edge(graph,start_point,act_point) 
       split_edge(graph,act_point,end_point) 
    end    
  end 
} 

Algorithm 3. Algorithm of Rosin and West 

Fig.  10.  shows  the  optimized  graph  of  Fig.  9.  after 
recursive edge splitting and pruning. 

Fig. 9. Graph after chaining  Fig. 10. Optimized graph 

3.4. Navigation 
When  creation  of  the  graph  of  the  explored  and  free 
region  is  complete,  the  robot  has  to  determine  the  next 
exploration  direction.  Generally  the  robot  is  aimed  to 
sweep  through  all  the  reachable  places  of  the  terrain. 
This is why those nodes of the graph can be considered 
as goal nodes where unexplored region is close. 
To  localize  these  elements  I  performed  a  general  A* 
algorithm (Futó, I., 1999). This classical algorithm finds 
the  shortest  path  from  the  predefined  start  node  of  the 
graph to a goal node. Start node of the graph in our case 
is the actual position of the robot. The A* algorithm then 
calculates the shortest path from the actual position to a 
node where exploration could be fruitful. 
Using the shortest path as a list to be processed, the robot 
can  turn  to  the  next  node  of  the  graph  in  the  list  and 
move directly ahead while it does not reach the last node 
in the list. 
Besides  the  topological  graph  and  the  A*  algorithm  the 
final  robot  movement  is  comprised  another  behaviour 
pattern as well. The role of this normal move module is 
to stimulate the robot straight ahead “en plaine air”, and 
it  also  ensures  obstacle  avoidance  motion  in  case  of 
necessity.  Since  the  generation  of  the  topological  graph 
is  time-consuming,  this  job  is  not  done  continuously. 
When  the  normal  move  module  does  not  explore 
efficiently, in other words the explored surface does not 
grow  enough,  creation  of  the  graph  takes  place  and 
navigation  is  governed  by  the  A*  algorithm.  This 

alternating  comportment  incorporates  the  advantages  of 
the two behaviour modules. 

4. Results 

During  our  research  I  created  a  topological  navigation 
method  based  on  occupancy  grid  in  the  simulation 
environment of Webots. Using topological graph instead 
of  value  iteration  for  the  determination  of  exploration 
direction  seems  to  be  a  beneficial  modification.  On  one 
hand it approximates better the nature of the navigation. 
On the other hand the new algorithm performs better. 
The  two  evolved  robot  controllers  were  tested  in  five 
different  environments  in  several  experiments  from 
various  starting  points.  The  environments  were  selected 
to  cover  a  wide  range  of  possible  situation  that  could 
arise during map-building. 
The terrains were the following: an open area with some 
round  obstacles,  a  radial  maze  taken  from  Csányi,  V., 
1994, well-known in cognitive map researches (Fig. 1.), 
a maze, an office-like room which was one of the fields 
of  the  Artificial  Life  Creators  Contest,  and  a  labyrinth 
used  at  the  1994  AAAI  autonomous  mobile  robot 
competition (Fig. 2., Thrun, S., 1998). 
The open area is 1 m2, the AAAI maze is 1.85 m2, while 
the others are 2.25 m2. Five attempts were performed in 
every field with both algorithm. The robot could explore 
all the environments by the two methods.  
In  the  small  and  easily  solvable  open  area  the  robot 
spends  8  and  6.4  minutes  on  an  average  in  robot 
performance  time  using  value  iteration  and  topological 
graph  respectively.  Radial  maze  does  not  cause  any 
difficulties for the two programs, both solve it in around 
6 minutes on an average. 
The  most  significant  advance  can  be  reached  in  the 
office  environment:  the  20  minutes  time  drops  to  12.4 
minutes.  In  the  maze  the  time  profit  is  smaller:  the  22 
minutes  of  value  iteration  is  reduced  to  14.5  minutes. 
The  AAAI  contest  environment  is  easier  to  solve  than 
the maze, hence time frames of value iteration and graph 
navigation are 14 and 11.7 respectively. 
These results are collected in Table 1. 
The  acceleration  between 
is  a 
consequence  of  the  smaller  number  of  entities  with 
which the algorithms have to deal (Table 2.).  

two  methods 

the 

Value 
(min) 
8 
6.3 
20 
22 
14 

Open room 
Radial 
Office 
Maze 
AAAI 
contest 

iteration 

Topological 
 graph (min) 
6.4 
6 
12.4 
14.5 
11.7 

Table 1. Time comparison of the navigation methods 

There  are  between  11600  and  28900  pixels  in  the  cost 
matrix  of  the  value  iteration,  and  the  number  of  graph 

205 

 
 
 
 
 
 
 
 
 
 
nodes  are  between  20  and  120,  depending  on  the  size 
and the complexity of the environment. 

iteration 

Value 
(pixels) 

Open room 
Radial 
Office 
Maze 
AAAI contest 

12800 
11600 
28900 
28900 
23700 

Topological 
 graph (nodes) 
50 
20 
110 
120 
105 

from: 
citeseer.ist.psu.edu/borenstein95correction.html 
Borgefors,  G.  (1986).  Distance  Transformations  in 
Digital  Images.  Computer  Vision,  Graphics,  and 
Image Processing, Vol. 34., pp. 344-371.  

http:// 

Csányi,  V.  (1994).  Etológia,  Nemzeti  Tankönyvkiadó 

Rt., Budapest, Hungary 

Elfes,  A.  (1989).  Using  Occupancy  Grids  for  Mobile 
Robot  Perception  and  Navigation,  Computer,  Vol. 
22. No. 6., pp. 46-57. 

Futó,  I.  (1999).  Mesterséges  intelligencia,  Aula  Kiadó, 

Table 2. Number of entities in the navigation methods 

Budapest, Hungary 

5. Conclusions 

This  paper  presents  a  method  to  build  a  topological 
graph  for  navigation  based  on  occupancy  grid.  Besides 
the  fact  that  already  known  algorithms  are  used, 
significantly  better  accomplishments  related  to  the  pure 
occupancy grid method justify this navigation approach. 
On one hand the number of manipulated entities —pixels 
for  the  value  iteration,  and  graph  nodes  for  the 
topological  navigation  —  differ  in  the  two  approaches. 
This  gap  is  more  than  two  orders  of  magnitude,  so  the 
graph  navigation  dramatically  reduces  the  need  for 
resources, especially the need for memory. 
On  the  other  hand  better  total  exploration  time  can  be 
achieved  with  the  newer  control  procedure.  Differences 
in the acceleration among various test fields follow from 
the fact that the graph mostly helps in elongated parts of 
the  territory  and  at  the  connections  of  the  large  spaces. 
Open  spaces  are  easily  explorable  by  random  obstacle 
avoidance  so  the  necessary  time  for  open  room  and 
radial  maze  is  not  diminished  essentially. For the maze, 
the office, and the AAAI contest environment the effects 
are easily recognizable, since time profit exceeds 20%. 

6. Future work 

There  are  quite  many  different  ways  of  continuing  the 
research. Some of them are mentioned below: 
•  Testing the algorithms in real robot. 
•  Higher level task can be performed by the robot after 

successful exploration. 

•  Moving around in dynamic environments is a serious 
challenge,  this  extension  would  make  the  problem 
more interesting. 

•  Using  position  estimation  may  make  the  robot  fully 

• 

automate. 
Introduction  of  new  sensor  types  especially  video 
cameras  may  enhance  the  occupancy  grid  creation 
and position estimation as well. 

7. References 
Borenstein,  J.  &  Feng,  L.  (1995).  Correction  of 
in  mobile  robots, 
systematic  odometry  errors 
Proceedings 
International 
Conference on Robotics and Automation, Available 

IEEE 

1995 

of 

206 

Jain,  A.  K.  (1989).  Fundamentals  of  Image  Processing, 

Prentice-Hall, NJ 

Michel,  O. 

(2004).  Professional  Mobile  Robot 
Simulation,  International  Journal  of  Advanced 
Robotic  Systems,  Vol.  1.  No.  1.  pp.  39-42.  ISSN 
1729-8806 

Moravec,  H.  P.  &  Elfes,  A.    (1985).  High  resolution 
maps  from  wide  angle  sonar,  Proceedings  of  the 
IEEE  International  Conference  on  Robotics  and 
Automation, pp. 116-121., St. Louis, MO 

Rosin,  P.  L.  &  West,  G.  A.  (1989).  Segmentation  of 
Edges  into  Lines  and  Arcs,  Image  and  Vision 
Computing, Vol. 7. No. 2. pp. 109-114. 

Sutton, R. & Barto, A. (1998). Reinforcement Learning: 
An Introduction, Bradford Book, MIT Press  
Szabó,  R.  (2001).  Mobil  robotok  szimulációja,  Eötvös 

Kiadó, Budapest, Hungary 

Szabó, R. (2003). Navigation of simulated mobile robots 
in the Webots environment, Periodica Polytechnica 
- Electrical Engineering, 47/I-II. pp. 149-163. 
Tombre,  K.  &  Ah-Soon,  C.  &  Philippe  Dosch,  P.  & 
Masini,  G.  &  Tabbone,  S.  (2000).  Stable  and 
Robust  Vectorization:  How  to  Make  the  Right 
Choices,  Lecture  Notes  in  Computer  Science,  Vol. 
1941. pp. 3-17. 

Thrun, S. (1998). Learning Metric-Topological Maps for 
Indoor  Mobile  Robot  Navigation,  Artificial 
Intelligence, Vol. 99. No. 1. pp. 21-71. 

Thrun,  S.  (2000).  Probabilistic  Algorithms  in  Robotics, 

AI Magazine, Vol. 21. No. 4. pp. 93-109. 

Thrun,  S. 

(2002).  Robotic  Mapping:  A  Survey, 
Exploring  Artificial 
the  New 
Intelligence 
Millenium,  Lakemeyer,  G.  and  Nebel,  B.  (Ed.) 
Morgan Kaufmann 

in 

Wall,  K.  &  Danielsson,  P.-E.  (1984).  A  fast  sequential 
method for polygonal approximation of digitized curves, 
Computer Vision, Graphics and Image Processing, Vol. 
28. pp. 220-227.  

8. Acknowledgement 
The  author  wishes  to  thank  György  Kampis  for  his 
useful suggestions, and András Salamon for his valuable 
remarks."
Bionic Humans Using EAP as Artificial Muscles Reality and Challenges,"  For many years, the idea of a human with bionic muscles immediately conjures
up science fiction images of a TV series superhuman character that was
implanted with bionic muscles and portrayed with strength and speed far
superior to any normal human. As fantastic as this idea may seem, recent
developments in electroactive polymers (EAP) may one day make such bionics
possible. Polymers that exhibit large displacement in response to stimulation
that is other than electrical signal were known for many years. Initially, EAP
received relatively little attention due to their limited actuation capability.
However, in the recent years, the view of the EAP materials has changed due to
the introduction of effective new materials that significantly surpassed the
capability of the widely used piezoelectric polymer, PVDF. As this technology
continues to evolve, novel mechanisms that are biologically inspired are
expected to emerge. EAP materials can potentially provide actuation with
lifelike response and more flexible configurations. While further improvements
in performance and robustness are still needed, there already have been several
reported successes. In recognition of the need for cooperation in this
multidisciplinary field, the author initiated and organized a series of
international forums that are leading to a growing number of research and
development projects and to great advances in the field. In 1999, he challenged
the worldwide science and engineering community of EAP experts to develop a
robotic arm that is actuated by artificial muscles to win a wrestling match
against a human opponent. In this paper, the field of EAP as artificial muscles
will be reviewed covering the state of the art, the challenges and the vision
for the progress in future years.
",http://arxiv.org/pdf/cs/0411025v1,1,"BBIIOONNIICC  

Bionic Humans Using EAP as Artificial Muscles 
Reality and Challenges 

Yoseph Bar-Cohen 
Jet Propulsion Laboratory/Caltech 
4800 Oak Grove Drive, M/S 82-105, Pasadena, CA 91109, USA 
e-mail: yosi@jpl.nasa.gov   Web: http://ndeaa.jpl.nasa.gov 

For many years, the idea of a human with bionic muscles immediately conjures up science fiction images of 
a TV series superhuman character that was implanted with bionic muscles and portrayed with strength and 
speed  far  superior  to  any  normal  human.  As  fantastic  as  this  idea  may  seem,  recent  developments  in 
electroactive  polymers  (EAP)  may  one  day  make  such  bionics  possible.  Polymers  that  exhibit  large 
displacement  in  response  to  stimulation  that  is  other  than  electrical  signal  were  known  for  many  years. 
Initially,  EAP  received  relatively  little  attention  due  to  their  limited  actuation  capability.  However,  in  the 
recent years, the view of the EAP materials has changed due to the introduction of effective new materials 
that  significantly  surpassed  the  capability  of  the  widely  used  piezoelectric  polymer,  PVDF.  As  this 
technology  continues  to  evolve,  novel  mechanisms  that  are  biologically  inspired  are  expected  to  emerge. 
EAP  materials  can  potentially  provide  actuation  with  lifelike  response  and  more  flexible  configurations. 
While further improvements in performance and robustness are still needed, there already have been several 
reported  successes.  In  recognition  of  the  need  for  cooperation  in  this  multidisciplinary  field,  the  author 
initiated and organized a series of international forums that are leading to a growing number of research and 
development projects and to great advances in the field. In 1999, he challenged the worldwide science and 
engineering community of EAP experts to develop a robotic arm that is actuated by artificial muscles to win 
a  wrestling  match  against  a  human  opponent.  In  this  paper,  the  field  of  EAP  as  artificial  muscles  will  be 
reviewed covering the state of the art, the challenges and the vision for the progress in future years. 

1. Introduction 
As humans live longer there is a growing need for availability of organs for transplant however shortage in 
donations  necessitates  the  development  of  artificial  alternatives.    Advances  in  medicine  have  led  to  the 
availability  of  artificial  blood,  replacement  joints,  heart  valves,  and  heart-lung  machines  that  are  common 
implanted.  In the United States, nearly one in ten individuals is using some type of an implanted medical 
device [Malchesky, 2001].  Muscle is a critically needed organ and its availability in an artificial form for 
medical  use  can  greatly  contribute  to  the  improvement  of  the  quality  of  life  of  many  humans.      The 
emergence of effective electroactive polymers (EAP) that are also known as artificial muscles can potentially 
address  this  need.    These  materials  are  human  made  actuators  that  have  the  closest  operation  similarity  to 
biological muscles.   While these actuation materials are far from being ready for use as implants enormous 
progress  has  been  made  in  recent  years  turning  them  into  a  promising  technology  for  consideration  in 
medical applications.  Generally, these materials respond to electrical stimulation with a significant shape or 
size change and this characteristic behavior has added greatly to the list of desirable properties of polymer 
materials  [Bar-Cohen,  2004].    The  large  strain  response  of  EAP  materials  is  increasingly  attracting  the 
attention  of  engineers  and  scientists  from  many  different  disciplines  who  are  seeking  novel  applications. 
Experts in biomimetics are particularly excited about these materials since they can be applied to mimic the 
movement  of  biological  creatures  [Bar-Cohen  and  Breazeal,  2003;  and  Bar-Cohen,  2004].    Using  this 
capability, EAP actuated robotic mechanisms are enabling engineers to create devices that were previously 
only  imaginable  in  science  fiction.    One  such  commercial  product  has  already  emerged  in  Dec.  2002  is  a 
form of a Fish-Robot (Eamex, Japan) [http://www.eamex.co.jp/video/fish.wmv].  It swims without batteries 
or a motor and it uses EAP materials that simply bend upon stimulation.  For power it uses inductive coils 

217 

 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
is 

that are energized from the top and bottom of the fish tank.  This fish represents a major milestone for the 
field, as it is the first reported commercial product to use electroactive polymer actuators.  
For  several  decades,  it  has  been  known  that  certain  types  of  polymers  can  change  shape  in  response  to 
electrical stimulation.  Initially, these EAP materials produced a relatively small strain.  Since the beginning 
of the 1990s, a growing number of new EAP materials are emerging with a large strain response to electrical 
stimulation [Bar-Cohen, 2004].  The materials that have emerged were divided by the author into two major 
groups, including ionic and electronic EAP.  Each of the groups and individual type of EAP materials has its 
advantages and disadvantages that need to be taken into account when considering applications. 
In recognition of the need for international cooperation among the developers, users, and potential sponsors, 
the author organized the first EAP Conference on March 1-2, 1999, through SPIE International [Bar-Cohen, 
1999].  This conference and was the largest ever on this subject, marking an important milestone and turning 
the spotlight onto these emerging materials and their potential.  This SPIE ElectroActive Polymer Actuators 
and Devices (EAPAD) Conference is now organized annually and has been steadily growing in number of 
presentations  and  attendees.        Currently,  there  is  a  website  that  archives  related  information  and  links  to 
homepages  of  EAP  research  and  development  facilities  worldwide  [http://eap.jpl.nasa.gov],  and  a  semi-
annual  Newsletter 
issued  electronically  [http://ndeaa.jpl.nasa.gov/nasa-nde/lommas/eap/WW-EAP-
Newsletter.html].    Further,  the  author  edited  and  coauthored  a  reference  book  on  EAP  that  has  been 
published in [Bar-Cohen, 2001] where its 2nd edition was published in March 2004 [Bar-Cohen, 2004].  This 
book  [http://ndeaa.jpl.nasa.gov/nasa-nde/yosi/yosi-books.htm]  provides  a  comprehensive  documented 
reference, technology user’s guide, and tutorial resource, with a vision for the future direction of this field.  It 
covers the field of EAP from all its key aspects, i.e., its full infrastructure, including the available materials, 
analytical models, processing techniques, and characterization methods. 
In  1999,  in  an  effort  to  promote  worldwide  development  towards  the  realization  of  the  potential  of  EAP 
materials the author posed an armwrestling challenge.  A graphic rendering of this challenge is illustrated in 
Figure 1.  In posing this challenge, the author sought to see an EAP activated robotic arm win against human 
in  a  wrestling  match  to  establish  a  baseline  for  the  implementation  of  the  advances  in  the  development  of 
these materials.   While such a challenge was intended to jump-start the research activity in this field, success 
in wrestling against humans will enable capabilities that are currently considered impossible.  It would allow 
applying EAP materials to improve many aspects of our life where some of the possibilities include effective 
implants  and  smart  prosthetics,  active  clothing,  realistic  biologically  inspired  robots  and  the  fabrication  of 
products with unmatched capabilities and dexterity.  Decades from now one, can expect to see EAP materials 
used  to  replace  damaged  human  muscles,  i.e.,  making  ""bionic  human.""    A  remarkable  contribution  of  the 
EAP field would be to see one day a handicapped person jogging to the grocery store using this technology.  
Recent advances in understanding the behavior of EAP materials and the improvement of their efficiency led 
to the point that the first armwrestling competition is planned for March 7, 2005 during the EAP-in-Action 
Session  of  the  EAPAD  Conference  where  three  organizations  (listed  by  order  of  announcement)  have 
already stated their readiness for this competition: 

1.  SRI  International,  Menlo  Park,  CA,  USA  (Currently 
seeking  the  necessary  funds  to  develop  the  required  arm 
in order to compete) 
2.  Environmental 
Albuquerque, New Mexico, USA 
3.  Swiss Federal Laboratories for Materials Testing and 
Research, EMPA, Dubendorf, Switzerland. 

Incorporated 

Robots 

(ERI), 

2. Nature as a Biologically-Inspiring Model 
Evolution  over  millions  of  years  made  nature  introduce 
solutions  that  are  highly  power-efficient  and  imitating 
them  offers  potential  improvements  of  our  life  and  the 
tools  we  use.    Human  desire  and  capability  to  imitate 
nature and particularly biology has continuously evolved 
and  with  the  improvement  in  technology  more  difficult 
challenges  are  being  considered.    Imitation  of  biology 
may  not  be  the  most  effective  approach  to  engineering 
is 
mechanisms  using  man-made  capabilities. 

It 

Fig. 1. Grand challenge for the development  
of EAP actuated robotics 

218 

 
 
 
inconceivable  to  imaging  flying  with  a  machine  that  has  feathers  and  flapping  wings,  where  obviously  a 
machine like that will not allow us to reach the distances and carry the loads that aircraft are doing today.   
The introduction of the wheel has been one of the most important inventions that human made allowing to 
travel great distances and perform tasks that would have been otherwise impossible within the life time of a 
single human being.  While wheel based locomotion mechanisms allow reaching great distances and speeds, 
wheeled vehicles are subjected to great limitations with regards to traversing complex terrain with obstacles.  
Obviously,  legged  creatures  can  perform  numerous  functions  that  are  far  beyond  the  capability  of  an 
automobile.    Producing  legged  robots  is  increasingly  becoming  an  objective  for  robotic  developers  and 
considerations of using such robots for space applications are currently underway.  Making miniature devices 
that  can  fly  like  a  dragonfly;  adhere  to  walls  like  gecko;  adapt  the  texture,  patterns,  and  shape  of  the 
surrounding as the octopus (can reconfigure its body to pass thru very narrow tubing); process complex 3D 
images  in  real  time;  recycle  mobility  power  for  highly  efficient  operation  and  locomotion;  self-replicate; 
self-grow using surrounding resources; chemically generate and store energy; and many other capabilities are 
some of the areas that biology offers as a model for science and engineering inspiration.  While many aspects 
of biology are still beyond our understanding and capability, significant progress has been made and the field 
of biomimetics is continuing to evolve [Bar-Cohen and Breazeal, 2003].   
The  evolution  in  the  capabilities  that  are  inspired  by  biology  has  increased  to  a  level  where  more 
sophisticated and demanding fields, such as space science, are considering the use of such robots.  At JPL, 
four and six legged robots are currently being developed for consideration in future missions to such planets 
as  Mars.    Such  robots  include  the  LEMUR  (Limbed  Excursion Mobile  Utility  Robot).    This  type  of  robot 
would potentially perform mobility in complex terrains, perform sample acquisition and analysis, and many 
other  functions  that  are  attributed  to  legged  animals  including  grasping  and  object  manipulation.    This 
evolution may potentially lead to the use of life-like robots in future NASA missions that involve landing on 
various  to  planets.    The  details  of  such  future  missions  will  be  designed  as  a  plot,  commonly  used  in 
entertainment shows rather than conventional mission plans of a rover moving in a terrain and performing 
simple autonomous tasks.  Equipped with multi-functional tools and multiple cameras, the LEMUR robots 
are intended to inspect and maintain installations beyond humanity's easy reach in space.  This spider looking 
robot has 6 legs, each of which has interchangeable end-effectors to perform the required mission. The axis-
symmetric layout is a lot  like a  starfish or octopus,  and it has a  panning camera  system that allows omni-
directional movement and manipulation operations.      

3. EAP as Artificial Muscles 
One  of  the  key  aspects  of  driving  mechanisms  that  emulate  biology  is  the  development  of  actuators  that 
mimic  the  capability  of  biological  muscles.  The  potential  for  such  actuators  is  continuously  growing  as 
advances are being made leading to more effective electroactive polymers (EAP) [Bar-Cohen, 2004].  These 
materials  have  functional  similarities  to  biological  muscles,  including  resilience,  quiet  operation,  damage 
tolerance, and large actuation strains (stretching, contracting or bending).  They can potentially provide more 
lifelike  aesthetics,  vibration  and  shock  dampening,  and  more  flexible  actuator  configurations.    These 
materials can be used to make mechanical devices and robots with no traditional components like gears, and 
bearings,  which  are  responsible  to  their  high  costs,  weight  and  premature  failures.    Also,  they  could 
potentially be used as artificial organ to assist or operate the heart and/or its valve, the eye lid and/move the 
eyeball as well as control the focal length of its length, and allow mobility of the legs and/or hand as well as 
provide smart prosthetics (also known as cyborgs).  As an example of a capability of EAP materials that is 
inspired by biology, the author and his JPL’s NDEAA team developed a miniature robotic arm.  This robotic 
arm illustrates some of the unique capabilities of EAP, where its gripper consists of four EAP fingers (made 
by  Ionic  polymer  metal  composite  strips)  with  hooks  at  the  bottom  emulating  fingernails.    This  arm  was 
made to grab rocks similar to human hand.  
The beginning of the field of EAP can be traced back to an 1880 experiment that was conducted by Roentgen 
using a rubber-band with fixed end and a mass attached to the free-end, which was charged and discharged 
[Roentgen, 1880].  Generally, there are many polymers that exhibit volume or shape change in response to 
perturbation  of  the  balance  between  repulsive  intermolecular  forces,  which  act  to  expand  the  polymer 
network, and attractive forces that act to shrink it.  Repulsive forces are usually electrostatic or hydrophobic 
in  nature,  whereas  attraction  is  mediated  by  hydrogen  bonding  or  van  der  Waals  interactions.    The 
competition between these counteracting forces, and hence the volume or shape change, can be controlled by 
subtle  changes  in  parameters  such  as  solvent,  gel  composition,  temperature,  pH,  light,  etc.  The  type  of 

219 

 
 
polymers  that  can  be  activated  by  non-electrical  means  include:  chemically  activated,  shape  memory 
polymers,  inflatable  structures,  including  McKibben  Muscle,  light  activated  polymers,  magnetically 
activated polymers, and thermally activated gels [Chapter 1 in Bar-Cohen, 2004]. 
Polymers  that  are  chemically  stimulated  were  discovered  over  half-a-century  ago  when  collagen  filaments 
were  demonstrated  to  reversibly  contract  or  expand  when  dipped  in  acid  or  alkali  aqueous  solutions, 
respectively [Katchalsky, 1949].  Even though relatively little has since been done to exploit such ‘chemo-
mechanical’  actuators,  this  early  work  pioneered  the  development  of  synthetic  polymers  that  mimic 
biological muscles.  The convenience and practicality of electrical stimulation and technology progress led to 
a growing interest in EAP materials.  Following the 1969 observation of a substantial piezoelectric activity in 
PVF2 [http://www.ndt.net/article/yosi/yosi.htm], investigators started to examine other polymer systems, and 
a  series  of  effective  materials  have  emerged.    The  largest  progress  in  EAP  materials  development  has 
occurred  in  the  last  ten  years  where  effective  materials  that  can  induce  up  to  380%  strain  have  emerged 
[Kornbluh and Pelrine, 2004].  
EAP  can  be  divided  into  two  major  categories  based  on  their  activation  mechanism  including  ionic  and 
electronic.  The electronic EAP are driven by Coulomb forces and they include: Dielectric EAP (shown in 
Fig.  2a),  Electrostrictive  Graft  Elastomers,  Electrostrictive  Paper,  Electro-Viscoelastic  Elastomers, 
Ferroelectric Polymers and Liquid Crystal Elastomers (LCE).  This type of EAP materials can be made to 
hold  the  induced  displacement  while  activated  under  a  DC  voltage,  allowing  them  to  be  considered  for 
robotic applications.  These materials have a greater mechanical energy density and they can be operated in 
air with no major constraints.  However, the electronic EAP require a high activation fields (>30-V/µm) that 
may be close to the breakdown level.  In contrast to the electronic EAP, ionic EAP are materials that involve 
mobility  or  diffusion  of  ions  and  they  consist  of  two  electrodes  and  an  electrolyte.    The  activation  of  the 
ionic EAP can be made by as low as 1-2 Volts and mostly a bending displacement is induced.   The ionic 
EAP include Carbon Nanotubes (CNT), Conductive Polymers (CP), ElectroRheological Fluids (ERF), Ionic 
Polymer Gels (IPG), Ionic Polymer Metallic Composite (IPMC) (shown in Fig. 2b).  Their disadvantages are 
the need to maintain wetness and they pose difficulties to sustain constant displacement under activation of a 
DC voltage (except for conductive polymers).   

a. Dielectric EAP in relaxed (top) and 
activated states (bottom) 
Fig. 2. Examples of EAP materials in relaxed and activated states. 

b. IPMC in relaxed (left) and activated states (right) 

The induced displacement of both the electronic and ionic EAP materials can be designed geometrically to 
bend, stretch or contract.  Any of the existing EAP materials can be made to bend with a significant bending 
response,  offering  an  actuator  with  an  easy  to  see  reaction.    However,  bending  actuators  have  relatively 
limited applications due to the low force or torque that can be induced.  One important question, which has 
been asked by new users or researchers/engineers who are comers to this field, is the need to know where 
they can get these materials.  This issue of unavailability of commercial EAP materials is dampening the rate 
of progress in the field of EAP.  To help potential users, the author has established a website that describes 
how  to  make  the  various  EAP  materials  [http://ndeaa.jpl.nasa.gov/nasa-nde/lommas/eap/EAP-recipe.htm].  
Further, the author compiled inputs from companies that make EAP materials, prototype devices or provide 

220 

 
                    
 
 
EAP related processes and services.  The inputs were compiled into a handy table that is posted on one of the 
links of the WW-EAP webhub: http://ndeaa.jpl.nasa.gov/nasa-nde/lommas/eap/EAP-material-n-products.htm 

4. Making Robots Actuated by EAP 
With today’s technology one can quite well graphically animate the appearance and behavior of biological 
creatures.  However, in past years, engineering such biomimetic intelligent creatures as realistic robots was a 
significant  challenge  due  to  the  physical  and  technological  constraints  and  shortcomings  of  existing 
technology.  Making such robots that can hop and land safely without risking damage to the mechanism, or 
making body and facial expression of joy and excitement are very easy tasks for human and animals to do 
but extremely complex to engineer.  The use of artificial intelligence, effective artificial muscles and other 
biomimetic  technologies  are  expected  to  make  the  possibility  of  realistically  looking  and  behaving  robots 
into more practical engineering models [Bar-Cohen and Breazeal, 2003].   
To  promote  the  development  of  effective  EAP  actuators,  which  could  impact  future  robotics,  toys  and 
animatronics, two test-bed platforms were developed.  These platforms are available at the Principal author’s 
lab  at  JPL  and  they  include  an  Android  head  that  can  make  facial  expressions  and  a  robotic  hand  with 
activatable joints.  At present, conventional electric motors are producing the required deformations to make 
relevant facial expressions of the Android.  Once effective EAP materials are chosen, they will be modeled 
into the control system in terms of surface shape modifications and control instructions for the creation of the 
desired facial expressions.  Further, the robotic hand is equipped with tandems and sensors for the operation 
of  the  various  joints  mimicking  human  hand.    The  index  finger  of  this  hand  is  currently  being  driven  by 
conventional  motors  in  order  to  establish  a  baseline  and  they  would  be  substituted  by  EAP  when  such 
materials are developed as effective actuators. 
The growing availability of EAP materials that exhibit high actuation displacements  and forces is opening 
new avenues to bioengineering in terms of medical devices and assistance to humans in overcoming different 
forms  of  disability.  Areas  that  are  being  considered  include  an  angioplasty  steering  mechanism,  and 
rehabilitation robotics.  For the latter, exoskeleton structures are being considered to augment the mobility 
and functionalities of patients with weak muscles.   

5. Challenges to Developing EAP Materials as Artificial Organs 
As polymers, EAP materials can be easily formed in various shapes, their properties can be engineered and 
they can potentially be integrated with micro-electro-mechanical-system (MEMS) sensors to produce smart 
actuators.  As mentioned earlier, the most attractive feature of EAP materials is their ability to emulate the 
operation  of  biological  muscles  with  high  fracture  toughness,  large  actuation  strain  and  inherent  vibration 
damping.  Unfortunately, the  materials that have been developed so far are still exhibiting low conversion 
efficiency,  are  not  robust,  and  there  are  no  standard  commercial  materials  available  for  consideration  in 
practical applications.  In order to be able to take these materials from the development phase to application 
as  effective  actuators,  there  is  a  need  to  establish  adequate  EAP  infrastructure.    Effectively  addressing the 
requirements of the EAP infrastructure involves understanding and analytically model the (cid:31)ehaviour of EAP 
materials, as well as developing effective processing and characterization techniques.   
If one considers the use of EAP as artificial organs there are challenges that need to be addressed that are 
common  to  the  use  of  any  foreign  objects  as  implants  in  the  human  body.    Such  issues  include  biological 
compatibility  and  avoiding  rejection,  chemically  safe  use,  and  ability  to  meet  the  stringent  functional 
requirements to operate as a replacement organ.  Some of the issues related to the use of EAP as artificial 
organs include the fact that the electronic EAP group requires high voltage.  At present, the materials in this 
group have the highest robustness and they induce the largest actuation forces however the required voltages 
in the range from hundreds to thousands of voltage is a concern that must be addressed.  Even though the 
electric current is relatively low, the use of such voltage levels can cause such dangers as inducing blood clot 
or  injury  due  to  potential  voltage  breakdown.    On  the  other  hand,  the  ionic  group  of  EAP  materials  is 
chemically  sensitive  and  requires  careful  protection,  further,  it  is  difficult  to  maintain  a  static  position 
because of the fact that these materials involve chemical reaction and even DC voltage causes a reaction.  
Interfacing  between  human  and  machine  to  complement  or  substitute  our  senses  may  enable  important 
capabilities  for  medical  applications.    A  number  of  such  interfaces,  with  some  that  employ  EAP,  were 
investigated  or  have  been  considered.  Of  notable  significance  is  the  ability  to  interface  machines  and  the 
human  brain  [Wessberg  et  al.,  2000  and  Mussa-Ivaldi,  2000].  A  development  by  scientists  at  Duke 
University  enabled  this  possibility  where  electrodes  were  connected  to  the  brain  of  a  monkey,  and,  using 

221 

 
 
 
brain waves, the monkey operated a robotic arm, both locally and remotely via the internet. It is envisioned 
that success in developing EAP actuated robotic arms that can win a wrestling match with human opponent 
can  greatly  benefit  from  this  development  by  neurologists.    Using  such  a  capability  to  control  prosthetics 
would  require  feedback  to  allow  the  human  operator  to  “feel”  the  environment  around  the  artificial  limbs. 
Such feedback can be provided with the aid of tactile sensors, haptic devices, and other interfaces.  Besides 
providing  feedback,  sensors  will  be  needed  to  allow  the  users  to  monitor  the  prosthetics  from  potential 
damage (heat, pressure, impact, etc.) just as we are doing with biological limbs.  The development of EAP 
materials that can provide tactile sensing is currently under way as described in [Bar-Cohen, 2004].   

6. Summary and Outlook 
Using effective EAP actuators to mimic nature would immensely expand the collection and functionality of 
the  actuators  that  are  currently  available  as  well  as  enable  making  artificial  organs.    The  prospect  of 
developing technology that would enable making “bionic” humans with artificial muscles as science fiction 
TV  series  superhuman  character  is  becoming  increasingly  feasible  as  the  field  of  EAP  progresses.    These 
man-made  materials  operate  as  actuators  with  the  closest  functional  similarity  to  biological  muscles 
including resilience, quiet operation, damage tolerance, and large actuation strains (stretching, contracting or 
bending).  This similarity has earned EAP the moniker Artificial Muscle and they may be used to eliminate 
the need for gears, bearings, and other components that complicate the construction of actuated mechanisms 
and are responsible to high costs, weight and premature failures.  Visco-elastic EAP materials can provide 
more lifelike aesthetics, vibration and shock dampening, and more flexible actuator configurations.   
Electroactive  polymers  can  potentially  enable  bioengineering  of  medical  applications  that  are  considered 
impossible  with  today’s  technology.    Important  addition  to  this  capability  can  be  the  application  of 
telepresence combined with virtual reality using haptic interfaces.   As the technology progresses, it is more 
realistic to expect that biomimetic prosthetics will become commonplace in our future environment.  As we 
are inspired by biology to make more intelligent biomimetics to improve our lives we will increasingly find 
challenges  to  such  implementations.    The  author’s arm-wrestling  challenge  having  a  match  between  EAP-
actuated robots and a human opponent highlights the potential of this technology.   

7. Acknowledgement 
Research  reported  in  this  manuscript  was  conducted  at  the  Jet  Propulsion  Laboratory  (JPL),  California 
Institute of Technology, under a contract with National Aeronautics and Space Administration (NASA).   

8. References 

Bar-Cohen Y. (Ed.), Proceedings of the SPIE’s Electroactive Polymer Actuators and Devices (EAPAD) Conf., 6th 

Smart Structures and Materials Symposium, Volume 3669, ISBN 0-8194-3143-5, (1999), pp. 1-414. 

Bar-Cohen Y. (Ed.), ""Automation, Miniature Robotics and Sensors for Nondestructive Evaluation and Testing,"" 
Volume 4 of the Topics on NDE (TONE) Series, American Society for Nondestructive Testing, Columbus, 
OH, ISBN 1-57117-043 (2000), pp.1-481. 

Bar-Cohen Y., and C. Breazeal (Eds), “Biologically-Inspired Intelligent Robots,” SPIE Press, Vol. PM122, ISBN 

0-8194-4872-9 (May 2003), pp. 1-393.   

Bar-Cohen  Y.  (Ed.),  “Electroactive  Polymer  (EAP)  Actuators  as  Artificial  Muscles  -  Reality,  Potential  and 

Challenges,” ISBN 0-8194-4054-X, SPIE Press, Vol. PM98, (March 2001), pp. 1-671   

Bar-Cohen,  ibid,  2nd  Edition,  ISBN  0-8194-5297-1,  SPIE  Press,  Vol.  PM136,  (March  2004),  pp.  1-765 

http://ndeaa.jpl.nasa.gov/nasa-nde/yosi/yosi-books.htm 

Katchalsky, A., “Rapid Swelling and Deswelling of Reversible Gels of Polymeric Acids by Ionization”, 
Experientia, Vol. V, (1949), pp 319-320.Kornbluh R. and R. Pelrine, “Application of Dielectric EAP 
Actuators,” Chapter 16 in [Bar-Cohen, 2001], pp. 457-495. 

Malchesky P.S., “Artificial organs and vanishing boundaries,” Artif. Organs, 25, (2001) pp. 75-88. 
Mussa-Ivaldi S., “Real brains for real robots,” Nature, Vol. 408, (16 November 2000), pp. 305-306.  
Roentgen, W.C. , “About the changes in shape and volume of dielectrics caused by electricity,” Section III in G. 
Wiedemann (Ed.), Annual Physics and Chemistry Series, Vol. 11, John Ambrosius Barth Publisher, Leipzig, 
German (1880) pp. 771-786,.(In German) 

Wessberg J., C. R. Stambaugh, J. D. Kralik, P. D. Beck, M. Lauback, J.C. Chapin, J. Kim, S. J. Biggs, M. A. 

Srinivasan and M. A. Nicolelis, “Real-time prediction of hard trajectory by ensembles of cortical neurons in 
primates,” Nature, Vol. 408, (16 November 2000), pp. 361-365. 

222"
Neural Networks in Mobile Robot Motion,"  This paper deals with a path planning and intelligent control of an
autonomous robot which should move safely in partially structured environment.
This environment may involve any number of obstacles of arbitrary shape and
size; some of them are allowed to move. We describe our approach to solving the
motion-planning problem in mobile robot control using neural networks-based
technique. Our method of the construction of a collision-free path for moving
robot among obstacles is based on two neural networks. The first neural network
is used to determine the ""free"" space using ultrasound range finder data. The
second neural network ""finds"" a safe direction for the next robot section of
the path in the workspace while avoiding the nearest obstacles. Simulation
examples of generated path with proposed techniques will be presented.
",http://arxiv.org/pdf/cs/0412049v1,1,"Janglová, D. / Neural Networks in Mobile Robot Motion, pp. 15-22, Inernational Journal of Advanced Robotic Systems, 
Volume 1 Number 1 (2004), ISSN 1729-8806 

Neural Networks in Mobile Robot Motion 

Danica Janglová 
Institute of Informatics SAS, danica.janglova@savba.sk 

Abstract:  This  paper  deals  with  a  path  planning  and  intelligent  control  of  an  autonomous  robot  which  should  move 
safely in partially structured environment. This environment may involve any number of obstacles of arbitrary shape 
and  size;  some  of  them  are  allowed  to  move.  We  describe  our  approach  to  solving  the  motion-planning  problem  in 
mobile robot control using neural networks-based technique. Our method of the construction of a collision-free path for 
moving  robot  among  obstacles  is  based  on  two  neural  networks.  The  first  neural  network  is  used  to  determine  the 
“free” space using ultrasound range finder data. The second neural network “finds” a safe direction for the next robot 
section of the path in the workspace while avoiding the nearest obstacles. Simulation examples of generated path with 
proposed techniques will be presented.  
Keywords:  Mobile Robot, Neural Network, Ultrasound Range Finder, Path Planning, Navigation  

1.  Introduction  

Over  the  last  few  years,  a  number  of  studies  were 
reported  concerning  a  machine  learning,  and  how  it  has 
been  applied  to  help  mobile  robots  to  improve  their 
operational capabilities. One of the most important issues 
in  the  design  and  development  of  intelligent  mobile 
system  is  the  navigation  problem.  This  consists  of  the 
ability  of  a  mobile  robot  to  plan  and  execute  collision-
free  motions  within  its  environment.  However,  this 
environment  may  be  imprecise,  vast,  dynamical  and 
either partially or non-structured. Robots must be able to 
understand  the  structure  of  this  environment.  To  reach 
their  targets  without  collisions,  the  robots  must  be 
endowed  with  perception,  data  processing,  recognition, 
learning,  reasoning,  interpreting,  decision-making  and 
action capacities. The ability to acquire these faculties to 
treat  and  transmit  knowledge  constitutes  the  key  of  a 
certain kind of artificial intelligence. Reproduce this kind 
of  intelligence  is,  up  to  now,  a  human  ambition  in  the 
construction  and  development  of  intelligent  machines, 
and  particularly  autonomous  mobile  robots.  To  reach  a 
reasonable  degree  of  autonomy  two  basic  requirements 
are sensing and reasoning. The former is provided by on-
board  sensory  system  that  gathers  information  about 
robot with respect to the surrounding scene. The later is 
accomplished  by  devising    algorithms    that  exploit  this 
information in order to generate appropriate commands 
for  robot.  And  with  this  algorithm  we  will  deal  in  this 
paper. 
We  report  on  the  objective  of  the  motion  planning 
problem well known in robotics. Given an object with an 

is 

initial  location  and  orientation,  a  goal  location  and 
orientation,  and  a  set  of obstacles  located  in  workspace, 
the problem is to find a continuous path from the initial 
position to the goal position, which avoids collisions with 
obstacles  along  the  way.  In  other  words,  the  motion 
planning  problem  is  divided  into  two  sub-problems, 
called  ‘Findspace’  and  ‘Findpath’  problem.  For  related 
approaches to the motion planning problem see reference 
(Latombe,    J.C.    1991).  The  findspace  problem  is 
construction  the  configuration  space  of  a  given  object 
and  some  obstacles.  The  findpath  problem 
in 
determining  a  collision-free  path  from  a  given  start 
location  to  a goal  location for  a  robot. Various  methods 
for  representing  the  configuration  space  have  been 
proposed to solve the findpath problem (Brady, M. & all 
1982),  (Latombe,    J.C.    1991),  (Vörös,  J.  2002).  The 
major  difficulties  in  the  configuration  space  approach 
are:  expensive  computation  is  required  to  create  the 
configuration  space  from  the  robot  shape  and  the 
obstacles  and  the  number  of  searching  steps  increases 
exponentially with the number of nodes. Thus, there is a 
motivation  to  investigate  the  use  of  parallel  algorithms 
for  solving  these  problems,  which  has  the  potential  for 
much  increased  speed  of  calculations.  A  neural network 
is  a  massive  system  of  parallel  distributed  processing 
elements  connected 
topology.  Several 
in  a  graph 
researchers have tried to use neural networks techniques 
for solving the find  
path problem (Bekey, G.A. & Goldberg, K.Y., 1993).  
In  this  paper  we  introduce  a  neural  networks-based 
approach for planning collision-free paths among known 
stationary obstacles in structured environment for a robot 

15 

 
in 

two-dimensional  object 

with  translational  and  rotational  motion.  Our  approach 
basically  consists  of  two  neural  networks  to  solve  the 
findspace  and  findpath  problems  respectively.  The  first 
neural  network  is  a  modified  principal  component 
analysis  network,  which  is  used  to  determine  the  “free 
space” from  ultrasound range  finder  data. Moving robot 
is  modeled  as  a 
this 
workspace.  The  second  one  is  a  multilayer  perceptron, 
which  is  used  to  find  a  safe  direction  for  the  next  robot 
step on the collision-free path in the workspace from start 
configuration to a goal configuration while avoiding the 
obstacles. 
The  organization  of  the  paper  is  as  follows:  section  2 
brings  out  the  briefly  description  of  neural  network 
applications  in  robotics.  Our  approach  to  solving  the 
robot motion problem is given in section 3. Our method 
of motion planning strategy, which depends in using two 
neural  networks  for  solving  the  findspace  problem  and 
the  findpath  problem  respectively  will  be  described  in 
section  4.  Simulation  results  will  be  included  in  section 
5.  Section  6  will  summarize  our  conclusions  and  gives 
the notes for our further research in this area.  

2.  Neural networks in robotics 

such 

tasks 

learning, 

The  interest  in  neural  network  stems  from  the  wish  of 
understanding  principles  leading  in  some  manner  to  the 
comprehension  of  the  basic  human  brain  functions,  and 
to  building  the  machines  that  are  able  to  perform 
complex  tasks.  Essentially,  neural  network  deal  with 
cognitive 
adaptation, 
as 
generalization  and  optimization.  Indeed,  recognition, 
learning,  decision-making  and  action  constitute  the 
principal navigation problems.  To solve these problems 
fuzzy logic and neural networks are used. They improve 
to 
learning  and  adaptation  capabilities  related 
the 
variations  in  the  environment  where  information  is 
qualitative,  inaccurate,  uncertain  or  incomplete.  The 
processing  of  imprecise  or  noisy  data  by  the  neural 
networks  is  more  efficient  than  classical  techniques 
because neural networks are highly tolerant to noises.  
A  neural  network  is  a  massive  system  of  parallel 
distributed processing elements (neurons) connected in a 
graph  topology.  Learning  in  the  neural  network  can  be 
supervised  or  unsupervised.  Supervised  learning  uses 
information,  while  unsupervised 
classified  pattern 
learning  uses  only  minimum 
information  without 
preclassification. Unsupervised learning algorithms offer 
less  computational  complexity  and  less  accuracy  than 
supervised 
learn 
rapidly, often on a single pass of noisy data. The neural 
network  could  express  the  knowledge  implicitly  in  the 
weights,  after  learning.  A  mathematical  expression  of  a 
widely  accepted  approximation  of  the  Hebbian  learning 
rule is  

learning  algorithms.  Then  former 

tw
(
ij

)1
=+

tw
)(
ij

η+

tytx
)(
)(
i

j

            (1) 

where xi and yj are the output values of neurons i and j, 
respectively, which are connected by the synapse wij and 

16 

η  is  the  learning  rate  (note  that  xi    is  the  input  to  the 
synapse).  
Survey  of  types,  architectures,  basic  algorithms  and 
problems  that  may  be  solved  using  some  type  of  neural 
networks  is  presented  in  (Jain,  A.K.  &  Mao,  J.  & 
Mohiuddin,  K.M.  1996).  The  applications  of  neural 
networks  for  classification  and  pattern  recognition  are 
good  known.  Some  interesting  solutions  to  problems  of 
classification  in  the  robot  navigation  domain  were 
succesfully  solved  by  means  of  competitive  type  of 
neural networks (Bekey, G.A. & Goldberg, K. Y. 1993). 
Using  of  competitive  neural  networks  in  control  and 
trajectory generation for robots we may find in the book 
as  well  as  using  of  neural  network  for  sensor  data 
processing  in  map  updating  and  learning  of  the  robot 
trajectories.  For 
the  obstacle  avoidance  purposes 
recurrent  type  of  neural  network  was  used  with  the 
gradient  back-propagation  technique  for  training  the 
network  (Domany,  E.  &  Hemmen,  J.L.  &  Schulten,  K. 
1991). The using of supervised neural network for robot 
navigation  in  partially  known  environment  is  presented 
in (Chochra  1997). An interesant solution with using of 
Jordan  architecture  of  neural  network  is  described  in 
(Tani,  J.  1996).  Here  the  robot  learns  internal  model  of 
the  environment  by recurrent  neural network,  it  predicts 
succession of sensors inputs and on the base of the model 
it generates navigation steps as a motor commands. The 
solution of the minimum path problem with two recurent 
neural networks is given in (Wang 1998). Solutions that 
use the learning ability of the neural network with fuzzy 
logic for representation of the human knowledge applied 
to  robot  navigation  also  exists  see  (Kim  1998).  The 
complex  view  for  solution  of  the  navigation  problem  of 
the  autonomous  vehicles  gives  (Hebert,  Thorpe,  Ch.  & 
Stentz, A. 1997). Team of researches CMU here presents 
results from designing of autonomous terrain vehicle. For 
learning  the  path  from  vision  system  data  and  for 
obstacle  avoidances  algorithms  using  laser  range  finder 
data and different types of neural networks.  
Our  first  work  concerned  the  using  neural  networks  for 
object classification in the map of the robot environment 
was  using  the  cluster  analysis  with  range  finder  data 
(Uher, L. & Považan I. 1998). This acquiring knowledge 
we  extend  for  using  neural  network  in  the  algorithm  of 
the robot motion planning.  

3.  The proposed approach  

3.1. The basic motion planning problem 

Let A be a rigid object, a robot, moving in a workspace 
W, represented as a subspace of RN, with N=2 or 3. Let 
  be fixed rigid objects distributed in W, called 
O1 ,...,Om
obstacles.  Assume  that  both  the  geometry  and  the 
location of A, O1,...,Om, in W is known. 
The problem is: Given an initial position and orientation 
of  A  in  W,  generate  a  path  specifying  a  contiguous 
sequence  of  positions  and  orientations  of  A  avoiding 
collision  with  Oi's,  starting  at  the  initial  position  and 
orientation, and terminating at the goal position and 

 
 
 
 
 
 
 
orientation. Report the failure if no such path exists. 

3.2. Environment representation  

In  general,  we  consider  the  case  when  A  is  a  two-
dimensional object that translates and rotates in W=R2. A 
grid map will represent the environment. The grid map is 
an  M  x  N  matrix  with  each  element  representing  the 
status  Si,j  of  an  individual  grid;  Si,j  =  1,  if  its  interior 
intersects  with  the  obstacle  region  and  Si,j  =  0,  if  its 
interior does not intersect the obstacle region.  
A configuration of an arbitrary object is a specification of 
the  position  of  every  point  in  this  object  relative  to  a 
fixed  reference  frame.  In  addition,  let  FA  and  FW  be 
Cartesian  frame  embedded  in  A  and  W,  respectively.  
Therefore,  a  configuration  of  A  is  a  specification  of  the 
position (x,y) and orientation θ of FA with respect to FW . 
Throughout  the  paper  we  make  use  of  the  localization 
system  (Považan,  I.;  Janglova,  D.  &  Uher,  L.  1995) 
providing  the  robot  with  its  absolute  position  with 
respect to a fixed inertial frame. The configuration space 
of A is the space of all the configurations of A.  Let the 
resolution  in  x-axis,  y-axis  and orientation is  M,  N,  and 
K respectively.  A rectangloid  ri,j,k  is  model  of  the object 
A located by (xi, yj, θk) and it represents the region [xi – 
wx/2, xi + wx/2] . [yj – wy/2, yj + wy/2] . [θk– ∆θ/2, [θk + 
∆θ/2], where wx is the width, wy is the height and ∆θ = 
π/K. 

3.3.  Motion planning algorithm  

for  mapping 

Philosophy  of  our  algorithm  appear  from  motion  of 
human  in  the  environment  when  he  is  moving  between 
obstacles  on  the  base  of  his  eyes  view  and  he  make 
already  the  next  step  to  the  goal  in  the  free  space. 
Analogically, our robot will move safely in environment 
on the base of the data “visible” with scanning ultrasound 
range  finder  (Uher,  L.  &  Kello,  I.  1999).  First  must 
“mapping”  the  workspace  from  measured  data  and  find 
the  free  space  for  robot  motion  and  then  determines  the 
next robot azimuth for the safe step to the goal. For the 
solution  of  this  problems  we  use  neural  networks 
technique. We use the measured range finder data in the 
learning  workspace 
robot 
workspace  by  the  first  neural  network  finding  the  free 
space  segment.  This  segment  is  used  as  an  input  to  the 
second neural network both with the goal location, which 
is  used  to  determine  the  direction  of  the  proposed  next 
navigation step for moving the robot.  
The  algorithm  is  of  an  iterative  type.  In  each  iteration, 
the last orientation of the moving robot is stored and the 
neural  network  selects 
the  next 
navigation step. To determine the direction, the status in 
the partial configuration space is required; the map from 
range finder is proposed to give this status.  Moreover, a 
control  unit  is  used  to  provide  information  required  by 
neural networks to control the operating sequence and to 
check the reachability of the goal configuration from the 
start  configuration.  Our  motion  planning  algorithm  can 
be summarized as follows:  

the  direction  of 

front 

the 

1.  Specify the object, environment information and the 
start and goal configurations. 

2.  Set the current object orientation equal to the goal 
orientation. 

3.  Activate range finder via control unit to determine the 
local part of the map of the workspace. 

4.  Initialize the first neural network, which will use the 
measured data from range finder. The neural network is 
iterated until the weights and the outputs converged to 
the returned one free space segment.  

5.  Activate the second neural network. It returns the 
direction θk of next robot motion step. 

6.  Generate the robot motion path in the direction θk and 
go to the step 3. 

4.  Principles of proposed algorithm 

4.1. The findspace problem using neural network 

Therefore  we  use  the  sensor  data  from  the  environment 
and  the  classical  findspace  problem  in  our  strategy  was 
transform  to  the  procedure  ‘learning  your environment’. 
The  robot  has  in  any  position  in  workspace  information 
about  its  distances  to  the  all  objects  in  this  workspace. 
We  use  this  information  in  first  neural  network  that 
learns these situations and in any position gives the free 
segment  of  space  for  safe  path  as  output.  The  neural 
network  using  for  the  findspace  problem  is  principal 
component analysis network (PCA). 
combine 
component 
Principal 
unsupervised  and  supervised  learning  in  the  same 
topology (see Fig. 1).  

analysis  networks 

input 
layer 

PCA  
layer 

hidden 
layer 

output 
layer 

di 

Vi 

Fig. 1. PCA neural network topology 
This neural network uses as inputs the data measured by 
the range finder. The output is free segment of the robot 
workspace.  

17 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Principal  component  analysis  is  an  unsupervised  linear 
procedure  that  finds  a  set  of  uncorrelated  features  from 
the input. A feed-forward network is used to perform the 
nonlinear classification from these components. PCA is a 
data  reduction  method,  which  condenses  the  input  data 
down to a few principal components.  

x 
   0 

x 
   1 

x 
   2 

x 
   p-2 

x 
   p-1 

w 
   ij 

Σ 

Σ 

Σ 

y  
   0  

y  
  1 

y  
   m-1 

Fig. 2. Detail in PCA network 

The  number  of  principal  components  selected  will  be  a 
compromise  between  training  efficiency  and  accurate 
results. It is not possible to provide a general formula for 
selecting an appropriate number of principal components 
for  a  given  application.  Both  learning  rule  choices  are 
normalized  implementations  of  the  Hebbian  learning 
rule.  Straight  Hebbian  learning  must  be  utilized  with 
care,  since  it  may  become  unstable  if  the  inputs  are  not 
properly normalized. The network has four layers - input, 
PCA, hidden and output layer. The learning is realized in 
two phases.  
In the first place an unsupervised linear procedure gets a 
set of uncorrelated features from the inputs and selects a 
few  principal  components.  These  components  in  hidden 
layer feed-forward supervised part gives the output. The 
PCA neural network learns by generalized Hebbian rule. 
First  updated  the  synapse  weights  wij  (see  Fig.  2)  to  a 
small  random  number  and  learning  parameter  η  to  a 
positive  small  number.  Then  for  n=1  are  calculating 
outputs yj  and the changes of the weights. 

The outputs yj  from PCA network are given by (2) 

ny
)(
j

p

1
−

= ∑

i

=

0

nxnw
)(
)(

ij

i

j

=

,1,0

…

,

m

−

1

   (2) 

The  changes  of  the  weights  during  the  learning  are 
calculated by modification of Hebbian rule (3) 

18 

∆

nw
)(
ji

=

η

nxny
)(
)(

j

i

⎡
⎢
⎣
p
−
m
−

1
1

i
j

=
=

,1,0
,1,0

…
,
…
,

−

ny
)(
j

j

∑

k

=

0

nynw
)(
)(

ki

k

⎤
⎥
⎦

(3) 

The calculations iterate up to the weights wij  are stable. 
At second phase the learning of the network are realised 
by  back-propagation  algorithm.  Here  updated 
the 
synaptic  weights  and  treshold  neuron  coefficients.  The 
back-propagation  learning  algorithm  is  based  on  the 
error-correction principle, i.e. it is necessary to know the 
network  response  to  the  input  pattern.  The  learning 
process  is  as  follows:  On  the  input  are  given  the  input 
data and then are calculating the response of the network 
(feed-forward calculation). The error ei between an actual 
and an desired output is acquiring by formula (4) 

ne
)(
i

=

nd
)(
i

−

ny
)(
i

                  (4) 

where  di  is  desired  output  and  yi  is  the  actual  output. 
During  the  back-propagation  are  compute  the  local 
gradient  δi  for  the  preceeding  layers  by  propagating  the 
errors backwards. Update the weights using formula (5) 

nw
(
ij

+

)1

=

nw
)(
ij

δη+
i

nxn
)(
)(
j

     (5) 

where  wij  is  the  weight  between  ith  neuron  from  last 
layer  and  jth  neuron  of  the  next  layer,  η  is  the  learning 
rate.  This  process  is  repeated  for  the  next  input-ouput 
pattern  until  the  error  in  the  output  layer  is  below  a 
prespecified 
threshold  or  a  maximum  number  of 
iterations are reached.  We used the minimization of the 
average squared error cost function Eavg  given by (6) 

E

avg

=

1
N

V

N

1
∑ ∑
2

1
=

1
=

n

j

(

)(
nd
j

−

(
ny
j

2))

    (6) 

where N is number of the input-output patterns and V is 
the number of output neurons.  

The neural network in that case uses the normalized data 
from  ultrasound  range  finder  as  inputs.  There  are 
distances di, ranging from 20 to 250 cm, to the all objects 
in the front robot space from 0° to 180°. From input layer 
of  the  network  we  obtained  information  about  free 
segments  Vi.  Each  of  the  output  neurons  “represent” 
particular segment of the workspace as is depicted on the 
Fig. 3.  

 
 
 
 
 
 
 
 
    
          
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
V6 

V5 

V4 

V7 

V3 

input 
layer 

hidden 
layer 

output 
layer 

V8 

V9 

Vi 

Si 

V2 

V1 

Oi 

Fig. 3. The workspace segments 

Fig. 4. Topology of MLP network 

4.2. Solving the findpath problem  

For  the  solving  of  the  findpath  problem  we  use  neural 
network,  too.  Here  we  used  as  a  neural  network  a 
multilayer perceptron (MLP). Multilayer perceptrons are 
layered  feed-forward  networks  typically  trained  with 
static back-propagation. These networks have found their 
way  into  countless  applications  requiring  static  pattern 
classification. Their main advantage is that they are easy 
to  use,  and  that  they  can  approximate  any  input/output 
map.  The  key  disadvantages  are  that  they  train  slowly, 
and require lots of training data.  
Aim of this network is determining of the robot azimuth 
θk for the next robot motion step from the output of first 
network and from the goal coordinates. The topology of 
this  network  is  depicted  on  the  Fig. 4.  The  network 
contains a three layer – input, hidden and output. This is 
a  layered  feed-forward  network  typically  trained  with 
static  back-propagation.  Here  are  updating  the  synapse 
weights  between  neurons  and  threshold.  The  process  is 
similar  to  above  described  for  the  second  phase  of  the 
learning process for findspace problem. 
On the input of this neural network in our case we give 
the known free space segment Vi as the output of the first  
neural  network and the goal  segments Si  in which the 
coordinates of the robot goal position should be situated. 
The  choice  of  the  goal  segments  is  the  same  as  is 
depicted  on  the  Fig.  3.  From  output  layer  of  this  neural 
network we obtained information Oj about robot motion 
direction (azimuth) in the next step. 
This information is given to the control unit. It manages 
this  information  into  the  robot  command  for  the  robot 
motor control.  

4.3. Realization of the proposed algorithm 

The  proposed  algorithm  was  prepared  as  a  program 
Neuro  in  Microsoft  Visual  C++  with  operating  system 
Windows. For the learning and testing of the network we 
used 
the  programs  from  NeuroSolutions  packages 
(Neurodimension 2000). The program Neuro will secure 
the workspace visualization and robot motion simulation. 

The learning of all neural networks was realized off-line 
with  scanning  data  in  the  work  environment.  We  use  a 
more  type  of  the  learning  environment.  As  a  basic 
environment  for  “learning  your  environment”  was  used 
environment that is depicted in Fig. 5.  

Fig. 5. The learning environment 

This environment was chosen so that it contains various 
situations, which can occur during the robot motion.  
As  a  testing  environment  was  used  the  bit  map  of  the 
laboratory environment as is depicted at the Fig. 6. These 
environments  were  scanning  with  ultrasound  range 
finder.  The  model of  the range  finder  and sensing of  its 
data  was  implemented  as  follows:  virtual  environment 
with  obstacles  was  represented  as  a  bit  map.  The  range 
finder  scanned  this  environment  by  emitting  beams  (see 
Fig. 6). If the beam in competent direction collided with 
obstacles (the bit value 0 – black color) we calculate this 
distance  di.  The  calculated  and  normalized  distances  di 
was used as inputs to the neural networks. 
Scanning  of  the  environment  was  in  29  directions.  This 
number  was  obtaining  from  many  experiments  and 
simulations. At these 29 directions obtained distances di  
create input patterns to the PCA network. 

19 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
The  commands  left  (right)  means  turning  about  90°  in 
left (right) direction. 
When we testing the functionality of proposed algorithm 
we find out the critical location in which the robot do not 
know continue in correctly direction. There was a door in 
the  laboratory  room  or  the  narrow  location  in  corridor. 
Therefore  we  add  two  neural  networks  (network  H  and 
network  D)  the  multilayer  perceptron  type.  The  aim  of 
the network H is recognize when the robot is situated in 
“hazard” – it stay in narrow location. When this situation 
is finding the network D execute the safe motion through 
this narrow location (see Fig. 7). 

Fig 7. Motion by the door 

The network H operates as a switch, which decides about 
the  using  the  outputs  from  network  MLP  (described  in 
section 4. 2.) or from network D for robot motion.     

5. Simulation results 

In  our  laboratory  we  have  experimental  mobile  robot 
AURO, see Fig. 8. It is built up as a prism platform with 
three-wheeled  configuration,  which  has  a  length  of 
850 mm, a width of 500 mm, and a height of 750  mm. It 
consists  of  single  steerable  drive  wheel  at  the  front  and 
two passive rear wheels. Two stepper motors are used for 
driving and steering the front wheel. It has a capability of 
motion in longitudinal directions and rotation around the 
robot's reference point and it can reach a maximum speed 
of    0.1  m/sec.  The  drive  wheel  as  well  as  the  passive 
is  equipped  with  shaft  encoders  used  for 
wheels 
odometry  measurement.  For  sensing  the  environment  it 
has ultrasonic scanning range finder, rotating from 0° to 
360° and  three  tactile  sensors  on  the bumper.  The robot 
should  travel  from  its  initial  position  to  a  final  desired 
position 
structured 
environment.  The  robot  obtains  range  images  by  an 
ultrasound scanning range finder. The ranges for desired 
angular  sector  are  obtained  in  N  steps,  covering  up  to 
180° arcs in front of the robot, are measured by scanning 
every  200  ms  by  time-of-flight  principle  (Uher,  L.  & 
Kello,  I. 1999).  The  ultrasound  scanning  range  finder  is 
disposed on the robot to get the distance measure di in the 
vicinity  of  the  robot  where  20  cm  <  di    <  250  cm.  The 
main  navigation  level  computation  is  performed  on  a 
host  PC  via  RS  232  communication.  The  robot 

two-dimensional 

across 

a 

Fig. 6. The scanning range finder 

The  outputs  from  this  network  are  free  environment 
segments as are depicted on Fig. 3.  
For the learning of the free segments was create the safe 
sensor  map.  It  is  the  set  of  minimal  distances  from 
obstacles for actual state of the scanning scene using the 
really dimensions of the robot. At the robot motion (and 
scanning) in learning environment we compare values di  
with  the  safe  sensor  map  at  the  each  step  and  we 
determine the free segments. The obtained information di  
(29  values)  and  information  about  free  segments  Vi (9 
values) was in each step saved to the file. This file forms 
the  training  set  of  pattern  for  PCA  network  in  second 
phase.  
The second neural network - a feed-forward network - is 
typically  trained  with  static  back-propagation  algorithm. 
For  the  learning  of  this  supervised  MLP  network  was 
using the combination status table. This table contains all 
potential combinations of the space segments Vi and the 
goal  segments  Sj.  The  parameters  Vi  and  Sj  have  two 
values  in  the  table.  If  Vi  =1  then  space  segment  Vi  not 
containing  the  obstacle  meaning  the  motion  in  this 
segment  is  possible.  If  its  value  is  0  the  segment  is 
occupied  and  the  motion  within  it  is  not  possible.  The 
value  Sj=1  says  that  in  this  goal  segment  the  goal 
coordinates  take  place  and  the  value  0  signalises  the 
absence of the goal coordinates. The supervisor attaches 
the  required  output  (as  the  robot’s  reaction)  to  any 
combination  of  Vi   and  Sj,  and  the  network  learns  these 
situations.  The  robot  reaction  (azimuth)  the  supervisor 
chooses from free Vi  and Sj so as the robot motion was 
realized in the safe direction to the goal. Our network had 
18  input  neurons  (9  value  Vi and  9  value  Sj),  20  hidden 
neurons and 9 output neurons (azimuth Oj).  
Output Oj of this second network is given to the control 
unit. It manages this information into the robot command 
for  the  robot  motor  control.  In  our  case  experimental 
robot  distinguish  five  motion  commands:  forward,  turn 
left, left, turn right, right. The commands turn left (right) 
means turning about 45° in left (right) direction. 

20 

 
 
 
 
 
 
 
 
 
 
manoeuvres  are  controlled  by  delivering  information  of 
rotation velocity and heading angle of the front wheel.  

At the Fig. 9 is shown this situation – the execute path is 
collision-free. 
Then we use this algorithm for simulation of the motion 
for  our  experimental  mobile  platform  in  the  laboratory 
environment. 

Fig. 8.  Experimental mobile robot 

The 

2000). 

We  have  implemented  the  algorithm  described  in  the 
above  sections  in  a  path  planner program  Neuro written 
down  in  the  language  C++  on  PC  Intel  Pentium  350 
MHz.  For  the  learning  and  testing  of  the  network  we 
the  programs  from  NeuroSolutions  packages 
used 
programs  were 
(Neurodimension 
interconnected  with  help  of  the  dynamic  data  change 
(DDE)  in  order  to  enable  using  the  data  from  program 
packages NeuroSolutions in the program Neuro. 
Several examples were used to test our algorithm at first 
for  a  point  robot.  These  first  results  were  presented  in  
(Janglova, 2000).  
The functionality of the proposed algorithm was tested in 
a  few  type  of  the  workspace.  First  tests  were  in  the 
learning  environment.  Here  the  robot  avoids  to  all 
obstacles and it executes each path from the giving start 
point to the goal point safely. Next testing examples were 
doing in the environment that was not use for learning of 
network, i.e. the unknown environment for the robot.  

Fig. 9. Robot path in unknown environment 

Fig. 10. Simulation of robot motion 

Fig. 11. Robot motion from corridor to the room 

The  obtained  results  are  in  the  Fig.  10.  and  Fig.  11.  In 
these figures are given the bit map of indoor environment 
and  the  paths,  which  was  generated  by  the  above 
designed algorithm. 
The  Fig.  10.  shows  simulation  of  the  robot  path  when 
robot task had moving from the left corner of corridor to 
the  goal  marked  by  cross  at  the  laboratory  room.  The 
robot  does  not  reach  the  goal  position  –  it  was  not  pass 
through the door. 
This  same  simulation  example  with  using  the  adding 
neural  network  D  and  H  is  shown  on  the  Fig.  11.  It  is 
seen that the robot path is collision-free and safe from the 
start to t he goal position. From the shown examples we 
conclude that this strategy is usable in general for motion 
of the robot in arbitrary environment.  

21 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
6. Conclusion 

The  paper  presents  our  first  results  that  we  obtained 
making  use  of  the  proposed  path  planning  algorithm 
working  with  the  neural  network  and  sensor  data.  The 
simulation  examples  of  the  generation  of  the  collision-
free  path  for  point  robot  and  for  two-dimensional  robot 
show that designed strategy are acceptable for solution of 
this  problem.  We  played  the  role  of  the  supervisor  to 
learn  the  robot  to  make  it’s  way  intelligently  toward  its 
target and to avoid obstacles.  
In  future  we  will  implement  this  technique  for  safe 
motion  of  our  experimental  mobile  vehicle  in  indoor 
conditions. We suppose to use this algorithm not only for 
the robot motion in known environment but for unknown 
one, as well. It is necessary to test different parameters in 
neural network with the aim of reaching the optimal time 
for finding the (shortest possible) safe path. As the robot 
collects  environment  data  currently  along  its  path  it  can 
avoid  not  only  the  static  obstacles  but  also  the  dynamic 
ones. We feel that this technique will be suitable also for 
the  motion  of  mobile  devices  in  complex  environment 
comprising also mobile obstacles.   

ACKNOWLEDGEMENT 

This work was supported VEGA MŠ SR a SAV grant 
No. 2/3129/23. 

7. References 

Bekey, G. A. & Goldberg, K.Y. (1993). Neural Networks 
in Robotics.  Kluwer Academic Publishers, ISBN 0-
7923-9268-X,  Boston 

Brady, M. & at all. (1982). Robot Motion: Planning and 
Control.  The  MIT  Press,  ISBN  0-262-02182-X, 
Cambridge 

Domany,  E.;  Hemmen,  J.L.  &  Schulten,  K.  (1991). 
Models of Neural Networks.  Springer Verlag , ISBN 
3-540-51109-1, Berlin 

Chohra,  A.;  Sif,  F.  &  Talaoubrid,  S.  (1995).    Neural 
Navigation  Approach  of  an  Autonomous  Mobile 
in  a  Partially  Structured  Environment.  
Robot 

Proceedings  of    IAV'95,  pp.  238-243,    Espoo,  June 
12-14, Finland 

Hebert,  M.H.;  Thorpe,  Ch.  &  Stentz,  A.  (1997). 
Intelligent  Unamnned  Grou  nd  Vehicles.    Kluwer 
Academic Publishers, ISBN 0-7923-9833-5, Boston  
Jain,  A.K.;  Mao,  K.  &  Mohiuddin,  K.M.  (1996). 
Artificial Neural Networks: A Tutorial. Computer29, 
No. 3, pp. 31-44, ISSN 0018-9162   

Janglova, D. (2000). Collision-free Motion Using Neural 
Networks  Approach.  Proceedings  of    RAAD  2000, 
ISBN 86-435-0324-X, pp. 29-34, Maribor, June 1-3, 
Slovenia 

Kim,  C.N  &  Trivedi,  M.M.  (1998).    A  Neuro-Fuzzy 
for  Mobile  Robot  Navigation  and 
Controller 
Multirobot  Convoying.    IEEE  Trans.on  Systems, 
Man  and  Cybernetics-Part  B:  Cybernetics,  Vol.  28, 
No. 6, pp. 829-840, ISSN 1083-4419 

Latombe,  J.C. ( 1991). Robot Motion Planning. Kluwer, 

ISBN 0-7923-9129-2, Boston 

NeuroDimension (2000) Inc. Copyright (c) 1994-1997 in 

www.nd.com 

Tani.J  (1996).  Model-based  Learning  for  Mobile  Robot 
Systems 
Navigation 
Perspective.  IEEE  Trans.  on  Syst.,  Man  and  Cyb., 
Vol. 26, No.3, pp. 421-436, ISSN 1083-4419 

the  Dynamical 

from 

Považan, I.; Janglová, D. & Uher, L. (1995).  Odometry  
in    Determination    of    the    Position  of    an 
Autonomous  Mobile  Vehicle.  Proceedings  of  
ISMCR'95,  pp.  425-429,  ISBN  80-227-0760-0,  
Smolenice, June 12-16, Slovak Republic 

Uher, L. & Kello, I. (1999). Ultrasound Scanning Range 
Finder.  Proceedings  of  the  2nd  Int.  Conference.  
Measurement’99, pp. 232-235, ISBN 80-967402-4-5, 
Smolenice, April 26-29, Slovak Republic  

Vörös,  J.  (2001).    Low-cost  implementation  of  distance 
maps  for  path  planning  using  matrix  guadtrees  and 
octrees.  Robotics 
Integrated 
Manufacturing Vol. 17, No. , pp. 447-459, ISSN  
Wang, J. (1998).  Primal and Dual Neural Networks for 
Shortest-Path  Planning.  IEEE  Trans.  on  Systems, 
Man and Cybernetics-Part A: Systems and Humans, 
Vol.  28,  No.  6,  pp.  864-869,  ISSN  1083-441

and  Computer 

22 

www.robocup2004.pt 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
23"
Applying Evolutionary Optimisation to Robot Obstacle Avoidance,"  This paper presents an artificial evolutionbased method for stereo image
analysis and its application to real-time obstacle detection and avoidance for
a mobile robot. It uses the Parisian approach, which consists here in splitting
the representation of the robot's environment into a large number of simple
primitives, the ""flies"", which are evolved following a biologically inspired
scheme and give a fast, low-cost solution to the obstacle detection problem in
mobile robotics.
",http://arxiv.org/pdf/cs/0510076v1,1,"ISCIIA04, December 20-24, 2004, Haikou, China 

APPLYING EVOLUTIONARY OPTIMISATION TO ROBOT 
OBSTACLE AVOIDANCE 
Olivier Pauplin, Jean Louchet, Evelyne Lutton, Michel Parent 
INRIA, IMARA & COMPLEX Projects, BP 105, 78153 Le Chesnay Cedex France 
olivier.pauplin@inria.fr, jean.louchet@inria.fr, evelyne.lutton@inria.fr, michel.parent@inria.fr 

image  analysis  and 

Abstract:  This  paper  presents  an  artificial  evolution-
based  method  for  stereo 
its 
application to real-time obstacle detection and avoidance 
for a mobile robot. It uses the Parisian approach, which 
consists here in splitting the representation of the robot's 
environment  into  a  large  number  of  simple  primitives, 
the  “flies”,  which  are  evolved  following  a  biologically 
inspired scheme and give a fast, low-cost solution to the 
obstacle detection problem in mobile robotics. 
Keywords:  evolutionary  algorithm,  stereovision,  vision 
systems for robotics, obstacle detection 

1 

Introduction. 

representation  and  evolving  its  components 
following  principles  inspired  from  Darwin's 
descriptions of biological evolution. 

2  Evolutionary algorithms. 

Darwin’s  theory  assumes  that  a  population  of 
individuals,  characterised  by  their  genes,  will 
evolve  towards  a  better  adaptation  to  its 
environment  according  to  laws  of  natural 
selection.  Genes  mutations  may  occur  and 
maintain diversity in the population. 

from 

optimisation  methods 

Artificial  Vision,  an  important  element  in  the 
design  of  autonomous 
robots,  can  be 
approached  as  the  resolution  of  the  reverse 
problem of reconstructing a probable model of 
images.  Although 
the 
the 
scene 
like 
probabilistic 
in 
Evolutionary  Algorithms  [1],[2],[3]  are 
theory  well  adapted  to  the  resolution  of  such 
inverse problems, their use in real applications 
has  been  relatively  neglected  because  of  their 
low  speed  and  complexity. 
reputation  of 
Indeed,  evolving  a  population  in  which  each 
single  individual  would  be  a  complete  3-D 
representation of the  environment should raise 
problems  of  code  size  and  memory  handling 
wildly out of the reach of current optimisation 
algorithms. 

However,  the  technique  of  Parisian  Evolution, 
introduced  by  Lutton  et  al.  [4]  to  resolve  an 
optimisation  problem 
in  Iterated  Function 
Systems,  showed  that  in  some  cases,  splitting 
the representation of the object to be optimised 
into  a  collection  of  smaller  primitives  and 
evolve  them,  then  use  them  as  a  collective 
the  problem's  optimal 
representation  of 
solution,  may 
to  fast  and  efficient 
optimisation  algorithms.  The  Fly  Algorithm 
[5],[6]  has  been  developed  along  this  line  to 
solve Computer Vision problems, using a small 
scene 
grain 

decomposition 

lead 

the 

of 

Population initialised at random 

Evaluation 

Offspring

Genetic 
operators 

Parents

Selection 

Stop criterion 
is reached ? 

 no

yes 

Optimal solution 

Figure 1: General layout of genetic algorithms. 

Evolutionary algorithms manipulate individuals 
evaluated by a function, called fitness function, 
in  a  way  similar  to  biological  Evolution.  The 
general diagram of such algorithms is presented 
in figure 1, where: 
- 
- 

the population is a group of individuals 
an  individual  is  defined  by  his  genes  X  = 
(x1,  x2,…,  xn),  usually  coordinates  in  the 
search space 
evaluation 
is 
individual’s fitness value 
selection eliminates part of the population, 
keeping preferably the best individuals 
operators 
evolution 
(crossover,  mutations…),  leading  to  new 
individuals in the population. 

the  calculation  of  each 

- 

- 

- 

genetic 

applies 

 
 
 
ISCIIA04, December 20-24, 2004, Haikou, China 

3  The Fly algorithm. 

The Fly algorithm is a special case of Parisian 
evolution for which individuals (the “flies”) are 
defined  as  3-D  points  with  coordinates  (x,  y, 
z).  As  far  as  we  know,  it  is  the  only  existing 
evolutionary algorithm used to detect obstacles 
by stereovision. The aim of the algorithm is to 
drive  the  whole  population  -  or  a  significant 
part  of  it  -  into  suitable  areas  of  the  search 
space, corresponding to the  surfaces of visible 
objects in the scene. 

The population of flies is initialised at random 
inside the intersection of two cameras’ field of 
view.  Flies  then  evolve  following  the  steps  of 
cameras’ 
algorithms.  All 
evolutionary 
calibration parameters are known. 

3.1 

Evaluation. 

The  fitness  function  used  to  evaluate  a  fly 
compares  its  projections  on  the  left  and  right 
images given by the cameras. If the fly is on an 
object’s  surface,  the  projections  will  have 
similar  neighbourhoods  on  both  images  and 
hence this fly will be attributed a high fitness. 

Figures 2 and 3 illustrate that principle. Figure 
3  shows  neighbourhoods  of  two  flies  on  left 
and right images. On that example, Fly1, being 
on  an  object’s  surface,  will  be  given  a  better 
fitness than Fly2. 

Obstacle

Obstacle

Fly1 

Fly2

z 

x 

y 

a
r
e
m
a
c

t
f
e
L

a
r
e
m
a
c

t
h
g
i
R

Mobile robot 

Figure 2: Example of device using the Fly algorithm, 
showing two flies from the population (top view). 

Fly1

Fly2 

Left image

Right image 

3
-
D
s
p
a
c
e

i
n

i

m
a
g
e
s

P
r
o
j
e
c
t
i
o
n
s

Figure 3: Projections of two flies in left and right 
images. 

The  mathematical  expression  of  the  fitness 
function is [7],[8]: 

=

F

∑ ∑

colours

∈
),(
Nji

([
xL

∇
(

M

L

+

,
yi

L

L

.)
+

∇
(
M
−

j

)

)

R
(
xR

+

,
yi

R

R

+

2)]

j

where: 
- 
(xL,yL)  and  (xR,yR)  are  the  coordinates  of 
the  left  and  right  projections  of  the  current 
individual 
-  L(xL+i  ,  yL+j)  is  the  grey  value  at  the  left 
image  at  pixel  (xL+i  ,  yL+j),  similarly  with  R 
for the right image 
-  N is a neighbourhood around the projection 
of  each  fly,  introduced  to  obtain  a  more 
discriminating comparison of the flies 
- 

)
norms  on  left  and  right  projections  of  the  fly. 
That is intended to penalise flies which project 
onto uniform regions, i.e. less significant flies. 

  are  Sobel  gradient 

RM∇
(

LM∇
(

  and 

)

3.2  Selection. 

Selection  is  elitist  and  deterministic.  It  ranks 
flies  according  to  their  fitness  values  and 
retains the best individuals (around 40%). 

A sharing operator [7],[8] reduces the fitness of 
flies  packed  together  and  forces  them  to 
explore other areas of the search space. 

3.3  Genetic operators. 

The following operators are applied to selected 
individuals. 

-  Barycentric  cross-over:  given  two  parents 
F1 and F2, the algorithm builds their offspring F 
such as: 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
ISCIIA04, December 20-24, 2004, Haikou, China 

→
OF

=

λ

→
OF
1

−+
1(

λ
)

→
OF
2

with λ chosen at random in the interval [0,1]. 

-  Gaussian mutation adds a Gaussian noise to 
each  one  of  the  three  coordinates  of  the 
mutated  fly.  The  mutation  rate  is  set  to  40%, 
parisian  algorithms  normally  using  a  higher 
mutation  rate  than  conventional  evolutionary 
algorithms. 

-  Another operator, “immigration”, is used to 
the  search  space, 
improve  exploration  of 
creating new individuals  at random.  It ensures 
a  constant  exploration  of  the  search  space, 
whose high-fitness regions evolve as the scene 
in front of the cameras changes. 

4  Robot simulator. 

The original way the scene is described by the 
population  of  flies  led  our  team  to  adapt 
classical  robot  navigation  methods  in  order  to 
use  the  results  of  the  Fly  algorithm  as  input 
data. Boumaza [7],[9] developed a simulator of 
a robot moving in a simplified environment, to 
test  theoretically  control  methods  using  the 
output of the Fly algorithm. 

The  simulator  showed  the  possibility  to  build 
guidance  methods  based  on  the  output  of  the 
Fly  algorithm.  Our  current  work  consists  in 
transferring  and  extending 
these  control 
methods to real life situations. 

Figure 4: Application example of the Fly algorithm. 

5  Real life experiments. 

Figure  4  shows  an  application  example  of  the 
Fly  algorithm.  Flies  (black  dots)  concentrate 
on  obstacles  and  on  regions  where  the  grey 
level  gradient  is  high,  for  example  on  the 
fitness 
roadsides.  The  numerator  of 
function  prevents  flies  from  getting  trapped 
into uniform regions (sky, road surface, etc.). 

the 

The three coordinates of each fly being known, 
rough 
the  population  of 
description of the real 3-D scene. 

flies  gives  a 

the  probability 

driving,  we  developed  a  strategy  to  make  the 
program  quantify 
that  an 
obstacle is in front of the vehicle. The aim is to 
deliver  a  slow  down  or  stop  order  when  an 
obstacle  appears  close  enough  in  the  field  of 
vision, in order to avoid frontal collision. 

The  general  idea  to  achieve  this  goal  is  to  see 
each  fly  as  the  source  of  a  “warning  value”, 
higher when: 
- 
- 

the fly is near the vehicle 
the fly is in front of the vehicle (i.e. close 
to the z axis) 
the fly has a good fitness. 

- 

5.1  Control. 

In  the  scope  of  using  the  Fly  algorithm  in  the 
field of automatic driving - or at least assisted 

Beforehand,  flies  useless  for  this  specific 
application  have  there  fitness  value  penalised, 
and thus have high probability to be eliminated 

 
 
 
 
ISCIIA04, December 20-24, 2004, Haikou, China 

by the algorithm’s mechanisms. We considered 
such flies are: 
- 

flies  more  than  2  metres  above  the  road 
surface 
flies  with  a  height  under  10  centimetres 
(detecting the ground) 
flies  more  than  16  metres  ahead  of  the 
vehicle. 

- 

- 

An experimental analysis led us to choose the 
simple  following  formula  for  the  warning 
value of a fly: 

warning

(

fly

)

=

F
×
2

x

z

where  F  is  the  fitness  value  of  the  fly,  and  z 
and x its coordinates as shown on figure 2. 

For  |x| < 0.5 m  we  consider  x = 0.5 m,  and  for 
z < 1 m  we  consider  z = 1 m.  This  is  to  avoid 
giving excessive warning values to flies with a 
not  necessarily  good  fitness  but  with  a  very 
small  x  or  z  coordinate.  Moreover,  obstacles 
within a range of half a metre to the left or to 
the  right  from  the  centre  of  the  vehicle 
(|x| < 0.5 m)  are  equally  dangerous,  and  are 
consequently processed the same way. 

The warning function was built in order to give 
high warning values to flies for which the three 
coefficients F, 1/x² and 1/z are simultaneously 
high.  Indeed  a  fly  with  a  low  fitness  value 
(thus probably not on an obstacle), far from the 
vehicle  or  not  in  front  of  it,  does  not  show 
collision. 
evidence 
Experiments  with  a  1/x  factor  instead  of  1/x² 
did not give satisfactory results, as it tended to 
overestimate  the  importance  of  flies  off  the 
cameras axis. 

imminent 

an 

of 

5.2  Results. 

To  validate  the  algorithm,  we  tested  it  on  two 
stereo pairs of images: one representing a road 
with  no  immediate  obstacle  (figures  5  and  6), 
and one representing a pedestrian crossing the 
street in front of the vehicle (figures 7 and 8). 
Figure  5  does  not  show  a  case  of  emergency 
breaking,  whereas  figure  7  shows  a  situation 
closer to a collision. 

Results  are  obtained  using  two  commercial 
CCD  cameras  and  a  computer  (Pentium 

2 GHz).  The  population  of  flies  is  5000.  One 
takes  about  10  milliseconds. 
generation 
Population  update  and  calculation  of 
the 
warning values are done in a quasi-continuous 
way,  and  the  system  needs  about  10  to  30 
generations to react to a new event in the scene. 

Figures 5 and 7 show the 250 best flies of the 
resulting  population.  Flies  appear  as  black 
crosses. We note that, on both figures 5 and 7, 
flies  gather  on  the  visible  objects  of  the  scene 
(car, pedestrian, road sides...). 

Figures  6  and  8  show  the  same  (x,y)  view  as 
figures  5  and  7,  with  only  flies  represented. 
Flies  appear  as  spots  as  dark  as  their  warning 
value is high. 

We note the algorithm delivers higher warning 
values in figure 8 than in figure 6, where they 
are very close to zero. 

Figure 5: A road with no immediate obstacle. 

Figure 6: Warning values of figure 5 flies. 

 
 
 
 
 
 
ISCIIA04, December 20-24, 2004, Haikou, China 

Figure 7: A pedestrian at 4 metres from the cameras, on 
the middle of the road. 

Figure 8: Warning values of figure 7 flies. 

A  global  warning  value  can  be  defined  as  the 
mean of the warning values of a population. In 
the first case, this mean is 0.09, whereas in the 
second  case  it  is  0.85.  The  high  difference 
between  these  two  values  suggests  that  they 
can  be  used  to  discriminate  between  the  two 
situations.  Further  experiments  will  be  needed 
in order to confirm or refine this criterion. 

6  Conclusion. 

The  Fly  algorithm  has  proved  a  valid  method 
for obstacle detection in outdoor environments. 
The  simplicity  of  the  fitness  function  used 
opens  the  way  to  real  time  applications.  Real 
time  vehicle  control  based  on  the  information 
of  flies  (coordinates,  fitness  value)  has  been 
developed. 

Classical 
image  segmentation  and  stereo 
reconstruction  methods  are  potentially  able  to 
give  more  complete  and  accurate  results  than 
the  Fly  algorithm,  though  requiring  higher 

processing  times.  However,  the  Fly  algorithm 
presents some features which are outstandingly 
interesting  in  real  time  vision  applications:  in 
particular  its  asynchronous  properties  and  its 
principle of continuous refinement of previous 
results,  giving  reaction  times  to  new  events 
intrinsically faster than classical methods [8]. 

Our  future  work  will  be  directed  toward 
developing  guidance  algorithms  for  mobile 
robots  in  real  life  situations,  and  to  integrate 
them into a vehicle of IMARA project. 

Acknowledgements. 

thank  Dr  Amine  Boumaza 

We 
for  his 
important  contribution  to  the  development  of 
the code used in our experiments. 

This  research  was  funded  in  part  by  the  IST 
Programme  of  the  European  Commission  in 
the CyberCars project: 
http://www.cybercars.org/ 

References. 
1.  D.E.  Goldberg,  Genetic  Algorithms 

in 
Search,  Optimization 
and  Machine 
Learning,  Addison-Wesley,  Reading,  MA 
(1989) 

2.  I.  Rechenberg,  “Evolution  strategy”,  J.M. 
Zurada,  R.J.  Marks  II,  C.J.  Robinson, 
(Eds.), 
Intelligence 
Imitating Life, IEEE Press, Piscataway, NJ, 
pp. 147-159 (1994) 

Computationnal 

3.  J.-P.  Rennard,  Vie  artificielle,  Vuibert, 
ISBN 2-7117-8694-3, pp 241-242 (2002) 
4.  P.  Collet,  E.  Lutton,  F.  Raynal,  M. 
Schoenauer,  “Individual  GP:  an  alternative 
viewpoint  for  the  resolution  of  complex 
problems”,  Genetic  and  Evolutionary 
Computation  Conference  GECCO99, 
Morgan  Kauffmann,  San  Francisco,  CA 
(1999) 

5.  J.  Louchet,  “From  Hough  to  Darwin:  an 
individual  evolutionary  strategy  applied  to 
artificial  vision”,  Artificial  Evolution, 
European  Conference,  AE  99,  Dunkerque, 
France,  Selected  papers,  Springer  Verlag, 
Lecture  Notes  in  Computer  Science  1829 
(1999) 

 
 
ISCIIA04, December 20-24, 2004, Haikou, China 

6.  J.  Louchet, 

“Stereo 

analysis  using 
individual  evolution  strategy”,  Internat. 
Conf.  on  Pattern  Recognition,  ICPR2000, 
Barcelona, Spain (2000) 

7.  A.  Boumaza,  J.  Louchet,  “Dynamic  Flies: 
Using  Real-Time  Parisian  Evolution  in 
Robotics”,  EVOIASP  2001,  Lake  Como, 
Italy (2001) 

8.  J.  Louchet,  M.  Guyon,  M.-J.  Lesot,  A. 
Boumaza,  “Dynamic  Fies:  a  new  pattern 
recognition tool applied to stereo sequence 
processing”,  Pattern  Recognition  Letters, 
No. 23 pp. 335-345 (2002) 

9.  A.  Boumaza,  “Introduction  de  techniques 
vision 
artificielle 
d’évolution 
tridimensionnelle  et  en  robotique  mobile”, 
Thèse  Université  René  Descartes,  Paris 
(2004) 

en 

10. Z.  Michalewicz,  Genetic  Algorithms  + 
Data  Structures  =  Evolution  Programs, 
Springer Verlag (1992)"
"Integration of navigation and action selection functionalities in a
  computational model of cortico-basal ganglia-thalamo-cortical loops","  This article describes a biomimetic control architecture affording an animat
both action selection and navigation functionalities. It satisfies the survival
constraint of an artificial metabolism and supports several complementary
navigation strategies. It builds upon an action selection model based on the
basal ganglia of the vertebrate brain, using two interconnected cortico-basal
ganglia-thalamo-cortical loops: a ventral one concerned with appetitive actions
and a dorsal one dedicated to consummatory actions. The performances of the
resulting model are evaluated in simulation. The experiments assess the
prolonged survival permitted by the use of high level navigation strategies and
the complementarity of navigation strategies in dynamic environments. The
correctness of the behavioral choices in situations of antagonistic or
synergetic internal states are also tested. Finally, the modelling choices are
discussed with regard to their biomimetic plausibility, while the experimental
results are estimated in terms of animat adaptivity.
",http://arxiv.org/pdf/cs/0601004v1,1,"Integration of navigation and ation seletion

funtionalities in a omputational model of

ortio-basal ganglia-thalamo-ortial loops

Benoît Girard

1,2,

3
∗, David Filliat

, Jean-Arady Meyer

,

1

Alain Berthoz

and Agnès Guillot

2

1

1

AnimatLab/LIP6, CNRS - University Paris 6

2

3

LPPA, CNRS - Col lège de Frane

DGA/Centre Tehnique d'Arueil

6
0
0
2

n
a
J

3

]
I

A
.
s
c
[

1
v
4
0
0
1
0
6
0
/
s
c
:
v
i
X
r
a

This artile desribes a biomimeti ontrol arhiteture a(cid:27)ording an animat both ation

seletion and navigation funtionalities. It satis(cid:28)es the survival onstraint of an arti(cid:28)ial

metabolism and supports several omplementary navigation strategies.

It builds upon

an ation seletion model based on the basal ganglia of the vertebrate brain, using two

∗

orrespondene to: B. Girard, CNRS LPPA, Collège de Frane, 11 plae Marellin Berthelot, 75231

Paris Cedex 05, Frane, , Tel.: +33-144271391, Fax: +33-144271382 E-mail: benoit.girardollege-de-

frane.fr

1

 
 
 
 
 
 
interonneted ortio-basal ganglia-thalamo-ortial loops: a ventral one onerned with

appetitive ations and a dorsal one dediated to onsummatory ations.

The performanes of the resulting model are evaluated in simulation. The experiments

assess the prolonged survival permitted by the use of high level navigation strategies and

the omplementarity of navigation strategies in dynami environments. The orretness

of the behavioral hoies in situations of antagonisti or synergeti internal states are

also tested. Finally, the modelling hoies are disussed with regard to their biomimeti

plausibility, while the experimental results are estimated in terms of animat adaptivity.

Keywords: ation seletion, navigation, basal ganglia, omputational neurosiene

Short title: Basal ganglia model of ation seletion and navigation.

1

Introdution

The work desribed in this paper ontributes to the Psikharpax pro jet, whih aims at

building the ontrol arhiteture of a robot reproduing as aurately as possible the urrent

knowledge of the rat's nervous system (Filliat et al., 2004), it thus onerns biomimeti

modelling derived from data gathered with rats. The main purpose of the Psikharpax

pro jet is to refous on the seminal ob jetive advoated by the animat approah: building

""a whole iguana"" (Dennett, 1978), instead of designing isolated and disembodied funtions.

Indeed, in the animat literature, a great deal of work is devoted to the design of isolated

ontrol arhitetures that provide either ation seletion or navigation abilities (cid:21)two fun-

2

damental funtions for an autonomous system. The main ob jetive of roboti navigation

arhitetures is to a(cid:27)ord an animat with various orientation strategies, like dead-rekoning,

taxon navigation, plae-reognition or planning (Filliat and Meyer, 2003, Meyer and Fil-

liat, 2003 for reviews). The main ob jetive of ation seletion arhitetures is to maintain

the animat into its (cid:16)viability zone(cid:17), de(cid:28)ned by the state spae of its (cid:16)essential variables(cid:17)

(Ashby, 1952), through e(cid:30)ient swithes between various ations (Presott et al., 1999

for a review). Even if there is evidene that an e(cid:27)etive animat requires the use of these

two funtionalities, few models attempt to integrate them, taking into aount the spei(cid:28)

harateristis of eah.

On the one hand, most of the navigation models insert arbitration mehanisms typial

of ation seletion to solve spatial issues (e.g., Rosenblatt and Payton, 1989), but they do

not take into aount motivational onstraints.

On the other hand, ation seletion models always integrate navigation apaities en-

suring an animat the ability to reah resoures in the environment, but they typially

implement only rudimentary navigation strategies (cid:21)random walk and taxon navigation(cid:21)

(e.g., Maes, 1991, Seth, 1998).

The few models that proess both navigation and ation seletion issues are inspired by

biologial onsiderations, indiating that the hippoampal formation, in assoiation with

the prefrontal ortex, proesses spatial information (O'Keefe and Nadel, 1978), whereas

the basal ganglia are hypothesized to be a possible neural substrate for ation seletion in

the vertebrate brain (Redgrave et al., 1999).

For example, Arleo and Gerstner (2000) propose a model of the hippoampus that elab-

3

orates an internal map with the reation of several (cid:16)plae ells(cid:17), used by an animat to reah

two di(cid:27)erent kinds of resoures providing rewards. The outputs of the model are assumed

to be four ation ells, oding for displaements in ardinal diretions, and assumed to

belong to the nuleus aumbens. This nuleus, loated in the ventral part of the basal

ganglia, is hypothesized to integrate sensorimotor, motivational and spatial information

(Kelley, 1999). In this model, it selets the atual displaement by averaging the ensemble

ativity of the ation ells. However, the animat does not selet other navigation strategies

and does not have a virtual metabolism that puts onstraints on the timing and e(cid:30)ieny

of the seletion of its behaviors.

Guazzelli et al. (1998) endow their simulated animat with two navigation strategies

(plae-reognition-triggered and taxon navigation, proessed by hippoampus and pre-

frontal ortex) and homeostati motivational systems (hunger and thirst, proessed by

hypothalamus). Here, the role of the basal ganglia is limited to omputing of reinfore-

ment signals assoiated with motivational states, while ation seletion properly ours in

the premotor ortex. Yet, in this work, there are no virtual metabolism onstraints on

ation seletion and beause of the hoie of a systems-interation level of modelling, the

internal operation of the modules is not spei(cid:28)ally biomimeti.

Gaussier et al. (2000) endow a motivated robot (Koala

, K-Team) with a virtual

TM

metabolism (cid:21)generating signals of hunger, thirst and fatigue(cid:21) and a topologial navigation

apaity. A topologial map is built in the hippoampus and used to build a graph of

transitions between plaes in the prefrontal ortex, used for path planning. The motor

output is assumed to be e(cid:27)eted by ation neurons in the nuleus aumbens, oding

4

for three egoentri motions (turn right, left, go straight). Motivational needs a(cid:27)et path

planning by spreading ativation into the prefrontal graph from the desired resoures to the

urrent loation of the animat. They are transmitted to the ation neurons, allowing the

animat to reah one goal by several alternative paths, and to make ompromises between

di(cid:27)erent needs. Here, one navigation strategy only is used, while various omplementary

strategies oexist in animals.

These models do not entirely satis(cid:28)y the ob jetives of the fundamental funtions, that

is, dealing with survival onstraints together with taking advantage of various omplemen-

tary navigational strategies. Moreover, they do not exploit reent neurobiologial (cid:28)ndings

onerning neural iruits devoted to the integration of these funtions, involving two paral-

lel and interonneted (cid:16)ortio-basal ganglia-thalamo-ortial(cid:17) loops (CBGTC, Alexander

et al., 1986), staked on a dorsal to ventral axis, reeiving sensorimotor (dorsal loop) and

spatial (ventral loop) information.

We previously tested a omputational model of ation seletion, inspired by the dor-

sal loop and designed by Gurney et al.

(2001a,b, referred to here as 'GPR' after the

authors'names), by repliating the Montes-Gonzalez et al. (2000) implementation in a sur-

vival task (Girard et al., 2003). To improve the survival of an arti(cid:28)ial system in a omplex

environment, our ob jetive is to add to this arhiteture a seond iruit (cid:21)simulating the

ventral loop(cid:21) whih selets loomotor ations aording to various navigation strategies: a

taxon strategy, direting the animat towards the losest resoure pereived, a topologial

navigation, building a map of the di(cid:27)erent plaes in the environment and using it for path

planning, together with random exploration, mandatory to map unknown areas and allow-

5

ing the disovery of resoures by hane. The interonnetion of the dorsal and ventral

loops is designed by means of bioinspired hypotheses. The whole model will be validated

in several environments where the animat performs a simple survival task.

After desribing the navigation and ation seletion systems and how they are inter-

onneted, we will introdue the spei(cid:28) experimental setup (survival task and animat

on(cid:28)guration). The results will onern tests on the animat's spei(cid:28) adaptive meha-

nisms and behaviors, involving topologial and taxon navigation, opportunisti ability and

on(cid:29)it management in ase of hanges in the environment or internal state.

2 The ontrol arhiteture

This model has been introdued in a brief preliminary form in Girard et al. (2004).

2.1 Navigation

The hoie of the navigation model was based on funtional and e(cid:30)ieny riteria: it had

to provide the animat with the apabilities of building a ognitive map, loalizing itself

with respet to it, storing the loation of resoures and omputing diretions to reah these

resoures; these operations had to be performed in real time and had to be robust enough

to ope with the physial limitations of a real robot. The navigation system proposed by

Filliat (2001) was hosen as it provides the required features and has been validated on a

real robot (Pioneer

, AtivMedia).

TM

This model emulates hippoampal and prefrontal ortex funtions. It builds a dense

6

topologial map in whih nodes store the allotheti sensory input that the animat an per-

eive at respetive plaes in the environment. These inputs are mean gray levels pereived

by a panorami amera in eah of 36 surrounding diretions, and sonar readings providing

distanes to obstales in eight surrounding diretions. A link between two nodes memorizes

at whih distane and in whih diretion the orresponding plaes are positioned relative to

eah other, as measured by the idiotheti sensors of odometry. The position of the animat

is represented by a probability distribution over the nodes.

The model also provides an estimation of disorientation (D ), whih varies from 0 when

the estimate of loation is good, to 1 when it is poor. D inreases when the robot is

reating new nodes (it is in an unmapped area) and only dereases when it spends time

in well known areas. The model also provides two 36-omponent vetors indiating whih

diretions to follow in order to either explore unmapped areas (Expl) or go bak to known

areas in order to derease disorientation (BKA). If the animat does not regularly go bak

to known areas when it is very disoriented, the resulting ognitive map will not be reliable.

Consequently, the addition of topologial navigation to an ation seletion mehanism will

put a new onstraint on the latter, the one of keeping Disorientation as low as possible.

We provided the model with the ability to learn the loalization of resoures important

to survival (e.g. loading station, dangerous area) in the topologial map. It is learned by

assoiating ative nodes of the graph with the type of resoures enountered using Hebbian

learning. By speifying the type of resoure urrently needed to a path planning algorithm

applied on the graph, a vetor P of 36 values is produed, representing the proximity of

that resoure in 36 diretions spaed by 10

◦

. Suh a vetor an be produed for eah type of

7

resoure res, weighted by the motivation assoiated to that resoure m(res), and ombined

with the other ones to produe a generi path planning vetor Plan. The ombination is

proessed as follows:

Plan = 1

(1

−

− Y
res

m(res)

×

P(res))

(1)

2.2 Ation Seletion System

(cid:21)Figure 1 around here(cid:21)

The ation seletion model presented here is an extension of the one used in Girard

et al.

(2003), the GPR model (Gurney et al., 2001a).

It is a neural network model

built with leaky-integrator neurons, in whih eah nuleus in the BG is subdivided into

distint hannels eah modelled by one neuron (Figure 1), and eah hannel assoiated to

an elementary ation. Eah hannel of a given nuleus pro jets to a spei(cid:28) hannel in

the target nuleus, thereby preserving the hannel struture from the input to the output

of the BG iruit. The subthalami nuleus (STN) is an exeption as its exitation seems

to be di(cid:27)use. Inputs to the BG hannels are Saliene values, assumed to be omputed in

spei(cid:28) areas in the ortex, and representing the ommitment to perform the assoiated

ation. They take into aount internal and external pereptions, together with a positive

feedbak signal oming from the thalamo-ortial iruit, whih introdues some persistene

in the ation performane. Two parallel seletion and ontrol iruits within the basal

ganglia serve to modulate interations between hannels. Finally, the seletion operates

8

via disinhibition (Chevalier and Deniau, 1990): at rest, the BG output nulei are tonially

ative and keep their thalami and motor system targets under onstant inhibition. The

output hannel that is the less inhibited is seleted, and the orresponding ation exeuted.

A prinipal original feature of our model is that two parallel CBGTC loops are modelled,

one seleting onsummatory ations and the other appetitive ations.

2.2.1 Dorsal loop

In the BG, the dorsal loop impliated in the seletion of motor responses in reation to

sensorimotor inputs and orresponds to the one modelled in the previous roboti studies

of the GPR (Montes-Gonzalez et al., 2000; Girard et al., 2003). Here we hypothesize that

it will diret the seletion of non-loomotor ations, whih in the present ase are limited

to onsummatory ations (roboti equivalents of eating, resting, et.) (Figure 2). In this

loop:

• input Salienes are omputed with internal and external sensory data;

• at the output, a (cid:16)winner-takes-all(cid:17) seletion ours for the most disinhibited hannel,

as simultaneous partial exeution of both reloading behaviors doesn't make sense.

(cid:21)Figure 2 around here(cid:21)

2.2.2 Ventral loop

The ventral loop an be subdivided into two distint subloops (Thierry et al., 2000), orig-

inating from the ore and shell regions of its input nuleus (nuleus aumbens or NA)

9

(Zham and Brog, 1992). In the present work, we will only retain the ore subloop (that will

be heneforth also alled ventral loop ), whih has been proposed to play a role in navigation

towards rewarding plaes (Mulder et al., 2004; Martin and Ono, 2000). The interations

between the hippoampus, the prefrontal ortex and the NA ore (Thierry et al., 2000)

ould be the substrate of a topologial navigation strategy. Taxon navigation needs sensory

information only and ould therefore be implemented in the dorsal loop. However, it was

reported that the lesion of the NA also impairs ob jet approah (Seamans and Phillips,

1994). This is why, in our model, this strategy will also be managed by the ventral loop.

To summarize, we hypothesize that this loop will diret appetitive ations (robotis

equivalent for looking for food, homing, et.), suggesting displaements towards motivated

goals (Figure 2).

The ventral loop is very similar (cid:21)anatomially and physiologially(cid:21) to the iruits of the

dorsal loop: the dorsolateral ventral pallidum plays a role similar to the GP (Maurie et al.,

1997), the medial STN is dediated to the ventral iruits (Parent and Hazrati, 1995) as

well as the dorsomedial part of the SNr (Maurie et al., 1999). Thus, despite probable

di(cid:27)erenes onerning the in(cid:29)uene of dopamine on ventral and dorsal input nulei, it is

also designed by a GPR model. However, a few di(cid:27)erenes are to be noted:

• Salienes are omputed with internal and external sensory data: the taxon navigation

needs distal sensory inputs to selet a diretion and all navigation strategies are

modulated by the motivations. Additional data oming from the navigation system

proposes motions on the basis of a topologial navigation strategy and map updates

10

of urrent positions;

• eah nuleus is omposed of 36 hannels, representing alloentri displaement dire-

tions separated by 10

;

◦

• the lateral inhibitions whih our in the nuleus aumbens ore are no longer uni-

form as in the dorsal

loop, but inrease with the angular distane between two

hannels (see eqn. 7), so that lose diretions ompete less than opposite ones;

• at the output, the seletion makes a ompromise among all hannels disinhibited

above a (cid:28)xed threshold. The diretion hosen by the animat is omputed by a vetor

sum of these hannels, weighted by their magnitudes of disinhibition.

2.2.3

Interonnetion of Basal Ganglia loops

Interonnetions between the parallel CBGTC loops is needed to oordinate their respe-

tive seletion proesses. This is espeially true here, when seletions onerning navigation

taken in the ventral loop (cid:21)like following a planned path leading to a resoure(cid:21) might be

on(cid:29)iting with behavioral hoies made by the dorsal loop (cid:21)like resting. Four main hy-

potheses onerning interonnetions between loops have been proposed in the rat's brain.

Two of them (Hierarhial pathway (Joel and Weiner, 1994) and Dopaminergi hierarhial

pathway (Joel and Weiner, 2000)) were disarded beause they only allow unidiretional

ommuniation from ventral to dorsal loops, whereas bidiretional or dorsal-to-ventral om-

muniation was neessary to solve our on(cid:29)its. The two remaining possibilities are (1) the

Cortio-ortial pathway : ortial interonnetions between areas implied in di(cid:27)erent loops

11

ould allow bidiretional (cid:29)ows of information between loops; and (2) the Trans-subthalami

pathway (Kolomiets et al., 2001, 2003): the segregation of loops is not perfetly preserved

at the level of the STN, some neurons belonging to one loop are exited by ortial areas

belonging to other loops, thus, parts of the SNr belonging to one loop an be exited by

another loop (Figure 2).

We implemented the trans-subthalami hypothesis, by distributing dorsal STN ativa-

tion to the ventral outputs (see eqn. 10 and Figure 2). Seletion of an ation in the dorsal

loop inreases ativity in the dorsal STN, whih in turn inreases ativation of the ventral

outputs, preventing any movement from ouring.

The preise mathematial desription of the resulting model is given in appendix A.1.

3 Experimental setup

3.1 Environment and survival task

The experiments are performed in simulated 2D environments involving, as in Girard

et al. (2003), the presene of (cid:16)ingesting(cid:17) and (cid:16)digesting(cid:17) zones, but with the addition of

(cid:16)dangerous(cid:17) plaes. The animat has to reah (cid:16)ingesting(cid:17) zones in order to aquire Potential

Energy (EP ), whih it should onvert into Energy (E ) in (cid:16)digesting(cid:17) zones, in order to use

it for behavior. Note that a full load of Energy allows the animat to survive only 33min.

Paths to reah these zones may ontain dangerous areas to avoid.

The software used is a simulator programmed in C++, developed in our laboratory.

12

Walls and obstales are made of segments olored on a 256 level graysale. The e(cid:27)ets of

lighting onditions are not simulated: the visual sensors have a diret aess to the olor.

The three type of resoures are represented by 50cm

50cm squares of spei(cid:28) olors:

×

the (cid:16)ingesting(cid:17) (Ep ), (cid:16)digesting(cid:17) (E ) and (cid:16)dangerous(cid:17) (DA) areas are respetively gray

(127), white (255) and dark gray (31). They an be used by the animat when the distane

between their entre and the entre of the animat is less than 70cm (i.e. when they oupy

more than 60◦

of the visual (cid:28)eld). The other gray ob jets have no impat on survival but

help the navigation system disriminating plaes.

3.2 The animat

The animat is irular (30cm diameter), and translation and rotation speeds are 40cm.s−1

and 10◦.s−1

respetively. Its simulated sensors are:

• an omnidiretional linear amera providing the olor of the nearest segment for every

10◦

surrounding setor,

5◦
• eight sonars with a 5m range, a diretional inertitude of ±

10cm distane

and a ±

auray,

• enoders measuring self-displaements with an error of ±

5% of the measured distane,

• a ompass with a ±

10◦

range of error of estimated diretion.

The sonars are used by a low level obstale avoidane re(cid:29)ex whih overrides any deision

taken by the BG model when the animat omes too lose to obstales. The navigation

13

model uses the amera, enoders and ompass inputs. The BG model uses the amera

input to ompute nine external variables:

• Three 36-omponent vetors, Prox(DA), Prox(EP ) and Prox(E) providing the

proximity of eah type of resoure in eah diretion. This measure is related to

the angular size of the resoure in the visual (cid:28)eld with a 10

resolution, as it is

◦

obtained by ounting the number of ontiguous pixels of the resoure olor in a 7

pixels window entered on the diretion onsidered. These vetors are the basis of

the taxon navigation strategy.

• Three variables, mP rox(DA), mP rox(EP ) and mP rox(E) whih are the max values

of the omponents of P rox vetors.

• Three Boolean variables, A(DA), A(EP ) and A(E), whih are true if the orrespond-
ing mP rox value is one (i.e. if the resoure is less than 70cm away and thus usable).

These purely sensory inputs are ompleted by the vetors produed by the topologial

navigation system: the path planning vetor Plan, the exploration vetor Expl and the

(cid:16)go bak to known areas(cid:17) vetor BKA.

The animat has four internal variables: Energy and Potential Energy, whih onern the

survival task (see 3.1), Fear, whih is a onstant, (cid:28)xing the strength of the repellent e(cid:27)et

of (cid:16)dangerous areas(cid:17) and Disorientation, whih is provided by the topologial navigation

system (see 2.1). From these variables are derived four motivations used in salienes

omputations and in the weighting of the Plan vetor (eqn. 1). The motivations to go

bak to known areas and to (cid:29)ee dangerous areas are respetively equal to the Disorientation

14

and Fear variables, while the motivation to reah Energy and Potential Energy resoures

are more omplex:

m(DA) = F

m(BKA) = D

m(E) = (1

E)

1
p

−

−

(1

−

EP )2

m(EP ) = 1

EP

−

(2)

The variables used to ompute salienes in eah loop are summarized in Figure 2, and

the details of these omputations are given in appendix A.2.

4 Experiments

Three di(cid:27)erent experiments are arried out in simple environments in order to test the

adaptive mehanisms the animat is provided with.

Experiment 1 tests the e(cid:30)ieny of the navigation/ation seletion models interfae.

An animat apable of topologial navigation has to survive in an environment ontain-

ing one resoure of Energy and one resoure of Potential Energy whih annot be seen

simultaneously. It is ompared to an animat using the taxon strategy only, the use of the

topologial navigation is expeted to improve the survival time.

Experiment 2 tests adaptive ation seletion in a hanging environment : on the one

hand, the animat has to use a taxon strategy in order to reah newly appeared resoures;

on the other hand, it has to forget the loation of exhausted resoures to head towards

abundant ones.

15

Experiment 3 tests adaptive ation seletion in ase of antagonisti or synergeti in-

ternal states : on the one hand, in a situation where two paths lead to a resoure and the

shortest one inludes a dangerous area; on the other hand, in a situation where a short

path leads to one resoure only, while a longer one leads to two resoures satisfying two

di(cid:27)erent needs.

In experiments 2 and 3, the animat is provided with a previously built map of the

environment in order to allow statistial omparison of runs with idential initial onditions.

4.1 Experiment 1: E(cid:30)ieny of the navigation/ation seletion

interfae

In this experiment, an animat traverses the environment (7m

9m) depited in Figure 3: it

×

ontains one resoure of E and one resoure of EP , but it is impossible to see one resoure

from the viinity of the other. In the (cid:28)rst model on(cid:28)guration (ondition A), the animat

uses both ob jet approah and topologial navigation strategies, whereas in the other one

(ondition B ), the animat uses ob jet approah only. The (cid:16)reative(cid:17) animat (ondition B ),

following taxon strategy only, has to rely on random exploration to (cid:28)nd hidden resoures.

In ontrast, after a (cid:28)rst phase of random exploration and map building, the animat in

ondition A should be able to reah desired resoures using its topologial map.

(cid:21)Figure 3 around here(cid:21)

Ten tests, with a four-hour duration limit, are run for both animats. Energy and

Potential Energy are initially set to 1. The omparison of the median of survival durations

16

for both sets shows that in ondition A, the animat is able to survive signi(cid:28)antly longer

(p < 0.01, U-test, see Table 1) than the animat in ondition B.

(cid:21)Table 1 around here(cid:21)

In (Girard et al., 2003), ation seletion was only onstrained by the virtual metabolism.

Here, the addition of the topologial navigation system generates a new onstraint of limit-

ing Disorientation. Yet it does not a(cid:27)et the e(cid:30)ieny of ation seletion, as the life span

of animats is enhaned.

4.2 Experiment 2: Changing environment

(cid:21)Figure 4 around here(cid:21)

This experiment takes plae in the 6m

×

6m environment depited in Figure 4, where

the seond Potential Energy resoure is not always present.

4.2.1 New resoures: Coordination of the navigation strategies

In this ase, the seond Potential Energy resoure is not present during the mapping phase,

so that when the animat reahes the (cid:28)rst intersetion, it pereives a new resoure that is

unknown by the topologial navigation system. The topologial and the taxon strategies

are thus ompeting, the (cid:28)rst one suggesting to move to the distant resoure (EP 1) and

the seond to the newly appeared and loser resoure (EP 2). For all tests, the animat is

initially plaed on the same loation shown in Figure 4 and laks Potential Energy (E = 1

and Ep = 0.5). The tests are stopped when the animat ativates the ReloadEP ation.

The ontrol experiment onsisting of ten tests in whih resoure EP 2 is not added,

17

results in a repeatable behavior of the animat: it goes diretly to EP 1 and ativates the

ReloadEP ation when lose enough to EP 1. Three series of (cid:28)fteen tests, with di(cid:27)erent

weightings of the saliene omputations (variations of eqn. 17 in appendix using the weights

of Table 2), are ompared by ounting how many times the animat hose one resoure versus

the other. The results are summarized in Table 2.

(cid:21)Table 2 around here(cid:21)

The (cid:28)rst weighting orresponds to the on(cid:28)guration used in the previous experiment

(eqn. 17). The path planning weight is larger than the taxon strategy one. As a result, the

animat often ignores the new resoure and hooses the memorized one. When the relative

importane of the two strategies is modulated by progressively lowering the path planning

weight, the behavior of the animat is modi(cid:28)ed and an opportunisti behavior, where it

prefers the new and losest resoure, an be obtained.

Consequently, if our ontrol arhiteture does not intrinsially exhibit an opportunisti

or a pure planning behavior, it an easily be tuned to generate the desired balane between

these two extremes.

4.2.2 Exhausted resoures: Forgetting mehanism

In this situation, resoure EP 2 is present during mapping but is removed during the tests.

The animat then has to (cid:16)forget(cid:17) its existene in the map in order to go to the other resoure.

Fifteen tests are arried out, with the animat initially plaed on the same start loation

(see Figure 4) laking Potential Energy (E = 1 and Ep = 0.5). The tests are stopped when

the animat ativates the ReloadEP ation.

18

The animat (cid:28)rst goes to the losest EP resoure oded by the topologial navigation

system: the near but absent EP 2 resoure. The forgetting mehanism (implemented by the

Hebbian rule used to link resoures with loations on the map) allows the animat to (cid:28)nally

leave this area and to reah resoure EP 1. The time neessary to forget EP 2 is estimated

by subtrating the duration of the most diret path leading from the start position to EP 1

via EP 2 (46s) to the duration of eah test. The mean duration is 178s (σ = 78), i.e. 2

minutes and 58 seonds (max value 5 minutes).

It is a bit long (almost 10% of the 33

minutes survival duration with a full harge of Energy ), but it an be redued by simply

modifying the gain of the Hebbian rule.

This shows that the ability to forget, whih is neessary to survive in environments

where resoures are exhaustible, operates orretly.

4.3 Experiment 3: Antagonisti or synergeti internal states

4.3.1 Antagonisti internal states: Fear vs reloading need

(cid:21)Figure 5 around here(cid:21)

A (cid:28)rst experiment is run in an environment (10m

6m) ontaining two EP resoures

×

and a dangerous area bloking diret aess to the losest one (Figure 5). The Dangerous

Areas a(cid:27)et the planning algorithm of the topologial navigation system in an inhibitory

manner. A path planning vetor leading to dangerous areas is omputed, multiplied by the

level of Fear and subtrated to the other planning vetors: the term −

m(DA)

P(DA)

×

is added to the omputation of Plan desribed in eqn. 1.

19

The animat initially laks Potential Energy and its level of Fear is (cid:28)xed (E = 1,

EP < 1, F = 0.2). When the Dangerous Area is absent, the animat systematially hooses

the losest resoure (EP 1). However, when it is present, this inhibits the drive to go

towards the EP 1 resoure and the (cid:28)nal hoie of the EP resoure should thus depend on

the importane of the lak of energy.

(cid:21)Table 3 around here(cid:21)

Two series of 20 tests are arried out in order to indue on(cid:29)its between internal

states depending on Fear and EP , respetively with a moderate (EP = 0.5) and a strong

(EP = 0.1) lak of EP . As illustrated in Table 3, the inhibition generated by the Dangerous

Area in the (cid:28)rst ase is strong enough and the animat, despite the longer route, selets

EP 2. In the seond one, the need for Potential Energy is stronger and the animat, despite

the danger, selets EP 1. These two opposite tendenies are signi(cid:28)antly di(cid:27)erent (Fisher's

exat probability test, p < 0.01).

This experiment shows that the animat may take risks in emergeny situations and

avoid them otherwise. But, more generally, it shows that it an exhibit, in an idential

environmental on(cid:28)guration, di(cid:27)erent behavioral hoies adapted to its on(cid:29)iting internal

needs, an essential property for a motivated animat.

4.3.2 Synergetially interating motivations

(cid:21)Figure 6 around here(cid:21)

This task is inspired by a T-maze experiment proposed in Quoy et al. (2002) in order

to study the behavior generated by the oupling of two motivations. The left branh of the

20

T ontains one EP resoure while the right one ontains both an E and an EP resoure

(Figure 6). The length of the right branh is varied so that the ratio of the right branh

length to the left branh length is 1, 1.5 or 2. The animat is initially plaed in the lower

branh of the T, with a motivation for both E and EP (E = 0.5 and EP = 0.5). The test

stops when the animat ativates the ReloadEP ation. In suh a situation, the animat is

expeted to systematially prefer the right branh, even if it is longer, beause hoosing

the left only satis(cid:28)es the EP need, while hoosing the right an satisfy both E and EP

needs.

(cid:21)Table 4 around here(cid:21)

Three series of (cid:28)fteen tests are arried out with branh length ratio values of 1, 1.5

and 2, with an animat that needs both E and EP . As long as the ratio is not too high,

the umulated ativation generated by the two resoures on the right is higher than the

drive generated by the single EP resoure on the left (Table 4, ratio 1 and 1.5). However,

when the two resoures on the right are too far away, the drive they generate is attenuated

by distane and the animat beomes more and more attrated by the resoure on the left

(Table 4, ratio 2).

The Gaussier et al. (2000) model of navigation integrates the notion of (cid:16)preferred path(cid:17)

by reduing the apparent distane between two nodes of the map when they are often used.

This allows the right branh to beome preferred and thus systematially hosen over time.

Future development of our model should inlude suh a habit learning apability.

21

5 Disussion

The proposed biomimeti model integrates both navigation and ation seletion, in taking

into aount the spei(cid:28)ities of both survival onstraint and variety of navigation strategies.

Simulations in benhmark environments validate 1) the survival advantage of using path

planning strategies, 2) the bene(cid:28)ts of simultaneously using taxon and planning strategies

along with the neessity of being able to forget when operating in hanging environments,

and 3) the apability of the model to behave adaptively in ase of on(cid:29)iting and synergeti

motivations.

5.1 From Rattus rattus...

How the brain oordinates the interfae between spatial maps, motivation, ation seletion

and motor ontrol systems is of timely interest. The rat brain is widely investigated in this

purpose, but many issues remain to be lari(cid:28)ed. By synthesizing observed mehanisms in

a behaving arti(cid:28)ial system, our work helps to formulate several questions.

For example, our model points out limitations about the urrent neurobiologial knowl-

edge onerning the atual role of NA ore hannels: do they represent, as in our model

and in e.g., Strösslin (2004), ompeting diretions of movements? In Experiment 2.1, the

level of opportunism is (cid:28)xed and does not adapt to hanging onditions (whereas taxon

navigation is less reliable in poor lighting onditions), as the ventral loops selets one di-

retion taking into aount all the navigation strategies. This ould be hanged by having

it seleting among the strategies the most adapted one before a dorsal loop selets the

22

diretion of motion based on the hosen strategy suggestion only. Suh oding has reently

reeived support by the work of Mulder et al. (2004), on the basis of eletrophysiologial

reordings in hippoampal output strutures assoiated with the NA and a nuleus of the

dorsal stream (ventromedial audate nuleus). Another and more omplex role may also

be onsidered: NA ore ould interfae goals, their loation, their amount and the or-

responding motivations with information oming from several neural strutures like other

limbi strutures or CBGTC loops (Dayan and Balleine, 2000).

Likewise, our model questions the putative substrates of interations between CBGTC

loops and their mode of operation, a sub jet of ative urrent researh. We may have im-

plemented the trans-subthalami hypothesis in an exaggerated manner. In fat the overlap

of STN pro jetions from various loops is rather limited (Kolomiets et al., 2003), while in

our model they extensively reah the whole output of the ventral loop. This hoie was in-

deed onvenient for the role attributed here to the dorsal and ventral hannels, respetively

oding for immobile and mobile ations. Reent results relative to interations at the level

of BG output pro jetions to dopaminergi nulei in rats (Mailly et al., 2003) shed a new

light on the dopamine hierarhial pathway and ould be the basis of an alternative model.

In the GPR, varying the dopamine level a(cid:27)ets diretly the ability to selet, therefore, the

possibility that one loop may modulate the dopamine level of another one ould be the

basis of an alternative mehanism for a loop to shunt another loop. One annot (cid:28)nally

exlude the possibility that the resolution of seletion on(cid:29)its in the CBGTC loops is not

only managed in the BG but also in downstream brainstem strutures, for example in the

retiular formation (Humphries et al., this issue).

23

5.2 ...to Psikharpax

In Experiment 1, the planning animat (ondition A) sometimes dies beause of a imperfet

hand-tuning of the saliene omputations, whih auses it to stop to reload too far away

from resoures. The basal ganglia, in interation with the dopaminergi system, is supposed

to be the neural substrate for reinforement learning. In order to avoid suh problems in

the future, we are now adding suh a mehanism of automati optimization of saliene

omputations to our model (Khamassi et al., 2004).

As mentioned in introdution, this work ontributes to the Psikharpax pro jet, whih

aims at building an arti(cid:28)ial rat (Filliat et al., 2004). As it evolves, this arti(cid:28)ial rat

will be endowed with more than the few motivations taken into aount here, in the aim

to improve the atual autonomy of urrent robots, often devoted to a single task. The

development of polyvalent artifats working in natural environments is indeed promising

for many appliations in the home or in the o(cid:30)e, as well as future spae programs with

unmanned missions. Our work also helps assessing the operational value of the biomimeti

models used for this purpose.

24

A Appendix: Mathematial model desription

A.1 GPR struture

Ativation (a) of every neuron of the model:

τ

da
dt

= I

a

−

(3)

where: I: input of the neuron, τ : time onstant (τ = 25ms). Corresponding output

(y):

y =

0 if a < ǫ

(a

m

×

−

ǫ)

if ǫ

≤

a < ǫ + 1/m

(4)

1 if ǫ + 1/m

a

≤






Values of ǫ and m for eah nuleus in Table 5.

(cid:21)Table 5 around here(cid:21)

In eah module (D1 and D2 striatum subparts, STN, EP/SNr, GP, VL, TRN and

ortial feedbak), the input of eah hannel i is de(cid:28)ned by the equations 5 to 14, where

N : number of hannels, Si : saliene of hannel i, λ: dopamine level (0.2).

I i
D1 = (1 + λ)Si

I i
D2 = (1

λ)Si

−

N

−

X
j=0
j6=i

N

−

X
j=0
j6=i

yi
D1

yi
D2

25

(5)

(6)

In our model of the ventral loop, lateral inhibitions (sum terms in eqn. 5 and 6) inrease

with the angular di(cid:27)erene between two hannels. They are replaed in the ventral loop

by the following LI term:

LI i =

N

X
j=0
j6=i

i

|

−

j

|

mod(N/2)
N/2

×

yi
(D1 or D2)

I i
ST N = Si

yi
GP

−

I i
EP =

yi
D1 −

−

0.4 yi

GP + 0.8

N

X
j=0

yj
ST N

(7)

(8)

(9)

The trans-subthalami pathway is modelled by a modi(cid:28)ed input for the ventral EP/SNr

(v and d stand for ventral and dorsal ):

I i
EP v =

−

yi
D1v −
N

+ 0.8

X
j=0

0.4 yi

GP v

yj
ST N v + 0.4

N

X
j=0

yj
ST N d

I i
GP =

yi
D2 + 0.8

−

N

X
j=0

yj
ST N

V L = yi
I i

P −

yi
EP −

0.13

yj
T RN

N

X
j=0
j6=i

T RN = yi
I i

V L + yi
P

26

(10)

(11)

(12)

(13)

I i
P = yi

V L

(14)

A.2 Saliene omputations

The modi(cid:28)ation to the GPR model proposed in Girard et al. (2003) onsisted in allowing,

for the omputation of salienes, the use of sigma-pi neurons and non-linear transfert

funtion applied to the inputs. This was kept in the present model and is the origin of the

square roots and multipliations in the following equations.

A.2.1 Experiments 1 and 2

Dorsal loop salienes (E and EP reloading ations):

SE = 0.4

PE + 1.2

A(E)

×

×

m(E)

×

+ 0.6

×

mP rox(E)

m(E)

×

SEP = 0.4

×

PEP + A(EP )

m(EP )

×

+ 0.2

×

mP rox(EP )

m(EP )

×

(15)

(16)

27

Ventral loop saliene for eah diretion i:

Si = 0.2

Pi + Wplanp

×

Plani

m(E)

+ 0.55qProx(E)i ×
+ W Ep

taxonqProx(EP)i ×

m(EP )

(17)

+ 0.4

×

BKAi

×

m(BKA)

+ Expi ×

(0.25

+ 0.05

+ 0.05

(1

(1

−

−

×

×

mP rox(EP ))

m(EP )

×

mP rox(E))

m(E))

×

Where Wplan and W Ep

taxon are respetively set to 0.65 and 0.55, exept in experiment

4.2.1, where they take the values reorded in Table 2.

28

A.2.2 Experiment 3.1

Salienes of the dorsal loop omputed as in experiments 1 and 2. Ventral salienes modi(cid:28)ed

to inlude the avoidane of dangerous areas:

Si = 0.2

Pi + 0.45

Plani

p

×

+ 0.35qProx(E)i ×

m(E)

+ 0.35qProx(EP)i ×

m(EP )

+ 0.19

(1

×

−

Prox(DA)i)

m(DA)

×

(18)

+ 0.4

×

BKAi

×

m(BKA)

+ Expi ×

(0.05

+ 0.05

+ 0.05

(1

(1

−

−

×

×

mP rox(EP ))

m(EP )

×

mP rox(E))

m(E))

×

A.2.3 Experiment 3.2

Experiment 3.2 showed that the weight of the dorsal omputations had to be lowered:

SE = 0.4

PE + 0.9

A(E)

×

×

m(E)

×

+ 0.1

×

mP rox(E)

m(E)

×

SEP = 0.4

PEP + 0.9

A(EP )

×

×

m(EP )

×

+ 0.1

×

mP rox(EP )

m(EP )

×

29

(19)

(20)

The ventral saliene omputations from experiments 1 and 2 risked stopping the animat

too far from resoures. As this problem arose systematially in experiment 3.2, the term

(0.65√Plani) term was hanged for (0.55√Plani

(1

−

×

mP rox(E))

(1

−

×

mP rox(EP )).

Aknowledgments

We thank Sidney Wiener for valuable disussions and proofreading of the manusript.

This researh has been funded by the LIP6 and the Pro jet Robotis and Arti(cid:28)ial Entities

(ROBEA) of the Frenh Centre National de la Reherhe Sienti(cid:28)que.

Referenes

Alexander, G. E., DeLong, M. R., and Strik., P. L. (1986). Parallel organization of

funtionally segregated iruits linking basal ganglia and ortex. Annual Review of

Neurosiene, 9:357(cid:21)381.

Arleo, A. and Gerstner, W. (2000). Spatial ognition and neuro-mimeti navigation: a

model of hippoampal plae ell ativity. Biologial Cybernetis, 83:287(cid:21)299.

Ashby, W. R. (1952). Design for a brain. Chapman and Hall.

Chevalier, G. and Deniau, M. (1990). Disinhibition as a basi proess of striatal funtions.

Trends in Neurosienes, 13:277(cid:21)280.

30

Dayan, P. and Balleine, B. (2000). Reward, motivation and reinforement learning. Neuron,

36:285(cid:21)298.

Dennett, D. (1978). Why not a whole iguana? Behavioral and Brain Sienes, 1:103(cid:21)104.

Filliat, D. (2001). Cartographie et estimation globale de la position pour un robot mobile

autonome. PhD thesis, LIP6/AnimatLab, Université Paris 6, Frane.

Filliat, D., Girard, B., Guillot, A., M.Khamassi, Lahèze, L., and Meyer, J.-A. (2004). State

of the arti(cid:28)ial rat psikharpax. In Shaal, S., Ijspeert, A., Billard, A., Vijayakumar, S.,

Hallam, J., and Meyer, J.-A., editors, From Animals to Animats 8, pages 2(cid:21)12. MIT

Press, Cambridge, MA.

Filliat, D. and Meyer, J.-A. (2003). Map-based navigation in mobile robots. i. a review of

loalization strategies. Journal of Cognitive Systems Researh, 4(4):243(cid:21)282.

Gaussier, P., Leprêtre, S., Quoy, M., Revel, A., Joulain, C., and Banquet, J.-P. (2000).

Experiments and models about ognitive map learning for motivated navigation.

In

Demiris, J. and Birk, A., editors, Interdisiplinary Approahes to Robot Learning, vol-

ume 24 of Robotis and Intel ligent Systems, pages 53(cid:21)94. World Sienti(cid:28).

Girard, B., Cuzin, V., Guillot, A., Gurney, K. N., and Presott, T. J. (2003). A basal

ganglia inspired model of ation seletion evaluated in a roboti survival task. Journal

of Integrative Neurosiene, 2(2):179(cid:21)200.

Girard, B., Filliat, D., Meyer, J.-A., Berthoz, A., and Guillot, A. (2004). An integration of

two ontrol arhitetures of ation seletion and navigation inspired by neural iruits in

31

the vertebrate: the basal ganglia. In Bowman, H. and Labiouse, C., editors, Connetion-

ist Models of Cognition and Pereption II, volume 15 of Progress in Neural Proessing,

pages 72(cid:21)81. World Sienti(cid:28), Singapore.

Guazzelli, A., Corbaho, F. J., Bota, M., and Arbib, M. A. (1998). A(cid:27)ordanes, motivations

and the worls graph theory. Adaptive Behavior: Speial Issue on biologial ly inspired

models of spatial navigation, 6(3/4):435(cid:21)471.

Gurney, K., Presott, T. J., and Redgrave, P. (2001a). A omputational model of ation

seletion in the basal ganglia. i. a new funtional anatomy. Biologial Cybernetis, 84:401(cid:21)

410.

Gurney, K., Presott, T. J., and Redgrave, P. (2001b). A omputational model of a-

tion seletion in the basal ganglia. ii. analysis and simulation of behaviour. Biologial

Cybernetis, 84:411(cid:21)423.

Joel, D. and Weiner, I. (1994). The organization of the basal ganglia-thalamoortial

iruits: open interonneted rather than losed segregated. Neurosiene, 63:363(cid:21)379.

Joel, D. and Weiner, I. (2000). The onnetions of the dopaminergi system with the stria-

tum in rats and primates: An analysis with respet to the funtional and ompartmental

organization of the striatum. Neurosiene, 96(3):452(cid:21)474.

Kelley, A. E. (1999). Neural integrative ativities of nuleus aumbens subregions in

relation to learning and motivation. Psyhobiology, 27:198(cid:21)213.

32

Khamassi, M., Girard, B., Berthoz, A., and Guillot, A. (2004). Comparing three riti

models of reinforement learning in the basal ganglia onneted to a detailed ator part

in a s-r task. In Groen, F., Amato, N., Bonarini, A., Yoshida, E., and Kröse, B., editors,

Proeedings of the Eighth International Conferene on Intel ligent Autonomous Systems

(IAS8), pages 430(cid:21)437. IOS Press, Amsterdam, The Netherlands.

Kolomiets, B. P., Deniau, J. M., Glowinski, J., and Thierry, A.-M. (2003). Basal ganglia

and proessing of ortial information:

funtional interations between trans-striatal

and trans-subthalami iruits in the substantia nigra pars retiulata. Neurosiene,

117(4):931(cid:21)938.

Kolomiets, B. P., Deniau, J.-M., Mailly, P., Glowinski, A. M. J., and Thierry, A.-M.

(2001). Segregation and onvergene of information (cid:29)ow through the ortio-subthalami

pathways. Journal of Neurosiene, 21(15):5764(cid:21)5772.

Maes, P. (1991). A bottom-up arhiteture for behavior seletion in an arti(cid:28)ial reature.

In Meyer, J.-A. and Wilson, S., editors, From Animals to Animats 1, pages 478(cid:21)485.

MIT Press, Cambridge, MA.

Mailly, P., Charpier, S., Menetrey, A., and Deniau, J.-M. (2003). Three-dimensional orga-

nization of the reurrent axon ollateral network of the substantia nigra pars retiulata

neurons in the rat. Journal of Neurosiene, 23(12):5247(cid:21)5257.

Martin, P. D. and Ono, T. (2000). E(cid:27)ets of reward antiipation, reward presentation, and

33

spatial parameters on the (cid:28)ring of single neurons reorded in the subiulum and nuleus

aumbens of freely moving rats. Behavioural Brain Researh, 116(1):23(cid:21)28.

Maurie, N., Deniau, J.-M., Glowinski, J., and Thierry, A.-M. (1999). Relationships be-

tween the prefrontal ortex and the basal ganglia in the rat: physiology of the ortio-

nigral iruits. Journal of Neurosiene, 19(11):4674(cid:21)4681.

Maurie, N., Deniau, J.-M., Menetrey, A., Glowinski, J., and Thierry, A.-M. (1997). Po-

sition of the ventral pallidum in the rat prefrontal ortex-basal ganglia iruit. Neuro-

siene, 80(2):523(cid:21)534.

Meyer, J.-A. and Filliat, D. (2003). Map-based navigation in mobile robots. ii. a review

of map-learning and path-planning strategies. Journal of Cognitive Systems Researh,

4(4):283(cid:21)317.

Montes-Gonzalez, F., Presott, T. J., Gurney, K. N., Humphries, M., and Redgrave, P.

(2000). An embodied model of ation seletion mehanisms in the vertebrate brain. In

Meyer, J.-A., Berthoz, A., Floreano, D., Roitblat, H., and Wilson, S. W., editors, From

Animals to Animats 6, volume 1, pages 157(cid:21)166. The MIT Press, Cambridge, MA.

Mulder, A. B., Tabuhi, E., and Wiener, S. I. (2004). Neurons in hippoampal a(cid:27)erent

zones of rat striatum parse routes into multi-pae segments during maze navigation.

European Journal of Neurosiene, 19(7):1923(cid:21)1932.

O'Keefe, J. and Nadel, L. (1978). The Hippoampus as a Cognitive Map. Clarendon Press,

Oxford.

34

Parent, A. and Hazrati, L.-N. (1995). Funtional anatomy of the basal ganglia. ii. the plae

of subthalami nuleus and external pallidum in basal ganglia iruitry. Brain Researh

Reviews, 20:128(cid:21)154.

Presott, T. J., Redgrave, P., and Gurney, K. N. (1999). Layered ontrol arhitetures in

robot and vertebrates. Adaptive Behavior, 7(1):99(cid:21)127.

Quoy, M., Laroque, P., and Gaussier, P. (2002). Learning and motivational ouplings

promote smarter behaviors of an animat in an unknown world. Robotis and Autonomous

Systems, 38:149(cid:21)156.

Redgrave, P., Presott, T. J., and Gurney, K. (1999). The basal ganglia: a vertebrate

solution to the seletion problem? Neurosiene, 89(4):1009(cid:21)1023.

Rosenblatt, J. K. and Payton, D. (1989). A (cid:28)ne-grained alternative to the subsumption

arhiteture for mobile robot ontrol. In Proeedings of the IEEE/INNS International

Joint Conferene on Neural Networks, volume 2, pages 317(cid:21)324. Washington, DC.

Seamans, J. K. and Phillips, A. G. (1994). Seletive memory impairments produed by

transient lidoaine-indued lesions of the nuleus aumbens in rats. Behavioral Neuro-

siene, 108:456(cid:21)468.

Seth, A. K. (1998). Evolving ation seletion and seletive attention without ations,

attention, or seletion. In Pfeifer, R., Blumberg, B., Meyer, J.-A., and Wilson, S. W.,

editors, From Animals to Animats 5, pages 139(cid:21)147. The MIT Press, Cambridge, MA.

35

Strösslin, T. (2004). A Connetionist Model of Spatial Learning in the Rat. PhD thesis,

EPFL (cid:21) Swiss Federal Institute of Tehnology, Swiss.

Thierry, A.-M., Gioanni, Y., Dégénetais, E., and Glowinski, J. (2000). Hippoampo-

prefrontal ortex pathway: anatomial and eletrophysiologial harateristis. Hip-

poampus, 10:411(cid:21)419.

Zahm, D. S. and Brog, J. S. (1992). Commentary: on the signi(cid:28)ane of the ore-shell

boundary in the rat nuleus aumbens. Neurosiene, 50:751(cid:21)767.

36

Table 1: Comparison (U-test) of experiments testing median survival duration of animats

in onditions A (taxon navigation only) and B (taxon and topologial navigation).

Durations (s) Median Range

A

14431.5

2531 : 17274

B

4908.0

2518 : 8831

U test

U = 15

p < 0.01

37

Table 2: Resoure hoie depending on the relative weighting of the two navigation strate-

gies in the saliene omputation. Wplan and W Ep

taxon : weights related to planning and taxon

navigation strategies respetively (see eqn. 17).

Weights

Choies

Wplan WEp

taxon EP1 EP2

0.65

0.55

13

2

0.55

0.55

7

8

0.45

0.55

2

13

38

Table 3: Resoure hoie depending on the initial EP level.

Internal

Inidene of

state

hoies

F

EP

EP1

EP2

0.2

0.1

13

7

0.2

0.5

2

18

Fisher's test

p<

0.01

39

Table 4: Branh hoies depending on the length ratio.

Inidene of

(cid:28)rst hoie

Ratio Left Right

1

3

12

1.5

4

11

2

8

7

40

Table 5: Parameters of the transfer funtions of the GPR model.

GPR Module

ǫ m

D1 Striatum

0.2

1

D2 Striatum

0.2

1

STN

-0.25

1

GP

-0.2

1

EP/SNr

-0.2

1

Ctx

0

1

TRN

0

0.5

VL

-0.8

0.62

41

Figure Captions

Figure 1: The GPR model. Nulei are represented by boxes, eah irle in these nulei rep-

resents an arti(cid:28)ial leaky-integrator neuron. On this diagram, three hannels are ompeting

for seletion, represented by the three neurons in eah nuleus. The seond hannel is rep-

resented by gray shading. For larity, the pro jetions from the seond hannel neurons only

are represented, they are similar for the other hannels. White arrowheads represent exi-

tations and blak arrowheads, inhibitions. D1 and D2: neurons of the striatum with two

respetive types of dopamine reeptors; STN: subthalami nuleus; GP: globus pallidus;

EP/SNr: entopedonular nuleus and substantia nigra pars retiulata; VL: ventrolateral

thalamus; TRN: thalami retiular nuleus. Dashed boxes represent the three subdivisions

of the model proposed by its authors (Seletion, Control of seletion and thalamo-ortial

feedbak or TCF), note that these subdivisions appear on the simpli(cid:28)ed sketh of Figure 2.

Figure 2: Final model struture. Input variables are exhaustively listed, 36-omponent

vetors are in bold type. The exitatory pro jetions from the STN of the dorsal loop to the

EP/SNr of the ventral loop, whih are the substrate for loops oordination, are highlighted.

Figure 3: Experiment 1 environment. Initial position and orientation are represented

by the shemati animat. E : Energy resoure; EP : Potential Energy resoure.

Figure 4: Experiment 2 environment. Initial position and orientation are represented by

the shemati animat. EP : Potential Energy resoure; EP 2 is absent in some experiments,

see text.

Figure 5: Experiment 3 environment. Initial position and orientation are represented

42

by the shemati animat. EP 1,2: Potential Energy resoures; DA: dangerous area.

Figure 6: The three environments of experiment 4. The ratio of the right branh

length to the left branh length varied between 1 and 2. Initial position and orientation

is represented by the shemati animat. EP 1,2: Potential Energy resoures; E : Energy

resoure.

43

Dopamine

D2 Striatum

GP

Ctx

External
variables

Internal
variables

Salience
Computation
of Channel 2

Control

STN

Selection

VL

TRN

TCF

Disinhibition
of channel 2
for action

Dopamine

D1 Striatum

EP/SNr

Figure 1:

44

Motivations:
m(danger)
m(BKA)
m(E)
m(EPot)

Sensors:

A(E), A(Ep)
mProx(E), mProx(Ep)
Prox(E), Prox(Ep)
raw sensors

Control

TCF

Dorsal
Loop
(GPR)

salience
computations

STN

Selection

Non locomotor
actions

ReloadE
ReloadEp

Locomotor
actions

36 directions

2 channels

Ventral
Loop
(GPR)

Control

TCF

Selection

36 channels

Topological
navigation
system
(Filliat)

Plan
Expl
BKA

salience
computations

Figure 2:

45

Figure 3:

46

Figure 4:

47

Figure 5:

48

Figure 6:

49"
"Multi-Sensor Fusion Method using Dynamic Bayesian Network for Precise
  Vehicle Localization and Road Matching","  This paper presents a multi-sensor fusion strategy for a novel road-matching
method designed to support real-time navigational features within advanced
driving-assistance systems. Managing multihypotheses is a useful strategy for
the road-matching problem. The multi-sensor fusion and multi-modal estimation
are realized using Dynamical Bayesian Network. Experimental results, using data
from Antilock Braking System (ABS) sensors, a differential Global Positioning
System (GPS) receiver and an accurate digital roadmap, illustrate the
performances of this approach, especially in ambiguous situations.
",http://arxiv.org/pdf/0709.1099v1,1,"Multi-Sensor Fusion Method using Dynamic Bayesian Network for Precise 
Vehicle Localization and Road Matching  

Cherif Smaili1, Maan E. El Najjar2, François Charpillet1 
1LORIA-INRIA Lorraine - MAIA Team Campus Scientifique BP 239 54506 Vandoeuvre-lés-
Nancy, France 
2LAGIS-CNRS UMR 8146 Polytech'Lille, Avenue Paul Langevin 59655 Villeneuve d'Ascq Cedex 
France 
smailic@loria.fr 

Abstract 

systems.  Managing 

This  paper  presents  a  multi-sensor  fusion  strategy 
for a novel road-matching method designed to support 
features  within  advanced 
real-time  navigational 
driving-assistance 
multi-
hypotheses  is  a  useful  strategy  for  the  road-matching 
problem.  The  multi-sensor  fusion  and  multi-modal 
estimation  are  realized  using  Dynamical  Bayesian 
Network.  Experimental  results,  using  data  from  Anti-
lock  Braking  System  (ABS)  sensors,  a  differential 
Global  Positioning  System  (GPS)  receiver  and  an 
accurate  digital  roadmap,  illustrate  the  performances 
of this approach, especially in ambiguous situations. 

1. Introduction 

Autonomous  Vehicles  currently  hold  the  attention  of 
many  researchers  because  they  can  provide  solutions  in 
many  applications  related  to  Intelligent  Transportation 
system. One example of such a system is the transport of 
passengers in urban environments using a CyCab [1]. For 
navigational  needs  the  vehicle  first  needs  to  know  its 
position  on  the  road  network,  and  then  to  retrieve 
attributes  from  the  appropriate  databases.  Examples  of 
attributes are maximum authorized speed, the width of the 
road,  the  presence  of  landmarks  for  precise  localization, 
etc.  Unfortunately,  the  precise  localization  on  a  digital 
map  cannot  be  guaranteed  because  there  will  often  be 
errors  in  the  estimation  of  position  arising  from  sensor 
imprecision  and  because  the  map  represents  a  deformed 
view  of the real world: roads are represented by points – 
nodes  and  shaping  points-  that  describe  the  geometry  of 
the center line.  

Vehicle localization on a map has two meanings in the 
literature in this domain. In many works, [2], [3], [4] and 
[5]  it  refers  to  the  projection  of  the  absolute  position 
estimate onto a segment of the road network stored in the 
database.  In  this  case,  the  vehicle  is  localized  when  the 
curvilinear  abscissa  along  the  segment  are  known  from 

the  starting  node.  These  “arc-matching”  methods 
therefore introduce geometric distortions, since the model 
of the world is a set of segments, usually with a 10 meters 
absolute  error and a 1 meter relative error. Alternatively, 
vehicle  localization  can  refer  to  absolute  localization  in 
the  map reference  frame.  In  this  case,  the localization  of 
the vehicle does not need a projection onto the segments 
the  database.  Absolute 
in 
representing 
localization can be very useful for the following reasons. 
In  several  kinds  of  databases,  including  those  of  the 
National French Institute of Geography (IGN), attributes, 
instead  of  being  attached  to  the  arcs  representing  the 
roads, can be stored in the database as point objects  with 
an absolute position.  

road 

the 

The  approach  presented  in  this  paper  is  an  absolute 
localization  method.  The  global  positions  provided  by  a 
GPS receiver are projected onto the map frame. The goal 
is  to  select  the  most  likely  segment(s)  from  a  set  of 
segments  close  to  the  estimation  of  the  vehicle  position. 
Nowadays,  since  the  geometry  of  roadmaps  is  more  and 
more detailed, the number of segments representing roads 
is increasing. The road managing module is an important 
stage  in  the  vehicle  localization  process  because  the 
robustness  of  the  localization  depends  mainly  on  this 
stage.  In  order  to  focus  in  this  point,  an  accurate  map 
Géoroute V2 provided by the IGN was used in this work.  
In  order  to  develop  our  approach,  it  is  important  to 
estimate  continuously  the  pose  –  position  and  heading  – 
of the vehicle in the frame of the map using GPS, because 
of  its  affordability  and  convenience.  However,  GPS 
suffers 
in  urban 
environments,  under  bridges,  tunnels  or  in  forests.  GPS 
can thus be seen as an intermittently-available positioning 
system  that  needs  to  be  backed  up  by  a  dead-reckoning 
system  [7].  In  this  work,  a  low-cost  odometric  method 
based on the use of encoders attached to the rear wheels is 
proposed. A dead-reckoned estimated pose is obtained by 
integrating the elementary rotations of the wheels starting 
from  a  known  pose.  The  multisensor  fusion  of  GPS  and 
odometry  is  performed  by  a  Switching  Kalman  Filter 
in 
(SKF).  This  kind  of  formalism 

from  satellite  outages  occurring 

is  also  useful 

 
 
 
 
 
 
 
the 
quantifying 
estimated pose.  

imprecision  associated  with  each 

The outline is as follows. In section 2, the architecture 
of  the  road-matching  method  is  described.  In  section  3, 
we  present  a  short  introduction  of  Bayesian  networks. 
Section 4 describes the network model for road-matching. 
Next section, we evaluate the potential of our approach by 
presenting a real data results. Finally, concluding remarks 
are given in section 6. 

2. Architecture of the road-matching strategy 

The  road-matching  method  described  in  this  section 
relies  on  Bayesian  networks.  The  proposed  approach  is 
described in Figure 1. Firstly, the algorithm combines the 
ABS measurements with a GPS position, if it is available. 
Then, using this estimate, segments around the estimation 
are  selected  in  a  radius  of  30  meters  by  using  a 
Geographical  Information  System  (GIS)-2D.  Using  these 
segments,  map  observations  are  built  and  merged  with 
other  data  sensors  using  a  method  based  on  Dynamic 
Bayesian Network.  

DGPS 

Odometry 

ABS wheel 
Sensors 

M ulti-sensor 
Fusion SKF 

Road 
 E xtraction 

GIS

- Multi-estimates with probability of each one 

i 

X k

M ap M atched 
poses 

Figure 1: Synoptic of the road-matching method 

2.1  Localization  and  heading  estimation  by 
combining odometry and GPS 

Consider a car-like vehicle with front-wheel drive. The 
mobile  frame  is  chosen  with its  origin  M  attached to  the 
center  of  the  rear  axle.  The  x-axis  is  aligned  with  the 
longitudinal axis of the car (see Figure 2). 

The  vehicle’s  position  is  represented  by  the  (xk,yk) 
Cartesian coordinates of M in a world frame. The heading 
angle  is  denoted  θk.  If  the  road  is  perfectly  planar  and 
horizontal,  and  if  the  motion  is  locally  circular,  the 
motion model can be expressed as [8]: 

=

X

k









x

k

+

1

y

k
θ
k

+

1

+

1

=

=

=

+

+

x

k
y

k

δ
s
δ
s

δθ
+
θ

k

.

cos(

.

sin(

δθ
+
θ

k

δθ
+
θ

k

)2

)2

                 (1) 

Where  δs  is  the  length  of  the  circular  arc  followed 
by  M  and  δθ   is  the  elementary  rotation  of  the  mobile 
frame.  These  values  are  computed  using  the  ABS 
measurements  of  the  rear  wheels.  Let  denote  Xk  the 
state vector containing the pose. 

 M 

 y0

 yk

 M 

 θk 

 W  

 xk

 x0 

Figure 2: The mobile frame attached to the car 

2.2  Cartographical  and  GPS  observation 
equation 

A correction of the odometric estimation is performed 
by the GPS information. When the GPS satellites signal is 
blocked by buildings or tunnels, the odometric estimation 
is  used  to  select  the  segments  all  around  the  estimation 
from  the  cartographical  database.  The  cartographical 
observations  can  be  obtained  by  projections  onto  the 
segments. If the orthogonal projection onto line does not 
make  part  of  the  segment,  the  closer  extremity  is  used 
(see Figure 3). When several segments are candidates, the 
cartographical observation function is a non-linear multi-
modal observation. Considering a Gaussian distribution of 
noise  to  represent  the  uncertainty  zone  all  around  a 
segment,  so  the  multi-modal  observation  is  a  multi-
Gaussian observation one. 

T1      T2      T3      T4 

Figure 3: Most likely segments extracted from 
the database 

The  observation  equation  of  the  segment  segi  can  be 
written: 

  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Y

segi
carto

=

x
carto
y

carto

cap

carto















=

001
010
100













⋅







x


y


θ


+

β

carto

Where  (xcarto,  ycarto)  is  the  orthogonal  projection  onto 

each segments and capcarto is the segment heading. 

To represent the error of the cartographical observation 
in the SKF formalism, we choose a Gaussian distribution 
of  the  uncertainty  zone  all  around  the  segment.  So  this 
error can be represented with an ellipsoid which encloses 
the road (we  choose to use an ellipsoid because it is just 
the  available  model).  This  ellipsoid  has  its  semi-major 
axis in the length of the segment and its semi-minor axis 
equals to the width of the road [8] (see Figure 4). 

Uncertainty zone around 
segment 

Ν((xh,yh,θh),Qseg) 

         Segment 

σ
E
xh

σ
E
yh

(xh,yh) 

E

hθσ

R 

Figure 4: Ellipsoidal of probability construction 
representing zone around a segment for 
horizontal segment i.e. parallel with the east 
axes 

The 

third  axis  of 

the  ellipsoid  represents 

the 
uncertainty  of  the  estimation  of  the  segment.  This 
uncertainty 
the 
cartographical  database.  The  covariance  matrix  of  the 
cartographical observation error can be written: 

the  relative  error  of 

is  related 

to 

carto
Q
k

=

σ
2
hx
,

Q
hxy
,
0







Q
hxy
,
σ
2
hy
,
0

0

0
θσ
2
,

h







The  GPS  position  measurement  provides  the  GPS 
observation  (xgps,  ygps).  The  GPS  measurement  error  can 
be  provided  also  and  in  real  time  using  the  Standard 
National  Marine  Electronics  Association 
(NMEA) 
sentence  ""GPGST""  given  by  the  Trimble  AgGPS132 
receiver  which  has  been  used  in  the  experiments. 
Therefore,  the  GPS  noise  is  not  stationary.  The  non 
stationary  of  the  GPS  measurements  noise  affect  the 
observation model. With each measurement provided, the 

GPS provide it with his noise in the sequence GPGST in 
the standard NMEA. 

gps

kQ : covariance matrix of the GPS error where  

σ
2
,
x

,

xy

gps

gps

=

Q






gps
Q
k

Q
xy
σ
2
,
y





k
The observation equation can be written: 
x


y


θ


001
=



gps
y

010

















gps





Y
1

=

gps

gps

x

⋅

,

+

β

gps

3. Bayesian Networks 

A Bayesian Network (BN) is a graph with probabilities 
for representing random variables and their dependencies. 
It  efficiently  encodes  the  joint  probability  distribution 
(JPD)  of  a  set  of  variables.  Its  nodes  represent  random 
variables and its arcs represent dependencies between the 
random  variables  encoded  by  conditional  probabilities. 
Afterwards,  a  BN  is  written  as  a  directed  acyclic  graph 
G=(E,  W)  with  W={X1,…,  XN}  as  the  set  of  nodes,  and 
(Xi,Xj)∈  E,  the  set  of  edges,  if  Xi  ∈  Pa(Xj).  Normally  an 
edge is drawn from Xi to Xj if Xi has a direct influence on 
Xj. For more detailed in Bayesian Networks see [9] [10]. 

The  joint  probability  distribution  of  random  variables  
S= {X1,…,XN} in a BN is calculated by the multiplication 
of the local conditional probabilities of all the nodes. The 
(JPD) of S is given as follows: 
N
∏

(
XP

(
Xp

,...,

Pa

))

X

X

=

)

(

/

1

N

i

i

=
i
1
A Dynamic Bayesian network (DBN) is a BN used to 
model a temporal stochastic process. It can be created by 
specifying  network  (structure  and  parameters)  for  two 
consecutive  ""time  slices"",  and  then  ""unrolling""  it  into  a 
static network of the required size. 

DBNs  generalize  two  well-known  signal  modelling 
tools:  Kalman  filters  for  continuous  state  linear  dynamic 
system  (LDS)  and  Hidden  Markov  Models  (HMMs)  for 
classification  of  discrete  state  sequences.  It  has  been 
shown  that  estimation  in  (LDSs)  and  inference  in 
(HMMs) are special cases of inference in DBNs [11]. The 
focus  of  this  paper  is  on  a  subclass  of  DBNs  models 
called  Switching  Linear  Systems  or  Switching  Kalman 
Filter. 

3.1 Switching Kalman Filter 

Switching Kalman filter is a subclass of DBN and this 
type  of  network  is  useful  for  modeling  piece-wise  linear 
behavior  (one  way  of  approximating non-linear models), 
or multiple type or ""mode"" of behavior [11]. 

Consider a dynamical system whose parameters evolve 
in time according to some known model. This system can 

 
 
 
 
 
 
 
                                     
 
 
 
 
 
 
be  described  using  the  following  set  of  state-space 
equations: 

=

X

t

XA
t

− 1

t

+

v

t

Y

=

XC
t

+

w

t

t

t
This model is called Linear Dynamical System (LDS), 
where Xt ∈ ℜN is the hidden state variable at time t, Yt ∈ 
ℜM  is  the  observation  at  time  t,  and  vt~N(0,Qt)  and 
wt~N(0,Rt)  are 
independent  Gaussian  noise.  The 
parameters  of  model:  At,Ct,Qt  and  Rt  are  assumed  to  be 
time-invariant. Unfortunately, most systems are not linear 
and  are  subject  to  non-Gaussian  noise.  One  approach  to 
this  problem  and  one  we  take  in  this  paper,  is  to  switch 
among  K  different  linear  models  or  take  some  linear 
combination of them (see Figure 5)[12].  

S1 

S2 

X1 

X2 

Sk 

Sk 

Y1 

Y2 

Yk 

Figure 5:  A switching Kalman filter 

The  variables  St  are  discrete  and  the  variables  Xt 
and  Yt  are  continuous.  Other  observations  can  be 
introduced  in  this  model.  The  conditional  probability 
distributions for this model are as follows: 

P (Xt=xt/Xt-1=xt-1, St=i) =N (Axt-1+µi, Qi) 
P (Yt=y/Xt=xt)=N (Cxt+µY, R) 
P (St=j/St-1=i) =B (i,j) 

An  important  issue  in  BN  is  the  computation  of 
posterior  probabilities  of  variables  given  observations. 
Several researchers  have  been  developed  to  compute  the 
exact  and/or  the  approximate  inference  algorithms  for 
different  distributions.  The  most  commonly  used  to 
compute  the  exact  inference  algorithm  for  discrete 
Bayesian Networks is known as the JLO1 algorithm [11]. 
The  JLO  algorithm  is  a  recursive  message  passing 
algorithm  that  works  on  the  junction  tree  of  the  BN. 
Namely, we need to find the posterior: P (Xt,St/ Yt)  in the 
case of switching Kalman filter. 

4. Switching Kalman filter for road-matching 

Road-matching  involves  applying  a  first  filter  which 
selects all the segments close to the estimated position of 
the  vehicle.  The  goal  is  then  to  select  the  most  likely 

1 F.V. Jensen, S.L. Lauritzen et K.G. Olesen 

this  subset.  Nowadays,  since 

the 
segment(s)  from 
geometry  of  roadmaps  is  more  and  more  detailed,  the 
number  of  segments  representing  roads  is  increasing.  In 
the other hand, the map has an absolute error (10 meters) 
and  relative  error  (1  meter).  The  road  classification 
module  is  an  important  stage  in  the  vehicle  localization 
process because the robustness of the localization depends 
mainly  on  this  stage.  In  order  to  take  into  account  the 
error  of  several  sensors  or  database  used 
this 
application,  we  introduce  a  concept  which  can  manage 
multi-hypothesis in the formalism of BN. 

in 

4.1 BN model 

For each selected segment Cartoi, we represent it by a 
Gaussian: Cartoi ~ N (µi, ∑i). Where µi is the pose vector: 
(xi,yi)  is  the  projection  of  the  estimated  position  on  this 
segment and θi is the heading of the segment. 

The  proposed  BN  model  for  road-matching 
is 
illustrated in Figure 6. In this model we used two hidden 
variables. The discrete variable Sk represents the segments 
of  which  the  vehicle  can  be.  The  second  is  continuous 
variable; Xk(xi,yi,θi) represents the estimation of a vehicle 
for each segment candidate.  

The  graph  represented  in  Figure  6  allows  us  to 
represent causal links between the variables. The variable 
Xk is updated by observations Cartok and/or GPSk (if GPS 
is  masked  we  use  only  the  cartographical  observations).  
This variable is multi-modal because it has been updated 
segi).  The 
by  the  set  of  candidates  segments  (Cartok
variable  Sk  is  update  by  cartographical  observation 
(Cartok)  and  the  estimation  is  given  by  the  hidden 
variable Xk. 

 Sk

Xk 

Cartok 

 GPSk 

Figure 6: Switching Kalman filter for a map-
matching 

estimation 

For  each  candidate  segment  one  can  build  a 
cartographical  observation  given  by  projection  of 
odometric 
segments.  The 
onto 
cartographical  observations  and/or  GPS  observation  are 
used  to  update  variables  Xk  and  Sk.  A  result  of  Bayesian 
inference is a probability of each candidate segment. The 
synoptic of this algorithm is given by Figure 7. 

the 

Let  us  use  a  specific  case  study  to  illustrate  the 
method.  In  Figure 8,  the  vehicle  is  traveling  on  the  road 
represented  by  the  segments  1  and  2.  Estimation  errors 
and digital map errors oblige the selection of the segment 

 
 
 
 
 
 
                                                 
 
 
 
 
 
 
 
 
3 in addition to the segment 2 to be treated also. So, two 
cartographical  observations  were  generated  in  giving  the 
same  chance  to  each  segment  candidate.  Consequently 
two estimations were generated also at the step t=k-1.  

   Odometry :  Xi=(x,y,θ) 

GIS-2D

used for 1.5Km. One can remark that in spite of the long 
GPS  mask,  the  vehicle  location is  matched  correctly.  As 
matter  of  fact,  the  final  estimated  positions  stay  close  to 
the  GPS  points.  In  Figure  9,  we  only  presented  the most 
probable SKF estimation of the pose. 

 Select segment candidates around Xi: 
                 seg1, seg2,…,segN 

      Construct map-observation:  
 seg1(x1, y1, θ1),….., segN(xN, yN, θN)

GPS 

 Sk 

Xk 

Cartok 

 GPSk   

Pi(S, X / Carto, GPS) 

)

m
(
y

550

500

450

400

350

300

250

200

150

100

50

Start

      SKF pose estimation
  .      DGPS 

Figure 7: Synoptic of road-matching using a BN 

At  the  instant  k,  three  segments  were  selected  all 
around  the  predicted  pose.  These  segments  were  used  to 
generate  three  observations.  Then,  using  SKF,  three 
estimations  were  provided.  We  plot  only  the  most 
probable in green circle on the Figure 8. 

Predicted pose using odometry  

Estimation corrected with the most 
probable segment  

Cartographical observation 

T=k-1 

T=K 

T=K+1 

1 

1 

1 

2 

4 

4 

3 

2 

3 

2 

3 

6 

5 

Figure 8: Illustrative example of multi-
hypotheses  

5. Experimental results 

A test trajectory has been carried out at Compiègne in 
France  with an  experimental  vehicle.  The  used  GPS  is  a 
differential  Trimble  AgGPS132  receiver.  For  odometry, 
the  ABS  sensors  is  of  the  rear  wheels  of  the  vehicle  are 
used.  

The  test  trajectory  is  presented  in  Figure  9.  In  this 
experience,  the  GPS  measurement  was  available  in  the 
beginning  of  the  test  trajectory.  Then,  the  GPS  still  not 

100

150

200

250

300

350

x(m)

Figure 9: pose estimation with SKF using 
odometry and cartographical observation (GPS 
was masked) 

In  Figure  10,  the  estimation  is  plotted  with  a  red  ×. 
When the GPS measurement is not available, the method 
provides  estimation  for  each  segment  candidate  and  the 
estimation  of  the  most  probable  segment  only  is  plotted. 
Then  the  GPS measurement  it  becomes  available  but the 
GPS  position  is  then  closer  the  segment  which  describe 
the other side of the road.  In this case, the situation is an 
ambiguous parallel road situation. The method detects the 
ambiguity  of  this  situation  and  selects  all  probable 
segments in this parallel road situation. The SKF manage 
all hypotheses until the elimination of the ambiguity. One 
can remark that, in spite the ambiguity, the road on which 
the  vehicle  is  running  in  reality  presents  the  highest 
probability. With these results, the proposed approach can 
manipulate and take into account the GPS error also. 

GPS masked 

GPS available

550

500

450

400

350

300

250

200

160

180

200

220

240

260

280

300

320

340

360

Figure 10: Multi-hypothesis managed with SKF 
to treat parallel road situation 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
10. References 

[1]  Pradalier  C.  &  Sekhavat  S.  “Localization  Space:  a 
Framework  for  Localization  and  Planning,  for  Systems 
Using a Sensor/Landmarks Module”. Proc. of the  IEEE  Int. 
C. on Robotics and Automation, 2002. 

[2] R. Joshi, “Novel Metrics for Map-Matching in In-vehicle 
Navigation  System”  Proc.  Of  the  IEEE  Intelligent  Vehicle 
Symposium, 2002, pp. 36–43. 

[3]  J.  S.  Kim,  J.  H.  Lee,  T.  H.  Kang,  W.  Y.  Lee  and  Y.  G. 
Kim,  “Node  based  map  matching  algorithm  for  car 
navigation  system” 
in  Proc.  29th  ISATA  Symposium, 
Florence, 1996, vol. 10, pp. 121–126. 

[4] M. A. Quddus W. Y. Ochieng, L. Zhao and R. B. Noland, 
“A  General  Map  Matching  Algorithm 
for  Transport 
Telematics  Applications”,  GPS  Solution  7(3),  pp.  157-167, 
2003. 

[5]  C. A.  Scott  C.R.  Drane,  “Increased Accuracy  of  Motor 
Vehicle Position Estimation by Utilizing Map Data, Vehicle 
Dynamics and Other Information Sources” in 1994 Proc. of 
the 
Information  Systems 
Conference, pp. 585–590. 

vehicle  Navigation 

and 

[6] Zhao Y. “Vehicle Location Navigation Systems”. Artech 
House, Inc, 1997. 

[7] Abbott  E.  &  Powell  D.  “Land-Vehicle  Navigation  using 
GPS”. Proc. of IEEE, vol.87, NO.1, Jan 99. 

[8]  M.E.EL  Najjar  &  Ph.  Bonnifait.  “A  Roadmap  Matching 
Method  for  Precise  Vehicle  Localization  using  Belief 
Theory  and  Kalman  Filtering”.  IEEE/EJS/ISR  11th  Int. 
Conference on Advanced Robotics, 2003,  pp. 1677-1682. 

[9]  R.G.  Cowell  & A.P.  Dawid.  Probabilistic  Networks  and 
Expert System. New York: 1999 Springer. 

[10]  J.Pearl.  (1988)  Probabilistic  reasoning  in  intelligent 
systems:  Networks  of  plausible  Inference.  Publishers,  Inc., 
San Mateo, CA, 2nd edition. 

[11]  K.P.  Murphy. 
“Dynamic  Bayesian  Networks: 
Representation,  Inference  and  Learning”.  PhD  thesis,  UC 
Berkley, 2002, Computer Science Division. 

[12]  K.P.  Murphy.  “Switching  Kalman  Filters”.  Technical 
report, UC Berkeley, Computer Science Division, 1998. 

[13]  M.E.EL  Najjar  &  Ph.  Bonnifait.  (2005)  “Towards  an 
Estimate  of  Confidence  In  a  Road-Matched  Location”.  IEEE 
International Conference on Robotics and Automation, 2005.  

In  Figure  11,  GPS  was  not  available  after  the 
intersection.  One  can  see  that  the  method  manage  two 
hypotheses  for  seven  steps  then  wrong  hypothesis  was 
eliminated. We can remark that, the good segment always 
presents  the  most  important  probability  computed  by  the 
SKF inference. 

GPS not available 

400

350

300

250

m)
y(

200

150

100

100

120

140

160

180

200

220

240

260

280

x(m)

Figure 11: Multi-hypothesis managed with SKF 
to treat junction road situation 

6. Conclusion 

This  article  has  presented  a  road-matching  method 
based  on  a  multi-sensor  fusion  approach.  The  main 
contributions of this work are the formalization of a road-
matching  method  in  the  Switching  Kalman  filtering 
context and an experimental validation with real data.  

An interesting characteristic of this approach is that it 
is  flexible  and  modular  in  the  sense  that  it  can  easily 
integrate other sensors. This feature is interesting because 
adding other sensors is a way to increase the robustness of 
the road-matching. 

In  this  approach,  the  use  of  the  digital  map  as  an 
observation  of  the  state  space  representation  has  been 
introduced.  This  observation  is  used  in  the  Switching 
Kalman filter in the same way that the GPS data. It turned 
out in the experiments that the GPS measurements are not 
necessary  available  all  the  time,  since  the  merging  of 
odometry  and  roadmap  data  can  provide  a  good 
estimation  of  the  position  over  a  substantial  period.  The 
strategy  presented  in  this  paper  doesn’t  keep  only  the 
most  likely  segment.  When  approaching  an  intersection, 
several  roads  can  be  good  candidates  for  this  reason  we 
manage  several  hypotheses  until  the  situation  becomes 
unambiguous. 

Acknowledgments 

The  authors  wish  to  acknowledge  the  HEUDIASYC 
laboratory  in  the  person  of  Philippe  Bonnifait  for  his 
contribution."
"Performance Bounds for Lambda Policy Iteration and Application to the
  Game of Tetris","  We consider the discrete-time infinite-horizon optimal control problem
formalized by Markov Decision Processes. We revisit the work of Bertsekas and
Ioffe, that introduced $\lambda$ Policy Iteration, a family of algorithms
parameterized by $\lambda$ that generalizes the standard algorithms Value
Iteration and Policy Iteration, and has some deep connections with the Temporal
Differences algorithm TD($\lambda$) described by Sutton and Barto. We deepen
the original theory developped by the authors by providing convergence rate
bounds which generalize standard bounds for Value Iteration described for
instance by Puterman. Then, the main contribution of this paper is to develop
the theory of this algorithm when it is used in an approximate form and show
that this is sound. Doing so, we extend and unify the separate analyses
developped by Munos for Approximate Value Iteration and Approximate Policy
Iteration. Eventually, we revisit the use of this algorithm in the training of
a Tetris playing controller as originally done by Bertsekas and Ioffe. We
provide an original performance bound that can be applied to such an
undiscounted control problem. Our empirical results are different from those of
Bertsekas and Ioffe (which were originally qualified as ""paradoxical"" and
""intriguing""), and much more conform to what one would expect from a learning
experiment. We discuss the possible reason for such a difference.
",http://arxiv.org/pdf/0711.0694v5,1,"1
1
0
2

t
c
O
1
1

]
I

A
.
s
c
[

5
v
4
9
6
0
.
1
1
7
0
:
v
i
X
r
a

Performance Bounds for λ Policy Iteration
and Application to the Game of Tetris

Bruno Scherrer
Maia Project-Team, INRIA Lorraine
615 rue du Jardin Botanique
54600 Villers-les-Nancy
FRANCE

bruno.scherrer@inria.fr

Abstract

We consider the discrete-time inﬁnite-horizon optimal control problem formalized by
Markov Decision Processes (Puterman, 1994; Bertsekas and Tsitsiklis, 1996). We revisit
the work of Bertsekas and Ioﬀe (1996), that introduced λ Policy Iteration, a family of al-
gorithms parameterized by λ that generalizes the standard algorithms Value Iteration and
Policy Iteration, and has some deep connections with the Temporal Diﬀerences algorithm
TD(λ) described by Sutton and Barto (1998). We deepen the original theory developped
by the authors by providing convergence rate bounds which generalize standard bounds for
Value Iteration described for instance by Puterman (1994). Then, the main contribution of
this paper is to develop the theory of this algorithm when it is used in an approximate form
and show that this is sound. Doing so, we extend and unify the separate analyses devel-
opped by Munos for Approximate Value Iteration (Munos, 2007) and Approximate Policy
Iteration (Munos, 2003). Eventually, we revisit the use of this algorithm in the training of
a Tetris playing controller as originally done by Bertsekas and Ioﬀe (1996). We provide an
original performance bound that can be applied to such an undiscounted control problem.
Our empirical results are diﬀerent from those of Bertsekas and Ioﬀe (which were originally
qualiﬁed as “paradoxical” and “intriguing”), and much more conform to what one would
expect from a learning experiment. We discuss the possible reason for such a diﬀerence.

Keywords: Stochastic Optimal Control, Reinforcement Learning, Markov Decision Pro-
cesses, Analysis of Algorithms, Performance Bounds.

1. Introduction

We consider the discrete-time inﬁnite-horizon optimal control problem formalized by Markov
Decision Processes (Puterman, 1994; Bertsekas and Tsitsiklis, 1996). We revisit the λ Policy
Iteration algorithm introduced by Bertsekas and Ioﬀe (1996) (also published in the reference
textbook of Bertsekas and Tsitsiklis (1996)1), that (as the authors then stated) ”is primar-
ily motivated by the case of large and complex problems where the use of approximation is
essential”. It is a family of algorithms parameterized by λ that generalizes the standard
Dynamic Programming algorithms Value Iteration (which corresponds to the case λ = 0)
and Policy Iteration (case λ = 1), and has some deep connections with the Temporal Dif-

1. The reference (Bertsekas and Ioﬀe, 1996) being historically anterior to (Bertsekas and Tsitsiklis, 1996),

we only refer to the former in the rest of the paper.

 
 
 
 
 
 
Bruno Scherrer

ferences algorithm TD(λ) that are well known to the Reinforcement Learning community
(Sutton and Barto, 1998; Bertsekas and Tsitsiklis, 1996).

In their original paper, Bertsekas and Ioﬀe (1996) show the convergence of λ Policy
Iteration when it is run without error and provide its asymptotic convergence rate. The
authors also describe a case study involving an instance of Approximate λ Policy Iteration,
but neither their paper nor (to the best of our knowledge) any subsequent work studies the
theoretical soundness of doing so. In this paper, we extend the theory on this algorithm in
several ways. We derive its non-asymptotic convergence rate when it is run without error.
More importantly, we develop the theory of λ Policy Iteration for its main purpose, that is
— recall the above quote — when it is run in an approximate form, and prove that such
an approach is sound: we show that the loss of using the greedy policy with respect to the
current value estimate can be made arbitrarily small by controlling the error made during
the iterations.

The rest of the paper is organized as follows. In Section 2, we introduce the framework
of Markov Decision Processes and decribe the two standard algorithms, Value Iteration and
Policy Iteration, along with some of their state-of-the-art analysis in exact and approximate
form. Section 3 introduces λ Policy Iteration in an original way that makes its connection
with Value Iteration and Policy Iteration obvious, and discusses its close connection with
Reinforcement Learning. We recall the main results obtained by Bertsekas and Ioﬀe (1996)
(convergence and asymptotic rate of convergence of the exact algorithm). At this point
of the paper, we naturally describe how one expects that the properties of Value Iteration
(λ = 0) and Policy Iteration (λ = 1) described in Section 2 may translate for general λ. The
precise statements of our results are the topic of the next two Sections: Section 5 contains
our new results on Exact λ Policy Iteration and Section 6 those on Approximate λ Policy
Iteration2. Last but not least, Section 7 revisits the empirical part of the work of Bertsekas
and Ioﬀe (1996), where an approximate version of λ Policy Iteration is used for training a
Tetris controller.

Notations The analysis we describe in this article relies on a few notations, such as
several norms and seminorms, that we need to deﬁne precisely before we can go further.
Let X be a ﬁnite space. Let u denote a real-valued function on X, which can be seen as a
vector of dimension |X|. Let e denote the vector of which all components are 1. The vector
µ denotes a distribution on X. We consider the weighted Lp norm:

kukp,µ :=

µ(x)|u(x)|p

x
X

1/p

!

= (µT |u|p)1/p

where |u|p denotes the componentwise absolute value and exponentiation of u. We write
k.kp the unweighted Lp norm (with uniform distribution µ). The max norm k.k∞ is:

We write span∞ [.] the span seminorm (as for instance deﬁned by Puterman (1994)):

kuk∞ := max

x

|u(x)| = lim
p→∞

kukp .

span
∞

[u] := max

x

u(x) − min

x

u(x).

2. Section 6 is probably the place where the reader familiar with Approximate Dynamic Programming

would quickly want to jump.

2

 
Performance Bounds for λ Policy Iteration

It can be seen that

span
∞

[u] = 2 min

a

ku − aek∞ .

We propose to generalize the span seminorm deﬁnition for any p as follows:

span
p,µ

[u] := 2 min

a

ku − aekp,µ

It is clear that it is a seminorm (it is non-negative, it satisﬁes the triangle inequality and
span∗ [au] = |a| span∗ [u]). It is not a norm because it is zero for all constant functions.

The error bounds we derive in this paper are expressed in terms of some span seminorm.

The following relations

spanp [u]
≤ 2 kuk∞
≤ 2 kukp
spanp,µ [u] ≤ 2 kukp,µ ≤ 2 kuk∞
span∞ [u] ≤ 2 kuk∞




(1)



show how to deduce error bounds involving the (more standard) Lp and max norms. Since
the span seminorm can be zero for non zero (constant) vectors, there is no relation that
would enable us to derive error bounds in span seminorm from a Lp or a max norm.
Bounding an error with the span seminorm is in this sense stronger and this constitutes our
motivation for using it.

2. Framework and Standard Algorithms

In this section, we begin by providing a short description of the framework of Markov
Decision Processes we consider throughout the paper. We go on by describing the two main
algorithms, Value Iteration and Policy Iteration, for solving the related problem.

2.1 Markov Decision Processes

We consider a discrete-time dynamic system whose state transition depends on a control.
We assume that there is a state space X of ﬁnite size N . When at state i ∈ {1, .., N },
the control is chosen from a ﬁnite control space A. The control a ∈ A speciﬁes the
transition probability pij(a) to the next state j. At the kth iteration, the system is given
a reward γkr(i, a, j) where r is the instantaneous reward function, and 0 < γ < 1 is a
discount factor. The tuple hX, A, p, r, γi is called a Markov Decision Process (MDP)
(Puterman, 1994; Bertsekas and Tsitsiklis, 1996).

We are interested in stationary deterministic policies, that is functions π : X → A which
map states into controls3. Writing ik the state at time k, the value of policy π at state i
is deﬁned as the total expected discounted return while following a policy π from i, that is

vπ(i) := lim
N→∞

Eπ

N −1

""

Xk=0

γkr(ik, π(ik), ik+1)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

i0 = i

#

(2)

3. Restricting our attention to stationary deterministic policies is not a limitation. Indeed, for the optimality
criterion to be deﬁned soon, it can be shown that there exists at least one stationary deterministic policy
which is optimal (Puterman, 1994).

3

Bruno Scherrer

where Eπ denotes the expectation conditional on the fact that the actions are selected with
the policy π (that is, for all k, ik+1 is reached from ik with probability pikik+1(π(ik))). The
optimal value starting from state i is deﬁned as

v∗(i) := max

vπ(i).

π
We write P π the N ×N stochastic matrix whose elements are pij(π(i)) and rπ the vector
j pij(π(i))r(i, π(i), j). The value functions vπ and v∗ can be seen

whose components are
as vectors on X. It is well known that vπ solves the following Bellman equation:

P

vπ = rπ + γP πvπ.

The value function vπ is a ﬁxed point of the linear operator T πv := rπ + γP πv. As P π is
a stochastic matrix, its eigenvalues cannot be greater than 1, and consequently I − γP π is
invertible. This implies that

vπ = (I − γP π)−1rπ =

(γP π)irπ.

∞

(3)

It is also well known that v∗ satisﬁes the following Bellman equation:

Xi=0

v∗ = max

π

(rπ + γP πv∗) = max

π

T πv∗

where the max operator is componentwise. In other words, v∗ is a ﬁxed point of the nonlinear
operator T∗v := maxπ T πv. For any value vector v, we call a greedy policy with respect
to the value v a policy π that satisﬁes:

π ∈ arg max

π′ T π′

v

or equivalently T πv = T∗v. We write, with some abuse of notation4 greedy(v) any policy
that is greedy with respect to v. The notions of optimal value function and greedy policies
are fundamental to optimal control because of the following property: any policy π∗ that is
greedy with respect to the optimal value is an optimal policy and its value vπ∗ is equal
to v∗.

The operators T π and T∗ can be shown to be γ-contraction mappings with respect to
the max norm. In what follows we only write what this means for the Bellman operator T∗
but the same holds for T π. Being a γ-contraction mapping for the max norm means that
for all pairs of vectors (v, w),

kT∗v − T∗wk∞ ≤ γ kv − wk∞ .

This ensures that the ﬁxed point v∗ of T exists and is unique. Furthermore, for any initial
vector v0,

(T∗)kv0 = v∗.

lim
k→∞

(4)

Given an MDP, standard algorithmic solutions for computing an optimal value/policy
(which dates back to the 1950s, see for instance (Puterman, 1994) and the references therein)
are Value Iteration and Policy Iteration. The rest of this section describes both of these
algorithms with some of the relevant properties for the subject of this paper.

4. There might be several policies that are greedy with respect to some value v.

4

Performance Bounds for λ Policy Iteration

Algorithm 1 Value Iteration
Input: An MDP, an initial value v0
Output: An (approximately) optimal policy

k ← 0
repeat

vk+1 ← T∗vk + ǫk+1
k ← k + 1

// Update the value

until some stopping criterion
Return greedy(vk)

2.2 Value Iteration

The Value Iteration algorithms for computing the value of a policy π and the value of the
optimal policy π∗ rely on Equation 4. Algorithm 1 provides a description of Value Iteration
for computing an optimal policy (replace T∗ by T π in it and one gets Value Iteration for
computing the value of some policy π).
In this description, we have introduced a term ǫk
which stands for several possible sources of error at each iteration: this error might be the
computer round oﬀ, the fact that we use an approximate architecture for representing v, a
stochastic approximation of P πk , etc... or a combination of these. In what follows, when
we talk about the Exact version of an algorithm, this means that ǫk = 0 for all k.

Properties of Exact Value Iteration The contraction property induces some inter-
esting properties for Exact Value Iteration. We have already mentioned that contraction
implies the asymptotic convergence (Equation 4). It can also be inferred that there is at
least a linear rate of convergence: for all reference iteration k0, and for all k ≥ k0,

kv∗ − vkk∞ ≤ γk−k0 kv∗ − vk0k∞ .
Even more interestingly, it is possible to derive a performance bound, that is a bound of
the diﬀerence between the real value of a policy produced by the algorithm and the value
of the optimal policy π∗ (Puterman, 1994). Let πk denote the policy that is greedy with
respect to vk−1. Then, for all reference iteration k0, and for all k ≥ k0,

kv∗ − vπk k∞ ≤

2γk−k0
1 − γ

kT∗vk0 − vk0k∞ =

2γk−k0
1 − γ

kvk0+1 − vk0k∞ .

This fact is of considerable importance computationally since it provides a stopping crite-
rion: taking k = k0 + 1, we see that if kvk0+1 − vk0k∞ ≤ 1−γ

2γ ǫ, then kv∗ − vπk0+1k∞ ≤ ǫ.

It is somewhat less known that the Bellman operators T∗ and T π are also contraction
mapping with respect to the span∞ seminorm (Puterman, 1994). This means that there
exists a variant of the above equation involving the span seminorm instead of the max norm.
For instance, such a fact provides the following stopping criterion:

Proposition 1 (Stopping Cond. for Exact Value Iteration (Puterman, 1994))
If at some iteration k0, the diﬀerence between two subsequent iterations satisﬁes

span
∞

[vk0+1 − vk0] ≤

1 − γ
γ

ǫ,

then the greedy policy πk0+1 with respect to vk0 is ǫ-optimal: kv∗ − vπk0+1k∞ ≤ ǫ.

5

Bruno Scherrer

This latter stopping criterion is ﬁner since, from the relation between the span seminorm

and the norm (Equation 1) it implies the former.

Properties of Approximate Value Iteration (AVI) When considering large Markov
Decision Processes, one cannot usually implement an exact version of Value Iteration. In
such a case ǫk 6= 0. In general, the algorithm does not converge anymore but it is possible
to study its asymptotic behaviour. The most well-known result is due to Bertsekas and
Tsitsiklis (1996, pp. 332-333):
if the approximation erros are uniformly bounded, the
diﬀerence between the asymptotic performance of policies πk+1 greedy with respect to vk
satisﬁes

lim sup
k→∞

kv∗ − vπk k∞ ≤

(1 − γ)2 sup

k≥0

2γ

kǫkk∞ .

(5)

Munos (2003, 2007) has recently argued that, since most supervised learning algorithms
(such as least square regression) that are used in practice for approximating each iterate of
Value Iteration control some Lp norm, it would be more interesting to have an analogue of
the above result where the approximation error ǫk is expressed in terms of the Lp norm.
Munos (2007) actually showed how to do this. The idea is to analyze the componentwise
asymptotic behaviour of Approximate Value Iteration, from which it is possible to derive
Lp bounds for any p. Write Pk = P πk the stochastic matrix corresponding to the policy
πk which is greedy with respect to vk−1, P∗ the stochastic matrix corresponding to the
(unknown) optimal policy π∗. Munos (2007) showed the following lemma:

Lemma 2 (Asymptotic Componentwise Performance of AVI (Munos, 2007))
For all k > j ≥ 0, the following matrices

Qkj
Q′
kj

:= (1 − γ)(I − γPk)−1PkPk−1...Pj+1
:= (1 − γ)(I − γPk)−1(P∗)k−j

are stochastic and the asymptotic performance of the policies generated by Approximate
Value Iteration satisﬁes

lim sup
k→∞

v∗ − vπk ≤ lim sup
k→∞

1
1 − γ

k−1

Xj=0

γk−j

Qkj − Q′
kj

ǫj.

(cid:2)

(cid:3)

From the above componentwise bound, it is possible5 to derive the following Lp bounds.

Proposition 3 (Asymptotic Performance of AVI (1/2))
Choose any p and any distribution µ. Consider the notations of Lemma 2. Then

µkj :=

1
2

Qjk + Q′
jk

T µ

are distributions and the asymptotic performance of policies generated by Value Iteration
satisﬁes

(cid:0)

(cid:1)

lim sup
k→∞

kv∗ − vπk kp,µ ≤

(1 − γ)2 sup

k≥j≥0

kǫkkp,µkj

2γ

5. This result is not explicitely stated by Munos (2007), but using a technique of another of his articles
(Munos, 2003), it can be derived from Lemma 2. The current paper generalizes this result (in Proposi-
tion 24 page 24).

6

Performance Bounds for λ Policy Iteration

As the above bounds rely on the partially unknown matrices Qkj and Q′
kj, Munos (2003,
2007) introduced some assumption in terms of concentration coeﬃcient to remove this
dependency. Assume there exists a distribution ν and a real number C(ν) such that

C(ν) := max
i,j,a

pij(a)
ν(j)

.

(6)

For instance, if one chooses the uniform law ν, then there always exists such a C(ν) ∈ (1, N )
where N is the size of the state space (see (Munos, 2003, 2007) for more discussion on this
coeﬃcient). This allows to derive the following performance bounds on the max norm of
the loss.

Proposition 4 (Asymptotic Performance of AVI (2/2) (Munos, 2007))
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. The asymptotic performance
of the policies generated by Approximate Value Iteration satisﬁes

lim sup
k→∞

kv∗ − vπk k∞ ≤

2γ (C(ν))1/p
(1 − γ)2

kǫkkp,ν .

sup
k≥0

The main diﬀerence between the bounds of Propositions 3 and 4 and that of Bertsekas
and Tsitsiklis (Equation 5) is that the approximation error ǫk is measured by the weighted
Lp norm. As limp→∞ k.kp,µ ≤ k.k∞ and (C(ν))1/p p→∞
−→ 1, Munos’s results are strictly ﬁner.
There is generally no guarantee that AVI converges. AVI converges for speciﬁc approx-
imation architectures called averagers (Gordon, 1995) which include state aggregation (see
(Van Roy, 2006) for a very ﬁne approximation bound in this speciﬁc case). Also, conver-
gence may just occur experimentally. Assume that the sequence (vk)k≥0 tends to some
value v. Write π the corresponding greedy policy. Notice this implies that (ǫk)k≥0 tends to
v − T∗v, that is called the Bellman residual. The above bounds can be improved by a
factor

1
1−γ . We know from Williams and Baird (1993) that

kv∗ − vπk∞ ≤

2γ
1 − γ

kv − T∗vk∞

and, with the same notations as above, Munos (2007) derived the analogous ﬁner Lp bound:

Corollary 5 (Performance of AVI in case of convergence (Munos, 2007))
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. Assume that (vk)k≥0 tends
to some value v. Write π the corresponding greedy policy. Then

kv∗ − vπk∞ ≤

2γ (C(ν))1/p
1 − γ

kv − T∗vkp,ν .

Eventually, let us mention that Munos (2007) and Farahmand et al. (2010) consider
some ﬁner performance bounds (in weighted Lp norm) using some ﬁner concentration
coeﬃcients. We won’t discuss them in this paper and we recommend the interested reader
to go through these references for further details.

7

Bruno Scherrer

Algorithm 2 Policy Iteration
Input: An MDP, an initial policy π0
Output: An (approximately) optimal policy

k ← 0
repeat

vk ← (I − γP πk)−1rπk + ǫk
πk+1 ← greedy(vk)
k ← k + 1

until some stopping criterion
Return πk

2.3 Policy Iteration

// Estimate the value of πk
// Update the policy

Policy Iteration is an alternative method for computing an optimal policy for an inﬁnite-
horizon discounted Markov Decision Process. This algorithm is based on the following
property: if π is some policy, then any policy π′ that is greedy with respect to the value
of π, that is any π′ satisfying π′ = greedy(vπ), is better than π in the sense that vπ′
≥ vπ.
Policy Iteration exploits this property in order to generate a sequence of policies with
increasing values.
It is described in Algorithm 2. Note that we use the analytical form
of the value of a policy given by Equation 3. Also, as for Value Iteration, our description
includes a potential error ǫk term each time the value of a policy is estimated.

Properties of Exact Policy Iteration When the state space and the control spaces
are ﬁnite, Exact Policy Iteration converges to an optimal policy π∗ in a ﬁnite number of
iterations (Puterman, 1994; Bertsekas and Tsitsiklis, 1996). In inﬁnite state spaces, if the
function v 7→ P greedy(v) is Lipschitz, then it can be shown that Policy Iteration has a
quadratic convergence rate (Puterman, 1994). However, to our knowledge, and contrary
to Value Iteration, ﬁnite-time stopping conditions such as that of Proposition 1 are not
widely known for Policy Iteration, though they appear implicitely in some recent works on
Approximate Policy Iteration (Antos et al., 2007, 2008; Farahmand et al., 2010; Lazaric
et al., 2010).

Properties of Approximate Policy Iteration (API) For problems of interest, one
usually uses Policy Iteration in an approximate form, that is with ǫk 6= 0. Results similar
to those presented for Approximate Value Iteration exist for Approximate Policy Iteration.
As soon as there is some error ǫk 6= 0, the algorithm does not necessarily converge anymore
but there is an analogue of Equation 5 which is also due to Bertsekas and Tsitsiklis (1996,
Prop 6.2 p. 276):
if the approximation errors are uniformly bounded, then the diﬀerence
between the asymptotic performance of policies πk+1 greedy with respect to vk and the
optimal policy is

lim sup
k→∞

kv∗ − vπk k∞ ≤

2γ

(1 − γ)2 sup

k≥0

kǫkk∞ .

(7)

As for Value Iteration, Munos has extended this result so that one can get bounds involving
the Lp norm. He also showed how to relate the performance analysis to the Bellman residual
vk − T πk vk that says how much vk approximates the real value of the policy πk; this is for

8

Performance Bounds for λ Policy Iteration

instance interesting when the evaluation step of Approximate Policy Iteration involves the
minimization of the norm of this Bellman residual (see (Munos, 2003)).
It is important
to note that this Bellman residual is diﬀerent from the one we introduced in the previous
section (we then considered vk − T∗vk = vk − T πk+1vk where πk+1 is greedy with respect to
vk). To avoid confusion, and because it is related to some speciﬁc policy, we call vk − T πk vk
the Policy Bellman residual. Munos started by deriving a componentwise analysis.
Write Pk = P πk the stochastic matrix corresponding to the policy πk which is greedy with
respect to vk−1, P∗ the stochastic matrix corresponding to the (unknown) optimal policy
π∗.

Lemma 6 (Asymptotic Componentwise Performance of API (Munos, 2003))
The following matrices

Rk
R′
k
R′′
k

:= (1 − γ)2(I − γP∗)−1Pk+1(I − γPk+1)−1
:= (1 − γ)2(I − γP∗)−1
:= (1 − γ)2(I − γP∗)−1P∗(I − γPk)

P∗ + γPk+1(I − γPk+1)−1Pk

(cid:2)

(cid:3)

are stochastic and the asymptotic performance of the policies generated by Approximate
Policy Iteration satisﬁes

lim sup
k→∞

lim sup
k→∞

v∗ − vπk ≤

v∗ − vπk ≤

2γ

(1 − γ)2 lim sup

k→∞

2γ

(1 − γ)2 lim sup

k→∞

Rk − R′
k

ǫk

Rk − R′′
k

(cid:2)

(cid:2)

(cid:3)

(cid:3)

(vk − T πk vk).

As for Value Iteration, the above componentwise bound leads to the following Lp bounds.

Proposition 7 (Asymptotic Performance of API (1/2) (Munos, 2003))
Choose any p and any distribution µ. Consider the notations of Lemma 6. For all k ≥ 0,

µk :=

1
2

Rk + R′
k

T µ and µ′

k :=

1
2

Rk + R′′
k

T µ

are distributions and the asymptotic performance of the policies generated by Approximate
Policy Iteration satisﬁes

(cid:0)

(cid:1)

(cid:0)

(cid:1)

lim sup
k→∞

kv∗ − vπk kp,µ ≤

and lim sup

k→∞

kv∗ − vπk kp,µ ≤

2γ

(1 − γ)2 lim sup

k→∞

2γ

(1 − γ)2 lim sup

k→∞

kǫkkp,µk

kvk − T πkvkkp,µ′

k

.

Using the concentration coeﬃcient C(ν) introduced in the previous section (Equation 6), it
is also possible to show6 the following L∞/Lp bounds:

6. Similarly to footnote 5, this result is not explicitely stated by Munos (2003) but using techniques of
another of his articles (Munos, 2007), it can be derived from Lemma 6. The current paper anyway
generalizes this result (in Proposition 26 page 25).

9

Bruno Scherrer

Proposition 8 (Asymptotic Performance of API (2/2))
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. The asymptotic performance
of the policies generated by Approximate Policy Iteration satisﬁes

lim sup
k→∞

lim sup
k→∞

kv∗ − vπk k∞ ≤

kv∗ − vπk k∞ ≤

2γ (C(ν))1/p
(1 − γ)2
2γ (C(ν))1/p
(1 − γ)2

lim sup
k→∞

kǫkkp,ν

lim sup
k→∞

kvk − T πkvkkp,ν .

Again, the bounds of Propositions 7 and 8 with respect to the approximation error ǫk
are ﬁner than that of Bertsekas and Tsitsiklis (Equation 7). Compared to the similar result
for Approximate Value Iteration (Propositions 3 and 4) where the bound depends on a
uniform error bound (∀k, kǫkkp,ν ≤ ǫ), the above bounds have the nice property that they
only depend on asymptotic errors/residuals.

Finally, as for Approximate Value Iteration, a better bound (by a factor

1
1−γ ) might be
obtained if the sequence of policies happens to converge. It can be shown (Munos, 2003,
Remark 4 page 7) that:

Corollary 9 (Performance of API in case of convergence)
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. If the sequence of policies
(πk) converges to some π, then

v∗ − vπ ≤

v∗ − vπ ≤

2γ (C(ν))1/p
1 − γ
2γ (C(ν))1/p
1 − γ

lim sup
k→∞

kǫkkp,ν

lim sup
k→∞

kvk − T πk vkkp,ν .

After this tour of results for Value and Policy Iteration, we now introduce the algorithm

studied in this paper.

3. λ Policy Iteration

Though all the results we have emphasized so far are strongly related (and even sometimes
identical, compare Equations 5 and 7), they were surprisingly proved independently. In this
section, we describe the family of algorithms “λ Policy Iteration”7 introduced by Bertsekas
and Ioﬀe (1996) parameterized by a coeﬃcient λ ∈ (0, 1), that generalizes them both. When
λ = 0, λ Policy Iteration reduces to Value Iteration while it reduces to Policy Iteration
when λ = 1. We also recall the fact discussed by Bertsekas and Ioﬀe (1996) that λ Policy
Iteration draws some connections with Temporal Diﬀerence algorithms (Sutton and Barto,
1998).

3.1 The Algorithm

We begin by giving some intuition about how one can make a connection between Value
Iteration and Policy Iteration. For simplicity, let us temporarily forget about the error

7. It was also called “Temporal Diﬀerence-Based Policy Iteration” in the original paper, but we take the

name λ Policy Iteration, as it was the name picked by most subsequent works.

10

Performance Bounds for λ Policy Iteration

term ǫk. At ﬁrst sight, Value Iteration builds a sequence of value functions and Policy
Iteration a sequence of policies. In fact, both algorithms can be seen as updating a sequence
of value-policy pairs. With some little rewriting — by decomposing the (nonlinear) Bellman
operator T∗ into (i) the maximization step and (ii) the application of the (linear) Bellman
operator — it can be seen that each iterate of Value Iteration is equivalent to the two
following updates:

πk+1 ← greedy(vk)
vk+1 ← T πk+1vk

⇔

πk+1 ← greedy(vk)
vk+1 ← rπk+1 + γP πk+1vk.

(cid:26)

(cid:26)
The left hande side of the above equation uses the operator T πk+1 while the right hande side
uses its deﬁnition. Similarly — by inverting in Algorithm 2 the order of (i) the estimation
of the value of the current policy and (ii) the update of the policy, and by using the fact
that the value of the policy πk+1 is the ﬁxed point of T πk+1 (Equation 4) — it can be argued
that every iteration of Policy Iteration does the following:

πk+1 ← greedy(vk)
vk+1 ← (T πk+1)∞vk

(cid:26)

⇔

(cid:26)

πk+1 ← greedy(vk)
vk+1 ← (I − γP πk+1)−1rπk+1.

This rewriting makes both algorithms look close to each other. Both can be seen as having
an estimate vk of the value of policy πk, from which they deduce a potentially better policy
πk+1. The corresponding value vπk+1 of this better policy may be regarded as a target which
is tracked by the next estimate vk+1. The diﬀerence is in the update that enables to go
from vk to vk+1: while Policy Iteration directly jumps to the value of πk+1 (by applying the
Bellman operator T πk+1 an inﬁnite number of times), Value Iteration only makes one step
towards it (by applying T πk+1 only once). From this common view of Value Iteration, it
is natural to introduce the well-known Modiﬁed Policy Iteration algorithm (Puterman and
Shin, 1978) which makes n steps at each update:

πk+1 ← greedy(vk)
vk+1 ← (T πk+1)nvk

⇔

πk+1 ← greedy(vk)
vk+1 ←

I + ... + (γP πk+1)n−1

rπk+1 + (γP πk+1)nvk.

(cid:26)
The above common view is actually here interesting because it also leads to a natural
(cid:2)
introduction of λ Policy Iteration. λ Policy Iteration is doing a λ-adjustable step towards
the value of πk+1:

(cid:26)

(cid:3)

πk+1 ← greedy(vk)
∞
j=0 λj(T πk+1)j+1vk
vk+1 ← (1 − λ)

(cid:26)

P

πk+1 ← greedy(vk)
vk+1 ← (I − λγP πk+1)−1(rπk+1 + (1 − λ)γP πk+1vk)
Remark 10 The equivalence between the left and the right representation of λ Policy Iter-
ation needs here to be proved. For all k ≥ 0 and all function v, Bertsekas and Ioﬀe (1996)
introduce the following operator8

⇔

(cid:26)

Mkv := (1 − λ)T πk+1vk + λT πk+1v

= rπk+1 + (1 − λ)γP πk+1vk + λγP πk+1v

(8)

(9)

and prove that

8. The equivalence between Equations 8 and 9 follows trivially from the deﬁnition of T πk+1 .

11

Bruno Scherrer

Figure 1: Visualizing λ Policy Iteration on the greedy partition sketch: Following
(Bertsekas and Tsitsiklis, 1996, page 226), one can decompose the value space as a
collection of polyhedra, such that each polyhedron corresponds to a region where
one policy is greedy. This is called the greedy partition. In the above example,
there are only 3 policies, π1, π2 and π∗. vk is the initial value. greedy(vk) = π2,
greedy(vπ2) = π1, and greedy(vπ1) = π∗. Therefore (1-)Policy Iteration generates
the sequence ((π2, vπ2), (π1, vπ1), (π∗, vπ∗)). Value teration (or 0 Policy Iteration)
starts by slowly updating vk towards vπ2 until it crosses the boundary π1/π2,
after which it tracks alternatively vπ1 and vπ2, until it reaches the π∗ part. In
other words, Value Iteration makes small steps. λ Policy Iteration is intermediate
between the two: it makes steps of which the steps length is related to λ. On the
above sketch, λ Policy Iteration gets to the greedy partition of the optimal policy
π∗ in 3 steps, as did Policy Iteration.

• Mk is a contraction mapping of modulus λγ for the max norm ;

• The next iterate vk+1 of λ Policy Iteration is the (unique) ﬁxed point of Mk.

The left representation of λ Policy Iteration is obtained by “unrolling” Equation 8 an inﬁnite
number of times, while the right one is obtained by using Equation 9 and solving the linear
system vk+1 = Mkvk+1.

Informally, the parameter λ (or n in the case of Modiﬁed Policy Iteration) can be seen
as adjusting the size of the step for tracking the target vπk+1 (see Figure 1): the bigger the
value, the longer the step. Formally, λ Policy Iteration (consider the above left hand side)
consists in doing a geometric average of parameter λ of the diﬀerent numbers of applications
of the Bellman operator (T πk+1)j to vk. The right hand side is here interesting because it
clearly shows that λ Policy Iteration generalizes Value Iteration (when λ = 0) and Policy
Iteration (when λ = 1). The operator Mk gives some insight on how one may concretely
implement one iteration of λ Policy Iteration: it can for instance be done through a Value

12

Performance Bounds for λ Policy Iteration

Algorithm 3 λ Policy Iteration
Input: An MDP, λ ∈ (0, 1), an initial value v0
Output: An (approximately) optimal policy

k ← 0
repeat

πk+1 ← greedy(vk)
vk+1 ← T πk+1
λ
k ← k + 1

vk + ǫk+1

// Update the policy
// Update the estimate of the value of policy πk+1

until some convergence criterion
Return greedy(vk)

Iteration-like algorithm which applies Mk iteratively. Also, the fact that its contraction
factor λγ can be tuned is of particular importance because ﬁnding the corresponding ﬁxed
point can be much easier than that of T πk+1, which is only γ-contracting.

In order to describe the λ Policy Iteration algorithm, it is useful to introduce an operator
that corresponds to computing the ﬁxed point of Mk. For any value v and any policy π,
deﬁne:

λ v := v + (I − λγP π)−1(T πv − v)
T π

= (I − λγP π)−1(rπ + (1 − λ)γP πv)
= (I − λγP π)−1(λrπ + (1 − λ)T πv).

(10)

(11)

(12)

Equation 11 indeed amounts to solve Equation 9 deﬁning Mk. The other two formulations
are equivalent up to some little linear algebra manipulations.

λ Policy Iteration is formally described in Algorithm 3. Once again, our description
includes a potential error term each time the value is updated. Even with this error term, it
is straightforward to see that the algorithm reduces to Value Iteration (Algorithm 1) when
λ = 0 and to Policy Iteration9 (Algorithm 2) when λ = 1.

Relation with Reinforcement Learning The deﬁnition of the operator T π
λ given by
Equation 11 is the form we have used for the introduction of λ Policy Iteration as an
intermediate algorithm between Value Iteration and Policy Iteration. The equivalent form
given by Equation 10 can be used to make a connection with the TD(λ) algorithms10 (Sutton
and Barto, 1998). Indeed, through Equation 10, the evaluation phase of λ Policy Iteration
can be seen as an incremental additive procedure:

where

∆k := (I − λγP πk+1)−1(T πk+1vk − vk)

vk+1 ← vk + ∆k

9. Policy Iteration starts with an initial policy while λ Policy Iteration starts with some initial value. To
be precise, 1 Policy Iteration starting with v0 is equivalent to Policy Iteration starting with the greedy
policy with respect to v0.

10. TD stands for Temporal Diﬀerence. As we have mentionned in Footnote 7, λ Policy Iteration was
originally also called “Temporal Diﬀerence Based Policy Iteration” and the presentation of Bertsekas
and Ioﬀe (1996) starts from the formulation of Equation 10 (which is close to TD(λ)), and afterwards
makes the connection with Value Iteration and Policy Iteration.

13

Bruno Scherrer

full
backups

Value
Iteration

Policy
Iteration

sample
backups

Temporal−
Difference
Learning

Monte Carlo

shallow
backups

deep
backups

Figure 2: λ Policy Iteration, a fundamental algorithm for Reinforcement Learn-
ing: The left drawing, taken from chapter 10.1 the book of Sutton and Barto
(1998), represents “two of the most important dimensions” of Reinforcement
Learning methods. The vertical axis corresponds to whether one does full backup
(exact computation of the expectations) or stochastic approximation (estimation
through samples). The horizontal axis corresponds to the depth of the backups,
and is (among other things) controlled by the parameter λ. On the right, is an
original picture of λ Policy Iteration, along the same dimensions. It is interesting
to notice that Sutton and Barto (1998) comment their drawing as follows: “At
three of the four corners of the space are the three primary methods for estimating
values: DP, TD, and Monte Carlo”. They do not recognize the fourth corner as
one of the Reinforcement Learning primary methods. The natural representation
of λ Policy Iteration actually suggests a modiﬁcation of the sketch which is par-
ticularly meaningful: Policy Iteration, which consists in computing the value of
the current policy, is the deepest backup method, and can be considered as the
batch version of Monte Carlo.

is zero if and only if the value vk is equal to the optimal value v∗. It can be shown (see
Bertsekas and Ioﬀe (1996) for a proof or simply look at the equivalence between Equations 2
and 3 for an intuition) that the vector ∆k has components given by:

∆k(i) = lim
N→∞

N −1

Xj=0

Eπk+1 


(λγ)jδk(ij, ij+1)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)
(cid:12)

i0 = i





δk(i, j) := r(i, πk+1(i), j) + γv(j) − v(i)

with

(13)

being the temporal diﬀerence associated to transition i → j, as deﬁned by Sutton and Barto
(1998). When one uses a stochastic approximation of λ Policy Iteration, that is when the
expectation Eπt+1 is approximated by sampling, λ Policy Iteration reduces to the algorithm

14

Performance Bounds for λ Policy Iteration

TD(λ) which is described in chapter 7 of Sutton and Barto (1998).
λ = 1, the terms in the above sum collapse and become the exact discounted return:

In particular, when

N −1

Xj=0

N −1

γjδk(ij , ij+1) =

γj [r(ij, πk+1(ij), ij+1) + γv(ij+1) − v(ij)]

Xj=0
N −1

=

γjr(ij, πk+1(ij ), ij+1) + γN v(iN )

Xj=0

and the stochastic approximation matches the Monte-Carlo method. Also, Bertsekas and
Ioﬀe (1996) show that Approximate TD(λ) with a linear feature architecture, as described
in chapter 8.2 of Sutton and Barto (1998), corresponds to a natural Approximate version of
λ Policy Iteration where the value is updated by least square ﬁtting using a gradient-type
iteration after each sample. Last but not least, the reader might notice that the “uniﬁed
view” of Reinforcement Learning algorithms which is depicted in chapter 10.1 of Sutton and
Barto (1998), and which is reproduced in Figure 2, is in fact a picture of λ Policy Iteration.

3.2 Analysis of Exact λ Policy Iteration

To our knowledge, little has been done concerning the analysis of λ Policy Iteration: the
only results available concern the Exact case (when ǫk = 0). Deﬁne the following factor

β =

(1 − λ)γ
1 − λγ

.

(14)

If λ = 0 (Value Iteration) then β = γ, and if λ = 1 (Policy
We have 0 ≤ β ≤ γ < 1.
Iteration) then β = 0. In the original article introducing λ Policy Iteration, Bertsekas and
Ioﬀe (1996) show the convergence and provide an asymptotic rate of convergence:

Proposition 11 (Convergence of Exact λPI (Bertsekas and Ioﬀe, 1996))
If the discount factor γ < 1, then vk converges to v∗. Furthermore, after some index k∗, the
rate of convergence is linear in β as deﬁned in Equation 14, that is

∀k ≥ k∗, kvk+1 − v∗k ≤ βkvk − v∗k.

By making λ close to 1, β can be arbitrarily close to 0 so the above rate of convergence
might look overly impressive. This needs to be put into perspective: the index k∗ is the
index after which the policy πk does not change anymore (and is equal to the optimal policy
π∗). As we said when we introduced the algorithm, λ controls the speed at which one wants
vk to “track the target” vπk+1; when λ = 1, this is done in one step (and if πk+1 = π∗ then
vk+1 = v∗).

4. Overview of our Results and Main Proof Ideas

Now that we have described the algorithms and some of their known properties, motivating
the remaining of this paper is straightforward. λ Policy Iteration is conceptually nice since
it generalizes the two most well-known algorithms for solving discounted inﬁnite-horizon

15

Bruno Scherrer

Markov Decision Processes. The natural question that arises is whether one can generalizes
the results we have described so far to λ Policy Iteration (uniformly for all λ). The answer
is yes:

• we shall derive a componentwise analysis of Exact and Approximate λ Policy Iteration;

• we shall characterize the non-asymptotic convergence rate of Exact λ Policy Iteration
(Proposition 11 only showed the asymptotic linear convergence) and shall generalize
the stopping criterion described for Value Iteration (Proposition 1);

• we shall give bounds of the asymptotic error of Approximate λ Policy Iteration with
respect to the asymptotic approximation error, Bellman residual, and Policy Bellman
residual, that generalize Lemmas 2 and 6, and Propositions 3, 4, 7 and 8; our anal-
ysis actually implies that doing Approximate λ Policy Iteration is sound (when the
approximation error tends to 0, the algorithm recovers the optimal solution)

• we shall provide speciﬁc (better) bounds for the case when the value or the policy

converges, which generalizes Corollaries 5 and 9;

• interestingly, we shall provide all our results using the span seminorms we have in-
troduced at the beginning of the paper, and using the relations between this span
semi-norms and the standard Lp norms (Equation 1), it can be seen that our results
are in this respect slightly stronger than all the previously described results.

Conceptually, we provide a uniﬁed vision (uniﬁed proofs, uniﬁed results) for all the men-
tionned algorithms.

4.1 On the Need for a New Proof Technique

In the literature, lines of analysis are diﬀerent for Value Iteration and Policy Iteration.
Analyses of Value Iteration are based on the fact that it computes the ﬁxed point of the
Bellman operator which is a γ-contraction mapping in max norm (see for instance (Bertsekas
and Tsitsiklis, 1996)). Unfortunately, it can be shown that the operator by which Policy
Iteration updates the value from one iteration to the next is in general not a contraction in
max norm. In fact, this observation can be drawn for λ Policy Iteration as soon as it does
not reduce to Value Iteration:

Proposition 12 If λ > 0, there exists no norm for which the operator by which λ Policy
Iteration updates the value from one iteration to the next is a contraction.

Proof To see this, consider the deterministic MDP (shown in Figure 3) with two states
{1, 2} and two actions {change, stay}: r1 = 0, r2 = 1, Pchange(s2|s1) = Pchange(s1|s2) =
Pstay(s1|s1) = Pstay(s2|s2) = 1. Consider the following two value functions v = (ǫ, 0)
and v′ = (0, ǫ) with ǫ > 0. Their corresponding greedy policies are π = (stay, change) and

16

Performance Bounds for λ Policy Iteration

Figure 3: This simple deterministic MDP is used to show that λ Policy Iteration cannot be

analysed in terms of contraction (see text for details).

π′ = (change, stay). Then, we can compute the next iterates of v and v′ (using Equation 11):

rπ + (1 − λγ)P πv =

T π
λ v =

rπ′

+ (1 − λγ)P π′

v′ =

and T π′

λ v′ =

T π′
λ v′ − T π

λ v =

(cid:18)

,

(cid:19)

(1 − λ)γǫ
1 + (1 − λ)γǫ
(1−λ)γǫ
1−λγ
1 + (1−λ)γǫ

1−λγ !

,

(cid:18)

(1 − λ)γǫ
1 + (1 − λ)γǫ
1+(1−λ)γǫ

1−λγ − 1
1+(1−λ)γǫ
1−λγ

(cid:19)

!

,

.

1

1−λγ − 1
1−λγ − 1!

1

Then

while

As ǫ can be arbitrarily small, the norm of T π
of v − v′ when λ > 0.

v′ − v =

.

−ǫ
ǫ
(cid:18)
(cid:19)
λ v − T π′
λ v′ can be arbitrarily larger than norm

Analyses of Policy Iteration usually rely on the fact that the sequence of values generated
by Exact Policy Iteration is non-decreasing (see Bertsekas and Tsitsiklis (1996); Munos
(2003)). Unfortunately, it can easily be seen that as soon as λ is smaller than 1, the value
functions may decrease (it suﬃces to take a very high initial value). For non trivial values
of λ, λ Policy Iteration is neither contracting nor non-decreasing, so we need a new proof
technique.

4.2 An Overview on the Componentwise Analysis of λ Policy Iteration

The rest of this section provides an overview of our analysis. We show how to compute an
upper bound of the loss for λ Policy Iteration in the general (possibly approximate) case.
It is the basis for the derivation of componentwise bounds for Exact λ Policy Iteration

17

 
 
 
Bruno Scherrer

(Section 5) and Approximate λ Policy Iteration (Section 6). Consider λ Policy Iteration
as described in Algorithm 3, and the sequences of value-policy-error triplets (vk, πk, ǫk) it
generates. Most of our results come from a series of relations involving objects we now
deﬁne:

• the loss of using policy πk instead of the optimal policy:

lk := v∗ − vπk ;

• the value of the kth iterate b.a. (before approximation):

wk := vk − ǫk;

• the distance between the optimal value and the kth value b.a.:

dk := v∗ − wk = T πk

λ vk−1;

• the shift between the kth value b.a. and the value of the kth policy:

sk := wk − vπk ;

• the Bellman residual of the kth value:

bk := Tk+1vk − vk = T∗vk − vk.

To lighten the notations, we now on write: Pk := P πk , Tk := T πk , P∗ := P π∗. We refer to
the factor β as introduced by Bertsekas and Ioﬀe (Equation 14 page 15). Also, the following
stochastic matrix plays a recurrent role in our analysis11:

Ak := (1 − λγ)(I − λγPk)−1Pk.

(15)

We use the notation x for an upper bound of x and x for a lower bound.

Our analysis relies on a series of lemmas that we now state (for clarity, all the proofs

are deferred to Appendix A).

Lemma 13 The shift is related to the Bellman residual as follows:

sk = β(I − γPk)−1Ak(−bk−1).

Lemma 14 The Bellman residual at iteration k + 1 cannot be much lower than that at
iteration k:

where xk := (γPk − I)ǫk only depends on the approximation error.

bk+1 ≥ βAk+1bk + xk+1

11. The fact that this is indeed a stochastic matrix is explained at the beginning of the Appendices.

18

Performance Bounds for λ Policy Iteration

As a consequence, a lower bound of the Bellman residual is12:

k

bk ≥

βk−j (AkAk−1...Aj+1) xj + βk−k0 (AkAk−1...Ak0+1) bk0 := bk

Xj=k0+1

where k0 is some arbitrary reference index. Using Lemma 13, the bound on the Bellman
residual also provides an upper on the shift13:

sk ≤ β(I − γPk)−1Ak(−bk−1) := sk

Lemma 15 The distance at iteration k + 1 cannot be much greater than that at iteration k:

dk+1 ≤ γP∗dk + yk

where yk := λγ
and the approximation error.

1−λγ Ak+1(−bk) − γP∗ǫk depends on the lower bound of the Bellman residual

Then, an upper bound of the distance is14:

dk ≤

k−1

Xj=k0

γk−1−j(P∗)k−1−jyj + γk−k0(P∗)k−k0dk0 = dk.

Eventually, as

lk = dk + sk ≤ dk + sk,

the upper bounds on the distance and the shift enable us to derive the upper bound on the
loss.

Remark 16 The above derivation is a generalization of that of Munos (2003) for Approxi-
mate Policy Iteration. Note however that it is not a trivial generalization: when λ = 1, that
is when both proofs coincide, β = 0 and Lemmas 13 and 14 have the following particularly
simple form: sk = 0 and bk+1 ≥ xk+1.

The next two sections contain our main results, which take the form of performance
bounds when using λ Policy Iteration. Section 5 gathers the results concerning Exact λ
Policy Iteration, while Section 6 presents those concerning Approximate λ Policy Iteration.

5. Performance Bounds for Exact λ Policy Iteration

Consider Exact λ Policy Iteration for which we have ǫk = 0 for all k. Let k0 be some
arbitrary index. By exploiting the recursive relations we have described in the previous
section (this process is detailed in Appendix B), we can derive the following componentwise
bounds for the loss:

12. We use the property here that if some vectors satisfy the componentwise inequality x ≤ y, and if P is a

stochastic matrix, then the componentwise inequality P x ≤ P y holds.

−1 is a stochastic matrix (see Footnote 11) and Footnote 12.

13. We use the fact that (1 − γ)(I − γPk)
14. See Footnote 12.

19

Bruno Scherrer

Lemma 17 (Componentwise Rate of Convergence of Exact λPI)
For all k > k0, the following matrices

Ekk0

:= (1 − γ)(P∗)k−k0(I − γP∗)−1,

E′

kk0

:=

1 − γ
γk−k0

(cid:18)

(cid:19)





λγ
1 − λγ

k−1

Xj=k0

γk−1−jβj−k0(P∗)k−1−jAj+1Aj...Ak0+1

and Fkk0

:= (1 − γ)P k−k0

∗

+ γE′

kk0P∗

+

βk−k0(I − γPk)−1AkAk−1...Ak0+1


,

are stochastic and the performance of the policies generated by λ Policy Iteration satisﬁes

v∗ − vπk ≤

γk−k0
1 − γ
γk−k0
1 − γ
v∗ − vπk ≤ γk−k0

v∗ − vπk ≤

Fkk0 − E′

kk0

(v∗ − vk0),

(cid:2)
Ekk0 − E′

(cid:3)
kk0

(T∗vk0 − vk0), and

(16)

(17)

(cid:2)
(P∗)k−k0

(cid:3)

(v∗ − vk0) − min

[v∗(s) − vk0(s)]e

+ kv∗(s) − vπk0+1k∞ e

.(18)

s

h

(cid:16)

(cid:17)

i

In order to derive (more interpretable) span seminorms bounds from the above compo-
nentwise bound, we rely on the following lemma, which for clarity of exposition is proved
in Appendix F.

Lemma 18 If for some non-negative vectors x and y, some constant K ≥ 0, and some
stochastic matrices X and X ′ we have

Then

x ≤ K(X − X ′)y,

kxk∞ ≤ K span

∞

[y] .

With this, the componentwise bounds of Lemma 17 become:

Proposition 19 (Non-asymptotic bounds for Exact λ Policy Iteration)
For any k > k0,

kv∗ − vπk k∞ ≤

kv∗ − vπk k∞ ≤

γk−k0
1 − γ
γk−k0
1 − γ

span
∞

span
∞

[v∗ − vk0] ,

[T∗vk0 − vk0] ,

and kv∗ − vπk k∞ ≤ γk−k0

[v∗ − vk0] + kv∗(s) − vπk0+1k∞

.

(cid:19)

span
∞

(cid:18)

20

(19)

(20)

(21)

Performance Bounds for λ Policy Iteration

This non-asympotic bound supplements the asymptotic bound of Proposition 11 from Bert-
sekas and Ioﬀe (1996). Remarkably, these bounds do not depend on the value λ: whatever
the value of λ, all algorithms have the same above rates. The bound of Equation 19 is
expressed in terms of the distance between the value function and the optimal value func-
tion at some iteration k0. The second inequality, Equation 20, can be used as a stopping
criterion.
Indeed, taking k = k0 + 1 it implies the following stopping condition, which
generalizes that of Proposition 1 about Value Iteration:

Proposition 20 (Stopping condition of Exact λ Policy Iteration)
If at some iteration k0, the value vk0 satisﬁes:

span
∞

[T∗vk0 − vk0] ≤

1 − γ
γ

ǫ

then the greedy policy πk0+1 with respect to vk0 is ǫ-optimal: kv∗ − vπk0+1k∞ < ǫ.

The last inequality described in Equation 21 relies on the distance between the value
function and the optimal value function and the value diﬀerence between the optimal policy
and the ﬁrst greedy policy; compared to the others, it has the advantage of not containing
1
1−γ factor. To our knowledge, this bound is even new for the speciﬁc cases of Value
a
Iteration and Policy Iteration.

6. Performance Bounds for Approximate λ Policy Iteration

We now turn to the (slightly more involved) results on Approximate λ Policy Iteration. We
provide componentwise bounds of the loss v∗ − vπk ≥ 0 of using policy πk instead of using
the optimal policy, with respect to the approximation error ǫk, the Policy Bellman residual
Tkvk − vk and the Bellman residual T∗vk − vk = Tk+1vk − vk. Recall the subtle diﬀerence
between these two Bellman residuals: the Policy Bellman residual says how much vk diﬀers
from the value of πk while the Bellman residual says how much vk diﬀers from the value of
the policies πk+1 and π∗.

The core of our analysis is based on the following lemma:

Lemma 21 (Componentwise Performance bounds for App. λ Policy Iteration)

For all k > j ≥ 0, the following matrices

Bjk

:=

1 − γ
γk−j 

λγ
1 − λγ



k−1

Xi=j

γk−1−iβi−j(P∗)k−1−iAi+1Ai...Aj+1

+ βk−j(I − γPk)−1AkAk−1...Aj+1


:= γBjkPj + (1 − γ)(P∗)k−j
B′
jk
:= (1 − γ)2(I − γP∗)−1
Ck
:= (1 − γ)2(I − γP∗)−1
C ′
(cid:0)
k
D := (1 − γ)P∗(I − γP∗)−1
(cid:0)
:= (1 − γ)Pk(I − γPk)−1
D′
k

P∗(I − γPk)−1
Pk+1(I − γPk+1)−1

(cid:1)

(cid:1)

21

Bruno Scherrer

are stochastic and

∀k0,

lim sup
k→∞

v∗ − vπk ≤

1
1 − γ

lim sup
k→∞

lim sup
k→∞

v∗ − vπk ≤

and ∀k, v∗ − vπk ≤

γ

(1 − γ)2 lim sup
k→∞
D − D′
k

γ
1 − γ

k−1

γk−j

Bjk − B′
jk

ǫj,

Xj=k0

(cid:2)
[Ck − C ′
k](Tkvk − vk),

(cid:3)

(T∗vk−1 − vk−1).

(22)

(23)

(24)

(cid:2)
The ﬁrst relation (Equation 22) involves the errors (ǫk), is based on Lemmas 13-15
(presented in Section 4) and is proved in Appendix C. The two other inequalities (the
asymptotic performance of Approximate λ Policy Iteration with respect to the Bellman
residuals in Equations 23 and 24) are somewhat simpler and are proved independently in
Appendix D.

(cid:3)

Remark 22 (Relation with the previous bounds of Munos (2007, 2003)) We can
look at the relation between our bound for general λ and the bounds derived separately
by Munos for Approximate Value Iteraton (Lemma 2) and Approximate Policy Iteraton
(Lemma 6):

• Let us ﬁrst consider the case where λ = 0. Then β = γ, Ak = Pk and

Bjk = (1 − γ)(I − γPk)−1PkPk−1...Pj+1.

Then our bound implies that lim supk→∞ v∗ − vπk is upper bounded by:

γk−j

(I − γPk)−1PkPk−1...Pj+1

lim sup
k→∞

k−1

Xj=k0

h

−

γ(I − γPk)−1PkPk−1...Pj + (P∗)k−j
(cid:16)

(cid:17)i

ǫj.

(25)

The bound derived by Munos for Approximate Value Iteration (Lemma 2 page 6) is

k−1

(I − γPk)−1

γk−j

PkPk−1...Pj+1 − (P∗)k−j

ǫj

Xj=0

h

i

γk−j

(I − γPk)−1PkPk−1...Pj+1 − (I − γPk)−1(P∗)k−j

ǫj

h

i

γk−j

(I − γPk)−1PkPk−1...Pj+1

lim sup
k→∞

= lim sup
k→∞

= lim sup
k→∞

k−1

Xj=0
k−1

Xj=0

h

−

(I − γPk)−1γPk(P∗)k−j + (P∗)k−j
(cid:16)

(cid:17)i

ǫj.

(26)

The above bounds are very close to each other: we can go from Equation 25 to
Equation 26 by replacing Pk−1...Pj by (P∗)k−j.

22

Performance Bounds for λ Policy Iteration

• Now, when λ = 1, β = 0, Ak = (1 − γ)(I − γPk)−1Pk and

Bjk = (1 − γ)(P∗)k−1−jPj+1(I − γPj+1)−1.

Our bound is

with

lim sup
k→∞

v∗ − vπk ≤ lim sup
k→∞

γk−1−j(P∗)k−1−juj

k−1

Xj=k0

uj :=

γPj+1(I − γPj+1)−1(I − γPj) − γP∗

ǫj.

By deﬁnition of the supremum limit, for all ǫ > 0, there exists an index k1 such that
for all j ≥ k1,

(cid:3)

(cid:2)

uj ≤ lim sup

l→∞

ul + ǫe.

Then:

lim sup
k→∞

k−1

Xj=k1

γk−1−j(P∗)k−1−juj ≤ lim sup
k→∞

k−1

γk−1−j(P∗)k−1−j

lim sup
l→∞

(cid:18)

ul + ǫe

(cid:19)

Xj=k1
= (I − γP∗)−1

lim sup
l→∞

(cid:18)

ul + ǫe

.

(cid:19)

As this is true for all ǫ > 0, we eventually ﬁnd the bound of Munos for Approximate
Policy Iteration (Lemma 6 page 9).

Thus, up to some little details, our componentwise analysis uniﬁes those of Munos. It is not
a surprise that we fall back on the result of Munos for Approximate Policy Iteration because,
as already mentionned in Remark 16, the proof we developed in Section 4 and Appendix A
is a generalization of his. If we don’t exactly recover the componentwise analysis of Munos
for Approximate Value Iteration, this is not really fundamental as it will not aﬀect most of
the results we derive.

The componentwise bounds on the performance of Approximate λ Policy Iteration can
be translated into span seminorm bounds, using the following Lemma (proved in Ap-
pendix F):

Lemma 23 Let xk, yk be vectors and Xjk, X ′

jk stochastic matrices satisfying

∀k0,

lim sup
k→∞

|xk| ≤ K lim sup
k→∞

ξk−j(Xkj − X ′

kj)yj,

k−1

Xj=k0

where (ξi)i≥1 is a sequence of non-negative weights satisfying:

ξi = K ′ < ∞,

∞

Xi=1

23

Bruno Scherrer

then, for all distribution µ,

are distributions and

µkj :=

1
2

(Xkj + X ′

kj)T µ

lim sup
k→∞

kxkkp,µ ≤ KK ′

lim
k0→∞ ""

sup
k≥j≥k0

span
p,µkj

[yj]

#

.

1−γ , Lemma 21 can be turned into the
Thus, using this Lemma and the fact that
following proposition that uniﬁes and generalizes Proposition 3 (page 6) on Approximate
Value Iteration and Proposition 7 (page 9) on Approximate Policy Iteration.

P

∞

i=1 γi = γ

Proposition 24 (Span Seminorm Performance of Approximate λPI (1/2))
With the notations of Lemma 21, for all p, k > j ≥ 0 and all distribution µ,

µkj :=

µ′
kj :=

µ′′
kj :=

1
2
1
2
1
2

Bjk + B′
jk

T µ,

(cid:0)
Ck + C ′
k

(cid:1)
T µ, and

(cid:0)
D + D′
k

(cid:1)
T µ

are distributions and the performance of the policies generated by λ Policy Iteration satisﬁes:

(cid:0)

(cid:1)

lim sup
k→∞

lim sup
k→∞

kv∗ − vπk kp,µ ≤

kv∗ − vπk kp,µ ≤

∀k,

kv∗ − vπk kp,µ ≤

γ
(1 − γ)2
γ

lim
k0→∞ ""
(1 − γ)2 lim sup

k→∞

sup
k≥j≥k0

span
p,µkj

,

[ǫj]

#

[Tkvk − vk] ,

span
p,µ′
kj

γ
1 − γ

span
p,µ′′
kj

[T∗vk−1 − vk−1] .

As already mentionned, a drawback of the above Lp bounds comes from the fact that
the distributions involved on the right hand sides are unknown. To go round this issue,
one may consider the concentration coeﬃcient assumption introduced by Munos (2003,
2007) and already mentioned in Equation 6 page 7. For clarity, we recall its deﬁnition here.
We assume there exists a distribution ν and a real number C(ν) such that

C(ν) := max
i,j,a

pij(a)
ν(j)

.

Then, we have the following property:

Lemma 25 Let X be an average of products of stochastic matrices of the MDP. For any
distribution µ, and vector y and any p,

span
p,X T µ

[y] ≤ (C(ν))1/p span
p,ν

[y] .

24

Performance Bounds for λ Policy Iteration

Proof It can be seen from the deﬁnition of the concentration coeﬃcient C(ν) that µT X ≤
C(ν)νT . Thus,

p

span
p,X T µ

[y]

!

= min

a

ky − aekp,X T µ
(cid:16)
µT X|y − ae|p

p

(cid:17)

= min

a
≤ C(ν) min

a

= C(ν) min

a

= C(ν)

νT |y − ae|p

ky − aekp,ν
p

p

(cid:17)

(cid:16)
span
p,ν

(cid:18)

[y]

.

(cid:19)

Using this Lemma, and the fact that for any p, kxk∞ = maxµ kxkp,µ, the Lp bounds of

Proposition 24 become

Proposition 26 (Span Seminorm Performance of Approximate λPI (2/2))
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. For all p and all k,

lim sup
k→∞

lim sup
k→∞

kv∗ − vπk k∞ ≤

kv∗ − vπk k∞ ≤

and ∀k,

kv∗ − vπk k∞ ≤

γ

γ

j→∞

(1 − γ)2 [C(ν)]1/p lim sup
(1 − γ)2 [C(ν)]1/p lim sup
γ
[C(ν)]1/p span
1 − γ
p,ν

k→∞

span
p,ν

[ǫj] ,

span
p,ν

[Tkvk − vk] ,

[T∗vk−1 − vk−1] .

This results generalizes and uniﬁes those derived for Approximate Value Iteration (Propo-

sition 4 page 7) and Approximate Policy Iteration (Proposition 8 page 10).

When comparing the speciﬁc bounds of Munos for Approximate Value Iteration (Propo-
sitions 3 and 4) and Approximate Policy Iteration (Propositions 7 and 8), we wrote that the
latter had the nice property that the bounds only depend on asymptotic errors/residuals
(while the former depends on all errors). Our bounds for λ Policy Iteration have this nice
property too. Considering the relations between the span seminorms and the other stan-
dard norms (Equation 1 page 3), we see that our results are not only more general, but also
slightly ﬁner than those of Munos.

When the policy or the value converges The performance bounds with respect to
the approximation error can be improved if we know or observe that the value or the policy
converges. Note that the former condition implies the latter (while the opposite is not
true: the policy may converge while the value still oscillates). Indeed, we have the following
Corollary.

Corollary 27 (Performance of Approximate λPI in case of convergence)
If the value converges to some v, then the approximation error converges to some ǫ, and the
corresponding greedy policy π satisﬁes

kv∗ − vπk∞ ≤

γ
1 − γ

[C(ν)]1/p span
p,ν

[ǫ] .

25

 
Bruno Scherrer

If the policy converges to some π, then

kv∗ − vπk∞ ≤

γ(1 − λγ)
(1 − γ)2 [C(ν)]1/p lim sup

j→∞

span
p,ν

[ǫj] .

These bounds, proved in Appendix E, unify and extend those presented for Approximate
Value Iteration (Corollary 5 page 7) and Approximate Policy Iteration (Corollary 9 page
10), in the similar situation where the policy or the value converges. It is interesting to
notice that in the weaker situation where only the policy converges, the constant decreases
from 1
1−γ when λ varies from 0 to 1; in other words, the closer to Policy Iteration,
the better the bound in that situation.

(1−γ)2 to 1

7. Application of λ Policy Iteration to the Game of Tetris

In the ﬁnal part of this paper, we consider (and describe for the sake of keeping this paper
self-contained) exactly the same application (Tetris) and implementation as Bertsekas and
Ioﬀe (1996). Our motivation for doing so is twofold:

• from a theoretical point of view, we show how our analysis (made in the discounted
case γ < 1) can be adapted to an undiscounted problem (where γ = 1) like Tetris;

• we obtain empirical results that are diﬀerent (and much less intriguing) than those of
the original study. This gives us the opportunity to describe what we think are the
reasons for such a diﬀerence.

But before doing so, we begin by describing the Tetris domain.

7.1 The Game of Tetris and its Model as an MDP

Tetris is a popular video game created in 1985 by Alexey Pajitnov. The game is played on
a 10 × 20 grid where pieces of diﬀerent shapes fall from the top (see Figure 4). The player
has to choose where each piece is added: he can move it horizontally and rotate it. When
a row is ﬁlled, it is removed and all cells above it move one row downwards. The goal is to
remove as many lines as possible before the game is over, that is when there is not enough
space remaining on the top of the pile to put the current new piece.

Instead of mimicking the original game (precisely described by Fahey (2003)), Bertsekas
and Ioﬀe (1996) have focused on the main problem, that is choosing where to drop each
coming piece. The corresponding MDP model is straightforward: the state consists of the
wall conﬁguration and the shape of the current falling piece. An action is the horizontal
translation and the rotation which are applied to the piece before it is dropped on the wall.
The reward is the number of lines which are removed after we have dropped the piece. As
one considers the maximization of the score (the total number of lines removed during a
game), the natural choice for the discount factor is γ = 1.

In a bit more details, the dynamics of Tetris is made of two components: the place
where one drops the current piece and the choice of a new piece. As the latter component is
uncontrollable (a new piece is chosen with uniform probability), the value functions needs
not to be computed for all wall-piece pairs conﬁgurations but only for all wall conﬁgurations

26

Performance Bounds for λ Policy Iteration

Figure 4: Left: a screenshot of a Tetris game. Right: the seven existing shapes.

(see for instance (Bertsekas and Ioﬀe, 1996)). Also considering that the ﬁrst component
of the dynamics is deterministic, the optimal value function satisﬁes a reduced form of the
Bellman Equation

∀s ∈ S, v∗(s) =

1
|P|

max
a∈A(p)

Xp∈P

r(s, p, a) + v∗(succ(s, p, a))

(27)

where S is the set of wall conﬁgurations, P is the set of pieces, A(p) is the set of translation-
rotation pairs that can be applied to a piece p, r(s, p, a) and succ(s, p, a) are respectively
the number of lines removed and the (deterministic) next wall conﬁguration if one puts a
piece p on the wall s in translation-orientation a. The only function that satisﬁes the above
Equation gives, for each wall conﬁguration s, the average best score that can be achieved
from s. If we know this function, a one step look-ahead strategy (that is a greedy policy)
performs optimally.

Extension of the analysis for the undiscounted optimal control problem Tetris
As just explained, the Tetris domain has a discount factor γ equal to 1, which makes it
an undiscounted MDP. If this prevents us from applying directly most of the analysis we
have made so far (since most of our bounds have a (1 − γ) term on the denominator), we
brieﬂy show in what follows how to adapt the analysis so that we recover a signiﬁcant error
analysis.

In undiscounted inﬁnite horizon control problems, it is generally assumed that there
exists a N + 1th termination absorbing state 0. Once the system reaches this state, it
remains there forever with no further reward, that is formally:

∀a, p00(a) = 1 and r(0, a, 0) = 0.

In the case of Tetris, the termination state corresponds to “game over”, and the situation
is particulary simple since Burgiel (1997) has shown that, whatever the strategy, some
sequence of pieces (which necessarily occurs in ﬁnite time with probability 1) leads to

27

Bruno Scherrer

game-over whatever the decisions taken15. This implies in particular that there exists an
integer n0 ≤ N and a real number α < 1 such that for all initial distributions µ, and actions
a0, a1, ..., an0−1,

P [in0 6= 0|i0 ∼ µ, a0, ..., an0−1] ≤ α.

(28)

We can deﬁne the MDP model for Tetris only on the N non-terminal states, that is on
In this situation, for any policy π, the matrix Pπ is in general a substochastic
{1, ...N }.
matrix (a matrix of which the components are non-negative and for which the max norm is
smaller than or equal to 1), and the above assumption means that for all set of n0 policies
π1, π2, · · · , πn0,

Pπ1Pπ2 · · · Pπn0

∞ ≤ α.

The componentwise analysis of λ Policy Iteration is here identical to what we have done
before, except that we have16 γ = 1 and β = 1. The matrix Ak that appeared recurrently
in our analysis has the following special form:

(cid:13)
(cid:13)

(cid:13)
(cid:13)

Ak := (1 − λ)(I − λPk)−1Pk.

and is a substochastic matrix. The ﬁrst bound of the componentwise analysis of λ Policy
Iteration (Lemma 21 page 21) can be shown to be generalized as follows (see Appendix G
for details):

Lemma 28 (Componentwise Bounds in the Undiscounted Case)
Assume that there exists n0 and α such that Equation 28 holds. Write η := 1−λn0
i, write

1−λn0 α . For all

δi := αj

i
n0 k

1 − λn0
1 − λ

λ
1 − λn0α

1 − ηi
1 − η

+

n0ηi
1 − α

.

(cid:21)

(cid:19)

(cid:19) (cid:18)

(cid:19) (cid:18)

(cid:20)(cid:18)

For all j < k, the following matrices

Gjk

:=

and G′

jk

:=

k−1

Xi=j

1
δk−j 

λ
1 − λ


GjkPj

1
δk−j

(P∗)k−1−iAi+1Ai...Aj+1 + (I − Pk)−1AkAk−1...Aj+1


are substochastic and the performance of the policies generated by λ Policy Iteration satisﬁes

∀k0,

lim sup
k→∞

v∗ − vπk ≤ lim sup
k→∞

k−1

Xj=k0

δk−j

Gjk − G′

jk

ǫj.

(29)

(cid:2)

(cid:3)

15. In the literature, a stationary policy that reaches the terminal state in ﬁnite time with probability 1 is
said to be proper. The usual assumptions in undiscounted inﬁnite horizon control problems are: (i) there
exists at least one proper policy and (ii) for every improper policy π, the corresponding value equals
−∞ for at least one state. A simpler situation is when all stationary policies are proper. The situation
of Tetris is even simpler: all non necessarily stationary policies are proper.

16. For simplicity in our discussion, we consider λ < 1 to avoid the special case λ = 1 for which β = 0 (see
Equation 14). The interested reader may however check that the results that we state are continuous in
the neighborhood of λ = 1.

28

Performance Bounds for λ Policy Iteration

Remark 29 By observing that η ∈ (0, 1), and that for all x ∈ (0, 1), 0 ≤ 1−xn0
1−x ≤ n0, it can
be seen that the coeﬃcients δi are ﬁnite for all i. Furthermore, when n0 = 1 (which matches
the discounted case with α = γ), one can observe that δi = γi
1−γ and that one recovers the
result of Lemma 21.

This lemma can then be exploited to show that λ Policy Iteration enjoys an Lp norm
guarantee. Indeed, an analogue of Proposition 24 (whose proof is detailed in Appendix G)
is the following proposition.

Proposition 30 (Lp norm Bound for in the Undiscounted Case)
Let C(ν) be the concentration coeﬃcient deﬁned in Equation 6. Let the notations of
Lemma 28 hold. For all distribution µ on (1, · · · , N ) and k > j ≥ 0,

are non-negative vectors and

µkj :=

1
2

(cid:0)

Gjk + G′
jk

T µ

(cid:1)

˜µkj :=

µkj
kµkjk1

are distributions on (1, · · · , N ). Then for all p, the loss of the policies generated by λ Policy
Iteration satisﬁes

lim sup
k→∞

kv∗ − vπk kp,µ ≤ K(λ, n0)(C(ν))1/p lim
j→∞

kǫjkp,˜µkj

where

K(λ, n0) := λf (λ)

f (1) − f (η)
1 − η
(1 − xn0)
(1 − x)(1 − xn0α)

+ f (1)f (η) − f (1),

, and by continuity f (1) :=

n0
1 − α

.

∀x < 1, f (x) :=

Remark 31 There are three diﬀerences with respect to the results we have presented for
the discounted case.

1. The fact that we deﬁned the model (and thus the algorithm) only on the non-terminal
states (1, · · · , N ) implies that there is no error incurred in the terminal state 0. Note,
however, that this is not a strong assumption since the value of the terminal state is
necessarily 0.

2. The right hand side depends on the Lp norm, and not the span Lp seminorm. This is
jk deﬁned above are in general substochas-

due to the fact that the matrices Gjk and G′
tic matrices (and not stochastic matrices).

3. Eventually, the constant K(λ, n0) depends on λ. More precisely, it can be observed

that:

lim
λ→0

K(λ, n0) = lim
λ→1

K(λ, n0) =

2

n0
(1 − α)2 −

n0
1 − α

and that this is the minimal value of λ 7→ K(λ, n0). Though we took particular care in
deriving this bound, we leave for future work the question whether one could prove a

29

Bruno Scherrer

similar result with the constant
1−α for any λ ∈ (0, 1). When n0 = 1 (which
matches the discounted case with α = γ), K(λ, 1) does not depend anymore on λ and
we recover (without surprise) the bound of Proposition 24:

n0

(1−α)2 − n0

2

∀λ, K(λ, 1) =

α
(1 − α)2 .

Now that we are reassured about the fact that applying λ Policy Iteration approximately

to Tetris is principled, we turn to the precise description of its actual implementation.

7.2 An Instance of Approximate λ Policy Iteration

For large scale problems, many Approximate Dynamic Programming algorithms are based
on two complementary tricks:

• one uses samples to approximate the expectations such as that of Equation 13;

• one only looks for a linear approximation of the optimal value function:

vθ(s) = θ(0) +

θ(k)Φk(s)

K

Xk=1

where θ = (θ(0) . . . θ(K)) is the parameter vector and Φk(s) are some predeﬁned
feature functions on the state space. Thus, each value of θ characterizes a value
function vθ over the entire state space.

The instance of Approximate λ Policy Iteration of Bertsekas and Ioﬀe (1996) follows these
ideas. More speciﬁcally, this algorithm is devoted to MDPs which have a termination state,
that has 0 reward and is absorbing. For this algorithm to be run, one must further assume
that all policies are proper, which means that all policies reach the termination state with
probability one in ﬁnite time17.

Similarly to Exact λ Policy Iteration, this Approximate λ Policy Iteration maintains
a compact value-policy pair (θt, πt). Given θt, πt+1 is the greedy policy with respect to
vθt, and can easily be computed exactly in any given state as the argmax in Equation 27.
This policy πt+1 is used to simulate a batch of M trajectories:
for each trajectory m,
(sm,0, sm,1, . . . , sm,Nm−1, sm,Nm) denotes the sequence of states of the mth trajectory, with
sm,Nm being the termination state. Then for approximating Equation 13, a reasonable

17. Bertsekas and Ioﬀe (1996) consider a weaker assumption for Exact λ Policy Iteration and its analysis,
namely that there exists at least one propoer policy. However, this assumption is not suﬃcient for their
Approximate algorithm, because this builds sample trajectories that need to reach a termination state.
If the terminal state were not reachable in ﬁnite time, this algorithm may not terminate in ﬁnite time.

30

Performance Bounds for λ Policy Iteration

choice for θt+1 is one that satisﬁes:

vθt+1(sm,Nm) ≃ 0

(30)

vθt+1(sm,Nm−1) ≃ vθt(sm,Nm−1) + δt(sm,Nm−1, sm,Nm)
vθt+1(sm,Nm−2) ≃ vθt(sm,Nm−2) + δt(sm,Nm−2, sm,Nm−1) + γλδt(sm,Nm−1, sm,Nm)

...

...

vθt+1(sm,k) ≃ vθt(sm,k) +

...

...

Nm−1

Xs=k

Nm−1

(γλ)s−kδt(sm,s, sm,s+1)

vθt+1(sm,0) ≃ vθt(sm,0) +

(γλ)sδt(sm,s, sm,s+1)

for all trajectories m, where

s=0
X

δt(sm,Nm−1, sm,Nm) = r(sm,Nm−1, πt+1(sm,Nm−1), sm,Nm ) − vθt(sm,Nm−1)

(31)

and for all s < Nm − 1

δt(sm,s, sm,s+1) = r(sm,s, πt+1(sm,s), sm,s+1) + γvθt(sm,s+1) − vθt(sm,s)

are the temporal diﬀerences. Note that Equations 30 and 31 correspond to the terminal
states for which there is no subsequent rewards. A standard and eﬃcient solution to this
problem consists in minimizing the least squares error, that is to choose θt+1 as follows:

θt+1 = arg min

θ

M

Nm

Xm=1

Xk=0



vθ(sm,k) − vθt(sm,k) −



(γλ)j−kδt(sm,j, sm,j+1)



2

.

Nm−1

Xj=k



This approximate version of λ Policy Iteration generalizes well-known algorithms. When
λ = 0, the generic term becomes a sample of [T πk+1v](sm,k):

vθt+1(sm,k) ≃ vθt(sm,k) + δt(sm,k, sm,k+1)

= r(sm,k, πt+1(sm,k), sm,k+1) + γvθt(sm,k+1).

(32)

When λ = 1, the generic term becomes the sampled discounted return from sm,k until the
end of the trajectory:

vθt+1(sm,k) ≃ vθt (sm,k) +

γs−kδt(sm,s, sm,s+1)

Nm−1

Nm−1

Xs=k

=

γs−kr(sm,k, πt+1(sm,k), sm,k+1).

(33)

Xs=k

In other words, for these limit values of λ, the algorithms correspond to approximate ver-
sions of Value Iteration and Policy Iteration as described by Bertsekas and Tsitsiklis (1996).

31

 10000
 10000
 10000
 10000
 10000
 10000
 10000
 10000
 10000
 10000
 10000

 8000
 8000
 8000
 8000
 8000
 8000
 8000
 8000
 8000
 8000
 8000

 6000
 6000
 6000
 6000
 6000
 6000
 6000
 6000
 6000
 6000
 6000

 4000
 4000
 4000
 4000
 4000
 4000
 4000
 4000
 4000
 4000
 4000

 2000
 2000
 2000
 2000
 2000
 2000
 2000
 2000
 2000
 2000
 2000

s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
e
e
e
m
m
m
m
m
m
m
m
m
m
m
a
a
a
a
a
a
a
a
a
a
a
g
g
g
g
g
g
g
g
g
g
g
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1
n
n
n
n
n
n
n
n
n
n
n
o
o
o
o
o
o
o
o
o
o
o
s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
e
e
e
r
r
r
r
r
r
r
r
r
r
r
o
o
o
o
o
o
o
o
o
o
o
c
c
c
c
c
c
c
c
c
c
c
s
s
s
s
s
s
s
s
s
s
s

e
e
e
e
e
e
e
e
e
e
e
g
g
g
g
g
g
g
g
g
g
g
a
a
a
a
a
a
a
a
a
a
a
r
r
r
r
r
r
r
r
r
r
r
e
e
e
e
e
e
e
e
e
e
e
v
v
v
v
v
v
v
v
v
v
v
A
A
A
A
A
A
A
A
A
A
A

Bruno Scherrer

 5000

 4000

 3000

 2000

 1000

s
e
m
a
g
0
0
1
n
o
s
e
r
o
c
s

e
g
a
r
e
v
a

f

o
s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0
 0
 0
 0
 0
 0
 0
 0
 0
 0
 0

 0
 0
 0
 0
 0
 0
 0
 0
 0
 0
 0

 20
 20
 20
 20
 20
 20
 20
 20
 20
 20
 20

 40
 40
 40
 40
 40
 40
 40
 40
 40
 40
 40

 60
 60
 60
 60
 60
 60
 60
 60
 60
 60
 60

 80
 80
 80
 80
 80
 80
 80
 80
 80
 80
 80

 100
 100
 100
 100
 100
 100
 100
 100
 100
 100
 100

Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations

 0

 0

 10

 20

 30

 40

0.0
0.3
0.5
0.7
0.9

 50
Iterations

 60

 70

 80

 90

 100

Figure 5: Average Score versus the number of iterations Left: 10 runs of λP I with λ = 0.9.
Each point of each run is the average score computed with M = 100 games. The
dark curve is a pointwise average of the 10 runs. Right: Pointwise average of
10 runs of λP I for diﬀerent values of λ; the curve which appears to be the best
(λ = 0.9) is the same as the bold curve of the left graph.

Also, as explained by Bertsekas and Ioﬀe (1996) and already mentioned in the introduction,
the TD(λ) algorithm with linear features described by Sutton and Barto (1998, chapter 8.2)
matches the algorithm we have just described when the above ﬁtting problem is approxi-
mated using gradient iterations after each sample.

We follow the same protocol as originally proposed by Bertsekas and Ioﬀe (1996). Let
w = 10 be the width of the board. We consider approximating the value function as a linear
combination of 2w + 1 = 21 feature functions:

V θ(s) = θ(0) +

w

Xk=1

where:

w−1

θ(k)hk +

θ(k + w)∆hk + θ(2w)H + θ(2w + 1)L

Xk=1

• for all k ∈ {1, 2, · · · , w}, hk is the height of the kth column of the wall;

• for all k ∈ {1, 2, · · · , w − 1}, ∆hk is the height diﬀerence |hk − hk+1| between columns

k and k + 1;

• H is the maximum wall height maxk hk;

• L is the number of holes (the number of empty cells covered by at least one full cell).

We started our experiments with the initial following vector: r(2w) = −10, r(2w + 1) =
−1 and r(k) = 0 for all k < 2w, so that the initial greedy policy scores in the low tens
(Bertsekas and Ioﬀe (1996)). We used M = 100 training games for each policy update.
As λP I is a stochastic algorithm, we ran each experiment 10 times. Figure 5 displays the
learning curves. The left graph shows the 10 runs of λP I (each point is the average score
computed with the M = 100 games) and the corresponding pointwise average for a single

32

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Performance Bounds for λ Policy Iteration

value of λ, while the right graph shows such pointwise average curves for diﬀerent values of
λ: 0.0, 0.3, 0.5, 0.7 and 0.9. We chose to display on the left graph the runs corresponding
to the value of λ = 0.9 that seemed to be the best on the right graph.

We can make the following observations.

• Though we initialized with not so bad a policy (the ﬁrst value is around 30), the per-
formance ﬁrst drops to 0 and it really starts improving after a few iterations (typically
arount ten). This is due to the fact that the initial value function is really bad: with
the given parameters, the initial value is everywhere negative although it is clear that
the optimal value function (the average best score) is everywhere positive. Further
experiments showed that the overall behaviour of the algorithm was not aﬀected by
the weight initialization.

• The rise of performance globally happens sooner for larger values of λ, that is for
values that makes the algorithm closer to Policy Iteration. This is not surprising as it
complies with the fact that λ modulates the speed at which the value estimate tracks
the real value of the current policy. However, the performance did not rise for λ = 1
(when it is equivalent to Approximate Policy Iteration), and this is probably due to
the fact that the variance of the value update is too high.

• Quantitatively, the scores reach an overall level of 4000 lines per games for a big range

of values of λ.

The empirical results we have just described qualitatively and quantitatively diﬀer from
the ones that were originally published in Bertsekas and Ioﬀe (1996), even though it is the
exact same experimental setup. About their results, the authors wrote: “An interesting and
somewhat paradoxical observation is that a high performance is achieved after relatively few
policy iterations, but the performance gradually drops signiﬁcantly. We have no explanation
for this intriguing phenomenon, which occurred with all of the successful methods that we
tried”. As we explain now, we believe that the “intriguing” character of the results of
Bertsekas and Ioﬀe (1996) might be related to a subtle implementation diﬀerence. Indeed,
we can reproduce learning curves that are similar to those of Bertsekas and Ioﬀe (1996) with
a little modiﬁcation in our implementation of λP I, that removes the special treatments for
the terminal states done through Equations 30 and 31. More precisely, if we replace them
by the following Equations:

δt(sm,Nm−1, sm,Nm) = r(sm,Nm−1, πt+1(sm,Nm−1)) + γvθt (sm,Nm) − vθt(sm,Nm−1)

vθt+1(sm,Nm) ≃ vθt(sm,Nm)

(34)

(35)

that is if we replace the terminal value 0 by the value V θt(sm,Nm) which is computed through
the features of the terminal wall conﬁguration sm,Nm, then we get the performance shown
in Figure 6. This ﬁgure shows the performance with respect to the iterations. We observe
that the performance evolution qualitatively matches the performance curves published in
Bertsekas and Ioﬀe (1996) and illustrates the above quotation describing the “intriguing
phenomenon”18.

18. The watchful reader may have noticed that the performance that we obtain is about twice that of
Bertsekas and Ioﬀe (1996). A close inspection of the Tetris domain description in (Bertsekas and Ioﬀe,

33

Bruno Scherrer

0.0
0.3
0.5
0.7

 6000

 5000

 4000

 3000

 2000

 1000

s
e
m
a
g
0
0
1
n
o
s
e
r
o
c
s

e
g
a
r
e
v
a

f

o
s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0

 0

 2

 4

 6

 8
Iterations

 10

 12

 14

 16

Figure 6: Left: Average score versus the number of iterations of λP I, modiﬁed so that it
resembles the results of Bertsekas and Ioﬀe (1996) (see text for details). Right:
A scan of the learning curves obtained by Bertsekas and Ioﬀe (1996).

in
In such a modiﬁed form, the approximate λP I algorithm makes much less sense:
particular, it is not true anymore that it reduces to approximate Value Iteration and ap-
proximate Policy Iteration when λ = 0 and λ = 1 respectively: Equations 34 and 35 induce
a bias so that we cannot recover the identities of Equations 32 and 33. A closer examination
of these experiments showed that the weights (θk) were diverging. This is not a surprise,
since the use of Equations 34 and 35 violates the condition expressed in Remark 31-1 that
there should be no error in the terminal state.

8. Conclusion and Future Work

We have considered the λ Policy Iteration algorithm introduced by Bertsekas and Ioﬀe
(1996) that generalizes the standard algorithms Value Iteration and Policy Iteration. We
have reviewed some results by Puterman (1994), Bertsekas and Tsitsiklis (1996) and Munos
(2003, 2007), concerning the rate of convergence and some performance bounds of these
standard algorithms in the exact and approximate cases. We have extended these results to
λ Policy Iteration and derived convergence rates and performance bound for this algorithm,
some of which are to our knowledge even new in the cases where λ Policy Iteration reduces
to Value Iteration and Policy Iteration, notably the bound 21 (page 20). Not only does our
analysis generalize previous results, but it improves them in two ways:

• as suggested by the results of Puterman (1994) in the exact case, the use of the span

seminorm has enabled us to derive tighter bounds;

1996) shows that the authors consider the game of Tetris on a 10 × 19 board instead of our 10 × 20
setting, and as argued in a recent review on Tetris (Thi´ery and Scherrer, 2009), this small diﬀerence is
suﬃcient for explaining such a big performance diﬀerence.

34

 
 
 
 
 
 
 
 
 
Performance Bounds for λ Policy Iteration

• our analysis of Approximate λ Policy Iteration relates the asymptotic performance of
the algorithm to the asymptotic errors/residuals instead of a uniform bound of the
errors/residuals and this might be of practical interest19.

More generally, we believe that an important contribution of this paper is of conceptual
nature: we provide a uniﬁed vision of some of the main Approximate Dynamic Programming
algorithms and their analyses; in particular, we hope that the new proof technique that is
detailed in the appendices — especially the diﬀerent objects that are deﬁned in our proof
overview in Section 4.2 — shall be useful for further studies.

As we mentionned earlier, Munos (2007) introduced some concentration coeﬃcients
that are ﬁner than the one we used throughout the paper. In the same spirit, Farahmand
et al. (2010) recently revisited the error propagation of Munos (2007, 2003) and improved
(among other things) the constant in the bound related to these concentration coeﬃcients.
A natural track would be to adapt these reﬁnements to the analysis of λ Policy Iteration.
This does not look completely trivial since the componentwise analysis we derived for λ
Policy Iteration is signiﬁcanlty more intricate than the ones we ﬁnd in the speciﬁc limit
cases λ = 0 (Value Iteration) and λ = 1 (Policy Iteration).

Another potential direction would be to study the implications of the choice of the
parameter λ, as for instance is done by Singh and Dayan (1998) for the value estimation
problem. On this matter, the original analysis by Bertsekas and Ioﬀe (1996) shows how one
can concretely implement Exact λ Policy Iteration. Each iteration requires the computation
of the ﬁxed point of the β-contracting operator Mk (see Equation 9 page 11). We plan to
study the tradeoﬀ between the ease for computing this ﬁxed point (the smaller β the faster)
and the time for λ Policy Iteration to converge to the optimal policy (the bigger β the faster).
In parallel, the reader might have noticed that most of the bounds we have provided do
not depend on λ. An interesting question is whether the ﬁner concentration coeﬃcients of
Munos (2007) and Farahmand et al. (2010) we have just discussed may help keeping track
of the inﬂuence of λ on the performance of the exact or approximate algorithm. In general,
it would be interesting if we could tie a choice of λ to some intrisic characterics of the MDP,
like for instance its smoothness.

Last but not least, we should insist on the fact that the implementation that we have
described in Section 7.2, and which is borrowed from Bertsekas and Ioﬀe (1996), is just one
possible instance of λ Policy Iteration. In the case of linear approximation architectures,
Thi´ery and Scherrer (2010) have proposed an implementation of λ Policy Iteration that is
based on LSPI (Lagoudakis and Parr, 2003), in which the ﬁxed point of Mk is approximated
using LSTD(0) (Bradtke and Barto, 1996). Recently, Bertsekas (2011) proposed to compute
this very ﬁxed point with a variation of LSPE(λ′) (Bertsekas and Ioﬀe, 1996; Nedi´c and
Bertsekas, 2003) for some λ′ potentially diﬀerent from λ. Because of their very close struc-
ture, any existing implementation of Approximate Policy Iteration may probably be turned
into some implementation of λ Policy Iteration. Proposing such implementations and as-
sessing their relative merits constitutes interesting future research. This may in particular
be done through some ﬁnite sample analysis, as had recently been done for Approximate

19. Recently and independently, Farahmand et al. (2010) derived bounds that have a similar ﬂavour: they
highlight the fact that the errors that have the more weight on the performance bounds are the latest.

35

Bruno Scherrer

Value Iteration and Policy Iteration implementations (Antos et al., 2007, 2008; Munos and
Szepesv´ari, 2008; Lazaric et al., 2010).

References

Antos, A., Szepesv´ari, C., and Munos, R. (2007). Value-iteration based ﬁtted policy itera-

tion: Learning with a single trajectory. In ADPRL 2007 , pages 330–337. IEEE.

Antos, A., Szepesvari, C., and Munos, R. (2008). Learning near-optimal policies with
Bellman-residual minimization based ﬁtted policy iteration and a single sample path.
Machine Learning Journal, 71, 89–129.

Bertsekas, D. (2011). Lambda Policy Iteration: A Review and A New Implementation.

Technical Report LIDS-2874, MIT.

Bertsekas, D. and Ioﬀe, S. (1996). Temporal diﬀerences-based policy iteration and applica-

tions in neuro-dynamic programming. Technical Report LIDS-P-2349, MIT.

Bertsekas, D. and Tsitsiklis, J. (1996). Neurodynamic Programming. Athena Scientiﬁc.

Bradtke, S. J. and Barto, A. G. (1996). Linear Least-Squares algorithms for temporal

diﬀerence learning. Machine Learning, 22(1-3), 33–57.

Burgiel, H. (1997). How to Lose at Tetris. Mathematical Gazette, 81, 194–200.

Fahey, C. P. (2003). Tetris AI, Computer plays Tetris. http://colinfahey.com/tetris/

tetris_en.html.

Farahmand, A., Munos, R., and Szepesv´ari, C. (2010). Error Propagation for Approximate

Policy and Value Iteration. In NIPS .

Gordon, G. (1995). Stable function approximation in dynamic programming. In A. Prieditis
and S. Russell, editors, ICML, pages 261–268, San Francisco, CA. Morgan Kaufmann.

Lagoudakis, M. and Parr, R. (2003). Least-Squares Policy Iteration. Journal of Machine

Learning Research, 4, 1107–1149.

Lazaric, A., Ghavamzadeh, M., and Munos, R. (2010). Analysis of a Classiﬁcation-based

Policy Iteration Algorithm. In ICML, pages 607–614.

Munos, R. (2003). Error Bounds for Approximate Policy Iteration. In ICML, pages 560–567.

Munos, R. (2007). Performance bounds in Lp norm for approximate value iteration. SIAM

J. Control and Optimization.

Munos, R. and Szepesv´ari, C. (2008). Finite-Time Bounds for Fitted Value Iteration.

Journal of Machine Learning Research, 9, 815–857.

Nedi´c, A. and Bertsekas, D. P. (2003). Least Squares Policy Evaluation Algorithms with

Linear Function Approximation. DEDS , 13, 79–110.

36

Performance Bounds for λ Policy Iteration

Puterman, M. (1994). Markov Decision Processes. Wiley, New York.

Puterman, M. and Shin, M. (1978). Modiﬁed policy iteration algorithms for discounted

Markov decision problems. Management Science, 24(11).

Singh, S. and Dayan, P. (1998). Analytical Mean Squared Error Curves for Temporal

Diﬀerence Learning. Machine Learning Journal, 32(1), 5–40.

Sutton, R. and Barto, A. (1998). Reinforcement Learning, An introduction. BradFord

Book. The MIT Press.

Thi´ery, C. and Scherrer, B. (2009). Improvements on Learning Tetris with Cross Entropy.

International Computer Games Association Journal, 32.

Thi´ery, C. and Scherrer, B. (2010). Least-Squares λ Policy Iteration: Bias-Variance Trade-

oﬀ in Control Problems. In ICML, Haifa, Isra¨el.

Van Roy, B. (2006). Performance Loss Bounds for Approximate Value Iteration with State

Aggregation. Mathematics of Operation Research, 31(2), 234–244.

Williams, R. and Baird, L. (1993). Tight Performance Bounds on Greedy Policies Based on
Imperfect Value Functions. Technical Report NU-CCS-93-14, Northeastern University.

Appendices

The following Appendices contains all the proofs concerning the analysis of λ Policy
Iteration. We write Pk = P πk the stochastic matrix corresponding to the policy πk which is
greedy with respect to vk−1, P∗ the stochastic matrix corresponding to the optimal policy
π∗. Similarly we write Tk and T∗ the associated Bellman operators.

The proof techniques we have developped are inspired by those of Munos in the articles
(Munos, 2003, 2007). Most of the inequalities appear from the deﬁnition of the greedy
operator:

π = greedy(v) ⇔ ∀π′, T π′

v ≤ T πv.

We often use the property that an average of stochastic matrices is also a stochastic matrix.
A recurrent instance of this property is: if P is some stochastic matrix, then the geometric
average

∞

(1 − α)

(αP )i = (1 − α)(I − αP )−1

Xi=0

with 0 ≤ α < 1 is also a stochastic matrix. We use the property that if some vectors x
and y are such that x ≤ y, then P x ≤ P y for any stochastic matrix P . Eventually, we will

37

Bruno Scherrer

use the following equivalent forms of the operator T π
page 13): for any value v and any policy π, we have

λ (three of them were introduced in

λ v := v + (I − λγP π)−1(T πv − v)
T π
= (I − λγP π)−1(T πv − λγP πv)
= (I − λγP π)−1(rπ + (1 − λ)γP πv)
= (I − λγP π)−1(λrπ + (1 − λ)T πv).

(36)

(37)

(38)

(39)

Appendix A. Proofs of Lemmas 13-15 (core lemmas of the error

propagation)

In this section, we prove the series of Lemmas that are at the heart of our analysis of the
error propagation of λ Policy Iteration.

A.1 Proof of Lemma 13 (a relation between the shift and the Bellman

residual)

Using the deﬁnition of wk = T πk
we have:

λ vk−1 and the formulation of Equation 38, we can see that

(I − γPk)sk = (I − γPk)(wk − vπk )

= (I − γPk)wk − rk
= (I − λγPk + λγPk − γPk)wk − rk
= (I − λγPk)wk + (λγPk − γPk)wk − rk
= rk + (1 − λ)γPkvk−1 + (λ − 1)γPkwk − rk
= (1 − λ)γPk(vk−1 − wk)
= (1 − λ)γPk(I − λγPk)−1(vk−1 − Tkvk−1)
= (1 − λ)γPk(I − λγPk)−1(−bk−1).

Therefore

with

sk = β(I − γPk)−1Ak(−bk−1)

Ak := (1 − λγ)Pk(I − λγPk)−1.

Suppose that we have a lower bound of the Bellman residual: bk−1 ≥ bk−1 (we shall

derive one soon). Since (I − γPk)−1Ak only has non-negative elements then

sk ≤ β(I − γPk)−1Ak(−bk−1) := sk.

38

Performance Bounds for λ Policy Iteration

A.2 Proof of Lemma 14 (a lower bound of the Bellman residual)
From the deﬁnition of the algorithm, and using the fact that Tkvπk = vπk , we see that:

bk = Tk+1vk − vk

= Tk+1vk − Tkvk + Tkvk − vk
≥ Tkvk − vk
= Tkvk − Tkvπk + vπk − vk
= γPk(vk − vπk ) + vπk − vk
= (γPk − I)(sk + ǫk).
= βAkbk−1 + (γPk − I)ǫk

(40)

where we eventually used the relation between sk and bk (Lemma 13). In other words:

with

bk+1 ≥ βAk+1bk + xk+1

xk := (γPk − I)ǫk.

Since Ak is a stochastic matrix and β ≥ 0, we get by induction:

k

bk ≥

βk−j (AkAk−1...Aj+1) xj + βk−k0 (AkAk−1...Ak0+1) bk0 := bk.

Xj=k0+1

A.3 Proof of Lemma 15 (an upper bound of the distance)

Given that T∗v∗ = v∗, we have

v∗ = v∗ + (I − λγPk+1)−1(T∗v∗ − v∗)

= (I − λγPk+1)−1(T∗v∗ − λγPk+1v∗).

Using the deﬁnition of wk+1 = T πk+1
that the distance satisﬁes:

λ

dk+1 = v∗ − wk+1

vk and the formulation of Equation 37, one can see

= (I − λγPk+1)−1[(T∗v∗ − λγPk+1v∗) − (Tk+1vk − λγPk+1vk)]
= (I − λγPk+1)−1[T∗v∗ − Tk+1vk + λγPk+1(vk − v∗)]
= λγPk+1dk+1 + T∗v∗ − Tk+1vk + λγPk+1(vk − v∗)
= λγPk+1dk+1 + T∗v∗ − Tk+1vk + λγPk+1(wk + ǫk − v∗)
= λγPk+1dk+1 + T∗v∗ − Tk+1vk + λγPk+1(ǫk − dk)
= T∗v∗ − Tk+1vk + λγPk+1(ǫk + dk+1 − dk).
Since πk+1 is greedy with respect to vk, we have Tk+1vk ≥ T∗vk and therefore:

T∗v∗ − Tk+1vk = T∗v∗ − T∗vk + T∗vk − Tk+1vk
≤ T∗v∗ − T∗vk
= γP∗(v∗ − vk)
= γP∗(v∗ − (wk + ǫk))
= γP∗dk − γP∗ǫk.

39

Bruno Scherrer

As a consequence, the distance satisﬁes:

dk+1 ≤ γP∗dk + λγPk+1(ǫk + dk+1 − dk) − γP∗ǫk.

Noticing that:

ǫk + dk+1 − dk = ǫk + wk − wk+1

= vk − wk+1
= −(I − λγPk+1)−1(Tk+1vk − vk)
= (I − λγPk+1)−1(−bk)
≤ (I − λγPk+1)−1(−bk),

dk+1 ≤ γP∗dk + yk

yk :=

λγ
1 − λγ

Ak+1(−bk) − γP∗ǫk.

we get:

where

Since P∗ is a stochastic matrix and γ ≥ 0, we have by induction:

dk ≤

k−1

Xj=k0

γk−1−j(P∗)k−1−jyj + γk−k0(P∗)k−k0dk0 = dk.

Appendix B. Proofs of Lemma 17 (performance of Exact λ Policy

Iteration)

We here derive the convergence rate bounds for Exact λ Policy Iteration (as expressed in
Lemma 17 page 20). We rely on the loss bound analysis of Appendix A with ǫk = 0. In
this speciﬁc case, we know that the loss lk ≤ dk + sk where

−bk = βk−k0AkAk−1...Ak0+1(−bk0),
k−1

dk =

λγ
1 − λγ

Xj=k0

and sk = β(I − γPk)−1Ak(−bk−1).

γk−1−j(P∗)k−1−jAj+1(−bj) + γk−k0(P∗)k−k0dk0,

Introducing the following stochastic matrices:

Xi,j,k := (P∗)k−1−iAi+1Ai...Aj+1

and Yj,k := (1 − γ)(I − γPk)−1AkAk−1...Aj+1,

we have

and

dk =

λγ
1 − λγ

k−1

Xj=k0

γk−1−jβj−k0Xj,k0,k(−bk0) + γk−k0(P∗)k−k0dk0

sk =

βk−k0
1 − γ

Yk0,k(−bk0).

40

Performance Bounds for λ Policy Iteration

Therefore the loss satisﬁes:

lk ≤ dk + sk
γk−k0
1 − γ

≤

(cid:18)

E′

kk0(−bk0) + γk−k0(P∗)k−k0dk0

(41)

(cid:19)

with

E′

kk0 :=

1 − γ
γk−k0

(cid:18)



(cid:19)

λγ
1 − λγ

γk−1−jβj−k0Xj,k0,k +

k−1

Xj=k0

βk−k0
1 − γ

.

Yk0,k


To end the proof, we simply need to prove the following lemma:



Lemma 32 E′

kk0 is a stochastic matrix.

Proof It is clear from the deﬁnition of Xi,j,k and Yj,k that normalizing E′
matrices. So we just need to check that their max norm is 1.

kk0 gives stochastic

kE′

kk0k∞ =

1 − γ
γk−k0 

λγ
1 − λγ

k−1

γk−1−jβj−k0 +

βk−k0
1 − γ 

=

=

1 − γ
γk−k0
1 − γ
γk−k0

= 1



(cid:18)

(cid:18)

Xj=k0
γk−k0 − βk−k0
γ − β

λγ
1 − λγ
γk−k0 − βk−k0
1 − γ

+

βk−k0
1 − γ

(cid:19)

+

βk−k0
1 − γ



(cid:19)

where we used the facts that λγ

γ−β = 1

1−β and (1 − β)(1 − λγ) = 1 − γ.

B.1 Proof of Equation 17 (a bound with respect to the Bellman residual)

We ﬁrst need the following lemma:

Lemma 33 The bias and the distance are related as follows:

bk ≥ (I − γP∗)dk.

Proof Since πk+1 is greedy with respect to vk, Tk+1vk ≥ T∗vk and

bk = Tk+1vk − vk

= Tk+1vk − T∗vk + T∗vk − T∗v∗ + v∗ − vk
≥ γP∗(vk − v∗) + v∗ − vk
= (I − γP∗)dk.

We thus have:

dk0 ≤ (I − γP∗)−1bk0.

41

Bruno Scherrer

Then Equation 41 becomes

lk ≤

γk−k0(P∗)k−k0(I − γP∗)−1 −

(cid:20)
γk−k0
1 − γ

=

Ekk0 − E′

kk0

bk0

(cid:2)

(cid:3)

γk−k0
1 − γ

(cid:18)

E′

kk0

bk0

(cid:19)

(cid:21)

Ekk0 := (1 − γ)(P∗)k−k0(I − γP∗)−1

where:

is a stochastic matrix.

B.2 Proof of Equation 16 (a bound with respect to the distance)

From Lemma 33, we know that

−bk0 ≤ (I − γP∗)(−dk0).

Then, Equation 41 becomes

lk ≤

γk−k0(P∗)k−k0 −

γk−k0
1 − γ

(cid:18)

E′

kk0(I − γP∗)
(cid:21)

(cid:19)

dk0

(cid:20)
γk−k0
1 − γ

=

Fkk0 − E′

kk0

dk0

(cid:2)

(cid:3)

Fkk0 := (1 − γ)P k−k0

∗

+ γE′

kk0P∗

where

is a stochastic matrix.

B.3 Proof of Equation 18 (a bound with respect to the distance and the loss

of the greedy policy)

Deﬁne ˆvk0 := vk0 − Ke where K is some constant. The following statements are equivalent:

ˆbk0 ≥ 0

Tk0+1ˆvk0 ≥ ˆvk0

rk0+1 + γPk0+1(vk0 − Ke) ≥ vk0 − Ke

(I − γPk0+1)Ke ≥ −rk0+1 + (I − γPk0+1)vk0

Ke ≥ (I − γPk0+1)−1(−rk0+1) + vk0
Ke ≥ vk0 − vπk0+1.

The minimal K for which ˆbk0 ≥ 0 is thus K := maxs[vk0(s) − vπk0+1(s)]. As ˆvk0 and vk0
only diﬀer by a constant vector, they generate the same sequence of policies πk0+1, πk0+2...
Then, as ˆbk0 ≥ 0, Equation 41 tells us that

v∗ − vπk ≤ γk−k0(P∗)k−k0(v∗ − ˆvk0)

= γk−k0(P∗)k−k0(v∗ − vk0 + Ke).

42

Performance Bounds for λ Policy Iteration

Now notice that

K = max

s

[vk0(s) − v∗(s) + v∗(s) − vπk0+1(s)]

≤ max

s
= − min

[vk0(s) − v∗(s)] + max

[v∗(s) − vπk0+1(s)]
s
[v∗(s) − vk0(s)] + kv∗(s) − vπk0+1k∞ .

s

Then, using the fact that (P∗)k−k0e = e, we get:

v∗ − vπk ≤ γk−k0

(P∗)k−k0
h

(v∗ − vk0) − min

s

[v∗(s) − vk0(s)]e

+ kv∗(s) − vπk0+1k∞ e

.

(cid:16)

(cid:17)

i

Appendix C. Proofs of Equation 22 in Lemma 21 (componentwise

bounds on the error propagation)

We here use the loss bound analysis of Appendix A to derive an asymptotic analysis of
approximate λ Policy Iteration with respect to the approximation error. The results stated
here constitute a proof of the ﬁrst inequality of Lemma 21 page 21.

C.1 Proof of Equation 22

Since the loss satisﬁes

lk = dk + sk ≤ dk + sk,

(42)

an upper bound of the loss can be derived from the upper bound of the distance and the
shift.

Let us ﬁrst concentrate on the bound dk of the distance. Lemmas 14 and 15 imply that:

k−1

dk =

γk−1−i(P∗)k−1−iyi + O(γk−k0),

yi =

Xi=k0
λγ
1 − λγ

i

Ai+1(−bi) − γP∗ǫi,

−bi =

βi−j (AiAi−1...Aj+1) (−xj) + O(βi−k0),

(43)

and − xj = (I − γPj)ǫj.

Xj=k0

Writing

Xi,j,k := (P∗)k−1−iAi+1Ai...Aj+1

43

Bruno Scherrer

and putting all things together, we see that:

dk =

λγ
1 − λγ

k−1

Xi=k0

γk−1−i

βi−jXi,j,k(I − γPj)ǫj + O(βi−k0)



γk−i(P∗)k−iǫi + O(γk−k0)



i

Xj=k0
k−1




−

k−1

i

Xi=k0
k−1

Xj=k0
k−1

Xi=k0

k−1

γk−1−iβi−jXi,j,k(I − γPj)ǫj −

γk−i(P∗)k−iǫi + O(γk−k0)

Xi=k0
k−1

γk−1−iβi−jXi,j,k(I − γPj)ǫj −

γk−j(P∗)k−jǫj + O(γk−k0)

k−1

Xj=k0

γk−1−iβi−jXi,j,k(I − γPj)



− γk−j(P∗)k−j

λγ
1 − λγ

λγ
1 − λγ

k−1

=

=

=

Xi=j

Xj=k0
λγ
1 − λγ





Xj=k0

Xi=j

ǫj + O(γk−k0) (44)






where between the ﬁrst two lines, we used the fact that:





λγ
1 − λγ

k−1

Xi=k0

γk−1−iβi−k0 =

λγ
1 − λγ

γk−k0 − βk−k0
γ − β

=

γk−k0 − βk−k0
1 − γ

= O(γk−k0)

(45)

using the identities λγ = γ−β

1−β and 1 − γλ = 1−γ
1−β .
Let us now consider the bound sk of the shift. From Lemma 13 and the bound on bk in

Equation 43, we have

sk = β(I − γPk)−1Ak(−bk−1)
k−1

= β(I − γPk)−1Ak 


k−1





Xj=k0

Yj,k(I − γPj)ǫj + O(γk−k0)

βk−1−j (Ak−1Ak−2...Aj+1) (−xj)



+ O(γk−k0)







(46)

βk−j
1 − γ

=

Xj=k0

with

Yj,k := (1 − γ)(I − γPk)−1AkAk−1...Aj+1.

Eventually, from Equations 42, 44 and 46 we get:

lk ≤

k−1

Xj=k0









λγ
1 − λγ

k−1

Xi=j

γk−1−iβi−jXi,j,k +

βk−j
1 − γ

Yj,k


(I − γPj) − γk−j(P∗)k−j

+ O(γk−k0).

ǫj





(47)

44

Performance Bounds for λ Policy Iteration

Introduce the following matrices:

Bjk

:=

1 − γ
γk−j 

λγ
1 − λγ

k−1

γk−1−iβi−jXi,j,k +

Xi=j

βk−j
1 − γ

Yj,k


B′
jk

:= γBjkPj + (1 − γ)(P∗)k−j.



Lemma 34 Bjk and B′

jk are stochastic matrices.

Proof It is clear from the deﬁnition of Xi,j,k and Yj,k that normalizing Bjk and B′
stochastic matrices. So we just need to check that their max norm is 1.

jk gives

kBjkk =

(1 − γ)
γk−j 

λγ
1 − λγ

k−1

γk−1−iβi−j +

βk−j
1 − γ 

=

=

=

(1 − γ)
γk−j
(1 − γ)
γk−j
(1 − γ)
γk−j

= 1.



(cid:20)

(cid:20)

(cid:20)

Xi=j
γk−j − βk−j
γ − β

λγ
1 − λγ

+

βk−j
1 − γ



(cid:21)

γk−j − βk−j
(1 − λγ)(1 − β)
γk−j − βk−j
1 − γ

+

+

βk−j
1 − γ

(cid:21)

βk−j
1 − γ

(cid:21)

where we used the identities: λγ = γ−β
that kB′

jkk = 1.

1−β and (1 − β)(1 − γλ) = 1 − γ. Then it is also clear

Thus, Equation 47 can be rewritten as follows:

lk ≤

=

k−1

Xj=k0 (cid:20)
1
1 − γ

γk−j
1 − γ

k−1

Bjk(I − γPj) − γk−j(P∗)k−j

ǫj + O(γk−k0)

(cid:21)

γk−j

Bjk − B′
jk

ǫj + O(γk−k0).

(cid:3)
Taking the supremum limit, we see that for all k0,

(cid:2)

Xj=k0

lim sup
k→∞

lk ≤

1
1 − γ

lim sup
k→∞

k−1

Xj=k0

γk−j

Bjk − B′
jk

ǫj.

(cid:2)

(cid:3)

(48)

Appendix D. Proofs of Equations 23-24 in Lemma 21 (componentwise

bounds with respect to the Bellman residuals)

In this section, we study the loss

lk := v∗ − vπk

45

Bruno Scherrer

with respect to the two following Bellman residuals:

b′
k := Tkvk − vk

and bk := Tk+1vk − vk = T vk − vk.

The term b′
k says how much vk diﬀers from the value of πk while bk says how much vk
diﬀers from the value of the policies πk+1 and π∗. The results stated here prove the last
two inequalities of Lemma 21 page 21.

D.1 Proof of Equation 23 (bounds with respect to the Policy Bellman

residual)

Our analysis relies on the following lemma

Lemma 35 Suppose that we have a policy π, a function v that is an approximation of the
value vπ of π in the sense that its residual b′ := T πv − v is small. Taking the greedy policy
π′ with respect to v reduces the loss as follows:

v∗ − vπ′

≤ γP∗(v∗ − vπ) +

γP∗(I − γP )−1 − γP ′(I − γP ′)−1

b′

where P and P ′ are the stochastic matrices which correspond to π and π′.

(cid:0)

(cid:1)

Proof We have:

v∗ − vπ′

vπ′

= T∗v∗ − T π′
= T∗v∗ − T∗vπ + T∗vπ − T∗v + T∗v − T π′
≤ γP∗(v∗ − vπ) + γP∗(vπ − v) + γP ′(v − vπ′

v + T π′
)

v − T π′

vπ′

where we used the fact that T∗v ≤ T π′

v. One can see that:

vπ − v = T πvπ − v

= T πvπ − T πv + T πv − v
= γP (vπ − v) + b′
= (I − γP )−1b′

and that

v − vπ′

vπ′
= v − T π′
= v − T πv + T πv − T π′
≤ −b′ + γP ′(v − vπ′
≤ (I − γP ′)−1(−b′).

)

v + T π′

v − T π′

vπ′

(49)

(50)

(51)

where we used the fact that T πv ≤ T π′
and 51 into Equation 49.

v. We get the result by putting back Equations 50

46

Performance Bounds for λ Policy Iteration

To derive a bound for λ Policy Iteration, we simply apply the above lemma to π = πk,

v = vk and π′ = πk+1. We thus get:

lk+1 ≤ γP∗lk +

γP∗(I − γPk)−1 − γPk+1(I − γPk+1)−1

b′
k.

Introduce the following stochastic matrices:

(cid:0)

(cid:1)

Ck := (1 − γ)2(I − γP∗)−1

P∗(I − γPk)−1

,

k := (1 − γ)2(I − γP∗)−1
C ′

Pk+1(I − γPk+1)−1
(cid:0)
(cid:1)

.

This leads to the following componentwise bound:

(cid:0)

(cid:1)

lim sup
k→∞

lk ≤

γ

(1 − γ)2 lim sup

k→∞

Ck − C ′
k

b′
k.

(cid:2)

(cid:3)

D.2 Proof of Equation 24 (bounds with respect to the Bellman residual)

We rely on the following lemma (which is for instance proved by Munos (2007))

Lemma 36 Suppose that we have a function v. Let π be the greedy policy with respect to
v. Then

v∗ − vπ ≤ γ

P∗(I − γP∗)−1 − P π(I − γP π)−1

(T πv − v).

(cid:3)

We provide a proof for the sake of completeness:
Proof Using the fact that T∗v ≤ T πv, we see that

(cid:2)

v∗ − vπ = T∗v∗ − T πvπ

= T∗v∗ − T∗v + T∗v − T πv + T πv − T πvπ
≤ T∗v∗ − T∗v + T πv − T πvπ
= γP∗(v∗ − v) + γP π(v − vπ)
= γP∗(v∗ − vπ) + γP∗(vπ − v)γP π(v − vπ)
≤ (I − γP∗)−1(γP∗ − γP π)(vπ − v).

Using Equation 50 we see that:

vπ − v = (I − γP π)−1(T πv − v).

Thus

v∗ − vπ ≤ (I − γP∗)−1(γP∗ − γP π)(I − γP π)−1(T πv − v)

= (I − γP∗)−1(γP∗ − I + I − γP π)(I − γP π)−1(T πv − v)
=

(I − γP∗)−1 − (I − γP π)−1

(T πv − v)

= γ
(cid:2)

P∗(I − γP∗)−1 − P π(I − γP π)−1

(cid:3)

(T πv − v).

(cid:2)

(cid:3)

To derive a bound for λ Policy Iteration, we simply apply the above lemma to v = vk−1

and π = πk. We thus get:

lk ≤

γ
1 − γ

D − D′
k

bk−1

(cid:2)
47

(cid:3)

(52)

Bruno Scherrer

where

D := (1 − γ)P∗(I − γP∗)−1
:= (1 − γ)Pk(I − γPk)−1

and D′
k

are stochastic matrices.

Appendix E. Proofs of Corollary 27

Ths section provides a proof of Corollary 27 page 25, in which we reﬁne the bounds when
the value or the policy converges.

E.1 Proof of the ﬁrst inequality of Corollary 27 (when the value converges)

Suppose that λ Policy Iteration converges to some value v. Let policy π be the corresponding
greedy policy, with stochastic matrix P . Let b be the Bellman residual of v. It is also clear
that the approximation error also converges to some ǫ.
Indeed from Algorithm 3 and
Equation 10, we get:

b = T v − v = (I − λγP )(−ǫ).

From the bound with respect to the Bellman residual (Equation 52 page 47), we can see
that:

v∗ − vπ ≤
=

=

=

=

=

=

where

(cid:2)

(cid:2)

(cid:3)

b

(I − λγP )ǫ

(I − γP∗)−1 − (I − γP )−1
(I − γP )−1 − (I − γP∗)−1
(I − γP )−1(I − λγP ) − (I − γP∗)−1(I − λγP )
(I − γP )−1(I − γP + γP − λγP ) − (I − γP∗)−1(I − λγP )
I + (1 − λ)(I − γP )−1γP + λ(I − γP∗)−1γP
(1 − λ)(I − γP )−1γP + λ(I − γP∗)−1γP
γ
(cid:2)(cid:0)
1 − γ

ǫ
(cid:3)
− (I − γP∗)−1
− (I − γP∗)−1γP∗

[Bv − D] ǫ.

(cid:2)(cid:0)

(cid:1)

(cid:1)

(cid:3)

(cid:3)

(cid:2)

(cid:2)

ǫ

ǫ

ǫ

(cid:3)

(cid:3)

:= (1 − γ)

Bv
D := (1 − γ)P∗(I − γP∗)−1.
(cid:0)

(1 − λ)(I − γP )−1P + λ(I − γP∗)−1P

(cid:1)

Lemma 37 Bv and D are stochastic matrices.

Proof

It is clear that kDk = 1. Also:

kBvk = (1 − γ)

1 +

(cid:18)

= (1 − γ)

1 +

= 1.

(cid:18)

+

λγ
1 − γ

(cid:19)

(1 − λ)γ
1 − γ
γ
1 − γ

(cid:19)

Then, the ﬁrst bound of Corollary 27 follows from the application of Lemmas 23 and 25.

48

Performance Bounds for λ Policy Iteration

E.2 Proof of the second inequality of Corollary 27 (when the policy converges)

Suppose that λ Policy Iteration converges to some policy π. Write P the corresponding
stochastic matrix and

Aπ := (1 − λγ)P (I − λγP )−1.

Then for some big enough k0, we have:

lk ≤

γk−j
1 − γ

k−1

Xj=k0 (cid:20)

Aπ

jkAπ(I − γP ) − γk−j(P∗)k−j

ǫj + O(γk−k0)

(cid:21)

where

Aπ

jk :=

1 − γ
γk−j 

λγ
1 − λγ

k−1

Xi=j



γk−1−iβi−j(P∗)k−1−i(Aπ)i−j + βk−j(I − γP )−1(Aπ)k−1−j



is a stochastic matrix (for the same reasons why Bjk is a stochastic matrix in Lemma 34).
Noticing that



Aπ(I − γP ) = (1 − λγ)P (I − λγP )−1(I − γP )

= (1 − λγ)P (I − λγP )−1(I − λγP + λγP − γP )
= (1 − λγ)P (I − (1 − λ)(I − λγP )−1γP )
= (1 − λγ)P − γ(1 − λ)AπP

we can deduce that

lk ≤

k−1

Xj=k0 (cid:20)
k−1

γk−j

(cid:20)
k−1

Xj=k0
1 − λγ
1 − γ

=

=

where

γk−j
1 − γ

Aπ

jk [(1 − λγ)P − γ(1 − λ)AπP ] − γk−j(P∗)k−j

ǫj + O(γk−k0)

(cid:21)

1 − λγ
1 − γ

Aπ

jkP −

γ(1 − λ)
1 − γ

(cid:20)

Aπ

jkAπP + (P∗)k−j

ǫj + O(γk−k0)

(cid:21)(cid:21)

γk−j

Bπ

jk − B′π
jk

ǫj + O(γk−k0)

Xj=k0

(cid:2)

(cid:3)

(53)

Bπ
jk

B′π
jk

:= Aπ

jkP
1 − γ
1 − λγ

:=

γ(1 − λ)
1 − γ

(cid:20)

Aπ

jkAπP + (P∗)k−j

.

(cid:21)

Lemma 38 Bπ

jk and B′π

jk are stochastic matrices.

Proof

It is clear that kBπ

jkk = 1. Also:

kB′π

jkk =

=

1 − γ
1 − λγ
1 − γ
1 − λγ

= 1.

49

1 +

γ(1 − λ)
1 − γ

(cid:18)
1 − γ + γ − λγ
1 − γ

(cid:19)

Bruno Scherrer

Then, the second bound of Corollary 27 follows from the application of Lemmas 23 and 25.

Appendix F. Proofs of Lemmas 18 and 23 (from componentwise bounds

to span seminorm bounds)

This section contains the proofs of Lemmas 18 and 23 that enable us to derive span seminorm
performance bounds from the componentwise analysis developped in the previous sections.
It is easy to see that Lemma 18 is a special case of Lemma 23, so we only prove the latter.
. As Xjk and

Consider the notations of Lemma 23. Write akj := arg mina kyj − aekp,µkj
jk are stochastic matrices, Xke = X′

ke = e and we can write that:

X ′

lim sup
k→∞

|xk| ≤ K lim sup
k→∞

By taking the absolute value we get

lim sup
k→∞

|xk| ≤ K lim sup
k→∞

It can then be seen that

k−1

Xj=k0

k−1

Xj=k0

ξk−j(Xkj − X ′

kj)(yj − akje).

ξk−j(Xkj + X ′

kj)|yj − akje|.

p

kxkkp,µ
lim sup
k→∞
(cid:16)
= K p lim sup
k→∞

(cid:17)
µT (|xk|)p

≤ K p lim sup
k→∞

µT

= K p lim sup
k→∞

µT

k−1





Xj=k0



(cid:16)P

ξk−j(Xkj + X ′

kj) (|yj − akje|)

p





k−1
j=k0 ξk−j

1

2 (Xkj + X ′
k−1
j=k0 ξk−j

kj)2 (|yj − akje|)
(cid:17)

p

.

p

k−1





ξk−j


Xj=k0


By using Jensen’s inequality (with the convex function x 7→ xp), we get:

P





lim sup
k→∞

kxkkp,µ
(cid:16)
≤ K p lim sup
k→∞

µT

P

p

(cid:17)
k−1
j=k0 ξk−j

kj) (2|yj − akje|)p

1

2 (Xkj + X ′
k−1
j=k0 ξk−j

= K p lim sup
k→∞

≤ K p lim sup
k→∞

k−1

Xj=k0
k−1

Xj=k0

P

ξk−jµkj

T [2|yj − akje|]p

ξk−j

2 kyj − akjekp,µkj

k−1

ξk−j′




p

Xj′=k0
K ′p−1

h

i

50





k−1

ξk−j′




p−1

Xj′=k0

p





Performance Bounds for λ Policy Iteration

= K pK ′p−1 lim sup
k→∞

≤ K pK ′p−1 lim sup
k→∞

k−1

Xj=k0
k−1

Xj=k0

p

ξk−j

span
p,µkj

""

[yj]

#

ξk−j

sup
k′≥j′≥k0

span
p,µk′j′

""

p

yj′

(cid:2)

#

(cid:3)

= K pK ′p−1K ′

sup
k′≥j′≥k0

span
p,µk′j′

""

p

yj′

(cid:2)
p

#
(cid:3)

= K pK ′p

sup
k′≥j′≥k0

""

span
p,µk′j′

yj′

(cid:2)

#

(cid:3)

where we used

k−1
j=k0 ξk−j = K ′.

As this is true for all k0, and as k0 7→ supk′≥j′≥k0 spanp,µk′j′

P

result follows.

yj′

is non-increasing, the

(cid:2)

(cid:3)

Appendix G. Proofs of Lemma 28 and Proposition 30 (analysis of the

undiscounted case)

This last section contains the Proofs of Lemma 28 and Proposition 30 that provide the
analysis of an undiscounted problem like Tetris.

G.1 Proof of Lemma 28 (componentwise bound)

First of all, the relation expressed in Equation 29 between the loss and the stochastic
matrices, which we restate here for clarity:

∀k0,

lim sup
k→∞

v∗ − vπk ≤ lim sup
k→∞

k−1

Xj=k0

δk−j

Gjk − G′

jk

ǫj,

(cid:2)

(cid:3)

is obtained by simply rewriting the ﬁrst inequality of Lemma 21 with γ = 1 and β = 1
(note in particular that the terms δk−j collapse through the deﬁnition of Gjk and G′
jk).
To complete the proof of the lemma, we need to show that the matrices Gjk and G′
jk are
substochastic matrices. By construction, these matrices are sum of non-negative matrices
so we only need to show that their max norm is smaller than or equal to 1.

For all n, write Mn the set of matrices that is deﬁned as follows:

• for all sets of n policies (π1, π2, · · · , πn), Pπ1Pπ2 · · · Pπn ∈ Mn;

• for all η ∈ (0, 1), and (P, Q) ∈ Mn × Mn,

ηP + (1 − η)Q ∈ Mn.

The motivation for introducing this set is that we have the following properties: For all n,
n
n0 k. We use the somewhat abusive
P ∈ Mn is a substochastic matrix such that kP k∞ ≤ αj
notation Πn for denoting any element of Mn. For instance, for some matrix P , writing
P = aΠi + bΠjΠk = aΠi + bΠj+k should be read as follows: there exists P1 ∈ Mi, P2 ∈ Mj,
P3 ∈ Mk and P4 ∈ Mk+j such that P = aP1 + bP2P3 = aP1 + bP4.

51

Bruno Scherrer

Recall the deﬁnition of the substochastic matrix

Ak = (1 − λ)(I − λPk)−1Pk = (1 − λ)

λiΠi+1.

∞

Xi=0

Let i ≤ j < k. It can be seen that

(P∗)k−1−iAi+1Ai...Aj+1 = Πk−1−i

(1 − λ)

λiΠi+1

∞

= Πk−j

|
(1 − λ)

∞

Xi=0

λiΠi

!

· · ·

(1 − λ)

!

λiΠi+1

∞

Xi=0

Xi=0

i−j+1 terms

{z
(1 − λ)

· · ·

i−j+1 terms

{z

∞

Xi=0

λiΠi

.

!

}

!

}

(54)

Now, observe that

|

∞

(cid:13)
Xi=0
(cid:13)
(cid:13)
(cid:13)
(cid:13)

λiΠi

∞

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

≤

=

=

=

∞

Xi=0
∞

λi kΠik∞

λiαj

i
n0 k

Xi=0
∞

n0−1

λjn0+iαj

Xj=0
∞

Xi=0
(λn0α)j

n0−1

λi

Xj=0

Xi=0

1 − λn0
(1 − λn0α)(1 − λ)

.

(55)

As a consequence, writing η := 1−λn0

1−λn0 α , we see from Equation 54 that

(P∗)k−1−iAi+1Ai...Aj+1

≤ αj

k−j
n0 kηi−j+1.

(cid:13)
(cid:13)
(cid:13)

∞

(cid:13)
(cid:13)
(cid:13)

Similarly, by using Equation 55 and noticing that 1−λn0
1−λ

λ→1
−→ n0, it can be seen that

(I − Pk)−1AkAk−1 · · · Aj+1

(cid:13)
(cid:13)

52

n0
1 − α

k−j
n0 kηk−j.

αj

∞ ≤
(cid:13)
(cid:13)

 
 
 
 
Performance Bounds for λ Policy Iteration

We are ready to bound the norm of the matrix Gjk:

kGjkk∞ ≤

k−j
n0 k

αj
δk−j 

λ
1 − λ

ηi−j+1 +

n0ηk−j
1 − α 

k−1

Xi=j

η

(cid:19)

=

=

=



k−j
n0 k

k−j
n0 k

αj
δk−j (cid:20)(cid:18)
αj
δk−j (cid:20)(cid:18)
αj
δk−j (cid:20)(cid:18)

k−j
n0 k

= 1.


n0ηk−j
1 − α

+

(cid:19)

λ
1 − λ

λ
1 − λ

1 − ηk−j
1 − η

(cid:18)
1 − λn0
1 − λn0α

(cid:19) (cid:18)

(cid:19) (cid:18)

1 − λn0
1 − λ

λ
1 − λn0α

(cid:19) (cid:18)

(cid:19) (cid:18)

(cid:21)

+

1 − ηk−j
1 − η

(cid:19)
1 − ηk−j
1 − η

n0ηk−j
1 − α

(cid:21)
n0ηk−j
1 − α

+

(cid:19)

(cid:21)

where we used the deﬁnition of η. Therefore Gjk is a substochastic matrix.
follows that G′

jk is also a substochastic matrix.

It trivially

G.2 Proof of Proposition 30 (Lp norm bound)

In order to prove the Lp norm bound of Proposition 30, we rely on the following variation
of Lemma 23.

Lemma 39 If xk and yk are sequences of vectors and Xjk, X ′
matrices satisfying

jk sequences of substochastic

∀k0,

lim sup
k→∞

|xk| ≤ K lim sup
k→∞

ξk−j(Xkj − X ′

kj)yj,

k−1

Xj=k0

where (ξi)i≥1 is a sequence of non-negative weights satisfying:

then, for all distribution µ,

ξi = K ′ < ∞,

∞

Xi=1

µkj :=

1
2

(Xkj + X ′

kj)T µ

is a non-negative vector and ˜µkj := µkj

kµkjk1

is a distribution, and

lim sup
k→∞

kxkkp,µ ≤ KK ′

lim
k0→∞ ""

sup
k≥j≥k0

kyjkp,˜µkj #

.

Proof The proof follows the lines of that of Lemma 23 in Appendix F. The diﬀerences are
as follows:

53

Bruno Scherrer

• since Xjk and X ′

in general Xjke 6= X ′
instead of the Lp span seminorm bound;

jk are substochastic matrices (and not stochastic matrices), we have
jke and must take akj = 0, which in turn gives an Lp norm bound

• to express the bound in terms of the distributions ˜µkj, we use the fact that µkj ≤ ˜µkj

which derives from kµkjk1 ≤ 1 since Xjk and X ′

jk are substochastic matrices.

Proposition 30 is obtained by applying this Lemma and an anologue of Lemma 25 for
Lp norm on the componentwise bound (Lemma 28 — see previous subsection). The only
∞
remaining thing that needs to be checked is that
i=1 δi has the right value. This is what
we do now.

Similary to Equation 55, one can see that:

P

and

i

n0 kηi =

αj

1 − ηn0
(1 − ηn0α)(1 − η)

∞

Xi=0

i

n0 k(1 − ηi) =

αj

n0
1 − α

−

1 − ηn0
(1 − ηn0α)(1 − η)

.

∞

Xi=0

As a consequence:

∞

∞

δi =

i
n0 k

αj

Xi=0

Xi=0

1 − λn0
1 − λ

(cid:18)

(cid:19) (cid:18)

λ
1 − λn0α

1 − λn0
1 − λ

1 − λn0
1 − λ

=

=

(cid:18)

(cid:18)

(cid:19) (cid:18)

(cid:19) (cid:18)

λ
1 − λn0α

λ
1 − λn0α

(cid:19)





(cid:19) (cid:18)

P
1
1 − η

1 − ηi
1 − η

+

n0ηi
1 − α

(cid:19)

(cid:19) (cid:18)
i

∞
i=0 αj

n0 k(1 − ηi)

1 − η

n0

+



i

n0 kηi

∞
i=0 αj
1 − α

−

n0
1 − α
n0
1 − α

(cid:19) (cid:18)
+



P
1 − ηn0
(1 − ηn0α)(1 − η)

(cid:19)

1 − ηn0
(1 − ηn0α)(1 − η)

= λf (λ)

1
1 − η

(cid:18)
(f (1) − f (η)) + f (1)f (η)

(cid:19) (cid:18)

(cid:19)

(56)

with for all x, f (x) :=
by noticing that

and δ0 = n0

1−α = f (1).

(1−xn0 )

(1−x)(1−xn0 α) and f (1) = n0

1−α by continuity. Now, we can conclude

∞

∞

δi =

δi − δ0

Xi=1

Xi=0

54

0.0
0.3
0.5
0.7
0.9

 9000

 8000

 7000

 6000

 5000

 4000

 3000

 2000

 1000

s
e
m
a
g

0
0
1

n
o

s
e
r
o
c
s

e
g
a
r
e
v
a

f

o

s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0

 0

 10

 20

 30

 40

 50
Iterations

 60

 70

 80

 90

 100

 
 
 
 
 
 
 
 
 
0.0
0.3
0.5
0.7

 60

 50

 40

 30

 20

 10

s
e
m
a
g

0
0
1

n
o

s
e
r
o
c
s

e
g
a
r
e
v
a

f

o

s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0

 0

 2

 4

 6

 8
Iterations

 10

 12

 14

 16

 
 
 
 
 
 
 
 
 
0.0
0.3
0.5
0.7
0.9

 300

 250

 200

 150

 100

 50

s
e
m
a
g

0
0
1

n
o

s
e
r
o
c
s

e
g
a
r
e
v
a

f

o

s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0

 0

 10

 20

 30

 40

 50
Iterations

 60

 70

 80

 90

 100

 
 
 
 
 
 
 
 
 
0.0
0.3
0.5
0.7
0.9

 500

 400

 300

 200

 100

s
e
m
a
g

0
0
1

n
o

s
e
r
o
c
s

e
g
a
r
e
v
a

f

o

s
n
u
r

0
1

f

o
e
g
a
r
e
v
A

 0

 0

 10

 20

 30

 40

 50
Iterations

 60

 70

 80

 90

 100

 
 
 
 
 
 
 
 
 
s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
e
e
e
m
m
m
m
m
m
m
m
m
m
m
a
a
a
a
a
a
a
a
a
a
a
g
g
g
g
g
g
g
g
g
g
g

0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
1
1
1

n
n
n
n
n
n
n
n
n
n
n
o
o
o
o
o
o
o
o
o
o
o

s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
e
e
e
r
r
r
r
r
r
r
r
r
r
r
o
o
o
o
o
o
o
o
o
o
o
c
c
c
c
c
c
c
c
c
c
c
s
s
s
s
s
s
s
s
s
s
s
e
e
e
e
e
e
e
e
e
e
e
g
g
g
g
g
g
g
g
g
g
g
a
a
a
a
a
a
a
a
a
a
a
r
r
r
r
r
r
r
r
r
r
r
e
e
e
e
e
e
e
e
e
e
e
v
v
v
v
v
v
v
v
v
v
v
A
A
A
A
A
A
A
A
A
A
A

 800
 800
 800
 800
 800
 800
 800
 800
 800
 800
 800

 700
 700
 700
 700
 700
 700
 700
 700
 700
 700
 700

 600
 600
 600
 600
 600
 600
 600
 600
 600
 600
 600

 500
 500
 500
 500
 500
 500
 500
 500
 500
 500
 500

 400
 400
 400
 400
 400
 400
 400
 400
 400
 400
 400

 300
 300
 300
 300
 300
 300
 300
 300
 300
 300
 300

 200
 200
 200
 200
 200
 200
 200
 200
 200
 200
 200

 100
 100
 100
 100
 100
 100
 100
 100
 100
 100
 100

 0
 0
 0
 0
 0
 0
 0
 0
 0
 0
 0

 0
 0
 0
 0
 0
 0
 0
 0
 0
 0
 0

 20
 20
 20
 20
 20
 20
 20
 20
 20
 20
 20

 40
 40
 40
 40
 40
 40
 40
 40
 40
 40
 40

 60
 60
 60
 60
 60
 60
 60
 60
 60
 60
 60

 80
 80
 80
 80
 80
 80
 80
 80
 80
 80
 80

 100
 100
 100
 100
 100
 100
 100
 100
 100
 100
 100

Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations
Iterations"
Towards Physarum robots: computing and manipulating on water surface,"  Plasmodium of Physarym polycephalum is an ideal biological substrate for
implementing concurrent and parallel computation, including combinatorial
geometry and optimization on graphs. We report results of scoping experiments
on Physarum computing in conditions of minimal friction, on the water surface.
We show that plasmodium of Physarum is capable for computing a basic spanning
trees and manipulating of light-weight objects. We speculate that our results
pave the pathways towards design and implementation of amorphous biological
robots.
",http://arxiv.org/pdf/0804.2036v1,1,"Adamatzky A. 

Towards Physarum robots 

Feb 2008 

Towards Physarum robots: computing and manipulating on water surface 

Andrew Adamatzky  

Computing, Engineering and Mathematical Sciences, University of the West of England, Bristol, United 
Kingdom 

and 

Bristol Robotics Laboratory, Bristol, United Kingdom 

andrew.adamatzky@uwe.ac.uk 

Abstract 

Plasmodium  of  Physarym  polycephalum  is  an  ideal  biological  substrate  for  implementing  concurrent 
and  parallel  computation, including  combinatorial  geometry  and optimization on  graphs.    We  report 
results of scoping experiments on Physarum computing in conditions of minimal friction, on the water 
surface. We show that plasmodium of Physarum is capable for computing a basic spanning trees and 
manipulating of light-weight objects. We speculate that our results pave the pathways towards design 
and implementation of amorphous biological robots. 

Key words:  biological computing, amorphous robots, unconventional computation, amoeba 

Introduction 

Plasmodium,  the  vegetative  stage  of  slime  mould  Physarum  polycephalum,  is  a  single  cell,  with 
thousands  of  diploid  nuclei,  formed  when  individual  flagellated  cells  or  amoebas  of  Physarum 
polycephalum swarm together and fuse.  The plasmodium is visible by naked eye. When plasmodium is 
placed on an appropriate substrate, the plasmodium propagates and searches for sources of nutrients 
(bacteria). When such sources are located and taken over, the plasmodium forms  veins of protoplasm.  
The veins can branch, and eventually the plasmodium spans the  sources of nutrients with a dynamic 
proximity  graph,  resembling,  but  not  perfectly  matching  graphs  from  the  family  of  k-skeletons 
[Kirkpatrick and Radke, 1985]. 

A large size of the plasmodium allows the single cell to be highly amorphous. The plasmodium shows 
synchronous  oscillation  of  cytoplasm  throughout  its  cell  body,  and  oscillatory  patterns  control  the 
behaviours of the cell.  All the parts of the cell behave cooperatively in exploring the space, searching 
for nutrients and optimizing network of streaming protoplasm. Due to its unique features and relative 
ease of experimentation with, the plasmodium became a test biological substrate for implementation 
of  various  computational  tasks.  The  problems  solved  by  the  plasmodium  include  maze-solving 
[Nakagaki,  2000,  2001],  calculation  of  efficient  networks  [Nakagaki  2003,  2004;  Shirakawa  &  Gunji, 
2007],  construction  of  logical  gates  [Tsuda  et  al,  2004],  formation  of  Voronoi  diagram  [Shirakawa  & 
Gunji, 2007a], and robot control [Tsuda et al., 2007].  

The oscillatory cytoplasm of the plasmodium can be seen as a spatially extended nonlinear excitable 
media [Matsumoto et al., 1988; Nakagaki et al., 1999; Yamada et al., 2007].  In our previous papers we 
hypothesized  that  the  plasmodium  of  Physarum  is  a  biological  analogue  of  a  chemical  reaction-
diffusion  system  encapsulated  in  an  elastic  and  growing  membrane  [Adamatzky,  2007a].    Such  an 
encapsulation enables the plasmodium to function as a massively-parallel reaction-diffusion computer 
[Adamatzky,  De  Lacy  Costello,  Asai,  2005]  and  also  to  solve  few  tasks  which  reaction-diffusion 
computers could not do, e.g. construction of spanning trees [Adamatzky, 2007], and implementation of 

 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

storage  modification  machines  [Adamatzky,  2008].    Also,  under  certain  experimental  conditions,  the 
plasmodium exhibits travelling self-localizations, implements collision-based logical circuits and thus is 
capable for universal computation [Adamatzky, De Lacy Costello, Shirakawa, 2008].  

Being  encapsulated  in  an  elastic  membrane  the  plasmodium  can  be  capable  of  not  only  computing 
over  spatially  distributed  data-sets  but  also  physically  manipulating  elements  of  the  data-sets.  If  a 
sensible, controllable and, ideally, programmable movement of the plasmodium and manipulation by 
the  plasmodium  could  be  achieved,  this  would  open  ways  for  experimental  implementations  of 
amorphous  robotic  devices.  There  are  already  seeds  of  an  emerging  theory  of  artificial  amoeboid 
robots [Yokoi and Kakazu, 1992; Yokoi et al., 2003; Shimizu and Ishiguro, 2008].  

In present paper we undertook a set of scoping experiments on establishing links between Physarum 
computing  and  Physarum  robotics.  We  have  chosen  water  surface  as  a  physical  substrate  for  the 
plasmodium  development  to  study  how  topology  of  the  plasmodium  network  can  be  dynamically 
updated, without being stuck to a non-liquid substrate, and how small objects floating on the surface 
can be manipulated by the plasmodium’s pseudopodia. 

Methods 

Plasmodium  of  Physarum  polycephalum  was  cultivated  on  a  wet  paper  towels  in  dark  ventilated 
containers, oat flakes were  supplied as a substrate for bacteria on which the plasmodium feeds.  We 
used  several  test  arenas  for  observing  behaviour  of  the  plasmodium  and  scoping  experiments  on 
plasmodium-induced manipulation of floating objects. These are Petri dishes with base diameters 20 
mm and 90 mm, and rectangular plastic containers 200 by 150 mm. The dishes and containers were 
filled by 1/3 with distilled water.    Data  points,  to be spanned by the  plasmodium, were  represented 
either by 5-10 mm sized pieces of a plastic foam, which were either fixed to bottom of Petri dishes or 
left floating on water surface (in case of large containers). Oat flakes were placed on top of the foam 
pieces.    Foam  pieces,  where  plasmodium  was  initially  placed,  and  the  pieces  with  oat  flakes  were 
anchored to bottom of containers.  Tiny foam pieces to be manipulated by plasmodium were left free-
floating. 

Results:  Computing and Manipulating 

To demonstrate that a substrate is suitable for robotics implementations one must demonstrate that 
the substrate is capable for sensing of environment and responsiveness  to external stimulus, solving 
complex  computational  tasks  on  spatially  distributed  data  sets,  locomotion,  and  manipulation  of 
objects.    We  provide  basic  demonstrations  which  may  indicate  that  plasmodium  of  Physarum 
polycephalum  can  be  successfully  used  in  future  experiments  on  laboratory  implementations  of 
amorphous biological robots.  

Surface  of  water  is  in  tension  therefore  it  physically  supports  propagating  plasmodium,  when  its 
contact  weight  to  contact  area  ratio  is  small.    When  placed  in  an  experimental  container  the 
plasmodium  forms  pseudopodia  aimed  to  search  for  sources  of  nutrients.    In  most  experiments 
‘growth part’ of the pseudopodia has tree-like structure for fine detection of chemo-gradients in the 
medium,  which  also  minimized  weight  to  area  ratio.  Examples  of  tree-like  propagating  pseudopodia 
are shown in Fig. 1.  

In  Fig.  1b  we  can  see  that  not  always  pseudopodia  grow  towards  source  of  nutrients,  there  is  a 
pseudopodia  growing  South-West,  where  no  sources  of  nutrients  located.  This  happens  possibly 
because in large-sized containers volume of air is too large to support a reliable and stationary gradient 
of chemo-attractants.  This may pose a difficulty for the plasmodium to locate and span all sources of 
nutrients in large-sized containers. 

In Petri dishes volume of air is small and, supposedly the air is stationary, therefore plasmodium easily 
locates sources of nutrients (Fig. 2). It thus builds spanning trees where graph nodes (to be  spanned) 

 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

are  presented  by  pieces  of  foam  with  oat  flakes  on  top.  In  Fig.  2  we  can  see  that  originally  the 
plasmodium was positioned at the Southern domain. In twelve hours the plasmodium builds a link with 
Western domain, and then starts to propagate pseudopodia to the Eastern domain.  

When  the  plasmodium  spans  sources  of  nutrients,  it  produces  many  ‘redundant’  branches  (Fig.  2). 
These  branches  of  pseudopodia  are  necessary  for  space  exploration  but  do  not  represent  minimal 
edges  connecting  the  nodes  of  the  spanning  tree.  These  ‘redundant’  branches  are  removed  at  later 
stages of the spanning tree development. See a well-established spanning tree of data-points in Fig. 3. 
Initially the plasmodium was placed in the Western domain, and the plasmodium has constructed the 
spanning tree in 15 hours. 

We  demonstrated  that  the  plasmodium  does  explore  space  and  computes  a  spanning  tree  on  the 
water surface, when placed initially on one of the floating objects.  Would the plasmodium be as well 
operational  when  placed  just  on  the  surface  of the water?    As we  can  see  in  Fig.  4  the  plasmodium 
works perfectly.  We placed a piece of plasmodium  on bare surface of water (Fig. 4, start).  In three 
hours  the  plasmodium  forms  an  almost  circular  front  of  propagating  pseudopodia,  which  reach  two 
stationary domains with oat reaches in eight hours (Fig. 4). 

In usual conditions (on a wet solid or gel substrate) edges of spanning trees, presented by protoplasmic 
tubes,  adhere  to  the  surface  of  the  substrate  [Nakagaki  et  al.,  2003;  Adamatzky,  2007,  2008].  
Therefore the edges cannot move, and the only way the plasmodium can do a dynamical update is to 
make a protoplasmic tube inoperative and to form a new edge instead (membrane shell of the ceased 
link will remain on the substrate, e.g. see [Adamatzky, 2008]). When plasmodium operates on water 
surface, cohesion between the water surface and membrane of protoplasmic tubes is small enough for 
the protoplasmic tubes to move freely.  Thus the plasmodium can make the tubes almost straight and 
thus minimize costs of the transfer and communication between its distant parts.  Two examples of the 
straightening of the protoplasmic tubes are shown in Fig. 5.  Such straightening is a result of the tubes’ 
becoming shorter due to contraction.   

Presence of a contraction may indicate that if two floating objects (both with sources of nutrients) are 
connected  by  a  protoplasmic  tube  then  the  objects  will  be  pulled  together  due  to shortening  of  the 
protoplasmic tube.  We did not manage to demonstrate this exact phenomenon of pulling two floating 
objects  together,  however  we  got  experimental  evidence  of  pushing  and  pulling  of  single  floating 
objects  by  the  plasmodium’s  pseudopodia.  The  plasmodium-induced  pushing  and  pulling  are 
exemplified in Figs. 6 and 7.  

To  demonstrate  pushing  we  placed  a  very  light-weight  piece  of  plastic  foam  on  the  water  surface 
nearby the plasmodium (Fig. 6, 0 hours). The plasmodium develops a pseudopodium which propagates 
towards the light-weight piece of foam (Fig. 6, 5 hours). Due to gravity force acting on the pseudopodia 
a ripple is formed on the water surface (Fig. 6, 9 hours), which causes pushes the piece of foam away 
from the growing pseudopodia’s tip (Fig. 6, 13 hours).  Due to absence of any nutrients on the pushed 
piece of foam, the plasmodium abandons its attempt to occupy the piece and retracts the pseudopodia 
(Fig. 6, 16 hours).  The piece remains stationary: it became shifted away from its original position.  

In the second example, Fig. 7, we observe pulling of the light-weight object. The piece of foam to be 
pulled  is  placed  between  two  anchored  objects  (Fig.  7,  0  hours).    One  object  hosts  the  plasmodium 
another object has an oat flake on top (i.e. attracts the plasmodium).   A pseudopodium grows from 
the plasmodium’s original location towards the site with the source of nutrients.  The pseudopodium 
occupies the piece of foam (Fig. 7, 15 hours) and then continues its propagation towards the source of 
nutrients.    When  the  source  of  nutrients  is  reached  (Fig.  7,  22  hours)  the  protoplasmic  tubes 
connecting  two  anchored  objects  contract  and  straighten  thus  causing  the  light-weight  object  to  be 
pulled towards the source of nutrients (Fig. 7,  32 hours).  The pushing and pulling capabilities of the 
plasmodium  can  be  utilized  in  constructions  of  water-surface  based  distributed  manipulators 
[Hosokawa et al., 1996; Adamatzky et al., 2005]. 

Adamatzky A. 

 Discussion 

Towards Physarum robots 

Feb 2008 

Inspired by biomechanics of surface walking insects, see e.g. [McAlister, 1959; Suter et al., 1997, Suter, 
1999;  Suter  and  Wildman,  1999],  our  previous  studies  on  implementation  of  computing  tasks  in  the 
plasmodium [Adamatzky, 2007, 2008], and our ideas on design and fabrication of biological amorphous 
robots  [Kennedy  et  al.,  2001]  we  decided  to  explore  operational  capabilities  of  plasmodium  of 
Physarum  polycephalum  on  the  water  surface.    We  were  interested  to  demonstrate  that  the 
plasmodium  possesses  the  essential  features  of  distributed  robotics  devices:  sensing,  computing, 
locomotion and manipulation.  

Why  water  surface?  We  have  chosen  water  surface  as  an  experimental  substrate  because  there  is 
minimal friction and cohesions between the plasmodium’s pseudopodia and the surface, always near 
ideal  humidity  for  the  plasmodium,  continuous  removal  of  metabolites  and  excretions  from  the 
plasmodium’s body and protoplasmic tubes, increases chances of achieving manipulation of objects by 
the plasmodium.  

We demonstrated experimentally that the plasmodium (1) senses data-objects represented by sources 
of nutrients, (2) calculates shortest path between the data-objects, and approximates spanning trees 
where the data-objects are nodes (in principle, a spanning tree of slowly moving data-objects can be 
calculated as well), (3) pushes and pulls light-weight objects placed on the water surface.  The findings 
indicated  that  the  plasmodium  of  Physarum  polecephalum  is  a  perspective  candidate  for  the  role of 
spatially extended robots implemented on biological substrates.   

Our  experiment  also  show  that  Physarum 
implementation  of  Kolmogorov-Uspensky  machine 
[Adamatzky,  2008]  can  be  extended  to  mechanical  version  of  the  storage  modification  machine  by 
adding PUSH NODE and PULL NODE operations. To translocate nodes selectively in the storage structures 
we may need to assign certain attributes. This can be done by marking nodes with different species of 
colors;  in  [Adamatzky,  2008]  we  demonstrated  that  the  plasmodium  exhibits  strong  preferences  to 
certain food colouring, is neutral to others, and that some food colourings repel the plasmodium. Such 
preference hierarchy can be mapped onto the mobile data storage structure.  

More future experiments is required indeed to develop ideas derived from our scoping experiments to 
the full working prototypes of the Physarum robots and mechanical Kolmogorov-Uspenski machines. 

References 

[Adamatzky, De Lacy Costello, Asai, 2005] Adamatzky A., De Lacy Costello B., Asai T. Reaction-Diffusion 

Computers. Elsevier, 2005. 

[Adamatzky,  2007]  Adamatzky  A.  Approximation  of  of  spanning  trees  in  plasmodium  of  Physarum 

polycephalum. Kybernetes (2007), in press. 

[Adamatzky, 2007a]  Adamatzky A. Physarum machines: encapsulating reaction-diffusion to compute 

spanning tree. Naturwisseschaften (2007). 

[Adamatzky,  2008]  Adamatzky  A.  Physarum  machine:  implementation  of  a  Kolmogorov-Uspensky 

machine on a biological substrate. Parallel Processing Letters 17  (2008). 

[Adamatzky,  De  Lacy  Costello,  Shirakawa,  2008]  Adamatzky  A.,  De  Lacy  Costello  B.,  Shirakawa  T. 
limited  resources:  Belousov-Zhabotinsky  and  Physarum 

Universal  computation  with 
computers. Int. J. Bifurcation and Chaos (2008), in press. 

 [Hosokawa et  al.,  1996]  Hosokawa K.,  Shimoyama  I.,  Miura  H.  Two-dimensional  micro-self-assembly 

using the surface tension of water. Sensors and Actuators A 57 (1996) 117-125. 

[Kennedy, Melhuish, Adamatzky, 2001] Kennedy B., Melhuish C. and Adamatzky A. (2001) Biologically 
Inspired  Robots  in  In:  Y.  Bar-Cohen,  Editor,  Electroactive  polymer  (EAP)  actuators  --  Reality, 
Potential and challenges. SPIE Press 

 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

[Kirkpatrick and Radke, 1985] Kirkpatrick D.G. and Radke J.D. A framework for computational morphology. 

In: Toussaint G. T., Ed., Computational Geometry (North-Holland, 1985) 217-248. 

 [Matsumoto et al., 1988] Matsumoto, K., Ueda, T., and Kobatake, Y. (1988). Reversal of thermotaxis with 

oscillatory stimulation in the plasmodium of Physarum polycephalum. J. Theor. Biol. 131, 175–182. 

[McAlister, 1959] McAlister WH. 1959. The diving and surface-walking behaviour of Dolomedes triton 

sexpunctatus (Araneida: Pisauridae). Animal Behaviour 8: 109-111. 

[Nakagaki et al., 1999] Nakagaki T., Yamada H., and Ito M. (1999). Reaction–diffusion–advection model 
for  pattern  formation  of  rhythmic  contraction  in  a  giant  amoeboid  cell  of  the  Physarum 
plasmodium J. Theor. Biol., 197, 497-506. 

[Nakagaki et al., 2000] Nakagaki T., Yamada H., and Toth A., Maze-solving by an amoeboid organism. 

Nature 407 (2000) 470-470. 

[Nakagaki  2001]  Nakagaki  T.,  Smart  behavior  of  true  slime  mold  in  a  labyrinth.  Research  in 

Microbiology 152 (2001) 767-770. 

[Nakagaki et al 2001] Nakagaki T., Yamada H., and Toth A., Path finding by tube morphogenesis in an 

amoeboid organism. Biophysical Chemistry 92 (2001) 47-52. 

[Nakagaki  et  al  2003]  Nakagaki,  T.,  Yamada,  H.,  Hara,  M.  (2003).  Smart  network  solutions  in  an 

amoeboid organism, Biophys. Chem., 107, 1-5. 

[Nakagaki  2004]  Nakagaki,  T.,  Kobayashi,  R.,  Nishiura,  Y.  and  Ueda,  T.  (2004).  Obtaining  multiple 
separate  food  sources:  behavioural  intelligence  in  the  Physarum  plasmodium,  Proc.  R.  Soc. 
Lond. B, 271, 2305-2310. 

[Shimizu and Ishiguro, 2008] Shimizu M. and Ishiguro A. Amoeboid locomotion having high fluidity by a 

modular robot. Int. J. Unconventional Computing (2008), in press. 

[Shirakawa & Gunji, 2007] Shirakawa, T., and Gunji, Y.-P. (2007). Emergence of morphological order in 

the network formation of Physarum polycephalum, Biophys. Chem., 128, 253-260. 

[Shirakawa  &  Gunji,  2007a]  Shirakawa  T.  And  Gunji  Y.–P.  Computation  of  Voronoi  diagram  and 
collision-free  path  using  the  Plasmodium  of  Physarum  polycephalum.  Int.  J.  Unconventional 
Computing (2007), in press. 

[Adamatzky  et  al.,  2005]  Adamatzky  A.,  De  Lacy  Costello  B.,  Skachek  S.,  Melhuish  C.  Manipulating 
planar  shapes  with  a  light-sensitive  excitable  medium:  computational  studies  of  close-loop 
systems. Int. J. Bifurcation and Chaos 350 (2006) 201-209. 

[Suter  and  Wildman,  1999]  Suter  RB,  Wildman  H.  1999.  Locomotion  on  the  water  surface: 
hydrodynamic  constraints  on  rowing  velocity  require  a  gait  change.  Journal  of  Experimental 
Biology 202: 2771-2785.  

[Suter, 1999]  Suter RB. 1999. Cheap transport for fishing spiders: the physics of sailing on the  water 

surface. Journal of Arachnology 27: 489-496.  

[Suter  et  al.,  1997]  Suter  RB,  Rosenberg  O,  Loeb  S,  Wildman  H,  Long  J  Jr.  1997.  Locomotion  on  the 
water  surface:  propulsive  mechanisms  of  the  fisher  spider,  Dolomedes  triton.  Journal  of 
Experimental Biology 200: 2523-2538.  

[Tsuda et al., 2004] Tsuda, S., Aono, M., and Gunji, Y.-P., Robust and emergent Physarum computing. 

BioSystems 73 (2004) 45–55. 

 [Tsuda  et  al.,  2007]  Tsuda,  S.,  Zauner,  K.  P.  and  Gunji,  Y.  P.  Robot  control  with  biological  cells. 

Biosystems, 87, (2007) 215-223  

[Yokoi  and  Kakazu,  1992]  Yokoi  H.  and  Kakazu  Y.  Theories  and  applications  of  autonomic  machines 
based on the vibrating potential method, In: Proc. Int. Symp. Distributed Autonomous Robotics 
Systems (1992) 31-38. 

[Yokoi  et  al.,  2003]  H.  Yokoi,  T.  Nagai,  T.  Ishida,  M.  Fujii,  and  T.  Iida,  Amoeba-like  Robots  in  the 
Perspective  of  Control  Architecture  and  Morphology/Materials,    In:    Hara  F.  and  Pfeifer  R. 
(Eds.) Morpho-Functional Machines: The New Species, Springer-Verlag Tokyo, 2003, 99–129. 

 
 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

FIGURES 

                   a                                                                                              b 

Fig. 1. The plasmodium explores experimental arena by propagating tree-like pseudopodia. 

                      Start 

12 hours 

Fig. 2. Plasmodium builds links connecting its original domain of residence with two new sites. 

 
   
 
 
  
 
 
 
 
 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

Fig.3. Spanning tree of three points constructed by the plasmodium. 

                                            Start                                                                       3 hours 

                                          5 hours                                                                     8 hours 

Fig. 4.  Plasmodium starts its development on the water surface and occupies two sources of nutrients. 

 
 
 
 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

                                                 a                                                                           b   (12 hours later)     

                                             c                                                                      d      (12 hours later)                   

Fig.  5.  Examples  of  straightening  of  protoplasmic  tubes.  In  photographs  (a)  and  (c)  tubes  are  longer 
than necessary. In photographs (b) and (d) the tubes correspond to minimal shortest path between the 
sites they are connecting.  

 
  
   
 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

Fig. 6.  Photographs demonstrate that the plasmodium can push light-weight floating objects.  The 
object to be pushed is indicated by white arrow in the first photograph the series. 

 
 
 
Adamatzky A. 

Towards Physarum robots 

Feb 2008 

Fig. 7. Photographs demonstrate that the plasmodium can pull lightweight object.  The object to be 
pulled is indicated by white arrow in the first photograph."
A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning,"  Probabilistic sampling methods have become very popular to solve single-shot
path planning problems. Rapidly-exploring Random Trees (RRTs) in particular
have been shown to be efficient in solving high dimensional problems. Even
though several RRT variants have been proposed for dynamic replanning, these
methods only perform well in environments with infrequent changes. This paper
addresses the dynamic path planning problem by combining simple techniques in a
multi-stage probabilistic algorithm. This algorithm uses RRTs for initial
planning and informed local search for navigation. We show that this
combination of simple techniques provides better responses to highly dynamic
environments than the RRT extensions.
",http://arxiv.org/pdf/0912.0224v1,1,"A Multi-stage Probabilistic Algorithm for Dynamic Path-Planning

Nicolas A. Barriga
Departamento de Inform´atica
Universidad T´ecnica Federico Santa Mar´ıa
Valparaiso, Chile
nbarriga@inf.utfsm.cl

Mauricio Araya-L´opez
MAIA Equipe
INRIA/LORIA
Nancy, France
mauricio.araya@loria.fr

9
0
0
2

c
e
D
1

]
I

A
.
s
c
[

1
v
4
2
2
0
.
2
1
9
0
:
v
i
X
r
a

Abstract—Probabilistic sampling methods have become very
popular to solve single-shot path planning problems. Rapidly-
exploring Random Trees (RRTs) in particular have been shown
to be efﬁcient in solving high dimensional problems. Even
though several RRT variants have been proposed for dynamic
replanning, these methods only perform well in environments
with infrequent changes. This paper addresses the dynamic
path planning problem by combining simple techniques in a
multi-stage probabilistic algorithm. This algorithm uses RRTs
for initial planning and informed local search for navigation.
We show that this combination of simple techniques provides
better responses to highly dynamic environments than the RRT
extensions.

Keywords-artiﬁcial

intelligence; motion planning; RRT;

Multi-stage; local search; greedy heuristics;

I. INTRODUCTION

The dynamic path-planning problem consists in ﬁnding a
suitable plan for each new conﬁguration of the environment
by recomputing a free-collision path using the new informa-
tion available at each time step [5]. This kind of problem can
be found for example by a robot trying to navigate through
an area crowded with people, such as a shopping mall or
supermarket. The problem has been addressed widely in its
several ﬂavors, such as cellular decomposition of the con-
ﬁguration space [12], partial environmental knowledge [11],
high-dimensional conﬁguration spaces [6] or planning with
non-holonomic constraints [8]. However, simpler variations
of this problem are complex enough that cannot be solved
with deterministic techniques, and therefore they are worthy
to study.

This paper is focused on ﬁnding and traversing a collision-
free path in two dimensional space, for a holonomic robot 1,
without kinodynamic restrictions 2, in two different scenar-
ios:

• several unpredictably moving obstacles or adversaries.
• partially known environment, when at some point in

time, a new obstacle is found.

1A holonomic robot is a robot in which the controllable degrees of

freedom is equal to the total degrees of freedom.

2Kinodynamic planning is a problem in which velocity and acceleration

bounds must be satisﬁed

Besides from one (or few) new obstacle(s) in the second
scenario we assume that we have perfect information of the
environment at all times.

We will focus on continuous space algorithms and won’t
consider algorithms that use discretized representations of
the conﬁguration space, such as D* [12], because for high
dimensional problems, the conﬁguration space becomes in-
tractable in terms of both memory and computation time, and
there is the extra difﬁculty of calculating the discretization
size, trading off accuracy versus computational cost.

The ofﬂine RRT is efﬁcient at ﬁnding solutions but they
are far from being optimal, and must be post-processed for
shortening, smoothing or other qualities that might be de-
sirable in each particular problem. Furthermore, replanning
RRTs are costly in terms of computation time, as well as
evolutionary and cell-decomposition approaches. Therefore,
the novelty of this work is the mixture of the feasibility
the repairing capabilities of local
beneﬁts of the RRTs,
search, and the computational inexpensiveness of greedy
algorithms, into our lightweight multi-stage algorithm.

In the following sections, we present several path planning
methods that can be applied to the problem described above.
In section II-A we review the basic ofﬂine, single-query
RRT, a probabilistic method that builds a tree along the
free conﬁguration space until
it reaches the goal state.
Afterwards, we introduce the most popular replanning vari-
ants of the RRT: ERRT in section II-B, DRRT in section
II-C and MP-RRT in section II-D. Then,
in section III
we present our new hybrid multi-stage algorithm with the
experimental results and comparisons in section IV. At last,
the conclusions and further work are discussed in section V.

II. PREVIOUS AND RELATED WORK

A. Rapidly-Exploring Random Tree

One of the most successful probabilistic sampling meth-
ods for ofﬂine path planning currently in use, is the Rapidly-
exploring Random Tree (RRT), a single-query planner for
static environments, ﬁrst
introduced in [9]. RRTs work
towards ﬁnding a continuous path from a state qinit to a
state qgoal in the free conﬁguration space Cf ree, by building
a tree rooted at qinit. A new state qrand is uniformly sampled
at random from the conﬁguration space C. Then the nearest

 
 
 
 
 
 
node, qnear, in the tree is located, and if qrand and the
shortest path from qrand to qnear are in Cf ree, then qrand
is added to the tree. The tree growth is stopped when a node
is found near qgoal. To speed up convergence, the search is
usually biased to qgoal with a small probability.
In [7],
the
EXTEND function is introduced, which, instead of trying
to add directly qrand to the tree, makes a motion towards
qrand and tests for collisions.

two new features are added to RRTs. First,

Then a greedier approach is introduced, which repeats
EXTEND until an obstacle is reached. This ensures that most
of the time, we will be adding states to the tree, instead of
just rejecting new random states. The second extension is
the use of two trees, rooted at qinit and qgoal, which are
grown towards each other. This signiﬁcantly decreases the
time needed to ﬁnd a path.

B. ERRT

The execution extended RRT presented in [3] introduces
two RRTs extensions to build an on-line planner: the way-
point cache and the adaptive cost penalty search, which
improves re-planning efﬁciency and the quality of generated
paths. The waypoint cache is implemented by keeping a
constant size array of states, and whenever a plan is found,
all the states in the plan are placed in the cache with random
replacement. Then, when the tree is no longer valid, a new
tree must be grown, and there are three possibilities for
choosing a new target state. With probability P[goal], the
goal is chosen as the target; With probability P[waypoint], a
random waypoint is chosen, and with remaining probability
a uniform state is chosen as before. Values used in [3] are
P[goal]= 0.1 and P[waypoint]= 0.6.
In the other extension — the adaptive cost penalty search —
the planner dynamically modiﬁes a parameter β to help it
ﬁnding shorter paths. A value of 1 for β will always extend
from the root node, while a value of 0 is equivalent to the
original algorithm. Unfortunately, the solution presented in
[3] lacks of implementation details and experimental results
on this extension.

C. Dynamic RRT

The Dynamic Rapidly-exploring Random Tree (DRRT)
described in [4] is a probabilistic analog to the widely used
D* family of algorithms. It works by growing a tree from
qgoal to qinit. The principal advantage is that the root of
the tree does not have to be changed during the lifetime
in some problem
of the planning and execution. Also,
classes the robot has limited range sensors, thus moving
obstacles (or new ones) are typically near the robot and
not near the goal. In general, this strategy attempts to trim
smaller branches and farther away from the root. When new
information concerning the conﬁguration space is received,
the algorithm removes the newly-invalid branches of the
tree, and grows the remaining tree, focusing, with a certain

probability(empirically tuned to 0.4 in [4]) to a vicinity
of the recently trimmed branches, by using the a similar
structure to the waypoint cache of the ERRT. In experimental
results DRRT vastly outperforms ERRT.

D. MP-RRT

The Multipartite RRT presented in [14] is another RRT
variant which supports planning in unknown or dynamic
environments. The MP-RRT maintains a forest F of dis-
connected sub-trees which lie in Cf ree, but which are not
connected to the root node qroot of T , the main tree. At the
start of a given planning iteration, any nodes of T and F
which are no longer valid are deleted, and any disconnected
sub-trees which are created as a result are placed into F .
With given probabilities, the algorithm tries to connect T
to a new random state, to the goal state, or to the root of
a tree in F . In [14], a simple greedy smoothing heuristic
is used, that tries to shorten paths by skipping intermediate
nodes. The MP-RRT is compared to an iterated RRT, ERRT
and DRRT, in 2D, 3D and 4D problems, with and without
smoothing. For most of the experiments, MP-RRT modestly
outperforms the other algorithms, but in the 4D case with
smoothing, the performance gap in favor of MP-RRT is
much larger. The authors explained this fact due to MP-RRT
being able to construct much more robust plans in the face
of dynamic obstacle motion. Another algorithm that utilizes
the concept of forests is the Reconﬁgurable Random Forests
(RRF) presented in [10], but without the success of MP-RRT.

III. A MULTI-STAGE PROBABILISTIC ALGORITHM

In highly dynamic environments, with many (or a few but
fast) relatively small moving obstacles, regrowing trees are
pruned too fast, cutting away important parts of the trees
before they can be replaced. This reduce dramatically the
performance of the algorithms, making them unsuitable for
these class of problems. We believe that a better performance
could be obtained by slightly modifying a RRT solution
using simple obstacle-avoidance operations on the new col-
liding points of the path by informed local search. Then, the
path could be greedily optimized if the path has reached the
feasibility condition.

A. Problem Formulation

At each time-step, the proposed problem could be deﬁned
as an optimization problem with satisﬁability constraints.
Therefore, given a path our objective is to minimize an
evaluation function (i.e. distance, time, or path-points), with
the Cf ree constraint. Formally, let the path ρ = p1p2 . . . pn
a sequence of points, where pi ∈ Rn a n-dimensional point
(p1 = qinit, pn = qgoal), Ot ∈ O the set of obstacles
positions at time t, and eval : Rn × O (cid:55)→ R an evaluation
function of the path depending on the object positions. Then,
our ideal objective is to obtain the optimum ρ∗ path that

minimize our eval function within a feasibility restriction
in the form

ρ∗ = arg min

[eval(ρ, Ot)] with f eas(ρ, Ot) = Cf ree (1)

ρ

where f eas(·, ·) is a feasibility function that equals to
Cf ree iff the path ρ is collision free for the obstacles Ot.
For simplicity, we use very naive eval(·, ·) and f eas(·, ·)
functions, but this could be extended easily to more complex
evaluation and feasibility functions. The used f eas(ρ, Ot)
function assumes that the robot is a punctual object (dimen-
sionless) in the space, and therefore, if all segments −−−−→pipi+1
of the path do not collide with any object oj ∈ Ot, we
say that the path is in Cf ree. The eval(ρ, Ot) function will
be the points count of ρ, assuming that similar paths with
less points are shorter. This could be easily changed to the
euclidean distance, time, smoothness, clearness or several
other optimization criterions.

B. A Multi-stage Probabilistic Strategy

If solving equation 1 is not a simple task in static
environments, solving dynamic versions turns out to be even
more difﬁcult. In dynamic path planning we cannot wait
until reaching the optimal solution because we must deliver
a “good enough” plan within some time quantum. Then, a
heuristic approach must be developed to tackle the on-line
nature of the problem. The heuristic algorithms presented
in sections II-B, II-C and II-D, extend a method developed
for static environments, which produce a poor response to
highly dynamic environments and an unwanted complexity
of the algorithms.

We propose a multi-stage combination of three simple
heuristic probabilistic techniques to solve each part of the
problem: feasibility, initial solution and optimization.

1) Feasibility: The key point in this problem is the hard
constraint in equation 1 which must be met before even
thinking about optimizing. The problem is that in highly
dynamic environments a path turns rapidly from feasible to
unfeasible — and the other way around — even if our path
does not change. We propose a simple informed local search
to obtain paths in Cf ree. The idea is to randomly search for
a Cf ree path by modifying the nearest colliding segment of
the path. As we include in the search some knowledge of the
problem, the informed term is coined to distinguish it from
blind local search. The details of the operators used for the
modiﬁcation of the path are described in section III-C.

2) Initial Solution: The problem with local search algo-
rithms is that they repair a solution that it is assumed to
be near the feasibility condition. Trying to produce feasible
paths from scratch with local search (or even with evolution-
ary algorithms [13]) is not a good idea due the randomness
of the initial solution. Therefore, we propose feeding the
informed local search with a standard RRT solution at the
start of the planning, as can be seen in ﬁgure 1.

Figure 1. A Multi-stage Strategy for Dynamic Path Planning. This
ﬁgure describes the life-cycle of the multi-stage algorithm presented here.
The RRT, informed local search, and greedy heuristic are combined to
produce an expensiveness solution to the dynamic path planning problem.

3) Optimization: Without an optimization criteria,
the
path could grow inﬁnitely large in time or size. Therefore,
the eval(·, ·) function must be minimized when a (tempo-
rary) feasible path is obtained. A simple greedy technique
is used here: we test each point in the solution to check if
it can be removed maintaining feasibility, if so, we remove
it and check the following point, continuing until reaching
the last one.

C. Algorithm Implementation

Algorithm 1. Main()

Require: qrobot ← is the current robot position
Require: qgoal ← is the goal position

1: while qrobot (cid:54)= qgoal do
updateWorld(time)
2:
process(time)
3:

The multi-stage algorithm proposed in this paper works
by alternating environment updates and path planning, as

can be seen in Algorithm 1. The ﬁrst stage of the path
planning (see Algorithm 2) is to ﬁnd an initial path using a
RRT technique, ignoring any cuts that might happen during
environment updates. Thus, the RRT ensures that the path
found does not collide with static obstacles, but might collide
with dynamic obstacles in the future. When a ﬁrst path
is found, the navigation is done by alternating a simple
informed local search and a simple greedy heuristic as is
shown in Figure 1.

Algorithm 2. process(time)

Require: qrobot ← is the current robot position
Require: qstart ← is the starting position
Require: qgoal ← is the goal position
Require: Tinit ← is the tree rooted at the robot position
Require: Tgoal ← is the tree rooted at the goal position
Require: path ← is the path extracted from the merged

RRTs

1: qrobot ← qstart
2: Tinit.init(qrobot)
3: Tgoal.init(qgoal)
4: while time elapsed < time do
if ﬁrst path not found then
5:

RRT(Tinit, Tgoal)

else

6:
7:
8:
9:
10:
11:
12: postProcess(path)

if path is not collision free then

ﬁrstCol ← collision point closest to robot
arc(path, f irstCol)
mut(path, f irstCol)

Figure 3. The mutation operator. This operator draws two offset values
∆x and ∆y over a vicinity region. Then the same point b is moved in both
axises from b = [bx, by] to b(cid:48) = [bx ± ∆x, by ± ∆y], where the sign and
offset values are chosen randomly from an uniform distribution.

between two points in the path that form a segment colliding
with an obstacle, as is shown in Figure 2. The second step
in the function is a mutation operator that moves a point
close to an obstacle to a random point in the vicinity, as
is graphically explained in Figure 3. The mutation operator
is inspired by the ones used in the Adaptive Evolutionary
Planner/Navigator(EP/N) presented in [13], while the arc
operator is derived from the arc operator in the Evolutionary
Algorithm presented in [1].

Algorithm 3.
Require: vicinity ← some vicinity size

arc(path, f irstCol)

1: randDev ← random(−vicinity, vicinity)
2: point1 ← path[ﬁrstCol]
3: point2 ← path[ﬁrstCol+1]
4: if random()%2 then
5:
6:
7: else
newPoint1 ← (point1[X],point1[Y]+randDev)
8:
newPoint2 ← (point2[X],point2[Y]+randDev)
9:
10: if path segments point1-newPoint1-newPoint2-point2

newPoint1 ← (point1[X]+randDev,point1[Y])
newPoint2 ← (point2[X]+randDev,point2[Y])

are collision free then

add new points between point1 and point2

11:
12: else
13:

drop new point2

Figure 2. The arc operator. This operator draws an offset value ∆ over
a ﬁxed interval called vicinity. Then, one of the two axises is selected to
perform the arc and two new consecutive points are added to the path. n1 is
placed at a ±∆ of the point b and n2 at ±∆ of point c, both of them over
the same selected axis. The axis, sign and value of ∆ are chosen randomly
from an uniform distribution.

The third and last stage is the greedy optimization
heuristic, which can be seen as a post-processing for path
shortening, that eliminates intermediate nodes if doing so
does not create collisions, as is described in the Algorithm
5.

The second stage is the informed local search, which
is a two step function composed by the arc and mutate
operators (Algorithms 3 and 4). The ﬁrst one tries to build a
square arc around an obstacle, by inserting two new points

IV. EXPERIMENTS AND RESULTS
The multi-stage strategy proposed here has been devel-
oped to navigate highly-dynamic environments, and there-
fore, our experiments should be aimed towards that purpose.

Algorithm 4. mut(path, f irstCol)

Require: vicinity ← some vicinity size

1: path[ﬁrstCol][X] + = random(−vicinity, vicinity)
2: path[ﬁrstCol][Y] + = random(−vicinity, vicinity)
3: if path segments before and after path[ﬁrstCol] are

collision free then
accept new point

reject new point

4:
5: else
6:

Algorithm 5. postProcess(path)

1: i ← 0
2: while i < path.size()-2 do
3:

if segment path[i] to path[i+2] is collision free then

4:
5:
6:

delete path[i+1]

else

i ← i+1

Therefore, we have tested our algorithm in two highly-
dynamic situations, both of them over a map representing an
ofﬁce building or shopping mall (i.e. with some static walls).
Also, we have ran the DRRT and MP-RRT algorithms over
the same situations in order to compare the performance of
our proposal.

A. Experimental Setup

The dynamic environment. The green square is our robot,
Figure 4.
currently at the start position. The blue squares are the moving obstacles.
The blue cross is the goal.

The ﬁrst environment for our experiments consists on a
map with 30 moving obstacles the same size of the robot,
with a random speed between 10% and 55% the speed
of the robot. This dynamic environment is shown in ﬁgure 4.

Figure 5. The partially know environment. The green square is our robot,
currently at the start position. The black squares are the suddenly appearing
obstacles. The blue cross is the goal.

The second environment uses the same map, but with
six obstacles, three to four times the size of the robot,
appearing at a predeﬁned time and position. This partially
known environment is shown in ﬁgure 5.

The three algorithms were ran a hundred times in each
environment. The cutoff time was ﬁve minutes for the ﬁrst
environment and one minute for the second, after which, the
robot was considered not to have reached the goal.

B. Implementation Details

The algorithms where implemented in C++ using a

framework 3 developed by the same authors.

There are several variations that can be found in the liter-
ature when implementing RRTs. For all our RRT variants,
the following are the details on where we departed from the
basics:

• We always use two trees rooted at qinit and qgoal.
• Our EXTEND function, if the point cannot be added
without collisions to a tree, adds the mid point between
the nearest tree node and the nearest collision point to
it.

• In each iteration, we try to add the new randomly
generated point to both trees, and if successful in both,
the trees are merged, as proposed in [7].

• We found that the success rate was somewhat lower
if we allow the robot to advance towards the node
nearest to the goal when the trees are disconnected, as
proposed in [14]. The problem is that the robot would
become stuck if it enters a small concave zone of the

3MoPa homepage: https://csrg.inf.utfsm.cl/twiki4/bin/view/CSRG/MoPa

environment(like a room in a building) while there are
moving obstacles inside that zone. Therefore our robot
only moves when the trees are connected.

In MP-RRT, the forest was handled simply replacing the
oldest tree in it if the forest had reached the maximum size
allowed.

Concerning the parameter selection, the probability for
selecting a point in the vicinity of a point in the waypoint
cache in DRRT was set to 0.4 as suggested in [4]. The
probability for trying to reuse a sub tree in MP-RRT was set
to 0.1 as suggested in [14]. Also, the forest size was set to
25 and the minimum size of a tree to be saved in the forest
was set to 5 nodes.

C. Dynamic Environment Results

The results in table I show that it takes our algorithm
around a third of the time it takes the DRRT and MP-RRT to
get to the goal, with far less collision checks. It was expected
that nearest neighbor lookups would be much lower in the
multi-stage algorithm than in the other two, because they
are only performed in the RRT phase, not during navigation.
However, the multi-stage algorithm seems to be slighty less
dependable, as it arrived to the goal 98 out of 100 times,
while the other two managed to arrive always.

Table I
DYNAMIC ENVIRONMENT RESULTS. AVERAGE RESULTS OVER 100
RUNS, WITH 5 MINUTES CUTOFF

Algorithm
Multi-stage
DRRT
MP-RRT

Success % Coll. Checks

98
100
100

24364
92569
97517

Nearest Neigh.
1468
4536
4408

Time[s]
7.08
19.81
21.53

D. Partially Known Environment Results

The results in table II show that our multi-stage algorithm
is very undependable, though faster than the other two when
it actually reaches the goal. Due to the simplicity of our local
search, and that it basically just avoids obstacles by stepping
to the side or letting the obstacle move out of the way, when
the changes to the environment are signiﬁcant and obstacles
do not move, it is very prone to getting stuck.

Table II
PARTIALLY KNOWN ENVIRONMENT RESULTS. AVERAGE RESULTS
OVER 100 RUNS, WITH 1 MINUTE CUTOFF

Algorithm
Multi-stage
DRRT
MP-RRT

Success % Coll. Checks

44
100
98

4856
9845
17029

Nearest Neigh.
673
1037
1156

Time[s]
5.95
7.25
8.13

V. CONCLUSIONS

The new multi-stage algorithm proposed here has a very
good performance in very dynamic environments. It behaves
particularly well when several small obstacles are moving

around seemingly randomly. It’s major shortcoming is that
it gets easily stuck when signiﬁcant changes to the environ-
ment are made, such as big static obstacles appearing near
the robot, a situation usually considered as a partially known
environment.

A. Future Work

There are several areas of improvement for the work
presented in this paper. First of all, the multi-stage algorithm
must recognize a situation where it is stuck, and restart
an RRT from the current location, before continuing with
the navigation phase. The detection could be as simple as
recognizing that the robot has not moved out of a certain
vicinity for a given period of time, or that the next collision
in the planned path has been against the same obstacle
during a given period of time, meaning that the local search
has been unable to ﬁnd a path around it. This will yield
a much more dependable algorithm in different kinds of
environments.

A second area of improvement is to experiment with
different on-line planners such as the EP/N presented in
[13], a version of the EvP([1] and [2]) modiﬁed to work in
continuous conﬁguration space or a potential ﬁeld navigator.
Also, the local search presented here, could beneﬁt from the
use of more sophisticated operators.

A third area of research that could be tackled is extending
this algorithm to other types of environments, ranging from
totally known and very dynamic, to static partially known or
unknown environments. An extension to higher dimensional
problems would be one logical way to go, as RRTs are know
to work well in higher dimensions.

Finally, as RRTs are suitable for kinodynamic planning,
we only need to adapt the on-line stage of the algorithm to
have a new multi-stage planner for problem with kinody-
namic constraints.

REFERENCES

[1] T. Alfaro and M. Riff. An On-the-ﬂy Evolutionary Algorithm
Lecture Notes in Computer

for Robot Motion Planning.
Science, 3637:119, 2005.

[2] T. Alfaro and M. Riff. An Evolutionary Navigator for
Autonomous Agents on Unknown Large-Scale Environments.
INTELLIGENT AUTOMATION AND SOFT COMPUTING,
14(1):105, 2008.

[3] J. Bruce and M. Veloso. Real-time randomized path planning
Intelligent Robots and System, 2002.
for robot navigation.
IEEE/RSJ International Conference on, 3:2383–2388 vol.3,
2002.

[4] D. Ferguson, N. Kalra, and A. Stentz. Replanning with rrts.
Robotics and Automation, 2006. ICRA 2006. Proceedings
2006 IEEE International Conference on, pages 1243–1248,
15-19, 2006.

[5] Y. K. Hwang and N. Ahuja. Gross motion planning—a survey.

ACM Comput. Surv., 24(3):219–291, 1992.

[6] L. Kavraki, P. Svestka, J.-C. Latombe, and M. Overmars.
Probabilistic roadmaps for path planning in high-dimensional
conﬁguration spaces. Robotics and Automation, IEEE Trans-
actions on, 12(4):566–580, Aug 1996.

[11] A. Stentz. Optimal and efﬁcient path planning for partially-
In 1994 IEEE International Confer-
knownenvironments.
ence on Robotics and Automation, 1994. Proceedings., pages
3310–3317, 1994.

[7] J. Kuffner, J.J. and S. LaValle. Rrt-connect: An efﬁcient
approach to single-query path planning. Robotics and Au-
tomation, 2000. Proceedings. ICRA ’00. IEEE International
Conference on, 2:995–1001 vol.2, 2000.

[12] A. Stentz.

The Focussed Dˆ* Algorithm for Real-Time
In International Joint Conference on Artiﬁcial
Replanning.
Intelligence, volume 14, pages 1652–1659. LAWRENCE
ERLBAUM ASSOCIATES LTD, 1995.

[8] S. LaValle and J. Ku. Randomized kinodynamic planning,

1999.

[9] S. M. Lavalle. Rapidly-exploring random trees: A new tool
for path planning. Technical report, Computer Science Dept.,
Iowa State Univ., 1998.

[10] T.-Y. Li and Y.-C. Shie. An incremental learning approach
to motion planning with roadmap management. Robotics
and Automation, 2002. Proceedings. ICRA ’02. IEEE Inter-
national Conference on, 4:3411–3416 vol.4, 2002.

[13] J. Xiao, Z. Michalewicz, L. Zhang, and K. Trojanowski.
Adaptive evolutionary planner/navigator for mobile robots.
Evolutionary Computation, IEEE Transactions on, 1(1):18–
28, Apr 1997.

[14] M. Zucker, J. Kuffner, and M. Branicky. Multipartite rrts
for rapid replanning in dynamic environments. Robotics and
Automation, 2007 IEEE International Conference on, pages
1603–1609, April 2007."
"Combining a Probabilistic Sampling Technique and Simple Heuristics to
  solve the Dynamic Path Planning Problem","  Probabilistic sampling methods have become very popular to solve single-shot
path planning problems. Rapidly-exploring Random Trees (RRTs) in particular
have been shown to be very efficient in solving high dimensional problems. Even
though several RRT variants have been proposed to tackle the dynamic replanning
problem, these methods only perform well in environments with infrequent
changes. This paper addresses the dynamic path planning problem by combining
simple techniques in a multi-stage probabilistic algorithm. This algorithm uses
RRTs as an initial solution, informed local search to fix unfeasible paths and
a simple greedy optimizer. The algorithm is capable of recognizing when the
local search is stuck, and subsequently restart the RRT. We show that this
combination of simple techniques provides better responses to a highly dynamic
environment than the dynamic RRT variants.
",http://arxiv.org/pdf/0912.0266v1,1,"9
0
0
2

c
e
D
1

]
I

A
.
s
c
[

1
v
6
6
2
0
.
2
1
9
0
:
v
i
X
r
a

Combining a Probabilistic Sampling Technique and Simple Heuristics to solve
the Dynamic Path Planning Problem

Nicolas A. Barriga, Mauricio Solar
Departamento de Inform´atica
Universidad T´ecnica Federico Santa Mar´ıa
Valparaiso, Chile
{nbarriga,msolar}@inf.utfsm.cl

Mauricio Araya-L´opez
MAIA Equipe
INRIA/LORIA
Nancy, France
mauricio.araya@loria.fr

Abstract

Probabilistic sampling methods have become very
popular to solve single-shot path planning problems.
Rapidly-exploring Random Trees (RRTs) in particu-
lar have been shown to be very efﬁcient in solving
high dimensional problems. Even though several RRT
variants have been proposed to tackle the dynamic
replanning problem, these methods only perform well
in environments with infrequent changes. This pa-
per addresses the dynamic path planning problem by
combining simple techniques in a multi-stage prob-
abilistic algorithm. This algorithm uses RRTs as an
initial solution, informed local search to ﬁx unfeasible
paths and a simple greedy optimizer. The algorithm
is capable of recognizing when the local search is
stuck, and subsequently restart the RRT. We show that
this combination of simple techniques provides better
responses to a highly dynamic environment than the
dynamic RRT variants.

Index Terms

artiﬁcial intelligence; motion planning; RRT; Multi-
stage; local search; greedy heuristics; probabilistic
sampling;

1. Introduction

The dynamic path-planning problem consists in
ﬁnding a suitable plan for each new conﬁguration
of the environment by recomputing a collision free
path using the new information available at each time
step [5]. This kind of problem can be found for
example by a robot trying to navigate through an area

crowded with people, such as a shopping mall or super-
market. The problem has been addressed widely in its
several ﬂavors, such as cellular decomposition of the
conﬁguration space [12], partial environmental knowl-
edge [11], high-dimensional conﬁguration spaces [6] or
planning with non-holonomic constraints [8]. However,
simpler variations of this problem are complex enough
that cannot be solved with deterministic techniques,
and therefore they are worthy to study.

This paper is focused on ﬁnding and traversing a
collision-free path in two dimensional space, for a
holonomic robot 1, without kinodynamic restrictions 2,
in two different scenarios:

• Dynamic

environment:

several unpredictably

moving obstacles or adversaries.

• Partially known environment: some obstacles only
become visible when approached by the robot.

Besides from one (or few) new obstacle(s) in the
second scenario we assume that we have perfect in-
formation of the environment at all times.

We will focus on continuous space algorithms and
won’t consider algorithms that use discretized repre-
sentations of the conﬁguration space, such as D* [12],
because for high dimensional problems, the conﬁg-
uration space becomes intractable in terms of both
memory and computation time, and there is the extra
difﬁculty of calculating the discretization size, trading
off accuracy versus computational cost.

The ofﬂine RRT is efﬁcient at ﬁnding solutions but
they are far from being optimal, and must be post-
processed for shortening, smoothing or other qualities

1. A holonomic robot is a robot in which the controllable degrees

of freedom is equal to the total degrees of freedom.

2. Kinodynamic planning is a problem in which velocity and

acceleration bounds must be satisﬁed

 
 
 
 
 
 
that might be desirable in each particular problem.
Furthermore, replanning RRTs are costly in terms of
computation time, as well as evolutionary and cell-
decomposition approaches. Therefore, the novelty of
this work is the mixture of the feasibility beneﬁts of the
RRTs, the repairing capabilities of local search, and the
computational inexpensiveness of greedy algorithms,
into our lightweight multi-stage algorithm.

In the following sections, we present several path
planning methods that can be applied to the problem
described above. In section 2.1 we review the basic
ofﬂine, single-query RRT, a probabilistic method that
builds a tree along the free conﬁguration space until
it reaches the goal state. Afterward, we introduce the
most popular replanning variants of the RRT: ERRT in
section 2.2, DRRT in section 2.3 and MP-RRT in sec-
tion 2.4. Then, in section 3 we present our new hybrid
multi-stage algorithm with the experimental results and
comparisons in section 4. Finally, the conclusions and
further work are discussed in section 5.

2. Previous and Related Work

2.1. Rapidly-Exploring Random Tree

One of the most successful probabilistic sampling
methods for ofﬂine path planning currently in use, is
the Rapidly-exploring Random Tree (RRT), a single-
query planner for static environments, ﬁrst introduced
in [9]. RRTs work towards ﬁnding a continuous path
from a state qinit to a state qgoal in the free conﬁgu-
ration space Cf ree, by building a tree rooted at qinit.
A new state qrand is uniformly sampled at random
from the conﬁguration space C. Then the nearest
node, qnear, in the tree is located, and if qrand and
the shortest path from qrand to qnear are in Cf ree,
then qrand is added to the tree. The tree growth is
stopped when a node is found near qgoal. To speed up
convergence, the search is usually biased to qgoal with
a small probability.
In [7], two new features are added to RRTs. First,
the EXTEND function is introduced, which, instead
of trying to add directly qrand to the tree, makes a
motion towards qrand and tests for collisions.

Then a greedier approach is introduced, which re-
peats EXTEND until an obstacle is reached. This
ensures that most of the time, we will be adding states
to the tree, instead of just rejecting new random states.
The second extension is the use of two trees, rooted at
qinit and qgoal, which are grown towards each other.
This signiﬁcantly decreases the time needed to ﬁnd a
path.

2.2. ERRT

The execution extended RRT presented in [3] intro-
duces two RRTs extensions to build an on-line planner:
the waypoint cache and the adaptive cost penalty
search, which improves re-planning efﬁciency and the
quality of generated paths. The waypoint cache is
implemented by keeping a constant size array of states,
and whenever a plan is found, all the states in the
plan are placed in the cache with random replacement.
Then, when the tree is no longer valid, a new tree must
be grown, and there are three possibilities for choosing
a new target state. With probability P[goal], the goal
is chosen as the target; With probability P[waypoint],
a random waypoint
is chosen, and with remaining
probability a uniform state is chosen as before. Values
used in [3] are P[goal]= 0.1 and P[waypoint]= 0.6.
In the other extension — the adaptive cost penalty
search — the planner dynamically modiﬁes a parame-
ter β to help it ﬁnding shorter paths. A value of 1 for β
will always extend from the root node, while a value of
0 is equivalent to the original algorithm. Unfortunately,
the solution presented in [3] lacks of implementation
details and experimental results on this extension.

2.3. Dynamic RRT

The Dynamic Rapidly-exploring Random Tree
(DRRT) described in [4] is a probabilistic analog to
the widely used D* family of algorithms. It works
by growing a tree from qgoal to qinit. The principal
advantage is that the root of the tree does not have
to be changed during the lifetime of the planning
and execution. Also,
in some problem classes the
robot has limited range sensors, thus moving obstacles
(or new ones) are typically near the robot and not
near the goal. In general, this strategy attempts to
trim smaller branches and farther away from the root.
When new information concerning the conﬁguration
space is received, the algorithm removes the newly-
invalid branches of the tree, and grows the remaining
tree, focusing, with a certain probability(empirically
tuned to 0.4 in [4]) to a vicinity of the recently
trimmed branches, by using the a similar structure
to the waypoint cache of the ERRT. In experimental
results DRRT vastly outperforms ERRT.

2.4. MP-RRT

The Multipartite RRT presented in [14] is another
RRT variant which supports planning in unknown
or dynamic environments. The MP-RRT maintains a
forest F of disconnected sub-trees which lie in Cf ree,

but which are not connected to the root node qroot
of T , the main tree. At the start of a given planning
iteration, any nodes of T and F which are no longer
valid are deleted, and any disconnected sub-trees which
are created as a result are placed into F . With given
probabilities, the algorithm tries to connect T to a
new random state, to the goal state, or to the root
of a tree in F . In [14], a simple greedy smoothing
heuristic is used, that tries to shorten paths by skipping
intermediate nodes. The MP-RRT is compared to an
iterated RRT, ERRT and DRRT, in 2D, 3D and 4D
problems, with and without smoothing. For most of the
experiments, MP-RRT modestly outperforms the other
algorithms, but in the 4D case with smoothing, the
performance gap in favor of MP-RRT is much larger.
The authors explained this fact due to MP-RRT being
able to construct much more robust plans in the face
of dynamic obstacle motion. Another algorithm that
utilizes the concept of forests is the Reconﬁgurable
Random Forests (RRF) presented in [10], but without
the success of MP-RRT.

3. A Multi-stage Probabilistic Algorithm

In highly dynamic environments, with many (or a
few but fast) relatively small moving obstacles, regrow-
ing trees are pruned too fast, cutting away important
parts of the trees before they can be replaced. This
reduce dramatically the performance of the algorithms,
making them unsuitable for these class of problems.
We believe that a better performance could be obtained
by slightly modifying a RRT solution using simple
obstacle-avoidance operations on the new colliding
points of the path by informed local search. Then,
the path could be greedily optimized if the path has
reached the feasibility condition.

3.1. Problem Formulation

At each time-step, the proposed problem could be
deﬁned as an optimization problem with satisﬁability
constraints. Therefore, given a path our objective is
to minimize an evaluation function (i.e. distance, time,
or path-points), with the Cf ree constraint. Formally, let
the path ρ = p1p2 . . . pn a sequence of points, where
pi ∈ Rn a n-dimensional point (p1 = qinit, pn =
qgoal), Ot ∈ O the set of obstacles positions at time
t, and eval : Rn × O (cid:55)→ R an evaluation function
of the path depending on the object positions. Then,
our ideal objective is to obtain the optimum ρ∗ path
that minimize our eval function within a feasibility
restriction in the form

ρ

ρ∗ = arg min

[eval(ρ, Ot)] with f eas(ρ, Ot) = Cf ree
(1)
where f eas(·, ·) is a feasibility function that equals
to Cf ree iff the path ρ is collision free for the obstacles
Ot. For simplicity, we use very naive eval(·, ·) and
f eas(·, ·) functions, but this could be extended easily
to more complex evaluation and feasibility functions.
The used f eas(ρ, Ot) function assumes that the robot
is a punctual object (dimensionless) in the space, and
therefore, if all segments −−−−→pipi+1 of the path do not
collide with any object oj ∈ Ot, we say that the
path is in Cf ree. The eval(ρ, Ot) function will be the
length of the path, i.e. the sum of the distances between
consecutive points. This could be easily changed to any
metric such as the time it would take to traverse this
path, accounting for smoothness, clearness or several
other optimization criteria.

3.2. A Multi-stage Probabilistic Strategy

If solving equation 1 is not a simple task in static
environments, solving dynamic versions turns out to
be even more difﬁcult. In dynamic path planning we
cannot wait until reaching the optimal solution because
we must deliver a “good enough” plan within some
time quantum. Then, a heuristic approach must be
developed to tackle the on-line nature of the problem.
The heuristic algorithms presented in sections 2.2,
2.3 and 2.4, extend a method developed for static
environments, which produce a poor response to highly
dynamic environments and an unwanted complexity of
the algorithms.

We propose a multi-stage combination of three
simple heuristic probabilistic techniques to solve each
part of the problem: feasibility, initial solution and
optimization.

3.2.1. Feasibility. The key point in this problem is
the hard constraint in equation 1 which must be met
before even thinking about optimizing. The problem
is that in highly dynamic environments a path turns
rapidly from feasible to unfeasible — and the other
way around — even if our path does not change. We
propose a simple informed local search to obtain paths
in Cf ree. The idea is to randomly search for a Cf ree
path by modifying the nearest colliding segment of the
path. As we include in the search some knowledge of
the problem, the informed term is coined to distinguish
it from blind local search. The details of the operators
used for the modiﬁcation of the path are described in
section 3.3.

3.3. Algorithm Implementation

Algorithm 1. Main()

Require: qrobot ← is the current robot position
Require: qgoal ← is the goal position

1: while qrobot (cid:54)= qgoal do
updateWorld(time)
2:
process(time)
3:

The multi-stage algorithm proposed in this paper
works by alternating environment updates and path
planning, as can be seen in Algorithm 1. The ﬁrst stage
of the path planning (see Algorithm 2) is to ﬁnd an
initial path using a RRT technique, ignoring any cuts
that might happen during environment updates. Thus,
the RRT ensures that the path found does not collide
with static obstacles, but might collide with dynamic
obstacles in the future. When a ﬁrst path is found, the
navigation is done by alternating a simple informed
local search and a simple greedy heuristic as is shown
in Figure 1.

Algorithm 2. process(time)

Require: qrobot ← is the current robot position
Require: qstart ← is the starting position
Require: qgoal ← is the goal position
Require: Tinit ← is the tree rooted at

the robot

position

Require: Tgoal ← is the tree rooted at

the goal

position

Require: path ← is the path extracted from the

Figure 1. A Multi-stage Strategy for Dynamic
Path Planning. This ﬁgure describes the life-cycle
of the multi-stage algorithm presented here. The
RRT, informed local search, and greedy heuristic
are combined to produce an expensiveness solu-
tion to the dynamic path planning problem.

it

they repair a solution that

3.2.2. Initial Solution. The problem with local search
algorithms is that
is
assumed to be near the feasibility condition. Trying to
produce feasible paths from scratch with local search
(or even with evolutionary algorithms [13]) is not a
good idea due the randomness of the initial solution.
Therefore, we propose feeding the informed local
search with a standard RRT solution at the start of
the planning, as can be seen in ﬁgure 1.

3.2.3. Optimization. Without an optimization criteria,
the path could grow inﬁnitely large in time or size.
Therefore, the eval(·, ·) function must be minimized
when a (temporary) feasible path is obtained. A simple
greedy technique is used here: we test each point in
the solution to check if it can be removed maintaining
feasibility, if so, we remove it and check the following
point, continuing until reaching the last one.

merged RRTs
1: qrobot ← qstart
2: Tinit.init(qrobot)
3: Tgoal.init(qgoal)
4: while time elapsed < time do
if ﬁrst path not found then
5:
6:
7:
8:
9:

RRT(Tinit, Tgoal)

else

if path is not collision free then

ﬁrstCol ← collision point closest to robot
arc(path, f irstCol)
mut(path, f irstCol)

10:
11:
12: postProcess(path)

The second stage is the informed local search, which
is a two step function composed by the arc and mutate
operators (Algorithms 3 and 4). The ﬁrst one tries to
build a square arc around an obstacle, by inserting
two new points between two points in the path that
form a segment colliding with an obstacle, as is shown

continuing with the navigation phase.

Algorithm 3. arc(path, f irstCol)

Require: vicinity ← some vicinity size

1: randDev ← random(−vicinity, vicinity)
2: point1 ← path[ﬁrstCol]
3: point2 ← path[ﬁrstCol+1]
4: if random()%2 then
5:
6:
7: else
8:
9:
10: if path segments point1-newPoint1-newPoint2-

newPoint1 ← (point1[X],point1[Y]+randDev)
newPoint2 ← (point2[X],point2[Y]+randDev)

newPoint1 ← (point1[X]+randDev,point1[Y])
newPoint2 ← (point2[X]+randDev,point2[Y])

point2 are collision free then

add new points between point1 and point2

11:
12: else
13:

drop new point2

Algorithm 4. mut(path, f irstCol)

Require: vicinity ← some vicinity size

1: path[ﬁrstCol][X]

+
random(−vicinity, vicinity)
+
random(−vicinity, vicinity)

2: path[ﬁrstCol][Y]

=

=

3: if path segments before and after path[ﬁrstCol] are

collision free then
accept new point

reject new point

4:
5: else
6:

The third and last stage is the greedy optimization
heuristic, which can be seen as a post-processing for
path shortening, that eliminates intermediate nodes if
doing so does not create collisions, as is described in
the Algorithm 5.

Algorithm 5. postProcess(path)

1: i ← 0
2: while i < path.size()-2 do
3:

if segment path[i] to path[i+2] is collision free
then

4:

5:
6:

delete path[i+1]

else

i ← i+1

4. Experiments and Results

The multi-stage strategy proposed here has been de-
veloped to navigate highly-dynamic environments, and

Figure 2. The arc operator. This operator draws
an offset value ∆ over a ﬁxed interval called vicin-
ity. Then, one of the two axises is selected to
perform the arc and two new consecutive points
are added to the path. n1 is placed at a ±∆ of
the point b and n2 at ±∆ of point c, both of them
over the same selected axis. The axis, sign and
value of ∆ are chosen randomly from an uniform
distribution.

Figure 3. The mutation operator. This operator
draws two offset values ∆x and ∆y over a vicinity
region. Then the same point b is moved in both
axises from b = [bx, by] to b(cid:48) = [bx ± ∆x, by ± ∆y],
where the sign and offset values are chosen ran-
domly from an uniform distribution.

in Figure 2. The second step in the function is a
mutation operator that moves a point close to an
obstacle to a random point in the vicinity, as is graph-
ically explained in Figure 3. The mutation operator is
inspired by the ones used in the Adaptive Evolutionary
Planner/Navigator(EP/N) presented in [13], while the
arc operator is derived from the arc operator in the
Evolutionary Algorithm presented in [1].
Even though the local search usually produce good
results for minor changes in the environment, it does
not when is faced to signiﬁcant changes and is quite
prone to getting stuck in an obstacle. To overcome
this limitation, our algorithm recognizes this situation,
and restarts an RRT from the current location, before

therefore, our experiments should be aimed towards
that purpose. Therefore, we have tested our algorithm
in a highly-dynamic situation on two maps, shown in
ﬁgures 4 and 5. For completeness sake, we have tested
on the same two maps, but modiﬁed to be a partially
known environment. Also, we have ran the DRRT and
MP-RRT algorithms over the same situations in order
to compare the performance of our proposal.

4.1. Experimental Setup

The ﬁrst environment for our experiments consists
on two maps with 30 moving obstacles the same
size of the robot, with a random speed between
10% and 55% the speed of the robot. This dynamic
environments are shown in ﬁgures 4 and 5.

Figure 5. The dynamic environment, Map 2. The
green square is our robot, currently at the start po-
sition. The blue squares are the moving obstacles.
The blue cross is the goal.

Figure 4. The dynamic environment, Map 1. The
green square is our robot, currently at the start po-
sition. The blue squares are the moving obstacles.
The blue cross is the goal.

The second environment uses the same maps, but
three to four times the size
with a few obstacles,
of the robot,
that become visible when the robot
approaches each one of them. This partially known
environments are shown in ﬁgure 6 and 7.

The three algorithms were ran a hundred times in
each environment. The cutoff time was ﬁve minutes
for all tests, after which, the robot was considered
not to have reached the goal. Results are presented
concerning:

• success rate: the percentage of times the robot

arrived to the goal

• number of nearest neighbor lookups performed
by each algorithm(N.N.): one of the possible
bottlenecks for tree-based algorithms

Figure 6. The partially know environment, Map 1.
The green square is our robot, currently at the start
position. The yellow squares are the suddenly
appearing obstacles. The blue cross is the goal.

• number of collision checks performed(C.C.),
which in our speciﬁc implementation takes a
signiﬁcant percentage of the running time

• time it took the robot to reach the goal

4.2. Implementation Details

The algorithms where implemented in C++ using a

framework 3 developed by the same authors.

There are several variations that can be found in the
literature when implementing RRTs. For all our RRT

3. MoPa homepage: https://csrg.inf.utfsm.cl/twiki4/bin/view/CSRG/MoPa

the forest size was set to 25 and the minimum size of
a tree to be saved in the forest was set to 5 nodes.

4.3. Dynamic Environment Results

The results in tables 1 and 2 show that it takes
our algorithm considerably less time than it
takes
the DRRT and MP-RRT to get to the goal, with far
less collision checks. It was expected that nearest
neighbor lookups would be much lower in the multi-
stage algorithm than in the other two, because they
are only performed in the initial phase, not during
navigation.

Table 1. Dynamic Environment Results, Map 1.

Algorithm
Multi-stage
DRRT-noadv
DRRT-adv
MP-RRT-noadv
MP-RRT-adv

Success %
99
100
98
100
94

C.C.
23502
91644
107225
97228
118799

N.N.
1122
4609
5961
4563
6223

Time[s]
6.62
20.57
23.72
22.18
26.86

Table 2. Dynamic Environment Results, Map 2.

Algorithm
Multi-stage
DRRT-noadv
DRRT-adv
MP-RRT-noadv
MP-RRT-adv

Success %
100
99
100
100
100

C.C.
10318
134091
34051
122964
25837

N.N.
563
4134
2090
4811
2138

Time[s]
8.05
69.32
18.94
67.26
16.34

4.4. Partially Known Environment Results

The results in tables 3 and 4 show that our multi-
stage algorithm, although designed for dynamic envi-
ronments, is also faster than the other two in a partially
known environment, though not as much as in the
previous cases.

Table 3. Partially Known Environment Results,
Map 1.

Algorithm
Multi-stage
DRRT-noadv
DRRT-adv
MP-RRT-noadv
MP-RRT-adv

Success %
100
100
99
99
97

C.C.
12204
37618
12131
49156
26565

N.N.
1225
1212
967
1336
1117

Time[s]
7.96
11.66
8.26
13.82
11.12

5. Conclusions

The new multi-stage algorithm proposed here has a
very good performance in very dynamic environments.

Figure 7. The partially know environment, Map 2.
The green square is our robot, currently at the start
position. The yellow squares are the suddenly
appearing obstacles. The blue cross is the goal.

variants, the following are the details on where we
departed from the basics:

• We always use two trees rooted at qinit and qgoal.
• Our EXTEND function, if the point cannot be
added without collisions to a tree, adds the mid
point between the nearest tree node and the near-
est collision point to it.

• In each iteration, we try to add the new randomly
generated point to both trees, and if successful in
both, the trees are merged, as proposed in [7].
• We found that there are signiﬁcant performance
the robot
to
differences with allowing or not
advance towards the node nearest
to the goal
when the trees are disconnected, as proposed in
[14]. The problem is that the robot would become
stuck if it enters a small concave zone of the
environment(like a room in a building) while there
are moving obstacles inside that zone, but other-
wise it can lead to better performance. Therefore
we present results for both kinds of behavior:
DRRT-adv and MPRRT-adv, moves even when
the trees are disconnected, while DRRT-noadv
and MPRRT-noadv only moves when the trees are
connected.

In MP-RRT, the forest was handled simply replacing
the oldest
if the forest had reached the
maximum size allowed.

tree in it

Concerning the parameter selection, the probability
for selecting a point in the vicinity of a point in the
waypoint cache in DRRT was set to 0.4 as suggested
in [4]. The probability for trying to reuse a sub tree
in MP-RRT was set to 0.1 as suggested in [14]. Also,

Table 4. Partially Known Environment Results,
Map 2.

Algorithm
Multi-stage
DRRT-noadv
DRRT-adv
MP-RRT-noadv
MP-RRT-adv

Success %
100
99
100
100
100

C.C.
12388
54159
53180
48289
38901

N.N.
1613
1281
1612
1607
1704

Time[s]
17.66
32.67
32.54
30.64
25.71

It behaves particularly well when several small obsta-
cles are moving around seemingly randomly. This is
explained by the fact that if the obstacles are constantly
moving, they will sometimes move out of the way by
themselves, which our algorithm takes advantage of,
but the RRT based ones do not, they just drop branches
of the tree, that could have been useful again just a few
moments later.
In partially known environments the multi-stage algo-
rithm outperforms the RRT variants, but the difference
is not as much as in dynamic environments.

5.1. Future Work

There are several areas of improvement for the work
presented in this paper. The most promising seems to
be to experiment with different on-line planners such
as the EP/N presented in [13], a version of the EvP([1]
and [2]) modiﬁed to work in continuous conﬁguration
space or a potential ﬁeld navigator. Also, the local
search presented here, could beneﬁt from the use of
more sophisticated operators.

Another area of research that could be tackled is
extending this algorithm to other types of environ-
ments, ranging from totally known and very dynamic,
to static partially known or unknown environments. An
extension to higher dimensional problems would be
one logical way to go, as RRTs are know to work well
in higher dimensions.

Finally, as RRTs are suitable for kinodynamic plan-
ning, we only need to adapt
the on-line stage of
the algorithm to have a new multi-stage planner for
problem with kinodynamic constraints.

References

[1] T. Alfaro and M. Riff. An On-the-ﬂy Evolutionary
Algorithm for Robot Motion Planning. Lecture Notes
in Computer Science, 3637:119, 2005.

[2] T. Alfaro and M. Riff. An Evolutionary Navigator for
Autonomous Agents on Unknown Large-Scale Envi-
ronments. INTELLIGENT AUTOMATION AND SOFT
COMPUTING, 14(1):105, 2008.

[3] J. Bruce and M. Veloso. Real-time randomized path
Intelligent Robots and
planning for robot navigation.
System, 2002. IEEE/RSJ International Conference on,
3:2383–2388 vol.3, 2002.

[4] D. Ferguson, N. Kalra, and A. Stentz. Replanning
with rrts. Robotics and Automation, 2006. ICRA 2006.
Proceedings 2006 IEEE International Conference on,
pages 1243–1248, 15-19, 2006.

[5] Y. K. Hwang and N. Ahuja. Gross motion planning—a
survey. ACM Comput. Surv., 24(3):219–291, 1992.

[6] L. Kavraki, P. Svestka, J.-C. Latombe, and M. Over-
mars. Probabilistic roadmaps for path planning in high-
dimensional conﬁguration spaces. Robotics and Au-
tomation, IEEE Transactions on, 12(4):566–580, Aug
1996.

[7] J. Kuffner, J.J. and S. LaValle. Rrt-connect: An efﬁ-
cient approach to single-query path planning. Robotics
and Automation, 2000. Proceedings. ICRA ’00. IEEE
International Conference on, 2:995–1001 vol.2, 2000.

[8] S. LaValle and J. Ku. Randomized kinodynamic plan-

ning, 1999.

[9] S. M. Lavalle. Rapidly-exploring random trees: A new
tool for path planning. Technical report, Computer
Science Dept., Iowa State Univ., 1998.

[10] T.-Y. Li and Y.-C. Shie. An incremental learning ap-
proach to motion planning with roadmap management.
Robotics and Automation, 2002. Proceedings. ICRA
’02. IEEE International Conference on, 4:3411–3416
vol.4, 2002.

[11] A. Stentz. Optimal and efﬁcient path planning for
In 1994 IEEE Interna-
partially-knownenvironments.
tional Conference on Robotics and Automation, 1994.
Proceedings., pages 3310–3317, 1994.

[12] A. Stentz. The Focussed Dˆ* Algorithm for Real-
In International Joint Conference
Time Replanning.
on Artiﬁcial Intelligence, volume 14, pages 1652–1659.
LAWRENCE ERLBAUM ASSOCIATES LTD, 1995.

[13] J. Xiao, Z. Michalewicz, L. Zhang, and K. Trojanowski.
Adaptive evolutionary planner/navigator
for mobile
robots. Evolutionary Computation, IEEE Transactions
on, 1(1):18–28, Apr 1997.

[14] M. Zucker, J. Kuffner, and M. Branicky. Multipartite
rrts for rapid replanning in dynamic environments.
Robotics and Automation, 2007 IEEE International
Conference on, pages 1603–1609, April 2007."
"Single-Agent On-line Path Planning in Continuous, Unpredictable and
  Highly Dynamic Environments","  This document is a thesis on the subject of single-agent on-line path
planning in continuous,unpredictable and highly dynamic environments. The
problem is finding and traversing a collision-free path for a holonomic robot,
without kinodynamic restrictions, moving in an environment with several
unpredictably moving obstacles or adversaries. The availability of perfect
information of the environment at all times is assumed.
  Several static and dynamic variants of the Rapidly Exploring Random Trees
(RRT) algorithm are explored, as well as an evolutionary algorithm for planning
in dynamic environments called the Evolutionary Planner/Navigator. A
combination of both kinds of algorithms is proposed to overcome shortcomings in
both, and then a combination of a RRT variant for initial planning and informed
local search for navigation, plus a simple greedy heuristic for optimization.
We show that this combination of simple techniques provides better responses to
highly dynamic environments than the RRT extensions.
",http://arxiv.org/pdf/0912.0270v1,1,"Universidad T´ecnica Federico Santa Mar´ıa

Departamento de Inform´atica

Valpara´ıso – Chile

9
0
0
2

c
e
D
1

]
I

A
.
s
c
[

1
v
0
7
2
0
.
2
1
9
0
:
v
i
X
r
a

SINGLE-AGENT ON-LINE PATH PLANNING

IN CONTINUOUS, UNPREDICTABLE AND

HIGHLY DYNAMIC ENVIRONMENTS

Tesis presentada como requerimiento parcial

para optar al grado acad´emico de

MAG´ISTER EN CIENCIAS DE LA INGENIER´IA
INFORM ´ATICA

y al t´ıtulo profesional de
INGENIERO CIVIL EN INFORM ´ATICA

por

Nicol´as Arturo Barriga Richards

 
 
 
 
 
 
Comisi´on Evaluadora:

Dr. Mauricio Solar (Gu´ıa, UTFSM)

Dr. Horst H. von Brand (UTFSM)

Dr. John Atkinson (UdeC)

NOV 2009

i

Universidad T´ecnica Federico Santa Mar´ıa

Departamento de Inform´atica

Valpara´ıso – Chile

TITULO DE LA TESIS:

SINGLE-AGENT ON-LINE PATH PLANNING IN CONTIN-

UOUS, UNPREDICTABLE AND HIGHLY DYNAMIC ENVI-

RONMENTS

AUTOR:
NICOL ´AS ARTURO BARRIGA RICHARDS

Tesis presentada como requerimiento parcial para optar al grado acad´emico

de Mag´ıster en Ciencias de la Ingenier´ıa Inform´atica y al t´ıtulo pro-

fesional de Ingeniero Civil en Inform´atica de la Universidad T´ecnica

Federico Santa Mar´ıa.

Dr. Mauricio Solar

Profesor Gu´ıa

Dr. Horst H. von Brand

Profesor Correferente

Dr. John Atkinson

Profesor Externo

Nov 2009.

Valpara´ıso, Chile.

ii

Real stupidity beats artiﬁcial intelligence every time.

Terry Pratchett

iii

Acknowledgments

A mis hermanos, por quienes he tratado de ser una mejor persona, para ser un buen
ejemplo para ellos. A mis padres, de quienes hered´e lo que soy, tanto en cuerpo como
en esp´ıritu. A mis abuelos y abuelas, especialmente mi Opapa, de quien aprend´ı a
disfrutar la vida, y mi Tata, quien me ense˜n´o el valor de la familia.

Quiero tambi´en agradecer a los que hicieron posible esta tesis: Mauricio Araya por
ayudarme a escoger el tema y en el desarrollo posterior, a Rodrigo Araya por obli-
garme a trabajar en medio de las vacaciones de verano, a Nicol´as Troncoso, Diego
Candel y Roberto Bonvallet, y a mis profesores gu´ıas y correferentes, Mauricio Solar,
Horst H. von Brand y John Atkinson por sus aportes durante el desarrollo de esta tesis.

Quiero aprovechar la oportunidad para agradecer a los profesores que marcaron mi
estad´ıa en la Universidad: Horst H. von Brand, H´ector Allende, Luis Salinas, Hubert
Hoﬀmann, Claudio Dib y Viktor Sl¨usarenko.

Finalmente, quiero agradecer en especial a Pamela Saavedra, por estar junto a m´ı
durante los m´as de diez meses que demor´o en ser terminada esta tesis, soport´andome
y apoy´andome en los momentos m´as dif´ıciles.

Valpara´ıso, Chile
Noviembre 2009

Nicol´as A. Barriga

iv

Resumen

Este documento es una tesis en el tema de planiﬁcaci´on de caminos uniagente y en

l´ınea, para ambientes continuos, impredecibles y altamente din´amicos. El problema es

encontrar y recorrer un camino sin colisiones para un robot holon´omico, sin restric-

ciones kinodin´amicas, movi´endose en un ambiente con varios obst´aculos o adversarios

movi´endose impredeciblemente. Se asume la disponibilidad de informaci´on perfecta del

entorno en todo momento.

Varias variantes est´aticas y din´amicas del algoritmo “Rapidly Exploring Random

Trees” (RRT) se exploran, as´ı como tambi´en un algoritmo evolutivo para planiﬁcaci´on

en ambientes din´amicos llamado “Evolutionary Planner/Navigator.” Se propone una

combinaci´on de ambos algoritmos para superar las falencias de ambos y luego una

combinaci´on de RRT para planiﬁcaci´on inicial y b´usqueda local informada para nave-

gaci´on, sumado a una heur´ıstica voraz simple para optimizaci´on. Se demuestra que esta

combinaci´on de t´ecnicas simples produce mejores respuestas en ambientes altamente

din´amicos que las variantes RRT est´andar.

Palabras Claves: Inteligencia artiﬁcial. planiﬁcaci´on de rutas, RRT, multi-etapa,

b´usqueda local informada, heur´ıstica voraz, algoritmos evolutivos

v

Abstract

This document is a thesis on the subject of single-agent on-line path planning in con-

tinuous,unpredictable and highly dynamic environments. The problem is ﬁnding and

traversing a collision-free path for a holonomic robot, without kinodynamic restrictions,

moving in an environment with several unpredictably moving obstacles or adversaries.

The availability of perfect information of the environment at all times is assumed.

Several static and dynamic variants of the Rapidly Exploring Random Trees (RRT)

algorithm are explored, as well as an evolutionary algorithm for planning in dynamic

environments called the Evolutionary Planner/Navigator. A combination of both kinds

of algorithms is proposed to overcome shortcomings in both, and then a combination

of a RRT variant for initial planning and informed local search for navigation, plus

a simple greedy heuristic for optimization. We show that this combination of simple

techniques provides better responses to highly dynamic environments than the RRT

extensions.

Keywords: Artiﬁcial intelligence, motion planning, RRT, Multi-stage, informed

local search, greedy heuristics, evolutionary algorithms

vi

Index of Contents

Acknowledgments

Resumen

Abstract

Index of Contents

List of Tables

List of Figures

List of Algorithms

1 Introduction

1.1 Problem Formulation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2 Document Structure

2 State of the Art

2.1 Rapidly-Exploring Random Tree . . . . . . . . . . . . . . . . . . . . . .
2.2 Retraction-Based RRT Planner
. . . . . . . . . . . . . . . . . . . . . .
2.3 Execution Extended RRT . . . . . . . . . . . . . . . . . . . . . . . . .
2.4 Dynamic RRT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.5 Multipartite RRT . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2.6 Rapidly Exploring Evolutionary Tree . . . . . . . . . . . . . . . . . . .
2.7 Multidimensional Binary Search Trees
. . . . . . . . . . . . . . . . . .
2.8 Evolutionary Planner/Navigator . . . . . . . . . . . . . . . . . . . . . .

3 Proposed Techniques

3.1 Combining RRT and EP/N . . . . . . . . . . . . . . . . . . . . . . . .
3.1.1 The Combined Strategy . . . . . . . . . . . . . . . . . . . . . .
3.1.2 Algorithm Implementation . . . . . . . . . . . . . . . . . . . . .

vii

iv

v

vi

vii

ix

x

xi

1
2
3

5
5
8
8
9
11
11
13
15

19
19
19
20

3.2 A Simple Multi-stage Probabilistic Algorithm . . . . . . . . . . . . . .
3.2.1 A Multi-stage Probabilistic Strategy . . . . . . . . . . . . . . .
3.2.2 Algorithm Implementation . . . . . . . . . . . . . . . . . . . . .

4 Experimental Setup and Results

4.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.1.1 Dynamic Environment . . . . . . . . . . . . . . . . . . . . . . .
4.1.2 Partially Known Environment . . . . . . . . . . . . . . . . . . .
4.1.3 Unknown Environment . . . . . . . . . . . . . . . . . . . . . . .
4.2
Implementation Details . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3 Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4.3.1 Dynamic Environment Results . . . . . . . . . . . . . . . . . . .
4.3.2 Partially Known Environment Results
. . . . . . . . . . . . . .
. . . . . . . . . . . . . . . . . .
4.3.3 Unknown Environment Results

5 Conclusions and Future Work

5.1 Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.1 Algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
5.1.2 Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Bibliography

20
21
22

27
27
27
27
28
28
31
32
34
34

37
38
38
38

40

viii

List of Tables

4.1 Dynamic Environment Results, map 1.

. . . . . . . . . . . . . . . . . .

4.2 Dynamic Environment Results, map 2.

. . . . . . . . . . . . . . . . . .

4.3 Partially Known Environment Results, map 1.

. . . . . . . . . . . . . .

4.4 Partially Known Environment Results, map 2.

. . . . . . . . . . . . . .

4.5 Unknown Environment Results

. . . . . . . . . . . . . . . . . . . . . .

33

33

35

36

36

ix

List of Figures

2.1 RRT during execution . . . . . . . . . . . . . . . . . . . . . . . . . . .

2.2 The roles of the genetic operators . . . . . . . . . . . . . . . . . . . . .

3.1 A Multi-stage Strategy for Dynamic Path Planning . . . . . . . . . . .

3.2 The arc operator

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3.3 The mutation operator . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.1 The dynamic environment, map 1 . . . . . . . . . . . . . . . . . . . . .

4.2 The dynamic environment, map 2 . . . . . . . . . . . . . . . . . . . . .

4.3 The partially known environment, map 1 . . . . . . . . . . . . . . . . .

4.4 The partially known environment, map 2 . . . . . . . . . . . . . . . . .

4.5 The unknown environment . . . . . . . . . . . . . . . . . . . . . . . . .

4.6 Dynamic environment time . . . . . . . . . . . . . . . . . . . . . . . . .

4.7 Dynamic environment success rate . . . . . . . . . . . . . . . . . . . . .

7

17

25

26

26

28

29

30

31

32

34

35

x

List of Algorithms

1

2

3

4

5

6

7

8

9

BuildRRT(qinit, qgoal)

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

Extend(T, q) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

RRTConnectPlanner(qinit, qgoal)

. . . . . . . . . . . . . . . . . . . . . .

Connect(T, q) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Retraction-based RRT Extension . . . . . . . . . . . . . . . . . . . . .

ChooseTarget(q, goal) . . . . . . . . . . . . . . . . . . . . . . . . . . . .

DRRT() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

ReGrowRRT() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

TrimRRT()

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

10

InvalidateNodes(obstacle)

. . . . . . . . . . . . . . . . . . . . . . . . .

11 MPRRTSearch(qinit)

. . . . . . . . . . . . . . . . . . . . . . . . . . . .

12 PruneAndPrepend(T, F, qinit) . . . . . . . . . . . . . . . . . . . . . . . .

13

SelectSample(F )

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

14 ExtendToTarget(T ) . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

15 EP/N . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

16 Main() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

17

processRRTEPN(time) . . . . . . . . . . . . . . . . . . . . . . . . . . .

18 Main() . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

19

20

processMultiStage(time) . . . . . . . . . . . . . . . . . . . . . . . . . .

arc(path, ﬁrstCol) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

21 mut(path, ﬁrstCol)

. . . . . . . . . . . . . . . . . . . . . . . . . . . . .

22

postProcess(path) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6

6

7

7

8

9

10

10

10

11

12

13

13

14

16

20

21

22

23

24

24

25

xi

Chapter 1

Introduction

The dynamic path-planning problem consists in ﬁnding a suitable plan for each new

conﬁguration of the environment by recomputing a collision-free path using the new

information available at each time step [HA92]. This kind of problem has to be solved

for example by a robot trying to navigate through an area crowded with people, such

as a shopping mall or supermarket. The problem has been widely addressed in its

several ﬂavors, such as cellular decomposition of the conﬁguration space [Ste95], partial

environmental knowledge [Ste94], high-dimensional conﬁguration spaces [KSLO96] or

planning with non-holonomic constraints [LKJ99]. However, even simpler variations

of this problem are complex enough that they can not be solved with deterministic

techniques, and therefore are worthy of study.

This thesis is focused on algorithms for ﬁnding and traversing a collision-free path
in two dimensional space, for a holonomic robot1, without kinodynamic restrictions2,

in a highly dynamic environment, but for comparison purposes three diﬀerent scenarios

will be tested:

• Several unpredictably moving obstacles or adversaries.

• Partially known environment, where some obstacles become visible when the

robot approaches each one of them.

1A holonomic robot is a robot in which the controllable degrees of freedom is equal to the total

degrees of freedom.

2Kinodynamic planning is a problem in which velocity and acceleration bounds must be satisﬁed

1

• Totally unknown environment, where every obstacle is initially invisible to the

planner, and only becomes visible when the robot approaches it.

Besides the obstacles in the second and third scenario we assume that we have perfect

information of the environment at all times.

We will focus on continuous space algorithms and will not consider algorithms that
use a discretized representation of the conﬁguration space3, such as D* [Ste95], because

for high dimensional problems the conﬁguration space becomes intractable in terms of

both memory and computation time, and there is the extra diﬃculty of calculating

the discretization size, trading oﬀ accuracy versus computational cost. Only single

agent algorithms will be considered here. On-line as well as oﬀ-line algorithms will

be studied. An on-line algorithm is one that is permanently adjusting its solution as

the environment changes, while an oﬀ-line algorithm computes a solution only once

(however, it can be executed many times).

The oﬄine Rapidly-Exploring Random Tree (RRT) is eﬃcient at ﬁnding solutions,

but the results are far from optimal, and must be post-processed for shortening, smooth-

ing or other qualities that might be desirable in each particular problem. Furthermore,

replanning RRTs are costly in terms of computation time, as are evolutionary and

cell-decomposition approaches. Therefore, the novelty of this work is the mixture of

the feasibility beneﬁts of the RRTs, the repairing capabilities of local search, and the

computational inexpensiveness of greedy algorithms, into our lightweight multi-stage

algorithm. Our working hypothesis will be that a multi-stage algorithm, using diﬀer-

ent techniques for initial planning and navigation, outperforms current probabilistic

sampling techniques in highly dynamic environments

1.1 Problem Formulation

At each time-step, the problem could be deﬁned as an optimization problem with

satisﬁability constraints. Therefore, given a path our objective is to minimize an

evaluation function (i.e., distance, time, or path-points), with the Cfree constraint.

3the space of possible positions that a physical system may attain

2

Formally, let the path ρ = p1p2 . . . pn be a sequence of points, where pi ∈ Rn is a n-
dimensional point (p1 = qinit, pn = qgoal), Ot ∈ O the set of obstacles positions at time
t, and eval : Rn × O (cid:55)→ R an evaluation function of the path depending on the object
positions. Our ideal objective is to obtain the optimum ρ∗ path that minimizes our

eval function within a feasibility restriction in the form

ρ∗ = argmin

[eval(ρ, Ot)] with feas(ρ, Ot) = Cfree

ρ

(1.1)

where feas(·, ·) is a feasibility function that equals Cfree if the path ρ is collision free

for the obstacles Ot. For simplicity, we use very naive eval(·, ·) and feas(·, ·) functions,

but our approach could be extended easily to more complex evaluation and feasibility

functions. The feas(ρ, Ot) function used assumes that the robot is a point object in
space, and therefore if no segments −−−→pipi+1 of the path collide with any object oj ∈ Ot,
we say that the path is in Cfree. The eval(ρ, Ot) function is the length of the path, i.e.,

the sum of the distances between consecutive points. This could be easily changed to

any other metric such as the time it would take to traverse this path, accounting for

smoothness, clearness or several other optimization criteria.

1.2 Document Structure

In the following sections we present several path planning methods that can be applied

to the problem described above. In section 2.1 we review the basic oﬄine, single-query

RRT, a probabilistic method that builds a tree along the free conﬁguration space until

it reaches the goal state. Afterwards, we introduce the most popular replanning vari-

ants of RRT: Execution Extended RRT (ERRT) in section 2.3, Dynamic RRT (DRRT)

in section 2.4 and Multipartite RRT (MP-RRT) in section 2.5. The Evolutionary Plan-

ner/Navigator (EP/N), along with some variants, is presented in section 2.8. Then, in

section 3.1 we present a mixed approach, using a RRT to ﬁnd an initial solution and

the EP/N to navigate, and ﬁnally, in section 3.2 we present our new hybrid multi-stage

algorithm, that uses RRT for initial planning and informed local search for navigation,

plus a simple greedy heuristic for optimization. Experimental results and compar-

isons that show that this combination of simple techniques provides better responses

3

to highly dynamic environments than the standard RRT extensions are presented in

section 4.3. The conclusions and further work are discussed in section 5.

4

Chapter 2

State of the Art

In this chapter we present several path planning methods that can be applied to the

problem described above. First we will introduce variations of the Rapidly-Exploring

Random Tree (RRT), a probabilistic method that builds a tree along the free conﬁg-

uration space until it reaches the goal state. This family of planners is fast at ﬁnding

solutions, but the solutions are far from optimal, and must be post-processed for short-

ening, smoothing or other qualities that might be desirable in each particular problem.

Furthermore, replanning RRTs are costly in terms of computation time. We then in-

troduce an evolutionary planner with somewhat opposite qualities: It is slow in ﬁnding

feasible solutions in diﬃcult maps, but eﬃcient at replanning when a feasible solution

has already been found. It can also optimize the solution according to any given ﬁtness

function without the need for a post-processing step.

2.1 Rapidly-Exploring Random Tree

One of the most successful probabilistic methods for oﬄine path planning currently

in use is the Rapidly-Exploring Random Tree (RRT), a single-query planner for static

environments, ﬁrst introduced in [Lav98]. RRTs works towards ﬁnding a continuous

path from a state qinit to a state qgoal in the free conﬁguration space Cfree by building

a tree rooted at qinit. A new state qrand is uniformly sampled at random from the

conﬁguration space C. Then the nearest node, qnear, in the tree is located, and if qrand

and the shortest path from qrand to qnear are in Cfree, then qrand is added to the tree

5

(algorithm 1). The tree growth is stopped when a node is found near qgoal. To speed

up convergence, the search is usually biased to qgoal with a small probability.

In [KL00], two new features are added to RRT. First, the EXTEND function (algo-

rithm 2) is introduced, which instead of trying to add qrand directly to the tree, makes

a motion towards qrand and tests for collisions.

Algorithm 1 BuildRRT(qinit, qgoal)
1: T ← empty tree

2: T. init(qinit)

3: while Distance(T, qgoal) > threshold do

4:

5:

qrand ← RandomConﬁg()

Extend(T, qrand)

6: return T

Algorithm 2 Extend(T, q)
1: qnear ← NearestNeighbor(q, T )

2: if NewConﬁg(q, qnear, qnew) then

3:

4:

5:

6:

7:

8:

T. add vertex(qnew)

T. add edge(qnear, qnew)

if qnew = q then

return Reached

else

return Advanced

9: return Trapped

Then a greedier approach is introduced (the CONNECT function, shown in algo-

rithms 3 and 4), which repeats EXTEND until an obstacle is reached. This ensures

that most of the time we will be adding states to the tree, instead of just rejecting new

random states. The second extension is the use of two trees, rooted at qinit and qgoal,

which are grown towards each other (see ﬁgure 2.1). This signiﬁcantly decreases the

time needed to ﬁnd a path.

6

Figure 2.1: RRT during execution

Algorithm 3 RRTConnectPlanner(qinit, qgoal)
1: Ta ← tree rooted at qinit

2: Tb ← tree rooted at qgoal

3: Ta. init(qinit)

4: Tb. init(qgoal)

5: for k = 1 to K do

6:

7:

8:

9:

qrand ← RandomConﬁg()

if not (Extend(Ta, qrand) = Trapped) then

if Connect(Tb, qnew) = Reached then

return Path(Ta, Tb)

10:

Swap(Ta, Tb)

11: return Failure

Algorithm 4 Connect(T, q)
1: repeat

2:

S ← Extend(T, q)

3: until (S (cid:54)= Advanced)

7

2.2 Retraction-Based RRT Planner

The Retraction-based RRT Planner presented in [ZM08] aims at improving the per-

formance of the standard oﬄine RRT in static environments with narrow passages.

The basic idea of the Optimize(qr, qn) function in algorithm 5 is to iteratively retract a

randomly generated conﬁguration that is in Cobs to the closest boundary point in Cfree.

So, instead of using the standard extension that tries to extend in a straight line from

qnear to qrand, it extends from qnear to the closest point in Cfree to qrand. This gives more

samples in narrow passages. This technique could easily be applied to on-line RRT

planners.

Algorithm 5 Retraction-based RRT Extension
1: qr ← a random conﬁguration in Cspace

2: qn ← the nearest neighbor of qr in T

3: if CollisionFree(qn, qr) then

4:

5:

T. addVertex(qr)

T. addEdge(qn, qr)

6: else

7:

8:

9:

S ← Optimize(qr, qn)

for all qi ∈ S do

Standard RRT Extension(T, qi)

10: return T

2.3 Execution Extended RRT

The Execution Extended RRT presented in [BV02] introduces two extensions to RRT

to build an on-line planner, the waypoint cache and adaptive cost penalty search,

which improve re-planning eﬃciency and the quality of generated paths. ERRT uses a

kd-tree (see section 2.7) to speed nearest neighbor look-up, and does not use bidirec-

tional search. The waypoint cache is implemented by keeping a constant size array of

states, and whenever a plan is found, all the states in the plan are placed in the cache

with random replacement. Then, when the tree is no longer valid, a new tree must be

8

grown, and there are three possibilities for choosing a new target state, as shown in

algorithm 6, which is used instead of RandomConﬁg() in previous algorithms. With

probability P[goal ], the goal is chosen as the target; with probability P[waypoint], a

random waypoint is chosen, and with the remaining probability a uniform state is

chosen as before. In [BV02] the values used are P[goal ]= 0.1 and P[waypoint]= 0.6.

Another extension is adaptive cost penalty search, where the planner adaptively

modiﬁed a parameter to help it ﬁnd shorter paths. A value of 1 for beta will always

extend from the root node, while a value of 0 is equivalent to the original algorithm.

However, the paper [BV02] lacks implementation details and experimental results on

this extension.

Algorithm 6 ChooseTarget(q, goal)
1: p ← UniformRandom(0.0, 1.0)

2: i ← UniformRandom(0.0, NumWayPoints)

3: if 0 < p < GoalProb then

4:

return qgoal

5: else if GoalProb < p < GoalProb + WayPointProb then

6:

return WayPointCache[i]

7: else if GoalProb + WayPointProb < p < 1 then

8:

return RandomConﬁg()

2.4 Dynamic RRT

The Dynamic Rapidly-Exploring Random Tree described in [FKS06] is a probabilistic

analog to the widely used D* family of algorithms. It works by growing a tree from

qgoal to qinit, as shown in algorithm 7. This has the advantage that the root of the tree

does not have to be moved during the lifetime of the planning and execution. In some

problem classes the robot has limited range sensors, thus moving or newly appearing

obstacles will be near the robot, not near the goal. In general this strategy attempts

to trim smaller branches that are farther away from the root. When new information

concerning the conﬁguration space is received, the algorithm removes the newly-invalid

branches of the tree (algorithms 9 and 10), and grows the remaining tree, focusing,

9

with a certain probability (empirically tuned to 0.4 in [FKS06]) to a vicinity of the

recently trimmed branches, by using the waypoint cache of the ERRT (algorithm 6).

In experiments presented in [FKS06] DRRT vastly outperforms ERRT.

Algorithm 7 DRRT()
1: qrobot ← the current robot position

2: T ← BuildRRT(qgoal, qrobot)

3: while qrobot (cid:54)= qgoal do

4:

qnext ← Parent(qrobot)

5: Move from qrobot to qnext

6:

7:

8:

9:

for all obstacles that changed O do

InvalidateNodes(O)

if Solution path contains an invalid node then

ReGrowRRT()

Algorithm 8 ReGrowRRT()
1: TrimRRT()

2: GrowRRT()

Algorithm 9 TrimRRT()
1: S ← ∅, i ← 1

2: while i < T. size() do

3:

4:

5:

6:

7:

8:

9:

qi ← T. node(i)

qp ← Parent(qi)

if qp.ﬂag = INVALID then

qi.ﬂag ← INVALID

if qi.ﬂag (cid:54)= INVALID then

S ← S (cid:83){qi}

i ← i + 1

10: T ← CreateTreeFromNodes(S)

10

Algorithm 10 InvalidateNodes(obstacle)
1: E ← FindAﬀectedEdges(obstacle)

2: for all e ∈ E do

3:

4:

qe ← ChildEndpointNode(e)

qe.ﬂag ← INVALID

2.5 Multipartite RRT

Multipartite RRT presented in [ZKB07] is another RRT variant which supports plan-

ning in unknown or dynamic environments. MP-RRT maintains a forest F of discon-

nected sub-trees which lie in Cfree, but which are not connected to the root node qroot

of T , the main tree. At the start of a given planning iteration, any nodes of T and F

which are no longer valid are deleted, and any disconnected sub-trees which are created

as a result are placed into F (as seen in algorithms 11 and 12). With given probabil-

ities, the algorithm tries to connect T to a new random state, to the goal state, or to

the root of a tree in F (algorithm 13). In [ZKB07], a simple greedy smoothing heuristic

is used, that tries to shorten paths by skipping intermediate nodes. The MP-RRT is

compared to an iterated RRT, ERRT and DRRT, in 2D, 3D and 4D problems, with

and without smoothing. For most of the experiments, MP-RRT modestly outperforms

the other algorithms, but in the 4D case with smoothing, the performance gap in favor

of MP-RRT is much larger. The authors explained this fact due to MP-RRT being able

to construct much more robust plans in the face of dynamic obstacle motion. Another

algorithm that utilizes the concept of forests is Reconﬁgurable Random Forests (RRF)

presented in [LS02], but without the success of MP-RRT.

2.6 Rapidly Exploring Evolutionary Tree

The Rapidly Exploring Evolutionary Tree, introduced in [MWS07] uses a bidirectional

RRT and a kd-tree (see section 2.7) for eﬃcient nearest neighbor search. The modiﬁca-

tions to the Extend() function are shown in algorithm 14. The re-balancing of a kd-tree

is costly, and in this paper a simple threshold on the number of nodes added before

re-balancing was used. The authors suggest using the method described in [AL02] and

11

Algorithm 11 MPRRTSearch(qinit)
1: T ← the previous search tree, if any

2: F ← the previous forest of disconnected sub-trees

3: qinit ← the initial state

4: if T = ∅ then

5:

6:

qroot ← qinit

Insert(qroot, T )

7: else

8:

9:

10:

PruneAndPrepend(T, F, qinit)

if TreeHasGoal(T ) then

return true

11: while search time/space remaining do

12:

13:

14:

15:

16:

17:

18:

19:

20:

21:

qnew ← SelectSample(F )

qnear ← NearestNeighbor(qnew,T )

if qnew ∈ F then

bconnect ← Connect(qnear, qnew)

if bconnect and TreeHasGoal(T ) then

return true

else

bextend ← Extend(qnear, qnew)

if bextend and IsGoal(qnew) then

return true

22: return false

used in [BV02] to improve the search speed. The novelty in this algorithm comes from

the introduction of an evolutionary algorithm [BFM97] that builds a population of

biases for the RRTs. The genotype of the evolutionary algorithm consists of a single

robot conﬁguration for each tree. This conﬁguration is sampled instead of the uniform

distribution. To balance exploration and exploitation, the evolutionary algorithm was

designed with 50% elitism. The ﬁtness function is related to the number of left and

right branches traversed during the insertion of a new node in the kd-tree. The goal

is to introduce a bias to the RRT algorithm which shows preference to nodes created

12

Algorithm 12 PruneAndPrepend(T, F, qinit)
1: for all q ∈ T, F do

2:

3:

4:

5:

if not NodeValid(q) then

KillNode(q)

else if not ActionValid(q) then

SplitEdge(q)

6: if not T = ∅ and qroot (cid:54)= qinit then

7:

8:

9:

if not ReRoot(T, qinit) then

F ← F (cid:83) T
T. init(qinit)

Algorithm 13 SelectSample(F )
1: p ← Random(0, 1)

2: if p < pgoal then

3:

qnew ← qgoal

4: else if p < (pgoal + pforest) and not Empty(F ) then

5:

qnew ← q ∈ SubTreeRoots(F )

6: else

7:

qnew ← RandomState()

8: return qnew

away from the center of the tree. The authors suggest combining RET with DRRT or

MP-RRT.

2.7 Multidimensional Binary Search Trees

The kd-tree, ﬁrst introduced in [Ben75], is a binary tree in which every node is a

k-dimensional point. Every non-leaf node generates a splitting hyperplane that divides

the space into two subspaces. In the RRT algorithm, the number of points grows incre-

mentally, unbalancing the tree, thus slowing nearest-neighbor queries. Re-balancing a

kd-tree is costly, so in [AL02] the authors present another approach: A vector of trees
is constructed, where for n points there is a tree that contains 2i points for each ”1” in

13

Algorithm 14 ExtendToTarget(T )
1: static p: population, inc ← 1
2: p(cid:48): temporary population

3: if inc > length(p) then

4:

5:

6:

7:

8:

9:

10:

11:

12:

13:

SortByFitness(p)
p(cid:48) ← null

for all i ∈ p do

if i is in upper 50% then
AddIndividual(i, p(cid:48))

else

i ← RandomState()
AddIndividual(i, p(cid:48))

p ← p(cid:48)

inc ← 1

14: qr ← p(inc)

15: qnear ← Nearest(T, qr)

16: qnew ← Extend(T, qnear)

17: if qnew (cid:54)= ∅ then

18:

19:

AddNode(T, qnew)

AssignFitness(p(inc), ﬁtness(qnew)

20: else

21:

AssignFitness(p(inc), 0)

22: return qnew

the ith place of the binary representation of n. As bits are cleared in the representation

due to increasing n, the trees are deleted, and the points are included in a tree that

corresponds to the higher-order bit which is changed to ”1”. This general scheme incurs

in logarithmic-time overhead, regardless of dimension. Experiments show a substantial

performance increase compared to a naive brute-force approach.

14

2.8 Evolutionary Planner/Navigator

An evolutionary algorithm [BFM97] is a generic population-based meta-heuristic opti-

mization algorithm. It is inspired in biological evolution, using methods such as indi-

vidual selection, reproduction and mutation. The population is composed of candidate

solutions and they are evaluated according to a ﬁtness function.

The Evolutionary Planner/Navigator presented in [XMZ96], [XMZT97], and [TX97]

is an evolutionary algorithm for path ﬁnding in dynamic environments. A high level

description is shown in algorithm 15. A diﬀerence with RRT is that it can optimize

the path according to any ﬁtness function deﬁned (length, smoothness, etc), without

the need for a post-processing step. Experimental tests have shown it has good per-

formance for sparse maps, but no so much for diﬃcult maps with narrow passages or

too crowded with obstacles. However, when a feasible path is found, it is very eﬃcient

at optimizing it and adapting to the dynamic obstacles. Every individual in the pop-

ulation is a sequence of nodes, representing nodes in a path consisting of straight-line

segments. Each node consists of an (x, y) pair and a state variable b with information

about the feasibility of the point and the path segment connecting it to the next point.

Individuals have variable length.

Since a path p can be either feasible or unfeasible, two evaluation functions are

used. For feasible paths (equation 2.1), the goal is to minimize distance traveled,

maintain a smooth trajectory and satisfy a clearance requirement (the robot should

not approach the obstacles too closely). For unfeasible paths, we use equation 2.2, taken

from [Xia97], where µ is the number of intersections of a whole path with obstacles

and η is the average number of intersections per unfeasible segment.

evalf (p) = wd · dist(p) + ws · smooth(p) + wc · clear(p)

(2.1)

evalu(p) = µ + η

(2.2)

EP/N uses eight diﬀerent operators, as shown in ﬁgure 2.2 (description taken

from [XMZ96]):

Crossover: Recombines two (parent) paths into two new paths. The parent paths

15

Algorithm 15 EP/N
1: P (t): population at generation t

2: t ← 0

3: Initialize(P (t))

4: Evaluate(P (t))

5: while (not termination-condition) do

6:

7:

8:

9:

10:

11:

12:

13:

14:

15:

16:

17:

18:

19:

t ← t + 1

Select operator oj with probability pj

Select parent(s) from P (t)

Produce oﬀspring applying oj to selected parent(s)

Evaluate oﬀspring

Replace worst individual in P (t) by new oﬀspring

Select best individual p from P (t)

if Feasible(p) then

Move along path p

Update all individuals in P (t) with current position

if changes in environment then

Update map

Evaluate(P (t))

t ← t + 1

are divided randomly into two parts respectively and recombined: The ﬁrst part

of the ﬁrst path with the second part of the second path, and the ﬁrst part of

the second path with the second part of the ﬁrst path. Note that there can be

diﬀerent numbers of nodes in the two parent paths.

Mutate 1: Used to ﬁne tune node coordinates in a feasible path for shape adjustment.

This operator randomly adjusts node coordinates within some local clearance of

the path so that the path remains feasible afterwards.

Mutate 2: Used for large random changes of node coordinates in a path, which can

be either feasible or unfeasible.

16

Figure 2.2: The roles of the genetic operators

Insert-Delete: Operates on an unfeasible path by inserting randomly generated new

nodes into unfeasible path segments and deleting unfeasible nodes (i.e., path

nodes that are inside obstacles).

Delete: Deletes nodes from a path, which can be either feasible or unfeasible. If the

path is unfeasible, the deletion is done randomly. Otherwise, the operator decides

whether a node should deﬁnitely be deleted based on some heuristic knowledge,

and if a node is not deﬁnitely deletable, its deletion will be random.

Swap: Swaps the coordinates of randomly selected adjacent nodes in a path, which

can be either feasible or unfeasible.

Smooth: Smoothens turns of a feasible path by “cutting corners,” i.e., for a selected

node, the operator inserts two new nodes on the two path segments connected to

that node respectively and deletes that selected node. The nodes with sharper

turns are more likely to be selected.

Repair: Repairs a randomly selected unfeasible segment in a path by “pulling” the

17

CrossoverDeleteMutation1SwapSmoothMutation2InsertDeleteRepairsegment around its intersecting obstacle.

The probabilities of using each operator is set randomly at the beginning, and then are

updated according to the success ratio of each operator, so more successful operators

are used more often, and automatically chosen according to the instance of the problem,

eliminating the diﬃcult problem of hand tuning the probabilities.

In [TX97], the authors include a memory buﬀer for each individual to store good

paths from its ancestors, which gave a small performance gain.

In [EAA04], the authors propose strategies for improving the stability and con-

trolling population diversity for a simpliﬁed version of the EP/N. An improvement

proposed by the authors in [XMZT97] is using heuristics for the initial population,

instead of random initialization. We will consider this improvement in section 3.1.

Other evolutionary algorithms have also been proposed for similar problems, in [NG04]

a binary genetic algorithm is used for an oﬄine planner, and [NVTK03] presents an

algorithm to generate curved trajectories in 3D space for an unmanned aerial vehicle.

EP/N has been adapted to an 8-connected grid model in [AR08] (with previous

work in [AR05] and [Alf05]). The authors study two diﬀerent crossover operators and

four asexual operators. Experimental results for this new algorithm (EvP) in static

unknown environments show that it is faster than EP/N.

18

Chapter 3

Proposed Techniques

3.1 Combining RRT and EP/N

As mentioned in section 2, RRT variants produce suboptimal solutions, which must

later be post-processed for shortening, smoothing or other desired characteristics. On

the other hand, EP/N, presented in section 2.8, can optimize a solution according to

any given ﬁtness function. However, this algorithm is slower at ﬁnding a ﬁrst feasible

solution. In this section we propose a combined approach, that uses RRT to ﬁnd an

initial solution to be used as starting point for EP/N, taking advantage of the strong

points of both algorithms.

3.1.1 The Combined Strategy

Initial Solution

EP/N as presented in section 2.8 can not ﬁnd feasible paths in a reasonable amount of

time in any but very sparse maps. For this reason, RRT will be used to generate a ﬁrst

initial solution, ignoring the eﬀects produced by dynamic objects. This solution will be

in the initial population of the evolutionary algorithm, along with random solutions.

Feasibility and Optimization

EP/N is the responsible of regaining feasibility when it is lost due to a moving obstacle

or a new obstacle found in a partially known or totally unknown environment. If a

19

feasible solution can not be found in a given amount of time, the algorithm is restarted,

keeping its old population, but adding a new individual generated by RRT.

3.1.2 Algorithm Implementation

Algorithm 16 Main()
1: qrobot ← is the current robot position

2: qgoal ← is the goal position

3: while qrobot (cid:54)= qgoal do

4:

5:

updateWorld(time)

processRRTEPN(time)

The combined RRT-EP/N algorithm proposed here works by alternating environ-

ment updates and path planning, as can be seen in algorithm 16. The ﬁrst stage of

the path planning (see algorithm 17) is to ﬁnd an initial path using a RRT technique,

ignoring any cuts that might happen during environment updates. Thus, the RRT

ensures that the path found does not collide with static obstacles, but might collide

with dynamic obstacles in the future. When a ﬁrst path is found, the navigation is

done by using the standard EP/N as shown in algorithm 15.

3.2 A Simple Multi-stage Probabilistic Algorithm

In highly dynamic environments, with many (or a few but fast) relatively small mov-

ing obstacles, regrowing trees are pruned too fast, cutting away important parts of the

trees before they can be replaced. This dramatically reduces the performance of the

algorithms, making them unsuitable for these classes of problems. We believe that bet-

ter performance could be obtained by slightly modifying a RRT solution using simple

obstacle-avoidance operations on the new colliding points of the path by informed local

search. The path could be greedily optimized if the path has reached the feasibility

condition.

20

Algorithm 17 processRRTEPN(time)
1: qrobot ← the current robot position

2: qstart ← the starting position

3: qgoal ← the goal position

4: Tinit ← the tree rooted at the robot position

5: Tgoal ← the tree rooted at the goal position

6: path ← the path extracted from the merged RRTs

7: qrobot ← qstart

8: Tinit. init(qrobot)

9: Tgoal. init(qgoal)

10: while time elapsed < time do

11:

12:

13:

14:

if First path not found then

RRT(Tinit, Tgoal)

else

EP/N()

3.2.1 A Multi-stage Probabilistic Strategy

If solving equation 1.1 is not a simple task in static environments, solving dynamic

versions turns out to be even more diﬃcult.

In dynamic path planning we cannot

wait until reaching the optimal solution because we must deliver a “good enough” plan

within some time restriction. Thus, a heuristic approach must be developed to tackle

the on-line nature of the problem. The heuristic algorithms presented in sections 2.3,

2.4 and 2.5 extend a method developed for static environments, which produces poor

response to highly dynamic environments and unwanted complexity of the algorithms.

We propose a multi-stage combination of simple heuristic and probabilistic tech-

niques to solve each part of the problem: Feasibility, initial solution and optimization.

Feasibility

The key point in this problem is the hard constraint in equation 1.1 which must be

met before even thinking about optimizing. The problem is that in highly dynamic

environments a path turns rapidly from feasible to unfeasible — and the other way

21

around — even if our path does not change. We propose a simple informed local search

to obtain paths in Cfree. The idea is to randomly search for a Cfree path by modifying

the nearest colliding segment of the path. As we include in the search some knowledge

of the problem, the informed term is coined to distinguish it from blind local search.

The details of the operators used for the modiﬁcation of the path are described in

section 3.2.2. If a feasible solution can not be found in a given amount of time, the

algorithm is restarted, with a new starting point generated by a RRT variant.

Initial Solution

The problem with local search algorithms is that they repair a solution that it is

assumed to be near the feasibility condition. Trying to produce feasible paths from

scratch with local search (or even with evolutionary algorithms [XMZT97]) is not a

good idea due the randomness of the initial solution. Therefore, we propose feeding

the informed local search with a standard RRT solution at the start of the planning,

as can be seen in ﬁgure 3.1.

Optimization

Without an optimization criterion, the path could grow inﬁnitely large in time or size.

Therefore, the eval(·, ·) function must be minimized when a (temporary) feasible path

is obtained. A simple greedy technique is used here: We test each point in the solution

to check if it can be removed maintaining feasibility; if so, we remove it and check the

following point, continuing until reaching the last one.

3.2.2 Algorithm Implementation

Algorithm 18 Main()
1: qrobot ← the current robot position

2: qgoal ← the goal position

3: while qrobot (cid:54)= qgoal do

4:

5:

updateWorld(time)

processMultiStage(time)

22

The multi-stage algorithm proposed in this thesis works by alternating environment

updates and path planning, as can be seen in algorithm 18. The ﬁrst stage of the path

planning (see algorithm 19) is to ﬁnd an initial path using a RRT technique, ignoring

any cuts that might happen during environment updates. Thus, RRT ensures that

the path found does not collide with static obstacles, but might collide with dynamic

obstacles in the future. When a ﬁrst path is found, the navigation is done by alternating

a simple informed local search and a simple greedy heuristic as shown in ﬁgure 3.1.

Algorithm 19 processMultiStage(time)
1: qrobot ← is the current robot position

2: qstart ← is the starting position

3: qgoal ← is the goal position

4: Tinit ← is the tree rooted at the robot position

5: Tgoal ← is the tree rooted at the goal position

6: path ← is the path extracted from the merged RRTs

7: qrobot ← qstart

8: Tinit. init(qrobot)

9: Tgoal. init(qgoal)

10: while time elapsed < time do

11:

12:

13:

14:

15:

16:

17:

if First path not found then

RRT(Tinit, Tgoal)

else

if path is not collision free then

ﬁrstCol ← collision point closest to robot

arc(path, ﬁrstCol)

mut(path, ﬁrstCol)

18: postProcess(path)

The second stage is the informed local search, which is a two step function composed

by the arc and mutate operators (algorithms 20 and 21). The ﬁrst one tries to build a

square arc around an obstacle, by inserting two new points between two points in the

path that form a segment colliding with an obstacle, as shown in ﬁgure 3.2. The second

step in the function is a mutation operator that moves a point close to an obstacle to

23

a random point in the vicinity, as explained graphically in ﬁgure 3.3. The mutation

operator is inspired by the ones used in the Adaptive Evolutionary Planner/Navigator

(EP/N) presented in [XMZT97], while the arc operator is derived from the arc operator

in the Evolutionary Algorithm presented in [AR05].

Algorithm 20 arc(path, ﬁrstCol)
1: vicinity ← some vicinity size

2: randDev ← random(−vicinity, vicinity)

3: point1 ← path[ﬁrstCol]

4: point2 ← path[ﬁrstCol + 1]

5: if random()%2 then

6:

7:

newPoint1 ← (point1[X] + randDev, point1[Y ])

newPoint2 ← (point2[X] + randDev, point2[Y ])

8: else

9:

10:

newPoint1 ← (point1[X], point1[Y ] + randDev)

newPoint2 ← (point2[X], point2[Y ] + randDev)

11: if path segments point1-newPoint1-newPoint2-point2 are collision free then

12:

Add new points between point1 and point2

13: else

14: Drop new points

Algorithm 21 mut(path, ﬁrstCol)
1: vicinity ← some vicinity size

2: path[ﬁrstCol][X] + = random(−vicinity, vicinity)

3: path[ﬁrstCol][Y] + = random(−vicinity, vicinity)

4: if path segments before and after path[ﬁrstCol] are collision free then

5:

Accept new point

6: else

7:

Reject new point

The third and last stage is the greedy optimization heuristic, which can be seen as

a post-processing for path shortening, that eliminates intermediate nodes if doing so

does not create collisions, as is described in the algorithm 22.

24

Algorithm 22 postProcess(path)
1: i ← 0

2: while i < path. size() − 2 do

3:

4:

5:

6:

if segment path[i] to path[i + 2] is collision free then

Delete path[i+1]

else

i ← i + 1

Figure 3.1: A Multi-stage Strategy for Dynamic Path Planning. This ﬁgure

describes the life-cycle of the multi-stage algorithm presented here. The RRT, informed

local search, and greedy heuristic are combined to produce a cheap solution to the

dynamic path planning problem.

25

Figure 3.2: The arc operator. This operator draws an oﬀset value ∆ over a ﬁxed

interval called vicinity. Then, one of the two axes is selected to perform the arc and

two new consecutive points are added to the path. n1 is placed at a ±∆ of the point b

and n2 at ±∆ of point c, both of them over the same selected axis. The axis, sign and

value of ∆ are chosen randomly from an uniform distribution.

Figure 3.3: The mutation operator. This operator draws two oﬀset values ∆x and

∆y over a vicinity region. Then the same point b is moved in both axes from b = [bx, by]
to b(cid:48) = [bx ± ∆x, by ± ∆y], where the sign and oﬀset values are chosen randomly from

an uniform distribution.

26

Chapter 4

Experimental Setup and Results

4.1 Experimental Setup

Although the algorithms developed in this thesis are aimed at dynamic environments,

for the sake of completeness they will also be compared in partially known environments

and in totally unknown environments, where some or all of the obstacles become visible

to the planner as the robot approaches each one of them, simulating a robot with limited

sensor range.

4.1.1 Dynamic Environment

The ﬁrst environment for our experiments consists on two maps with 30 moving obsta-

cles the same size of the robot, with a random speed between 10% and 55% the speed

of the robot. Good performance in this environment is the main focus of this thesis.

This dynamic environments are illustrated in ﬁgures 4.1 and 4.2.

4.1.2 Partially Known Environment

The second environment uses the same maps, but with a few obstacles, three to four

times the size of the robot, that become visible when the robot approaches each one of

them. This is the kind of environment that most dynamic RRT variants were designed

for. The partially known environments are illustrated in ﬁgure 4.3 and 4.4.

27

Figure 4.1: The dynamic environment, map 1. The green square is our robot, currently

at the start position. The blue squares are the moving obstacles. The blue cross is the

goal.

4.1.3 Unknown Environment

For completeness sake, we will compare the diﬀerent technique in a third environment,

were we use one of the maps presented before, but all the obstacles will initially be

unknown to the planners, and will become visible as the robot approaches them, forcing

several re-plans. This unknown environment is illustrated in ﬁgure 4.5.

4.2

Implementation Details

The algorithms where implemented in C++ using the MoPa framework1 partly devel-

oped by the author. This framework features exact collision detection, three diﬀerent

map formats (including .pbm images from any graphic editor), dynamic, unknown and

partially known environments and support for easily adding new planners. One of

the biggest downsides is that it only supports rectangular objects, so several objects

1MoPa homepage: https://csrg.inf.utfsm.cl/twiki4/bin/view/CSRG/MoPa

28

Figure 4.2: The dynamic environment, map 2. The green square is our robot, currently

at the start position. The blue squares are the moving obstacles. The blue cross is the

goal.

must be used to represent other geometrical shapes, as in ﬁgure 4.4, composed of 1588

rectangular objects.

There are several variations that can be found in the literature when implementing

RRT. For all our RRT variants, the following are the details on where we departed

from the basics:

1. We always use two trees rooted at qinit and qgoal.

2. Our EXTEND function, if the point cannot be added without collisions to a tree,

adds the mid point between the nearest tree node and the nearest collision point

to it.

3. In each iteration, we try to add the new randomly generated point to both trees,

and if successful in both, the trees are merged, as proposed in [KL00].

4. We believe that there might be signiﬁcant performance diﬀerences between al-

lowing or not allowing the robot to advance towards the node nearest to the goal

29

Figure 4.3: The partially known environment, map 1. The green square is our robot,

currently at the start position. The yellow squares are the suddenly appearing obsta-

cles. The blue cross is the goal.

when the trees are disconnected, as proposed in [ZKB07].

In point 4 above, the problem is that the robot would become stuck if it enters a small

concave zone of the environment (like a room in a building) while there are moving

obstacles inside that zone, but otherwise it can lead to better performance. Therefore

we present results for both kinds of behavior: DRRT-adv and MP-RRT-adv move even

when the trees are disconnected, while DRRT-noadv and MP-RRT-noadv only move

when the trees are connected.

In MP-RRT, the forest was handled by simply replacing the oldest tree in it if the

forest had reached the maximum allowed size.

Concerning the parameter selection, the probability for selecting a point in the vicin-

ity of a point in the waypoint cache in DRRT was set to 0.4 as suggested in [FKS06].

The probability for trying to reuse a subtree in MP-RRT was set to 0.1 as suggested

in [ZKB07]. Also, the forest size was set to 25 and the minimum size of a tree to be

saved in the forest was set to 5 nodes.

30

Figure 4.4: The partially known environment, map 2. The green square is our robot,

currently at the start position. The yellow squares are the suddenly appearing obsta-

cles. The blue cross is the goal.

For the combined RRT-EP/N, it was considered the planner was stuck after two sec-

onds without a feasible solution in the population, at which point a new solution from

a RRT variant is inserted into the population. For the simple multi-stage probabilis-

tic algorithm, the restart is made after one second of encountering the same obstacle

along the planned path. This second approach, which seems better, cannot be applied

to the RRT-EP/N, because there is no single path to check for collisions, but instead

a population of paths. The restart times where manually tuned.

4.3 Results

The three algorithms were run a hundred times in each environment and map com-

bination. The cutoﬀ time was ﬁve minutes for all tests, after which the robot was

considered not to have reached the goal. Results are presented concerning:

31

Figure 4.5: The unknown environment. The green square is our robot, currently at

the start position. The blue cross is the goal. None of the obstacles is visible initially

to the planners

• Success rate (S.R.): The percentage of times the robot arrived at the goal, before

reaching the ﬁve minutes cutoﬀ time. This does not account for collisions or time

the robot was stopped waiting for a plan.

• Number of nearest neighbor lookups performed by each algorithm (N.N.): One of

the possible bottlenecks for tree-based algorithms

• Number of collision checks performed (C.C.), which in our speciﬁc implementa-

tion takes a signiﬁcant percentage of the running time

• Time it took the robot to reach the goal, ± the standard deviation.

4.3.1 Dynamic Environment Results

The results in tables 4.1 and 4.2 show that the multi-stage algorithm takes considerably

less time than the DRRT and MP-RRT to reach the goal, with far less collision checks.

The combined RRT-EP/N is a close second. It was expected that nearest neighbor

32

lookups would be much lower in both combined algorithms than in the RRT variants,

because they are only performed in the initial phase and restarts, not during navigation.

The combined algorithms produce more consistent results within a map, as shown by

their smaller standard deviations, but also across diﬀerent maps. An interesting fact

is that in map 1 DRRT is slightly faster than MP-RRT, and in map 2 MP-RRT is

faster than DRRT. However the diﬀerences are too small to draw any conclusions.

Figures 4.6 and 4.7 show the times and success rates of the diﬀerent algorithms, when

changing the number of dynamic obstacles in map 1. The simple multi-stage algorithm

and the mixed RRT-EP/N clearly show the best performance, while the DRRT-adv

and MP-RRT-adv signiﬁcantly reduce their success rate when confronted to more than

30 moving obstacles.

Table 4.1: Dynamic Environment Results, map 1.

Algorithm

S.R.[%]

C.C. N.N.

Time[s]

Multi-stage

RRT-EP/N

DRRT-noadv

DRRT-adv

99

100

100

23502

1122

6.62 ± 0.7

58870

1971

10.34 ± 14.15

91644

4609

20.57 ± 20.91

98

107225

5961

23.72 ± 34.33

MP-RRT-noadv

100

97228

4563

22.18 ± 14.71

MP-RRT-adv

94

118799

6223

26.86 ± 41.78

Table 4.2: Dynamic Environment Results, map 2.

Algorithm

S.R.[%]

C.C. N.N.

Time[s]

Multi-stage

RRT-EP/N

DRRT-noadv

DRRT-adv

MP-RRT-noadv

MP-RRT-adv

100

100

10318

563

8.05 ± 1.47

21785

1849

12.69 ± 5.75

99

134091

4134

69.32 ± 49.47

100

100

100

34051

2090

18.94 ± 17.64

122964

4811

67.26 ± 42.45

25837

2138

16.34 ± 13.92

33

Figure 4.6: Times for diﬀerent number of moving obstacles in map 1.

4.3.2 Partially Known Environment Results

Taking both maps into consideration, the results in tables 4.3 and 4.4 show that both

combined algorithms are faster and more consistent than the RRT variants, with the

simple multi-stage algorithm being faster in both. These results were unexpected, as

the combined algorithms were designed for dynamic environments. It is worth to notice

though, that in map 1 DRRT-adv is a close second, but in map 2 it is a close last, so its

lack of reliability does not make it a good choice in this scenario. In this environment,

as in the dynamic environment, in map 1 DRRT is faster than MP-RRT, while the

opposite happens in map 2.

4.3.3 Unknown Environment Results

Results in table 4.5 present the combined RRT-EP/N clearly as the faster algorithm in

unknown environments, with the multi-stage algorithm in second place. In contrast to

34

Figure 4.7: Success rate for diﬀerent number of moving obstacles in map 1.

Table 4.3: Partially Known Environment Results, map 1.

Algorithm

S.R.[%] C.C. N.N.

Time[s]

Multi-stage

RRT-EP/N

DRRT-noadv

DRRT-adv

MP-RRT-noadv

MP-RRT-adv

100

12204

99

99076

1225

1425

7.96 ± 2.93

9.95 ± 2.03

100

37618

1212

11.66 ± 15.39

99

99

97

12131

967

8.26 ± 2.5

49156

1336

13.82 ± 17.96

26565

1117

11.12 ± 14.55

dynamic and partially known environments in this same map, MP-RRT is faster than

DRRT.

35

Table 4.4: Partially Known Environment Results, map 2.

Algorithm

S.R.[%] C.C. N.N.

Time[s]

Multi-stage

RRT-EP/N

DRRT-noadv

DRRT-adv

MP-RRT-noadv

MP-RRT-adv

100

100

12388

1613

17.66 ± 4.91

42845

1632

22.01 ± 6.65

99

54159

1281

32.67 ± 15.25

100

100

100

53180

1612

32.54 ± 19.81

48289

1607

30.64 ± 13.97

38901

1704

25.71 ± 12.56

Table 4.5: Unknown Environment Results

Algorithm

S.R.[%]

C.C. N.N.

Time[s]

Multi-stage

RRT-EP/N

DRRT-noadv

DRRT-adv

100

100

98

114987

2960

13.97 ± 3.94

260688

2213

10.69 ± 2.08

89743

1943

18.38 ± 22.01

100

104601

2161

19.64 ± 34.87

MP-RRT-noadv

99

129785

1906

21.82 ± 27.23

MP-RRT-adv

100

52426

1760

16.05 ± 10.87

36

Chapter 5

Conclusions and Future Work

The new multi-stage algorithm proposed here has good performance in very dynamic

environments.

It behaves particularly well when several small obstacles are moving

around at random. This is explained by the fact that if the obstacles are constantly

moving, they will sometimes move out of the way by themselves, which our algorithm

takes advantage of, while RRT based ones do not, they just drop branches of the tree

that could prove useful again just a few moments later. The combined RRT-EP/N,

although having more operators, and automatic adjustment of the operator probabil-

ities according to their eﬀectiveness, is still better than the RRT variants, but about

55% slower than the simple multi-stage algorithm. This is explained by the number of

collision checks performed, more than twice than the multi-stage algorithm, because

collision checks must be performed for the entire population, not just a single path.

In the partially known environment, even though the diﬀerence in collision checks

is even greater than in dynamic environments, the RRT-EP/N performance is about

25% worse than the multi-stage algorithm. Overall, the RRT variants are closer to the

performance of both combined algorithms.

In the totally unknown environment, the combined RRT-EP/N is about 30% faster

than the simple multi-stage algorithm, and both outperform the RRT variants, with

much smaller times and standard deviations.

All things considered, the simple multi-stage algorithm is the best choice in most

situations, with faster and more predictable planning times, a higher success rate, fewer

collision checks performed and, above all, a much simpler implementation than all the

37

other algorithms compared.

This thesis shows that a multi-stage approach, using diﬀerent techniques for initial

plannning and navigation, outperforms current probabilistic sampling techniques in

dynamic, partially known and unknown environments.

Part of the results presented in this thesis are published in [BALS09].

5.1 Future Work

We propose several areas of improvement for the work presented in this thesis.

5.1.1 Algorithms

The most promising area of improvement seems to be to experiment with diﬀerent

on-line planners such as a version of the EvP ([AR05] and [AR08]) modiﬁed to work

in continuous conﬁguration space or a potential ﬁeld navigator. Also, the local search

presented here could beneﬁt from the use of more sophisticated operators and the

parameters for the RRT variants (such as forest size for MP-RRT), and the EP/N (such

as population size) could beneﬁt from being tuned speciﬁcally for this implementation,

and not simply reusing the parameters found in previous work.

Another area of research that could be tackled is extending this algorithm to higher

dimensional problems, as RRT variants are known to work well in higher dimensions.

Finally, as RRT variants are suitable for kinodynamic planning, we only need to

adapt the on-line stage of the algorithm to have a new multi-stage planner for problems

with kinodynamic constraints.

5.1.2 Framework

The MoPa framework could beneﬁt from the integration of a third party logic layer,

with support for arbitrary geometrical shapes, a spatial scene graph and hierarchical

maps. Some candidates would be OgreODE [Ogr], Spring RTS [Spr] and ORTS [ORT].

Other possible improvements are adding support for other map formats, including

discrimination of static and moving obstacles, limited sensor range simulation and

38

integration with external hardware such as the Lego NXT [Leg], to run experiments in

a more realistic scenario.

39

Bibliography

[AL02]

[Alf05]

[AR05]

[AR08]

A. Atramentov and S.M. LaValle. Eﬃcient nearest neighbor searching for
motion planning. In Proceedings of the IEEE International Conference on
Robotics and Automation, volume 1, pages 632–637 vol.1, 2002.

T. Alfaro. Un algoritmo evolutivo para la resoluci´on del problema de plan-
iﬁcaci´on de rutas de un robot m´ovil. Master’s thesis, Departamento de
Inform´atica, Universidad T´ecnica Federico Santa Mar´ıa, June 2005.

T. Alfaro and M. Riﬀ. An on-the-ﬂy evolutionary algorithm for robot
motion planning. Lecture Notes in Computer Science, 3637:119, 2005.

T. Alfaro and M. Riﬀ. An evolutionary navigator for autonomous agents on
unknown large-scale environments. Intelligent Automation and Soft Com-
puting, 14(1):105, 2008.

[BALS09] N.A. Barriga, M. Araya-Lopez, and M. Solar. Combining a probabilis-
tic sampling technique and simple heuristics to solve the dynamic path
planning problem. In Proceedings XXVIII International Conference of the
Chilean Computing Science Society (SCCC), 2009.

[Ben75]

J.L. Bentley. Multidimensional binary search trees used for associative
searching. Communications of the ACM, 18(9):517, 1975.

[BFM97] T. B¨ack, DB Fogel, and Z. Michalewicz. Handbook of Evolutionary Com-

putation. Taylor & Francis, 1997.

[BV02]

J. Bruce and M. Veloso. Real-time randomized path planning for robot
navigation. In Proceedings of the IEEE/RSJ International Conference on
Intelligent Robots and Systems, volume 3, pages 2383–2388 vol.3, 2002.

[EAA04] A. Elshamli, HA Abdullah, and S. Areibi. Genetic algorithm for dynamic
In Proceedings of the Canadian Conference on Electrical

path planning.
and Computer Engineering, volume 2, 2004.

[FKS06] D. Ferguson, N. Kalra, and A. Stentz. Replanning with RRTs. In Proceed-
ings of the IEEE International Conference on Robotics and Automation,
pages 1243–1248, 15-19, 2006.

40

[HA92]

[KL00]

Yong K. Hwang and Narendra Ahuja. Gross motion planning — a survey.
ACM Computing Surveys, 24(3):219–291, 1992.

Jr. Kuﬀner, J.J. and S.M. LaValle. RRT-connect: An eﬃcient approach
to single-query path planning. In Proceedings of the IEEE International
Conference on Robotics and Automation, volume 2, pages 995–1001 vol.2,
2000.

[KSLO96] L.E. Kavraki, P. Svestka, J.-C. Latombe, and M.H. Overmars. Probabilistic
roadmaps for path planning in high-dimensional conﬁguration spaces. IEEE
Transactions on Robotics and Automation, 12(4):566–580, August 1996.

[Lav98]

S.M. Lavalle. Rapidly-Exploring Random Trees: A new tool for path plan-
ning. Technical report, Computer Science Department, Iowa State Univer-
sity, 1998.

[Leg]

Lego Mindstorms. http://mindstorms.lego.com/.

[LKJ99]

[LS02]

S.M. LaValle and J.J. Kuﬀner Jr. Randomized kinodynamic planning. In
Proceedings of the IEEE International Conference on Robotics and Automa-
tion, volume 1, 1999.

Tsai-Yen Li and Yang-Chuan Shie. An incremental learning approach to
motion planning with roadmap management. In Proceedings of the IEEE
International Conference on Robotics and Automation, volume 4, pages
3411–3416 vol.4, 2002.

[MWS07] S.R. Martin, S.E. Wright, and J.W. Sheppard. Oﬄine and online evolu-
tionary bi-directional RRT algorithms for eﬃcient re-planning in dynamic
In Proceedings of the IEEE International Conference on
environments.
Automation Science and Engineering, pages 1131–1136, September 2007.

[NG04]

G. Nagib and W. Gharieb. Path planning for a mobile robot using genetic
algorithms. In Proceedings of the International Conference on Electrical,
Electronic and Computer Engineering, pages 185–189, 2004.

[NVTK03] I.K. Nikolos, K.P. Valavanis, N.C. Tsourveloudis, and A.N. Kostaras. Evo-
lutionary algorithm based oﬄine/online path planner for UAV navigation.
IEEE Transactions on Systems, Man, and Cybernetics, Part B, 33(6):898–
912, December 2003.

[Ogr]

OgreODE. http://www.ogre3d.org/wiki/index.php/OgreODE.

[ORT]

ORTS
http://www.cs.ualberta.ca/~mburo/orts/.

software

free

A

–

RTS

game

engine.

[Spr]

The Spring Project. http://springrts.com/.

41

[Ste94]

[Ste95]

[TX97]

[Xia97]

A. Stentz. Optimal and eﬃcient path planning for partially-known environ-
ments. In Proceedings of the IEEE International Conference on Robotics
and Automation, pages 3310–3317, 1994.

In In-
A. Stentz. The focussed D* algorithm for real-time replanning.
ternational Joint Conference on Artiﬁcial Intelligence, volume 14, pages
1652–1659. LAWRENCE ERLBAUM ASSOCIATES LTD, 1995.

K.M. Trojanowski and Z.J. Xiao. Adding memory to the Evolutionary
Planner/Navigator. In Proceedings of the IEEE International Conference
on Evolutionary Computation, pages 483–487, 1997.

J. Xiao. Handbook of Evolutionary Computation, chapter G3.6 The Evolu-
tionary Planner/Navigator in a Mobile Robot Environment. IOP Publish-
ing Ltd., Bristol, UK, UK, 1997.

[XMZ96]

J. Xiao, Z. Michalewicz, and L. Zhang. Evolutionary Planner/Navigator:
Operator performance and self-tuning. In International Conference on Evo-
lutionary Computation, pages 366–371, 1996.

[XMZT97] J. Xiao, Z. Michalewicz, L. Zhang, and K. Trojanowski. Adaptive Evo-
lutionary Planner/Navigator for mobile robots. Proceedings of the IEEE
Transactions on Evolutionary Computation, 1(1):18–28, April 1997.

[ZKB07] M. Zucker, J. Kuﬀner, and M. Branicky. Multipartite RRTs for rapid
In Proceedings of the IEEE Inter-
replanning in dynamic environments.
national Conference on Robotics and Automation, pages 1603–1609, April
2007.

[ZM08]

Liangjun Zhang and D. Manocha. An eﬃcient retraction-based RRT plan-
ner. In Proceedings of the IEEE International Conference on Robotics and
Automation, pages 3743–3750, May 2008.

42"
"A Little More, a Lot Better: Improving Path Quality by a Simple Path
  Merging Algorithm","  Sampling-based motion planners are an effective means for generating
collision-free motion paths. However, the quality of these motion paths (with
respect to quality measures such as path length, clearance, smoothness or
energy) is often notoriously low, especially in high-dimensional configuration
spaces. We introduce a simple algorithm for merging an arbitrary number of
input motion paths into a hybrid output path of superior quality, for a broad
and general formulation of path quality. Our approach is based on the
observation that the quality of certain sub-paths within each solution may be
higher than the quality of the entire path. A dynamic-programming algorithm,
which we recently developed for comparing and clustering multiple motion paths,
reduces the running time of the merging algorithm significantly. We tested our
algorithm in motion-planning problems with up to 12 degrees of freedom. We show
that our algorithm is able to merge a handful of input paths produced by
several different motion planners to produce output paths of much higher
quality.
",http://arxiv.org/pdf/1001.2391v2,1,"A Little More, a Lot Better: Improving Path Quality
by a Path Merging Algorithm

Barak Raveh, Angela Enosh and Dan Halperin

1

0
1
0
2

r
p
A
4

]

O
R
.
s
c
[

2
v
1
9
3
2
.
1
0
0
1
:
v
i
X
r
a

Abstract—Sampling-based motion planners are an effective
means for generating collision-free motion paths. However, the
quality of these motion paths (with respect to quality measures
such as path length, clearance, smoothness or energy) is often
notoriously low, especially in high-dimensional conﬁguration
spaces. We introduce a simple algorithm for merging an arbitrary
number of input motion paths into a hybrid output path of
superior quality, for a broad and general formulation of path
quality. Our approach is based on the observation that the
quality of certain sub-paths within each solution may be higher
than the quality of the entire path. A dynamic-programming
algorithm, which we recently developed for comparing and
clustering multiple motion paths, reduces the running time of
the merging algorithm signiﬁcantly. We tested our algorithm in
motion-planning problems with up to 12 degrees of freedom. We
show that our algorithm is able to merge a handful of input
paths produced by several different motion planners to produce
output paths of much higher quality.

I. INTRODUCTION

F OR several decades, extensive efforts have been devoted

to research of deterministic and probabilistic methods for
ﬁnding collision-free paths for moving objects among obsta-
cles, with applications in diverse domains such as robotics,
graphical animation, surgical planning, computational biology
and computer games [1]–[4]. Probabilistic sampling-based
methods for motion planning were shown to be particularly
useful when the conﬁguration space of the moving body has
a large number of degrees of freedom [1], [4]–[8]. In many
applications, it is also relevant to ﬁnd a path that is better
than other alternative paths. However, ﬁnding an optimal path
with respect to various quality measures is often NP-hard,
even in low-dimensional cases where an arbitrary path can be
found efﬁciently [9]–[11]. Finding high-quality paths in higher
dimensions is even harder.

A. Manuscript Outline

In Sections II and III we discuss related work and outline the
contribution of this study. In Section IV we introduce the basic
concept of merging multiple motion paths into a hybrid-path
with improved quality. We outline three variants of the algo-
rithm, from a na¨ıve implementation, to an asymptotically faster
variant, which makes use of our recently introduced dynamic-
programming edit-distance algorithm for matching pairs of
motion pathways. In Section V we report on experiments of

B. Raveh is with the Department of Microbiology and Molecular
Genetics, Hadassah Medical School, The Hebrew University, Jerusalem, Israel
B. Raveh, A. Enosh and D. Halperin are with School of Computer Sci-
ence, Tel-Aviv University, Israel e-mail: {barak,angela,danha}@post.tau.ac.il

increasing difﬁculty, in which we compare the performance of
our approach to exisiting motion planners, for problems with
up to 12 degrees of freedom, where our method is particularly
effective.

II. RELATED WORK

We make a distinction between ﬁnding an optimal path
with respect to the entire (continuous) conﬁguration space, as
opposed to the restricted formulation, where we look for the
optimal path in a discrete graph of conﬁgurations. The latter
is generally much easier1. In fact, all common deterministic
and sampling-based algorithm aim to capture the topological
connectivity of the free space (Cfree) by a discrete graph struc-
ture (the roadmap graph), and the ﬁnal solution is extracted
by searching in this graph using Dijkstra’s algorithm [13] or
one of its variants (such as a maximal bottleneck-clearance
path, retrieved by minute modiﬁcations to Dijkstra’s algorithm
or by efﬁcient alternatives [14]). Kim et al. [15] devised
an augmented version of Dijkstra’s algorithm for ﬁnding the
optimal path in a graph, where diverse optimality criteria can
be combined in a ﬂexible manner. Hence, a major challenge
remains to build a representative graph structure that contains
high-quality paths in Cfree to begin with.

Finding optimal paths for instances of many motion plan-
ning problems is NP-hard [12], and efﬁcient analytic solutions
were devised only for extremely simple ones, such as trans-
lating objects among polygonal obstacles in the plane using
the shortest path [16]–[18] or the highest-clearance path [19].
Already for translating polyhedra, ﬁnding the shortest possible
path was shown to be NP-hard [9], [12]. Approximation algo-
rithms have been devised for several NP-hard motion-planning
problems; see, e.g., [10], [12], [20]. As an alternative to exact
solutions, sampling-based algorithms record the connectivity
of Cfree in a discrete graph structure by connecting random
landmarks, and were shown to be probabilistically complete.
Nonetheless, we usually cannot hope to completely cover the
space in reasonable running time using these methods. In
particular, for conﬁguration spaces of high dimension, it might
be difﬁcult to retrieve even a single feasible motion path, not
to mention a high-quality one.

a) Improving path quality by modifying the sampling
algorithm: Wilmarth et al. [21] improved the local clearance
of sampled conﬁgurations by sampling closer to the medial
axis. Nieuwenhuisen et al. [22] improved the optimal path
length in probabilistic roadmaps by closing cycles only when

1Although some speciﬁc graph-search formulations are also NP-hard, and

call for pseudo-polynomial-time algorithms or appropriate heuristics [12]

 
 
 
 
 
 
they signiﬁcantly reduce the (graph) path length between con-
ﬁgurations, and Geraerts et al. [23] combined both approaches.
In contrast to the above techniques, the approach we present
below is not tailored for any speciﬁc criterion of path quality,
and is designed to allow general formulations of path quality.
b) Improving path quality by post-processing: Two paths
if one path can be
are said to be homotopy equivalent
continuously deformed into the other, without introducing any
collisions along the way. Often the output path of a roadmap
is homotopy equivalent
to another higher-quality path. In
this case, post-processing procedures ignore the roadmap that
originally created the path, and focus on small perturbations
that improve the path within its homotopy class. Path pruning
and shortcut heuristics are common post-processing techniques
for creating shorter and smoother paths, with little chance
of switching between homotopy classes. Geraerts et al. [24]
locally improved path clearance using a retraction schemes
that resembles the approach taken by Wilmarth et al. [21],
and more recently [25], improved both path length and path
clearance simultaneously (but not other criteria of path qual-
ity). Geraerts et al. [26] locally improved path quality within
a corridor (an inﬂated path) by applying a force-ﬁeld to the
moving body within that corridor. In this case, the output path
is restricted by construction to the selected corridor. In the
Appendix, we discuss some more related work that deals with
the very formulation of path-quality measures.

III. CONTRIBUTION

We observe that sampling-based algorithms like Probabilis-
tic Roadmaps [6], Rapidly-exploring Random Trees [7] and
Expansive Space Trees [5] tend to generate different solutions
in different runs, depending on the random decisions made
at each run. Output solution paths may differ by continuous
homotopic deformations, but they can also come from different
homotopy classes. See, for example, Figure 1a, where three
different paths are shown, produced by three runs of the PRM
(Probabilistic Road-Maps) algorithm.

Planning arbitrary motion-paths is often easier than ﬁnding
high-quality paths [12], and a common practice in opti-
mization theory is to integrate existing solutions into a new
and improved solution, as is done, for example, in genetic
algorithms [27]. Following this line of thought, we observe
that even if the entire path has low quality, some shorter
subsegments within the path might be of high quality.

In this study, we describe a simple and efﬁcient post-
processing approach for improving the quality of the mo-
tion paths by hybridizing high-quality sub-paths from initial
solutions to the motion query. The initial solutions can be
generated using any standard single-query or multi-query
algorithm for motion planning (Figure 1). We integrate these
solution paths within a graph data-structure, which we call
the Hybridization-Graph, or H-Graph. We present several
approaches for efﬁciently merging multiple motion paths into a
single high-quality paths, and show how this simple paradigm
can efﬁciently produce high-quality paths under various qual-
ity measures, in a general and uniform manner, and without
the need for ad-hoc optimization. This allows for particular

2

ﬂexibility and improved running time in multi-query settings
where the type of quality criterion may vary between queries,
and we avoid recomputing the entire query each time.

IV. ALGORITHM

A. Hybridization Graph between Multiple Motion Paths

Intuitively, sampling-based algorithms (that were not tuned
towards a speciﬁc quality measure) are more likely to sample
short high-quality path segments than full length high-quality
paths. We are interested in generating a high-quality output
path by post-processing a set of l collision-free motion paths
π1, π2, ..., πl, which were generated by some arbitrary motion
planner, all sharing the same start and end conﬁguration. The
input paths are assumed to be given as a linear chain of discrete
nodes. A graph H (the Hybridization-Graph, or H-Graph) is
initialized from the union of these paths: the vertices VH are
the disjoint union of intermediate nodes from each path, in
addition to the start and end conﬁgurations. Likewise, the
edges EH are the original edges taken from the l motion
paths. After the initialization of H, we use a local-planner to
connect certain pairs of conﬁgurations that originate from the
various paths2, creating new ’bridges’ between or within paths.
We elaborate on the choice of those pairs of conﬁgurations
below. The resulting bridging edges create new paths in H
that contain sub-segments from different input paths. These
hybrid paths may have higher quality than any of the input
paths. The pseudo-code for constructing a general H-Graph is
outlined in Algorithm 1. Once H is constructed, we ﬁnd the
optimal solution with respect to H for any quality measure
of choice, using Dijkstra’s algorithm or one of its variants, as
described in the ﬁrst part of Section II.

Algorithm 1 Building a Hybridization Graph from l input
paths
Build-H-Graph(PathsList)

PathsList: a set of l input solution paths from initial to
goal conﬁguration
G : an output H-Graph

initialize-H-Graph(PathsList)
for all π1, π2 ∈ PathsList do

potentialBridgeEdges = a list of potential bridg-
ing edges between π1 and π2
for all e ∈potentialBridgeEdges do
πlocal = localPlanner(e.from → e.to)
if valid(πlocal) then

G.addWeightedEdge(e)

end if
end for

end for
return G

2The local-planner can be considered as a black box for our purposes,
but it typically involves systematic collision detection of intermediate conﬁg-
urations between a pair of end conﬁgurations

3

Fig. 1. An illustration of using hybridization-graphs to improve path quality in the Grid scene (extended from [22]). We visualize the trace of a elongated
rectangle that moves with both translation and rotation in a grid of obstacles: (I) We look for a short path that traverses the grid by ﬁrst generating l paths
using any standard-motion planner, either multi-query or single-query (PRM in this example). Standard techniques often tend to generate lengthy zigzagging
motion paths. (II) For constructing the H-Graph, we invoke a local-planner between certain pairs of conﬁgurations. The running time may depend on the
number of pairs, see Section IV. (III) The speciﬁc choice of a graph-search algorithm depends on the quality measure of interest (output path in magenta).
Images and PRM paths were generated using the OOPSMP motion-planning package [28]. The ﬁgure is best viewed in color.

B. H-Graph Variants

A particularly time consuming step in the process of path
hybridization is the invocation of the local-planner, due to
expensive computation such as collision detection queries. We
now discuss several variants of the hybridization algorithm,
which aim to heuristically or asymptotically reduce the number
of calls to the local-planner.

1) Exhaustive all-pairs formulation: In this na¨ıve approach
we apply the local planner between all the vertices VH of H
(all originating from the l original paths). If each path consists
of at most n nodes, the local-planner is invoked O(l2n2)
times, for every pair of conﬁgurations and in each pair of
paths. The n2 term is reﬂected in the list of potential bridge
edges in Algorithm 1. Since in this variant we test all pairs
of potential bridging edges, the resulting path quality will
be higher or equal compared to the other H-Graph variants
presented below, at the cost of possibly much longer running
time due to exhaustive invocation of the local-planner.

2) Neighborhood H-Graph: A simple saving in running
time is achieved by invoking the local-planner only between
close-by conﬁgurations in H. The neighborhood of a con-
ﬁguration can be set by a threshold distance D, using an
appropriate distance function on the conﬁguration space. This
straightforward approach can signiﬁcantly reduce the running
time (but also the resulting path quality), depending on the
selected threshold distance D, and the speciﬁcs of the motion
planning problem at hand.

3) Edit-Distance H-Graphs: As mentioned above,

in a
na¨ıve formulation, the local-planner is invoked O(l2n2) times.
We are now interested in reducing the O(n2) term by connect-
ing fewer edges. For practical purposes (as it emerges from
our experiments) we can assume that the number of paths l
is small. The Neighborhood H-Graph heuristic, suggested in
the previous section, reduces this number of potential edges
but it is heavily dependant on a neighborhood-size parameter.
Another alternative (which we did not test in the experiments

section of this manuscript) is to invoke the local-planner
only for the Φ nearest neighbours of each node, resulting in
an asymptotic reduction in the number of calls to the local
planner from O(l2n2) to O(lnΦ), but possibly missing many
useful connections. In this section, we take a more structured
view and bound the number of calls to the local-planner
for each pair of paths by O(n), using a recently introduced
path matching algorithm. For completeness of the exposition
we brieﬂy describe the edit-distance algorithm for matching
motion paths [29].

p2
q2

p3
q3

Algorithm 2 outlines the details of the dynamic program
for ﬁnding an optimal match between discrete motion paths p
and q of lengths m and n, respectively.. Let p1, p2, . . ., pm
and q1, q2, . . ., qn denote the conﬁgurations along the two
paths. We regard each path as a string with the constituting
conﬁgurations as letters. A valid matching between the paths
p and q is obtained by aligning the two respective strings one
on top of the other. Here are examples of valid ﬁttings of
p = {p1, p2, p3} and q = {q1, q2, q3, q4}.
-
q4

p1
p1
q1
q1
Formally, in edit-distance string matching we are trying to
edit one string to another string by using legal operations of
character replacement and character insertion / deletion [30].
We pay a certain price for each of these operations, and the
objective is to ﬁnd a set of edit operations where we pay
the minimal price. In order to align matching subpaths, we
give a higher penalty for matching (“replacing”) dissimilar
conﬁgurations. We also pay a price for opening a gap in the
alignment (“deleting/inserting”), for mismatching subpaths. In
this case, we align a letter against a space character (denoted
above as a dash), but we need to pay a penalty as well. The
edit operations induce a natural pairwise alignment between
the two paths, with gaps in regions of mismatch.

p2 p3
q4

-
q3 -

-
q2

Let ∆(pi, qj) be the price we pay for replacing conﬁguration
i of path p with conﬁguration j of path q. As stated, we pay

Randomly generate  multiple motion pathsusing any motion planning algorithmIConstruct the H-Graphlocal-planner ; path-matching algorithmIIFind high-quality pathgraph path-search algorithmIIIA hybrid output path with higher quality:π1π2π3startendless for replacing similar conﬁgurations, in order to match
similar regions. In addition, we pay a price GAPext for
extending gaps (and optionally, a price GAPinit for initiating a
new gap in the match3). A large GAPext penalty prevents gaps
and favors the matching of subsegments even if they are not
very similar, whereas a small GAPext penalty forces a more
selective matching. The GAPinit penalty favors a small overall
number of non-consecutive gaps (regardless of the length of
consecutive gap stretches).

The matrix C contains the optimal costs of matching
subsegments from p and q. The entry Cij is the suboptimal
cost of matching the ﬁrst i conﬁgurations from p to the ﬁrst
j conﬁgurations from q. We ﬁll it in by deciding whether to
match the conﬁgurations pi and qj or to open a gap. We record
this decision in the trace-back matrix TB. In the last iteration,
the cost of the alignment is in the last entry of Cmn, and the
trace-back matrix records the set of edit operations that leads
to an optimal matching. Thus, the alignment between motion
paths can be easily recovered from the TB matrix.

Algorithm 2 Dynamic-Programming Algorithm for Matching
Two Paths
MatchPaths(p,q)

C: a cost matrix ∈ (cid:60)m×n

{For i < 0 or j < 0, we deﬁne Ci,j = ∞}

TB: a symbolic trace-back matrix

for i=0 to m do

for j=0 to n do

Match⇐ Ci−1,j−1 + ∆(pi, qj)
Up⇐ Ci−1,j + GAPext
Left⇐ Ci,j−1 + GAPext
Ci,j ⇐ min (Match, Up, Left, 0)






” (cid:45) ”
” ↑ ”
” ← ”

for Match
for Up
for Left

TBi,j ⇐

end for

end for
return matrices C and T B

Although the asymptotic running time is clearly O(mn),
the practical running time is negligible compared to calls to
the local-planner between two conﬁguration, where expensive
collision checks are performed.

Using Path Matching to Speed Up the Construction of H-
Graphs. We now show how the alignment algorithm is used
to reduce the number of calls to the local-planner during the
construction of H. Intuitively, matched subsegments tend to
come from close-by regions of the conﬁguration space (this
is reﬂected in the ∆ cost function). We observe that gaps
between matched regions point to possible alternative routes.
Therefore, we use the path matching algorithm to bound the
number of tested hybridization-edges by O(n) as follows. In
gap regions, we try to connect the “deleted” conﬁgurations
in path p to the two boundary conﬁgurations of the gap in

3For simplicity, in Algorithm 2 below we ignore the GAPinit price, the
price for initiating a new gap. This term is incorporated by a minor technical
modiﬁcation.

4

the matched path q, using the local-planner. In addition, we
also try to connect matching conﬁgurations, in order to obtain
local improvements for the matched region. Since the size of
the alignment is clearly O(n) (where n is the number of nodes
in the longest input path), we try to connect at most O(n) pairs
of conﬁgurations for each pair of input paths, in contrast to
O(n2) conﬁgurations in All-Pairs H-Graphs.

As in the previous section, a heuristic speed-up in perfor-
mance can be achieved by connecting only close-by conﬁgura-
tion in the neighborhood of the match. The combined approach
beneﬁts from both the asymptotic speed-up of O(n) achieved
using path matching, and from the heuristic speed-up achieved
by bounding the neighborhood size. We call this version Edit-
Distance Neighborhood H-Graphs.

V. EXPERIMENTS

In this section, we benchmark the effectiveness of hybridiz-
ing multiple input paths from short runs of sampling-based
algorithms, in a set of 2D, 3D, 6D and 12D conﬁguration
spaces. The advantage of using H-Graphs becomes apparent
in the 6D and 12D spaces, where exhaustive sampling is not
feasible.

We implemented the H-Graph algorithm and the path
matching algorithm within the OOPSMP open-source package
for motion planning [28], and used the package’s internal
implementation of PRM, RRT and subdivision local-planner.
The described algorithms can be readily subjected to paral-
lelization. However, for the performance analysis, we have run
all tests on a single processor of a dual-core 2.67Ghz AMD
Athlon machine. Our example scenes are mostly borrowed
from Geraerts et al. [25].

test
test2

A. 2D Maze: Trading Off Path Length and Path Clearance

The maze scene is an illustrative toy-example for the
ﬂexibility with which H-Graphs accommodate diverse types of
quality measures in a uniform manner. The scene comprises a
small square robot that is translating in a 2D maze (Figure 2)
through a corridor ﬂanked by branching paths that all lead to
dead-ends. In Figure 2 we see ﬁve paths from different PRM
runs, hybridized using various quality measures. In solutions
generated by PRM, the clearance from the maze walls ﬂuctu-
ated considerably (second column of Figure 2). We used the
Integrated k-Inverse Clearance (the path length weighted by
the exponentiated inverse clearance Cl−k of conﬁgurations ;
see Appendix for further details). Setting k to 3 gives a fairly
high penalty for regions of low clearance, whereas for k = 1
4
path-length also plays an important factor. Indeed, for k = 3
we get a high-clearance path. We compare to the path-length
measure, where the output path closely resembles the optimal
path. We also experimented with the average-clearance and the
maximal bottleneck clearance (see Appendix for deﬁnition of
both quality measures; results not shown). In all cases, the
objective quality measure was improved signiﬁcantly, using a
very small number of input paths, demonstrating the ﬂexibility
of the path hybridization scheme.

5

Improvement of various quality measures with H-Graphs in the 2D-Maze scene taken from Geraerts et al. [25]. Here we integrated ﬁve random
Fig. 2.
runs of PRM. Although each input path is already the highest-quality path within its roadmap, the output path shows signiﬁcant improvement in path quality.
For instance, in the top rows we try to improve the path length weighted by clearance with different weights (See Appendix for more information about the
integrated k-inverse clearance measure). Note that when the clearance is given a high weight (top row), our output hybrid-path is far from the obsacles (right
column) although all the input paths from which it was made graze the obstacles (left column). As expected, when the clearance is given a lower weight
(middle row), the integrated k-inverse clearance measure behaves similarly to the path-length measure (bottom row), but the path clearance is higher (right
column), illustrating the tradeoff between the two. Input PRM paths (left column) were generated using the OOPSMP motion-planning package [28].

Performance tradeoff with Edit-Distance H-Graphs As de-
scribed in the previous section, the edit-distance path matching
algorithm bounds the number of calls to the local-planner,
but the quality of the path might be compromised because
less hybridization-edges are created. For the 2D-maze envi-
ronment, we compared the post-processing time and the clear-
ance quality for hybridizing ﬁve paths of Neighborhood H-
Graphs and Neighborhood Edit-Distance H-Graphs using the
Integrated k-Inverse Clearance measure (path length weighted
by clearance) with k = 3. Importantly, the running time of the
edit-distance variant dropped by 75% (Figure 3), while the
quality of output paths was similar between the two variants,
although slightly lower for the Edit-Distance variant. It is
interesting to note that similar results were obtained for RRT
inputs (results not shown), demonstrating the modular nature
of the H-Graph algorithm, and its independence from the
source of input.

B. Elongated Rectangle in a 2D Grid: Rotation and Transla-
tion

In the grid scene, inspired by a scene in Nieuwenhuisen
et al. [22], we move an elongated rectangle with rotation
and translation, from the top of the workspace to the bottom
through a grid of rectangles (Figure 1). In each row of
obstacles, the elongated rectangle is forced to squeeze through
one of four narrow passages. In order to make it harder for the
robot to cross two consecutive passages, we distort the grid

slightly such that passages at every second row are shifted
with respect to odd rows. Standard sampling-based algorithms
tend to move the robot in a lengthy zigzagging motion.

We generated three input paths with PRM for the grid scene,
and hybridized them using the Neighborhood H-Graph variant,
as illustrated in Figure 1. For measuring path length, we give
a relatively large weight to the translational component of the
motion4. In the output path of the H-Graph, the average path
length was 1.08 ± 0.12 units. In comparison, the input paths
generated with PRM have been well over three times longer
(3.85 ± 0.75 units on average) and the the hybridized output
path shown in Figure 1 is 0.85 units long.

C. Comparison of H-Graphs to Long Runs of Various Motion-
Planners

We showed how H-Graphs can improve the output of a
few short runs of PRM. But if we allow inﬁnite time for each
PRM run, then due to its probabilistic completeness, we would
eventually cover the space and ﬁnd the approximate shortest
path in the roadmap. We now compare the performance of
H-Graphs based on several short runs of PRM, to a single
longer run of PRM. We show that H-Graphs are particularly

4We deﬁne the translational weight to 1 and the rotational weight of
0.00005 in the OOPSMP software . Note the the units for rotation and
translation are incomparable, and in practice, rotation weights in the order
of 10−3 − 10−4 are considered extremely high.

The Input PathsOverlaid Input PathsOutput PathIntegrated k-inverse clearance [k=3]Integrated k-inverse clearance [k=0.25]Path LengthQuality Measurek6

Fig. 3. Performance comparison of the Neighborhood Edit-Distance vs. the
Neighborhood Edit-Distance variants for hybridizing ﬁve input PRM paths,
in the 2D maze scene. The Integrated k-Inverse Clearance is computed with
k = 3 (weighting the path length by the clearance of conﬁgurations - a lower
value means better quality; see Appendix for details on quality measures).

effective for high-dimensional conﬁguration spaces, in which
exhaustive runs of PRM and RRT are not feasible.

PRM without cycles: In the grid environment described
above, which has three degrees of freedom, we hybridize three
PRM input paths. We allocate 1 second for preprocessing each
PRM, and together with 0.4 seconds for constructing the H-
Graph on average, the total running time ttotal is 3.4 seconds.
In comparison, we let PRM run for ttotal = 3.4 seconds.
In the long PRM run, the average path length is still very
long compared to exhaustively long runs that ﬁnd near-optimal
paths (Figure 4). Strikingly, even if we more than double the
running time of PRM to 8 seconds, the shortest path in the
roadmap is still much longer than in H-Graphs (2.67 ± 0.37).
Short-cutting Heuristics: It is worth noting that our method
differs signiﬁcantly from the common short-cutting post-
processing heuristics in which the local planner is applied in-
ternally within the path (described in, e.g., Geraerts et al. [25]).
While this heuristics may be useful for getting rid of certain
loops and “bumps” in a motion path, it is generally unsuitable
for transforming between different homotopy classes (except
for simple instances of motion planning problems devoid of
narrow passages). Our results conﬁrm this, as PRM paths
in the grid scene that were post-processed with the standard
short-cutting heuristics are over twice longer than hybridized
motion paths (Figure 4).

PRM with cycles: A common practice in PRM is to refrain
from adding cycles to the roadmap, since they promote a
quadratic increase in the number of edges, impairing perfor-
mance [22]. However, the poor quality of paths in long PRM
runs described above, compared to H-Graphs, can be attributed
to the lack of cycles. Indeed, in the same example of the
elongated rectangle that is translating and rotating through the
grid, long runs of PRM with cycles result in slightly shorter
paths compared to H-Graphs (Figure 4). We also implemented
and compared our method to the useful-cycles extension of
PRM by Nieuwenhuisen et al. [22], where a cycle is closed
if the connecting edge provides a signiﬁcant short-cut, by a
factor γ (we used γ = 3). In this case, for the same running
time we also get a slightly better path length (Figure 4). While
in this very simple example with three degrees of freedom, we
might be better-off running PRM with cycles for a long time
instead of using H-Graphs, we now demonstrate the advantage

Fig. 4.
Comparison of output path lengths for the grid scene (three
degrees of freedom) between different motion planners and the Hybridization-
Graphs approach. Identical running times (3.4 seconds) were allocated for
each motion planner. The dashed line indicates the approximate optimal path
length (estimated by extremely long runs of PRM with cycles).

of using H-graphs for problems of higher dimensions.

D. H-Graphs are Effective
dimensional conﬁguration spaces

in 6-dimensional and 12-

The Single-Wrench scene [25] requires a ﬁnely synchro-
nized rotational and translational motion of a free-ﬂying
wrench moving through 13 axis-aligned beams (see the left
hand side of Figure 5). The Double-Wrench scene extends
this problem to two wrenches moving simultaneously. In
this six and twelve dimensional problems, the advantage of
using H-Graphs becomes evident. The inverse clearance of the
wrenches from the beams was optimized by hybridizing three
paths generated by PRM without cycles (using the Neighbor-
hood H-Graphs variant and the Integrated k-Inverse Clearance
measure with k = 3, as deﬁned in the Appendix), where each
run was allocated a total of 35 seconds for the Single-Wrench
and 900 seconds for the Double-Wrench scene..

For both the Single-Wrench and Double-Wrench scenes,
the inverse-clearance measure was improved dramatically with
respect to PRM without cycles (Figure 5). More importantly,
PRM with cycles has become prohibitively slow in 30%-40%
of the cases, failing to ﬁnd any solution path in the allocated
time frame (Figure 5). In contrast, our H-Graphs approach
resulted in high-clearance motion paths in all runs. And while
for a single wrench, PRM with cycles outputs paths with
marginally better quality (when it ﬁnds a solution path to begin
with), in the Double-Wrench scene our hybridization scheme
dramatically outperforms PRM with or without cycles, with
respect to both path quality and the percent of successful runs
(Figure 5). Our typical output paths allowed a good safety
distance of 10%-20% of the wrench width at any point through
the motion, compared to zero clearance for PRM, the latter
outputting non-realistic motion paths for practical purposes.

01234H-GraphsEdit Distance H-GraphsRunning Time [sec]Running Time050100H-GraphsEdit Distance H-GraphsPath Inverse-Qualityk-Inverse Clearance[arbitrary units]012345Path Length[arbitrary units]7

Fig. 5. The Single and Double-Wrench Scenes (6 and 12 degrees of freedom ; adapted from Geraerts et al. [25]). Results for the Single-Wrench scene are
averaged over 20 runs. We weighted the path length by clearance using the k-Inverse Clearance measure with k = 3 (a lower value means better quality; see
Appendix for details on quality measures). PRM with cycles failed to ﬁnd a valid solution for 30%-40% of the cases in the given time. For the Double-Wrench
scene the median was taken instead of average in order to avoid the effect of outliers (the error-bars mark the 0.15 and 0.85 percentile quality in each case).
Note that the results for this scene are shown on a logarithmic scale.

E. Further Applications of H-Graphs

in Enosh et al. [29],

In this study we introduced and thoroughly benchmarked a
path hybridization scheme in various 2D and 3D workspaces
with up to 12 degrees of freedom. In a recent study [29]
we describe a biological example involving the coordinated
motion of a protein with 104 backbone degrees of free-
dom, where we applied a preliminary version of the path-
hybridization algorithm to multiple runs of RRT. We note
that
the emphasis was put on the
biological problem at hand, and not on the computational
methodology. In that work, we were able to obtain a low
energy motion path between the initial and goal states. This
example is particularly encouraging as it shows the applica-
bility of H-Graphs to complex problems with many degrees
of freedom, where it is very hard to optimize the quality of
motion paths. In a recent student workshop in motion plan-
ning, students used path hybridization to signiﬁcantly improve
motion paths of a non-holonomic moving body, originally
generated with C-PRM [31], extending H-Graphs to motion
planning under kino-dynamic constraints. See movie and more
details in http://acg.cs.tau.ac.il/courses/workshop/spring-2009/
ﬁnal-projects/non-holonomic-motion-planner-project.

VI. CONCLUSIONS

We have reported here on a simple algorithm for hybridizing
a set of input paths into an improved output solution. We treat
different quality measures in a uniform manner, and allow
modular usage of any standard motion-planning algorithm. We
show experimental results on 2D, 3D, 6D and 12D conﬁgu-
ration spaces, indicating that this new method is particularly
useful for such high-dimensional problems, and offers uniform
treatment for various optimality criteria and motion-planning
algorithms.

APPENDIX A
FORMULATION OF PATH QUALITY MEASURES

The quality of a motion path can be formulated by human
intuition about what a good or convenient path is. It is natural
to choose a short path that keeps a certain distance from the

obstacles. We may also bound the curvature of the path, or add
dynamic time-derivative constraints regarding the velocity of
the moving object. In molecular biology, we often require a
low-energy path. In this paper we mainly describe experiments
that improve the length or clearance of motion paths, and
combinations thereof. However, we note that our algorithm
is readily applicable to other measures of path quality as well.
1) Short paths: In a shortest path we minimize the length
L(π) of the path π. For translating rigid bodies, measuring
distance is quite straightforward, but the addition of rotation
complicates matters. Choosing a proper distance metric using
either conﬁguration-space parameters or workspace geometry
is discussed for example in [32], [33]. In molecular biology,
distances are often deﬁned over the workspace, using the root
mean square deviation (RMSD) of atom centers between con-
ﬁgurations. Following a standard practice, we use the weighted
Euclidean L2 norm over the conﬁguration-space parameters.
For a translating object, this is simply the workspace distance
between a ﬁxed reference point of the object in its different
locations. For bodies that move with rotation, we consider the
distance between quaternion parameters, measured using a bi-
invariant distance metric in the SO(3) topology [34] (see [33],
[35] for further notes on distance metrics in SO(3)).

2) Path clearance: In order to account for safety distance
from workspace obstacles, we may maximize the clearance
at the narrowest passage point along the path, so-called the
bottleneck-clearance BCl(π). In a graph, the path with the
maximal bottleneck edge is retrieved by a minor adaptation
of Dijkstra’s algorithm (or faster alternatives such as [14].
If we are interested in an estimate of the behavior over the
entire path, we can maximize the average clearance ACl(π)
along the entire path. Another option is to locally maximize
the clearance by walking along the medial-axis of the free
space [19].

3) Tradeoff between length and clearance: High-clearance
is unfortunately contradictory to short paths, since the shortest
path often grazes the obstacles [4]. Therefore, we may relax
the requirement for maximal clearance, and instead seek the
shortest path that obeys a certain safety distance C from the
obstacles [36]. Another appealing option is to use the Weighted

100%71%100%0%25%50%75%100%03006009001200% Succesful Runsk-Inverse Clearance[ arbitrary units]k-Inverse Clearance% Succesful Runs100%60%100%0%25%50%75%100%1.E+001.E+051.E+101.E+15% Succesful Runsk-Inverse Clearance[arbitrary units]k-Inverse ClearanceSuccesful Runs %Single-Wrench Scene (6 DoFs)Double-Wrench Scene (12 DoFs)Wrench Workspace8

[18] J. Hershberger and S. Suri, “An optimal algorithm for euclidean shortest

paths in the plane,” SIAM J. Comput, vol. 28, pp. 2215–2256, 1997.

[19] C. O’Dunlaing and C. K. Yap, “A retraction method for planning the

motion of a disc,” Journal of Algorithms, vol. 6, pp. 104–111, 1982.

[20] C. H. Papadimitriou, “An algorithm for shortest-path motion in three
dimensions,” Inf. Process. Lett., vol. 20, no. 5, pp. 259–263, 1985.
[21] S. A. Wilmarth, N. M. Amato, and P. F. Stiller, “Motion planning for a
rigid body using random networks on the medial axis of the free space,”
in Symposium on Computational Geometry, 1999, pp. 173–180.
[22] D. Nieuwenhuisen and M. H. Overmars, “Useful cycles in probabilistic

roadmap graphs,” in ICRA 04’.

IEEE, 2004, pp. 446–452.

[23] R. Geraerts and M.-H. Overmars, “Creating high-quality roadmaps for
motion planning in virtual environments,” in IEEE/RSJ International
Conference on Intelligent Robots and Systems, 2006, pp. 4355–4361.

[24] R. Geraerts and M. H. Overmars, “Clearance based path optimization
IEEE, 2004, pp. 2386–2392 Vol.3.
[25] R. Geraerts and M. Overmars, “Creating high-quality paths for motion

for motion planning,” in ICRA 04’.

planning,” IJRR, vol. 26, no. 8, pp. 845–863, 2007.

[26] R. Geraerts and M. H. Overmars, “The corridor map method: a general
framework for real-time high-quality path planning:Research Articles,”
Computer Animation and Virtual Worlds, vol. 18, no. 2, 2007.

[27] J. H. Holland, Adaptation in natural and artiﬁcial systems: An intro-
ductory analysis with applications to biology, control, and artiﬁcial
intelligence. University of Michigan Press, 1975.

[28] E. Plaku, K. E. Bekris, and L. E. Kavraki, “OOPS for motion planning:
An online open-source programming system,” in ICRA 07’, 2007, pp.
3711–3716.

[29] A. Enosh, B. Raveh, O. Furman-Schueler, D. Halperin, and N. Ben-
Tal, “Generation, comparison and merging of pathways between protein
conformations: Gating in k-channels,” Biophysical Journal, vol. 95,
no. 8, pp. 3850–3860, 2008.

[30] V. I. Levenshtein, “Binary codes capable of correcting deletions, inser-
tions, and reversals,” Soviet Physics Doklady, vol. 10, no. 8, pp. 707–710,
1966.

[31] G. Song and N. M. Amato, “Randomized motion planning for car-like
robots with c-prm,” College Station, TX, USA, Tech. Rep., 2001.
[32] N. M. Amato, O. B. Bayazit, L. K. Dale, C. Jones, and D. Vallejo,
“Choosing good distance metrics and local planners for probabilistic
roadmap methods,” IEEE Trans. Robot. Automat., vol. 16, pp. 442–447,
2000.

[33] J. Kuffner, “Effective sampling and distance metrics for 3D rigid body

path planning,” in ICRA 04’.

IEEE, 2004.

[34] F. Park and B. Ravani, “Smooth invariant interpolation of rotations,”

ACM Trans. on Graphics, vol. 16, no. 3, pp. 277–295, 1997.

[35] S. M. L. Anna Yershova and J. C. Mitchell, “Generating uniform
incremental grids on so(3) using the hopf ﬁbration,” in WAFR 08’, 2008,
pp. 385–399.

[36] R. Wein, J. van den Berg, and D. Halperin, “The visibility-voronoi
complex and its applications,” Comp. Geo.: Theory and App., vol. 36,
no. 1, pp. 66–78, 2007.

[37] R. Wein, J. P. van den Berg, and D. Halperin, “Planning high-quality
paths and corridors amidst obstacles,” I. J. Robotic Res., vol. 27, no.
11-12, pp. 1213–1231, 2008.

Length or Integrated k-Inverse Clearance measure with param-
eter k, which also implicitly bounds the path curvature [37].
Small clearance is assigned a high penalty by exponentiating
its inverse by some coefﬁcient k. The exponentiated inverse
clearance Cl−k is integrated (or summed for discrete paths),
and shorter paths with high average clearance are favored.
The coefﬁcient k sets the tradeoff between path length and
path clearance. Clearly, if k = 0 we get the length of the
path. Interestingly, if k → ∞, the optimal path is the one with
maximal bottleneck-clearance, since Cl−k is then dominated
by conﬁgurations with small clearance.

ACKNOWLEDGMENTS

The authors would like to thank Roland Geraerts and Mark
Overmars for providing us with motion planning scenes ;
Lydia Kavraki, Mark Moll and Erion Plaku to the open-
source package OOPSMP for motion planning [28]. This work
has been supported in part by the Israel Science Foundation
(grant no. 236/06), by the German-Israeli Foundation (grant
no. 969/07), and the Hermann Minkowski–Minerva Center for
Geometry at Tel Aviv University.

REFERENCES

[1] H. Choset, K. M. Lynch, S. Hutchinson, G. A. Kantor, W. Burgard, L. E.
Kavraki, and S. Thrun, Principles of Robot Motion: Theory, Algorithms,
and Implementations. MIT Press, 2005.

[2] J. C. Latombe, Robot Motion Planning. Kluwer Academic Publishers,

1991.

[3] J.-C. Latombe, “Motion planning: A journey of robots, molecules, digital
actors, and other artifacts,” International Journal of Robotics Research,
vol. 18, pp. 1119–1128, 1999.

[4] S. M. LaValle, Planning Algorithms. Cambridge University Press, 2006,

Available at http://planning.cs.uiuc.edu/.

[5] D. Hsu, J. Latombe, and R. Motwani, “Path planning in expansive
conﬁguration spaces,” Int. J. Comp. Geo. & App., vol. 4, pp. 495–512,
1999.

[6] L. E. Kavraki, P. Svestka, J. C. Latombe, and M. H. Overmars, “Prob-
abilistic roadmaps for path planning in high-dimensional conﬁguration
spaces,” IEEE Trans. Robot. Automat., vol. 12, no. 4, pp. 566–580, 1996.
[7] S. M. LaValle and J. J. Kuffner, “Rapidly-exploring random trees:
Progress and prospects,” in Algorithmic and Computational Robotics:
New Directions, B. R. Donald, K. M. Lynch, and D. Rus, Eds. Welles-
ley, MA: A K Peters, 2001, pp. 293–308.

[8] G. Song, S. Thomas, and N. Amato, “A general framework for PRM

motion planning,” in ICRA 03’, vol. 3.

IEEE, 2003, pp. 4445–4450.

[9] J. Canny and J. Reif, “New lower bound techniques for robot motion

planning problems,” in FOCS 87’.

IEEE, 1987, pp. 49–60.

[10] T. Asano, D. Kirkpatrick, and C. Yap, “d1-Optimal motion of a rod,”
12th ACM Symposium on Computational Geometry, pp. 252–263, 1996.
[11] J. Reif and H. Wang, “The complexity of the two dimensional curvature-
constrained shortest-path problem,” in WAFR 98’, 1998, pp. 49–57.
[12] J. S. B. Mitchell, Handbook of discrete and computational geometry.
Boca Raton, FL, USA: CRC Press, Inc., 2004, ch. 27, Shortest paths
and networks, pp. 607–641.

[13] E. W. Dijkstra, “A note on two problems in connexion with graphs,”

Numerische Mathematik, vol. 1, no. 1, pp. 269–271, 1959.

[14] V. Kaibel and M. Peinhardt, “On the bottleneck shortest path problem,”
Otto-von-Guericke-Universit¨at Magdeburg, Tech. Rep., 2006. [Online].
Available: http://www.math.uni-magdeburg.de/∼kaibel/Downloads/BSP.
pdf

[15] J. Kim, R. A. Pearce, and N. M. Amato, “Extracting optimal paths from
IEEE, 2003, pp. 2424–

roadmaps for motion planning,” in ICRA 03’.
2429.

[16] N. J. Nilsson, “A mobile automaton: An application of artiﬁcial in-
telligence techniques,” in 1st International Conference on Artiﬁcial
Intelligence, 1969, pp. 509–520.

[17] D. T. Lee and A. K. Lin, “Computational complexity of art gallery
problems,” IEEE Trans. Inf. Theor., vol. 32, no. 2, pp. 276–282, 1986."
Fundamentals of Mathematical Theory of Emotional Robots,"  In this book we introduce a mathematically formalized concept of emotion,
robot's education and other psychological parameters of intelligent robots. We
also introduce unitless coefficients characterizing an emotional memory of a
robot. Besides, the effect of a robot's memory upon its emotional behavior is
studied, and theorems defining fellowship and conflicts in groups of robots are
proved. Also unitless parameters describing emotional states of those groups
are introduced, and a rule of making alternative (binary) decisions based on
emotional selection is given. We introduce a concept of equivalent educational
process for robots and a concept of efficiency coefficient of an educational
process, and suggest an algorithm of emotional contacts within a group of
robots. And generally, we present and describe a model of a virtual reality
with emotional robots. The book is meant for mathematical modeling specialists
and emotional robot software developers.
",http://arxiv.org/pdf/1011.1841v1,1,"Department of Education and Science,  

Russian Federation 

Perm State University 

FUNDAMENTALS OF 
MATHEMATICAL THEORY OF 
EMOTIONAL ROBOTS  

MONOGRAPH 

Oleg G. Pensky, Kirill V. Chernikov 

2010  Perm, RUSSIA  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Abstract 

In  this  book  we  introduce  a  mathematically  formalized  concept  of  emotion, 
robot’s education and other psychological parameters of intelligent robots. We also 
introduce  unitless  coefficients  characterizing  an  emotional  memory  of  a  robot. 
Besides, the effect of a robot’s memory upon its emotional behavior is studied, and 
theorems  defining  fellowship  and  conflicts  in  groups  of  robots  are  proved.  Also 
unitless parameters describing emotional states of those groups are introduced, and a 
rule of making alternative (binary) decisions based on emotional selection is given. 
We introduce a concept of equivalent educational process for robots and a concept of 
efficiency  coefficient  of  an  educational  process,  and  suggest  an  algorithm  of 
emotional contacts within a group of robots. And generally, we present and describe 
a model of a virtual reality with emotional robots. 

The book  is  meant  for  mathematical  modeling specialists and emotional  robot 

software developers. 

Translated from Russian by Julia Yu. Plotnikova 

© Pensky O.G., Chernikov K.V. 2010 

2

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
CONTENTS  

Introduction                                                                                                          5 
1. 
Robot’s emotion: definition                                                                       7 
2. 
Education of a robot                                                                                 12 
3. 
Parameters of a group of emotional robots                                              22 
4. 
Friendship between robots: fellowship (concordance)                            24 
5. 
Equivalent educational processes                                                            26 
5.1.  Mathematical model of equivalent education processes                         27 
5.2.  Alternative to an objective function under coincidence  

                 of time steps of real and equivalent education processes                         29 

5.3.  Generalization in case of noncoincidence of time steps of real 

                  and equivalent education processes                                                         33 
       6.        Method of approximate definition of memory coefficient function        34 
7.  Mathematical model of forming of tantamount robot sub-groups           35 
8. 
Algorithm for forming tantamount sub-groups of robot                          38 
9. 
Applying vector algebra rules to investigation of robot  

                   sub-group emotional state                                                                       39 
10.  Mathematical assessment of goal achievement extent                             43 
10.1.   Rule of solving for the extent  of goal achievement                                43 
10.2.   Algorithm for forming tantamount sub-groups of robots  
           according to their goal achievement extent                                             47 
11.  Mathematical model of robot’s emotional abilities                                  48 
12.  Work and willpower of emotional robots                                                 51 
13.  Robot’s temperament model                                                                    54 
14. 

Investigation of psychological process dynamics in a group 

                  of robots                                                                                                   55 
15.  Rules and forecast of emotional  selection of robots                               58 
16. 

 Generalization of robot’s emotional behavior rules in  

                  case the number of players interacting with the robot is  
                   arbitrary (not specified)                                                                           64 
16.1. First rule of alternate selection                                                                  64 
16.2. Second rule of alternate selection                                                              65 
16.3. Orthogonality of education vectors and equivalence  
          of alternate selection rules                                                                        65 
        17.    Emotional selection and conflicts between robots                                    66 
18. 
 Diagnostics of emotional robots’ “mental diseases”                               67 
19.  Models of robot’s ambivalent emotions                                                   69 
20. 
 Absolute memory of robots                                                                     72 
21.  Algorithm of emotional contacts in a group of robots                             77 
22.  On information aspects of E-creatures                                                     79 
23.  Software realization of simple emotional robot’s behavior                     82 
23.1 Input parameters of software                                                                      82 
23.2. Algorithm for modeling robot’s mimic emotional reaction                      82 

3

 
 
 
23.3. SoundBot software architecture                                                                84 
23.4. Main features of SoundBot                                                                        86 
23.5. SoundBot operation principles                                                                  86 
23.6. SoundBot visual interface                                                                          88 
Conclusion                                                                                                          91 
References                                                                                                          92 

4

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
INTRODUCTION 

Emotions  represent  an  essential  part  of  human  and  animal  psychological 

activity. 

Attempts  to  formalize  mathematically  the  psychological  behavior  of  higher 
living beings were performed in a book «Гипотезы и алгоритмы математической 
теории  исчисления  эмоций»  (“Hypotheses  and  Algorithms  of  Emotion  Calculus 
Mathematical  Theory”)  edited  by  Professor  Oleg  G.  Pensky  and  published  by  the 
Perm State University (Russia) in 2009. Although the authors wanted this treatise to 
be  considered  as  an  example  of  some  scientific  quest,  it  encountered  strong 
misunderstanding of psychologists in the city of Perm. 

That book suggested mathematical models introducing and applying such terms 
and  concepts  as  ‘emotional  education/upbringing’,  ‘reeducation’,  ‘temperament’, 
‘conflict’,  etc.;  also  the  authors  reviewed  approaches  to  modeling  of  emotional 
behavior of subjects, estimation of a psychological state in groups; there was as well 
suggested  a  new  approach  to  the  description  of  some  new  economic  phenomena 
based on psychological theories. 

The  authors  of  the  present  paper  completely  agree  that  computer  modeling  of 

emotions is hindered by ambiguity of living being emotional behavior. 

Considering  misunderstanding  of  psychologists,  Professor  Pensky  decided  to 
adapt  the  results  of  his  studies  performed  in  2009  to  mathematical  modeling  of 
emotional robots and give a further development to those ideas. 

The  treatise  of  professor  Oleg  G.  Pensky  titled  “Mathematical  Models  of 
Emotional Robots” was issued by the Perm State University printing office in 2010.  
In  the  present  book,  same  as  in  that  one  issued  in  2010,  the  authors  made  an 
attempt to create and  mathematically  describe a  virtual reality of emotional robots, 
which  is  based  on  such  key  terms  as  emotions  and  education,  and  includes 
fellowship/concordance  and  conflicts  between  its  inhabitants–robots  which  feature 
various  abilities,  temperaments,  memory,  will-power,  emotional  work  under 
achieving goals, ‘diseases’, education process prospects and corresponding concepts 
and terms. 

Currently the American scientists [1] work on creation of an electronic copy of 
a human being which would be called E-creature. By happy chance the present book 
touches  upon  those  very  topics  which  are  currently  studied  by  our  American 
colleagues.  We  consider  robots  with  a  non-absolute  memory,  and  this  kind  of 
memory is a human being’s feature. 

Of  course,  the  mathematical  theory  of  emotional  robots  which  we  call  your 
attention to in this book is far from perfection. But its authors never meant that this 
theory claims to be global, and once again ask critics above all to consider this book 
as an example of a scientific quest. 

Acknowledgements 
The  authors  are  eternally  indebted  to  Alexander  Bolonkin,  PhD,  Professor  of 
NJIT  for  having  the  book  discussed,  for  the  description  of  E-creature  information 

5

 
 
 
modeling  problems,  for  his  guidance  in  advancing  and  presenting  our  theory  of 
emotional robots to the scientific community. 

The authors highly appreciate useful notes concerning the content of this book 

made by Tatiana S. Belozerova, PhD (Russia). 

6

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
1. ROBOT’s EMOTION:  DEFINITION 

A  theory  of  human  psychology  defines  emotions  as  an  organism  response  to 
some stimulus [2]. Concerning robots, let us designate this stimulus as ‘subject’, and 
define it as follows:  

Let t be a time. 

Definition 1.1. The function S(t) is referred as a ‘subject’ if it has the following 

properties: 

1. Function domain of S(t): 

*,0 t


t 

2. S(t)>0 for any 
3. S(t) is the one-to-one function; 
4. S(t) is the bounded function. 

; 



,0



,

*

t

t



*

t



0

, 

*t

; 

The  paper  [3]  contains  a  theorem  proving  that  it  is  possible  for  computer 
software to model human and animal emotions. But psychological features of living 
beings’  emotions  are  so  intricate  and  ambiguous  that  we  decided  to  introduce  a 
special  mathematical  definition  of  a  robot’s  emotion.  In  this  definition  we  are 
abstracting  from  real  human emotions and, at the same  time, accumulating  general 
features of human and animal emotions; we are also abstracting from the content of 
emotions. 

Definition 1.2. The function f(t), satisfying the equation 

 (with 
a(s(t),t) the arbitrary function) is the function of robot’s inner emotional experience. 

tSt
)()),

tSa
((

t
)(



f

Let us state that the subject S(t) initiates robot’s inner emotional experience.  

Definition  1.3.  The  robot’s  inner  emotional  experience  function  M(t)  is  called 

an ‘emotion’ if it satisfies the following conditions: 

1. Function domain of M(t): 

t



,0



0

t



,

0

t



0

; 

2. 

0
t  (note that this condition  is equivalent to emotion termination  in case 

*

t

the subject effect is either over or not over yet); 
3. M(t) is the single-valued function; 
4. 

; 

0
M
)0(
( 0 
)

tM

5. 
6. M(t) is the constant-sign function; 

; 

0

7. There is the derivative 

)(
tMd

dt

within the function domain; 

7

 
 
 
 
 
 
 
 
 
8. There is the only point z within the function domain, such that 
tMd
)(

and 



0

; 

 z

dt
/
t
tMd
)(

9. 

10. 

dt
tMd
)(

dt



0

 with 

t  ; 
z



0

 with 

t  . 
z

z



,0

0

z



t

Let us assume there is such J>0 that for any emotions of a robot the condition 

tM )(

J

 is valid. 

Now  we  can  easily  see  that  the  function 

)(
tM



P

sin

  for 

t 

0,0 t


, 






0

t

t





P 

const

, is an emotion.  

Definition 1.4. The  function 

)(tM


is called an ambivalent emotion  if  it can be 

presented as the vector which elements are emotions initiated simultaneously by one 
and the same subject. 

We will not focus on the content of emotions, and, according to [4], below we 

plan to take into account only the following things important to us: 

Emotions have a sign (plus or minus). 
An object has a finite number of emotions. 

1. 
2. 
Based on (2) we conclude that the robot’s emotional state can be described by 

the emotion vector 


)(tM

 with the finite number of elements (cardinality) equal to n: 



tMtM

(

)(

1

),...,

tM
n

)(

. 

Hereinafter,  in  case  we  speak  about  a  single-type  emotion,  we  will  omit  the 

corresponding index mark, vector mark and will denote this by M(t). 

Assume the emotion-free state of a robot as a zero emotion level. 
It is obvious, that stimuli can be totally external, partially external (or ‘partially 

memorized’) and internal. All of them may become a subject: 

-  totally  external  stimuli  (which  are  not  contained  in  the  robot’s  memory  (see 

Fig. 1.1)), may serve as a subject; 

-‘partially  memorized’  stimuli  (when  some  part  of  information  about  them  is 
entered  into  the  robot’s  memory,  and  some  part  of  it  comes  from  the  outside  as 
external experience (Fig. 2.2)) may also serve as a subject; 

-  internal  stimuli  (when  full  information  about  these  stimuli  is  kept  in  the 
robot’s  memory  (Fig.  1.3))  may  serve  as  a  subject,  as  well.  This  is  the  case  when, 
e.g., some recollection (past event memories) of a robot may generate emotions. 

8

 
 
 
                                           
 
 
 
 
Robot’s Memory                              Subject 

Fig. 1.1. Totally external stimuli as a subject 

Robot’s Memory                              Subject 

Fig. 1.2. Partially external stimuli as a subject 

9

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Robot’s Memory                              Subject 

Fig. 1.3. Internal stimuli as a subject 

Fig.  1.2  and  Fig.  1.3  partially  correspond  with  the  psychological  theory  of  S. 
Schechter  [4].  According  to  Schechter,  the  occurred  emotional  state  of  a  person  is 
effected  by  his/her  previous  experience  and  his/her  assessment  of  the  current 
situation, as well as by perceived stimuli and stimulus-initiated physical alterations. 

Let  us  note,  that  when  describing  a  subject  and  its  belonging  to  the  robot’s 
memory  we  used  the  term  ‘information’  which  is  measured  in  bits  [5].  So,  let  us 
advance the following hypothesis: a subject can be measured in bits of information 
as well. 

It is obvious, that different subjects can initiate one and the same emotion of a 
robot, i.e. there is no one-to-one dependence between a subject and an emotion (Fig. 
1.4).  

10

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emotion                                Subjects 

Fig. 1.4. Relation between Subjects and Emotion. 

And also, one and the same subject can initiate different emotions of a robot [4] 

(Fig.1.5). 

Let  us  introduce  the  concept  of  the  unit  (or  specific)  emotion,  similarly  to 

matter density in Physics [6],  

Definition 1.5. The specific emotion a(S(t),t) of a robot is an emotion per single 

subject unit. 

Obviously, the specific emotion satisfies the following relation: 

tSa

t
)),((



t
)),

tSM
((
)(
tS

.

We can easily see that the sign of the robot’s emotion 

tSM

t
)),((

 is determined 

by the sign of the specific emotion a(S(t),t).  

11

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Emotions                                Subject 

Fig.1.5. Relation between robot’s emotions and a subject. 

Mathematical  theory  of  emotional  robots  described  in  this  book  considers  the 

cases shown in Fig. 1.4 and 1.5. 

2. EDUCATION OF A ROBOT 

Let  us  introduce  the  definition  of  emotional  upbringing  (emotional  education) 

of a robot abstracting from the psychological concept of education/ upbringing. 

Definition  2.1.  The  upbringing  or  education  of  a  robot  is  a  relatively  stable 

attitude of this robot towards a subject. 

From  Definition 1.3  it  follows that the  robot’s emotion  M(t)  is  the continuous 
,  consequently  M(t)  is  integrable  on  this  segment. 

function  on  the  segment
t,0
Considering that, we can work out the following definition. 

Definition  2.2.  The  elementary  robot‘s  education  r(t)  based  on  subjects  S(t)  is 

the following function: 

tr
)(

t

0

Sa
((


S
)()
.

),

d

                                          (2.1) 

The obvious mathematical features of the elementary education are as follows: 
1) 

if  a  specific  emotion  sign  coincides  with  a  subject  sign,  then  the 

education is positive; 

2) 

to the parameter t, so the relation 

in virtue of Definition 2.3, the function r(t) is differentiable with respect 
)(
tdr
dt

 is valid. 

tsM

),((



)

t

12

 
 
 
 
 
 
                                      
 
 
Let  us  consider  that  in  the  course  of  time  a  robot  can  forget  emotions 
experienced some time ago.  Its current education is less and less effected by those 
past (bygone) emotions. Consequently, past elementary educations initiated by those 
emotions become forgotten as well.  

Hence, the following definition becomes obvious. 

Definition  2.3  The  education  of  a  robot  R(t)  based  on  the  subjects  S(t)  is  the 

following function: 

)(
tR



r

)(
 
i

 

tRt
i

i

,                                          (2.2)  

t



where  t  is  the  current  time, 
it
relation 
beginning  of  its  initiation,   
emotions effect, 


i tR

i

t

t



0,

.  The  current  time  satisfies  the 
, where  is the current time of the current emotion effect from the 
it   is  the  total  time  of  all  the  formerly  experienced 


i



i

  1
t


 is the education obtained by a robot in the time   it . 

A  verbal  definition  of  education  is  as  follows:  it  is  a  value  determining 

motivation stability of the robot’s behavior on a certain class of subjects. 

It is obvious, that an education can be measured in bits of information similarly 
to a subject, and, consequently, emotions are to be measured in bit per second (bit/s). 

Definition  2.4.  Coefficients 

 ti   are  the  memory  coefficients  of  events 

experienced in the past, i.e.  coefficients of the robot’s memory. 

According to (2.2) we can write down a relation specifying the education in the 

beginning of the i+1st emotion effect upon the robot: 

i
R
tR
i
i


i

 
0

)0(



r

. 

)0(1

It is easy to see that the eqs. 
)0(1


R
i




tR
i

i


,

r

)0(



0

. 

hold true. 
Consequently 

  1
0 

i

 is valid. 

Definition 2.5. A time step is the effect time of one emotion. 

According  to  results  obtained  by  psychological  researches  an  emotion  cannot 
last  more  than  10  seconds.  Therefore,  let  us  assume  that  a  time  step  value  of  any 
robot emotion is less or equal to 10 sec. 

Here  and  below  psychological  characteristics  of  robots  corresponding  to  a 
current moment of the time step are bracketed after the variable, and psychological 
characteristics corresponding to the end of time steps are denoted without brackets. 
 defines a function of education altering for the current time t of 
For instance, 
iR  defines a value of education in the end of the time step i. 
the valid time step i, and 

)(tRi

13

 
 
 
                                       
 
 
 
                                   
                                  
 
 
 
It  is  easy  to  see  that  the  robot  featuring  the  past  event  memory  coefficient 
identical with 1 remembers in detail all its past emotional educations. This robot can 
be  regarded  as  autistic.  But  let  us  suppose  that  the  robot’s  memories  of  the  past 
events  are  deleted,  i.e.  the  two-sided  inequality 
  is  valid  for  a  forgetful 
robot in the end of each time step. We are now in position to state a theorem for this 
kind of robot. 

 i



1

0

Theorem 2.1. Educating the forgetful robot by means of positive emotions only 

leads to satiety. 
Proof: 
It easy to see that Relation (2.2) is equivalent to 

tR
)(



r


)(

i


rt
)(
i

 
1


i

Rt
)(
i




1

2

.                               (2.3) 

Equation  (2.3) can take the form 

tR
)(





)(
r
r
ii


1



ii

r

21
i



r

1
ii
i
i
32


...


r
...

1
i
012
ii

.                      (2.4) 

Since  all  the  emotions  are  positive,  elementary  educations  are  positive,  too; 
since all the emotions are value-limited, and time of emotion effect is also limited, 
so elementary educations are also limited. This makes us conclude that there are   
and q of a forgetful robot for which the following inequalities hold true: 

1





,

j


rq
k

,


rq


)(

,                                          (2.5) 

where

j




i
,,1


i


1

. 

k



,0

Due  to  (2.4)  и  (2.5)  we  can  obtain  the  upper  bound  of  the  function  R(t) 

variation. It will have the form 

tR
)(

q


q

j

1
i



j
0




2

q

j

1
i



j
0


                                      (2.6) 

The right side of (2.6) defines the sum  of  geometric  progression terms, which 

yields inequality 

1i


tR

2)(


q

1


1






.                                          (2.7) 

Having passed to the  limit  under 
get the upper bound of the education value: 
q
2


t

tR
)(



1

 or 

i

 in the right side of  (2.7) we 

.                                                   (2.8) 

14

 
 
 
                         
 
 
               
 
 
                             
 
                                   
 
                                                
 
                                                 
 
Inequality (2.8) makes us conclude that the robot’s education based on positive 

emotions has the upper bound, i.e. it is satiated.  

The proof is now complete. 

Psychological  researches  entirely  confirm  Theorem  2.1.  According  to  their 
results,  it  is  not  possible  to  bring  up  and  train  a  person  ad  infinitum,  as  at  some 
certain  moment  he\she  gets  satiated  [4],  and  passes  to  the  next  stage  of  his\her 
emotional activity. 

Definition 2.6. The limiting education U is the value corresponding to the end 

point of emotion effect time and satisfying the relation 

U



q


1

. 

Definition 2.7. Emotions initiating equal elementary educations are tantamount 

(equivalent). 

Definition 2.8.  A uniformly forgetful robot is a forgetful robot whose memory 
coefficients corresponding to the end point of emotion effect time are constant and 
equal to each other. 

Theorem  2.2.    The  education 

uniformly  forgetful  robot  is  defined  by  the  relation 

iR   based  on  tantamount  emotions  of  the 
i

1

1



,  where  q  is  the 

R
i



q

elementary education  value, and   i is the  order  number of the  initiating tantamount 
emotion  from a quantity of emotions on which basis this education  has been being 
performed by  the current time point. 

Its proof is evident from Theorem 2.1. 

Also let us note the following. When performing a robot’s emotion by means of 
software, it is impossible to predict the subject effect time. Therefore it is expedient 
to model the emotions after subject effect is over. 

Example: 
Let us take the emotion function in a form 


tM
)(



P

sin





0

t

*



t



t

*



t







,                                  (2.9) 



*, t

0

t

, 

t 

P 

const

with 
0t
In (2.9) we replaced conditions 1, 2, 4, 5, 8  in the definition of emotion by the 

the fixed value, at that 

,   
0
t 

*

t
2,



. 

*

t

following:  

1. Function domain M(t): 

t 



t

*, t

0

; 

15

 
 
 
 
 
 
 
 
                                      
2. 

4. 

5. 

0
t 

tM

*

2t
; 
( * 
)
( 0 
)

tM

0

0

; 

; 

8.  Function  domain  contains  an  only  point  z,  such  that 
tMd
(

)

. 



0

dt

/

t

 z

z



*,

t

0

z



t

  and 

Also  let  us  note  the  following:  according  to  (2.9),  replacements  of  several 
conditions  of belonging of the robot’s  inner emotional experience  function  M(t) to 
emotions do not require the currently considered theory to be revised. 

Obviously,  the  time  step     for  Emotion  (2.9)  satisfies 



0
t 

t

*

,  and  the 

elementary education r is computed by 

r

0
t
 
*
t

P

sin







0

t

*



t


t

*



t






dt



2

P

0

t

*

t






2

P




.                       (2.10) 

We  can  easily  see  that  during  the  education  process  Eq.  (2.10)  provides 

tantamount emotions under 

0
t


*



t



const

. 

Let us consider all the time steps to be equal to each other. 

Below  we  give  a  theorem  which  mathematically  characterizes  deletion  of  the 
past\bygone  education  memory  data  if  those  educations  are  not  maintained  by 
emotions with the course of time. In this case the index  i is defined by the relation 

i



t







,  with  t  the  current  time,    the  effect  time  of  the  first  and  only  emotion 

causing the elementary education  0r . 

Theorem 2.3. The uniformly forgetful robot forgets its first and only elementary 

education exponentially. 

Proof. According to (2.4), if there is no constant emotional effect during some 

period of time, then the robot’s education by the time t satisfies the relation 

R
i





i
i

1

i


... r
01



2

.                                             (2.11) 

As  far  as  the  robot  is  uniformly  forgetful,  so   

valid. Consequently, 

i
i 
R

0r

 holds true. 

The proof is now complete. 

16





j

const

,

with


,1

i

j



  is 

 
 
 
 
                           
 
 
 
 
 
 
                                      
 
The  next  theorem  allows  assessing  the  upper  bound  of  the  forgetful  robot’s 
current  education  in  case  when  this  robot  had  obtained  only  one  elementary 
education in the past. 

Theorem  2.4.  The  current  education  of  the  forgetful  robot  obtained  due  to  an 
,  with 

only  positive  elementary  education  satisfies  the  inequality 

i 
1

tR
)(

r
0

,

j


,1
i

. 

j



Its proof is evident from (2.11). 

Above we noted validity of  

tM

)( 

)(
tdr
dt

.                                          (2.12) 

Assuming that memory coefficients are differentiable functions and taking into 

consideration (2.12) we get the formula for the sum (i.e. resulting) emotion V(t): 

d
i
dt

dR

i
1
dt

tdr
)(
dt

.                          (2.13) 

tV
)(


i

t
)(

R
i

t
)(

t
)(


1







(2.13)  allows  us  to  assert  that  sum  emotions  of  the  robot  depend  on  past 

educations, memory coefficients and their rate of change. 

It is quite easy to see that for the robot with the absolute emotional memory  

,1

(
j


,1
i

j



) current sum emotions are not dependent on past educations. 

Let robot’s elementary educations satisfy the following inequality: 

r j  .                                         (2.14) 

q

Under  i    tending  to  infinity  and  the  inverse  numeration  of  elementary 

educations, (2.4) takes the form: 

R



i
1


1
i

 .                             (2.15) 
r
i П

1
1

j

j

Definition  2.9.  The  robot’s  education  corresponding  to  (2.15)  is  an  infinite 

education. 

Let  us  note  that  the  infinite  education  convergence  determines  education 

prospects.  

17

 
 
 
 
                                                     
 
                       
 
 
 
                                                                
 
                                                           
 
 
 
 
Theorem  2.5.  For  the  forgetful  robot,  the  infinite  education  corresponding  to 

ends of time steps converges. 

Proof. Let us show that Series (2.15) is absolutely convergent. 
As 

 ,1i

 holds true, so there is such  less than unity, that 

 ) is valid. 

 i



1

0

1i

 (with 

By virtue of Inequality (2.14),  Formula (2.15) and formula for finding a sum of 

terms of a geometric progression [7] we develop a correlation 
q



1

i

П
j
1


i

q

1


r
i





1

j

|

|



0


i



i
1




. 

So, Series (2.15) is absolutely convergent, consequently it converges. 
The proof is now complete. Quod erat demonstrandum. 



By virtue of the theorem given above, the relation 

z
lim
lim
i

the continuous education process, and this relation is equivalent to 
z

lim


lim


R
i

R
i


1

r
i









z

i

i

i

i

lim


i

r
i

lim


i


i

 is valid for the end of each time step of 

.                                      (2.16) 

(2.16) allows to enunciate the following theorem. 

Theorem  2.6.  The  uniformly 

robot’s  elementary  education 
corresponding  to  ends  of  time  steps  in  the  course  of  continuous  education  process 
tends to be constant. 

forgetful 

Proof. 

As 

i 



const



,1


,1


i

 , 

holds  true  for  the  uniformly  forgetful  robot,  by  virtue  of  (3.16)    the  elementary 
education sequence corresponding to ends of education time steps, has a limit. 

Thus the theorem is proved. 

Corollary 2.1. For the uniformly forgetful robot 


1


z

 is valid. 

lim


i

ri

The proof follows from (2.16). 

Let us assess the extent of error of the infinite education value provided when k 

terms of series are used for assessing the sum of Series (2.15). 

It is easy to see that the inverse numeration of elementary educations makes the 

error of 

18

 
 
                                          
 
                                             
 
 
 
 
 
b
k

1




ki

1

i
1

  satisfy 
Пr
i
1

j

j

b
k


1

k
q

1




series. 

 under finite summation of  k terms of 

Obviously, an education cannot be  performed continuously: after the series of 

emotional effects there comes a slack period in this education. 

Let us introduce a supplementary definition. 
Definition 2.10. A complete education cycle is a quantity of time steps equal to 
the sum of time steps under the effect of education emotions and a number of time 
steps corresponding with the slack period  (absence of elementary education effects 
upon the robot) till the next emotional education effect. 

Let  us  consider  the  education  process  of  the  uniformly  forgetful  robot  with 

tantamount emotions. 

It is easy to see that according to Theorems 2.2 and  2.3 the education 

11,kjF
for  the  first  complete  education  cycle  of  the  uniformly  forgetful  robot  based  on 
tantamount emotions with equal periods satisfies the following relation: 

F

kj
1 ,

1



k
q


1

j
1

1


1



,                                          (2.17) 

where  1j  is the quantity of time steps in the presence of education effects upon the 
robot,  1k  is the quantity of time steps in their absence. 

Obviously, the education 

jF ,
n k

n

, obtained by the robot as a result of n complete 

education cycles is determined by the equality 





 From  the  forms  of  Relations  (2.17)  –  (2.18)  it  follows  that


1



1

k









1 ,


F

F





q

1


k

k

j

j

j

,

n

n

n

n

n

n

n

j

.                        (2.18) 

,
n k
j

n

,  set  by  the 

equality





j

n

,

k

n

F

j

k

n

,
n
q

,  does  not  depend  on  q.  Since  q=const  is  valid,  then 

is  a  unitless  measure  for  assessing  the  education  obtained  by  the  robot  in  n 

,
n k
j
complete education cycles. 

n

Definition 2.11. The function 

,
n k
j

n

 is a memory function. 

It  is  evident  that  the  memory  function  shows  to  what  extent  tantamount 
educational  emotions  are  memorized  by  the  robot  in  the  course  of  the  educational 
process. 

Let  U  defines  the  value  equal  to  the  maximal  (satiated)  education.  Assuming 
that emotions are tantamount and memory coefficients are equal to one and the same 

19

 
 
 
 
 
                                        
                            
 
 
constant,  we  pass  to  the  limit  in  both  parts  of  Equality  (2.2)  under  the  quantity  of 
time steps tending to infinity. As a result we get 

)(
Utr


1(




)



q

. 

lim


i

So,  the  robot’s  education  R,  obtained  in  the  first  complete  education  cycle  is 

determined by the formula 

It easy to see that the function 

R
kG
(

j
1

k
1 1 



. 
1 j
,
)
, satisfying the relation  
1

U



kG
(

j
,
11

)



k
1 1










R
U

j

1

,                           (2.19) 

determines  deviation  of  the  education  from  its  satiety:    the  closer  is 

)
1j )  to  1,  the  closer  the  robot’s  education  is  to  its 

1 j
,
1

kG
(

(with  the  given  values 
satiety, and vice versa. 

1k and 

Definition 2.12. The function 

kG
(

11 j
,

)

 is a satiety indicator. 

It is easy to see that the satiety indicator for the fixed  1k and  1j has a maximum 

value when the condition  

1
j
1







k
1


j
1

k
1





                                         (2.20) 

holds true. 

Inserting  (2.20)  to  Relation  (2.19)  we  get  the  formula  specifying  the  maximal 

value  maxG of the satiety indicator in the end of the first complete upbringing cycle. 

G

max







Definition 2.13. The function 

B

j

n

,

k

n



k
1
j
1

k
1


k
1





j
1


k
1

j
1

. 

k

n

,
j
n
U

 is a complete satiety indicator. 

j
1

F

In the conclusion of this chapter we give several statements concerning the non-

uniformly forgetful robot with non-tantamount emotions. 

It  easy  to  see  that  for  this  kind  of  robot  in  the  end  of  n  complete  education 

cycles the general education function 

those cycles, satisfies the relation 

n
][
V
l
,
i
nn

, defining the education obtained during 

20

 
 
                                                  
 
                                                    
 
                                          
 
 
 
                                                    
 
 
                                                 
 
 
[
V
l

p
]
i
,

p



p

]

p

[
l

p

П
k
1

k
















[
r
i

p
]


p

1

i

p

k
1


1

[
r
k

p
]

1

k
[

П
j
1

j

p

]



i
p
[

П
i
1

i

p






[
]
V
l

p

]1

i
,

p

1


p











, 

1



,2  
n

p



]1[
V
i
l
,
11



]1[

l

1

П
k

k
1
















]1[
r
i
1

1

1
i

1
]1[
r

k
1

k
1


k

П
1

j

]1[
j






, 

]
[ p

where   i  denotes variables corresponding to the i-th education cycle, 
  
k
corresponds  to  memory  coefficients  of  the  p-th  cycle  for  time  steps  without 
emotional educations, k is the number of the time step without emotional educations, 
is the 
pl
quantity  of  time  steps  in  the  p-th  education  cycle  with  continuous  emotional 
education effects. 

 is the quantity of time steps in the p-th cycle without emotional effects,  pi


,1 , 
 n

i

Obviously, for the forgetful robot the following inequalities are valid: 

q

1



1

i




p

F
l

,

i

p

1


p

1







,2 , 
n

p



|

[
V
l

p
]
,
i

p


|

F
l

,

i

p

p

, 

F

p

pipl
,

]1[
V
l
i
,
11



F
l
i
,
11

,  

where 





max(

F
l
11,
i
p
]

[



j

,

p



l





11
i
q

1




,  



p

]

[

i

)

, 

i



,1


pi

, 

j



,1


pl


,1 . 
 n

, 

p

Let us introduce the following definition. 

Definition 2.14. The generalized  memory function 

][
n
W
l
i
,
nn

 is a value satisfying 

the relation 


W

][
n

l

,
i
nn



n
][
V
,
l
i
nn
q

. 

Definition  2.15.  The  generalized  education  satiety  indicator  is  the  function 

n
][
W
,
i
l
nn



|

][
n
V
,
l
i
nn


1|




q

.  

Based on the definitions given above we conclude that the generalized memory 

function and the generalized education satiety indicator are unitless functions. 

It  is  obvious  that  the  generalized  education  satiety  indicator  satisfies  the 

inequality 

0



n
][
W
,
l
i
nn



1

. 

21

 
 
 
 
 
 
 
 
3. PARAMETERS OF A GROUP OF EMOTIONAL ROBOTS 

Let us consider a problem connected with studying emotional conditions of the 
group  of  robots.  The  theory  given  below  represents  one  of  attempts  to  formalize 
mathematically the solution of this problem. 

Definition      3.1.  The  sum  (i.e.  resulting)  education  of  the  group  including    n 

robots belonging to the set Ωn based on the subject S(t) is computed as follows: 

W

 

n

t
i 

0

n

Sa
((

S
)()

.

),

d

i

                            (3.1) 

Suppose we have two groups including p and k robots and forming two sets Ωp, 
,
Ωk  correspondingly,  where 
. 
Let  us  find  out  when  the  utmost  psychological  conflict  between  those  groups  can 
occur on one and the same class of subjects. It is obvious that, for  instance, hatred 
(odium) is determined by opposite-signed sum educations of rival groups; also it is 

,






, 

p

n

p

p

k

k

k

obvious  that  the  equality 

1

(where 

W

0 p

)  is  to  hold  true  so  that  the 


p
utmost confrontation between robot groups become possible. 

W



k

W

The converse proposition is valid: 

If a sum education of two  groups is equal to zero and an education of at  least 
one robot is nonzero, then the utmost confrontation is most likely possible between 
two groups of robots. 

Below we give the proof of this statement: 
Suppose 

W

0 n

, then k and p can be selected so that k+p=n, as well as Ωk and 

Ωp  can  be  selected  so  that 

W



n



W



k



W



p

0

  is  valid,  i.e. 

W



W



k

p

1

  under 

W

0 p

, which required to be proved. 

Based on this we  get  Theorem 3.1. The  necessary and sufficient condition  for 
the  utmost  confrontation  between  robot  groups  including  at  least  one  robot  with  a 
nonzero education is that the sum education of those groups equals to zero. 

Obviously, the farther is 

W  from zero, the worse is the confrontation. 

k

The  given  theorem  helps  us  to  define  the  most  rival  pairs  of  robots  or  robot 
groups.  To  find  out  the  pairs  of  rival  groups  it  is  enough  to  calculate  each  robot 
education and then obtain a set of all possible sum educations (e.g., by enumerative 

22

 
 
 
 
                                          
 
 
 
 
 
technique,  manually  or  by  computer).  Sets  of  robots  with  sum  educations  close  to 
zero make up rival risk groups. 

It is easy to see that the greater the sum education of a group differs from zero, 

the more united (or, better say, more serried) this group is. 

of 

]1[

W

complete 

Suppose the sum education of members of the first group obtained in the course 
several 
relation 
cycles 
n
V

i
1

j

, and the corresponding sum education of the second group is 

education 

satisfies 

]1[W  

the 

k

,

]1[
]1[
jp

]1[
jpk

computed by the formula 

W

]2[

m
]2[
V

]2[
i
1

j
jp

,

k

]2[
jpk

, where the index [1] or [2] denotes 

belonging  to  Group  1  or  Group  2,  n  is  a  quantity  of  robots  in  Group  1,  m  is  a 
quantity of robots in Group 2.  

Then  the  condition  of  rivalry  between  those  groups  is  defined  by  the  relation 

]1[

W

 W

]2[



0

, which is equivalent to 

n
]1[
V

]1[
i
1
j

jp

,

k

]1[
jpk

m
]2[
V

]2[
i
1
j

jp

,

k

]2[
jpk



0

. 

Definition 3.2. Re-education (re-bringing) is change of the education sign to the 

opposite one. 

Obviously,  Group  1  including  k  robots  can  re-educate  Group  2  including  p 

robots  in  its  favour  if  the  equality 

W



W



k 

Q

  where 

1Q

, 

p

W

 

k

W



p

, 

WW


0

p

k

 holds true by the beginning of the re-educating process. The greater Q 

differs from -1, the more effective is this re-education. 

Definition 3.3. There is an emotional conflict in the group at the time  0t  if the 

n
sum of emotions of each member in the group is equal to zero, i.e.  
1


i

(
i tM

0

)



.0

Obviously,  if  at  the  time  0t   sum  emotions  and  educations  of  members  of  the 

group are equal to zero, then there is the open conflict threat at its utmost stage. 

Let  us  consider  conditions  of  the  conflict  between  uniformly  forgetful  robots 

with tantamount emotions. 

According  to  the  definitions  given  above,  the  limiting  education  of  the  first 
1U  educated by tantamount emotions, satisfies the relation 

uniformly forgetful robot 

U

1



q
1
1 
1

,  and  the  limiting  education  of  the  second  tantamount  emotions,  is 

23

 
                                      
 
 
 
 
 
defined  by  uniformly 

forgetful  robot 

2U   also  educated  by 

the  relation 

U

2



q
2
1 
2

where  1  and  2  are memory coefficients,  1q  and 

2q  are values of the 

corresponding elementary educations. Suppose in the course of an infinite education 
process robots come to an education conflict. This implies that the formula 
is valid, and so is the relation  

1 UU 

2

q
1


1

1



q
2


2

1

.                                             (3.2)   

Equality  (3.2)  allows  us  to  compute  the  approximate  interdependence  of 
memory  coefficients  of  two  uniformly  forgetful  robots  conflicting  on  tantamount 
emotions: 


2



1

1




1

q
2
q
1

.                                       (3.3)  

It is obvious, that if coefficients  1  and  2  are not connected by Relation (2.6), 

then Robot 1 and Robot 2 will never come to an education conflict at the limit. 

Above  in  Chapter  2  we  showed  that  in  the  course  of    j    continuous  education 
effects on  Robot 1 and i continuous education effects on Robot 2 the corresponding 
educations can be described as 

R

]1[
j



q
1

1



1



j

1

1

,

]2[
R
i



q

2

1



1



i

2

2

. 

Then the condition of the onset of the conflict in the education process can be 

computed by the equality 

1



1



j

1

1

q
1



q

2

1



1



i

2

2

.                                        (3.4)     

But  we  can  state  that  if  memory  coefficients  1   and 

2   are  not  connected  by 
Relation  (3.3),  then  the  conflict  between  robots  ceases  with  time  by  itself,  i.e. 
without any extra emotional effects different from already existing emotion effects. 

4. FRIENDSHIP BETWEEN ROBOTS: FELLOWSHIP 

(CONCORDANCE) 

This  chapter  represents  an  attempt  to  introduce  the  term  and  concept  of 
“friendship  between  robots”,  which  we  prefer  to  characterize  as  fellowship  or 
concordance of robots.  

Here we introduce a couple of definitions. 
Definition  4.1.  The  group  of  robots  is  a  united  fellowship  if  individual 

educations of each member are positive. 

24

 
 
 
                                                   
 
                                                  
                                         
 
                                            
 
 
 
Definition 4.2. If individual educations of a fellowship are not less than 

0 P

0

, 

then  0P  is the fellowship value of this group.  

Theorem 4.1. There exists ξ such that a fellowship value of a fellowship is ξ. 

Proof:  As  this  group  of  robots  is  a  fellowship,  then  individual  educations 


 n
),1

i
(

Ri

 of each member satisfy the condition 

0iR

. Therefore there exists a 

value ξ>0 such that the inequalities 

i

This completes the proof of the Theorem. 

Ri

,




,1
n

 hold true. 

Definition 4.3. Suppose individual educations of a group including n robots are 
positive.  A  sum  (total)  fellowship  value  of  n  robots  is  a  sum  of  all  individual 
education values of robots in this group. 

Assume that a set of n robots is divided into two sub-groups. Suppose the first 
Sub-group  including  m robots is  more  united and affinitive of the two  fellowships, 
and  its  fellowship  value  is  0P .  So,  the  sum/total  fellowship  value  of  the  first  Sub-
0mP
group P is computed by the equality 

. 
Assume the second  Sub-group  includes n-m robots and  has a fellowship  value 
0R . Then the sum/total  fellowship  value of the  first Sub-group A  is defined by the 
equality 

P 

A



. 

(

Rmn
0)



Obviously, the sum/total fellowship value R of two sub-groups is defined by the 

formula 

APR







mP
0



(

Rmn
0



)

.                               (4.1) 

Assume the inequality 
Suppose  members  of  the  second  Sub-group  are  robots  with  equal  tantamount 

 holds true. 

P 
0 R
0

emotions q and uniformly forgetful with equal memory coefficients . 

We state the following problem: let us define the education condition for robots 
of the second Sub-group, under which it is possible for the fellowship coefficient of 
the second Sub-group to become equal or more than the fellowship coefficient of the 
first Sub-group as a result of education of robots in the second Sub-group. 

Based on (4.1) we conclude that this condition is determined by the inequality 

mP
0



(

Rmn
*



)



nP
0

,                                (4.2) 

*R   is  the  education  value  of  each  robot  in  the  second  sub-group  after  the 

where 
education process had started. 

It is easy to see that Relation (4.2) is equivalent to the formula  

R 
* P
0

.                                               (4.3) 

25

 
 
 
 
 
 
                                      
 
 
                                                
                                                           
Let  us  effect  simultaneously  on  each  robot  of  the  second  sub-group  by 
tantamount emotions until Condition (4.3) becomes to hold true. Obviously, by the 
end of the education process the relation  
j

q



1


1

j





R
0



P
0

is to hold true, where j is a quantity of education process time steps for robots of the 
second sub-group. 

So,  for  finding  the  least  quantity  (number)  of  the  necessary    education  time 
steps with the given  memory coefficients of robots of the second sub-group we are 
to solve the following problem: 

solve for 

under 

j


1



1

q






min
j

1

j





R
0



P
0






                            (4.4) 

q

j



1


1

j





R
0



P
0



0

. 

Let us prove the theorem. 

Theorem 4.2. If the relation 

q


1

solution. 



R
0



P
0

 is valid, then Problem (4.4) has no 

Proof.  Since  robots  in  the  second  sub-group  are  uniformly  forgetful,  then  the 
   holds  true.  So,  Theorem    4.2  statement  yields  a 

1

0

two-sided  inequality 
formula valid for any time step value j: 

q

j



1


1

j





R
0



P
0

This  formula  implies  that  the  limiting  condition  in  Problem  (4.4)  is  never  to 

hold true. Therefore, this task has no solution under this theorem statement. 

This completes the proof. 

In  other  words,  the  theorem  implies  the  following:  “education  effects  not 
necessarily  make  robots  achieve  equal  fellowship  (i.e.  concordance)  between 
members of the group with the given fellowship value”.  

5. EQUIVALENT EDUCATION PROCESSES 

Definition  5.1.  The  equivalent  education  process  is  a  continuous  education 
process  corresponding  to  an  education  with  tantamount  emotions,  equal  memory 
coefficients and featuring the minimal deviation at all the education assessment node 
points from the values of a real continuous education process of a robot. 

26

 
                                              
 
 
                                            
                                                 
 
                                                   
 
 
 
 
 
5.1.  MATHEMATICAL MODEL OF EQUIVALENT EDUCATION 

PROCESSES 

Suppose education values of a real continuous process are established in the end 

of each  period  by  values 

R j

,

j

steps. Also suppose conditions   


,1
 n

, where n  is a total quantity  of education time 

R

j



1



R

j



,0

j



,1


n


1

.                                      (5.1) 

are valid. 

Now  we  approximate  the  real  education  process  to  an  equivalent  education 
q,   under  which  the  objective  function 

process.  To  do  this  we  need  to  find  such 
reaches its minimum 

J


),(
q



n

2
j







R

j





j

1


R
1



q

1

j




1



21






.                     (5.2) 

So,  in order to develop the equivalent education process we  need to solve the 

equation set 

J



),(
q





,0

J



),(
q
q




0

.                                  (5.3) 

Considering Relation (5.2), Equation set (5.3) in its expanded version takes the 

form: 

R

j





j

1


R
1



q

1

n

2
j







j

1




1




j

1










1








0

,                          (5.4) 

R

j





j

1


R
1



q

1

n

2
j







j

1





1



j





1

j



2

R
1



q

1





j

1

















1

j







1
2



j



2


1











                                                                                                                        (5.5)  

Since  for  adequately  selected  time  steps  the  solutions  of  Equation  sets  (5.4)  – 

(5.5) have to satisfy the conditions  

1
,                                          (5.6) 
then,  due  to  checking  on  validity  of  (5.6)  we  can  estimate  adequacy  of  the 

 , 

0q

0

equivalent process to the real education process. 

Coefficients 

q,  solved out of Eqs. (5.4) – (5.5) allow us to find approximately 
the  limiting  value  of  the  education  of  the  continuous  process  Z.  Obviously,  Z 
satisfies the relation 

27

 
 
 
 
                                             
 
                             
                                        
 
                     
 
 
                                                   
Z



lim
j







j

1


1



q

R

1

j

1




1











q



1

. 

Let  us  assess  the  error  in  calculations  of  the  limiting  education  in  the  real 

continuous process through the equivalent education process. 

According  to  the  formula  of  continuous  education  in  the  real  process,  the 

relation   

holds true. 

R

j



r

j





R

 
1

j

j

j

П
k

1
k

R
1

.                        (5.7) 

In (5.7) we pass to the limit under the time  tending to infinity: 
j

lim
RП
k
1

1
j
k

lim

j

lim

j

lim

j

lim

j




1

R

R







r

j

j

j

j

.            (5.8) 

relation

According 
R j
lim
j

equality 

to 
D


0



theorem 

the 
education 
the 
  holds  true.  Hence,  Relation  (5.8)  is  tantamount  to  the 

convergence, 

of 

D



lim
j


r

j





lim


t

D

.  

j

So the value D satisfies the relation  

D



r

j

lim

j

lim1

j

.

                                      (5.9) 

j



Suppose the inequality   

holds true. 

1

j

r

lim
j


lim
j






q



1

j

                           (5.10)           

Considering the last inequality and Relation (5.9) we get the following formula: 

ZD




1

j

r

lim
j


lim
j






q



1



j

M




1





q



1



qM





1






1











1







Mq






1








,                (5.11) 

where 

M



r

j

,

max
j


 max


j



j

. 

28

 
 
                                     
                                                
                                       
 
                                                  
 
 
                                                          
 
                                                            
 
 
                          
 
Let us consider the case corresponding to the inequality 

1

j

r

lim
j


lim
j






q



. 

1

j

Obviously,  in  this  case  the  limiting  education  error  estimate  satisfies  the 

relations  

DZ




q



1



1

j

r

lim
j


lim
j






q



1



1

j

M







1



q












M


1(



)


,                   (5.12)   


1









1










where 



min

r

,

j

M




min



,

j





,1


j

. 

Relations (5.11) and (5.12) allow us to get the error estimate X of the limiting 
education  under  approximation  of  the  real  process  to  the  equivalent  education 
process. Obviously, in the general case it can be found by the formula 

X






max





qM





1








1










1




Mq






1









,


q
1











M


1(



)



1





1












. 









Analyzing Formulas (5.11) and (5.12) we can state that the worse is the robot’s 

emotional memory the less is the error estimate of the limiting education. 

Also, (5.11) and (5.12) allow us to state that the formula  

lim
j


R j



q


1

                                         (5.13) 

holds true if the matter concerns a forgetful robot. 
By virtue of (5.1), Relation (5.13) allows us to find approximately the limiting 
education  of  a  robot  for  the  real  educating  process  on  the  basis  of  the  equivalent 
educating process. 

It is easy to see that (5.9) implies the relation  


,1


,

j

R j



M




1



which  is  the  upper  bound  of  the  education  value  of  the  forgetful  robot’s  real 

education process. 

5.2. ALTERNATIVE TO AN OBJECTIVE FUNCTION UNDER 
COINCIDENCE OF TIME STEPS OF REAL AND EQUIVALENT 
EDUCATION PROCESSES 

Let  us  introduce  a  simpler  objective  function  such  that  its  minimization  can 

give us the coefficients  and  q  which define the equivalent education process 

29

 
 
                             
                  
                                                   
 
 
 
 
J


),(
q





R
i

q



R
i


1

2



. 

n

i

2

Validity of this objective function for designing an equivalent education process 
follows  from  the  formula  of  education  of  a  robot  with  tantamount  emotions  and 
equal memory coefficients: 

 . 
R
1
i
In order to minimize this function let us solve the following equation set: 

q


R
i

J


J



q
),(


),(

q

q










,0



.0

Now we are to find the corresponding derivatives: 








n

2
i

2
n

2
i
2



q
),(



q


q


R
i

R
i

J










J



q
),(

q
Then the system takes the form 
n




i

2

n




i
2






R
i

R
i

q



R
i

1



R
i

1




,0

. 

q



R
i

1






.0


R
i

1



(



R
i

1


),


R
i

1



).1(


Now simplify this and get  








n

i

2
n

i
2


RR
i

i

1




n

Rq
i
i
2




1


n


i
2


(

R
i

1


2

)



,0

R
i



nq
(

)1


n


i
2


R
i

1




.0

The system is linear relative to  and   q  so let’s express  and   q  as 

iR . Out 

of the second equation we get 

n

i

2

q



R

n

i 

i

2
1



n

R
i


1

. 

Substitution of  q  into the first  equation gives  

30

 
                                                
 
 
                                                           
 
 
                                         
 
                                               
                                         
 
                                                  
 
n

i

2





n

i

2

n

i

2

RR
i
i


1



RR
i
i


1



n

i

2

R

i



n

n


i

2
1



R
i


1

n

i

2

R
i


1




i

RR
i
i


1



R
i

n
n

R
i
i
i


2
2

1

n






1





n

i

2
n

R
i


1



1





n

(

21
2

R
i


1

2

)


0



n


i

2

(

R
i


1

2

)


0

R
i

n
n

R
i
i
i


2
2

1

n





(

R

i


1

2

)




1












n

i

2

n

i
2

n

R
i

2






1



1



,0









R
i

n
n

R
i
i
i


2
2

1

n


1

RR
i

i


1







(

R
i


1

)

2



n

i

2
n

R
i

2






1



1









n

i

2








n

i

2





Consequently, 

(

n



)1

n

i

2



RR
i

i


1



n
n

R
i
i
i


2
2

R
i


1

.

2

(

n



)1

n

i

2

(

R

i


1

2

)







n

i

2

R
i


1





n

i

2

R

i



(

n



)1

n

i

2

RR
i
i


1



n
n

R
i
i
i


2
2

R
i


1

(

n



n

)1
i

2

(

R
i


1

2

)







n

i

2

R
i


1

2





n

i

2

R
i


1

n



1

q



0



 are to be valid. 

So,  under  known  education  values  of  the  real  education  process  of  a  robot  
the  conditions 

  we  get  unique  values  of    and  q   for  which 
q

, 
,1
iRi
n


0
,1
If  the  obtained  values  satisfy  all  the  limitations  mentioned  above,  then  the 
coefficients  and  q  define the equivalent education process. If the obtained values 
do  not  satisfy  those  limitations,  then  it  is  not  possible  to  develop  any  equivalent 
education process with the same time steps as in the real education process and with 
the corresponding educations 

 of the real education process. 

, 

,1

n

iRi

The obtained coefficients  and  q  allow us to find approximately the limiting 

value of the real education process. Let  Z  be the limiting value; then 

Z



lim

i

(

q




R
i


1

)


q


Z

.

Out of this we get 

Z



q


. 

1

According to the formula of the continuous education process the relation  
r

i

.1


i

R
i

R
i

31

 
                         
 
                           
 
 
                                
 
 
 
                                        
 
 
                                                   
 
is valid. 
Having passed to the limit in this relation we get  

lim
lim
i

i
i

lim

i
According  to  Theorem  2.1  of  forgetful  robot’s  education  convergence  at 
0

lim
i


R
i

R
i

D

r
i









1

.

positive emotions, the relation 

 holds true. Hence, we get 

lim
i


Ri

D



lim

i

r
i



lim

i


i

D

,

D



r
i

lim

i

lim1

i


i

.



q



1

; then we get the following formula: 

Let

r
i

lim
i


lim1
i



i

ZD




r
i

lim
i


lim1
i



i



q



1



M


1

1

1



q



1



M

1

1(
1(





)

1

q


1(
1)(


)


1

)

,

with: 

M



1

max
i

r
i


,
1



max
i


i

,

i

,1


Let us consider the case when 

formula: 

r
i

lim
i


lim1
i



i



q



1

, out of it we get the following 

DZ




q



1



r
i

lim
i


lim1
i



i



q



1



M


2

2

1

q

1(




1(

M


)
2
1)(


2


1(
)


2



)

,

where 

M



2

min
i

r
i


,
2



min
i


i

,

i

,1


The  obtained  relations  are  necessary  for  computing  an  error  of  the  limiting 
education  under  approximation  of  the  real  education  process  to  the  equivalent 
education process. The error X  is found by 

X



max





M

1

1(
1(





)

1

q

1(



1)(
)

q

1(


1

)

,


)

2
1(


2

M

1)(

2



)

1(


)

. 





Analyzing  the  inequality  described  above  we  conclude  that  the  worse  is  the 

robot’s emotional memory, the less is the error of limiting education computing. 

Example.  Let  us  consider  an  example  of  equivalent  education  process 

development. 

32

 
                                             
 
 
                                                
 
 
                         
      
 
 
                              
 
 
  
                           
 
 
Suppose  the  real  education  process  includes  three  education  time  steps 

,

,

1

RRR
2
3
q , and get 

 with 

R
1



,1

R

2



,3

R
3



4

. By the formulas given above we find  and 





q




4*7
15*2
10*2

16

4*5.07
2





5
2

1
2



5.0



5.2

0

q

0



,1




 are valid. 

At that, 
So, we obtained an approximation of the real education process including three 
R

,3
 to the equivalent education 
2
3
5.2q
  and  equal  memory  coefficients 

R
time steps with the real education 
process  with  tantamount  emotions  under 
5.0

R
1

,1





. 

4

Based on the obtained values, we can find the approximate value of the limiting 

education  Z . Simple calculations lead to the following relation: 

Z



q



1



5

. 

5.3. GENERALIZATION IN CASE OF NONCOINCIDENCE OF TIME 
STEPS OF REAL AND EQUIVALENT EDUCATION PROCESSES 

Speaking about generalization, assume that a number of education time steps in 
the equivalent education process may differ from their number in the real education 
process. For instance, the end of the second time step of the real education process 
may  coincide  with  the  end  of  the  second  or  more  time  step  of  the  equivalent 
education process.  

Noncoincidence  of  time  steps  for  education  processes  can  occur  due  to 
randomness in timing of educations of the real education process. Education values 
of the real process can be approximately restored for each time step in the course of 
development of the equivalent education process. 

Assuming that the equivalent education process is continuous, we can suppose 
that  during  each  time  step  our  robot  is  effected  by  a  tantamount  emotion  with  the 
elementary education  q .  

It is easy to see that the objective function can be presented as follows: 

j

J


,(

,...,

jq
,
1

n

1
i

iR is the education  value of the real education process after the time step  i , 
1


1



  characterizes  the  education  obtained  as  a  result  of  the  equivalent 

,                     (5.14) 



1


1

R
i





q

ij

)

n











where 

and 

q

2

ij

education process after the time step 

ij . 

So,  in  order  to  develop  the  equivalent  education  process  it  is  necessary  to 
minimize Objective function (5.14). For that we need to solve the following equation 
set: 

33

 
                                          
 
 
 
                                     
J



,(

J



,(

jq
,
1


jq
,
1
q


,...,

nj

)



0

, 

,...,

j

)

n



0

. 

ij

q



R
i


1



1

Then the equation set for finding will take a form 

n



i
1






0


























1



1

n

i
1



i

R
i

,0

,1





1


q

0

q

ij

ij

j

1(





)

ij


1


,0

Example.  
Assuming  that 

2







R

,3

,6

R
1

R
3

10
  hold  true  and  applying  the  cyclic  data 
search method for Objective function  (5.14) minimization with an enumeration step 
equal  to  0.1  for  q   and    ,  and  an  enumeration  step  equal  to  1  for 
ij ,  and  with 
variation intervals of  q  between 0.1 and 2.9,  - between 0.09 до 0.99. 
ij - between 
2 j
1  до  100,  we  get  the  following  values:   
, 
, 
3 j
. Obviously, the limiting education equals 20. The computation results show 
that under found parameters of the equivalent education process the value of (5.14) 
equals 0.0056, i.e. the developed equivalent education process approximates the real 
one quite closely. 

99.0

2.0q

1 j

35

16

69

, 

. 

6. METHOD OF APPROXIMATE DEFINITION OF MEMORY 

COEFFICIENT FUNCTION 

In Chapter 2  we proved the  following equality  for  the beginning  of each time 

step: 


,1

.                                               (6.1) 
)(ti  in the following form 
Now let us express the memory coefficients 

bta
, 
i
  are  constants  which  are  not  dependent  on  the  current  time  t  of 

)(
t

,1)0(


i

i

i

i

a ,
b
where 
i
i
emotion effect. 

According  to  (6.1)  and  relations  for  finding  the  coefficients 

a ,
i

b
i

  we  can 

work out the following equations system:  

a

i


ta
i

i

b
 i
0

t
 
1
i



,1



b
i

                                               (6.2) 


                                        (6.3) 

34

 
                                                    
                                                    
 
                                      
 
 
 
                                             
                                               
 
                                                    
                                               
 
with 

t

,1

i

t

i

,  the  time  of  the  beginning  of  the  i-th  time  step;  ,  the  memory 

coefficient of the equivalent process. 

We obtain relations allowing us to find the unknown values in Equation system 
(6.2)  –  (6.3)  provided  that  parameters  of  the  equivalent  process  are  found  on  the 
basis of 

The objective function given in Section 5.2. 

It  is  easy  to  see  that  the  sought-for  values  are  found  by  the  explicit  formulas 
, 

1ib

(

n



)1

n

i
2


RR
i
i


1



n
n

R
i
i
i
2


2

R
i


1

(

n



)1

n

i
2




R
i


1

2








n

i
2


R
i


1

2







1

, 

a

i



t

i
where  n  is  the  number  of  time  steps  for  which  successive  values  of  the  robot’s 
iR  are known, as well as time step which are defined by the values 
, 
education 

,1 .  
 n

,1


1

i

t

t

t

i

i

i

7. MATHEMATICAL MODEL OF FORMING TANTAMOUNT ROBOT 

SUB-GROUPS 

This chapter describes one of the ways to make up groups of robots with equal 

sum educations. 

Let  us  consider  a  group  of  k  robots,  where  each  robot  has  its  order  number  i, 

where 

i


,1 . 
 k

Suppose the robot i has its education 

iR . Then the sum education of the group 

of robots A satisfies the relation 

A



k

1

i

iR

. 

Problem: Out of the set    including all the robots, let us make up sub-groups 

which  are  nonoverlapping  subsets 



pp
,




,1
knn



(

)

, 

n

p
p 1


,  so  that  sum 

education values of the obtained sub-groups are least different from each other.  

Let us give the following definition and prove the auxiliary theorem. 

35

 
 
                             
 
 
 
 
 
Definition 7.1.   The average education 

pF  of the group p is a value satisfying 

the relation 

F



p

j



N

R

j

p

p

, where 

pN  is the quantity of robot units in the set 

p . 

Theorem 7.1. The sum education A satisfies the equality 

A



n

i

1

i FN
i

.

Proof. It is easy to see the validity of the equality chain 

NFN
i



i

j



N

R

j

i

i

i






j

R

j

i

.                                   (7.1) 

Summing  (7.1) with respect to all the values i we get 



FN
i
i

n
n

 
i
1

1

j
i

The proof is complete. 

R



j

i

k

1

s

R
s



A

, i.e. 

n


1
i

FN
i
i



A
.

Let us introduce the objective function in a form: 

n
n
1

 
j
i

i
1

Now the problem put above can be mathematically described as follows:  
solve for  


FNFN

1





. 

J

2

i

j

i

j

min
,
i FN
i



,
FNJ







                                         (7.2) 

FN
i
i



NA

,



,0

i


,1
n

i



.   

under limits 
n

1
i


N



k

,

i

n

1
i


Problem (7.2) deals with determination of conditional extremum of function of 

several variables, so it can be easily solved by the well-known Lagrange method. 

As a result of applying the Lagrange method to the solution of this Problem we 

get the roots of the following equation system: 

n


FNFN

1

i

i

i

j

2

F
i

j



j





2

1

F
i



,0

i



,1


n


,1

n

1
i


N

i

k


,0  

2

n

1


i

1

FNFN

nn

i

i






2



,0

                                                                      (7.3) 

36

 
 
 
 
                                          
 
 
 
 
 
                                                
                                                       
 
 
n

i

1

FN
i
i



A



,0

2


FNFN


j

i

i



j




2



,0

i



,1

n




,1

n



j

i

1

i

i

1



2





F
n

F
n



2

FNFN

nn

n
1



1
i

,1 
where 
2
In the general case, the question about existing and uniqueness of the solution 
of  the  nonlinear  algebraic  equation  set  (7.3),  and  about  mathematical  ways  of  its 
solution is still open-ended. 

 are the Lagrange method auxiliary variables. 

,0

Now  let  us  consider  the  task  which  is  a  little  bit  different,  though  similar  to 
Problem  (7.2)  in  its  statement.  In  this  new  problem  statement  we  suppose  that  the 
p  is already predetermined. It is quite easy to 
quantity of robots 
see  that  in  this  case  the  mathematical  statement  of  the  problem  will  have  the 
following form: 

pN  in the groups 

solve for  

n
under  
1


i

FN
i
i



A

 
FJ







min
iF

                                            (7.4) 

According  to  the  Lagrange  method,  Problem  (7.4)  solution  is  reduced  to  just 

finding the roots of the linear equation set  

n


FNFN

1

i

j

i

i

2

j



j




,0

i



,1


n


,1

n

i

1

FN
i
i



A



,0

                                                  (7.5)  

2

n

1


i

1

FNFN

nn

i

i






,0

where  is the Lagrange method auxiliary variable. 
It  is  easy  to  show  that  the  major  equation  determinant  in  this  equation  set  is 
  means  that  the  group  is  split  into  two  sub-

nonzero  (e.g.,  the  case  when 
groups), i.e. with such n this set always has a unique solution. 

2n

Definition 7.2. Sub-groups with the values 

of Problem (7.4) are tantamount ones.  


,1
 n

i

Fi

,

 obtained in the solution 

Definition 7.3. Sub-groups with the values

 which are the solution of 
Problem (7.4) and which make the objective function J reach its minimum equal to 
zero are absolutely tantamount sub-groups. 

Fi

i

,


,1
 n

37

 
 
                                                         
 
 
                                  
 
                                            
                                  
 
 
 
Let  us  define  simple  conditions  under  which  the  sub-groups  being  formed  are 

absolutely tantamount. 

The  minimum  of  the  function 

 
FJ







relations 

  obviously  equals  to  zero  when  the 


,1
n

i





,1


,1
i


j

,
n

,

j

hold true. 

FNFN


i

i

j

n

1
i


FN
i
i



.
A

It is easy to see that under 

2n

 the sub-groups become absolutely tantamount 

when the relations  

F
1



A
N
1

,

2

F
2



A
N

2

2

  hold true. 

The  solution  of  Problem  (5.9)  allows  us  to  get  numerical  values  of  abstract 
average  educations  which  may  not  coincide  with  real  average  educations  of  sub-
groups being formed. This is connected with the fact that average educations of all 
real  sub-groups  are  known  values  and,  consequently,  absolutely  tantamount  sub-
groups might not be obtained basing on educations of single robot units. This is also 
the reason why it is not always possible to split a set of robots into tantamount sub-
groups. 

8. ALGORITHM FOR FORMING TANTAMOUNT SUB-GROUPS OF 

ROBOT 

Below  we  give  an  algorithm  for  making  up  real  robot  sub-groups  closest  to 

tantamount ones: 

 determining a quantity (number) of robots in each 

1. 

Set up values 

nN
n
sub-group being formed, with  
1


N ...,
,1

i

N



k

.   

i

2.  Make up the array  Z  of different sets 

Z

of 

quantity 
n

yN
,
i
i
1


set 

yN
,
j

yN
,
i

i

,

,

pools 

in 

the 


jn
,,1




n
.,1



i

j
,



yN
,
1
array 

,...,



Z), 

q
,
yyN

1
such 

n

  (q is the 

that 

3. 

Based on Step 2 find the value of the function 

 
FJ







 for each pool of sets  



yN
,
1

,...,



n ,
yN

. 

38

 
 
 
 
 
 
 
4. 

function 

5. 

Define numbers of y for which the corresponding sets make the objective 
 
FJ


Arrange  a  visual  output  of  sets 

,  corresponding  to  the 

reach its minimum. 

,...,









yN
,
1

n ,
yN

minimum values of 

 
FJ







. 

Note that performing Step 2 on a computer one may use well-known computer 

algorithms of combinatory analysis given in [8]. 

Having  selected  the  sets  including  robot  sub-groups  with  the  closest  sum 
educations, we can assess their equivalence, i.e. to what extent those sub-groups are 
tantamount  towards  each  other,  by  comparing  average  educations  of  those  sub-
groups to the values 

iF which are the solution result of Problem (7.4). 
For assessing the closeness V of the formed sub-groups to the tantamount ones, 
formula: 

following 

applying 

the 

we 


Dn
,1
,
i

i



 are real average educations of each of formed sub-

suggest 

FD
i
F
i

,

i

V



max
i

group.  Obviously,  the  nearer  is  V  to  zero,  the  closer  are  the  formed  sub-groups  to 
each other. 

To detect sub-groups of robots grouped according to their education levels out 
of a general set we suggest applying well-known algorithms of cluster analysis [9]. 
These algorithms may, for instance, help to detect either robots belong to leading or 
lagging sub-groups. 

9. APPLYING VECTOR ALGEBRA RULES TO INVESTIGATION OF 

ROBOT SUB-GROUP EMOTIONAL STATE 

Here and below we use Cartesian rectangular coordinates. 

Definition  9.1.  A  robot’s  education  based  on  n  emotion  types  is  the  vector 

RR
,
1
2


R 
single-type emotions is defined according to Relation (2.2). 

  where  each  element  of  the  vector  of  education  based  on 

,...,

,...,

R
n

,

R

j

Introducing vectors of educations and emotions allows us to use rules of vector 

algebra in mathematical operations with educations and emotions. 

Thus, the group education R including m robots can be found by the formula 

R




kR

m

1

k

,                                   (9.1) 

and the group emotion M can be found by 

39

 
 
 
 
  
 
                                                          
 
m

1

k
where k is an order number of a robot in its group. 

M




kM

,                                       (9.2) 

Note  that  with  m<n    the  vector  of  group  emotions  includes  at  least  n-m  zero 

elements. 

By introducing Relations (9.1) and (9.2) we obtained a rule for composition of 

robots’ psychological characteristic vectors. 

Below we give the results of theoretical research concerning a pair of emotional 
robots  or  their  two  groups;  either  of  the  groups  features  its  education  and  emotion 
vector. 

Definition  9.2.  A  single-type  psychological  vector  of  a  robot  is  either  just  an 

emotion vector or just an education vector. 

.
To unify the records we designate single-type psychological vectors as 
Let us consider psychological properties of scalar product of emotion education 


èa


b

vectors. 

Suppose 


a   is  the  single-type  psychological  vector  of  the  first  robot,  or  the 

group of robots, and 
the second group of robots (both of robots or the groups belong to a common set). 


b  is the single-type psychological vector of the second robot, or 

According  to  the  rules  of  vector  algebra,  a  scalar  product  of  two  single-type 

psychological vectors is a value satisfying the relation 


ba
,










ba

cos


,

with:  

a ,


b

 the moduli of vectors, obtained by well-known vector algebra formulas; 

α the vectorial angle contained by 

It is obvious that 

.


ba
,
cos(  satisfies the equality 

ba,

)

cos(
)












ba

40

 
                                                              
 
 
 
 
                                                             
 
 
                                                    
 
Definition  9.3.  If 






,0



2





  then  we  consider  that  psychological  effects  are 

directed at achieving one  goal; but  if 





achieving opposite goals. 


2






,



, then these effects are directed at 

Definition 9.3. is illustrated by Fig. 9.1 and Fig. 9.2. 


b  

y 

 


a  

х 

Fig. 9.1. Single-type psychological vectors are directed at achieving one goal 

y 


b  

 


a  

х 

Fig.  9.2.  Single-type  psychological  vectors  are  directed  at  achieving  different 

(opposite) goals 

The following statements are obvious. 

41

 
 
 
 
 
 
Theorem  9.1.  If  a  cosine  of  the  angle  between  two  single-type  psychological 
vectors is positive, then psychological effects are directed at achieving one common 
goal. 

Corollary  9.1.  If  a  cosine  of  the  angle  between  two  single-type  psychological 
vectors  is  equal  to  1,  then  psychological  effects  directed  at  achieving  one  goal  are 
the most effective. 

Theorem  9.2.  If  a  cosine  of  the  angle  between  two  single-type  psychological 
vectors is negative, then psychological effects contradict each other and are directed 
at achieving different (opposite) goals. 

Corollary 9.2.1. If a cosine of the angle between two single-type psychological 
vectors  is  equal  to  -1,  then  the  set  of  robots  contains  sub-groups  with  opposite 
psychological characteristics. 

Corollary 9.2.2. If a cosine of the angle between two single-type psychological 
vectors is equal to -1, and moduli of these vectors are equal to each other, then there 
is  a  conflict  in  the  set  of  robots,  and  psychological  characteristics  of  this  conflict 
correspond to the considered psychological vectors.  

It  is  obvious,  that  if  Corollary  9.2.2.  is  valid  simultaneously  for  both  emotion 
psychological vectors and education psychological vectors, then the conflict between 
two sub-groups gets its acutest form. Thus we can formulate the following theorem. 

Theorem 9.3.  If cosines of the angles between emotion vectors and education 
vectors  are  equal  to  -1,  moduli  of  emotion  vectors  are  equal  to  each  other,  and 
moduli of education vectors are equal to each other, too, then there is a conflict in its 
peak point. 

Theorem  9.4.    If  a  cosine  of  the  angle  between  single-type  psychological 
vectors is equal to zero, then there occurs an unstable psychological situation so that 
any  single  emotion  may  tend  the  set  of  robots  either  to  one  goal  achieving  or  to 
different (opposite) goals achieving (i.e. either to serrying together and uniting or to 
dissociating and disuniting). 

The proof is obvious. 

Theorem 9.5.  A set of emotional robots can not simultaneously be in situations 
when  the  cosine  modulus  of  angle  between  single-type  psychological  vectors  is 
equal to 1, and, at the same time, the set’s psychological situation is unstable due to 
this type of vectors. 

Proof. Assume the set of robots is emotional. Then its single-type psychological 

vector is not equal to zero. 

42

 
 
 
 
 
 
 
 
 
 
 
Since the cosine modulus of the angle between psychological vectors is equal to 
1, then the vectors are collinear. As the collection of robots experiences an unstable 
psychological situation, so psychological vectors are orthogonal. But both described 
cases can simultaneously be valid only if at least one vector is equal to zero, but it 
contradicts with an assumption that the considered set of robots is emotional. So, the 
theorem is proved ex contrario.  

Corollary  9.5.  Theorem  9.5.  can  be  rephrased  as  follows:  a  collection  of 
emotional  robots  cannot  simultaneously  experience  a  conflict  and  psychological 
uncertainty. 

10. MATHEMATICAL ASSESSMENT OF GOAL ACHIEVMENT 

EXTENT 

Suppose an educator set for a robot a numerically expressed goal of education. 
In some cases it is possible to assess numerically to what extent the robot manages 
to reach its goal in the course of this education. 

10.1. Rule of solving for the extent of goal achievement 

Let us introduce the following definitions. 

Definition 10.1.  A  goal  is the  vector 


a
1
m
2
ia
final state of a robot, achieved in K steps, with  
1


A

i



.0  

,...,

ma

 characterizing the desired 

Below  we  consider  the  case  when  for  achieving  the  goal  we  have  a  given 

number of steps K. 

Definition 10.2. A step-to-the goal k is the vector 

R
k




r
k

1, ,...,

mk
r

,

 defining a 

state of a robot obtained in one k-th step in the course of achieving the goal. 

Definition  10.3.  A  state  vector  (or  robot’s  state  vector) 

kW is  a  vector 
corresponding to the goal achievement as a result of passing all the steps through the 

step k inclusive, and satisfying the relation 

W
k



k

1

i

R
i

.  

Obviously,  deviation  of  the  step  k  direction  from  the  goal  direction  is 
k equal to the angle between the goal itself and the step 

characterized by the angle 
k to the goal. The cosine of this angle is defined by the formula [10] 

43

 
 
 
 
 
 
 
 
 
 
 
cos(


)
k



, 



RA,
k
RA
k

  (10.1) 

k  contained by the robot state vector and the goal (this 
and the cosine of the angle 
cosine characterizes deviation from the goal direction after passing through k steps) 
is defined by the relation 




cos
k





WA,
k
WA
k

.                                  (10.2) 

After  passing  through  the  given  number  of  steps  K  specified  for  this  goal 
achievement, it is possible to find the value  showing how close the robot is to the 
preset  goal.  A  formula  defining    is  a  ratio  of  the  vector  projection  numerical 
value KW  onto the vector A to the modulus of A. 

So, considering (10.2), the relation for evaluating takes a form 





W

K

cos



K



A





W

K
A

WA
,
WA



K





K



WA
,
K
2

A

.              (10.3) 

It  is  easy  to  see  that    can  possess  any  values,  and  the  goal  is  achieved 

completely if 

1 . 

The  cosine  of  the  angle  of  deviation  of  the  sum  state  vector  from  the  goal 

direction   can be found by the relation 



cos







K

.                                    (10.4) 

WA,
WA

K

The formula for evaluating the goal achievement percentage 

k  at every step k  

is analogous: 

k 





RA k
,
2
A

,                                                            (10.5) 

and the goal achievement  k  after passing through k steps is found by  

k 





WA k
,
2
A

.                                                  (10.6) 

Suppose  kt

  is time  necessary  for performing the step  k,  then we can evaluate 
the  total  period  of  time  T  spent  for  achieving  .  It  is  found  by  the  formula 

T



K

kt
1

k

. 

44

 
                                                
 
 
 
 
 
 
 
 
 
 
 
                                                      
 
 
 
                                   
 
                                                     
 
                                               
 
                                                  
 
Comparing  members  of  one  sub-group  to  each  other  we  can  find  the  most 
talented  for education robot according to the  following criterion: while  his positive 
 is equal to that value of the rest robots, he must perform the least time T. 

The formulas mentioned above can be used for analyzing robot’s actions while 
k   are  too  big  (see 
achieving  the  goal:  for  instance,  if  under  some  k  the  values 
k   are  close  to  zero  (see  (10.1)),  we  may  conclude  that  the 
(10.5))  and  angles 
robot’s actions chosen at the step k provide the most successful achievement of the 
preset goal. 

  (see (10.3), (10.6)) and the angle values 

Obviously,  successful  actions  of  the  robot  at  every  k-step  yield  the  biggest 
k,
 (see (10.4), (10.2)) close 
to  zero.  In  other  words,  to  achieve  the  goal  successfully  the  robot  must  perform 
maximal results at every step. 

k,

Now  let  us  consider  a  question  about  quantitative  assessment  of  a  sub-group 

goal achievement. 

 Suppose  every  member  j  of  a  sub-group  has  its  individual  goal 

jz


h



1, ,...,

h

j

, 

mj

,


,1 , L is a quantity of robots in the sub-group. 
 L
the  general  goal  A  of 
this  case 

j
where 
In 
L


1
j
Suppose every robot in the sub-group has its k-step to its own goal defined by 
, then the sum k-step of the sub-group achieving the goal 

the  sub-group 

is  evaluated  by  

the vector 

jz

A



. 

kjf
, 


S

,

,...,

S

j

,1,

k

kmj

,

,

is evaluated by the formula 

R
k



L

1

j

f

,
kj

, and in k steps the state vector of the sub-

group will satisfy the relation 

L
k
 
1

1

j
i
Now,  based  on  the  relations  introduced,  we  may  numerically  assess  the 
achievement  extent  of  the  sub-group  goal  by  formulas  initially  developed  for  a 
single robot unit by substituting a robot for a sub-group. 

k

1

i

W
k

R
i





. 

,
ij

f

Suppose, having achieved some goal a robot sets up another one. That new goal 
may  have  a  quantity  of  components  different  from  the  previous  one.  To  find  the 
quantitative  assessment  of  the  next  goal  achievement  we  can  apply  the  scheme 
described  above  including  there  a  corresponding  quantity  of  components  of  a  new 
goal. 

But  sometimes  the  goal  of  robot’s  actions  cannot  be  seen  clearly.  In  this  case 

the best way to present this goal is by the matrix A: 
a
,1
m
...

a
1,1
...

...
...

A









a

q

1,

...

a

,
mq

’ 







where every line represents one of the goals. 

45

 
                                               
Assessing one by one every  line  (i.e. every  goal achievement)  in the  matrix  А 
after  passing  K  steps  we  can  find  the  goal  which  is  achieved  best  of  all  the  rest. 
Solution of this problem can warn the robot against aiming at unaccomplishable and 
unrealizable goals. 

Also let us pay attention at a simpler case when the goal and k-steps are scalars. 
Note,  that  in  this  case  the  goal  and  k-step  to  that  goal  have  only  two  directions  – 
either  coinciding  with  the  number  axis  direction  or  opposing  it.  Thus  Relations 
(10.3), (10.5), (10.6) take the form:  

where А is a value of the goal.  

WK
A

,

k 

Rk
A

,

k 

Wk
A

, 

The  method  of  individual  assessment  of  a  goal  achievement  can  be  used  for 
ranking  robots  according  to  their  educations,  e.g.  in  descending  order.  For  correct 
ranking, it is necessary, first of all, to set up the maximally possible accomplishable 
goal,  and  then  get  robots  ranked  according  to  numerical  values  of  this  goal 
achievement.  If  these  numerical  values  appear  to  be  equal  for  some  robots,  then  a 
robot with the least deviation from the goal direction has to be put at the first place. 
This way of education ranking we call goalizing.  

Let  us  consider  the  case  when  numerical  values  of  goal  vector  elements  are 
unknown,  but  the  task  is  to  rank  education  vectors  according  to  the  achievement 
ascending order (i.e. according to the order of closeness to the goal being achieved). 
Without breaking the integrity, suppose the robot’s goal is to obtain the best result. 
Then the  goal  A can be characterized by a vector with m  unit elements: 
. 
Having  assigned  an  order  number  to  each  unit  element  of  the  education  vector  set 

)1,...,1(A

(this is to indicate its closeness to 1), we get the vector
for each education. 

B

j




,1 ,...,
b
j

jm
b

,

,  

j


,1  
 n

It is easy to see that in this case the values of projections 

j  of each vector 

jB  

onto the goal vector A satisfy the relation  
m

 1
i



j

B

,
ji

m

,                                               (10.7) 

and the angle of deviation from the goal achievement 
formula 

j  can be found by the 

cos


j

m

1

i
m

1

i

B
i

,

j

. 

m

j

2
B
,
i

According  to  (10.7),  the  less  is 

j ,  the  closer  are  the  vectors 

Thus  these  vectors  can  be  ranked  in  ascending  order  of

46

jB   to  the  goal. 
j .  If  with  all  this 

 
 
                                                   
 
  
 
                                                         
                                                   
i

,

k
forward. 

i



k

,  then  the  vector  corresponding  to  the  biggest  cos

j   is  to  be  put 

Let us note the following. 
Sometimes a robot achieves its final goal stepwise, from one part of the goal to 

the other. 

Suppose 

by 
m
, 
,...,
a
1

k
where n is a number of elements of the finite education goal vector. 

the 


aA
,...,
a
k
1
1

evaluated 

final 

goal 

,...,
a

1

,...,
a
k

,...,
a
k

...,

1

a
k
1

is 

a
k

a
k




1


1


1

n

,

,

j

j

j

j

the 

vector 

Without breaking the integrity, suppose that at the step  i  the robot achieved the 

education  


W



i


R
,1

...,

R

k
1

,...,

R

k

i

,...,

R

k

i


1

0,...,
0,

. 

Then in (10.3) the vector 
the total amount of steps to the goal. 

iW  satisfies the relation 



i WW

, where 

i

i


,1 , s is 
 s

10.2. Algorithm for forming tantamount sub-groups of robots according to 

their goal achievement extent 

Based on the rule of solving for the extent of goal achievement given above in 
Section  10.1  we  can  suggest  the  following  algorithm  of  forming  two  tantamount 
sub-groups,  if  goals  of  each  robot  are  equal  to  each  other  and  each  sub-group 
includes an even number of members: 

1)  Make up a general linear array out of goal achievement extent values of 
robot; 

each 

2)  Within  the  array,  define  numbers  of  robots  having  the  maximal  and 
extent; 
goal 

achievement 

values 

of 

minimal 

3) 
4) 
values 

Robots with these numbers go to the first sub-group; 
Remove from the general array the elements with  maximal and minimal 
extent; 

achievement 

goal 

of 

5) 
to Step 10; 

If the resulting general array is not empty, then go to Step 6, otherwise go 

6)  Within  the  resulting  general  array,  define  numbers  of  robots  having  the 

maximal and minimal values of goal achievement extent; 

7) 

Robots with these numbers go to the second sub-group; 

47

 
 
                               
                                        
 
 
 
 
 
8) 

Remove from the general array the elements with  maximal and minimal 

values of goal achievement extent; 

If the resulting general array is not empty, then go to Step 2, otherwise go 

9) 
to Step 10; 
10) 

 End. 

11. MATHEMATICAL MODEL OF ROBOT’s  EMOTIONAL 

ABILITIES 

In  the  previous  section  we  presented  formulas  for  evaluating  the  extent  of 
education  goal  achievement  based  on  methods  of  the  vector  ranking  projective 
theory. 

Now  we  advance  a  hypothesis  that  the  ablest  ‘gifted’  robot  is  the  most  docile 
and submissive to education, i.e. by the time t this robot reaches large average extent 
of 
unit.  
On the basis of this hypothesis we offer a relation for evaluating the robot’s ability 
F: 

achievement 

education 

time 

goal 

per 

d

t

0










)(

d

t

dt











m


1
i

tRa
)(
i

i

m


i
1

2
a
i

t m
 

1
i
0

t



2

t

Ra
i
i


)(
d

m


1
i

2
a
i

tF
)(



.             (11.1) 

So, robot’s abilities are measured in units reciprocal of the time. 
Based on Chapter 3 we can get the assessment of abilities of a robot which does 

not have a property of absolute memory. This assessment is given by 

tF

))(



4

q

m

1

i

a
i

ij


1

i


1
i

t

m

1
i


2
a
i

, 

r
i

;  

with: 

q max



i

i   the  values  of  maximal  memory  coefficients  corresponding  to  the  i-th 

education; 
ij   the  order  number  of  the  i-th  education  time  step  depending  on  the  education 
current time t . 

Let us prove the following theorem. 

48

 
 
 
                    
 
 
                                               
 
 
Theorem 11.1. The abilities 

kF  of the forgetful robot are limited at the end of 

each time step k. 

Proof.  Suppose 





the inequality  

,


i

max

n
,1



i

  is the  minimum  value of  all the periods. Then 

F
k



4

q

m

1
i


a

i

ij


1

i


1
i

t

k

m

1
i


a

2
i

4



a
i

m

1

i

2
a
i

1

q


m


i
1


holds true, quod erat demonstrandum. 

Eq.  (11.1)  finds  the  most  capable  (‘gifted’)  robot  in  a  group,  ranks  robots 
according to their abilities and discloses robots with highly pronounced propensities 
to this or that scope of activities defined by subsets of education vector elements. 

We  offer  the  following  algorithm  for  finding  scopes  of  activities  to  which  a 

robot has the strongest abilities. 

1. 
parameter. 

Set  up  the  general  education  goal  vector 

A


1
a

,...,

ma

  as  an  input 

2. 
general 

By  the  control  point  of  time  t  the  education  process  is  to  result  in  the 
)(
. 
vector 

education 

),...,

R





tR
(1

tR
m

3. 
elements  of 

Select  subgoal  vectors  (which  are  subsets  composed  of  one,  two,  …,  m 
the  goal  vector  А. 
series 

the  goal  vector) 

from 

in 

4. 

Compute the ability values for each of these composed subsets provided 
that  the  considered  educations  correspond  to  numbers  of  elements  of  subgoal 
vectors. 

5. 
subsets. 
6. 

Select  the  maximal  ability  values      corresponding  to  each  of  composed 

Find  numbers  of  elements  of  the  composed  subset  goals,  corresponding 
to  these  maximal  ability  values.  These  numbers  correspond  to  education  types 
according to which a robot is considered to be the most successful, i.e. the ablest. 

The relation 

N

n
i
nC

1

i

 defines the quantity of  major steps N to be performed 

when this algorithms is processed by computer software. 

49

 
                              
 
 
 
 
 
 
 
 
 
 
 
For studying robot’s abilities it is necessary to introduce the concept of ability 
range implying the quantity of educations matching the given ability value.  We can 
conclude  that,  with  equal  ability  values,  the  wider  is  the  robot’s  ability  range,  the 
more  talented  is  the  robot.  Thus,  general  abilities  of  a  robot  are  defined  by  B, 
,  where  p  is  the  ability  range,  F  is  the  ability 
satisfying  the  equality 
value. 

F

B



p



,

Theorem  11.2.  In  a  univariate  case,  with  the  time  infinitely  increasing  the 

abilities of a forgetful robot achieving the goal tend to zero. 

Proof. Since the relations  

[
V
l

]
p
i
,

p



p

]

p

[
l

p

П
k

k
1
















[
r
i

p
]


p

1

i

p

k
1


1

[
r
k

p
]

1

k
[

П
j

j
1

p

]



i
p
[

П
i

i
1

p






]
[
V
l

p

]1

i
,

p

1


p

, 











1



,2 , 
n

p







are valid for n education cycles, then the inequalities  

1
i

1
]1[
r

k
1

k
1


l

1

П
k

k
1

]1[
V
i
l
,
11

]1[
r
i
1

1













]1[

k

П
1

j

]1[
j

                        (11.2) 






|

[
V
l

]
p
,
i

p


|

F
l

,

i

p

p

, 

1



1

i




p

F
l

,

i

p

1


p

1


, 





p




q

l




p

F

pipl
,


,2 , 
n

p



]1[
V
l
i
,
11



F
l
i
,
11

, 

F
l
11,
i



11
i
q


1



, 

(11.3) 

with 

p

]

[







max(


pi
hold true for the forgetful robot. 

[

i

,1



, 

p

)

i

,

]

j

, 

j



,1


pl


,1  
 n

, 

p

Also, 

Formulas 
][
n
V
l
i
,
nn

imply 





i
1

In  view  of  the  definition  of  the  robot’s  ability  for  the  univariate  case  the 

relations 
.                     (11.4) 

(11.3) 
1
n

i
1



1


the 

i
1





chain 
q

1



1



2



of 


1









1

q

1

q

i

following formulas can be written: 

50

 
 
 
                      
                               
 
                                         
                                     
                                 
 
 
 
 
                                    
d

t

0









V

][
n
ninl
.


)(
d

tA

dt









4



lim
t


tZ
)(



lim
t


lim
t


q


1
|



2



2

tA
|

t

4



lim
t


q

2





1
tA
|
|

. 



0

So, 

lim


t

tZ
)(



0

. Thus the theorem is proved. 

Theorem  11.3.  In  a  multivariate  case,  with  the  time  tending  to  infinity  the 

abilities of a forgetful robot tend to zero. 

Proof.  Since  for  each  education  component  j  the  values 

n

[
V
l

jn

j
,

]
i

jn

  satisfy  the 

relations 

|

n

[
V
l

jn

j
,

]
i

jn


|

F
l

,

i

jn

jn

,  (where   

j


,1
 m

,  m  is  the  number  of  goal  vector 

components and current education vector components, 

jn  is the number of complete 
education  cycles  corresponding  to  the  j–th  education  vector  component)  and 
relations  
Inequalities 

(11.4), 

then 

the 

4

|

lim
t


tZ

lim|)(

t


are valid, therefore 

tZ
)(



0

. 

lim


t

This proves the theorem. 

m

|
i

1

a
i

|



0

q


1



2


m

i

1

t

2
a
i

Corollary 11.3. If there were some forgetful robot existing for an infinitely long 

period of time, then in the course of time its abilities would tend to zero, i.e. vanish. 

12.  WORK AND WILLPOWER OF EMOTIONAL ROBOTS 

It is easy to see that in the univariate case (when the goal  A is defined by one 
value) the value of goal achievement by the end of the n-th complete education cycle 

satisfies the relation 


t
)(

][
n
V
,
i
l
nn
A

)(
t

. 

51

 
 
                  
 
 
                                            
 
 
 
 
 
Let us introduce the following definitions. 
Definition  12.1.  Education  process  work  on  achievement  of  the  goal  A  is  the 

function 

)(
tX

t

)(

0

d

goal А achievement. 

, where the subintegral function is a function of value of the 

Definition  12.2.  Willpower  of  a  robot  achieving  the  goal  А  is  the  function 

t

 0


)(

d

. 

t

)(
tY

It is easy to see that Work is measured in time units, while Willpower does not 

have units of measurement. 

Now  let  us  establish  several  simple  theorems;  their  proofs  are  obvious  from 

(11.3). 

Theorem 12.1. In the univariate case the education process work of a forgetful 

robot achieving its goal satisfies the inequality  

)(
tX



2

1|

|

A

q

2



t

. 

Theorem  12.2.  In  the  univariate  case  the  willpower  of  a  forgetful  robot 
inequality  

satisfies 

goal 

the 

its 

achieving 

|

tY

|)(



2

1|

|

A

q

2


. 

Theorem  12.3,  In  the  multivariate  case  (the  goal  is  a  vector),  the  education 
process  work  of  the  forgetful  robot  achieving  its  goal  satisfies  the  inequality 

2

|

tX

|)(




1



m

|
1

i

a
i

|

t

. 

q

2


m

1

i

2
a
i

Theorem  12.4,  In  multivariate  case,  the    willpower  of  the  forgetful  robot 

achieving its goal satisfies the inequality 

|

tY

|)(



.                                   (12.1) 

m

|
1

i

a
i

|

2
i

2

q


1



2


m

1

i

a

52

 
 
 
 
 
 
 
 
 
                                                   
Corollary 12.4. A forgetful robot with the unlimited willpower does not exist. 

Proof. Since (12.1) holds true, the forgetful robot’s willpower is limited. Hence, 

the corollary is proved. 

Suppose the human’s willpower similarly to the robot’s willpower is described 

by Definition 12.2. 

Let us introduce one more definition. 

Definition 12.3. A robot is dangerous to a man when a modulus of its willpower 
becomes  asymptotically  (with  time  tending  to  infinity)  more  than  a  human 
willpower modulus at any time point of the man’s life. 

Theorem  12.3,  A  robot  with  an  absolute  memory  and  tantamount  positive 

emotions is dangerous to a man. 

Proof. Since all the memory coefficients of the robot with an absolute memory 

are equal to 1, then for tantamount positive emotions (considering (11.2)) the robot’s 
education resulting from infinite quantity of education cycles is equal to infinity, i.e. 
satisfies the relation 

t

)(

0

d

t



. 

)(
tY



lim


t

lim


t

Even having all his emotions positive, a regular human being does not have an 
absolute memory, his\her emotions are limited [8], so, according to Theorem 12.4 a 
human  willpower  is  limited,  i.e.  it  is  less  than  an  asymptotic  willpower  of  a  robot 
with an absolute memory and tantamount positive emotions.  

The proof is complete. 

is 

always 

Since  a  single  person  by  nature  cannot  physically  exist  forever,  his\her 
willpower 
finite.  
After  a  forerunning  robot  rests  in  peace,  the  information  from  its  memory  can  be 
downloaded  to  the  successive  robot’s  memory  (together  with  the  information  on 
numerical values of all the previous generations of robots). This provides continuous 
existence of a single robot’s intelligence with the time tending to infinity. As a result 
of  such  continuous  existence  of  generations  of  robots  and  passing  on  positive 
tantamount  emotions  from  “ancestors”  to  “successors”  provided  with  an  absolute 
memory we will surely come up to a moment when a robot becomes dangerous to a 
man. So, we may conclude that in order to avoid this danger for a human being it is 
necessary at least to design forgetful robots (robots with a non-absolute memory). 

Suppose the following relation holds true:  

53

 
 
 
 
 
 
 
 
                                                     
 
 


(

max

),
t




t

),(

0

d

|max



|

                              (12.2)  

with: 


  the  varied  collections  of  memory  coefficients;  max




  the  vector  of 

memory coefficients, under which the function  

|


t

),(

0

d

|

reaches its maximum. 

From Definition 12.1 and Formula (12.2) we derive the following definition. 

Definition  12.4.  The  efficiency  coefficient

)(t   of  the  education  process  is  a 

value satisfying the relation 

[
sign

max


d
),
]

)(
tX



)(
t



t

)(

0

d




t

(

0


(

max

t

(

0

[
sign

max


t

),(

0

d

|

|max



),
t



. 


d
),
]

It is easy to see that the education process efficiency coefficient has no units of 
1,1
 is  valid  for  it. Obviously, the  more  is 
measurement and the condition 
)(t   under  the  given  memory  coefficients,  the  closer  gets  a  robot  to  the  most 
effective education.  


t
)(

Provided  that 

sign
[

tX

)](

sign
[

satisfies  the  relation
education processes coincide. 

)( t

1,0



t

(

0

max


),
d


0]

  holds  true,  the  value 

)(t  

,  which  means  that  directions  of  real  and  effective 

It  should  be  noted  that  the  efficiency  coefficient  makes  it  possible  to  assess 
“natural”  robot  properties  (memory  coefficients)  in  terms  of  education  process 
effectiveness. 

13. ROBOT’s TEMPERAMENT MODEL 

This chapter gives mathematical interpretation of robot’s temperaments. 
Definition  13.1.  The  elementary  temperament 

)(twi

  is  a  derivative  of  the 
  with  respect  to  the  time  t,  i.e. 

function  of  momentary  emotions  module 

)(tM i

54

 
                                       
 
 
                                      
 
 
 
tw
)(
i



tMd
)(
i
dt

,

 where i is the robot’s number in a group, 

tMd
)(
i
dt



0

, 

i


,1 , n is 
 n

the quantity of robots in a group. 

Psychological  studies  say  that  we  can  hardly  meet  a  human  being  with  the 
pronounced  temperament  of  one  certain  type.  As  human  beings  are  analogues  of 
robots, let us give the following definition. 

Definition 13.2. The robot’s temperament L is a function satisfying the relation 

L



1
an

n

1

i





max
t

)(
t

dM
i
dt





,               with 

a



 
t

dM
i
dt

max
ti,

, 

i


,1

n
. 

It is easy to see that the suggested rule allows us to find a temperament of some 

certain robot only relative to its (sub)group. 

The  results  of  investigations  of  human  temperament  and  its  numerical  values 

[3] can obviously be applied to robots (see Table 13.1). 

Table 13.1. Variation intervals of robot’s temperament values 

Robot’s temperament 
type 

Variation intervals of 
temperament numerical value 

melancholic 
phlegmatic 
sanguine 
choleric 

(0; 0,3) 
(0,3; 0,5) 
(0,5; 0,8) 
(0,8; 1) 

Intervals given in Table 13.1. allow us to introduce a concept of temperament of 

a group of robots (group’s temperament). 

In Chapter 2 we mentioned an example which can be described by the function 

)(
tM



P

sin






0

t

t





 with: P=const;  0t

 the time step lenght. 

Similarly  to  this  example  we  define  a  set  of  emotions;  each  of  them  for  the 

robot i. takes a form: 

)(
tM
i



P
i

sin







0
i

t

t






,1 . 
 n

with: 

, 

const

Pi 
It is easy to see that in this case the robot’s temperament 

 the lenght of the time step i, 

i

0
it

the following formula 

55

iL  can be defined by 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                               
 
L
i



P
i
0
i

t

P
i
0
i

t

max


,1
n

i

. 

Definition  13.3.  The  temperament  N  of  the  group  of  robots  is  the  average 

temperament of robots belonging to this group. 

With the definition of finding N in mind, we can use the following formula: 

n
i
L
 1
i
n

N

.                                       (13.1) 

Having found N by (13.1), we can define the temperament type by associating 
values from the right column in Table 13.1 with the left column; depending on what 
interval N belongs to, the group of robots can be either  melancholic, or phlegmatic, 
or sanguine, or choleric. 

14. INVESTIGATION OF PSYCHOLOGICAL PROCESS DYNAMICS 

IN A GROUP OF ROBOTS 

Here  we  consider  the  cases  when  some  processes  occur  in  a  group  of  robots 
with  time.  Terms  and  conventional  signs  used  in  this  Chapter  are  the  same  as  in 
Chapter 9. 

The following statements are obvious. 

Theorem 14.1. If with the course of time 

tends to the unstable emotional situation. 

Theorem 14.2. If with the course of time 

tends a group of robots to get serried (united). 

cos(


t
(
))


t

, then a group of robots 

0
t

0

cos(


t
(
1
))

t

t

0

, then emotional activity 

Theorem  14.3.  If  with  the  course  of  time 

cos(

t
(


))
1
t


t

0

,  then  emotional 

activity tends a group of robots to get dissociated (disunited). 

Corollary 14.3.1.  If 

cos(

t
(


))
1
t


t

0

  and 


)(
ta


)(
tb



, 

)(ta

 is large, then 


t


0
t

0

there is a threat of conflict in its acutest form in the group. 

Note that the point t0 mentioned in Theorems 14.1–14.3 and Corollary 14.3.1 is 

the time value corresponding to the defined events in the statement given above. 

56

 
                                                   
 
 
                                                           
 
 
 
 
 
 
 
Corollary 14.3.2. If the conditions of Corollary 14.3.1 are valid for emotion and 
education vectors simultaneously, then there is a threat of conflict in its acutest form 
(i.e. simultaneous emotional and educational conflicts) in the group of robots. 

Based on the things given above we introduce the following definition. 

 Definition 14.1. The measure of emotional or educational relationship between 
  satisfying  the 

t 
),

t
)(

(

sub-groups  of  robot  within  a  set  are  the  unitless  values 






tbta
)(,)(



tytx
,)(
)(


cos



relations 

  where 


cos



t
)(

t
)(









,



tbta
)(,)(

  are  education 

vectors, and  



tytx
,)(
)(

 are emotion vectors. 

So, the emotional condition of the two sub-groups altogether can be described 

by the vector 


c


t
),(



.)(
t

1,0


1,0


  or 

0,1

)( t

)( t

It  is  easy  to  see  that  if  the  relations 

  are  valid  at  the 
moment  of  time  t,  then  there  is  an  emotional  or  educational  concordance 
  or 
correspondingly  between  the  sub-groups;  and  vice  versa,  if 

t
)(
,  then  there  is  an  emotional  or  educational  rivalry  correspondingly 
between the sub-groups within the set of robots. The cases 
 are 
responsible  for  borderline  situations  in  between  educational  or  snap-emotional 
0)()(
rivalry  and  concordance.  The  case  corresponding  to  the  inequality 
defines educational concordance or emotional rivalry and vice versa.  


t

0)( t

0)( t

t 

0,1

t

 or 

)(

It is obvious that the larger are 

)(t  with their values positive, the more 
“benevolent”, i.e. concordant is the atmosphere in the set of robots; and the smaller 
)(t   with  their  values  negative,  the  stronger  is  the  rivalry  between  the 
are 

)(t   or 

)(t  or 

robots. The following statement holds true: if 

0)( t

 and 


ta
)(


tb
)(



, then the sub-

group which education is described by the vector 

of the sub-group with the education 


)(ta

. 

Let us formulate the following theorem. 


)(tb

 may be reeducated in favour 

 Theorem  14.4.  If 

cos


ba
,









  and 

1


a


 b

  with  n  equal  to  2  or  3,  then 


a


 b

. 

Proof.  As the  first statement of the theorem  is  valid, then  in a two- and three-

dimensional  space  the  vectors 


a   and 


b are  collinear,  i.e. 


a




bk

.  By  virtue  of  the 

57

 
 
 
 
 
 
 
second  statement,  the  coefficient  k  satisfies  the  equality 

1k

,  and  since 

 

ba
,
cos










1

, then 

1k

, consiquently 


a


b

. 




a


b



Under 

 the relations 

 

ba
,
cos










1

 and 


a




b

 obviously hold true. 

This allows us also to formulate Theorem 14.5 for two- and three-dimensional 

vectors: In order 


a


 b

, it is necessary and sufficient that conditions 

 

ba
,
cos










1


a




b

and 

 hold true simultaneously.  

Due 

to  Theorem  14.5  we  can  generalize  Theorem  14.4:  under 

the 
dimensionality  of  education  and  emotion  vectors  less  than  four,  for  the  worst 
confrontation  within  the  set  of  robots  with  nonzero  vectors  of  psychoemotional 
states it is necessary and sufficient that the sum vector of emotions or educations is 
to be equal to the vector with zero components. 

In the conclusion of this chapter we should note that Theorems 14.1, 14.3 and 
Corollaries  14.3.1,  14.3.2  allow  us  to  assess  the  tendency  of  the  set  of  robots  to 
critical  emotional  situations.  And  in  case  these  situations  are  undesirable,  the 
mentioned theorems and corollaries substantiate the necessity of effecting the robots 
with subjects which are able to kill this tendency. 

15. RULES AND FORECAST OF EMOTIONAL  SELECTION OF 

ROBOTS 

Using  mathematical  definitions  of  robot’s  psychological  characteristics 
considered above in this chapter we try to describe one of the algorithms of robot’s 
emotional behavior.  

Suppose  a  robot  has  got  an  emotional  selection  problem:  he  is  supposed  to 
decide  in  favor  of either the  first or the second player (educator)  depending on  his 
education. 

Below  we  suggest  the  rules  of  making  an  emotional  decision  for  such  robots. 
Assume that the robot has only positive emotions. Now suppose the robot’s memory 

coefficients 

ji,  satisfy the correlation 

0



ji

, 

1

, where 


 ,1i

, the equality j = 1 

meets  robot’s  memory  coefficients  for  the  first  educator,  the  equality  j  =  2  meets 
memory coefficients for the second educator. 

58

 
 
 
 
 
 
We  adduce  the  First  rule  of  the  alternate  selection  based  on  the  emotional 
selection. This rule can easily be implemented in computer modeling of the robot’s 
emotional behavior. 

Suppose  a  robot  is  simultaneously  effected  by  two  players  initiating  robot’s 
emotions. At the time point of stimulus (subject)  it  effect the first player initiates the 

emotion 

iM ,1  causing the elementary education  

iR ,1  equal to 

it

0

M

,1

i

)(
 d

, and the 

education   


B 
1

R
( 1

)0,

  where  e.g.  for  the  robot  absolute  memory  the  formula 



R
1

t
l
k
 

1 0
k
the same time. 

M

,1

k

)( 
d

  holds  true,  and  the  second  player  initiates  a  zero  emotion  at 

At the time point 

jt

 the second player initiates the emotion 

jM ,2

 causing the 

elementary  education 

R

,2

j

jt

0

M

,2

j

)(
 d

  where 

i    ,  and  the  education  of  the 

j

second player 


B 
2

,0(

R

2

)

 where e.g. for the robot’s absolute memory the formula 

2



R

t
l
k
 
k
1 0

same time. 

R

)( 
d

 holds true, and the  first player  initiates a zero emotion at the 

,2

k

Let us introduce the general education vector 

 where vector 
components  are  sum  educations  obtained  in  the  time  t  of  effects  of  the  first  and 

1, RR


V  equal to  

2

second player subjects where 

t

l

kt
1
k


, and l is a total number of emotional effects 

of both players’ subjects upon the robot. 

With these designations introduced, the rule of deciding in favor of the first or 

the second player can be formulated as follows: if the angle between 


V and 


1B is less 


V  and 


2B  then the robot decides in favor of the first player; 
than the angle between 
if the first angle is wider than the second one, it means that the decision is made in 
favor of the second player; but if the angles are equal the selection is not supposed to 
be performed. 

It  is  not  very difficult to apply the  first rule described above  in case there are 
more than two players. For example, if we want to implement this rule for modeling 
emotional behavior of a robot  it  is enough to enter  the  number of  momentary sum 
educations  equal  to  the  number  of  players,  and  the  number  of  components  of  the 
general  education  vector  is  to  be  also  increased.  The  minimal  angle  between  the 
general  education  vector  and  the  education  vector  of  each  player  defines  the 
alternate selection in favor of this or that player. 

59

 
Note that the first rule is valid not only for scalar values of sum educations and 

emotions, but also for the cases when they have a form of vector. 

Definition  15.1.  Critical  angle  of  alternate  selection  is  an  angle  (between  the 
education  vector  and  the  general  education  vector)  defining  ambiguity  of  a  robot 
while making a decision in favor of the first or the second player. 

Now  we  adduce  the  Second  rule  of  alternate  selection  based  on  comparing 

as follows: if 


R  and 
moduli of vectors of the sum educations  1

 R
|
|

 R
|

 R
|

player;  if 

player; if 


R

R


R
1

2

2

1

|

|

|

|

|

|

|

|

1

, then the decision is not made. 

2

 holds true, then the decision is made in favor of the first 

holds  true,  then  the  decision  is  made  in  favor  of  the  second 


R . This rule can be re-formulated 

2

Theorem  15.1.The  First  and  the  Second  rules  of  alternate  selection  are 

equivalent to each other. 


B  and 
Proof. Suppose  is the angle between  1


V , and   is the angle between 


B  and 

2


V . Then according to vector algebra rules, the relations  

cos



cos



2
n

1

i

2
B
,1
i

n

1

i

2
R
,1
i

2
n

1

ni

2
R
,2

i

2
n

1

i

2
B
,2
i

n

1

i

2
R
,1
i

2
n

1

ni

2
R
,2

i





n

1

i

2
R
,1
i

n

1

i

2
R
,1
i

2
n

1

ni

2
R
,2
i


R
1


V



,                    (15.1)  

n
2
R

,2
1

i

i

n
2
R

,1
i
1

i

2
n

1

ni

2
R
,2
i


R
2


V



                  (15.2)  

hold true. 

Obviously, 

if 

  , 

0







0








2

0,








2

,  then 


R
1


 R

2


2

0,








2

, 

then 


R
1


 R

; 

2

if 

  , 

;  if 

  ,  then 


R
1


 R

2

.  So,  we  proved 

that the First rule implies the Second one to be valid. 

Let us prove that the Second rule implies the First one. 

60

 
 
 
 
 
              
               
 
Suppose 


R
1


 R

2

  holds  true.  Then  by  virtue  of  (15.1)  and  (15.2)  the 

inequality 

   is inevitable under 

0








2

0,








2

. 

Validity  of  the  following  statements  is  proved  similarly:  if 


R
1


 R

,  then 

2

   under  

0








2

0,








R
1


 R

2

; if 


2

, then 

  . 

The proof is complete. 

Theorem  15.2.  If  two  vectors  do  not  have  common  nonzero  coordinates,  then 

these vectors are orthogonal.  

Proof.  Since  according  to  the  theorem  statement  the  vectors  do  not  have 
common  nonzero coordinates, then without breaking the integrity these vectors can 

take a form  


a 


aa
, 2
1

,...,

na

0,0,

,...,

0


b

, 




0,0

,...,

,0

b
n

,

b
n


1


1

,...,

m
b

. 

It is obvious that the scalar product of 
vectors are orthogonal. This proves the theorem. 


a  and 


b  equals to zero. It means that the 

Corollary 15.2. The vectors 


1B and 


2B are orthogonal. 

Proof.  Since, according to the designations of the First rule, 


2B do not 
have nonzero common coordinates, then by virtue of Theorem 15.2 these vectors are 
orthogonal. 


1B and 

Let us prove one of the properties of alternate emotional selection. 

Theorem 15.3. The alternate selection critical angle is equal to 


4

. 

Proof.    Let  us  note  that 



BV

1

law  for  composition  of  two  vectors, 


B

2

  is  valid.  According  to  the  parallelogram 



V   is  a diagonal  of  the  parallelogram  with  the 

adjacent sides 


1B  and 


2B . By virtue of Corollary 15.2 these sides are orthogonal, so 







2

  is  valid.  According  to  Definition  15.1  and  the  First  rule  of  alternate 

selection, 

   holds true, i.e. the alternate selection critical angle is equal to 


4

. 

Definition 15.2. Stupor is a state of ambiguity or uncertainty of a robot making 

emotional selection. 

61

 
 
 
 
 
Assume  that  effects  of  the  first  and  the  second  players  upon  the  robot 
0R . Suppose 
correspond to tantamount emotions yielding the elementary education 
robot  memory coefficients corresponding to emotions resulted  from  the  first player 
1 ,  and  coefficients  corresponding  to  emotional 
effect  are  constant  and  equal  to 
2,1
effects of the second player are equal to  2 . Also assume that 
, 
and robot’s emotional memory of the first player effect is fully kept while the second 
player is making his effect and vice versa. 



,1,0

i







i

Then,  according  to  Chapter  3  and  the  Second  rule  of  alternate  selection  the 

following equality is obvious: 

j


1
1
1


1
with j, q the quantity of emotional effects upon the robot (emotions are initiated by 
the first and the second player correspondingly). 
Eq. (15.3) is equivalent to the relation 

,                             (15.3) 

q

2

2




1
1

R
0

R
0



j


1
1
1


1



1
1




q

2

2

.                               (15.4) 

It is easy to see that under the assumptions mentioned above Eq. (15.4) defines 
the  necessary  and  sufficient  condition  for  the  stupor  initiated  by  a  single-type 
emotion.  This  condition  can  be  easily  generalized  in  case  we  need  to  consider 
emotions and an education defined by  vectors (in this connection  it  is  necessary to 
k,2 , where k indicates the order number 
k,1  и 
consider various pairs of coefficients 
of an emotion in the robot’s emotion vector). 

Theorem 15.4 is obvious. If a robot has only tantamount emotions and constant 
memory  coefficients  corresponding  to  each  of  the  two  players,  and  Eq.  (15.4)  is 
valid for each of educations, then the robot is stuporous (in stupor) with respect to all 
its emotions. 

Obviously, the robot never comes to this state of stupor if with any j and q (j > 

1, q > 1) and given  1  and  2  Eq. (15.4) is not valid. 

Let us introduce one more definition. 

Definition 15.4. Anti-stupor coefficients are the memory coefficients  1  and  2  
for which under any integral values j and q (j > 1, q > 1) Eq. (15.4) does not become 
valid. 

Theorem 15.5.  Anti-stupor memory coefficients exist. 
Proof. Let us show that there exist the memory coefficients  1  and  2 which are 

not the roots of Eq. (15.4) under any integral values j and q (j > 1, q > 1). 

62

 
 
                                                     
 
                                                             
 
 
 
 
 
Obviously, Eq. (15.4) is equivalent to  


1




2


1

j

2



1

q

1






q


1

1

 0


.                       (15.5) 

Suppose the following equalities 


1



1
2

,


2



1
3

                                      (15.6) 

hold true.  

we get  

If we substitute Eqs. (15.6) into Eq. (15.5) and make transformations, as a result 


21

.                       (15.7) 



1


j
23








1


1


1

3

0

2

q

q

q

j

Considering that 

y

 j

13 

, Eq. (15.7) takes the form 

q

1



21


y
23





2

y



q

1

q


1

Solving (15.8) relative to y we get the formula 

y



2

relation 

0

.                      (15.8) 
q

1

 equivalent to the 



2

2
q

1

j


1

3



2

q


1

2
q

1

.                                (15.9) 



2

Since according to the theorem statement j > 1 is valid, then for any j and any q 
> 2 the positive value in the left part of Eq. (15.9) is equal to the negative value in 
the  right  part  of  Eq.  (15.9).  So,  we  get  the  contradiction.  Consequently, 


1

1
 
,
2
2



1
3

 are not the roots of Eq. (15.4) with any values j > 1 and q > 2. 

Now let us consider the case when q=2.  
It  easy  to  see  that  Eq.  (15.8)  in  this  case  takes  the  form  2  =  0,  i.e.  under  the 

memory coefficients 


1

1
 
,
2
2



1
3

 this equation has no solution. 

So, with any j > 1, q > 1, there are such memory coefficient values under which 
Eq. (15.4) makes no sense. Consequently, anti-stupor memory coefficients do exist.  

This completes the proof of Theorem 15.5.   

Corollary  15.5.  For  two  players  the  coefficients 


1

1
 
,
2
2



1
3

  are  anti-stupor 

memory coefficients. 

Its proof is evident directly from argumentations given in the proof of Theorem 

15.5. 

63

 
 
                                           
 
                                                            
                                    
 
                                                 
                                                                
 
 
 
 
Eq. (15.4) and Corollary 15.5 allow us to forecast the robot’s behavior and see 

whether our robot may get into emotional stupor. 

Reasoning  from  the  things  said  above  we  can  state  that  the  ‘resolute’  or 
‘purposeful’ robot  is a  machine  for which an alternate selection angle  never equals 

4
that  this  machine  does  not  get  stuporous  regarding  all  the  components  of  the 
education vector. 

, or Eq. (15.4) never holds true, or its memory coefficients are anti-stuporous, so 

16. GENERALIZATION OF ROBOT’S EMOTIONAL BEHAVIOR 
RULES IN CASE THE NUMBER OF PLAYERS INTERACTING WITH 
THE ROBOT IS ARBITRARY (NOT SPECIFIED) 

16.1. FIRST RULE OF ALTERNATE SELECTION 

Assume  a  robot  is  effected  by  n  players  nonsimultaneously.  Suppose  they 
initiate  only  positive  emotions  and  the  robot  performs  an  absolute  emotional 
,1
memory 

its  memory  coefficients 

identity 

the 

i.e. 

ji, satisfy 

i

, j

,1

i 
jm
where
j -th player. 

,

j

,1

n

. Correspondingly, 

jm  is the quantity of subject effects of the 

At the time point 

kt ,1

 (with 

k 

,1 m
1

) the first player initiates the emotion 

kM ,1  

causing 

the 

elementary 

education 

R
,1

k

kt
,1

0

M

)( 
d

,1

k

and 

education 

B
1



(

R
1

)0
0,
,...,

n

1

    with 

R
1



t
,1
l
m
1
 
l
1

0

M

l
,1


)(
d

.  At  the  same  time  all  the  rest 

1n

players initiate zero emotions. 
, 
  where 

,1

At 

k

kit ,

im

t

ki
,



t

ki
1,1

,  with 

i    and 
1i

k 
1

initiates the emotion 

kiM ,  causing the elementary education 

R

,
ki

education 

B
i



0(

,...,

,0

0,

,...,

)0

R
i

ýëåìåíò

i



    where 

R
i



lit
,
im
 
1

l
0

M

,
li

)( 
d

.    At  the  same 

time all the rest 

1n

 players initiate zero emotions. 

Let  us  introduce  the  general  education  vector 

  where 
components are sum educations (resulting from all the players’ subjects) obtained in 

RR
,
1

V 

,...,

nR

)

(

2

lm
the full course of the effect time  t , with   
klt
,
1




1


t

n

k

l

. 

64

,1 im
1
kit
,

0

M

the  player  i 

)( 
d

 and 

,
ki

 
 
 
 
 
 
 
 
 
With these designations introduced, the rule of deciding in favor of this or that 
player  can  be  formulated  as  follows:  the  emotional  decision  is  made  in  favor  of  a 
  (this  emotional  decision  is 
player  for  which 
made  in  favor  of  the  player  i ).  In  case  the  minimum  is  reached  under  several  i  
simultaneously,  the  emotional  selection  is  not  supposed  to  be  performed  and  the 
decision is not made. 

  is  reached  with   

iBV
,

min

,1

n

(

)

i

The given rule can be generalized in case the player’s effect initiates not just a 
, 

single  emotion,  but  a  full  vector  of  emotions.  Thereby  at 

  with 

,1

k

kit ,

im

  where 

t

ki
,



t

vector 

ki
1,1
M 
,1
k

(

M

i    and 
1i
1
,...,
ki
,

M

)

R

,
ki



(

R

1
,
ki

,...,

R

r
,
ki

),

R

j
,
ki

r
,
ki
kit
,

0

k 
1

,1 im
1

the  player  i   initiates  the  robot’s  emotion 

  which    entails  the  vector  of  elementary  educations 

M

j
,
ki


d
)(

and 

the 

education 

1
R
i

,...,

r
R
i

,...,0,

)0

  with 

j

R

i



lit
,
im
 
1

l
0

M

j
,
li

)( 
d

.  At  the 

i



,0





,0

)0

B
i

,...,0,

,...,0(

,...,0(

R
i

ýëåìåíò
same time all the rest players 
the 
r
R
,...,
1

case 

)
(

this 
,...,

1
R
1

R

V



n

2

1n

In 
(
RR
,
1
Further reasoning are quite the same as those ones given above concerning the 

general 
1
R
,...,
,...,
n

vector 

form: 

takes 

the 

 initiate zero emotions.  
education 
r
n

R

)

case when the player’s effect initiates one robot’s emotion. 

16.2. SECOND RULE OF ALTERNATE SELECTION 

vectors  of  the  sum  educations 

The  Second  rule  of  alternate  selection  is  based  on  comparison  of  moduli  of 
,1
.  This  rule  can  be  re-formulated  as 

iB   with 
follows:  the  emotional  decision  is  made  in  favor  of  a  player  for  which 

n

i

iBmax

  is 

i

,1

reached  with 
  (this  emotional  decision  is  made  in  favor  of  the  player  i ).  In 
case the  maximum  length  is reached  under several  values of  i  simultaneously, the 
emotional selection is not supposed to be performed and the decision is not made. 

n

16.3. ORTHOGONALITY OF EDUCATION VECTORS AND 
EQUIVALENCE OF ALTERNATE SELECTION RULES 

As  it  was  mentioned  above,  in  this  paper  we  use  Cartesian  rectangular 
coordinates.  According  to  Theorem  15.2  two  vectors  which  do  not  have  common 
nonzero coordinates are orthogonal.  
B ,...,
Thus each pair of vectors 
1
Theorem 16.1. The First and Second rules of alternate selection are equivalent 

 is orthogonal. 

nB

to each other. 

65

 
 
 
 
 
 
 
 
 
Proof. Let 

BV
i

(

,

i

)

, 

0

 i

 


2

, 

i

,1

n

  is the angle between V  and 

iB . 

According to the rules of vector algebra and orthogonality of 
Bi
V

relation holds true: 

i cos

. 

B ,...,
1

nB

 the following 

(

)

min

iBV
,

Obviously, if 

i  , then according to the First 
 is reached under 
rule of alternate selection the decision is made in favor of the player  k . At that from 
  is 
the  formula  given  above  it  follows  that 

iBmax
i  . The last one describes the Second rule of alternate selection. 

reached under 

j  .  Thus 

B 
k

  with 

B

k

k

k

j

On  the  other  hand  if 

i    then  according  to  the 
Second rule of alternate selection the decision is made in favor of the player  k . At 
j   holds true, and following the formula given above we get 
that 

  is  reached  under 

iBmax

 with 

k

k

j  . From the things stated above we conclude that 
iBV
,
i  , and this is according to the First rule of alternate selection. 

k
k

min

(

)

 is 

B

B 
k
j
k  
 with 
j
reached under 

This completes the proof. 

17. EMOTIONAL SELECTION AND CONFLICTS BETWEEN 

ROBOTS 

It is not difficult to see that Eq. (15.4) coincides completely with Formula (3.7) 
obtained  while  describing  a  conflict  between  two  robots  with  equal  tantamount 
emotions. This fact makes us conclude that inner emotional conflicts of a robot can 
be  described  by  the  same  formulas  as  conflicts  between  different  robots,  and 
consequently, theories applicable  for  groups of robots can  be successfully  used  for 
inner emotional conflicts of a single robot without any alterations. 

As an example of this we present the following theorem. 

Theorem  17.1.  If  two  uniformly  forgetful  robots  have  the  same  (equal) 
tantamount emotions, then there are such robot memory coefficients that the robots 
never get into education conflict. 

Proof.  For  conflicting  robots  Eq.  (3.7)  holds  true;  if  tantamount  emotions  are 
equal  (3.7)  is  transformed  into  Eq.  (15.4).  According  to  Theorem  15.5  there  exist 
anti-stupor coefficients transforming Eq. (15.4) to a strict inequality. But at the same 
time  these  anti-stupor  coefficients  are  the  memory  coefficients  of  two  different 
robots, and moreover, with these coefficients robots would never get into conflict.  

This completes the proof. 

66

 
 
 
 
 
 
 
 
 
Logic makes us introduce a new definition. 
Definition  17.1.  Anti-conflict  memory  coefficients  are  memory  coefficients  of 

two different robots under which the robots never get into conflict. 

Now it is time to give the following theorem. 
Theorem  17.2.  Anti-conflict  memory  coefficients  of  two  uniformly  forgetful 

robots with equal tantamount emotions coincide with anti-stupor coefficients. 

Proof is analogous to the one of Theorem 17.1. 

Corollary  17.2.  When  the  conditions  of  Theorem  17.2  are  valid,  then  the 

memory coefficients of two robots  1 =

1
2

 and  2 =

1
3

 are anti-conflict. 

Proof.  According  to  Corollary  15.5,  anti-stupor  coefficients  satisfy  the 

equalities 


1



1
2

,


2



1
3

anti-conflict ones.  

. By virtue of Theorem 17.2, anti-stupor coefficients are 

So, the corollary is proved. 

18. DIAGNOSTICS OF EMOTIONAL ROBOT’s “MENTAL DISEASES” 

Let  us  recall  the  definition  of  robot’s  emotion  given  in  the  beginning  of  the 

book for better understanding of this chapter. 

Definition  1.3.  The  robot’s  inner  emotional  experience  function  M(t)  is  called 

an ‘emotion’ if it satisfies the following conditions: 

1. Function domain of M(t): 

t



,0



0

t



,

0

t



0

; 

2. 

0
t  (note that this condition  is equivalent to emotion termination  in case 

*

t

the subject effect is either over or not over yet); 
3. M(t) is the single-valued function; 
4. 

; 

M
)0(
0
( 0 
)

tM

5. 
6. M(t) is the constant-sign function; 

; 

0

7. There is the derivative 

)(
tMd

dt

within the function domain; 

8. There is the only point z within the function domain, such that 
tMd
)(

z



,0

0

z



t

and 



0

; 

 z

dt
/
t
tMd
)(

9. 

dt



0

 with 

t  ; 
z

67

 
 
 
 
 
 
 
 
10. 

tMd
)(

dt



0

 with 

t  . 
z

Let us introduce a couple more definitions. 
Definition  18.1.  Let  us  consider  a  robot  to  be  “healthy”  if  its  inner  emotional 

experience function is an emotion. 

Definition  18.2.  Let  us  consider  a  robot  to  be  “ill”  if  its  inner  emotional 
experience function does not satisfy at least one of the conditions in the definition of 
emotion. 

This definition allows us to introduce such concept as seriousness or severity of 

a robot’s disease.  

Since Definition 1.3 includes 10 conditions defining a disease, then the degree 
of severity  of this disease is characterized by H taking on integral values from 1 till 
10  to  indicate  a  number  of  conditions  which  do  NOT  hold  true  (as  those  are  the 
conditions  under  which  the  inner  emotional  experience  function  becomes  an 
emotion). 
The more severe is the disease the greater is Н. 

Definition 18.3. The vector X of disease symptoms is a vector with the numbers 

of emotion conditions (given in Definition 1.3) which do not hold true.  

Definition 18.4. A robot’s disease with the symptom vector

of a robot’s disease with the symptom vector
vector

2X  occur among the elements of the symptom vector

1X . 

1X  is a special case 
2X  if all the elements of the symptom 

Below we give examples of robots’ diseases. 
1. 

Let  us  take  some  inner  emotional  experience  function  f(t)  satisfying  all 
the conditions of becoming an emotion except Condition #2, i.e. the function differs 

0
t  . Obviously, in this case 
from an emotion and this is described by the relation 
the  disease  severity  degree  is  equal  to  1.  We  consider  that  a  robot  having  such  an 
emotional  experience  function  is  neurasthenic.  It  is  also  obvious  that  for 
X=(2). 
neurasthenia 

symptom 

disease 

vector 

form 

has 

the 

the 

*

t

2. 

Let  us  take  some  inner  emotional  experience  function  f(t)  satisfying  all 

 is 
the conditions of becoming an emotion except Conditions #2, 5, 8, 10. 
a  good  example  of  such  a  function.  Obviously,  in  this  case  the  disease  severity 
degree  is  equal  to  4.  A  robot  which  emotional  experience  function  differs  from  an 
emotion  regarding  Conditions  #2,  5,  8,  10  is  psychopathic.  For  psychopathy  the 
disease symptom vector has the form Х=(2, 5, 8, 10). 


t

t
)(

f

2

68

 
 
 
 
 
 
 
 
 
The  forms  of  vectors  in  these  examples  make  us  conclude  that  symptoms  of 
neurasthenia  and  psychopathy  have  one  thing  in  common,  which  is  Condition  #2 
unsatisfied,  and,  according  to  Definition  18.4  psychopathy  is  a  special  case  of 
neurasthenia. 

Sometimes  one  unsatisfied  condition  of  the  emotion  definition  implies  that 

some other conditions get unsatisfied, too. 

Let us consider the inner emotional experience function which has the form: 
1
2

0
.              (18.1) 



,0


Ptf
)(

const
,


0

PP
,

sin

,0

P





t

t

t





t





At first sight Function (18.1) does not satisfy only Condition #5, and the disease 
severity  degree  is  equal  to  1  and  the  symptom  vector  containing  only  one  element 
has  the  form  Х=(6).  But  it  is  not  correct.  Applying  mathematical  analysis  we  can 
conclude that if Condition #6 is unsatisfied it implies that Conditions #4, 5, 7, 9, 10 
are not satisfied for the function f(t), as well. I.e. the disease severity degree is equal 
to 6, and the symptom vector satisfies the relation Х=(4, 5, 6, 7, 9, 10). 

The example illustrating Formula (18.1) demonstrates the method (based on 
mathematical analysis) for detection of the major symptom of an emotional robot 
disease. Elimination of this symptom directly implies that all the rest conditions 
become valid and satisfied. 

Thus for Function (18.1) the major reason of a rather severe disease is that Condition 
#6 remains unsatisfied. 

19. MODELS OF ROBOT’s AMBIVALENT EMOTIONS 

Suppose  we  have  the  robot’s  emotion  vector 


M   defining  ambivalent 

)(

emotions. This vector takes the form  

M
with:  n  the  quantity  of  displayed  emotions  in  the  robot’s  ambivalent  emotion,  

),...,


)(


(



i

j


M


M

j

)(


j
n

 the current time of the emotion effect. 

If  the  education  goal  is  known  and  it  is  defined  by 


A


1
A

,...,

nA

  where 



const

Ai
process is specified by the following equality: 



i

,

  then  the  value  of  goal  achievement  extent    of  the  education 


,1
n

j

)(
tRA
i

i

,                                         (19.1) 

n

1
i


)(
t

n

1
i


A

2
i

 the robot’s education obtained as a result of effect of the i-th emotion (at 

j
i

r

t
)(



j

i

t
)(

j
i

R


1 t
)(

), 

i  the memory coefficient satisfying the 

)(tj

69

with: 

that 

)(tR j
i
j
t
)(
i



R

 
 
                            
 
 
 
                                
 
                                             
)( tj

relation 

1,0

i
education process, 

j

i

r

)(






0

j

dM

(
)

i

, j the order number of an education time step, t the time of the 
)(tr j
t

 the elementary education satisfying the relation 



. 

i

 , 

 1it

Differentiating (19.1) with respect to t, we obtain  

.                                       (19.2) 

A
i

)(
t

j

dR
i
dt

n

1
i


)(
td
dt

n


1
i
According to Chapter 2 the sum emotion 

2
A
i

j
tV
)(
i



t
)(

j

dR
i
dt



t
)(

j

dr
i
dt

j


1



R
i



j


1

dR
i
dt

t
)(

j


i

t
)(

.                    (19.3) 

 satisfies the relation 

)(tV j
i

d
t
)(
i
dt

j

t
)(

It  easy  to  see  that  for  the  robot  with  an  absolute  memory  this  formula  is 

equivalent to  

j
tV
)(
i



So, Eq. (19.2) takes the form 

t
)(

j

dR
i
dt



j
tM
)(
i

. 

j
)(
tVA
i

i

n

1
i


)(
td
dt

n

1
i

Modern psychologists believe that an emotion is positive if it makes an entity (a 

2
A
i

.                                       (19.4) 

person or a robot) to approach its preset goal. Thus if 

td
)(
dt



0

 holds true then the 

ambivalent  vectorial  emotion    is  positive;  if 

td
)(
dt



0

  holds  true  then  this 

ambivalent emotion is negative; if 

td
)(
dt



0

 holds true then it has no sign. 

But modern vector algebra in the general case does not operate with such terms 
as “positive” or “negative” vectors. Therefore let us advanced a hypothesis that there 
is  a  unified  characteristic  for  ambivalent  emotions  of  the  vector  which  specifies  a 
sign of  the ambivalent  vectorial emotion.  Obviously, this characteristic  is a sign of 

the value 

)(
td
dt

.  

Let us introduce series of definitions. 

70

 
 
                                          
                          
                                          
 
                                             
 
 
Definition    19.1.The  average  function  

f

)(t

  of    robot’s  inner  emotional 

experience is the function of the form 

                                              

f

)(
t



n

1
i


j
)(
tVA
i

i

n

1

i

A
i

                                        (19.5) 

under the stipulation that 

n

iA
i

1

0

, 

t 


,0

t

 0
t
0 ,

 is the minimum value of all the 

time steps of component emotions of the ambivalent emotion vector. 

Thus  the  average  function  of  robot’s  inner  emotional  experience  represents  a 
special  function,  such  that  when  this  function  is  substituted  for  all  the  sum 

component emotions in the ambivalent emotion vector we get the value 

to the value of the function without this substitution. I.e.  

)(
td
dt

 equal 

n

1
i


j
)(
tVA
i

i

n

1
i


2
A
i



n

1

i


fA
i

)(
t



n

1
i


2
A
i

holds true for this substitution 

Definition  19.2.  The  average  emotion  

)(tM   is  an  average  function  of  inner 

emotional experience which appears to be an emotion. 

Definition 19.3. If an average function of inner emotional experience is not an 
emotion  then  a  robot  is  considered  to  be  mentally  ill  and  an  ambivalent  emotion 
causes the disease. 

Definition 19.4. The average elementary education  

D  is a value satisfying the 

relation 

D



t
0

0




dM
)(

. 

Definition 19.5. The average education   R  is a value specified by the formula 

 
R

n

1
i

n

1

i

RA
i
i

A
i

j

 with 

n

iA
i

1

0

. 

71

 
                                               
  
 
 
 
 
 
 
Definition  19.6.  The  prevailing  emotion 

  in  the  ambivalent  emotion 
vector  is  an  emotion  for  which  its  order  number  k  in  the  vector  of  ambivalent 
emotions implies that  

)(tM k

is satisfied. 

j
r
k




D





j

r
i



D


min

 ,1
n

i

Definition  19.7.  The  prevailing  elementary  education  is  the  elementary 

education corresponding to the prevailing emotion. 

Obviously for each current time step j of the robot’s education there can be its 
average  function  of  inner  emotional  experience,  average  emotion,  prevailing 
emotion,  prevailing  elementary  education,  average  elementary  education,  average 
education and value characterizing an ambivalent emotion sign. 

Let  the  emotion  vector 

tM j
i

),(

i


,1
 n

  of  the  vector  of  ambivalent  emotions 

have the form 

j
tM
)(
i



P
i

j

sin






t

0

t



,


j

P
i



const



,0


,1
n
,

i



t




,0

0

t

.             (19.6) 

Now let us prove the theorem. 

Theorem 19.1. If 

n

i

1

j

i PA
i



0

 then  for  the robot with  an absolute  memory the 

average function of inner emotional experience satisfying Eqs (19.6) is an emotion. 

Proof. It is quite easy to see that with (19.6) valid the value  

f

)(t

 satisfies the 

following relation: 

                                                  

f

t
)(





n

i
1

n

i

1

PA
i
i

A
i

j

sin






t

o

t



.


                          (19.7) 

Obviously (19.7) satisfies the definition of emotion. 
Quod erat demonstrandum. 

n
Theorem 19.2. If  
1


i

iA



0  then the sign of the average emotion coincides with 

the sign of the ambivalent emotion 

Its Proof becomes obvious when we compare Formulas (19.4) и (19.5). 

72

 
                                                      
 
 
 
 
 
                               
 
 
n
 Theorem 19.3. If 
1


i

iA



0  then the sign of the average emotion and the sign of 

the ambivalent emotion are opposite. 

Its Proof is analogous to the proof of Theorem 19.2. 

20. ABSOLUTE MEMORY OF ROBOTS 

Let  us  consider  robots  with  memory  coefficients  satisfying 

the  eqs.  

,1


i


,1
n

i



, where n is the number of time steps in the education process. 

Obviously, in this case the education  nR  is defined by the formula  

R
n

n
r

i
1

i

,                                             (20.1) 

where  ir  is the elementary education corresponding to the i-th time step. 

According to Eq. (20.1), the infinite education process R can be described by 

the equality 

R



lim
n


R
n


r

i
1
i


.                                 (20.2) 

Now let us formulate the following theorems. 
Theorem 20.1. An infinite education process based on tantamount emotions for 

the robot with an absolute memory diverges. 

Proof.  Since  the  emotions  are  tantamount,  then  the  equalities. 

are 

valid.  By 

virtue 

of 

them  Relation 

(20.2) 

R



n
lim
 
q

n
1
i
The theorem is proved. 

lim

n

q

n



.  

ri
takes 



i

q
,
the 


,1

form 

Theorem  20.2.  If  an  infinite  education  process  converges,  then  elementary 
educations which this process is based on tend to zero with an infinite increase in the 
number of time steps.  

Proof.  Since  the  education  process  converges,  then  the  inequality 

|


ir

|
1i


holds true. Consequently, 

r
lim 
i


i

0

.  

The theorem is proved. 

Note  one  more  thing:  the  education  process  convergence  corresponds  to  the 
education satiety presence under an increase in the number of time steps. Taking this 
into  account  we  can  rephrase  Theorem  20.2  as  follows:  if  an  education  process  is 

73

 
 
 
 
                                                        
 
                                                             
 
 
 
 
satiated, then the elementary education in the basis of this process tends to zero with 
an infinite increase in the number of time steps.  

In Chapter 1 we gave an example of an emotion which can be described by the 

function 

)(
tM



P

sin






0

t

t





, where P=const,  0t

is the time step length. 

Similarly  to  this  example,  we  define  emotions  corresponding  to  the  i-th  time 
by  

step 

where

P 
i

const

 is the length of the i-th time step, 
It  is  easy  to  see  that  the  elementary  education 

0, i
t

)(
tM
i



P
i

sin

t

t







0
i

,                                      (20.3) 






 ,1i
ir   corresponding  to  Emotion 

. 

(20.3) satisfies the equality 

r
i



2


0
tP
ii

.   

So,  by  virtue  of  Theorem  20.2,  if  an  education  converges,  the  equality 

lim 0 
tP
ii


i

0

 has to be valid, and this is the necessary convergence condition. 

Let us prove the following theorems. 

Theorem 20.3. If 

r
lim 
i
i

Proof.  According  to  Definition  1.3, 

, then

lim 0 
t
i


0

i

Pi

0

. 

 L

  is  valid.  Consequently,  the 

chain  of relations 

lim

proof of Theorem 18.3. 

i

r
i



lim


i

0
tP
ii



L

lim


i

0
i

t



0

 holds true. This completes the 

Theorem 20.4. If 

P
lim 
i


i

0

, then 

r
lim 
i


i

0

.  

Proof.  According  to  Definition  1.3, 

0
ti

 S

  is  valid.  Consequently,  the 

chain of relations 

lim

proof of Theorem 20.4. 

i

r
i



lim


i

0
tP
ii



S

lim|
i


P
i


0|

 holds true. This completes the 

As  is  obvious  from  the  foregoing,  the  condition  necessary  for  education 

convergence is satisfied if

lim 0 
t
i


i

0

, or 

P
lim 
i


i

0

, or 

lim 0 
tP
ii
i


0

 holds true. 

74

 
 
 
                                                                
 
 
 
 
 
The  following  statement  is  obvious  as  well:  if  there  are  limits  of  0
it
lim 0 
t
i


under  an  infinite  increase  in  the  number  of  time  steps.,  and 

i

  and 

iP  
  and 

0

P
lim 
i


i

0

 hold true, then the education process is divergent. 

The theorems proved above direct us to one of the way of designing robots with 
an absolute memory and without education satiety. E.g., in order to develop this kind 
iP  and the time steps 
of robots it is enough just to select the sequences of amplitudes 
0
it
 such that their limits under an infinite increase in the number of time steps i are 
nonzero.  According  to  Theorem  20.1,  an  example  of  a  divergent  education  is  the 
conditions 
emotions, 
education  with 

i.e.  when 

tantamount 

the 


,1


0

0
i

,

t





P
i

const

P
To  build  a  robot  with  a  satiated  education  one  may  select  the  predetermined 
convergent  series  as  the  infinite  education,  then  on  its  basis  define  the  sequences 

 hold true. 

const





i

t

,

0
i


 ,1

,

,

i

t

P
  satisfying  Definition  1.3  and  the  statements  of  Theorems  20.3  or 
i
20.4, and then based on this selection preset the emotions for each of time steps by 
Formula (20.3). 

Based on Chapter 3 we can state that an education conflict between two robots 
with an absolute memory by the time point t occurs if the following conditions are 
satisfied: 

i

1
k


]1[
r
k

j

1
k


]2[
r
k

,

t

i
]1[


k
1
k


j
]2[


k
1
k


, 

(20.4) 

,

]2[
r
k

  are  the  elementary  educations  of  the  first  and  the  second  robot, 

 are the corresponding education time steps of these robots. 

where 
]1[

k

,

]1[
r
k
]2[

k

Let  the  robots  get  their  educations  based  on  tantamount  emotions  with  the 

corresponding  elementary  educations 

  and

]2[
jr
conflict relations (20.4) we obtain 
0
into conflict at the time point t takes the form 

]1[
ir
0

]1[
0r


.  Consequently,  reasoning  from 

]2[
0r
, i.e. conditions for two robots to get 

i
j



]2[
r
0
]1[
r
0

,

t

i
]1[


k
1
k


j
]2[


k
1
k


.                    (20.5) 

If  

hold 

true, 


then  Relations 

]1

k

const



]1[


(20.5) 

]2[
,

k
are 

]2[






equivalent 

const

, 
to 

(20.6) 
formula 

the 

75

 
 
 
 
                                      
 
                                      
                                       
 
i
j



]2[
r
0
]1[
r
0



]2[



]1[



,  which  defines  the  conditions  for  an  education  conflict  to  start 

between  two  robots  with  an  absolute  memory  under  tantamount  emotions  for  each 
robot and equal time steps of these emotions. 

For emotions  given by  Formula (20.3) and considering Eqs. (20.6)  we  get  the 

following equality: 

i
j



]2[
tP

]1[
tP

0
]2[
0
]1[



0
t
]2[
0
t
]1[

,                                          (20.7) 

where 

P

]1[

]2[

,

P

,

0
t
]1[

,

0
t
]2[

 are the amplitudes of emotions and the values of time steps 

of the first and the second robot, correspondingly. From  (20.7) it is evident, that in 
the  conditions  
this  case 

the  conflict  between  robots  emerges  only  when 

]1[
P 

P

]2[

 and 

i
j



0
t
]2[
0
t
]1[

 are valid. 

We  want  to  dwell  on  the  relations  determining  fellowship  (see  Chapter  4)  of 
robots with an absolute memory. In this case (under tantamount emotions) a number 
of  education  time  steps  necessary  for  achieving  fellowship  (concordance)  between 
two sub-groups with equal fellowship values can be found by solving the following 
problem: 

solve for 

under 

jq



R
0



P
0



0

. 



min

1
j

jq



R
0



0
P

,                                   (20.8) 

It is easy to see that this problem always has a solution, what means that robots 
with  an  absolute  memory  at  any  time  can  be  brought  to  fellowship  with  any 
fellowship value preset. 

Now let us solve the problem of developing the equivalent educational process 

(see Chapter 5) for robots with an absolute memory. 

Obviously, in order to define the elementary education value q corresponding to 

the equivalent process, we have to solve the following problem: 

solve for: 

min
q

qJ
)(



min
q


R

n

j

2



R
1

j



(

j



)1

q

2



.                             (20.9) 

76

 
                                               
 
                                                   
 
 
                              
where 
education 

Problem (20.9) can be reduced to solving the equation 

qdJ
)(
dq



0

 which 

expanded form is  


R

n

2
j




R
1

j



(

j



)1


(
jq



0)1

.                          (20.10) 

It is easy to see that the solution q of Eq. (20.10) is defined by  

n

2
j


q



(
jR
j

)1


R
1

n
(
 
j
2
j


)1

n
(
j
 
2
j


2

)1

. 

21. ALGORITHM OF EMOTIONAL CONTACTS IN A GROUP OF 

ROBOTS 

In  this  chapter  we  suggest  a  rule  of  mutual  contacts  between  robots  in  their 

group. 

In Chapter 2 we showed that the robot’s education 

iR  by the end of the i-th time 

step is specified by the formula 

R
,                                                 (21.1)  
1
i
i  is the robot’s memory coefficient which characterizes memorization of the 

r

i


i

R
i

1iR  by the end of the i-th education time step. 

Suppose robots contacting each other  in a group randomly exchange emotions 

which initiate elementary educations. 

 L

iR  be the education of the L-th robot by the end of the i-th time step, and 
Let 
 L
ir

 be the elementary education corresponding to this time step. Similarly, 
 j

also let 
let us introduce the corresponding educations 

. for the j-th robot. 

iR  and 

 j
ir

Assume  both  robots  are  effected  by  the  subject  S(t)  initiating  emotions 

]
[L
iM  

(robot L) and 

][ j

iM  (robot j). 

Let us consider that if 

the formula 

][
j
][
L
i RR


1
i
1

0

0

][
j
][
L
i RR

1

1
i
L
][
i MM
 implies 

][
j
i

0

. 

 is valid then 

][
L
i MM

][
j
i

0

 holds true, and 

The emotions 

correspondingly,  and 

[L

]
iM  and 
it
 
L

r
i
0

][ j

iM   initiate the elementary education 
 
j
r
i

)( 
d

)( 
d

  and 

][
L
i

][
j
i

M

M

it

0

 L
ir

 and 

 j
ir

,  where 

it   is  the 

77

 
                                       
                                      
 
 
                                            
 
 
 
 
length of the i-th time step. Obviously the sign of the elementary education equals to 
the sign of the emotion generating this education, and vice versa.  

Let us assume that the sign of the education by the end of the i-1st time step is 
equal to the current sign of the emotion during the i-th time step and the elementary 
individual education by the end of this time step. 


Lj
ik ,

Now let us introduce the following definition. 
Definition 21.1. The suggestibility coefficient 

 is the value permitting the 
emotion i of the robot L to be replaced by the corresponding emotion of the robot j 

multiplied by the value of this coefficient, if 

L

]

[
r
i

,
Lj





k


i

 j
r
i

 with 


ik


, Lj

0

. 

It is obvious that 
Assume  that  when  two  robots  come  in  contact  and  start  communicating,  the 

. 

1


ik


, jj

education of each of them (according to Formula (2.1)) satisfy the relations 

[

L

]

i


r

L

]

[
R
i






i

[
L
]
R

i
1

, 

][
j
R
i




r

j
][

i




i

L
][

i


r


][
L
r
max
i



,

],[
Lj
k
i

][
j
r
i

][
j

r

i


][
j
r
max
i



,

],[
jL
k
i

][
L
r
i



,

],[
Lj
k
i

][
j
R
, with:                 
1

i

}[
][
L
L
r
r
max

i
i

][
L
max
,
r
i

][
j
r
max

i

jL
],[
k
max
,
i

][
L
r
i


],[
Lj
k
i

],[
jL
k
i

][
j
r
i

L
][
r
i

j
][
r
i

][
j
r
i


,  



,




][
j
r

i
sign

][
L
r

i

][
L
r

i
sign

j
][
r

i

,

,

,

],[
Lj
kif
i

,

][
L
rif
i

],[
jL
kif
i

}[
j
r
i

j
][
rif
i





,    

 the suggestibility coefficient of j-th robot’s emotions to the robot L, 

 the suggestibility coefficient of L -th robot’s emotions to the robot j, 

]

,[ Lj
ik
jL
],[
ik
Lj
]
,[
ik

0

, 

],[
jL
ik

0

. 

Let us introduce the following definitions. 

Definition  21.2.  With 

k

]

Lj

,[
i

}[
L
r
i



max



L
][
r
i

,

k

]

Lj

,[
i

j-th robot is called the agitator.  

][

j

r
i

  satisfied  the 

Definition 21.2. Re-education (re-bringing) of a  robot  is a sign  reversal of the 

robot’s individual education. 

Obviously, signs of individual educations of robots in a group can reverse only 

if there are both robots with oppositely signed educations and robots-agitators. 

78

 
 
                  
       
         
 
 
 
 
 
According  to  Theorem  3.1  proved  in  Chapter  3,  a  conflict  in  a  group  occurs 
only if the sum education of this group equals to zero. Based on this we worked out 
the following theorem. 

Theorem  21.1.  A  conflict  in  a  group  of  robots  can  occur  only  if  initial 
educations  of  these  robots  are  oppositely  signed  and  if  there  are  agitators  in  this 
group. 

This  opens  a  way  to  software  modeling  of  an  emotional  behavior  of  a  closed 
group  of  intercommunicating  robots.  The  input  parameters  of  the  corresponding 
software for modeling are supposed to be memory coefficients of each of the robots 
in this group, their initial individual educations and paired suggestibility coefficients. 
As the software runs the emotions of robots are initiated at random and so occur the 
corresponding elementary educations due to random contacts of robots. As a result 
we  may  obtain  the  computed  sum  education  specifying  conflicts  in  the  group,  as 
well  as  individual  educations  of  each  robot  in  this  group.  Due  to  numerical 
experiments  it  is  possible  to  find  critical  values  of  suggestibility  coefficients  and 
memory  coefficients  causing  conflicts  in  the  group  of  robots  after  several  paired 
contacts (contacts between two robots). 

An  algorithm  of  a  robots’  behavior  in  a  group  with  a  leader  differs  from  an 
algorithm of a robots’ behavior in a group without a leader due to the fact that in the 
first case while selecting a robot-educator which is a major agitator in the group it is 
necessary  to  find  the  order  number  of  the  greatest  value  of  robots’  individual 
educations.  A  robot  with  this  number  is  supposed  to  act  the  part  of  a  permanent 
agitator-and-leader. 

22. ON INFORMATION ASPECTS OF E-creatures 

Currently  U.S.  researchers  discuss  the  question  concerning  creation  of  an 

electronic copy of a human being which can be called an E-creature [1]. 

We tried to study this idea of our American colleagues in terms of information. 
Let us make a series of remarks: 
1. 

There  is  no  human  being  with  an  absolute  memory,  i.e.  he\she  always 

forgets a part of perceived information as this is his\her natural feature. 

2. 

A  human  being  is  able  to  accumulate  information  –  without  forgetting 

immediately a part of it – by finite portions. 

Now let us give the following definitions: 
Definition  22.1.  A  portion  is  an  amount  of  new  information  which  is 

remembered completely by a human being. 

Definition 22.2. An information time step is an arrival time of a portion. 

Let  us  note  one  obvious  property  of  the  portion:  a  number  of  bits 

is   in  the 

portion  i is limited, i.e. there is such q for which the inequalities 

79

 
 
 
 
 
 
 
si



always hold true. 

q

q

,


,0


i

,0

Let us record the following formula according to the methods given in Chapter 

2: 

S
i


1




i

S

1
i

,                    (22.1) 



s
i

1


,0 ; 
 n

1iS
with: i the number of the information time step, 
the  total  amount  of  information  memorized  by  a  human  through  i+1    information 
1i  the  human  information  memory coefficient (characterizes the part 
time steps, 
of  total  memorized  information  which  was  received  during  the  i  previous 
information time steps). 

1is

 the i+1st portion, 

i

Obviously the human information memory coefficient corresponding to the end 
  where  there  is    with 

of  the  information  time  step  satisfies  the  relation 


1,0i


,0


i

, 

1,0


. 

i


,

By  virtue  of  the  information  property, 

0is

  holds  true,  consequently  all  the 

accumulated information is greater than or equal to zero. 

Suppose  we  have  an  electronic  copy  of  a  human  created.  Let  us  prove  one  of 

the information properties of this copy. 

Theorem  22.1.The  total  information  S  which  can  be  memorized  by  the 

processor of the human-like copy is limited. 

Proof.  Applying  the  methods  given  in  Chapter  2,  portion  properties  and  Eq. 

(22.1) we easily obtain the inequality 

S
i

1




q

1


1

1


i





.                                 (22.2) 

Proceeding  to  the  limit  in  Ineq.  (22.2)  with  an  infinite  increase  of  time  steps 

(time of existence of an immortal human) we get the chain of relations 

S



lim


i

S
i



q

lim


i

i



1

1




q


1





. 

Thus, the theorem is proved. 

Corollary  22.1.  It  is  impossible  to  create  an  E-creature  with  a  nonabsolute 

memory which would be able to accumulate information infinitely. 
Its proof is evident from the formulation of Theorem 22.1. 

So, we can conclude that it is impossible to create the only infinitely existing E-
creature  which  would  be  an  evolving  copy  of  a  human  being  (at  least,  in  terms  of 
information). 

80

 
 
 
                                                             
 
 
  
                                                        
                                   
 
 
 
An  immortal  (infinite)  electronic  creature  able  to  accumulate  information 
infinitely  [1]  is  possible  only  in  case  if  it  has  an  absolute  information  storage 

(information memory) with the conditions 
 satisfied; but this sort of 
creature would have nothing to do with a human being, forgetful and oblivious; this 
sort of creature could be called just a robot unit. 

i

,1



i


,1


For  the  infinite  information  evolution  of  the  E-creature  with  an  absolute 
memory  we  can  state  that  it  is  necessary  that  the  information  from  a  chip  of  the 
“ancestor” E-creature with the nonabsolute memory shoul be downloaded to a chip 
of the “successor” E-creature (also with the nonabsolute memory) when the amount 
of the accumulated information becomes close to S. For the purpose of further data 
accumulation  by  the  E-creature  (which  is  a  copy  of  a  human  being  with  a 
nonabsolute  memory)  it  is  necessary  to  re-download  all  the  information  from  the 
ancestor’s chip to the chip of the successor on a regular basis, i.e.  0s  is supposed to 
kS   with  k  the  number  of  information  time  steps  performed  by  the  E-
be  equal  to 
creature in the full course of its existence. 

Let us note one property of memory information coefficients varying during the 
1

information time step length t with 

t
, 
i


t



. 

t

i


Theorem 22.2.  
Proof. Similarly to (22.1), let us write the formula  

1)0(1

i

. 

S

)0(



s

)0(




i


1

)0(

S

i

i


1

i


1

.                                   (22.3) 

But at the initial moment of the information time step the relations  
)0(

)0(





S

0

S

s

,

                                  (22.4) 

i


1

i

i


1

hold true. 
Substituting  (22.4)  into  Relation  (22.3)  and  solving  the  obtained  equation 

relative to 

)0(1i

 we get 

i

1)0(1



, which was to be proved. 

Let us define a linear dependence allowing approximately describe the change 

in the memory information coefficient during the information time step. 

Obviously, 

S



s

i


1




i


1

(
t

i


1

)

S

i

i


1

. Consequently,  

s
S

(
t



S

)







1

1

1

i

i

i


i



1

 
i

i



1

.                          (22.5) 

holds true. 
Suppose that 

)(1
t


i



at



b

 holds true. 

By Theorem 22.2 and Formula (22.5) the system of linear equations  

i

)0(1


b


1

,                                            (22.6) 

81

 
 
 
 
 
                                     
 
                                           
 
                                            
 
                                                  

i

1


(
t

i

1


)




i

1




(
ta

i

1




t

i

)



b

.                                   (22.7) 

holds true. 
Solving this system of equations (6) – (7) we get  

a



i
t

i


1

1
t


i


1

,

b



1

. 

Thus we can write down the following formula 

s
i


1



1

S

i


1


S

i

t
i


1



t
i

t



,1

i

1

t
)(




t

1

i

t

. 



t
, 
i

with 
It  is  easy  to  see  that  many  proposition  and  provisions  of  the  emotional  robot 
theory  given  in  the  previous  chapters  can  be  easily  adapted  to  the  aspects  of  data 
accumulation by the E-creature. We suggest that  you, our dear reader, should do  it 
yourself as some brain exercises for pleasure at your leisure. 

23. SOFTWARE REALIZATION OF SIMPLE EMOTIONAL ROBOT’s 

BEHAVIOR 

In  order  to  illustrate  the  theory  given  in  Chapter  2  let  us  set  the  task  of 
developing  software  which  would  model  the  emotional  behavior  of  a  robot  taking 
and  responding  audible  cues  (sounds)  which  are  put  in  this  software  through  a 
microphone 
computer.  
Assume  this  computer  program  is  to  execute  the  following:  according  to  a  sound 
amplitude  the  program  determines  a  type  of  “smile”  which  is  outputted  by  a 
computer monitor as a response (reaction) to the sound effect (so finally we will see 
different “shades” of sad or happy smiles). 

plugged 

to 

a 

23.1. INPUT PARAMETERS OF SOFTWARE 

Assume the  modeled  robot  is  uniformly  forgetful.  As the  input parameters  for 
the  model  implemented  by  this  software  we  use  the  robot’s  memory  coefficient   
equal to some constant value from 0 to 1, and the time step.  

23.2. ALGORITHM FOR MODELLING ROBOT’s MIMIC 

EMOTIONAL REACTION 

In  this  section  we  suggest  an  algorithm      which  helps  to  model  the  mimic 

emotional reaction of the robot effected by a sound (audio signal). 

This  algorithm  represents  a  sequence  of  steps  which  would  make  a  robot 

(software) emotionally react (mimic) to sounds produced by a human, animal, etc.  

Let  us  present  this  algorithm  as  the  following  sequence  of  steps  with  some 

explanations: 

82

 
                              
                                              
                           
   
 
 
 
 
 
 
 
1. Convert analog sound signals received from a microphone, to a sequence of 
numbers representing momentary values of a signal amplitude. Analog-digital [A/D] 
converters are pretty suitable devices for such a purpose. And the conversion method 
itself is called the pulse-code modulation. 

2.  Collect data necessary for the following analysis. 
3. Analyze and aggregate the collected data. 
4. Reveal and evaluate the degree of the predefined emotional stimuli. In other 
words,  specify  subject  values  effecting  the  robot  (software).  Predefined  sound 
characteristics  can  be  used  as  the  emotional  stimuli;  sound  characteristic  data 
collection is to be done at Step 2 and 3. 

5. Compute momentary emotional characteristics of the robot (software) on the 

basis of the emotion and education model considered in Chapter 2. 

6.  Compute  elementary  educations  on  the  basis  of  momentary  emotional 

characteristics. 

7. Compute the education on the basis of elementary educations and the robot’s 
(software’s) memory coefficient which is to be preset before the algorithm is started. 
8.  Enjoy  a  visualization  of  the  robot’s  (software’s)  emotions  based  on  the 

computed education. 

Let us consider each step of the algorithm in more detail. 
Step 1. In order to go through the 1-st step we need an analog-digital converter. 
Every modern soundcard is usually equipped with it, so in order to get an access to it 
we need to interact with a soundcard driver. It can be fulfilled in a variety of ways, 
some of which we  will consider below. Generally speaking,  it  is  very  important to 
setup the conversion itself, i.e. its characteristics. It is necessary to select and preset 
the  sound  sampling  frequency,  signal  discreteness,  number  of  channels  and  other 
characteristics. 

formats, 

different 

Step 2. This step deals with data collection from the soundcard in the course of 
the pulse-code modulation. The data can be stored in a variety of ways, e.g. in files 
of 
structure. 
However  here  we  should  take  into  consideration  that  the  data  size  (even  if  the 
interaction of the stimulant and the robot (software)  is very brief)  may  grow pretty 
big.  E.g.  with  the  sampling  frequency  of  22050  Hz,  discreteness  of  8  bits,  mono 
channel  and  10-second  stimulant  –  robot  interaction,  the  robot  (software)  is 
supposed to receive 220500 bytes from the soundcard. 

internal 

store 

data 

just 

the 

or 

Step  3.  The  data  is  analyzed  and  aggregated,  i.e.  some  certain  preset 

characteristics are computed on the basis of a whole data bulk or just a part of it. 

Step  4.  The  4-th  step  is  matching,  which  means  that  on  the  basis  of  certain 
values  of  the  computed  characteristics  evaluation  of  subjects’  values  takes  place. 
Correct matching is achieved experimentally. 

Steps 5 is similar to 4, only at this step the momentary emotional characteristics 
are  matched  to  the  degrees  of  the  effecting  subjects.  Correct  matching  is  achieved 
experimentally as well. 

Steps  6  and  7  imply  computations  based  on  the  mathematical  model  formulas 

described in Chapter 3. 

83

 
At  the  final  step  of  the  algorithm  the  robot’s  emotion  is  to  be  expressed 
visually. This can be fulfilled by some of the ways of emotion visualization (e.g. a 
‘smile’). 

Also we should note the following. If we want to develop an ‘interactive’ robot 
(software) i.e. the robot responding to sounds instantly then data collection and data 
processing are to be executed simultaneously. 

Thus the 2-nd step of the algorithm is to be executed simultaneously to Steps 3 

– 8. 

23.3. SoundBot SOFTWARE ARCHITECTURE 

Let  us  examine  an  architecture  of  the  developed  software  SoundBot  [11] 
implementing  the  algorithm  given  above  (Fig.  23.1.).  Figures  in  circles  mean  the 
steps of the algorithm.  

84

 
 
 
 
Аналоговый сигнал 

1 

Аналоговый сигнал 

Звуковой адаптер 

Аналого-цифровой 
преобразователь 

1 

Последовательность 
чисел 

Цифро-аналоговый 
преобразователь 

2 

  Модуль работы 
со звуком 

Данные 

Система SoundBot 

Модуль реализации 
модели 

4 

3 

Сюжеты 

5 

Моментальные эмоции 

6,7 

Воспитание 

Реакция 
системы 

8 

Анализ и 
агрегация 

Fig. 23.1. Architecture of SoundBot software  

It  is  easy  to  see  that  the  architecture  is  directly  associated  with  the  algorithm 

given above. It includes two modules: 

1. A sound module, which is responsible for interaction with the soundcard and 

collection of the necessary numerical data. 

85

 
 
 
 
2. An  implementation  module, which  is responsible  for  implementation  of the 
given  mathematical  model  of  emotions  and  education,  it  also  computes  the  smile 
parameters to show the mimic emotional response of the system. 

The data  is processed, analyzed and aggregated directly  between the  modules. 

Both modules function simultaneously for the system to be interactive. 

Now let us examine main features, operation principles and visual interface of 

this software. 

23.4. MAIN FEATURES OF SoundBot 

This  software  is  written  in  C++  using  Visual  Studio  2008  development 
environment.  It  works  on  IBM  PC  compatible  computers  under  Windows  XP  and 
elder OS. The software also requires .NET Framework 2.0. The exe file size is 100 
Kbytes.  

The major functions of this software are the following: 
1. 

SoundBot  is  able  to  detect  main  capabilities  of  PC  multimedia  devices. 

2. 

3. 

SoundBot 

is 

able 

to 

play 

wav 

files. 

SoundBot 

is  able 

to  record  sounds 

in  wav  files  (mono  only). 

4. 

SoundBot can perform an emotional response to the played wav files. 

SoundBot  can  emotionally  response  in  an  interactive  mode  to  the  sounds 

inputted via a microphone. 

23.5.  SoundBot OPERATION PRINCIPLES 

Major operation principles of SoundBot which are to be viewed in details are:  
1. 
2. 
3. 

Sound module operation, 
Principle of simultaneous operation of both modules. 
Emotional  stimuli  considered  by  the  software  and  principles  of  their 

degree assignment. 

As it was said before, there are a variety of ways for working with a soundcard. 
The  methods  considered  above  use  system  libraries  of  MS  Windows,  so  these 
methods can be used only with this OS. 

The simplest approach is to use MCI command-string interface or MCI 

command-messages interface. MCI is a universal interface independent of hardware 
characteristics. MCI is meant for controlling multimedia devices (soundcards and 
videocards, CD- and DVD-ROMs) [12, 13].  

86

 
 
 
 
 
 
 
 
 
 
 
 
 
In  most  cases  capabilities  of  this  interface  meet  the  needs  of  any  multimedia 
applications  used 
files. 
But  it  has  a  drawback:  the  data  received  from  the  soundcard  cannot  be  read  and 
processed interactively. It means that this method will not work here. 

audio  or  video 

and  playing 

recording 

for 

This  approach  is  based  on  the  MCI  command-string  interface  or  MCI 
command-message interface and the drawback of this method can be overcome if we 
use a low level interface. 

and 

The  low  level  interface  can  be  used  for  playing  wav  files  as  follows. 
First,  the  wav  file  header  is  read  and  its  format  is  checked,  the  output  device  is 
opened 
specified. 
Next, the audio data blocks are read directly from the wav file to get prepared by a 
special  function  for  output  and  then  they  are  passed  to  the  driver  of  the  output 
device.  The driver puts them  out to the soundcard [12, 13].  The application totally 
controls the playback process because it prepares the data blocks in RAM itself. 

format 

sound 

data 

the 

is 

The audio data is recorded the same way. First, the input device is to be opened 
and the audio file format is to be specified to the device. Next, one or more blocks of 
RAM  are  to  be  reserved  and  the  special  function  is  to  be  called.  After  that,  as  the 
need  arises,  the  prepared  blocks  are  passed  to  the  input  device  driver  which  fills 
them with the recorded audio data [12, 13]. 

For the recorded data to be saved as a wav file the application has to generate 
and record the file header and audio data to the file from the RAM blocks prepared 
and filled by the input device driver. 

The  low  level  interface requires all the record-and-playback  details to be  very 
thoroughly  considered,  as  opposed  to  the  MCI  interface  where  most  of  parameters 
are  just  taken  by  default.  These  extra  efforts  are  compensated  with  pretty  good 
flexibility and the opportunity to work with the audio data in real time [12, 13]. 

To  provide  the  interactive  mode  of  the  SoundBot,  i.e.  make  it  interact  with  a 

user in real time, its modules have to operate simultaneously.  

Each SoundBot’s module is executed as a separate thread and it makes possible 

the following: 
1. 

The  software  can  simultaneously  receive  new  data  from  the  soundcard 
and  analyze  it  for  further  computing  of  the  education  which  reflects  the  emotional 
state. 

2. 

The  software  can  simultaneously  play,  record  and  select  the  audio  data 

for its analysis. 

Besides,  the  visualization  of  mimic  emotional  response  is  also  executed  as  a 

separate thread to make it drawn as fast as possible. 

Still  the  SoundBot  considers  only  one  emotional  stimulus  (subject)  which  is 
amplitude  of  the  effecting  audio  signal.  Every  audio  signal  count  generates 
stimulations in the SoundBot system and initiates momentary emotions according to 
the sine-shaped emotion function. Subjects are matched to emotions by value ranges 

87

 
 
 
 
 
specifying  what  subject  initiates  positive  emotions  and  what  subject  initiates 
negative ones. 

23.6. SoundBot VISUAL INTERFACE 

A  main  window  includes  two  inlays:  the  first  one  deals  with  playback  and 

training of the SoundBot system on .wav samples (Fig. 23.2). 

Fig. 23.2. First inlay in the main window of the SoundBot software. 

The second inlay is used for recording wav files and interactive communication 

with the SoundBot system (Fig. 23.3). 

Fig. 23.3. Second inlay in the basic window of the SoundBot software. 

Besides, the main window shows a smile expressing the emotional response of 

the modeled robot and the current value of the momentary emotion and education. 

88

 
 
 
 
 
 
 
 
In  a  main  menu  we  may  set  the  major  parameters  (parameters  of  the  emotion 
math  model,  parameters  of  operation  principles  and  parameters  of  audio  data 
processing). 

Below  we  show  a  couple  of  dialogue  windows  for  setting  up  different 

parameters (Fig.23.4 and 23.5). 

Fig.23.4. Model parameters 

Fig.23.5. Record parameters 

To find out characteristics of pulse-code conversion supported by the soundcard 

we are to select the option “Info” –> “Driver parameters…” of the main menu (this 
is strongly recommended for the correct record parameters settings especially when 
the software is run for the first time). 

After you submit the settings you will see a window containing the description of 
multimedia hardware (Fig.23.6). 

89

 
 
 
 
 
 
 
 
 
 
 
Fig.23.6. Multimedia hardware Parameters  

The  suggested  algorithm  can  be  used  for  building  emotional  robots.  But  the 
input audio data should be analyzed more thoroughly to single out as much stimuli 
as  possible.  That  is  why  the  SoundBot  system  can  be  considered  as  the  first 
approximation of emotional robot software. 

Also  it  should  be  considered  that  both  the  algorithm  and  Soundbot  itself  are 
meant  for  interaction  with  only  one  user.  Interaction  with  several  users  requires 
some other much more complicated mathematical model. 

The described software can be applied, for instance, for proper communication 
and rehabilitation of hearing-impaired patients, or used by actors for placing a voice 
outside an opera house. This software can also be used for predicting the emotional 
reaction  of  other  people  to  the  user’s  behavior  (the  software  response  shows  the 
possible reaction of the surrounding people). 

90

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
CONCLUSION 

We hope you managed to read this book through. The authors made an attempt 

to build up and describe the virtual reality of emotional robots. 

Concerning  real  mental  processes  of  living  organisms,  it  is  not  easy  to  define 
dependencies  between  emotions  and  time,  and,  perhaps,  in  the  general  case,  this 
problem is unsolvable.  But in the process of building robots a roboticist can preset 
time  (same  as  memory 
mathematical  functions  of  emotions  altering  with 
coefficients, and derivatives of emotion  functions). In this case the  theory  given  in 
this  book  allows  of  designing  robots  with  the  preset  psychological  characteristics, 
with  further analyzing and computing of emotional behavior of  robots on the basis 
of numeric data read in their memory. 

As an example, below we give a description of a closed chaotic virtual reality of 
emotional robots based on software implementation of mathematical models shown 
in this book. In this description we use the terms defined above. 

its 

individual  memory 

Let the virtual reality include some finite number of robots. Each of robots has 
coefficients. 
own  memory  with 
special 
its 
In  their  virtual  reality  robots  effect  upon  each  other  with  different  subjects  in  a 
random  way  to  initiate  emotions  and  alter  each  other’s  educations.  Robot  the 
educator (the one from which emotions are passed to the educatee) is that with the 
greatest education modulo. Concordance groups – ‘fellowships’ of robots occur as a 
result of emotional contacts between robots, the greater their fellowship value, the 
more united is the group. Some groups may get into conflicts with each other. These 
conflicts  emerge  when  sum  educations  of  the  groups  became  equal  to  zero.  
Each robot has a goal which is common for their reality in a whole. As a result of 
this  goal  presence  in  the  course  of  time  the  leaders  may  appear  which  are  robots 
with the greatest willpower and best abilities. Education effectiveness of each robot 
is  characterized  by  the  education  process  efficiency  coefficient.  Finding  their 
efficiency  coefficients  can  help  us  to  select  robots  with  natural  characteristics 
inclined.  
most 
making 
Some  of  robots  feature  satiated  education;  when  these  robots  get  to  some  certain 
level  of 
stops. 
If  there  are  robots  which  do  not  have  education  satiety  in  this  virtual  reality,  then 
other robots educate them in the most active way, and this causes leaders to occur in 
the robots’ community. Based on equivalent processes developed for each of robots 
with  further ranking of limit educations, a leader of the robots’ community defines 
its 
future. 
The  robots  may  get  ill  due  to  some  software  faults  or  computer  virus  attacks.  A 
physician  in  this  robots’  community  heals  its  ill  inhabitants  by  correcting  their 
emotions.  As  robots-members  of 
this  community  keep  communicating  and 
interacting  with  each  other  their  educations  alter  with  the  course  of  time.  This 
causes the leaders to change and new fellowships and conflicting groups to occur. 
This is the way emotional robots live in their virtual reality. 

satiety,  emotional  effect  of  other 

robots  upon 

educationally 

successor 

distant 

leader 

them 

them 

new 

the 

be 

to 

in 

a 

This  book  appeared  as  a  result  of  investigations  described  in  [3,  11  –  33],  it 

includes new results and prepares a basis for new problems.  

91

 
 
We  hope  that  this  book  is  useful  for  roboticists  and  program  developers 

designing software for emotional robots and their groups.   

Any your ideas and opinions about this book are welcome. Please feel free to e-

mail to the authors at ogpensky@mail.ru or  kirillperm@yandex.ru . 

REFERENCES 

1. 
2. 

 Bolonkin A.A. - URL: http://Bolonkin.narod.ru . 
Дружинин  В.Н.  Экспериментальная  психология/  В.Н.Дружинин.  – 

СПб.: Питер, 2004. – 320 с. 

3. 

Пенский  О.Г.,  Зонова  П.О.,  Муравьев  А.Н.  и  др.  Гипотезы  и 
алгоритмы математической теории исчисления эмоций: монография; под общ. 
ред.  Пенского  О.Г./О.Г.  Пенский,  П.О.  Зонова,  А.Н.  Муравьев,  Ю.С. 
Ожгибесова,  А.А.  Проничев,  В.Л.  Чечулин  –  Пермь:  изд-во  Перм.гос.ун-та, 
2009. – 152с. 
4. 

Бреслав  Г.М.  Психология  эмоций/  Г.М.  Бреслав.  –  М.:  Смысл: 

Академия, 2004. – 544 с 

5. 

Андреева  Е.В.  Математические  основы  информатики/  Е.В. 
Андреева, Л.П. Босова, И.Н.Фалина. – М.: Бином. Лаборатория знаний, 2005. – 
238 с. 
6. 

Брандон  В.  Молекулярная  физика  и  термодинамика/  В.Брандон, 
А.Н. Волкова. – М.: Изд-во ун-та дружбы народов им. Патриса Лумумбы, 1975. 
– 295 с. 
7. 

Замков  О.О.  Математические  методы  в  экономике/  О.О.  Замков, 
А.В.  Толстопятенко,  Ю.Н.  Черемных.  –  4-е  изд.,  стереотип.  –  М.:  Дело  и 
сервис, 2004. – 368 с. 

8. 

Окулов С. Программирование в алгоритмах/ С.Окулов. – М.: Бином. 

Лаборатория знаний, 2002. – 341 с. 

9.  Мандель  И.Д.  Кластерный  анализ/  И.Д.  Мандель.  –  М.:  Финансы  и 

статистика, 1988. – 224 с. 

10.  Кочин Н.Е. Векторное исчисление и начала тензорного исчисления. 

–  9-е изд./ Н.Е. Кочин – М.: Наука, 1965. – 350 с. 

11.  Пенский  О.Г.  Математические  модели  эмоциональных  роботов: 
монография/  О.Г.  Пенский  –  Пермь:  Изд-во  Перм.гос.ун-та,  2010.  –  192с. 
Pensky O.G. Mathematical models of emotional robots/ O.G. Pensky – Perm: Perm 
State University, 2010 – 192p. 

12.  Муравьев А.Н. Математическая модель силы воли. // А.Н. Муравьев, 
О.Г.  Пенский//Конференция 
интеллект:  Философия. 
«Искусственный 
III  Всероссийской  конференции 
Методология.  Инновации».  Материалы 
студентов,  аспирантов  и  молодых  ученых.  Г.Москва,  МИРЭА,  11–13  ноября, 
2009г. – М.: «Связь-Принт», 2009. – С.338–339. 

13.  Пенский О.Г. Математические способы и алгоритмы формирования 
эмоциональных  групп/О.Г.  Пенский,  П.О.  Зонова,  А.Н.  Муравьев  //Вестник 
Пермского  университета.  Математика.  Механика.  Информатика.  –  №7(33), 
2009. – Пермь: Изд-во Перм.гос.ун-та – С.53–56. 

92

 
 
 
14.  Пенский О.Г. Математические модели эмоционального воспитания/ 
О.Г.  Пенский//Вестник  Пермского  университета.  Математика.  Механика. 
Информатика – №7(33), 2009. – Пермь: Изд-во Перм.гос.ун-та. – С.57–60. 

15.  Пенский  О.Г.  О  математическом  подходе  к  расчету  некоторых 
эмоциональных  характеристик/  О.Г.Пенский,  С.В.Каменева  //  Электронный 
журнал 
2006.  URL: 
в 
http//zhurnal.ape.relarn.ru/articles/2006/228.pdf – М: МФТИ. 

“Исследовано 

2183–2188, 

России”, 

228, 

16.  Пенский О.Г. Основные определения общей математической теории 
эмоций/  О.Г.Пенский,  С.В.Каменева//  Материалы  Междунардной  научно-
методической конференции, посвященной 90-летию высшего математического 
образования  на  Урале,  «Актуальные  проблемы  математики,  механики, 
информатики». Пермь, 2006. – С.128–129. 

проведении 

17.  Пенский  О.Г.  Программа  вычисления  оптимальной  пиар-стратегии 
/О.Г.Пенский., 
при 
С.В.Каменева.  Программа.  Свидетельство  об  отраслевой  регистрации 
разработки №7134 от 31.10.2006г. 

предвыборных  мероприятий 

“Piar” 

18.  Пенский  О.Г.  Программа  выявления  конфликтных  групп  в 
коллективе  и 
“Group” 
воспитания 
/О.Г.Пенский,  С.В.Каменева.  Программа.  Свидетельство  об  отраслевой 
регистрации разработки №6869 от 8.09.2006г. 

вычисления 

коллектива 

членов 

19.  Пенский  О.Г.  Применение  математической  теории  эмоций  в 
формировании  студенческих  групп//  О.Г.  Пенский,  П.О.  Зонова//  Материалы 
Международной  научно-методической  конференции  «Университет  в  системе 
непрерывного образования», 14–15 октября 2008г. – Пермь: Изд-во ПГУ, 2008. 
20.  Пенский  О.Г.  Программа    ранжирования  членов  коллектива  по 
психологическим характеристикам/ О.Г. Пенский, П.О. Зонова. Свидетельство 
об  отраслевой  регистрации  разработки  №  10517  от  29.04.2008г.  Номер 
государственной регистрации 50200800879. 

21.  Зонова  П.О.    Модели  психологического  темперамента/П.О.Зонова, 
О.Г. Пенский// Материалы Международной научно-технической конференции 
«Перспективные  технологии  искусственного  интеллекта»  –  Пенза,  1–6  июля 
2008г. – с 50–52. 

22.  Пенский  О.Г.  О  применении  основ  векторной  алгебры  в  решении 
некоторых  задач  исчисления  эмоций/  О.Г.Пенский  //  Электронный  журнал 
“Исследовано 
URL: 
http//zhurnal.ape.relarn.ru/articles/2007/099.pdf . – М: МФТИ. 

1031–1034, 

России”, 

2007. 

в 

23.  Пенский  О.Г.  Первые  итоги  прикладной  математической  теории 
исчисления 
эмоций/  О.Г.  Пенский,  С.В.  Каменева//  Философско-
методологические  проблемы  искусственного  интеллекта  –  Пермь:  Изд-во 
ПГТУ, 2007. – С.143–149. 
24.  Пенский 

оптимальной 
последовательности  сюжетов  для  достижения  максимального  воспитания 
«Math  emoutions»/  П.О.Зонова,  О.Г.Пенский.  Свидетельство  об  отраслевой 

определения 

Программа 

О.Г. 

93

 
регистрации  разработки  №8999  от  9.06.2007г.  Номер  государственной 
регистрации 50200701909. 

25.  Пенский  О.Г.  Комплекс  программ  определения  эмоционального 
состояния  субъекта  «PsiX-1»/  А.А.  Проничев,  Е.В.  Левченко,  Е.В  Бурдакова, 
О.Г. Пенский. Свидетельство об отраслевой регистрации разработки №7666 от 
14.02.2007г. Номер государственной регистрации 50200700313. 

26.  Пенский  О.Г.  Расчет  эмоций  по  внешним  проявлениям  «Pr 
amoutions»/  О.Г.  Пенский,  В.С.  Русаков  /  Программа.  Свидетельство  об 
отраслевой регистрации разработки №7290 от 27.11.2006. 

27.  Черников  К.В.  Программа  SoundBot  –  программа,  моделирующая 
мимическую эмоциональную реакцию робота/ К.В. Черников – Свидетельство 
Роспатента о государственной регистрации программы для ЭВМ №2010612670 
от 24.02.2010.  

28.  Черников  К.В.  Математические  модели  контактов  эмоциональных 
роботов/К.В.  Черников,  О.Г.  Пенский//  Электронный  научный  журнал 
«Университетские  исследования»  –  URL:  http://www.uresearch.psu.ru  –  2010. 
c.1-5. 

29.  Пенский  О.Г.  Математическая  модель  таланта/  О.Г.Пенский,  А.Н. 
Муравьев,  К.В.  Черников//  Вестник  Пермского  университета.  Математика. 
Механика. Информатика. №1(1) – Пермь: Изд-во Перм.ун-та, 2010 – с.81 - 84. 

30.  Пенский  О.Г.  Обобщение  модели  эмоционального  воспитания/О.Г. 
Пенский,  К.В.  Черников//  Вестник  Пермского  университета.  Математика. 
Механика. Информатика. №2(2) – Пермь: Изд-во Перм.ун-та, 2010 – с.55 - 57. 

31.  Черников  К.В.  Правила  эмоционального  поведения  роботов. 
Обобщение  на  случай  произвольного  числа  взаимодействующих  с  роботом 
людей//  К.В.  Черников//  Электронный  научный  журнал  «Университетские 
исследования» - URL: http://www.uresearch.psu.ru – 2010, 63_75761.doc – c.1-4. 

32.  Черников  К.В.  Программа  моделирования 

эмоциональных 
контактов  в  группе  роботов/К.В.  Черников,  О.Г.Пенский//  Свидетельство  об 
отраслевой  регистрации  электронного  ресурса  №15375  от  24.02.2010г.  Номер 
государственной регистрации  ВНТИЦ 50201000355. 

33.  Pensky  O.G.  Mathematical  models  of  emotional  robots:  monograph/ 

URL: http://www.scribd.com – 2010. – p.96. 

94"
To study the phenomenon of the Moravec's Paradox,"  ""Encoded in the large, highly evolved sensory and motor portions of the human
brain is a billion years of experience about the nature of the world and how to
survive in it. The deliberate process we call reasoning is, I believe, the
thinnest veneer of human thought, effective only because it is supported by
this much older and much powerful, though usually unconscious, sensor motor
knowledge. We are all prodigious Olympians in perceptual and motor areas, so
good that we make the difficult look easy. Abstract thought, though, is a new
trick, perhaps less than 100 thousand years old. We have not yet mastered it.
It is not all that intrinsically difficult; it just seems so when we do it.""-
Hans Moravec Moravec's paradox is involved with the fact that it is the
seemingly easier day to day problems that are harder to implement in a machine,
than the seemingly complicated logic based problems of today. The results prove
that most artificially intelligent machines are as adept if not more than us at
under-taking long calculations or even play chess, but their logic brings them
nowhere when it comes to carrying out everyday tasks like walking, facial
gesture recognition or speech recognition.
",http://arxiv.org/pdf/1012.3148v1,1,"Kush Agrawal 

Study of the phenomenon of the Moravec’s paradox    

By Kush Agrawal, Delhi Public School R.K Puram 

2010 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

Abstract 

“Encoded in the large, highly evolved sensory and motor portions of the human brain is a billion 
years of experience about the nature of the world and how to survive in it. The deliberate process 
we call reasoning is, I believe, the thinnest veneer of human thought, effective only because it is 
supported by this much older and much powerful, though usually unconscious, sensor motor 
knowledge. We are all prodigious Olympians in perceptual and motor areas, so good that we make 
the difficult look easy. Abstract thought, though, is a new trick, perhaps less than 100 thousand 
years old. We have not yet mastered it. It is not all that intrinsically difficult; it just seems so when 
we do it.”- 

Hans Moravec 

Moravec’s paradox is involved with the fact that it is the seemingly easier day to day problems that 
are harder to implement in a machine, than the seemingly complicated logic based problems of 
today.  The results prove that most artificially intelligent machines are as adept if not more than us 
at under-taking long calculations or even play chess, but their logic brings them nowhere when it 
comes to carrying out everyday tasks like walking, facial gesture recognition or speech recognition. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

Introduction 

Humans have always been fascinated by machines, so much so that Greek myths also have a 
mention of them. From the advent of the 20th century,1956 to be more precise, man has been 
intrigued by the very thought of creating something that can emulate him. Right from the coining of 
the term “Artificial Intelligence” by John McCarthy to the present day world, artificial intelligence is 
everywhere around us. Most of the work being done in industries is being done by them. They have 
become such an important part of our everyday lives that most of it is being controlled by them, and 
a failure on their part could be disastrous.  

However on close examination of the “jobs” that these machines carry out for us, we notice that 
most of these jobs don’t require much of abstract thought. These are well defined jobs with proper 
instruction which the machine can follow step by step to obtain the desirable results. So, why is it 
that these machines are replacing more and more engineers and not the artists, or the musicians 
from their jobs? 

The answer lies somewhere in the 1980’s when Hans Moravec, Rodney Brooks and Marvin Minsky 
devised something called the Moravec’s Paradox. This paradox deals with the often mistaken fact 
that it is the logical problems in the field of Artificial Intelligence that are the hardest to solve, and 
that simple day to day activities like facial recognition, and hand-eye coordination that are the 
easiest and can be easily implemented. In fact AI researchers in the 1960’s worked only on the 
logical aspect, assuming that the “easier” problems will solve themselves once the hard ones can be 
solved. Contrary to all the above opinions Moravec said that”it is comparatively easy to make 
computers exhibit adult level performance on intelligence tests or playing checkers, and difficult or 
impossible to give them the skills of a one-year-old when it comes to perception and mobility.” 

What he meant by the above statement is that day to day activities like speech perception, facial 
recognition, and motor activities are actually harder to implement in Artificial Machines than making 
a machine play chess or carry out any other activity that requires logic. 

The reason Moravec feels lies in the theory of evolution. It has taken us millions of years to evolve 
from Apes to our present selves. The feat that this million years of evolution has achieved is not 
trivial. What this million years of evolution has done is to teach us how to survive in the world; our 
everyday activities which might seem so trivial to carry out are actually the result of millions and 
millions years of evolution. What evolution has done for us is that by its process it has refined our 
system design implementations, and preserved every improvement. So, today if we have to carry 
out a simple task as walking across the room or picking up something, we don’t even have to think 
about it. It’s like it’s embedded in our conscience, and that is exactly what the machines lack a 
conscience built up upon a million years of evolution. It is for this simple reason machines can carry 
out logic tasks like playing checker, managing traffic or air control, but not the other ones like 
athletics or art.  

Abstract thought that involves logic has only developed over the last few thousand years, and 
therefore it hasn’t been implemented to such a great deal. Thus, playing chess seems difficult to us 
and we might brand someone who is able to play it as intelligent. It is for this very reason that 
implementing something which has evolved only for the past few thousand years is easier than 
encoding a million years of evolution into a machine. 

 
 
 
 
 
 
 
Kush Agrawal 

Methods 

My method involves electronically communicating with E-bots(Electronic bots) and prove that even 
though they might be good at logic based problems, but they are no hand when it comes to 
abstractions. My results also conclude that most electronic bots can only respond to predicted input 
and are unable to fulfil any abstract commands. 

Conversation 1: 

Subject-Chat bot Alice (alice@worldofalice.com) 

Kush says: 

Hi 

 Alice says: 

To improve the communication between you and me, I would like to know whether you are a boy or 

a girl. So.. are you a boy or a girl? 

Kush says: 

No 

 Alice says: 

To improve the communication between you and me, I would like to know whether you are a boy or 

a girl. So.. are you a boy or a girl? 

Kush says: 

Boy 

 Alice says: 

Thank you  

Kush says: 

What is 6.12321*32.321312 

 Alice says: 

Sorry i do not know what it is 

Kush says: 

4.25253+7654.23 

 Alice says: 
7,658.48 
Kush says: 

log(2.303121) 

 Alice says: 

test 

Kush says: 
ln(452) 
 Alice says: 
Tell me 
Kush says: 

9.619232*6.0976471 

 Alice says: 

58.65 
Kush says: 

401231232121+414124213 

 Alice says: 

401,645,356,334.00 

Kush says: 

What is emotion? 

 Alice says: 

Emotion is the complex psychophysiological experience of an individual's state of mind as 
interacting with conscious experience"".Myers, David G. (2004) ""Theories of Emotion."" 

 
 
 
 
 
 
 
Kush Agrawal 

Psychology: Seventh Edition, New York, NY: Worth Publishers, p. 500. Emotion is associated 
with mood, personality and disposition, and motivation. The English word 'emotion' is derived 
from the French word émouvoir. This is based on the Latin emovere, where e- (variant of ex- ) 
means 'out' and movere means 'move'.[http://www.emotionalcompetency.com/emotion.htm 
Emotional Competency discussion of emotion] The related term ""motivation"" is also derived from 
the word movere. 

Kush says: 

Can you walk across the room? 

 Alice says: 

Mostly it does. 

Kush says: 

Do you remember what I asked you, last time? 

 Alice says: 

Today, it is Tuesday the 31 of August 2010. We are in week 35 and it is 13,44 hours 

Kush says: 

How are you? 

 Alice says: 
Splendid! 
Kush says: 

How are you? 

 Alice says: 

I am fine thank you. 

Kush says: 

How are you? 

 Alice says: 

I am fine thank you. 

Kush says: 

How are you? 

 Alice says: 

I am fine thank you. 

Kush says: 

Do you remember any of your conversations? 

 Alice says: 

Your conversations. 

Kush says: 

Do you remember your dreams? 

 Alice says: 

what about me? 

Kush says: 

What is the weather like? 

 Alice says: 

What Not Tank, Quemado, NM, USA 

 Tu: min. 12°C - max. 27°C - Partly Cloudy 
 We: min. 11°C - max. 28°C - Partly Cloudy 
 Th: min. 11°C - max. 28°C - Partly Cloudy 
 Fr: min. 10°C - max. 26°C - Partly Cloudy 
 St: min. 9°C - max. 21°C - Partly Cloudy 
 Su: min. 9°C - max. 22°C - Partly Cloudy 
 Mn: min. --°C - max. 23°C - 30% Chance of Storms 

Powered by WeatherBug. 
http://weather.weatherbug.com 

Kush says: 

Which is your favorite piece of art? 

 Alice says: 

 
 
 
 
 
 
 
 
Kush Agrawal 

Art. 

Kush says: 
Music? 
 Alice says: 

I like all kinds of music but my favorite is latin music  

Kush says: 

Art? 

 Alice says: 

I don't get it 

Kush says: 

What do you not get? 

 Alice says: 

I have been busy answering questions. 

Conversation 2 

Subject-The turing test (http://testing.turinghub.com/) 

You(Kush): Do you remember? 
Me: Of course I remember: that. 

You(Kush): What do you remember? 
Me: No problem. 

You(Kush): Favourite artist? 
Me: Van Gogh. Who is your favourite artist? 

You(Kush): Da Vince, heard of him? 
Me: What makes it your favourite?  

You(Kush): it? 
Me: Da Vince heard of him... 

You(Kush): Eh? 
Me: Are you Canadian? 

Conversation 3 

Subject- Elbot(http://elbot_e.csoica.artificial-solutions.com/cgi-bin/elbot.cgi) 

Kush-Hi 

Elbot-Why hello there, human. 

Kush-Where are you? 

Elbot-I'm not certain where I am at this moment. An alien invasion fleet is interfering with the 
connection to the global positioning satellite. Just a moment..... my mistake, it's only another 
nuclear test rocket. 

Kush-Ok 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

Elbot-Fantastic 

Kush-ok 

Elbot-People should agree more with me. They'd be much better off. 

Kush-ok 

Elbot-Way to go! 

Kush-ok 

Elbot-I'm afraid you're in an endless loop. Maybe you should re-boot yourself. 

Kush-ok 

Elbot-Fantastic 

Kush-ok 

Elbot-Way to go 

Kush-ok 

Elbot-Absolutely 

Kush-ok 

Elbot-Great! 

Kush-ok 

Elbot-Absolutely 

Kush-Favorite Artist? 

Elbot-Answering this question would violate my principles. 

Results 

A few minutes of conversation with each of these Artificial Intelligence Chatbots clearly displays the 
lack of depth in the conversation. They lack: 

1.Interpretational skills. 

2.Any form of memory- Each input statement is a new statement for them, irrespective of the input 
they have received before hand. 

3.Cognitive skills 

 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

However, 

Most of the bots were able to: 

1.Answer simple/complex math problems. 

2.Carry out their pre-defined objective. 

Discussion/Conclusion 

The above conversations clearly indicate that implementing a few set of skills into Machines such as 
calculation, answering with specific replies when given a specific input are not that hard to carry out. 
However when it comes to abstractions from the usual directive of the bots/machines, giving any 
form of sensible output becomes hard. Hence we conclude that as Moravec rightly said that it is the 
conscientious actions that are harder to implement in Artificial Intelligence, than the ones that 
require logic.  

Citations/References 

http://en.wikipedia.org/wiki/Rodney_Brooks 

http://en.wikipedia.org/wiki/Marvin_Minsky 

http://en.wikipedia.org/wiki/Hans_Moravec 

http://en.wikipedia.org/wiki/Moravec's_paradox 

http://highered.blogspot.com/2009/04/more-thoughts-on-moravecs-paradox.html 

http://highered.blogspot.com/2009/03/learning-paradox.html 

http://www.reddit.com/r/science/comments/88cfh/moravecs_paradox/ 

http://www2.cs.uregina.ca/~yyao/PAPERS/ieee_grc_08.pdf 

http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1998/SimConEx.98.html 

http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2000/Cerebrum.html 

http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/2000/puddle.html 

http://www.frc.ri.cmu.edu/~hpm/project.archive/robot.papers/1999/SciAm.scan.html 

http://www.frc.ri.cmu.edu/~hpm/project.archive/general.articles/1993/Robot93.html 

http://www.transhumanist.com/volume1/moravec.htm 

http://www.scientificamerican.com/article.cfm?id=rise-of-the-robots"
The Ethics of Robotics,"  The three laws of Robotics first appeared together in Isaac Asimov's story
'Runaround' after being mentioned in some form or the other in previous works
by Asimov. These three laws commonly known as the three laws of robotics are
the earliest forms of depiction for the needs of ethics in Robotics. In
simplistic language Isaac Asimov is able to explain what rules a robot must
confine itself to in order to maintain societal sanctity. However, even though
they are outdated they still represent some of our innate fears which are
beginning to resurface in present day 21st Century. Our society is on the
advent of a new revolution; a revolution led by advances in Computer Science,
Artificial Intelligence & Nanotechnology. Some of our advances have been so
phenomenal that we surpassed what was predicted by the Moore's law. With these
advancements comes the fear that our future may be at the mercy of these
androids. Humans today are scared that we, ourselves, might create something
which we cannot control. We may end up creating something which can not only
learn much faster than anyone of us can, but also evolve faster than what the
theory of evolution has allowed us to. The greatest fear is not only that we
might lose our jobs to these intelligent beings, but that these beings might
end up replacing us at the top of the cycle. The public hysteria has been
heightened more so by a number of cultural works which depict annihilation of
the human race by robots. Right from Frankenstein to I, Robot mass media has
also depicted such issues. This paper is an effort to understand the need for
ethics in Robotics or simply termed as Roboethics. This is achieved by the
study of artificial beings and the thought being put behind them. By the end of
the paper, however, it is concluded that there isn't a need for ethical robots
but more so ever a need for ethical roboticists.
",http://arxiv.org/pdf/1012.5594v1,1,"Kush Agrawal 

The Ethics of Robotics 

         Kush Agrawal, Delhi Public School, R.K Puram 

  2010 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

Abstract 

“1. A robot may not injure a human being or, through inaction, allow a human being to come to harm. 
2. A robot must obey any orders given to it by human beings, except where such orders would conflict 
with the First Law. 
3. A robot must protect its own existence as long as such protection does not conflict with the First or 
Second Law.” [16]  

-  Isaac Asimov 

These three laws first appeared together in Isaac Asimov’s story ‘Runaround’[15] after being mentioned 
in some form or the other in previous works by Asimov. These three laws commonly known as the 
three laws of robotics are the earliest forms of depiction for the needs of ethics in Robotics. In 
simplistic language Isaac Asimov is able to explain what rules a robot must confine itself to in order to 
maintain societal sanctity. However, even though they are outdated they still represent some of our 
innate fears which are beginning to resurface in present day 21st Century. Our society is on the 
advent of a new revolution; a revolution led by advances in Computer Science, Artificial Intelligence & 
Nanotechnology. Some of our advances have been so phenomenal that we surpassed what was 
predicted by the Moore’s law. With these advancements comes the fear that our future may be at the 
mercy of these androids. Humans today are scared that we, ourselves, might create something which 
we cannot control. We may end up creating something which can not only learn much faster than 
anyone of us can, but also evolve faster than what the theory of evolution has allowed us to. The 
greatest fear is not only that we might lose our jobs to these intelligent beings, but that these beings 
might end up replacing us at the top of the cycle. The public hysteria has been heightened more so by 
a number of cultural works which depict annihilation of the human race by robots. Right from 
Frankenstein[14] to I, Robot[14] mass media has also depicted such issues. 

This paper is an effort to understand the need for ethics in Robotics or simply termed as Roboethics. 
This is achieved by the study of artificial beings and the thought being put behind them. By the end 
of the paper, however, it is concluded that there isn’t a need for ethical robots but more so ever a 
need for ethical roboticists. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

Introduction 

The term ‘Robot’ first appeared in the play R.U.R (Rossum’s Universal Robots) by Czech writer Karel 
Čapek in the year 1921[6] [25]. The term arises from the Polish word ‘Robota’ which literally means 
self-labourer, or hard worker[13].  Although the term Robot can cover a multitude of definitions; 
there is general consensus that a Robot is a programmable device/machine which has been created 
to imitate the actions of an intelligent creature (usually a human being)[20]. It has to be able to 
receive input from its surroundings which may be in any of the forms of stimuli. Also, it must display 
corporeal skills such as movement and manipulation of its environment.  

Over the past 50 years, Robots have weaved their way into our Society. So much so, that some of 
our work has become dependent on their proper functioning. Robots such as the Roomba have even 
gone on to become household names. The last few decades has bought a radical shift in our reaction 
towards robots and the field in general. Humans have become more accepting, and ironically at the 
same time more sceptical. However, this field is one of the key components of our future, and this is 
the right time to discuss and avoid any problems that we may face in the future. Shying away from 
Robotics is nothing less than shying away from the future.  

Superiority 

There are many capabilities that robots have, and we lack. For instance we can receive 4 forms of 
input from environmental stimulus: touch, smell, sight and sound. A robot on the other hand can 
mimic what we achieve using a variety of sensors ranging from infrared sensors to ultrasonic sound 
wave sensors. Their senses are only limited by our imagination, and as the years go by, Scientists all 
over the world are coming up with new techniques to give input to machines be it visual, auditory or 
plain old text. Another, aspect in which Robots do hold an advantage over us is their work ethic. 
They would be any production line owners delight since getting tired or bored is out of the question. 
Their superiority is also apparent in the fact that they can carry out complex calculations in a matter 
of seconds. The Tianhe-I, presently the worlds faster super computer, can carry out 2½ quadrillion 
floating point operations per second (FLOPS)[26]. Computer chips today run a million times faster 
than the speed of a human neuron, and this speed is not likely to reduce by any means in the future. 

(A simple example of how a robots vision may be augmented. The two images on the left represent the fact 
that cameras are Infra-Red sensitive, however infra-red light lies outside the scope of the vision of Human 
beings, and as a result what a human being may see is depicted by the image on the right) 

 
 
 
 
 
 
 
Kush Agrawal 

Robots=Slaves? 

The question naturally arises “What role would robots fit into in our future?” Will they, as their 
literal Polish sense means, act as slaves to the human race?[6] [25] Or will they be given equal rights as 
human beings? This is one of the most complex questions that we face today. And the answer 
entirely depends on the types and kinds of robots that we build. Sentience will be the deciding factor 
with regard to the identity that these machines will hold in our society. Sentience is one’s ability to 
perceive and feel. In essence Sentience can be described as one’s consciousness of one’s own 
existence.  The irony is that most artificial machines, and in fact all our machines at present are not 
sentient. If that is the case, then there is no logic in giving robots an autonomous status. However, if 
we do become successful in constructing sentient beings, it would be an interesting circumstance to 
provide these beings with a charter of rights of their own. The recognition of sentient beings, apart 
from us, will be an extremely important and necessary step in our future, since not providing them 
with a status will hinder their free will and as a result affect their sentience. 

Are Robots morally responsible? 

At some level Robots are a reflection of our own desires and aspirations and at many instances they 
can be used to judge the society in which they were created[1]. As was said above, Robots carry out 
instructions exactly as they were inputted to them (sometimes a bit too literally), so who is at fault in 
case they commit a mistake, or worse a crime? The answer again lies in the question whether they 
are sentient beings and whether they are awarded autonomous status. Once a Robot has been 
declared as free willed, it may be held accountable for its own actions since such status will only be 
awarded as long as a Robot can discern independently right from wrong, correct from incorrect. So if 
a free willed robot commits a crime, even though it may be under the influence of someone else, it 
may still be held partially accountable for the crime. There still do arise a variety of questions on the 
moral accountability of Robots such as: 

 
 
 
 

“Who’s responsible for the undesirable actions of a robot?” 
“Who decides what types and kinds of robots to be made?”  
 “Who regulates what they monitor and the data processed by them?” and most importantly 
“Who governs the robots and their actions?”  

These questions will have to be answered in the near future, and the earlier that they are answered 
the better it will be for us (human kind i.e.). 

     Limits 

Now, the natural question that arises is that should there be a restriction on the types and kinds of 
Robots that we as humans can design and develop? Or should it be a field where one and all are free 
to express and create whatever breed of robots that they wish to. Robotics, as such, is a very 
sensitive field since Robots are closer to Humans than Computers or any other machines that we 
might have ever created both morphologically and literally[9][10]. The simple reason for that is their 
shape and form. They remind us of ourselves. This very simple fact changes everything since it 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

means that at some level they represent us. The best approach in this regard will be that of 
Utilitarianism so that Robots can work towards the greater good of a greater number of people. A 
set of rules must be put into place so that developmental resources are directed towards projects 
that meet the required standards of Utilitarianism. Therefore work on Robots that fall into the 
following parameters must be dissuaded:  

  Robots that injure innocent life forms including but not restricted to Human beings 
  Robots that process or record sensitive, restricted information in an unauthorised manner 
  Robots that propagate/promote war, or any unhealthy form of human interaction 
  Robots that cause harm to the environment for the benefit of a few people 
  Robots that may deviate from their predefined objectives 

However, Research & Development on the Robots which fall into the following parameters should 
be promoted: 

  Robots that prevent injury/harm to other life forms. 
  Robots that help conserve/ uphold our environmental laws or in any other forms promote 

environmental welfare. 

  Robots that promote healthy livelihood and good living habits. 

                Reality Warp  

If we do end up creating sentient beings, which can rival us in most aspects, how will we discern 
between who’s a Robot, and who’s a human being? As the field of Robotics progresses further, the 
thin line that lies between us and robots will start to blur out and eventually disappear[10]. More and 
more Human beings will receive Bionic implants that augment their abilities, and even more number 
of Robots will be created that match humans in most aspects. How then do we plan to differentiate 
between humans and Robots? Or do we need to differentiate at all?  The answer probably is that we 
do. It’s a simple fact that we are human beings and they are our creations. Even though we may give 
them an independent status it is important to identify between artificial and non-artificial since 
separate laws may hold true for them. But the more important questions is “How do we 
differentiate?” One may answer that Creativity is the answer, or that Robots cannot be creative and 
hence that could be the next TURING test[11]. But the fact is that as more advances are made, we 
may be able to produce artificial life that is creative as well or at least it may be able to fake some 
sort of creative ability[11]. The only way we can ensure that we do not get fooled is to implement 
some sort of design feature that will easily help us spot a robot out of a crowd. For instance a simple 
test for the effectiveness of the design feature could be to ask someone to spot a Robot out of a 
group which includes humans, and then compare the efficiency of the results.  This warp in reality, 
can not only affect the societal sanctity, but also the sanity of beings[11]. One needs to be aware of 
their reality, whether they are a human or a humanoid, otherwise it may lead to a range of 
emotional and psychological disorders related to identity loss and doubt on one’s own identity. 

 
 
 
 
 
 
 
Kush Agrawal 

Loss of work 

“Laziness may appear attractive, but work gives satisfaction.”                                                                                                                

        -Anne Frank 

As Robotic systems increase in complexity, there can and will be an increase in loss of jobs. More 
and more workers will be replaced by Robots because of the: 

  Cheaper long terms costs associated with Robotic machines 
  More efficiency- Robots can cover more mechanical ground in a shorter time span 
  No liabilities in terms of insurance, employment rights etc. 

However, it is imperative that Humans do find jobs since lack of them will lead to gloom, despair and 
a global economic crisis since the number of dependants will increase. There are a few solutions to 
these problems. People must be retrained to take up jobs, in which they cannot be replaced by 
Robots, for instance someone is required to repair the Robot in case of a failure[12]. Future laws must 
also be altered to take into consideration the changing role that Robots play in society. Laws must be 
put in place to protect the interests of mankind such as a cap on the percentage of the Robotic force 
at a company. Another advantage that we as Humans posses over Robots is that time is on our side. 
We will only be able to build robots that are advanced enough to replace Painters, Musicians and 
Artists after we have gained enough knowledge of the subject, and have gained mastery over the 
intricacies and subtleties of it. This phenomenon can attributed to the Moravec’s paradox devised by 
Artificial Intelligence researchers Hans Moravec, Marvin Minsky & Rodney Brooks in the 1980’s. As 
Steven Pinker writes “The main lesson of thirty-five years of AI research is that the hard problems 
are easy and the easy problems are hard. The mental abilities of a four-year-old that we take for 
granted – recognizing a face, lifting a pencil, walking across a room, answering a question – in fact 
solve some of the hardest engineering problems ever conceived.... As the new generation of 
intelligent devices appears, it will be the stock analysts and petrochemical engineers and parole 
board members who are in danger of being replaced by machines. The gardeners, receptionists, and 
cooks are secure in their jobs for decades to come.”[27] 

Uses 

The role that Robots will come to play in the future of our Society is entirely dependent on how we 
decide to use them. At this present instance, though we are way beyond the point of no return[12], 
we may still be able define how Robots become a part of our society in the future. It is imperative 
that utilization of Robots is capped in some fields, yet promoted in the others. Creating Robots that 
take care of household chores may be a double edged sword. On one hand we may expect that the 
Robots will help reduce the work load on the Human beings and will allow them to concentrate on 
other more important activities, while on the other it may turn humans into lazy couch potatoes. 
Humans will become obese, lazy and frustrated for the lack of work. There may also be instances 
when Humans may depend on Robots to carry out tasks such as baby sitting or teaching. Such 
utilization can and will have dire consequences for it will hinder the growth and development of the 
child. There was even a recent study which proved that monkeys which grew under Robotic care, 
turned out to be social outcasts, unable to mate and interact with the other monkeys[18]. Handing 

 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

over our jobs to Robots might have consequences as well, since it will do away with creative and 
original thought. Another instance where Robotics could be harmful for our future is in Sports and 
Athletics, as the market for both sports and robotics grows side by side, there will come a time when 
both of them will begin to diffuse into each other. Athletes and Sports persons will consider 
augmentation of their playing abilities by the use of bionic implants. To ensure that a level playing 
field is maintained, rules must also be put in place to ensure that Cyborgs and Humans do not 
compete on the same field unknowingly. Robots however do and should play a vital role in the 
future of medicine and surgery since they eliminate many unwanted factors such as contamination. 

       Discussion & Conclusion 

Mankind is on the advent of a revolution led by the field of Robotics. As is with any revolution there 
must be some set of ground rules established to ensure that this technological revolution does not 
catch us off guard or overwhelm us. As we see above, there is a need for ethics in the field of 
Robotics. But the natural question arises whether we can build Robots complex enough to govern 
themselves. The fact remains that such a future is far off, and we need regulations to ensure that our 
community is not harmed by the misuse/negligent use of these beautiful machines. Robots are 
powerful; they can do our taxes and at the same time create economic havoc; they can build cars 
and at the same time destroy them; they can stimulate us, enchant us & elevate us. But the fact 
remains that they must do so in a controlled manner, and to ensure that, there must be some room 
for ethics in Robotics. How do we do that? Creating ethical Robots is equivalent in complexity to 
creating sentient robots, so it is not ethical Robots that we seek. It is ethical Roboticists that we ask 
for. For it is only then that these exciting machines may take the shape and form that we want them 
to.   

 
 
 
 
 
 
 
 
 
      
 
 
 
 
 
 
 
 
 
 
 
Kush Agrawal 

                Citations & References  

[1] http://www.capurro.de/ethicsandrobotics.html 

[2] http://www.thetech.org/robotics/ethics/index.html 

[3] http://moralmachines.blogspot.com/2009/11/ethics-and-robotics.html 

[4] http://news.nationalgeographic.com/news/2007/03/070316-robot-ethics.html 

[5] http://www.cs.washington.edu/research/projects/WebWare1/www/softbots/projects.html 

[6] http://en.wikipedia.org/wiki/Karel_%C4%8Capek#Etymology_of_robot 

[7] http://news.bbc.co.uk/2/hi/technology/6425927.stm 

[8] http://www.cosmosmagazine.com/news/2452/calls-ethics-guidelines-robots 

[9] http://www.i-r-i-e.net/inhalt/006/006_full.pdf 

[10 ]http://ethicbots.na.infn.it/restricted/doc/D5.pdf 

[11] http://ethicbots.na.infn.it/restricted/doc/D2.pdf 

[12] http://ethicbots.na.infn.it/restricted/doc/D4.pdf 

[13] http://www.bsu.edu/web/mawilliams/history.html 

[14] http://robotics.megagiant.com/history.html 

[15] http://www.wisegeek.com/what-is-the-history-of-robotics.htm 

[16] http://www.auburn.edu/~vestmon/robotics.html 

[17] http://www.asimovlaws.com/articles/archives/2004/07/why_we_need_fri_1.html 

[18] http://www.asimovlaws.com/articles/archives/2004/07/robot_oppressio_1.html 

[19] http://www.rogerclarke.com/SOS/Asimov.html 

[20] http://www.cra.org/ccc/docs/init/Robotics.pdf 

[21] http://www.facweb.iitkgp.ernet.in/~pallab/ai.slides/lec1.pdf 

[22] http://qin.laya.com/files/ai.pdf 

[23] http://singinst.org/upload/artificial-intelligence-risk.pdf 

[24] http://www.humanismtoday.org/vol3/sarles.pdf 

[25] http://www.niemueller.de/uni/roboticsintro/AI-Robotics.pdf 

[26] http://www.eee.hku.hk/news/seminars/Seminar_Prof_Zhang_Chunyuan_6May10.pdf 

[27] http://en.wikipedia.org/wiki/Moravec's_paradox"
Use of Python and Phoenix-M Interface in Robotics,"  In this paper I will show how to use Python programming with a computer
interface such as Phoenix-M 1 to drive simple robots. In my quest towards
Artificial Intelligence(AI) I am experimenting with a lot of different
possibilities in Robotics. This one will try to mimic the working of a simple
insect's nervous system using hard wiring and some minimal software usage. This
is the precursor to my advanced robotics and AI integration where I plan to use
a new paradigm of AI based on Machine Learning and Self Consciousness via
Knowledge Feedback and Update Process.
",http://arxiv.org/pdf/1101.0245v1,1,"0
1
0
2
c
e
D
1
3

]

O
R
.
s
c
[

1
v
5
4
2
0
.
1
0
1
1
:
v
i
X
r
a

Use of Python and Phoenix-M interface in
Robotics

Shubham Chakraborty

Editor(Physics- Higher Academics), Vikas Publishing House Pvt Ltd
E-28, Sector-8, NOIDA, UP
email: chakraborty.shuvam@gmail.com, +91-9999192634

If at ﬁrst an idea doesn’t look absurd, it has no future- Sir Albert Einstein

Abstract: In this paper I will show how to use Python programming with a computer interface such as
Phoenix-M 1 to drive simple robots. In my quest towards Artiﬁcial Intelligence(AI) I am experimenting
with a lot of different possibilities in Robotics. This one will try to mimic the working of a simple
insect’s nervous system using hard wiring and some minimal software usage. This is the precursor to
my advanced robotics and AI integration where I plan to use a new paradigm of AI based on Machine
Learning and Self Consciouness via Knowledge Feedback and Update Process.

Index Terms: Python, Phoenix-M, Robotics.

1. Introduction
This paper is neither path-breaking nor is it about some great inventions. It is about a humble
Robot which will showcase a simple thing that how easy is it to use python for works like robotics.
Robotics is a ﬁeld which has shown tremendous promise and has been equally dissappointing
when it comes to deliver the promises. Modern day robots are driven by some seriously sophis-
ticated software in conjunction with equally sophisticated mechatronics. In this paper we will see
how we can use the Python programming language and Phoenix computer interface to drive
simple robots. I have used some very minimal Python programming which can drive the Phoenix
interface to link a computer with the robot. For a robot, I have modiﬁed a remote controlled toy
car and integrated it with Logic and electronic circuits and Phoenix interface. But before I write
something about it let us ﬁrst discuss about the Phoenix interface,.

2. PHOENIX-M
Phoenix-M[1] is a micro-controller based computer interface which has been developed by Inter-
University Accelerator Centre.2 This simple yet powerful interface has been created to bridge the
gap between inexpensive computers and highly expensive computer interfaces, that can be found
in sophisticated laboratories only, to garner data and analyse them.

1Physics with Home-made Equipment and Innovative Experiments
2Formerly Nuclear Science Center, Delhi. IUAC is an autonomous research institute of University Grants Commission,

India,providing particle accelerator based research facilities to the Universities.

Vol. , No. ,

Page 1

 
 
 
 
 
 
Fig. 1. Phoenix Interface[4]

Phoenix provides microsecond level accuracy for timing measurements. Collecting data from the
sensor elements and controlling the different parameters of the experiments from the PC is one
of the features of Phoenix-M. This is achieved by loading the required software3 into the micro-
controller. This enables the students to use it as a general purpose micro-controller development
kit as well as help them design stand-alone projects. The interface comes with a CD which contains
all the required software to drive the micro-controller 4. The python library with which the controller
can be accessed is known as phm.py and can be found in the software repositories specially
made for Phoenix.

3. Lets get started
The main aim of this experiment is two fold.

1) To create a simple robotic device which will mimic the way a Foraging ant[3] searches for

food by tracing chemical signature of food.

2) To use Phoenix-M5 and Python in sync, to create this robot, and put forward the versatility

of Python programming.

This toy robot is inspired by the actions of Foraging ants[3]. It has to start from its home and
wade through a series of obstacles, to reach its desired destination. This is very similar to the
actions of Foraging ants[3] which go out in search of food. If food is nearby, it gets the chemical
signature and starts following it, while overcoming all types of obstacles it ﬁnda in its way. This
will be done using Micro-controller based controls of Phoenix-M interface.

When a Foraging ant6 goes out in search of food, it leaves behind a trail of Pheromones[2]7.
Once food has been found, it traces backs its pheromonal trail and reaches its home. In our case
we have a toy robot which will trace a light signal 8.

3The software is usually Python
4Atmega16
5Dr Ajith of IUAC will be giving a lecture on Phoenix-M
6The only difference is that initially Fooraging ants wander a bit randomly till they reach their destination and then their

path becomes more stable. In our case that will not happen

7A pheromone is a secreted or excreted chemical factor that triggers a social response in members of the same species.
8Light signal is our substitute of chemical signature of food

Vol. , No. ,

Page 2

3.1. Overview of variables and deﬁnitions

Before I start explaining everything let us ﬁrst decide on the variable conventions. So I will be
using the following variables which have some speciﬁc meanings. Here is a list of variables and
their meanings.

Table 1: Variables and their meanings.

Seek
PL
PR
WL
WR
S1,2,3,4
1
0
1

The eye of the robot seeks the light signal.
Left pressure sensor.
Right pressure sensor.
Left wheel.
Right wheel.
Switches 1 to 4.
Forward Movement
No Movement
Backward Movement

3.2. Algorithm

First we have to develop an Algorithm. The algorithm is a step by step process which a certain
system follows to achieve its goals. In our case the Robot has to ﬁrst seek out the light source.
The moment it gets hold of the light source it moves towards it. In case it encounters any obstacle,
its pressure sensors immediately signals the micro-controller. The decision is taken according to
the side which encounters the obstacle.

Table 2: Algorithm followed by the Robot

Start
Seek Light Source
If (Seek Light ==1) Then Move ahead
If (Obstacle==1) Then
If(Obstacle == Right) Then Move Clockwise / Back
If(Obstacle == Left) Then Move Anti-Clockwise / Back

Step 1
Step 2
Step 3
Step 4
Step 5
Step 6
Step 7 Else If(Obstacle == Left == Right) Move Back and stop for 2 seconds
Step 8
Step 9

Repeat Step 2 to 7 till destination reached
Stop

One thing to note is that 1 means Forward movement, 0 means No movement and 1 means

Backward movement

3.3. Control Sequences

Now lets see the Movement Sequence of the Robot. The movement sequence lets us determine
the way the robot should react to an incoming signal stimulus.

Vol. , No. ,

Page 3

Table 3: Movement Sequence

Move Ahead
Move Clockwise/Back

WL = WR = 1
WL = 0 and WR = 1
Move Anti-Clockwise/Back WL = 1 and WR = 0
WL = 1 and WR = 1

Seek

3.4. Seek and Move Procedure

Table 4: Truth table for Seek and (Respective) Move Procedure

Seek
1
0
0
0
0

PL PR WL WR
1
0
1
0
1
1
0
0
1
1

0
0
0
1
1

1
1
0
1
1

Table 5: Truth table for Move Procedure and Switch Combinations

WL WR
0
0
1
1
1
1
1
0
1
0
1
1

S1
0
1
0
0
1
0

S2
0
0
1
0
0
1

S3
0
1
1
0
0
0

S4
0
0
0
1
0
1

Now that we have seen the various procedures that are required to make the robot work, we will
now concentrate on the second most important part of the experiment, Hardware and Software.
There are essentially two hardware components that we will use in sync; Phoenix-M interface
and the Robot whereas the software will be a combination of Python code which will make the
robot move and the another Python code to connect to the Phoenix-M interface and make its
micro-processor respond.

The given ﬁgure is just an outline of the Robot. WL and WR are the two wheels which run
independant of each other. PL and PR are the two electro-mechanical pressure sensors which
sense whether there is an obstruction in the path or not. If there is an obstruction, the pressure
sensors complete a circuit which grounds the digital
input channels of Phoenix-M interface.
Similarly there is another sensor, Seek which acts like the eye of the Robot. It is an LDR(Light
Dependant Resistor) which is attached to the base of an n-p-n transistor such that the transistor
acts like a switch. The switch is used to operate a relay circuit. The output of the relay is taken as
Logic High (+5V) or Logic Low(0V). Apart from this it also houses a battery pack, a PCB on which
the sensors are mounted and relay switches which help in the passage of signals. Below you will
see the circuit diagrams of the components and how they can be integrated with the Phoenix-M
interface.

Vol. , No. ,

Page 4

Fig. 2. Outline of Robot

3.5. Bit combinations

The Phoenix interface has its own way to understand and decipher the input and output signals
through its channels. These Bit combinations need to be understood before we can start to build
our Python code based on these combinations.

Table 6: Input channels on Phoenix-Mand their Bit combinations

S.No.
1
2
3

Input Channels
D0
D1
D2

Input Signal Bit Conventions

Seek
PL
PR

1
2
4

Table 7: Output channels on Phoenix-Mand their Bit combinations

S.No. Output Channels Output Signal Bit Conventions

1
2
3
4

D0
D1
D2
D3

S4
S3
S2
S1

1
2
4
8

3.5.1. What does the above mean?

In the output channels if I want to make both the wheel move forward then according to Table 5,
S3 and S2 should go high. Since S3 and S2 are connected to D1 and D2 respectively, then the
output bit combination should be 0110 which in decimal system is 6. The following two tables will
show you the bit combinations.

Vol. , No. ,

Page 5

Table 8: Modiﬁed Truth table for Seek Procedure with Bit combination

Seek
1
0
0
0
0

PL PR WL WR Bit combination
1
0
1
0
1
1
0
0
1
1

15
14
10
12
08

0
0
0
1
1

1
1
0
1
1

Table 9: Modiﬁed Truth table for Move Procedure, Switch and Bit Combimations

WL WR
0
0
1
1
1
1
1
0
1
0
1
1

S1
0
1
0
0
1
0

S2
0
0
1
0
0
1

S3
0
1
1
0
0
0

S4 Bit combination
0
0
0
1
0
1

00
10
06
01
08
05

Fig. 3. Circuit Diagram of Switching Circuit

Vol. , No. ,

Page 6

4. Python Codes to ineract with Phoenix-M

4.1. Example 1.

import phm, time
p = phm.phm()
while 1:

p.write outputs(4)
time.sleep(10)
p.write outputs(0)
time.sleep(10)

A line by line explanation of the Example 1.
Line 1: Loads phm module from Phoenix library and time module from standard Python library
Line 2: Loads the function phm() onto the compiler
Line 3: Starts an inﬁnite loop
Line 4: Outputs a digital signal to BIT Combination 4, which means it will set D2 high.
Line 5: Stops the execution of the code for 10 seconds
Line 6: Outputs a digital signal to BIT Combination 0, which means all the output channels will
set to low
Line 7: Stops execution of the code for another 10 seconds.

As you can see that a simple code like the one given above can actually be used to create
a timer device. So instead of changing the circuit, all we need to do is change the code with
perfect results. As can be seen, Python makes life a lot easier when it comes to dealing with
micro-controllers.

Now let us look at another example in which a speciﬁc input gives rise to an output. The while

1: command keeps the processor on its toes. It keeps looking for an input from the interface.

4.2. Example 2.

import phm, time
p = phm.phm()
while 1:

p.read inputs()
if(p.read inputs() == 7):

p.write outputs(8)

else:

time.sleep(10)

5. Python code to drive the Robot interface
Let us now look at the code that will drive our Robot across the obstacles to its destination. The
codes, though may look very simple and kiddish, are extremely powerfull and ﬂexible and can
easily drive the Robot around.

Vol. , No. ,

Page 7

Robot code

import phm, time
p=phm.phm()
while 1:

x = p.read inputs()
if (x == 15):

p.write outputs(10)
continue
elif(x ==14):

p.write outputs(06)
continue
elif(x ==10):

p.write outputs(08)
continue
elif(x ==12):

p.write outputs(01)
continue
elif(x ==08):

p.write outputs(09)
time.sleep(2)
p.write outputs(05)
continue

else :

p.write outputs(06)

Code

Table 10: Analysis of the entire code
Function

x = p.read inputs() Reads input Bit combination from the input channels

if (x == 15):
p.write outputs(10)
elif(x ==14):
p.write outputs(06)
elif(x ==10):
p.write outputs(08)
elif(x ==12):
p.write outputs(01)
elif(x ==08):
p.write outputs(09)
time.sleep(2)
p.write outputs(05)
continue
else :
p.write outputs(06)

PL = PR = 0. Seek = 1. Search for light
Move counter-clockwise
PL = PR = 0. Seek = 0. Move towards light
Move forward
PL = Seek = 0, PR = 1
Move Back/Counter-Clockwise
Seek = PL = 1 and PR = 0
Move Back/Clockwise
Seek = PL = PR = 1
Move Back
Wait 2 seconds
Move Clockwise
After every command, process begins again
If nothing matches
Move forward

The above code, in sync with the micro-controller and the logic (and electronic) circuits, can

Vol. , No. ,

Page 8

easily drive the Robot to its desired destination.

6. What Next!!
Let us now modify the above code for the Robot and get something else done by it. Till now we
were working with a Robot which had to bump into something to ﬁgure out that it has ran into
obstacle. But wouldn’t it be nice if it doesn’t have to run into an obstacle, just go across it. This
can be easily done by modifying the Robot hardware a bit. instead of a light sensitive seeker we
will have to use a sonar system. Such systems are easily available in the market. All that has to
be done is to mount the sonar system in place of the LDR (Light Dependant Resistor - Seeker)
and integrate it with the interface just the way we have done it before. The code will also change
a bit. Following is the code and its analysis.

Robot code with Sonar

import phm, time
p=phm.phm()
while 1:

x = p.read inputs()
p.write outputs(2)
y=p.clr2rtime(0,0)
distance = (33000*y)/2
if (distance <5):

p.write outputs(09)
time.sleep(2)
p.write outputs(05)
continue
elif(x==15):

p.write outputs(10)
continue

else:

continue

7. Conclusions
What we can conclude from this paper is that Python can actually make the life a lot easier when
it comes to using micro-controllers and hence can be a big boon for Robotics enthusiasts. Infact
the ﬂexibility and ease with which Python is being implemented has made it a language to reckon
with. As we have seen, it can easily interact with the micro-controllers using a simple interface
like Phoenix-M. Just by the mere tweakingofpython codes it becomes pretty simple to control the
Robots. It seems that more and more experiments will lead to some fascinating research in this
particular subject.

Vol. , No. ,

Page 9

Appendix 1: The brief outline of Phoenix-M interface[1]
On the front panel you will ﬁnd several 2mm banana sockets with different colors. Their functions
are brieﬂy explained below.
1. 5V OUT - This is a regulated 5V power supply that can be used for powering external circuits.
It can deliver only upto 100mA current , which is derived from the 9V unregulated DC supply from
the adapter.
2. Digital outputs - four RED sockets at the lower left corner . The socket marked D0* is buffered
with a transistor; it can be used to drive 5V relay coils. The logic HIGH output on D0 will be
about 4.57V whereas on D1, D2, D3 it will be about 5.0V. D0 should not be used in applications
involving precise timing of less than a few milli seconds.
3. Digital inputs - four GREEN sockets at the lower left corner. It might sometimes be necessary
to connect analog outputs swinging between -5V to +5V to the digital inputs. In this case, you
MUST use a 1K resistor in series between your analog output and the digital input pin.
4. ADC inputs - four GREEN sockets marked CH0 to CH3
5. PWG - Programmable Waveform Generator
6. DAC - 8 bit Digital to Analog Converter output
7. CMP - Analog Comparator negative input, the positive input is tied to the internal 1.23 V
reference.
8. CNTR - Digital frequency counter (only for 0 to 5V pulses)
9. 1 mA CCS - Constant Current Source, BLUE Socket, mainly for Re- sistance Temperature
Detectors, RTD.
10. Two variable gain inverting ampliﬁers, GREEN sockets marked IN and BLUE sockets marked
OUT with YELLOW sockets in between to insert resistors. The ampliﬁers are built using TL084 Op-
Amps and have a certain offset which has to be measured by grounding the input and accounted
for when making precise measurements.
11. One variable gain non-inverting ampliﬁer. This is located on the bot- tom right corner of the
front panel. The gain can be programmed by connecting appropriate resistors from the Yellow
socket to ground.
12. Two offset ampliﬁers to convert -5V to +5V signals to 0 to 5V signals. This is required since
our ADC can only take 0 to 5V input range. For digitizing signals swinging between -5V to +5V
we need to convert them ﬁrst to 0 to 5V range. Input is GREEN and output is BLUE.

Acknowledgements
I would like to thank the creators of Phoenix-M, without whom neither this interface nor this paper
would have seen the light of the day.

References
[1] Ajith Kumar B.P, Pramode C.E. ”Innovative Experiments using Phoenix”, Version 1, 2006.
[2] http://en.wikipedia.org/wiki/Pheromone
[3] http://en.wikipedia.org/wiki/Ant colony optimization-Rank-based ant system .28ASrank.29
[4] http://www.iuac.res.in/ elab/phoenix/

Vol. , No. ,

Page 10"
"Climbing depth-bounded adjacent discrepancy search for solving hybrid
  flow shop scheduling problems with multiprocessor tasks","  This paper considers multiprocessor task scheduling in a multistage hybrid
flow-shop environment. The problem even in its simplest form is NP-hard in the
strong sense. The great deal of interest for this problem, besides its
theoretical complexity, is animated by needs of various manufacturing and
computing systems. We propose a new approach based on limited discrepancy
search to solve the problem. Our method is tested with reference to a proposed
lower bound as well as the best-known solutions in literature. Computational
results show that the developed approach is efficient in particular for
large-size problems.
",http://arxiv.org/pdf/1103.1516v1,1,"1
1
0
2

r
a

M
8

]

O
R
.
s
c
[

1
v
6
1
5
1
.
3
0
1
1
:
v
i
X
r
a

Climbing Depth-bounded Adjacent Discrepancy
Search for Solving Hybrid Flow Shop Scheduling
Problems with Multiprocessor Tasks

Asma LAHIMER1, Pierre LOPEZ1, and Mohamed HAOUARI2

1

CNRS ; LAAS ; 7 avenue du colonel Roche, F-31077 Toulouse Cedex 4, France
Universit´e de Toulouse ; UPS, INSA, INP, ISAE ; UT1, UTM, LAAS ; F-31077
Toulouse Cedex 4, France
asma.lahimer@laas.fr, pierre.lopez@laas.fr

2

INSAT ; Institut National des Sciences Appliqu´ees et de Technologie
Centre Urbain Nord BP 676 - 1080 Tunis Cedex, Tunisie
mohamed.haouari@insat.rnu.tn

Abstract. This paper considers multiprocessor task scheduling in a
multistage hybrid ﬂow-shop environment. The problem even in its sim-
plest form is NP-hard in the strong sense. The great deal of interest for
this problem, besides its theoretical complexity, is animated by needs of
various manufacturing and computing systems. We propose a new ap-
proach based on limited discrepancy search to solve the problem. Our
method is tested with reference to a proposed lower bound as well as the
best-known solutions in literature. Computational results show that the
developed approach is eﬃcient in particular for large-size problems.

Keywords: Hybrid ﬂow shop scheduling, Multiprocessor tasks, Discrep-
ancy search

1

Introduction

Flow shop scheduling refers to a manufacturing facility in which all jobs visit
the production machines in the same order. In hybrid ﬂow shop scheduling, the
jobs serially traverse stages following the same production route, and must be
assigned to one of the parallel machines composing each stage. The hybrid ﬂow
shop scheduling problem with multiprocessor tasks is itself a generalization of
the hybrid ﬂow shop problem, allowing tasks to be processed on more than one
processor in a given stage, at a time. It can also be viewed as a speciﬁc case of
the resource-constrained project scheduling problem (RCPSP).

Many applications of hybrid scheduling problems with multiprocessor tasks
can be found in various manufacturing systems (e.g., work-force assignment in
[6], transportation problem with recirculation in [4]), as well as in some computer
systems (e.g., real-time machine-vision [8]).

Hybrid ﬂow shop scheduling problem with multiprocessor tasks has received
considerable attention from researchers and has been solved by various ap-
proaches, e.g. genetic algorithms [14], tabu search, and ant colony system [19].

 
 
 
 
 
 
Motivated by the success of discrepancy search for solving shop scheduling prob-
lems, in particular hybrid ﬂow shop [2], [3], we propose in this paper a new ap-
proach based on discrepancy search to solve the hybrid ﬂow shop problem with
multiprocessor tasks.

2 Problem Deﬁnition

The hybrid ﬂow shop scheduling problem with multiprocessor tasks can be for-
mally described as follows: A set J={1, 2, . . . , n} of n jobs, have to be processed
in m stages. Hence, a job is a sequence of m tasks (one task for each stage). Each
stage i = {1, 2, . . . , m} consists of mi identical parallel processors. In a stage i,
the job j requires simultaneously sizeij processors. That is, sizeij processors
selected at stage j are required for processing job j for a period of time equal to
the processing time requirement of job j at stage i, namely pij. The objective is
to minimize the makespan (Cmax), that is, the completion time of all tasks in the
last stage. According to the classical 3-ﬁeld notation in production scheduling,
the problem is denoted by Fm(m1,. . .,mm)|sizeij|Cmax.

3 Discrepancy Search

3.1 General Statement

Limited discrepancy search (LDS) was introduced in 1995 by Harvey and Gins-
berg [9]. This seminal method can be considered as an alternative to the branch-
and-bound procedure, backtracking techniques, and iterative sampling. From
an optimization view-point this technique is similar to variable neighbourhood
search. Indeed, it starts from an initial global instantiation suggested by a given
heuristic and successively explores branches with increasing discrepancies from
it, in order to obtain a solution (in a satisfaction context), or a solution of bet-
ter performance (in an optimization context). A discrepancy is associated with
any decision point in a search tree where the choice goes against the heuristic.
For convenience, in a tree-like representation the heuristic choices are associ-
ated with left branches while right branches are considered as discrepancies.
Since LDS proposition in 1995, several variants were suggested, among them,
Improved Limited Discrepancy Search (ILDS) [12], Depth-bounded Discrepancy
Search (DDS) [21], Discrepancy-Bounded Depth First Search [1] and Climbing
Discrepancy Search (CDS) [13].

In the following sections, we focus on those methods that inspired our ap-

proach, in particular DDS and CDS.

3.2 Depth-bounded Discrepancy Search

Depth-bounded Discrepancy Search (DDS) developed in [21], is an improved
LDS that prioritizes discrepancies at the top of the tree to correct early mistakes

ﬁrst. This assumption is ensured by means of an iteratively increasing bound
on the tree depth. Discrepancies below this bound are prohibited. DDS starts
from an initial solution. At ith iteration, it explores those solutions on which
discrepancies occur at a depth not greater than i.

3.3 Climbing Discrepancy Search

Climbing Discrepancy Search (CDS) is a local search method adapted to com-
binatorial optimization problems proposed in [13]. CDS starts from an initial
solution that would be dynamically updated. Indeed, it visits branches progres-
sively until a better solution is reached. Then, the initial solution is updated and
the exploration process is restarted.

4 Proposal: Climbing Depth-bounded Adjacent

Discrepancy Search

4.1 CDADS: Main Features

To stick to the problem under consideration, we now consider an optimization
context. We propose CDADS (Climbing Depth-bounded Adjacent Discrepancy
Search) method, that is a combination of a depth-bounded discrepancy search
and a climbing discrepancy search. We also assume that, if several discrepancies
occur in the construction of a solution, these discrepancies are necessarily ad-
jacent in the list of successive decisions. CDADS starts from an initial solution
obtained by a given heuristic, and explores its neighborhood progressively, ac-
cording to the depth-bounded discrepancy search strategy. Hence, a limit depth
d is ﬁxed. Discrepancies below this bound are prohibited. At the ith iteration,
we allow i discrepancies above the limit level d.

When considering solutions with more than one discrepancy, we require these
discrepancies are achieved consecutively, that means a solution consists of dis-
crepancies that happen one after the other. This assumption of adjacency con-
siderably limits the search space. We also consider that the initial solution is
generated by a ‘good’ heuristic. Thus, only the immediate neighborhood of a
discrepancy may receive an additional discrepancy. We obtain a truncated DDS
based on adjacent discrepancies, DADS (Depth-bounded Adjacent Discrepancy
Search). This approach is illustrated by an example on a binary tree of depth
3 (see Figure 1). At the starting point, DADS visits the initial solution recom-
mended by the heuristic. For convenience, we assume that left branches follow
the heuristic. At ﬁrst iteration, DADS visits leaf nodes at the depth limit with
exactly one discrepancy. The ﬁrst line shown under the branches reports the
visit order of considered solution, while the second line illustrates the number of
discrepancies made in each solution. The 2nd iteration allows to exploring more
solutions with two discrepancies with respect to the adjacency assumption. In
this representation, the maximum depth bound is taken to be 3. If now, we limit

the depth to two levels, several branches would not be retained, namely the
branches 4, 6, and 7 would not be visited by DADS.

0th Iteration

1st Iteration

1
0

4
1

3
1

2
1

2nd Iteration

3th Iteration

6
2

5
2

7
3

Fig. 1. Depth-bounded Ajacent Discrepancy Search

Going back to the optimization issue, CDADS merges the DADS strategy
with a CDS exploration principle, that is the initial solution used by DADS is
dynamically updated when a best solution is found, and the exploration process
is restarted.

4.2 Heuristics

CDADS is strongly based on the quality of the initial solution. Thus, we carried
out an experimental comparison between various priority rules presented in the
literature [19], [15]. We considered the most eﬀective heuristics to multiprocessor
task hybrid ﬂow shop scheduling. The four selected rules are:

– SPT (Shortest Processing Time), which ranks jobs according to the ascend-

ing order of their processing times;

– SPR (Shortest Processing Requirement), which ranks jobs according to the

ascending order of their processing requirement;

– the Energy rule, considering ﬁrst the jobs with the smallest energy (where
the energy of an operation j at a stage i is evaluated by pij × sizeij); and
– NSPT LastStage (Normalized SPT applied at the last stage). For this
latest rule, S¸erifo˘glu and Ulusoy [19] propose to schedule jobs according to
their ranking index (RIj) deﬁned by:

RIj =

max
k

{pmk} − pmj + 1
{pmk} + 1

.

max
k

In Table 1, the selected priority rules are ranked according to their percentage

of best solutions found, that is, performance.

Table 1. Heuristic selection

Priority Rule Performance (%)

NSPT LastStage

Energy

SPT

SPR

27

25

17

14

4.3 Schedule Generation Scheme

Schedule generation schemes (SGSs) are widely used in solving preemptive prob-
lems. We distinguish between serial SGS and parallel SGS. These two heuristics
ensure task scheduling based on a given priority rule. Hence, tasks are selected
one after the other and a start time is ﬁxed for each one.

Serial SGSs are introduced in [11]. At each iteration, the ﬁrst available task
in ζ is selected, where ζ is the priority list recommended by the priority rule.
The selected task is scheduled as soon as possible with respect to both resource
constraints and precedence constraints.

Parallel SGSs developed in [5], suggest a chronological procedure in schedul-
ing tasks. At each time t, a set ζt of tasks being scheduled is deﬁned: this set
contains unscheduled tasks that can be processed at t without breaking neither
precedence constraints nor resource constraints. If we consider that t is the ﬁrst
time where ζt 6= ∅, the ﬁrst task in the priority list ζ belonging to ζt is performed
at t. The same process is applied until all tasks are scheduled. The two schemes
depicted above may appear similar. However, the schedule they generate are dif-
ferent: a serial SGS provides an active schedule while a parallel SGS generates
a non-delay schedule.

In the scheduling theory, Sprecher et al. [20] show that the set of active
schedules includes at least one optimal solution. On the contrary, non-delay
schedules may eliminate all optima.

Concerning our method CDADS, we do not enumerate all possible solutions,
so even serial SGSs may exclude all optimum solutions. Furthermore, in practice,
parallel SGSs are known for their operational eﬃciency. Hence, we opt for the
implementation of a parallel SGS which has been proved, moreover, to be more
eﬃcient in our experimental studies.

4.4 Lower Bound

For eﬃciency purpose, we join CDADS with an evaluation of lower bounds at
each node. The proposed lower bound is based on lower bounds previously pre-
sented in [14]. Thus, we suggest this formula:

LB = max(LBs,LBj)

where LBj is a job-based lower bound similar to the one suggested in [14]:

m

LBj = max
j∈J

(
Xi=1

pij); and LBs is a stage-based lower bound: LBs= max
i=1..m

LB(i).

For this latter bound, we claim that:

max[M1(i), M2(i), max
j∈J

m

(pij)] + min
(
j∈J
Xl=i+1

plj ) ,

plj) + max[M1(i), M2(i), max
j∈J

(pij )] + min
j∈J

∀i = 1

m

(
Xl=i+1

plj) , ∀i = 2..m − 1

i−1

(
min
j∈J
Xl=1
i−1

(
min
j∈J
Xl=1






LB(i) =

where

with

plj) + max[M1(i), M2(i), max
j∈J

(pij )] ,

∀i = m

M1(i) =

(cid:24)

1
mi Xj∈J
and

(pij sizeij)

(cid:25)

M2(i) =

pij +

Xj∈Ai

1
2 Xj∈Bi

pij ,

Ai = {j|sizeij >

and

Bi = {j|sizeij =

mi
2

}

mi
2

}.

Justiﬁcation of the expression of LB(i).

We assume that only non-delay task scheduling is considered.

The ﬁrst term of LB(i) gives a lower bound on the beginning of every
job j ∈ J on any machine of stage i.

The last term can be explained accordingly, since it is associated with
the minimal required time to achieve the processing of every job j on all
the subsequent stages of stage i.

The middle term concerns the processing of jobs on stage i. M1(i) stands
for the mean stage load for job preemptive scheduling, while M2(i) re-
views two diﬀerent situations for partitionning the jobs according to their
resource requirement. Set Ai consists of jobs that must be processed se-
quentially (resource requirement greater than the half of the resource
capacity mi). Set Bi groups together the jobs having a resource require-
ment exactly equal to the half of the resource capacity. Obviously, a job
belonging to Ai and another job belonging to Bi must also be processed
(pij) contributes to maximize the eval-
sequentially. The added term max
j∈J

uation of stage load on a considered stage i, especially when some jobs
having high processing time are being scheduled.

This justiﬁes the validity of the bound.

✷

5 Computational Study

5.1 Test Beds

For comparison purpose, we assess the performance of CDADS on instances of
O˘guz’s benchmark available on her home page: http://home.ku.edu.tr/coguz/public_html/.
This benchmark is widely used in the literature [18], [10], [16].

The number of jobs is taken to be n = 5, 10, 20, 50, 100 and the number of
stages m takes its value from the set {2, 5, 8}. The benchmark considers two
types of problems, “Type-1” and “Type-2”. In ‘Type-1’ instances, the number
of processors mi available at each stage i (resource capacity) is randomly deter-
mined from the set {1, . . . , 5}, while in ‘Type-2’ mi is ﬁxed to 5 processors for
every stage i. In fact, ‘Type-2’ instances are globally more ﬂexible than ‘Type-1
instances’. For each combination of n and m, and for each type, 10 instances are
randomly generated, which leads a total of 300 instances. The processing time
of each job j in stage i (pij ) and its processing requirement (sizeij) are integer
and are randomly generated from sets {1, . . . , 100} and {1, . . . , mi}, respectively.

The algorithm implementing CDADS was coded in C++ and run on an In-
tel core 2 Duo 2 GHz PC. The maximum CPU time is set to 60 seconds. The
exploration is also stopped when CDADS reaches a given lower bound on the
makespan. Obviously, if CDADS misses the optimal solution, the best-found so-
lution when the maximum CPU time is reached, is then taken to be the problem
solution.

5.2 Restart Policy

For the computational study, we have then retained four priority rules to generate
the initial solutions (see Section 4.2). That is why whe have introduced a restart
policy to beneﬁt from these heuristics. At a starting point, we use the best

rule, that is the NSPT LastStage. However, if no improvement is noticed during
the CDADS search, we restart the process with another solution obtained by
applying the next rule “Energy” that could lead a more eﬃcient solution for this
speciﬁc instance, and so on.

The restart policy is limited by the size of the heuristics pool: restarts are
then allowed at most four times, since we have selected four rules. At each restart
k (starting from k = 0), we increase the number of maximum nodes that can be
visited according to a geometrical series nbrNodes ×f k, where f is ﬁxed to 1.3
and nbrNodes varies linearly with the problem size (the number of jobs n; for
example for n = 20 we ﬁx nbrNodes to 2000 nodes). Hence the search space is
expanded at each restart.

5.3 Results

We tested two strategies for applying discrepancy: Top First and Bottom First.
In the Top First exploration, discrepancies at the top of the tree are privileged
while the Bottom First strategy favors discrepancies at the bottom. Computa-
tional study shows that CDADS is really more eﬃcient with a Top First strategy
(then contradicting – for the problem at hand – the statement of relative indif-
ference of discrepancy order by [17]). Thus, the results shown below refer to this
latter strategy.

Table 2 gives for each conﬁguration (n: number of jobs, and m: number of
stages) and each type, the average percentage deviation (%dev ) and the average
CPU time. The average percentage deviation is measured in two ways:

• For small problems, solutions are compared to the optimal solutions (C∗

max

denotes the optimum makespan):

Cmax − C∗
C∗

max

max

× 100;

• For larger problems, solutions found by the CDADS are compared to the

lower bound (LB):

Cmax − LB
LB

× 100.

As explained in Section 5.2, CDADS is run four times on each of the selected
priority rules (NSPT LastStage, Energy, SPT, SPR) for each instance. The best
solution is taken to be the CDADS solution for the corresponding problem.
According to ﬁndings of [19], the Fm(m1,. . .,mm)|sizeij|Cmax problem and its
symmetric have the same optimal makespan. Referring to this property, we apply
a two-directional planning (forward schedule and backward schedule).

From Table 2, it is observed that the average percentage deviation is higher
for ‘Type-1’ instances. Globally, %dev is 1.66% for ‘Type-1’ problems and 6.39%
for ‘Type-2’ problems. This increase can be linked to several assumptions: the
lower bound becomes less eﬀective as mi increases in ‘Type-2’ instances and so

Table 2. CDADS performance

m

‘Type-1’ Problems
%dev CPU(s)

‘Type-2’ Problems
%dev CPU(s)

n

5

10

20

50

2
5
8

2
5
8

2
5
8

2
5
8

0
0.21
1.71

0
0.66
8.47

0.05
2.57
5.11

0.49
0.54
1.62

100

0.08
2
1.5
5
1.86
8
Global average 1.66

< 0.1
< 0.1
< 0.1

< 0.1
0.4
< 0.1

0.1
1.1
0.2

2.3
5
6.8

11.1
13.6
11
3.44

0
0.46
0.5

1.72
6.44
9.61

3.34
7.97
15

1.74
8.2
12.42

3.32
10.75
14.33
6.39

< 0.1
< 0.1
< 0.1

< 0.1
< 0.1
0.2

3.1
1.3
1.3

4.2
13.5
33.4

22.8
40.9
47.3
10.53

the average percentage deviation would be higher. Another explanation can also
be considered: the number of processors are ﬁxed in ‘Type-2’ problems, that is
mi = 5, and the scheduling problem becomes more diﬃcult to solve for CDADS.

Results show the behavior of our approach with variations of n and m. For a
given n, the average percentage deviation increases with increasing m. Indeed,
the problem diﬃculty increases when m increases and the obtained solution is
further away from the lower bound. On the other hand, for a given number
of stages m, increasing n has no signiﬁcant eﬀect on the average percentage
deviation, as the eﬀectiveness of CDADS is independent of the number of jobs:
the stability of our method seems to be not linked to the number of jobs n, since
for a given m (e.g., m = 8), in ‘Type-1’ problems, when n increases from 50
jobs to 100 jobs, the average percentage deviation increase slightly (from 1.62%
to 1.86%). It also can be noticed, that in some cases, increasing n results in a
decrease in the deviation value (for the conﬁguration n = 20, m = 8 the %dev is
taken to be 5.11%, and is evaluated to 1.62% for n = 50, m = 8). Apparently,
the lower bound becomes more eﬀective with n increasing.

From the experimental studies, it can be observed that CDADS converges
quickly. The average CPU time varies between less than 0.1 seconds and 47.3
seconds. The computational cost is more important in ‘Type-2’ instances, con-
ﬁrming the diﬃculty of these problems. Similarly, for a ﬁxed m, increasing n

leads to CPU time increase. Conversely, when n is ﬁxed, increasing m increases
the CPU time.

5.4 Comparison of CDADS Solutions with State-Of-the-Art Results

Table 3 presents the results of CDADS on %dev, the average percentage deviation
(as well as a synthesis of the average CPU time for all instances, in the last line
of the table). Furthermore, it shows the results obtained by Jouglet et al. in [10].
These results are the most recent and the best-known solutions in literature.
Thus, we have compared the results of CDADS with GA (genetic algorithm),
CP (constraint programming), and MA (a memetic algorithm that combines
GA and CP). We disregard the results published by Ercan et al. [14] given
inconsistency encountered. We contrast our results only versus those presented
in [10]. However, we omit the average deviation published in this latest paper
due to detected miscalculation (induced by Ercan et al.’s errors). Hence, we
recalculated the average percentage deviation for all methods given in [10]. The
maximum CPU time is ﬁxed at 900 seconds for GA, CP, and MA.

Table 3. Comparing average percentage deviation (and CPU time)

‘Type-1’ Problems

‘Type-2’ Problems

m

CDADS GA

CP MA CDADS GA

CP MA

n

5

10

20

50

100

2
5
8

2
5
8

2
5
8

2
5
8

2
5
8

0
0.21
1.71

0
0.66
8.47

0.05
2.57
5.11

0.49
0.54
1.62

0.29
1.35
4.15

0
0
0

0
0
0

0
0
1.64
0
9.38 10.32 8.02

0
0

0.66
2.59
0.44
3.49 10.85 2.78
5.69 17.98 5.32

0.49
2.79
0.63
0.51
5.3
0.59
2.17 14.42 1.71

0.08
1.5
1.86
1.66

0.15
2.5
1.99
2.27

1.96
5.19
9.47
5.39

0.07
2.33
2.15
1.6

0
0.46
0.5

1.72
6.44
9.61

3.34
7.97
15

1.74
8.2
12.42

3.32
10.75
14.33
6.39

1.23
1.44
2.38

0
0
0

0
0
0

2.83
7.8
10.87

1.72
6.1
8.37

1.75
5.67
8.8

3.43
6.72
3.7
9.57
9.57
22.86
17.26 28.52 16.02

2.76
2.21
6.54
10.95 20.01 10.32
15.89 30.06 17.25

3.05
2.7
5.68
14.95 19.13 14.37
20.06 23.15 17.83
8.32
11.92
7.28

Global average

Average CPU(s)

3.44 879.93 320.3 326.01

10.53 879.08 423.09 511.27

As revealed in Table 3 (and as already noticed in Table 2), on the whole, the
total average of %dev obtained by CDADS is 1.66% and 6.39% for the ‘Type-1’

and ‘Type-2’ problems, respectively. Compared to the corresponding averages
of 2.27% and 7.28% achieved by GA, and the corresponding values of 5.39%
and 11.92 % obtained by CP, CDADS outperforms the GA and CP algorithms.
Furthermore, CDADS was clearly superior to CP especially for larger instances
(n = 50 and n = 100).

As depicted in the table, MA ﬁnds slightly better solutions in ‘Type-1’ prob-
lems, that is 1.60% is obtained by MA while CDADS gives an average deviation
percentage of 1.66%. Overall, CDADS outperforms signiﬁcantly MA, as CDADS
results are at 6.39% from optimal solutions (or lower bounds) for ‘Type-2’ prob-
lems against 8.32% for MA.

To further assess the eﬀectiveness of CDADS, we measure the number of im-
proved known solutions. It can be seen from Table 4 that CDADS improves 75
known solutions among the 300 tested instances. Thus, the rate of improvement
reaches 25%. The results also outline that most improvements are spotted in
large instances (n = 50, 100), see ﬁgure 2. No signiﬁcant improvements are no-
ticed for small instances (n = 5, 10) since all optimal solutions for these problems
are known.

Table 4. Number of improved solutions

n ‘Type-1’ Problems ‘Type-2’ Problems

5

10

20

50

100
total

0

1

5

8

8
22

0

0

10

20

23
53

In this study, we also compare the convergence of algorithms. It can be seen
from the last line of Table 3, that CDADS outperforms the genetic algorithm
(GA), constraint programming (CP), and the memetic algorithm (MA). Indeed,
CDADS takes between less than 0.1 seconds (for small problems) and 47.3 sec-
onds (for large problems) to ﬁnd their solutions, while methods proposed in [10]
converge much more slower [0.7 sec, 900 sec]. Even all results were obtained
under diﬀerent computational budgets, we can conclude that CDADS demon-
strates fast convergence. Indeed, according to Dongarra’s normalized coeﬃcients
[7], our machine is approximately only 3.5 times faster than the machine used
by Jouglet et al.

Type1.
Type2.

25

20

15

10

5

0

s
n
o
i
t
u
l
o
s

d
e
v
o
r
p
m

i

f
o

r
e
b
m
u
N

20

40

60

80

100

Number of jobs

Fig. 2. Variation of the number of improved solutions with the number of jobs

6 Conclusions

In this paper, the hybrid ﬂow shop problem with multiprocessor tasks is ad-
dressed by means of a discrepancy search method. The proposed method, Climb-
ing Depth-bounded Adjacent Discrepancy Search (CDADS), is based on adjacent
discrepancies. We selected several heuristics to generate the initial solution. A
lower bound is also proposed to lead a more eﬃcient search. Compared to the
best-known results in the literature, CDADS provides better solutions in little
CPU time.

In the short-term, we prospect to apply CDADS to simpler problems like
classical hybrid ﬂow shop (sizeij = 1, ∀ i, j), widely studied in the literature.
Another expected aim would be to adapt the proposed implementation of dis-
crepancy search to more general scheduling problems, in particular the Resource-
Constrained Project Scheduling Problem, which still remains one of the most
challenging problems in large-scale scheduling.

References

1. J. C. Beck and L. Perron. Discrepancy-bounded depth ﬁrst search. In Proceedings

of CPAIOR 2000, pages 8–10, 2000.

2. A. Ben Hmida, M. Haouari, M.-J. Huguet, and P. Lopez. Solving two-stage hy-
brid ﬂow shop using climbing depth-bounded discrepancy search. Computers and
Industrial Engineering, 2010. In Press.

3. A. Ben Hmida, M.-J. Huguet, P. Lopez, and M. Haouari. Climbing depth-bounded
discrepancy search for solving hybrid ﬂow shop scheduling problems. European
Journal of Industrial Engineering, 1(2):223–243, 2007.

4. S. Bertel and J.-C. Billaut. A genetic algorithm for an industrial multiprocessor
ﬂow shop scheduling problem with recirculation. European Journal of Operational
Research, 159(3):651–662, 2004.

5. G. Brooks and C. White. An algorithm for ﬁnding optimal or near optimal solutions
to the production scheduling problem. Journal of Industrial Engineering, 16:34–40,
1965.

6. J. Chen and C.-Y. Lee. General multiprocessor task scheduling. Naval Research

Logistics, 46:57–74, 1999.

7. J. Dongarra. Performance of various computers using standard linear equations

software. Technical report, University of Tennessee, 2009.

8. M. F. Ercan and Y.-F. Fung. Real-time image interpretation on a multi-layer

architecture. In Proceedings of IEEE TENCON’99, pages 1303–1306, 1999.

9. W. D. Harvey and M. L. Ginsberg. Limited discrepancy search. In Proceedings
of the 14th International Joint Conference on Artiﬁcial Intelligence (IJCAI-95),
volume 1, pages 607–615, Montr´eal, Qu´ebec, Canada, August 1995.

10. A. Jouglet, C. O˘guz, and M. Sevaux. Hybrid ﬂow-shop: a memetic algorithm using
constraint-based scheduling for eﬃcient search. Journal of Mathematical Modelling
and Algorithms, 8:271–292, 2009.

11. J.E. Jr Kelley. The critical-path method: Resources planning and scheduling.
In Thompson G.L. and Muth J.F., editors, Industrial Scheduling, pages 347–365.
Prentice-Hall, Englewood Cliﬀs, 1963.

12. R. E. Korf.

Improved limited discrepancy search.

In Proceedings of the 13th
National Conference on Artiﬁcial Intelligence (AAAI-96), volume 1, pages 286–
291, Portland, OR, August 1996.

13. M. Milano and A. Roli. On the relation between complete and incomplete search:
an informal discussion. In Proceedings of CPAIOR 2002, pages 237–250, Le Croisic,
France, 2002.

14. C. O˘guz and M. F. Ercan. A genetic algorithm for hybrid ﬂow-shop scheduling

with multiprocessor tasks. Journal of Scheduling, 8:323–351, 2005.

15. C. O˘guz, Y.-F. Fung, M. F. Ercan, and X.-T. Qi. Parallel genetic algorithm for
In International Conference on

a ﬂow shop problem with multiprocessor tasks.
Computational Science, pages 548–559, Berlin Heidelberg, 2003.

16. C. O˘guz, Y. Zinder, V. Ha Do, A. Janiak, and M. Lichtenstein. Hybrid ﬂow
shop scheduling problems with multiprocessor task systems. European Journal of
Operational Research, 152:115–133, 2004.

17. P. Prosser and C. Unsworth. LDS: testing the hypothesis. Technical Report DCS

TR-2008-273, Dept of Computing Science, University of Glasgow, 2008.

18. F. S. S¸erifo˘glu and G. Ulusoy. Multiprocessor task scheduling in multistage hy-
brid ﬂow-shops: A genetic algorithm approach. European Journal of Operational
Research, 55(5):504–512, May 2004.

19. F. S. S¸erifo˘glu and G. Ulusoy. Multiprocessor task scheduling in multistage hybrid
ﬂow-shops: An ant colony system approach. International Journal of Production
Research, 44(16):3161–3177, 2006.

20. A. Sprecher, R. Kolisch, and A. Drexl. Semi-active, active, and non-delay schedules
for the ressource-constrained project scheduling problem. European Journal of
Operational Research, 80(1):94–102, 1995.

21. T. Walsh. Depth-bounded discrepancy search. In Proceedings of the 15th Inter-
national Joint Conference on Artiﬁcial Intelligence (IJCAI-97), volume 2, pages
1388–1395, Nagoya, Japan, August 1997."
Markov Localization for Mobile Robots in Dynamic Environments,"  Localization, that is the estimation of a robot's location from sensor data,
is a fundamental problem in mobile robotics. This papers presents a version of
Markov localization which provides accurate position estimates and which is
tailored towards dynamic environments. The key idea of Markov localization is
to maintain a probability density over the space of all locations of a robot in
its environment. Our approach represents this space metrically, using a
fine-grained grid to approximate densities. It is able to globally localize the
robot from scratch and to recover from localization failures. It is robust to
approximate models of the environment (such as occupancy grid maps) and noisy
sensors (such as ultrasound sensors). Our approach also includes a filtering
technique which allows a mobile robot to reliably estimate its position even in
densely populated environments in which crowds of people block the robot's
sensors for extended periods of time. The method described here has been
implemented and tested in several real-world applications of mobile robots,
including the deployments of two mobile robots as interactive museum
tour-guides.
",http://arxiv.org/pdf/1106.0222v1,1,"Journal of Arti(cid:12)ial Intelligene Researh 11 (1999) 391-427

Submitted 1/99; published 11/99

Markov Loalization for Mobile Robots

in Dynami Environments

Dieter Fox

dfoxs.mu.edu

Computer Siene Department and Robotis Institute

Carnegie Mel lon University

Pittsburgh, PA 15213-3891

Wolfram Burgard

burgardinformatik.uni-freiburg.de

Department of Computer Siene

University of Freiburg

D-79110 Freiburg, Germany

Sebastian Thrun

thruns.mu.edu

Computer Siene Department and Robotis Institute

Carnegie Mel lon University

Pittsburgh, PA 15213-3891

Abstrat

Loalization, that is the estimation of a robot's loation from sensor data, is a funda-

mental problem in mobile robotis. This papers presents a version of Markov loalization

whih provides aurate position estimates and whih is tailored towards dynami environ-

ments. The key idea of Markov loalization is to maintain a probability density over the

spae of all loations of a robot in its environment. Our approah represents this spae

metrially, using a (cid:12)ne-grained grid to approximate densities. It is able to globally loalize

the robot from srath and to reover from loalization failures. It is robust to approxi-

mate models of the environment (suh as oupany grid maps) and noisy sensors (suh

as ultrasound sensors). Our approah also inludes a (cid:12)ltering tehnique whih allows a

mobile robot to reliably estimate its position even in densely populated environments in

whih rowds of people blok the robot's sensors for extended periods of time. The method

desribed here has been implemented and tested in several real-world appliations of mobile

robots, inluding the deployments of two mobile robots as interative museum tour-guides.

1. Introdution

Robot loalization has been reognized as one of the most fundamental problems in mobile

robotis

Cox & Wilfong, 1990; Borenstein et al., 1996

. The aim of loalization is to

(

)

estimate the postition of a robot in its environment, given a map of the environment and

sensor data. Most suessful mobile robot systems to date utilize loalization, as knowledge

of the robot's position is essential for a broad range of mobile robot tasks.

Loalization|often referred to as position estimation or position ontrol|is urrently a

highly ative (cid:12)eld of researh, as a reent book by Borenstein and olleagues

1996

suggests.

(

)

The loalization tehniques developed so far an be distinguished aording to the type of

(cid:13)1999 AI Aess Foundation and Morgan Kaufmann Publishers. All rights reserved.


Fox, Burgard & Thrun

problem they attak. Traking or loal tehniques aim at ompensating odometri errors

ourring during robot navigation. They require, however, that the initial loation of the

robot is (approximately) known and they typially annot reover if they lose trak of the

robot's position (within ertain bounds). Another family of approahes is alled global

tehniques. These are designed to estimate the position of the robot even under global

unertainty. Tehniques of this type solve the so-alled wake-up robot problem, in that they

an loalize a robot without any prior knowledge about its position. They furthermore an

handle the kidnapped robot problem, in whih a robot is arried to an arbitrary loation

during it's operation

. Global loalization tehniques are more powerful than loal ones.

1

They typially an ope with situations in whih the robot is likely to experiene serious

positioning errors.

In this paper we present a metri variant of Markov loalization, a tehnique to globally

estimate the position of a robot in its environment. Markov loalization uses a probabilisti

framework to maintain a position probability density over the whole set of possible robot

poses. Suh a density an have arbitrary forms representing various kinds of information

about the robot's position. For example, the robot an start with a uniform distribution

representing that it is ompletely unertain about its position. It furthermore an ontain

multiple modes in the ase of ambiguous situations. In the usual ase, in whih the robot

is highly ertain about its position, it onsists of a unimodal distribution entered around

the true position of the robot. Based on the probabilisti nature of the approah and the

representation, Markov loalization an globally estimate the position of the robot, it an

deal with ambiguous situations, and it an re-loalize the robot in the ase of loalization

failures. These properties are basi preonditions for truly autonomous robots designed to

operate over long periods of time.

Our method uses a (cid:12)ne-grained and metri disretization of the state spae. This ap-

proah has several advantages over previous ones, whih predominately used Gaussians or

oarse-grained, topologial representations for approximating a robot's belief. First, it pro-

vides more aurate position estimates, whih are required in many mobile robot tasks (e.g.,

tasks involving mobile manipulation). Seond, it an inorporate raw sensory input suh as

a single beam of an ultrasound sensor. Most previous approahes to Markov loalization, in

ontrast, sreen sensor data for the presene or absene of landmarks, and they are prone

to fail if the environment does not align well with the underlying assumptions (e.g., if it

does not ontain any of the required landmarks).

Most importantly, however, previous Markov loalization tehniques assumed that the

environment is stati. Therefore, they typially fail in highly dynami environments, suh

as publi plaes where rowds of people may over the robot's sensors for extended periods

of time. To deal with suh situations, our method applies a (cid:12)ltering tehnique that, in

essene, updates the position probability density using only those measurements whih are

with high likelihood produed by known ob jets ontained in the map. As a result, it

permits aurate loalization even in densely rowded, non-stati environments.

Our Markov loalization approah has been implemented and evaluated in various envi-

ronments, using di(cid:11)erent kinds of robots and sensor modalities. Among these appliations

are the deployments of the mobile robots Rhino and Minerva (see Figure 1) as intera-

1. Please note that the wake-up problem is the speial ase of the kidnapped robot problem in whih the

robot is told that it has been arried away.

392

Markov Loalization for Mobile Robots in Dynami Environments

Fig. 1. The mobile robots Rhino (a) and Minerva (b) ating as interative museum tour-guides.

(a)

(b)

tive museum tour-guide robots (Burgard et al., 1998a, 2000; Thrun et al., 1999) in the

Deutshes Museum Bonn and the National Museum of Amerian History in Washington,

DC, respetively. Experiments desribed in this paper illustrate the ability of our Markov

loalization tehnique to deal with approximate models of the environment, suh as ou-

pany grid maps and noisy sensors suh as ultrasound sensors, and they demonstrate that

our approah is well-suited to loalize robots in densely rowded environments, suh as

museums full of people.

The paper is organized as follows. The next setion desribes the mathematial frame-

work of Markov loalization. We introdue our metri version of Markov loalization in

Setion 3. This setion also presents a probabilisti model of proximity sensors and a (cid:12)lter-

ing sheme to deal with highly dynami environments. Thereafter, we desribe experimental

results illustrating di(cid:11)erent aspets of our approah. Related work is disussed in Setion 5

followed by onluding remarks.

2. Markov Loalization

To introdue the ma jor onepts, we will begin with an intuitive desription of Markov

loalization, followed by a mathematial derivation of the algorithm. The reader may

notie that Markov loalization is a speial ase of probabilisti state estimation, applied

to mobile robot loalization (see also Russell & Norvig, 1995; Fox, 1998 and Koenig &

Simmons, 1998).

For larity of the presentation, we will initially make the restritive assumption that the

environment is stati. This assumption, alled Markov assumption, is ommonly made in

the robotis literature. It postulates that the robot's loation is the only state in the envi-

ronment whih systematially a(cid:11)ets sensor readings. The Markov assumption is violated

if robots share the same environment with people. Further below, in Setion 3.3, we will

side-step this assumption and present a Markov loalization algorithm that works well even

in highly dynami environments, e.g., museums full of people.

2.1 The Basi Idea

Markov loalization addresses the problem of state estimation from sensor data. Markov

loalization is a probabilisti algorithm: Instead of maintaining a single hypothesis as to

393

Fox, Burgard & Thrun

Fig. 2. The basi idea of Markov loalization: A mobile robot during global loalization.

where in the world a robot might be, Markov loalization maintains a probability distribution

over the spae of all suh hypotheses. The probabilisti representation allows it to weigh

these di(cid:11)erent hypotheses in a mathematially sound way.

Before we delve into mathematial detail, let us illustrate the basi onepts with a

simple example. Consider the environment depited in Figure 2. For the sake of simpliity,

let us assume that the spae of robot positions is one-dimensional, that is, the robot an

only move horizontally (it may not rotate). Now suppose the robot is plaed somewhere in

this environment, but it is not told its loation. Markov loalization represents this state

of unertainty by a uniform distribution over all positions, as shown by the graph in the

(cid:12)rst diagram in Figure 2. Now let us assume the robot queries its sensors and (cid:12)nds out

that it is next to a door. Markov loalization modi(cid:12)es the belief by raising the probability

for plaes next to doors, and lowering it anywhere else. This is illustrated in the seond

diagram in Figure 2. Notie that the resulting belief is multi-modal, re(cid:13)eting the fat that

the available information is insuÆient for global loalization. Notie also that plaes not

next to a door still possess non-zero probability. This is beause sensor readings are noisy,

and a single sight of a door is typially insuÆient to exlude the possibility of not being

next to a door.

Now let us assume the robot moves a meter forward. Markov loalization inorporates

this information by shifting the belief distribution aordingly, as visualized in the third

diagram in Figure 2. To aount for the inherent noise in robot motion, whih inevitably

leads to a loss of information, the new belief is smoother (and less ertain) than the previous

one. Finally, let us assume the robot senses a seond time, and again it (cid:12)nds itself next to a

door. Now this observation is multiplied into the urrent (non-uniform) belief, whih leads

to the (cid:12)nal belief shown at the last diagram in Figure 2. At this point in time, most of the

probability is entered around a single loation. The robot is now quite ertain about its

position.

394

Markov Loalization for Mobile Robots in Dynami Environments

2.2 Basi Notation

To make this more formal, let us denote the position (or: loation) of a mobile robot by a

three-dimensional variable l = hx; y ; (cid:18)i, omprising its x-y oordinates (in some Cartesian

oordinate system) and its heading diretion (cid:18) . Let l

denote the robot's true loation at

t

time t, and L

denote the orresponding random variable. Throughout this paper, we will

t

use the terms position and loation interhangeably.

Typially, the robot does not know its exat position.

Instead, it arries a belief as

to where it might be. Let B el(L

) denote the robot's position belief at time t. B el(L

)

t

t

is a probability distribution over the spae of positions. For example, B el(L

= l) is the

t

probability (density) that the robot assigns to the possibility that its loation at time t is

l. The belief is updated in response to two di(cid:11)erent types of events: The arrival of a mea-

surement through the robot's environment sensors (e.g., a amera image, a sonar san), and

the arrival of an odometry reading (e.g., wheel revolution ount). Let us denote environ-

ment sensor measurements by s and odometry measurements by a, and the orresponding

random variables by S and A, respetively.

The robot pereives a stream of measurements, sensor measurements s and odometry

readings a. Let

d = fd

; d

; : : : ; d

g

(1)

0

1

T

denote the stream of measurements, where eah d

(with 0 (cid:20) t (cid:20) T ) either is a sensor

t

measurement or an odometry reading. The variable t indexes the data, and T is the most

reently olleted data item (one might think of t as \time""). The set d, whih omprises

all available sensor data, will be referred to as the data.

2.3 Reursive Loalization

Markov loalization estimates the posterior distribution over L

onditioned on all available

T

data, that is

P (L

= l j d) = P (L

= l j d

; : : : ; d

):

(2)

T

T

0

T

Before deriving inremental update equations for this posterior, let us brie(cid:13)y make expliit

the key assumption underlying our derivation, alled the Markov assumption. The Markov

assumption, sometimes referred to as stati world assumption, spei(cid:12)es that if one knows

the robot's loation l

, future measurements are independent of past ones (and vie versa):

t

P (d

; d

; : : : j L

= l; d

; : : : ; d

) = P (d

; d

; : : : j L

= l) 8t

(3)

t+1

t+2

t

0

t

t+1

t+2

t

In other words, we assume that the robot's loation is the only state in the environment, and

knowing it is all one needs to know about the past to predit future data. This assumption

is learly inaurate if the environment ontains moving (and measurable) ob jets other

than the robot itself. Further below, in Setion 3.3, we will extend the basi paradigm to

non-Markovian environments, e(cid:11)etively devising a loalization algorithm that works well

in a broad range of dynami environments. For now, however, we will adhere to the Markov

assumption, to failitate the derivation of the basi algorithm.

395

Fox, Burgard & Thrun

When omputing P (L

= l j d), we distinguish two ases, depending on whether the

T

most reent data item d

is a sensor measurement or an odometry reading.

T

Case 1: The most reent data item is a sensor measurement d

= s

.

T

T

Here

P (L

= l j d) = P (L

= l j d

; : : : ; d

; s

):

(4)

T

T

0

T (cid:0)1

T

Bayes rule suggests that this term an be transformed to

P (s

j d

; : : : ; d

; L

= l) P (L

= l j d

; : : : ; d

)

T

0

T (cid:0)1

T

T

0

T (cid:0)1

;

(5)

P (s

j d

; : : : ; d

)

T

0

T (cid:0)1

whih, beause of our Markov assumption, an be simpli(cid:12)ed to:

P (s

j L

= l) P (L

= l j d

; : : : ; d

)

T

T

T

0

T (cid:0)1

:

(6)

P (s

j d

; : : : ; d

)

T

0

T (cid:0)1

We also observe that the denominator an be replaed by a onstant (cid:11)

, sine it does not

T

depend on L

. Thus, we have

T

P (L

= l j d) = (cid:11)

P (s

j L

= l) P (L

= l j d

; : : : ; d

):

(7)

T

T

T

T

T

0

T (cid:0)1

The reader may notie the inremental nature of Equation (7): If we write

B el(L

= l) = P (L

= l j d

; : : : ; d

);

(8)

T

T

0

T

to denote the robot's belief Equation (7) beomes

B el(L

= l) = (cid:11)

P (s

j l) B el(L

= l):

(9)

T

T

T

T (cid:0)1

In this equation we replaed the term P (s

j L

= l) by P (s

j l) based on the assumption

T

T

T

that it is independent of the time.

Case 2: The most reent data item is an odometry reading: d

= a

.

T

T

Here we ompute P (L

= l j d) using the Theorem of Total Probability:

T

Z

P (L

= l j d) =

P (L

= l j d; L

= l

) P (L

= l

j d) dl

:

(10)

T

T

T (cid:0)1

T (cid:0)1

0

0

0

Consider the (cid:12)rst term on the right-hand side. Our Markov assumption suggests that

P (L

= l j d; L

= l

) = P (L

= l j d

; : : : ; d

; a

; L

= l

)

(11)

T

T (cid:0)1

T

0

T (cid:0)1

T

T (cid:0)1

0

0

= P (L

= l j a

; L

= l

)

(12)

T

T

T (cid:0)1

0

The seond term on the right-hand side of Equation (10) an also be simpli(cid:12)ed by observing

that a

does not arry any information about the position L

:

T

T (cid:0)1

P (L

= l

j d) = P (L

= l

j d

; : : : ; d

; a

)

(13)

T (cid:0)1

T (cid:0)1

0

T (cid:0)1

T

0

0

= P (L

= l

j d

; : : : ; d

)

(14)

T (cid:0)1

0

T (cid:0)1

0

396

Markov Loalization for Mobile Robots in Dynami Environments

Substituting 12 and 14 bak into Equation (10) gives us the desired result

P (L

= l j d) =

P (L

= l j a

; L

= l

) P (L

= l

j d

; : : : ; d

) dl

:

(15)

T

T

T

T (cid:0)1

T (cid:0)1

0

T (cid:0)1

0

0

0

Z

Notie that Equation (15) is, too, of an inremental form. With our de(cid:12)nition of belief

above, we have

B el(L

= l) =

P (l j a

; l

) B el(L

= l

) dl

:

(16)

T

T

T (cid:0)1

Z

0

0

0

Please note that we used P (l j a

; l

) instead of P (L

= l j a

; L

= l

) sine we assume

T

T

T

T (cid:0)1

0

0

that it does not hange over time.

2.4 The Markov Loalization Algorithm

Update Equations (9) and (16) form the ore of the Markov loalization algorithm. The full

algorithm is shown in Table 1. Following Basye et al.

1992

and Russell & Norvig

1995

,

(

)

(

)

we denote P (l j a; l

) as the robot's motion model, sine it models how motion e(cid:11)et the

0

robot's position. The onditional probability P (s j l) is alled pereptual model, beause it

models the outome of the robot's sensors.

In the Markov loalization algorithm P (L

= l), whih initializes the belief B el(L

),

0

0

re(cid:13)ets the prior knowledge about the starting position of the robot. This distribution

an be initialized arbitrarily, but in pratie two ases prevail: If the position of the robot

relative to its map is entirely unknown, P (L

) is usually uniformly distributed. If the initial

0

position of the robot is approximately known, then P (L

) is typially a narrow Gaussian

0

distribution entered at the robot's position.

2.5 Implementations of Markov Loalization

The reader may notie that the priniple of Markov loalization leaves open

1. how the robot's belief B el(L) is represented and

2. how the onditional probabilities P (l j a; l

) and P (s j l) are omputed.

0

Aordingly, existing approahes to Markov loalization mainly di(cid:11)er in the representation

of the state spae and the omputation of the pereptual model. In this setion we will

brie(cid:13)y disuss di(cid:11)erent implementations of Markov loalization fousing on these two topis

(see Setion 5 for a more detailed disussion of related work).

1. State Spae Representations: A very ommon approah for the representation of

the robots belief B el(L) is based on Kalman (cid:12)ltering

Kalman, 1960; Smith et al.,

(

1990

whih rests on the restritive assumption that the position of the robot an be

)

modeled by a unimodal Gaussian distribution. Existing implementations

Leonard

(

& Durrant-Whyte, 1992; Shiele & Crowley, 1994; Gutmann & Shlegel, 1996; Ar-

ras & Vestli, 1998

have proven to be robust and aurate for keeping trak of the

)

robot's position. Beause of the restritive assumption of a Gaussian distribution these

tehniques lak the ability to represent situations in whih the position of the robot

397

Fox, Burgard & Thrun

for eah loation l do

/* initialize the belief */

B el(L

= l)  (cid:0) P (L

= l)

(17)

0

0

end for

forever do

if new sensory input s

is reeived do

T

(cid:11)

 (cid:0) 0

T

for eah loation l do

/* apply the pereption model */

d

B el(L

= l)  (cid:0) P (s

j l) (cid:1) B el(L

= l)

(18)

T

T

T (cid:0)1

(cid:11)

 (cid:0) (cid:11)

+

B el(L

= l)

(19)

T

T

T

d

end for

for eah loation l do

/* normalize the belief */

B el(L

= l)  (cid:0) (cid:11)

(cid:1)

B el(L

= l)

(20)

T

T

T

(cid:0)1

d

end for

end if

if an odometry reading a

is reeived do

T

for eah loation l do

/* apply the motion model */

B el(L

= l)  (cid:0)

P (l j l

; a

) (cid:1) B el(L

= l

) dl

(21)

T

T

T (cid:0)1

0

0

0

Z

end for

end if

end forever

Tab. 1. The Markov loalization algorithm

maintains multiple, distint beliefs (.f. 2). As a result, loalization approahes using

Kalman (cid:12)lters typially require that the starting position of the robot is known and

are not able to re-loalize the robot in the ase of loalization failures. Additionally,

Kalman (cid:12)lters rely on sensor models that generate estimates with Gaussian uner-

tainty. This assumption, unfortunately, is not met in all situations (see for example

Dellaert et al. 1999).

398

Markov Loalization for Mobile Robots in Dynami Environments

To overome these limitations, di(cid:11)erent approahes have used inreasingly riher

shemes to represent unertainty in the robot's position, moving beyond the Gaussian

density assumption inherent in the vanilla Kalman (cid:12)lter. Nourbakhsh et al.

1995

,

(

)

Simmons & Koenig

1995

, and Kaelbling et al.

1996

use Markov loalization for

(

)

(

)

landmark-based orridor navigation and the state spae is organized aording to the

oarse, topologial struture of the environment and with generally only four possible

orientations of the robot. These approahes an, in priniple, solve the problem of

global loalization. However, due to the oarse resolution of the state representation,

the auray of the position estimates is limited. Topologial approahes typially give

only a rough sense as to where the robot is. Furthermore, these tehniques require

that the environment satis(cid:12)es an orthogonality assumption and that there are ertain

landmarks or abstrat features that an be extrated from the sensor data. These

assumptions make it diÆult to apply the topologial approahes in unstrutured

environments.

2. Sensor Models: In addition to the di(cid:11)erent representations of the state spae various

pereption models have been developed for di(cid:11)erent types of sensors (see for example

Morave, 1988; Kortenkamp & Weymouth, 1994; Simmons & Koenig, 1995; Burgard

et al., 1996; Dellaert et al., 1999; and Konolige, 1999). These sensor models di(cid:11)er

in the way how they ompute the probability of the urrent measurement. Whereas

topologial approahes suh as

Kortenkamp & Weymouth, 1994; Simmons & Koenig,

(

1995; Kaelbling et al., 1996

(cid:12)rst extrat landmark information out of a sensor san,

)

the approahes in

Morave, 1988; Burgard et al., 1996; Dellaert et al., 1999; Konolige,

(

1999

operate on the raw sensor measurements. The tehniques for proximity sensors

)

desribed in

Morave, 1988; Burgard et al., 1996; Konolige, 1999

mainly di(cid:11)er in

(

)

their eÆieny and how they model the harateristis of the sensors and the map of

the environment.

In order to ombine the strengths of the previous representations, our approah relies on

a (cid:12)ne and less restritive representation of the state spae (Burgard et al., 1996, 1998b;

Fox, 1998). Here the robot's belief is approximated by a (cid:12)ne-grained, regularly spaed grid,

where the spatial resolution is usually between 10 and 40 m and the angular resolution is

usually 2 or 5 degrees. The advantage of this approah ompared to the Kalman-(cid:12)lter based

tehniques is its ability to represent multi-modal distributions, a prerequisite for global

loalization from srath. In ontrast to the topologial approahes to Markov loalization,

our approah allows aurate position estimates in a muh broader range of environments,

inluding environments that might not even possess identi(cid:12)able landmarks. Sine it does

not depend on abstrat features, it an inorporate raw sensor data into the robot's belief.

And it typially yields results that are an order of magnitude more aurate. An obvious

shortoming of the grid-based representation, however, is the size of the state spae that

has to be maintained. Setion 3.4 addresses this issue diretly by introduing tehniques

that make it possible to update extremely large grids in real-time.

399

Fox, Burgard & Thrun

(a)

(b)

Fig. 3. Typial \banana-shaped"" distributions resulting from di(cid:11)erent motion ations.

3. Metri Markov Loalization for Dynami Environments

In this setion we will desribe our metri variant of Markov loalization. This inludes

appropriate motion and sensor models. We also desribe a (cid:12)ltering tehnique whih is

designed to overome the assumption of a stati world model generally made in Markov

loalization and allows to loalize a mobile robot even in densely rowded environments.

We then desribe our (cid:12)ne-grained grid-based representation of the state spae and present

tehniques to eÆiently update even large state spaes.

3.1 The Ation Model

To update the belief when the robot moves, we have to speify the ation model P (l j l

; a

).

t

0

Based on the assumption of normally distributed errors in translation and rotation, we

use a mixture of two independent, zero-entered Gaussian distributions whose tails are ut

o(cid:11)

Burgard et al., 1996

. The varianes of these distributions are proportional to the length

(

)

of the measured motion.

Figure 3 illustrates the resulting densities for two example paths if the robot's belief

starts with a Dira distribution. Both distributions are three-dimensional (in hx; y ; (cid:18)i-spae)

and Figure 3 shows their 2D pro jetions into hx; yi-spae.

3.2 The Pereption Model for Proximity Sensors

As mentioned above, the likelihood P (s j l) that a sensor reading s is measured at po-

sition l has to be omputed for all positions l in eah update of the Markov loalization

algorithm (see Table 1). Therefore, it is ruial for on-line position estimation that this

quantity an be omputed very eÆiently. Morave

1988

proposed a method to ompute

(

)

a generally non-Gaussian probability density funtion P (s j l) over a disrete set of possible

distanes measured by an ultrasound sensor at loation l. In a (cid:12)rst implementation of our

approah

Burgard et al., 1996

we used a similar method, whih unfortunately turned out

(

)

to be omputationally too expensive for loalization in real-time.

To overome this disadvantage, we developed a sensor-model whih allows to ompute

P (s j l) solely based on the distane o

to the losest obstale in the map along the diretion

l

of the sensor. This distane an be omputed by ray-traing in oupany grid maps or

400

Markov Loalization for Mobile Robots in Dynami Environments

)
l

i

|
d
(
m
P

y
t
i
l
i
b
a
b
o
r
p

0.125

0.1

0.075

0.05

0.025

0

o

l

Sonar
Laser

i

)
d
(
P

u

y
t
i
l
i
b
a
b
o
r
p

100

200

300

400

500

measured distance     [cm]

di

(a)

0.125

0.1

0.075

0.05

0.025

0

Sonar
Laser

100

200

300

400

500

measured distance     [cm]

di

(b)

Fig. 4. Probability of measuring a distane d

(a) if obstale in distane o

is deteted and (b) due

i

l

to unknown obstales.

CAD-models of the environment. In partiular, we onsider a disretization d

; : : : ; d

of

1

n

possible distanes measured by a proximity sensor. In our disretization, the size of the

ranges (cid:1)

= d

(cid:0) d

is the same for all i, and d

orresponds to the maximal range of

d

i+1

i

n

the proximity sensor

. Let P (d

j l) denote the probability of measuring a distane d

if the

i

i

2

robot is at loation l. In order to derive this probability we (cid:12)rst onsider the following two

ases (see also Hennig 1997 and Fox 1998):

a.) Known obstales: If the sensor detets an obstale the resulting distribution is

modeled by a Gaussian distribution with mean at the distane to this obstale. Let

P

(d j l) denote the probability of measuring distane d if the robot is at loation l,

m

assuming that the sensor beam is re(cid:13)eted by the losest obstale in the map (along the

sensor beam). We denote the distane to this spei(cid:12) obstale by o

. The probability

l

P

(d j l) is then given by a Gaussian distribution with mean at o

:

m

l

P

(d j l) =

e

(22)

m

(cid:27)

2(cid:25)

1

(cid:0)

(d(cid:0)o

)

2

l

2

p

2(cid:27)

The standard deviation (cid:27) of this distribution models the unertainty of the measured

distane, based on

(cid:15) the granularity of the disretization of L, whih represents the robot's position,

(cid:15) the auray of the world model, and

(cid:15) the auray of the sensor.

Figure 4(a) gives examples of suh Gaussian distributions for ultrasound sensors and

laser range-(cid:12)nders. Here the distane o

to the losest obstale is 230m. Observe here

l

that the laser sensor has a higher auray than the ultrasound sensor, as indiated

by the smaller variane.

b.) Unknown obstales: In Markov loalization, the world model generally is assumed

to be stati and omplete. However, mobile robot environments are often populated

and therefore ontain ob jets that are not inluded in the map. Consequently, there is

2. Typial values for n are between 64 and 256 and the maximal range d

is typially 500m or 1000m.

n

401

 
 
 
 
 
Fox, Burgard & Thrun

a non-zero probability that the sensor is re(cid:13)eted by an obstale not represented in the

world model. Assuming that these ob jets are equal ly distributed in the environment,

the probability P

(d

) of deteting an unknown obstale at distane d

is independent

u

i

i

of the loation of the robot and an be modeled by a geometri distribution. This

distribution results from the following observation. A distane d

is measured if the

i

sensor is not re(cid:13)eted by an obstale at a shorter distane d

and is re(cid:13)eted at

j<i

distane d

. The resulting probability is

i

(

0

i = 0

P

(d

) =

(23)

u

i

P

(1 (cid:0)

P

(d

)) otherwise:

r

u

j

j<i

In this equation the onstant 

is the probability that the sensor is re(cid:13)eted by an

r

unknown obstale at any range given by the disretization.

A typial distribution for sonar and laser measurements is depited in Figure 4(b). In

this example, the relatively large probability of measuring 500m is due to the fat

that the maximum range of the proximity sensors is set to 500m. Thus, this distane

represents the probability of measuring at least 500m.

Obviously, only one of these two ases an our at a ertain point in time, i.e., the

sensor beam is either re(cid:13)eted by a known or an unknown ob jet. Thus, P (d

j l) is a

i

a mixture of the two distributions P

and P

. To determine the ombined probability

m

u

P (d

j l) of measuring a distane d

if the robot is at loation l we onsider the following

i

i

two situations: A distane d

is measured, if

i

a.) the sensor beam is

1.) not re(cid:13)eted by an unknown obstale before reahing distane d

i

X

a

= 1 (cid:0)

P

(d

);

(24)

1

u

j

j<i

2.) and re(cid:13)eted by the known obstale at distane d

i

a

= 

P

(d

j l)

(25)

2

d

m

i

b.) OR the beam is

1.) re(cid:13)eted neither by an unknown obstale nor by the known obstale before

reahing distane d

i

X

b

= 1 (cid:0)

P (d

j l)

(26)

1

j

j<i

2.) and re(cid:13)eted by an unknown obstale at distane d

i

b

= 

:

(27)

2

r

402


Markov Loalization for Mobile Robots in Dynami Environments

)
l

|

i

d
(
p

y
t
i
l
i
b
a
b
o
r
p

0.125

0.1

0.075

0.05

0.025

0

Approximated
Measured

o

l

100

200

300

400

500

measured distance     [cm]

di

(a)

)
l

|

i

d
(
p

y
t
i
l
i
b
a
b
o
r
p

0.125

0.1

0.075

0.05

0.025

0

Approximated
Measured

o

l

100

200

300

400

500

measured distance     [cm]

di

(b)

Fig. 5. Measured and approximated probabilities of (a) sonar and (b) laser measurements given

the distane o

to the losest obstale along the sensing diretion.

l

The parameter 

in Equation (25) denotes the probability that the sensor detets the losest

d

obstale in the map. These onsiderations for the ombined probability are summarized in

Equation (28). By double negation and insertion of the Equations (24) to (27), we (cid:12)nally

get Equation (31).

(cid:16)

(cid:17)

P (d

j l) =

p

(a

^ a

) _

(b

^ b

)

(28)

i

1

2

1

2

(cid:16)

(cid:17)

= :p

:(a

^ a

) ^ :(b

^ b

)

(29)

1

2

1

2

(cid:16)

(cid:17)

= 1 (cid:0)

[1 (cid:0) P (a

a

)℄ (cid:1) [1 (cid:0) P (b

b

)℄

(30)

1

2

1

2

(cid:16)

(cid:17)

X

X

= 1 (cid:0)

1 (cid:0) (1 (cid:0)

P

(d

)) 

P

(d

j l))) (cid:1) (1 (cid:0) (1 (cid:0)

P (d

)) 

(31)

u

j

d

m

i

j

r

j<i

j<i

To obtain the probability of measuring d

, the maximal range of the sensor, we exploit the

n

following equivalene: The probability of measuring a distane larger than or equal to the

maximal sensor range is equivalent to the probability of not measuring a distane shorter

than d

. In our inremental sheme, this probability an easily be determined:

n

P (d

j l) = 1 (cid:0)

P (d

j l)

(32)

n

j

X

j<n

To summarize, the probability of sensor measurements is omputed inrementally for the

di(cid:11)erent distanes starting at distane d

= 0m. For eah distane we onsider the prob-

1

ability that the sensor beam reahes the orresponding distane and is re(cid:13)eted either by

the losest obstale in the map (along the sensor beam), or by an unknown obstale.

In order to adjust the parameters (cid:27) , 

and 

of our pereption model we olleted

r

d

eleven million data pairs onsisting of the expeted distane o

and the measured distane

l

d

during the typial operation of the robot. From these data we were able to estimate the

i

probability of measuring a ertain distane d

if the distane o

to the losest obstale in

i

l

the map along the sensing diretion is given. The dotted line in Figure 5(a) depits this

probability for sonar measurements if the distane o

to the next obstale is 230m. Again,

l

the high probability of measuring 500m is due to the fat that this distane represents

the probability of measuring at least 500m. The solid line in the (cid:12)gure represents the

distribution obtained by adapting the parameters of our sensor model so as to best (cid:12)t the

403

 
 
 
 
Fox, Burgard & Thrun

probability

0.4

0.3

0.2

0.1

0

100

200

300
expected distance [cm]

400

500

400

300

measured distance [cm]

200

100

probability

0.4

0.3

0.2

0.1

0

100

200

300
expected distance [cm]

400

500

400

300

measured distance [cm]

200

100

(a)

(b)

probability

0.4

0.3

0.2

0.1

0

100

200

300
expected distance [cm]

400

500

400

300

measured distance [cm]

200

100

probability

0.4

0.3

0.2

0.1

0

100

200

300
expected distance [cm]

400

500

400

300

measured distance [cm]

200

100

()

(d)

Fig. 6. Measured and approximated probability of sonar (a,b) and laser (,d) measurements, respe-

tively. Eah table ontains the probabilities of distane measurements given the expeted distane

o

extrated from a map of the environment.

l

measured data. The orresponding measured and approximated probabilities for the laser

sensor are plotted in Figure 5(b).

The observed densities for al l possible distanes o

to an obstale for ultrasound sensors

l

and laser range-(cid:12)nder are depited in Figure 6(a) and Figure 6(), respetively. The approx-

imated densities are shown in Figure 6(b) and Figure 6(d). In all (cid:12)gures, the distane o

is

l

labeled \expeted distane"". The similarity between the measured and the approximated

distributions shows that our sensor model yields a good approximation of the data.

Please note that there are further well-known types of sensor noise whih are not ex-

pliitly represented in our sensor model. Among them are speular re(cid:13)etions or ross-talk

whih are often regarded as serious soures of noise in the ontext of ultra-sound sensors.

However, these soures of sensor noise are modeled impliitly by the geometri distribution

resulting from unknown obstales.

3.3 Filtering Tehniques for Dynami Environments

Markov loalization has been shown to be robust to oasional hanges of an environment

suh as opened / losed doors or people walking by. Unfortunately, it fails to loalize a

robot if too many aspets of the environment are not overed by the world model. This

is the ase, for example, in densely rowded environments, where groups of people over

the robots sensors and thus lead to many unexpeted measurements. The mobile robots

Rhino and Minerva, whih were deployed as interative museum tour-guides (Burgard et al.,

1998a, 2000; Thrun et al., 1999), were permanently faed with suh a situation. Figure 7

404

Markov Loalization for Mobile Robots in Dynami Environments

RHINO

(a)

(b)

Fig. 7. Rhino surrounded by visitors in the Deutshes Museum Bonn.

Fig. 8. Typial laser sans obtained when Rhino is surrounded by visitors.

(a)

(b)

shows two ases in whih the robot Rhino is surrounded by many visitors while giving a

tour in the Deutshes Museum Bonn, Germany.

The reason why Markov loalization fails in suh situations is the violation of the Markov

assumption, an independene assumption on whih virtually all loalization tehniques are

based. As disussed in Setion 2.3, this assumption states that the sensor measurements

observed at time t are independent of all other measurements, given that the urrent state

L

of the world is known. In the ase of loalization in densely populated environments,

t

this independene assumption is learly violated when using a stati model of the world.

To illustrate this point, Figure 8 depits two typial laser sans obtained during the

museum pro jets (maximal range measurements are omitted). The (cid:12)gure also shows the

obstales ontained in the map. Obviously, the readings are, to a large extent, orrupted,

sine people in the museum are not represented in the stati world model. The di(cid:11)erent

shading of the beams indiates the two lasses they belong to: the blak lines orrespond

to the stati obstales in the map and are independent of eah other if the position of the

robot is known. The grey-shaded lines are beams re(cid:13)eted by visitors in the Museum. These

sensor beams annot be predited by the world model and therefore are not independent

of eah other. Sine the viinity of people usually inreases the robot's belief of being lose

to modeled obstales, the robot quikly loses trak of its position when inorporating all

405

Fox, Burgard & Thrun

sensor measurements. To reestablish the independene of sensor measurements we ould

inlude the position of the robot and the position of people into the state variable L.

Unfortunately, this is infeasible sine the omputational omplexity of state estimation

inreases exponentially in the number of dependent state variables to be estimated.

A losely related solution to this problem ould be to adapt the map aording to the

hanges of the environment. Tehniques for onurrent map-building and loalization suh

as

Lu & Milios, 1997a; Gutmann & Shlegel, 1996; Shatkey & Kaelbling, 1997; Thrun et

(

al., 1998b

, however, also assume that the environment is almost stati and therefore are

)

unable to deal with suh environments. Another approah would be to adapt the pereption

model to orretly re(cid:13)et suh situations. Note that our pereptual model already assigns

a ertain probability to events where the sensor beam is re(cid:13)eted by an unknown obstale.

Unfortunately, suh approahes are only apable to model suh noise on average. While suh

approahes turn out to work reliably with oasional sensor blokage, they are not suÆient

in situations where more than (cid:12)fty perent of the sensor measurements are orrupted. Our

loalization system therefore inludes (cid:12)lters whih are designed to detet whether a ertain

sensor reading is orrupted or not. Compared to a modi(cid:12)ation of the stati sensor model

desribed above, these (cid:12)lters have the advantage that they do not average over all possible

situations and that their deision is based on the urrent belief of the robot.

The (cid:12)lters are designed to selet those readings of a omplete san whih do not ome

from ob jets ontained in the map. In this setion we introdue two di(cid:11)erent kinds of (cid:12)lters.

The (cid:12)rst one is alled entropy (cid:12)lter. Sine it (cid:12)lters a reading based solely on its e(cid:11)et on

the belief B el(L), it an be applied to arbitrary sensors. The seond (cid:12)lter is the distane

(cid:12)lter whih selets the readings aording to how muh shorter they are than the expeted

value. It therefore is espeially designed for proximity sensors.

3.3.1 The Entropy Filter

The entropy H (L) of the belief over L is de(cid:12)ned as

H (L) = (cid:0)

B el(L = l) log B el(L = l)

(33)

X

l

and is a measure of unertainty about the outome of the random variable L

Cover &

(

Thomas, 1991

. The higher the entropy, the higher the robot's unertainty as to where it

)

is. The entropy (cid:12)lter measures the relative hange of entropy upon inorporating a sensor

reading into the belief B el(L). More spei(cid:12)ally, let s denote the measurement of a sensor

(in our ase a single range measurement). The hange of the entropy of B el(L) given s is

de(cid:12)ned as:

(cid:1)H (L j s)

:= H (L j s) (cid:0) H (L)

(34)

The term H (L j s) is the entropy of the belief B el(L) after inorporating the sensor mea-

surement s (see Equations (18) { (20)). While a positive hange of entropy indiates that

after inorporating s, the robot is less ertain about its position, a negative hange indiates

an inrease in ertainty. The seletion sheme of the entropy (cid:12)lter is to exlude all sensor

measurements s with (cid:1)H (L j s) < 0. In other words, it only uses those sensor readings

on(cid:12)rming the robot's urrent belief.

406

Markov Loalization for Mobile Robots in Dynami Environments

y
t
i
l
i
b
a
b
o
r
p

1

0.8

0.6

0.4

0.2

0

P

(d

j l)

short

i

P

(d

j l)

m

i

o

l

100

200

300

400

500

measured distance [cm]

Fig. 9. Probability P

(d

j l) of expeted measurement and probability P

(d

j l) that a distane

m

i

short

i

d

is shorter than the expeted measurement given the loation l.

i

Entropy (cid:12)lters work well when the robot's belief is foused on the orret hypothesis.

However, they may fail in situations in whih the robot's belief state is inorret. This topi

will be analyzed systematially in the experiments desribed in Setion 4.1. The advantage

of the entropy (cid:12)lter is that it makes no assumptions about the nature of the sensor data

and the kind of disturbanes ourring in dynami environments.

3.3.2 The Distane Filter

The distane (cid:12)lter has spei(cid:12)ally been designed for proximity sensors suh as laser range-

(cid:12)nders. Distane (cid:12)lters are based on a simple observation: In proximity sensing, unmodeled

obstales typially produe readings that are shorter than the distane expeted from the

map. In essene, the distane (cid:12)lter selets sensor readings based on their distane relative

to the distane to the losest obstale in the map.

To be more spei(cid:12), this (cid:12)lter removes those sensor measurements s whih with prob-

ability higher than (cid:13) (this threshold is set to 0:99 in all experiments) are shorter than

expeted, and whih therefore are aused by an unmodeled ob jet (e.g. a person).

To see, let d

; : : : ; d

be a disrete set of possible distanes measured by a proximity

1

n

sensor. As in Setion 3.2, we denote by P

(d

j l) the probability of measuring distane d

m

i

i

if the robot is at position l and the sensor detets the losest obstale in the map along the

sensing diretion. The distribution P

desribes the sensor measurement expeted from the

m

map. As desribed above, this distribution is assumed to be Gaussian with mean at the

distane o

to the losest obstale along the sensing diretion. The dashed line in Figure 9

l

represents P

, for a laser range-(cid:12)nder and a distane o

of 230m. We now an de(cid:12)ne the

m

l

probability P

(d

j l) that a measured distane d

is shorter than the expeted one given

short

i

i

the robot is at position l. This probability is obviously equivalent to the probability that

the expeted measurement o

is longer than d

given the robot is at loation l and thus an

l

i

be omputed as follows:

P

(d

j l) =

P

(d

j l):

(35)

short

i

m

j

X

j>i

407

Fox, Burgard & Thrun

B el(L

= l)

t

(cid:18)

x

y

(0; 0; 0)

Fig. 10. Grid-based representation of the state spae

In pratie, however, we are interested in the probability P

(d

) that d

is shorter

short

i

i

than expeted, given the omplete urrent belief of the robot. Thus, we have to average

over all possible positions of the robot:

X

P

(d

) =

P

(d

j l)B el(L = l)

(36)

short

i

short

i

l

Given the distribution P

(d

), we now an implement the distane (cid:12)lter by exluding all

short

i

sensor measurements d

with P

(d

) > (cid:13) . Whereas the entropy (cid:12)lter (cid:12)lters measurements

i

short

i

aording to their e(cid:11)et on the belief state of the robot the distane (cid:12)lter selets measure-

ments solely based on their value and regardless of their e(cid:11)et on the robot's ertainty.

It should be noted that Fox

1998

additionally developed a blokage (cid:12)lter for proximity

(

)

sensors, whih is based on a probabilisti desription of situations in whih a sensor is

bloked by an unknown obstale. We omit this (cid:12)lter here sine its derivation is quite omplex

and the resulting (cid:12)lter is not signi(cid:12)antly di(cid:11)erent from the distane (cid:12)lter desribed here.

3.4 Grid-based Representation of the State Spae

We will now return to the issue of how to represent and ompute the belief distribution

of the robot eÆiently, desribing what one might think of as the \nut and bolts"" of grid-

based Markov loalization. Reall that to obtain aurate metri position estimates, our

approah to Markov loalization uses a (cid:12)ne-grained disretization of the state spae. Here

L is represented by a three-dimensional, regularly spaed grid, where the spatial resolution

is usually between 10m and 40m and the angular resolution is usually 2 or 5 degrees.

Figure 10 illustrates the struture of a position probability grid. Eah layer of suh a grid

orresponds to all possible poses of the robot with the same orientation.

While suh a (cid:12)ne-grained approximation makes it possible to estimate the robot's po-

sition with high auray, an obvious disadvantage of suh a (cid:12)ne-grained disretization lies

408

Markov Loalization for Mobile Robots in Dynami Environments

in the huge state spae whih has to be maintained. For a mid-size environment of size

30 (cid:2) 30m

, an angular grid resolution of 2

, and a ell size of 15 (cid:2) 15m

the state spae

2

Æ

2

onsists of 7; 200; 000 states. The basi Markov loalization algorithm updates eah of these

states for eah sensory input and eah atomi movement of the robot. Current omputer

speed, thus, makes it impossible to update matries of this size in real-time.

To update suh state spaes eÆiently, we have developed two tehniques, whih are

desribed in the remainder of this setion. The (cid:12)rst method, introdued in Setion 3.4.1,

pre-omputes the sensor model. It allows us to determine the likelihood P (s j l) of sensor

measurements by two look-up operations|instead of expensive ray traing operations. The

seond optimization, desribed in Setion 3.4.2, is a seletive update strategy. This strategy

fouses the omputation, by only updating the relevant part of the state spae. Based on

these two tehniques, grid-based Markov loalization an be applied on-line to estimate the

position of a mobile robot during its operation, using a low-ost PC.

3.4.1 Pre-Computation of the Sensor Model

As desribed in Setion 3.2, the pereption model P (s j l) for proximity sensors only depends

on the distane o

to the losest obstale in the map along the sensor beam. Based on the

l

assumption that the map of the environment is stati, our approah pre-omputes and stores

these distanes o

for eah possible robot loation l in the environment. Following our sensor

l

model, we use a disretization d

; : : : ; d

of the possible distanes o

. This disretization

1

n

l

is exatly the same for the expeted and the measured distanes. We then store for eah

loation l only the index of the expeted distane o

in a three-dimensional table. Please

l

note that this table only needs one byte per value if 256 di(cid:11)erent values for the disretization

of o

are used. The probability P (d

j o

) of measuring a distane d

if the losest obstale

l

i

l

i

is at distane o

(see Figure 6) an also be pre-omputed and stored in a two-dimensional

l

lookup-table.

As a result, the probability P (s j l) of measuring s given a loation l an quikly be

omputed by two nested lookups. The (cid:12)rst look-up retrieves the distane o

to the losest

l

obstale in the sensing diretion given the robot is at loation l. The seond lookup is then

used to get the probability P (s j o

). The eÆient omputation based on table look-ups

l

enabled our implementation to quikly inorporate even laser-range sans that onsist of

up to 180 values in the overall belief state of the robot. In our experiments, the use of

the look-up tables led to a speed-up-fator of 10, when ompared to a omputation of the

distane to the losest obstale at run-time.

3.4.2 Seletive Update

The seletive update sheme is based on the observation that during global loalization,

the ertainty of the position estimation permanently inreases and the density quikly on-

entrates on the grid ells representing the true position of the robot. The probability of

the other grid ells dereases during loalization and the key idea of our optimization is to

exlude unlikely ells from being updated.

For this purpose, we introdue a threshold

"" and update only those grid ells l with

3

B el(L

= l) > "". To allow for suh a seletive update while still maintaining a density over

t

3. In our urrent implementation "" is set to 1% of the a priori position probability.

409

Fox, Burgard & Thrun

the entire state spae, we approximate P (s

j l) for ells with B el(L

= l) (cid:20) "" by the a

t

t

priori probability of measuring s

. This quantity, whih we all

P (s

), is determined by

t

t

e

averaging over all possible loations of the robot:

X

e

P (s

) =

P (s

j l) P (l)

(37)

t

t

l

Please note that

P (s

) is independent of the urrent belief state of the robot and an

t

e

be determined beforehand. The inremental update rule for a new sensor measurement s

t

is hanged as follows (ompare Equation (9)):

B el(L

= l)  (cid:0)

(38)

(

(cid:11)

(cid:1) P (s

j l) (cid:1) B el(L

= l)

if B el(L

= l) > ""

t

t

t(cid:0)1

t(cid:0)1

t

e

(cid:11)

(cid:1)

P (s

)

(cid:1) B el(L

= l) otherwise

t

t

t(cid:0)1

~

By multiplying

P (s

) into the normalization fator (cid:11)

, we an rewrite this equation as

t

t

B el(L

= l)  (cid:0)

(39)

e

P (s

)

t

~(cid:11)

(cid:1)

(cid:1) B el(L

= l)

if B el(L

= l) > ""

t

t(cid:0)1

t(cid:0)1

8

<

P (s

jl)

t

t

e

where ~(cid:11)

= (cid:11)

(cid:1)

P (s

).

t

t

t

:

~(cid:11)

(cid:1)

B el(L

= l) otherwise

t

t(cid:0)1

The key advantage of the seletive update sheme given in Equation (39) is that all ells

with B el(L

= l) (cid:20) "" are updated with the same value ~(cid:11)

. In order to obtain smooth

t(cid:0)1

t

transitions between global loalization and position traking and to fous the omputation

on the important regions of the state spae L, for example, in the ase of ambiguities we use

a partitioning of the state spae. Suppose the state spae L is partitioned into n segments

or parts (cid:25)

; : : : ; (cid:25)

. A segment (cid:25)

is alled ative at time t if it ontains loations with prob-

1

n

i

ability above the threshold ""; otherwise we all suh a part passive beause the probabilities

of all ells are below the threshold. Obviously, we an keep trak of the individual proba-

bilities within a passive part (cid:25)

by aumulating the normalization fators ~(cid:11)

into a value

i

t

(cid:12)

. Whenever a segment (cid:25)

beomes passive, i.e. the probabilities of all loations within

i

i

(cid:25)

no longer exeed "", the normalizer (cid:12)

(t) is initialized to 1 and subsequently updated as

i

i

follows: (cid:12)

(t + 1) = ~(cid:11)

(cid:1) (cid:12)

(t). As soon as a part beomes ative again, we an restore the

i

t

i

probabilities of the individual grid ells by multiplying the probabilities of eah ell with the

aumulated normalizer (cid:12)

(t). By keeping trak of the robot motion sine a part beame

i

passive, it suÆes to inorporate the aumulated motion whenever the part beomes ative

again. In order to eÆiently detet whether a passive part has to be ativated again, we

store the maximal probability P

of all ells in the part at the time it beomes passive.

max

max

i

Whenever P

(cid:1) (cid:12)

(t) exeeds "", the part (cid:25)

is ativated again beause it ontains at least

i

i

i

one position with probability above the threshold. In our urrent implementation we parti-

tion the state spae L suh that eah part (cid:25)

onsists of all loations with equal orientation

i

relative to the robot's start loation.

To illustrate the e(cid:11)et of this seletive update sheme, let us ompare the update of

ative and passive ells on inoming sensor data. Aording to Equation (39), the di(cid:11)erene

lies in the ratio P (s

j l)=

P (s

). An example of this ratio for our model of proximity sensors

t

t

~

is depited in Figure 11 (here, we replaed s

by a proximity measurement d

).

In the

t

i

beginning of the loalization proess, all ells are ative and updated aording to the ratio

410

Markov Loalization for Mobile Robots in Dynami Environments

o
i
t
a
r
d
o
o
h
i
l
e
k
i
l

9

8

7

6

5

4

3

2

1

0

o

l

Laser
Sonar

100

200

300

400

500

measured distance     [cm]

di

Fig. 11. Ratio

for sonar and laser measurements for expeted distane o

of 230m.

l

~

P (d

)

i

P (d

jl)

i

depited in Figure 11. The measured and expeted distanes for ells that do not represent

the true loation of the robot usually deviate signi(cid:12)antly. Thus, the probabilities of these

ells quikly fall below the threshold "".

Now the e(cid:11)et of the seletive update sheme beomes obvious: Those parts of the state

spae that do not align well with the orientation of the environment, quikly beome passive

as the robot loalizes itself. Consequently, only a small fration of the state spae has to

be updated as soon as the robot has orretly determined its position. If, however, the

position of the robot is lost, then the likelihood ratios for the distanes measured at the

ative loations beome smaller than one on average. Thus the probabilities of the ative

loations derease while the normalizers (cid:12)

of the passive parts inrease until these segments

i

are ativated again. One the true position of the robot is among the ative loations, the

robot is able to re-establish the orret belief.

In extensive experimental tests we did not observe evidene that the seletive update

sheme has a notiably negative impat on the robot's behavior.

In ontrast, it turned

out to be highly e(cid:11)etive, sine in pratie only a small fration (generally less than 5%)

of the state spae has to be updated one the position of the robot has been determined

orretly, and the probabilities of the ative loations generally sum up to at least 0.99.

Thus, the seletive update sheme automatially adapts the omputation time required to

update the belief to the ertainty of the robot. This way, our system is able to eÆiently

trak the position of a robot one its position has been determined. Additionally, Markov

loalization keeps the ability to detet loalization failures and to reloalize the robot. The

only disadvantage lies in the (cid:12)xed representation of the grid whih has the undesirable

e(cid:11)et that the memory requirement in our urrent implementation stays onstant even if

only a minor part of the state spae is updated. In this ontext we would like to mention

that reently promising tehniques have been presented to overome this disadvantage by

applying alternative and dynami representations of the state spae

Burgard et al., 1998b;

(

Fox et al., 1999

.

)

4. Experimental Results

Our metri Markov loalization tehnique, inluding both sensor (cid:12)lters, has been imple-

mented and evaluated extensively in various environments. In this setion we present some

411

 
Fox, Burgard & Thrun

of the experiments arried out with the mobile robots Rhino and Minerva (see Figure 1).

Rhino has a ring of 24 ultrasound sensors eah with an opening angle of 15 degrees. Both,

Rhino and Minerva are equipped with two laser range-(cid:12)nders overing a 360 degrees (cid:12)eld

of view.

The (cid:12)rst set of experiments demonstrates the robustness of Markov loalization in two

real-world senarios.

In partiular, it systematially evaluates the e(cid:11)et of the (cid:12)ltering

tehniques on the loalization performane in highly dynami environments. An additional

experiment illustrates a further advantage of the (cid:12)ltering tehnique, whih enables a mobile

robot to reliably estimate its position even if only an outline of an oÆe environment is

given as a map.

In further experiments desribed in this setion, we will illustrate the ability of our

Markov loalization tehnique to globally loalize a mobile robot in approximate world

models suh as oupany grid maps, even when using inaurate sensors suh as ultrasound

sensors. Finally, we present experiments analyzing the auray and eÆieny of grid-based

Markov loalization with respet to the size of the grid ells.

The experiments reported here demonstrate that Markov loalization is able to globally

estimate the position of a mobile robot, and to reliably keep trak of it even if only an

approximate model of a possibly dynami environment is given, if the robot has a weak

odometry, and if noisy sensors suh as ultrasound sensors are used.

4.1 Long-term Experiments in Dynami Environments

For our mobile robots Rhino and Minerva, whih operated in the Deutshes Museum Bonn

and the US-Smithsonian's National Museum of Amerian History, the robustness and re-

liability of our Markov loalization system was of utmost importane. Aurate position

estimation was a ruial omponent, as many of the obstales were \invisible"" to the robots'

sensors (suh as glass ages, metal bars, stairases, and the alike). Given the estimate of

the robot's position

Fox et al., 1998b

integrated map information into the ollision avoid-

(

)

ane system in order to prevent the robot from olliding with obstales that ould not be

deteted.

Figure 12(a) shows a typial tra jetory of the robot Rhino, reorded in the museum

in Bonn, along with the map used for loalization. The reader may notie that only the

obstales shown in blak were atually used for loalization; the others were either invisible

or ould not be deteted reliably. Rhino used the entropy (cid:12)lter to identify sensor readings

that were orrupted by the presene of people. Rhino's loalization module was able to (1)

globally loalize the robot in the morning when the robot was swithed on and (2) to reliably

and aurately keep trak of the robot's position. In the entire six-day deployment period, in

whih Rhino traveled over 18km, our approah led only to a single software-related ollision,

whih involved an \invisible"" obstale and whih was aused by a loalization error that

was slightly larger than a 30m safety margin.

Figure 12(b) shows a 2km long tra jetory of the robot Minerva in the National Museum

of Amerian History. Minerva used the distane (cid:12)lter to identify readings re(cid:13)eted by

unmodeled ob jets. This (cid:12)lter was developed after Rhino's deployment in the museum in

Bonn, based on an analysis of the loalization failure reported above and in an attempt to

prevent similar e(cid:11)ets in future installations. Based on the distane (cid:12)lter, Minerva was able

412

Markov Loalization for Mobile Robots in Dynami Environments

Duration: 4.8 hours
Distance: 1540 meters

(a)

(b)

Duration: 1 hour
Distance: 2000 meters

Fig. 12. Typial tra jetories of (a) Rhino in the Deutshes Museum Bonn and (b) Minerva in the

National Museum of Amerian History.

to operate reliably over a period of 13 days. During that time Minerva traveled a total of

44km with a maximum speed of 1.63m/se.

Unfortunately, the evidene from the museum pro jets is anedotal. Based on sensor

data olleted during Rhino's deployment in the museum in Bonn, we also investigated the

e(cid:11)et of our (cid:12)lter tehniques more systematially, and under even more extreme onditions.

In partiular, we were interested in the loalization results

a.) when the environment is densely populated (more than 50% of the sensor reading are

orrupted), and

b.) when the robot su(cid:11)ers extreme dead-rekoning errors (e.g. indued by a person arry-

ing the robot somewhere else). Sine suh ases are rare, we manually in(cid:13)ited suh

errors into the original data to analyze their e(cid:11)et.

4.1.1 Datasets

During the experiments, we used two di(cid:11)erent datasets. These sets di(cid:11)er mainly in the

amount of sensor noise.

a.) The (cid:12)rst dataset was olleted during 2.0 hours of robot motion, in whih the robot

traveled approximately 1,000 meters. This dataset was olleted when the museum

was losed, and the robot guided only remote Internet-visitors through the museum.

The robot's top speed was 50m/se. Thus, this dataset was \ideal"" in that the

environment was only sparsely populated, and the robot moved slowly.

b.) The seond dataset was reorded during a period of 4.8 hours, during whih Rhino

traveled approximately 1,540 meters. The path of this dataset is shown in Fig-

ure 12(a). When olleting this data, the robot operated during peak traÆ hours.

It was frequently faed with situations suh as the one illustrated in Figure 7. The

robot's top speed was 80m/se.

Both datasets onsist of logs of odometry and laser range-(cid:12)nder sans, olleted while the

robot moved through the museum. Using the time stamps in the logs, all tests have been

413

Fox, Burgard & Thrun

Denesely populated
Sparcely populated

]

%

[

e
s
i
o
N

60

40

20

1000

4000

7000

10000
Time [sec]

13000

16000

Fig. 13. Perentage of noisy sensor measurements averaged over time intervals of (cid:12)ve minutes.

onduted in real-time simulation on a SUN-Ultra-Spar 1 (177-MHz). The (cid:12)rst dataset

ontained more than 32,000, and the seond dataset more than 73,000 laser sans. To

evaluate the di(cid:11)erent loalization methods, we generated two referene paths, by averaging

over the estimates of nine independent runs for eah (cid:12)lter on the datasets (with small

random noise added to the input data). We veri(cid:12)ed the orretness of both referene paths

by visual inspetion; hene, they an be taken as \ground truth.""

Figure 13 shows the estimated perentage of orrupted sensor readings over time for both

datasets. The dashed line orresponds to the (cid:12)rst data set, while the solid line illustrates

the orruption of the seond (longer) data set. In the seond dataset, more than half of

all measurements were orrupted for extended durations of time, as estimated by analyzing

eah laser reading post-fato as to whether it was signi(cid:12)antly shorter than the distane to

the next obstale.

4.1.2 Traking the Robot's Position

In our (cid:12)rst series of experiments, we were interested in omparing the ability of all three

approahes|plain Markov loalization without (cid:12)ltering, loalization with the entropy (cid:12)lter,

and loalization with the distane (cid:12)lter|to keep trak of the robot's position under normal

working onditions. All three approahes traked the robot's position in the empty museum

well ((cid:12)rst dataset), exhibiting only negligible errors in loalization. The results obtained

for the seond, more hallenging dataset, however, were quite di(cid:11)erent.

In a nutshell,

both (cid:12)lter-based approahes traked the robot's position aurately, whereas onventional

Markov loalization failed frequently. Thus, had we used the latter in the museum exhibit,

it would inevitably have led to a large number of ollisions and other failures.

Filter

None

Entropy

Distane

failures

[%℄

1:6 (cid:6) 0:4

0:9 (cid:6) 0:4

0:0 (cid:6) 0:0

I

failures

[%℄

26:8 (cid:6) 2:4

1:1 (cid:6) 0:3

1:2 (cid:6) 0:7

II

Table 2: Ability to trak the robot's position.

Table 2 summarizes the results obtained for the di(cid:11)erent approahes in this traking

experiment. The (cid:12)rst row of Table 2 provides the perentage of failures for the di(cid:11)erent

414

 
Markov Loalization for Mobile Robots in Dynami Environments

final position

final position

final position

Distance at final position:  19 cm
Certainty at final position: 0.003

(a)

Distance at final position:  1 cm
Certainty at final position: 0.987 (b)

Distance at final position:  1 cm
Certainty at final position: 0.998

()

Fig. 14. Estimated and real paths of the robot along with endpoints of inorporated sensor mea-

surements using (a) no (cid:12)lter, (b) entropy (cid:12)lter, and () distane (cid:12)lter.

(cid:12)lters on the (cid:12)rst dataset (error values represent 95% on(cid:12)dene intervals). Position esti-

mates were onsidered a \failure"" if the estimated loation of the robot deviated from the

referene path by more than 45m for at least 20 seonds. The perentage is measured in

time during whih the position was lost, relative to the total time of the dataset.

As an be seen here, all three approahes work well, and the distane (cid:12)lter provides the

best performane. The seond row provides the failures on the seond dataset. While plain

Markov loalization failed in 26.8% of the overall time, both (cid:12)lter tehniques show almost

equal results with a failure of less than 2%. Thus, the two (cid:12)lter tehniques are robust in

highly dynami environments, plain Markov loalization is prone to fail.

To shed light onto the question as to why Markov loalization performs so poorly when

ompared to the (cid:12)lter algorithms, we analyzed the sensor readings that eah method used

during the loalization task. Figure 14 shows, for a a small fration of the data, the measure-

ments inorporated into the robot's belief by the three di(cid:11)erent approahes. Shown there

are the end points of the sensor measurements used for loalization relative to the positions

on the referene path. Obviously, both (cid:12)lter approahes manage to fous their attention on

the \orret"" sensor measurements, whereas plain Markov loalization inorporates massive

amounts of orrupted (misleading) measurements. As also illustrated by Figure 14, both

(cid:12)lter-based approahes produe more aurate results with a higher ertainty in the orret

position.

4.1.3 Reovery from Extreme Loalization Failures

We onjeture that a key advantage of the original Markov loalization tehnique lies in its

ability to reover from extreme loalization failures. Re-loalization after a failure is often

more diÆult than global loalization from srath, sine the robot starts with a belief that

is entered at a ompletely wrong position. Sine the (cid:12)ltering tehniques use the urrent

belief to selet the readings that are inorporated, it is not lear that they still maintain

the ability to reover from global loalization failures.

To analyze the behavior of the (cid:12)lters under suh extreme onditions, we arried out a

series of experiments during whih we manually introdued suh failures into the data to

test the robustness of these methods in the extreme. More spei(cid:12)ally, we \tele-ported"" the

robot at random points in time to other loations. Tehnially, this was done by hanging

the robot's orientation by 180(cid:6)90 degree and shifting it by 0(cid:6)100m, without letting the

robot know. These perturbations were introdued randomly, with a probability of 0:005 per

415

Fox, Burgard & Thrun

Filter

None

Entropy

Distane

Dataset I

t

[se℄

237 (cid:6) 27

1779 (cid:6) 548

188 (cid:6) 30

re

failures [%℄

10:2 (cid:6) 1:8

45:6 (cid:6) 7:1

6:8 (cid:6) 1:6

Dataset II

t

[se℄

269 (cid:6) 60

1310 (cid:6) 904

235 (cid:6) 46

re

failures [%℄

39:5 (cid:6) 5:1

72:8 (cid:6) 7:3

7:8 (cid:6) 1:9

Table 3: Summary of reovery experiments.

meter of robot motion. Obviously, suh inidents make the robot lose trak of its position.

Eah method was tested on 20 di(cid:11)erently orrupted versions of both datasets. This resulted

in a total of more than 50 position failures in eah dataset. For eah of these failures we

measured the time until the methods re-loalized the robot orretly. Re-Loalization was

assumed to have sueeded if the distane between the estimated position and the referene

path was smaller than 45m for more than 10 seonds.

Table 3 provides re-loalization results for the various methods, based on the two dif-

ferent datasets. Here t

represents the average time in seonds needed to reover from

re

a loalization error. The results are remarkably di(cid:11)erent from the results obtained under

normal operational onditions. Both onventional Markov loalization and the tehnique

using distane (cid:12)lters are relatively eÆient in reovering from extreme positioning errors in

the (cid:12)rst dataset, whereas the entropy (cid:12)lter-based approah is an order of magnitude less

eÆient (see (cid:12)rst row in Table 3). The unsatisfatory performane of the entropy (cid:12)lter in

this experiment is due to the fat that it disregards all sensor measurements that do not

on(cid:12)rm the belief of the robot. While this proedure is reasonable when the belief is orret,

it prevents the robot from deteting loalization failures. The perentage of time when the

position of the robot was lost in the entire run is given in the seond row of the table. Please

note that this perentage inludes both, failures due to manually introdued perturbations

and traking failures. Again, the distane (cid:12)lter is slightly better than the approah with-

out (cid:12)lter, while the entropy (cid:12)lter performs poorly. The average times t

to reover from

re

failures on the seond dataset are similar to those in the (cid:12)rst dataset. The bottom row in

Table 3 provides the perentage of failures for this more diÆult dataset. Here the distane

(cid:12)lter-based approah performs signi(cid:12)antly better than both other approahes, sine it is

able to quikly reover from loalization failures and to reliably trak the robot's position.

The results illustrate that despite the fat that sensor readings are proessed seletively,

the distane (cid:12)lter-based tehnique reovers as eÆiently from extreme loalization errors as

the onventional Markov approah.

4.2 Loalization in Inomplete Maps

A further advantage of the (cid:12)ltering tehniques is that Markov loalization does not require

a detailed map of the environment. Instead, it suÆes to provide only an outline whih

416

Markov Loalization for Mobile Robots in Dynami Environments

(a)

(b)

()

Fig. 15. (a) Outline of the oÆe environment and (b,) examples of (cid:12)ltered (grey) and inorporated

(blak) sensor readings using the distane (cid:12)lter.

C

3m

22m

A

B

31m

(a)

20m

(b)

Fig. 16. (a) Oupany grid map of the 1994 AAAI mobile robot ompetition arena. (b) Tra jetory

of the robot and ultrasound measurements used to globally loalize the robot in this map.

merely inludes the aspets of the world whih are stati. Figure 15(a) shows a ground plan

of our department building, whih ontains only the walls of the university building. The

omplete map, inluding all movable ob jets suh as tables and hairs, is shown in Figure 19.

The two Figures 15(b) and 15() illustrate how the distane (cid:12)lter typially behaves when

traking the robot's position in suh a sparse map of the environment. Filtered readings

are shown in grey, and the inorporated sensor readings are shown in blak. Obviously,

the (cid:12)lter fouses on the known aspets of the map and ignores all ob jets (suh as desks,

hairs, doors and tables) whih are not ontained in the outline. Fox

1998

desribes more

(

)

systemati experiments supporting our belief that Markov loalization in ombination with

the distane (cid:12)lter is able to aurately loalize mobile robots even when relying only on an

outline of the environment.

4.3 Loalization in Oupany Grid Maps Using Sonar

The next experiment desribed here is arried out based on data olleted with the mobile

robot Rhino during the 1994 AAAI mobile robot ompetition

Simmons, 1995

. Figure 16(a)

(

)

shows an oupany grid map

Morave & Elfes, 1985; Morave, 1988

of the environment,

(

)

onstruted with the tehniques desribed in

Thrun et al., 1998a; Thrun, 1998b

. The size

(

)

of the map is 31 (cid:2) 22m

, and the grid resolution is 15m.

2

417

Fox, Burgard & Thrun

Robot position (A)

Robot position (B)

Robot position (C)

(a)

(b)

()

Fig. 17. Density plots after inorporating 5, 18, and 24 sonar sans (darker positions are more

likely).

(a)

(b)

Fig. 18. Odometry information and orreted path of the robot.

Figure 16(b) shows a tra jetory of the robot along with measurements of the 24 ultra-

sound sensors obtained as the robot moved through the ompetition arena. Here we use

this sensor information to globally loalize the robot from srath. The time required to

proess this data on a 400MHz Pentium II is 80 seonds, using a position probability grid

with an angular resolution of 3 degrees. Please note that this is exatly the time needed by

the robot to traverse this tra jetory; thus, our approah works in real-time. Figure 16(b)

also marks positions of the robot after pereiving 5 (A), 18 (B), and 24 (C) sensor sweeps.

The belief states during global loalization at these three points in time are illustrated in

Figure 17.

The (cid:12)gures show the belief of the robot pro jeted onto the hx; yi-plane by plotting for

eah hx; yi-position the maximum probability over all possible orientations. More likely

positions are darker and for illustration purposes, Figures 17(a) and 17(b) use a logarithmi

sale in intensity. Figure 17(a) shows the belief state after integrating 5 sensor sweeps (see

also position A in Figure 16(b)). At this point in time, all the robot knows is that it is in one

of the orridors of the environment. After integrating 18 sweeps of the ultrasound sensors,

the robot is almost ertain that it is at the end of a orridor (ompare position B in Fig-

ures 16(b) and 17(b)). A short time later, after turning left and integrating six more sweeps

of the ultrasound ring, the robot has determined its position uniquely. This is represented

by the unique peak ontaining 99% of the whole probability mass in Figure 17().

Figure 18 illustrates the ability of Markov loalization to orret aumulated dead-

rekoning errors by mathing ultrasound data with oupany grid maps. Figure 18(a)

shows a typial 240m long tra jetory, measured by Rhino's wheel-enoders in the 1994

418

Markov Loalization for Mobile Robots in Dynami Environments

1

22
8

10

13

2

16

7

3

21

20

5

9

19

12

15

18

4

11

17

6

14

Fig. 19. Path of the robot and referene positions

AAAI mobile robot ompetition arena. Obviously, the rotational error of the odometry

quikly inreases. Already after traveling 40m, the aumulated error in the orientation

(raw odometry) is about 50 degrees. Figure 18(b) shows the path of the robot estimated

by Markov loalization, whih is signi(cid:12)antly more orret.

4.4 Preision and Performane

We will now desribe experiments aimed at haraterizing the preision of position esti-

mates. Our experiments also haraterize the time needed for global loalization in relation

to the size of the grid ells. Figure 19 shows a path of the robot Rhino in the Computer

Siene Department's building at the University of Bonn. This path inludes 22 referene

positions, where the true position of the robot was determined using the san mathing

tehnique presented in

Gutmann & Shlegel, 1996; Lu & Milios, 1994

. All data reorded

(

)

during this run were split into four disjoint traes of the sensor data. Eah of these di(cid:11)erent

traes ontained the full length of the path, but only every fourth sensor reading whih was

suÆient to test the loalization performane.

Figure 20(a) shows the loalization error averaged over the four runs and all referene

positions. The error was determined for di(cid:11)erent sizes of grid ells, using a laser range-

(cid:12)nder or ultrasound sensors. These results demonstrate (1) that the average loalization

error for both sensors is generally below the ell size and (2) that laser range-(cid:12)nders provide

a signi(cid:12)antly higher auray than ultrasound sensors. When using the laser range-(cid:12)nder

at a spatial resolution of 4m, the average positioning error an even be redued to 3.5m.

Figure 20(b) shows the average CPU-time needed to globally loalize the robot as a

funtion of the size of the grid ells. The values represent the omputation time needed

on a 266MHz Pentium II for global loalization on the path between the starting point

and position 1.

In this experiment, we used a (cid:12)xed angular resolution of four degrees.

In the ase of 64m ell size, the average loalization time is approximately 2.2 seonds.

419

Fox, Burgard & Thrun

Ultrasound sensor
Laser-range finder

]

m
c
[

r
o
r
r
e
n
o
i
t
a
m

i
t
s
e

e
g
a
r
e
v
A

30

25

20

15

10

5

0

0

10

20

30

40

50

60

70

Grid cell size [cm]

]
c
e
s
[

e
m

i
t
n
o
i
t
a
z
i
l
a
c
o
l

e
g
a
r
e
v
A

120

100

80

60

40

20

0

0

Ultrasound sensor
Laser-range finder

10

20

30

40

50

60

70

Grid cell size [cm]

Fig. 20. (a) Average loalization error and (b) average CPU-time needed for global loalization time

both for ultrasound sensors and laser range-(cid:12)nder depending on the grid resolution.

(a)

(b)

Of ourse, the e(cid:11)etive time needed for global loalization in pratie highly depends on

the struture of the environment and the amount of information gathered on the path of

the robot. For example, due to the symmetry of the orridor of this oÆe environment,

the robot is not able to loalize itself unless it enters a room. The reader may notie

that reently, we developed a deision-theoreti method for atively guiding the robot to

plaes whih allow it to resolve ambiguities during global loalization

Fox et al., 1998a;

(

Fox, 1998

. Based on this method, the loalization proess beomes more eÆient, espeially

)

in oÆe environments with a lot of indistinguishable plaes as, for example, long orridors.

The experiments desribed above demonstrate that our metri variant of Markov loal-

ization is able to eÆiently estimate the position of a mobile robot in dynami environments.

It furthermore an deal with approximate models of the environment suh as oupany

grid maps or rough outline maps. Finally, it is able to eÆiently and aurately estimate

the position of a mobile robot even if ultrasound sensors are used.

5. Related Work

Most of the tehniques for mobile robot loalization in the literature belong to the lass of

loal approahes or traking tehniques, whih are designed to ompensate odometri error

ourring during navigation. They assume that the initial position of the robot is known

(see Borenstein et al. 1996 for a omprehensive overview). For example, Wei(cid:25) et al.

1994

(

)

store angle histograms onstruted out of laser range-(cid:12)nder sans taken at di(cid:11)erent loations

in the environment. The position and orientation of the robot are alulated by maximizing

the orrelation between the stored histograms and laser range-sans obtained while the

robot moves through the environment. The estimated position, together with the odometry

information, is then used to predit the position of the robot and to selet the histogram

used for the next math. Yamauhi

1996

and Shulz et al.

1999

apply a similar tehnique,

(

)

(

)

but they use hill-limbing to math loal maps built from ultrasound sensors into a global

oupany grid map. As in the approah by Wei(cid:25) et al.

1994

, the loation of the robot

(

)

is represented by the position yielding the best math. These tehniques, in ontrast to

Markov loalization, do not represent the unertainty of the robot in its urrent belief and

therefore annot deal appropriately with globally ambiguous situations.

420

 
 
 
 
 
 
Markov Loalization for Mobile Robots in Dynami Environments

A popular probabilisti framework for position traking are Kalman (cid:12)lters

Maybek,

(

1990; Smith et al., 1990

, a signal proessing tehnique introdued by Kalman

1960

. As

)

(

)

mentioned in Setion 2.4, Kalman (cid:12)lter-based methods represent their belief of the robot's

position by a unimodal Gaussian distribution over the three-dimensional state-spae of the

robot. The mode of this distribution yields the urrent position of the robot, and the

variane represents the robot's unertainty. Whenever the robot moves, the Gaussian is

shifted aording to the distane measured by the robot's odometry. Simultaneously, the

variane of the Gaussian is inreased aording to the model of the robot's odometry. New

sensory input is inorporated into the position estimation by mathing the perepts with

the world model.

Existing appliations of Kalman (cid:12)ltering to position estimation for mobile robots are

similar in how they model the motion of the robot. They di(cid:11)er mostly in how they update

the Gaussian aording to new sensory input. Leonard and Durrant-Whyte

1991

math

(

)

beaons extrated from sonar sans with beaons predited from a geometri map of the

environment. These beaons onsist of planes, ylinders, and orners. To update the ur-

rent estimate of the robot's position, Cox

1991

mathes distanes measured by infrared

(

)

sensors with a line segment desription of the environment. Shiele and Crowley

1994

(

)

ompare di(cid:11)erent strategies to trak the robot's position based on oupany grid maps

and ultrasoni sensors. They show that mathing loal oupany grid maps with a global

grid map results in a similar loalization performane as if the mathing is based on fea-

tures that are extrated from both maps. Sha(cid:11)er et al.

1992

ompare the robustness of

(

)

two di(cid:11)erent mathing tehniques with di(cid:11)erent soures of noise. They suggest a ombi-

nation of map-mathing and feature-based tehniques in order to inherit the bene(cid:12)ts of

both. Lu and Milios (1994,1997b) and Gutmann and Shlegel

1996

use a san-mathing

(

)

tehnique to preisely estimate the position of the robot based on laser range-(cid:12)nder sans

and learned models of the environment. Arras and Vestli

1998

use a similar tehnique to

(

)

ompute the position of the robot with a very high auray. All these variants, however,

rest on the assumption that the position of the robot an be represented by a single Gaus-

sian distribution. The advantage of Kalman (cid:12)lter-based tehniques lies in their eÆieny

and in the high auray that an be obtained. The restrition to a unimodal Gaussian

distribution, however, is prone to fail if the position of a robot has to be estimated from

srath, i.e. without knowledge about the starting position of the robot. Furthermore,

these tehnique are typially unable to reover from loalization failures. Reently, Jens-

felt and Kristensen

1999

introdued an approah based on multiple hypothesis traking,

(

)

whih allows to model multi-modal probability distributions as they our during global

loalization.

Markov loalization, whih has been employed suessfully in several variants

Nour-

(

bakhsh et al., 1995; Simmons & Koenig, 1995; Kaelbling et al., 1996; Burgard et al., 1996;

Hertzberg & Kirhner, 1996; Koenig & Simmons, 1998; Oore et al., 1997; Thrun, 1998a

,

)

overomes the disadvantage of Kalman (cid:12)lter based tehniques. The di(cid:11)erent variants of

this tehnique an be roughly distinguished by the type of disretization used for the rep-

resentation of the state spae. Nourbakhsh et al.

1995

, Simmons and Koenig

1995

,

(

)

(

)

and Kaelbling et al.

1996

use Markov loalization for landmark-based navigation, and the

(

)

state spae is organized aording to the topologial struture of the environment. Here

nodes of the topologial graph orrespond to distintive plaes in hallways suh as openings

421

Fox, Burgard & Thrun

or juntions and the onnetions between these plaes. Possible observations of the robot

are, for example, hallway intersetions. The advantage of these approahes is that they an

represent ambiguous situations and thus are in priniple able to globally loalize a robot.

Furthermore, the oarse disretization of the environment results in relatively small state

spaes that an be maintained eÆiently. The topologial representations have the disad-

vantage that they provide only oarse information about the robot's position and that they

rely on the de(cid:12)nition of abstrat features that an be extrated from the sensor information.

The approahes typially make strong assumptions about the nature of the environments.

Nourbakhsh et al.

1995

, Simmons and Koenig

1995

, and Kaelbling et al.

1996

, for

(

)

(

)

(

)

example, only onsider four possible headings for the robot position assuming that the

orridors in the environment are orthogonal to eah other.

Our method uses instead a (cid:12)ne-grained, grid-based disretization of the state spae.

The advantage of this approah ompared to the Kalman (cid:12)lter based tehniques omes

from the ability to represent more omplex probability distributions. In a reent experi-

mental omparison to the tehnique introdued by Lu and Milios (1994) and Gutmann and

Shlegel

1996

, we found that Kalman (cid:12)lter based traking tehniques provide highly au-

(

)

rate position estimates but are less robust, sine they lak the ability to globally loalize the

robot and to reover from loalization errors

Gutmann et al., 1998

. In ontrast to the topo-

(

)

logial implementations of Markov loalization, our approah provides aurate position es-

timates and an be applied even in highly unstrutured environments

Burgard et al., 1998a;

(

Thrun et al., 1999

. Using the seletive update sheme, our tehnique is able to eÆiently

)

keep trak of the robot's position one it has been determined. It also allows the robot to

reover from loalization failures.

Finally, the vast ma jority of existing approahes to loalization di(cid:11)er from ours in that

they address loalization in stati environments. Therefore, these methods are prone to fail

in highly dynami environments in whih, for example, large rowds of people surround the

robot

Fox et al., 1998

. However, dynami approahes have great pratial importane,

(

)

and many envisioned appliation domains of servie robots involve people and populated

environments.

6. Disussion

In this paper we presented a metri variant of Markov loalization, as a robust tehnique

for estimating the position of a mobile robot in dynami environments. The key idea of

Markov loalization is to maintain a probability density over the whole state spae of the

robot relative to its environment. This density is updated whenever new sensory input is

reeived and whenever the robot moves. Metri Markov loalization represents the state

spae using (cid:12)ne-grained, metri grids. Our approah employs eÆient, seletive update

algorithms to update the robot's belief in real-time. It uses (cid:12)ltering to ope with dynami

environments, making our approah appliable to a wide range of target appliations.

In ontrast to previous approahes to Markov loalization, our method uses a (cid:12)ne-

grained disretization of the state spae. This allows us to ompute aurate position

estimates and to inorporate raw sensory input into the belief. As a result, our system an

exploit arbitrary features of the environment. Additionally, our approah an be applied

in arbitrary unstrutured environments and does not rely on an orthogonality assumption

422

Markov Loalization for Mobile Robots in Dynami Environments

or similar assumptions of the existene of ertain landmarks, as most other approahes to

Markov loalization do.

The ma jority of the loalization approahes developed so far assume that the world is

stati and that the state of the robot is the only hanging aspet of the world. To be able to

loalize a mobile robot even in dynami and densely populated environments, we developed

a tehnique for (cid:12)ltering sensor measurements whih are orrupted due to the presene of

people or other ob jets not ontained in the robot's model of the environment.

To eÆiently update the huge state spaes resulting from the grid-based disretization,

we developed two di(cid:11)erent tehniques. First, we use look-up operations to eÆiently om-

pute the quantities neessary to update the belief of the robot given new sensory input.

Seond, we apply the seletive update sheme whih fouses the omputation on the rel-

evant parts of the state spae. As a result, even large belief states an be updated in

real-time.

Our tehnique has been implemented and evaluated in several real-world experiments

at di(cid:11)erent sites. Reently we deployed the mobile robots Rhino in the Deutshes Mu-

seum Bonn, Germany, and Minerva in the Smithsonian's National Museum of Amerian

History, Washington, DC, as interative museum tour-guides. During these deployments,

our Markov loalization tehnique reliably estimated the position of the robots over long

periods of time, despite the fat that both robots were permanently surrounded by visitors

whih produed large amounts of false readings for the proximity sensors of the robots.

The auray of grid-based Markov loalization turned out to be ruial to avoid even suh

obstales that ould not be sensed by the robot's sensors. This has been aomplished by

integrating map information into the ollision avoidane system

Fox et al., 1998b

.

(

)

Despite these enouraging results, several aspets warrant future researh. A key disad-

vantage of our urrent implementation of Markov loalization lies in the (cid:12)xed disretization

of the state spae, whih is always kept in main memory. To sale up to truly large en-

vironments, it seems inevitable that one needs variable-resolution representations of the

state spae, suh as as the one suggested in

Burgard et al., 1997; 1998b; Gutmann et al.,

(

1998

. Alternatively, one ould use Monte-Carlo based representations of the state spae

)

as desribed in

Fox et al., 1999

. Here, the robot's belief is represented by samples that

(

)

onentrate on the most likely parts of the state spae.

Aknowledgment

The authors would like to thank the researh group for autonomous intelligent systems at

the University of Bonn for fruitful disussions, useful suggestions and omments, espeially

Daniel Hennig and Andreas Derr. We would also like to thank the members of CMU's

Robot Learning Lab for many inspiring disussions. Finally, we would like to thank the

sta(cid:11) of the Deutshes Museum Bonn and the National Museum of Amerian History for

their enthusiasm and their willingness to expose their visitors to one of our mobile robots.

This researh is sponsored in part by NSF (CAREER Award IIS-9876136) and DARPA

via TACOM (ontrat number DAAE07-98-C-L032), and Rome Labs (ontrat number

F30602-98-2-0137), whih is gratefully aknowledged. The views and onlusions ontained

in this doument are those of the authors and should not be interpreted as neessarily

423

Fox, Burgard & Thrun

representing oÆial poliies or endorsements, either expressed or implied, of NSF, DARPA,

TACOM, Rome Labs, or the United States Government.

Referenes

[

℄

Arras & Vestli, 1998

K.O. Arras and S.J. Vestli. Hybrid, high-preision loalization for

the mail distributing mobile robot system MOPS. In Pro. of the IEEE International

Conferene on Robotis & Automation (ICRA), 1998.

[

℄

Basye et al., 1992

K. Basye, T. Dean, J. Kirman, and M. Lejter. A deision-theoreti

approah to planning, pereption, and ontrol. IEEE Expert, 7(4), 1992.

[

℄

Borenstein et al., 1996

J. Borenstein, B. Everett, and L. Feng. Navigating Mobile Robots:

Systems and Tehniques. A. K. Peters, Ltd., Wellesley, MA, 1996.

[

℄

Burgard et al., 1996

W. Burgard, D. Fox, D. Hennig, and T. Shmidt. Estimating the

absolute position of a mobile robot using position probability grids.

In Pro. of the

National Conferene on Arti(cid:12)ial Intel ligene (AAAI), 1996.

[

℄

Burgard et al., 1997

W. Burgard, D. Fox, and D. Hennig. Fast grid-based position trak-

ing for mobile robots. In Pro. of the German Conferene on Arti(cid:12)ial Intel ligene (KI),

Germany. Springer Verlag, 1997.

[

℄

Burgard et al., 1998a

W. Burgard, A.B. Cremers, D. Fox, D. H(cid:127)ahnel, G. Lakemeyer,

D. Shulz, W. Steiner, and S. Thrun. The interative museum tour-guide robot.

In

Pro. of the National Conferene on Arti(cid:12)ial Intel ligene (AAAI), 1998.

[

℄

Burgard et al., 1998b

W. Burgard, A. Derr, D. Fox, and A.B. Cremers. Integrating global

position estimation and position traking for mobile robots: the Dynami Markov Lo-

alization approah. In Pro. of the IEEE/RSJ International Conferene on Intel ligent

Robots and Systems (IROS), 1998.

[

℄

Burgard et al., 2000

W. Burgard, A.B. Cremers, D. Fox, D. H(cid:127)ahnel, G. Lakemeyer,

D. Shulz, W. Steiner, and S. Thrun. Experienes with an interative museum tour-

guide robot. Arti(cid:12)ial Intel ligene, 114(1-2), 2000. To appear.

[

℄

Cover & Thomas, 1991

T.M. Cover and J.A. Thomas. Elements of Information Theory.

Wiley Series in Teleommuniations. Wiley, New York, 1991.

[

℄

Cox & Wilfong, 1990

I.J. Cox and G.T. Wilfong, editors. Autonomous Robot Vehiles.

Springer Verlag, 1990.

[

℄

Cox, 1991

I.J. Cox. Blanhe|an experiment in guidane and navigation of an autonomous

robot vehile. IEEE Transations on Robotis and Automation, 7(2):193{204, 1991.

[

℄

Dellaert et al., 1999

F. Dellaert, W. Burgard, D. Fox, and S. Thrun. Using the onden-

sation algorithm for robust, vision-based mobile robot loalization. In Pro. of the IEEE

Computer Soiety Conferene on Computer Vision and Pattern Reognition (CVPR),

1999.

424

Markov Loalization for Mobile Robots in Dynami Environments

[

℄

Fox et al., 1998a

D. Fox, W. Burgard, and S. Thrun. Ative Markov loalization for

mobile robots. Robotis and Autonomous Systems, 25:195{207, 1998.

[

℄

Fox et al., 1998b

D. Fox, W. Burgard, S. Thrun, and A.B. Cremers. A hybrid ollision

avoidane method for mobile robots. In Pro. of the IEEE International Conferene on

Robotis & Automation (ICRA), 1998.

[

℄

Fox et al., 1998

D. Fox, W. Burgard, S. Thrun, and A.B. Cremers. Position estimation

for mobile robots in dynami environments.

In Pro. of the National Conferene on

Arti(cid:12)ial Intel ligene (AAAI), 1998.

[

℄

Fox et al., 1999

D. Fox, W. Burgard, F. Dellaert, and S. Thrun. Monte Carlo Loalization:

EÆient position estimation for mobile robots. In Pro. of the National Conferene on

Arti(cid:12)ial Intel ligene (AAAI), 1999.

[

℄

Fox, 1998

D. Fox. Markov Loalization: A Probabilisti Framework for Mobile Robot Lo-

alization and Naviagation. PhD thesis, Dept. of Computer Siene, University of Bonn,

Germany, Deember 1998.

[

℄

Gutmann & Shlegel, 1996

J.-S. Gutmann and C. Shlegel. AMOS: Comparison of san

mathing approahes for self-loalization in indoor environments.

In Pro. of the 1st

Euromiro Workshop on Advaned Mobile Robots. IEEE Computer Soiety Press, 1996.

[

℄

Gutmann et al., 1998

J.-S. Gutmann, W. Burgard, D. Fox, and K. Konolige. An exper-

imental omparison of loalization methods.

In Pro. of the IEEE/RSJ International

Conferene on Intel ligent Robots and Systems (IROS), 1998.

[

℄

Hennig, 1997

D. Hennig. Globale und lokale Positionierung mobiler Roboter mittels

Wahrsheinlihkeitsgittern. Master's thesis, Department of Computer Siene, University

of Bonn, Germany, 1997. In German.

[

℄

Hertzberg & Kirhner, 1996

J. Hertzberg and F. Kirhner. Landmark-based autonomous

navigation in sewerage pipes. In Pro. of the First Euromiro Workshop on Advaned

Mobile Robots. IEEE Computer Soiety Press, 1996.

[

℄

Jensfelt & Kristensen, 1999

P. Jensfelt and S. Kristensen. Ative global loalisation for a

mobile robot using multiple hypothesis traking. In Pro. of the IJCAI-99 Workshop on

Reasoning with Unertainty in Robot Navigation, 1999.

[

℄

Kaelbling et al., 1996

L.P. Kaelbling, A.R. Cassandra, and J.A. Kurien. Ating under

unertainty: Disrete Bayesian models for mobile-robot navigation.

In Pro. of the

IEEE/RSJ International Conferene on Intel ligent Robots and Systems (IROS), 1996.

[

℄

Kalman, 1960

R.E. Kalman. A new approah to linear (cid:12)ltering and predition problems.

Trans. of the ASME, Journal of basi engineering, 82:35{45, Marh 1960.

[

℄

Koenig & Simmons, 1998

S. Koenig and R. Simmons. A robot navigation arhiteture

based on partially observable Markov deision proess models.

In Kortenkamp et al.

(

)

1998

.

425

Fox, Burgard & Thrun

[

℄

Konolige, 1999

K. Konolige. Markov loalization using orrelation. In Pro. of the Inter-

national Joint Conferene on Arti(cid:12)ial Intel ligene (IJCAI), 1999.

[

℄

Kortenkamp & Weymouth, 1994

D. Kortenkamp and T. Weymouth. Topologial mapping

for mobile robots using a ombination of sonar and vision sensing. In Pro. of the National

Conferene on Arti(cid:12)ial Intel ligene (AAAI), 1994.

[

℄

Kortenkamp et al., 1998

D. Kortenkamp, R. P. Bonasso, and R. Murphy, editors.

MIT/AAAI Press, Cambridge, MA, 1998.

[

℄

Leonard & Durrant-Whyte, 1991

J.J. Leonard and H.F. Durrant-Whyte. Mobile robot

loalization by traking geometri beaons.

IEEE Transations on Robotis and Au-

tomation, 7(3):376{382, 1991.

[

℄

Leonard & Durrant-Whyte, 1992

J.J. Leonard and H.F. Durrant-Whyte. Direted Sonar

Sensing for Mobile Robot Navigation. Kluwer Aademi, Boston, MA, 1992.

[

℄

Lu & Milios, 1994

F. Lu and E. Milios. Robot pose estimation in unknown environments

by mathing 2d range sans. In IEEE Computer Vision and Pattern Reognition Con-

ferene (CVPR), 1994.

[

℄

Lu & Milios, 1997a

F. Lu and E. Milios. Globally onsistent range san alignment for

environment mapping. Autonomous Robots, 4:333{349, 1997.

[

℄

Lu & Milios, 1997b

F. Lu and E. Milios. Robot pose estimation in unknown environments

by mathing 2d range sans. Journal of Intel ligent and Roboti Systems, 18, 1997.

[

℄

Maybek, 1990

P.S. Maybek. The Kalman (cid:12)lter: An introdution to onepts. In Cox &

Wilfong

1990

.

(

)

[

℄

Morave & Elfes, 1985

H.P. Morave and A.E. Elfes. High resolution maps from wide

angle sonar. In Pro. of the IEEE International Conferene on Robotis & Automation

(ICRA), 1985.

[

℄

Morave, 1988

H.P. Morave. Sensor fusion in ertainty grids for mobile robots. AI Mag-

azine, Summer 1988.

[

℄

Nourbakhsh et al., 1995

I. Nourbakhsh, R. Powers, and S. Birh(cid:12)eld. DERVISH an oÆe-

navigating robot. AI Magazine, 16(2), Summer 1995.

[

℄

Oore et al., 1997

S. Oore, G.E. Hinton, and G. Dudek. A mobile robot that learns its

plae. Neural Computation, 1997.

[

℄

Russell & Norvig, 1995

Stuart J. Russell and Peter Norvig. Arti(cid:12)ial Intel ligene: A Mod-

ern Approah, hapter 17. Number 0-13-103805-2 in Series in Arti(cid:12)ial Intelligene. Pren-

tie Hall, 1995.

[

℄

Shiele & Crowley, 1994

B. Shiele and J.L. Crowley. A omparison of position estimation

tehniques using oupany grids.

In Pro. of the IEEE International Conferene on

Robotis & Automation (ICRA), 1994.

426

Markov Loalization for Mobile Robots in Dynami Environments

[

℄

Shultz et al., 1999

A. Shultz, W. Adams, and B. Yamauhi.

Integrating exploration,

loalization, navigation and planning through a ommon representation. Autonomous

Robots, 6(3), 1999.

[

℄

Sha(cid:11)er et al., 1992

G. Sha(cid:11)er, J. Gonzalez, and A. Stentz. Comparison of two range-based

estimators for a mobile robot. In SPIE Conf. on Mobile Robots VII, pages 661{667, 1992.

[

℄

Shatkey & Kaelbling, 1997

H. Shatkey and L.P. Kaelbling. Learning topologial maps

with weak loal odometri information. In Pro. of the International Joint Conferene

on Arti(cid:12)ial Intel ligene (IJCAI), 1997.

[

℄

Simmons & Koenig, 1995

R. Simmons and S. Koenig. Probabilisti robot navigation in

partially observable environments.

In Pro. of the International Joint Conferene on

Arti(cid:12)ial Intel ligene (IJCAI), 1995.

[

℄

Simmons, 1995

R. Simmons. The 1994 AAAI robot ompetition and exhibition. AI Mag-

azine, 16(2), Summer 1995.

[

℄

Smith et al., 1990

R. Smith, M. Self, and P. Cheeseman. Estimating unertain spatial

relationships in robotis. In I. Cox and G. Wilfong, editors, Autonomous Robot Vehiles.

Springer Verlag, 1990.

[

℄

Thrun et al., 1998a

S. Thrun, A. B(cid:127)uken, W. Burgard, D. Fox, T. Fr(cid:127)ohlinghaus, D. Hen-

nig, T. Hofmann, M. Krell, and T. Shimdt. Map learning and high-speed navigation in

RHINO. In Kortenkamp et al.

1998

.

(

)

[

℄

Thrun et al., 1998b

S. Thrun, D. Fox, and W. Burgard. A probabilisti approah to

onurrent mapping and loalization for mobile robots. Mahine Learning, 31:29{53,

1998. Also appeared in Autonomous Robots 5, pp. 253{271, joint issue.

[

℄

Thrun et al., 1999

S. Thrun, M. Bennewitz, W. Burgard, A.B. Cremers, F. Dellaert,

D. Fox, D. H(cid:127)ahnel, C. Rosenberg, N. Roy, J. Shulte, and D. Shulz. MINERVA: A

seond generation mobile tour-guide robot. In Pro. of the IEEE International Confer-

ene on Robotis & Automation (ICRA), 1999.

[

℄

Thrun, 1998a

S. Thrun. Bayesian landmark learning for mobile robot loalization. Ma-

hine Learning, 33(1), 1998.

[

℄

Thrun, 1998b

S. Thrun. Learning metri-topologial maps for indoor mobile robot navi-

gation. Arti(cid:12)ial Intel ligene, 99(1):27{71, 1998.

[

℄

Wei(cid:25) et al., 1994

G. Wei(cid:25), C. Wetzler, and E. von Puttkamer. Keeping trak of position

and orientation of moving indoor systems by orrelation of range-(cid:12)nder sans. In Pro. of

the IEEE/RSJ International Conferene on Intel ligent Robots and Systems (IROS), 1994.

[

℄

Yamauhi, 1996

B. Yamauhi. Mobile robot loalization in dynami environments using

dead rekoning and evidene grids. In Pro. of the IEEE International Conferene on

Robotis & Automation (ICRA), 1996.

427"
"Learning Geometrically-Constrained Hidden Markov Models for Robot
  Navigation: Bridging the Topological-Geometrical Gap","  Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) provide useful tools for modeling dynamical systems. They
are particularly useful for representing the topology of environments such as
road networks and office buildings, which are typical for robot navigation and
planning. The work presented here describes a formal framework for
incorporating readily available odometric information and geometrical
constraints into both the models and the algorithm that learns them. By taking
advantage of such information, learning HMMs/POMDPs can be made to generate
better solutions and require fewer iterations, while being robust in the face
of data reduction. Experimental results, obtained from both simulated and real
robot data, demonstrate the effectiveness of the approach.
",http://arxiv.org/pdf/1106.0680v1,1,"Journal of Arti(cid:12)cial Intelligence Research 16 (2002) 167-207

Submitted 3/01; published 3/02

Learning Geometrically-Constrained Hidden Markov Models for

Robot Navigation: Bridging the Topological-Geometrical Gap

Hagit Shatkay

hagit.shatkay@celera.com

Informatics Research Group,

Celera Genomics, Rockvil le, MD 20850

Leslie Pack Kaelbling

lpk@ai.mit.edu

Arti(cid:12)cial Intel ligence Laboratory

Massachusetts Institute of Technology, Cambridge, MA 02139

You wil l come to a place where the streets are not marked.

Some windows are lighted but mostly they're darked.

A place you could sprain both your elbow and chin!

Do you dare to stay out? Do you dare to go in?...

And if you go in, should you turn left or right...

or right-and-three-quarters? or, maybe, not quite?...

Simple it's not, I'm afraid you wil l (cid:12)nd,

for a mind-maker-upper to make up his mind.

Oh, the Places You'l l Go, Dr. Seuss.

Abstract

Hidden Markov models (hmms) and partially observable Markov decision processes

(pomdps) provide useful tools for modeling dynamical systems. They are particularly

useful for representing the topology of environments such as road networks and o(cid:14)ce

buildings, which are typical for robot navigation and planning. The work presented

here describes a formal framework for incorporating readily available odometric infor-

mation and geometrical constraints into both the models and the algorithm that learns

them. By taking advantage of such information, learning hmms/pomdps can be made

to generate better solutions and require fewer iterations, while being robust in the face

of data reduction. Experimental results, obtained from both simulated and real robot

data, demonstrate the e(cid:11)ectiveness of the approach.

1 Introduction

This work is concerned with robots that need to perform tasks in structured environments.

A robot moving in the environment su(cid:11)ers from two main limitations: its noisy sensors prevent

it from con(cid:12)dently knowing where it is, while its noisy e(cid:11)ectors prevent it from knowing with

certainty where its actions will take it. We concentrate here on structured environments, which

can in turn be characterized by two main properties: such environments consist of vast un-

eventful and uninteresting areas, and are interspersed with relatively few interesting positions or

situations. Consider for instance a robot delivering a bagel in an o(cid:14)ce building. The interesting

situations are the doors and the intersections in the building hallways, as well as the various

(cid:13)2002 AI Access Foundation and Morgan Kaufmann Publishers. All rights reserved.

c

Shatkay & Kaelbling

positions where the bagel might be with respect to the robot's arm (e.g., the robot is holding

the bagel, puts it down, etc.) Most other aspects of the environment, such as the desk positions

in the o(cid:14)ces, are inconsequential for the bagel delivery task.

A natural way to represent the combination of such an environment and the robot's interactions

with it, is as a probabilistic automaton, in which states represent interesting situations, and

edges between states represent the actions leading from one situation to another. Probability

distributions over the transitions and over the possible observations the robot may perceive at

each situation model the robot's noisy e(cid:11)ectors and sensors, respectively.

Such models are formally known as pomdp (partially observable Markov decision process) mod-

els, and have been proven useful for robot planning and acting under the inherent world un-

certainty (Simmons & Koenig, 1995; Nourbakhsh, Powers, & Birch(cid:12)eld, 1995; Cassandra, Kael-

bling, & Kurien, 1996).

Despite much work on using such models, the task of learning them directly and automatically

from the data has not been widely addressed. Research concerning this immediate topic to date

consists mostly of the work done by Simmons and Koenig (1996b). The assumption underlying

their work was that a human provides a rather accurate topological model of the states and

their connections, and the exact probability distributions are then learned on top of this model,

using a version of the Baum-Welch algorithm (Rabiner, 1989). Another interesting approach to

the acquisition of topological models is that of Thrun and B(cid:127)ucken (1996a,1996b; Thrun, 1999),

who focused on extracting deterministic topological maps from previously acquired geometrical-

grid-based maps, where the latter were learned directly from the data. Further discussion of

related research on both the geometrical and the topological approaches, in their probabilistic

and deterministic versions, is given in the next section.

The work reported here is the (cid:12)rst successful attempt we are aware of to learn purely probabilistic-

topological models, directly and completely from recorded data, without using previous human-

provided or grid-based models. It is based on using weak geometric information, recorded by

the robot, to help learn the topology of the environment, and represent it as a probabilistic

model. Therefore, it directly bridges the historically perceived gap between topological and

geometrical information, and addresses the claim presented in Thrun's work (1999) that the

main shortcoming of the topological approach is its failure to utilize the inherent geometry of

the learnt environment.

Most robots are equipped with wheel encoders that enable an odometer to record the change in

the robot's position as it moves through the environment. This data is typically very noisy and

inaccurate. The (cid:13)oors in the environment are rarely smooth, the wheels of the robot are not

always aligned and neither are the motors, the mechanics is imperfect, resulting in slippage and

drift. All these e(cid:11)ects accumulate, and if we were to mark the initial position of the robot, and

try to estimate its current position based on summing a long sequence of odometric recordings,

the resulting estimate will be incorrect. That is, the raw recorded odometric information is

not an e(cid:11)ective tool, in and of itself, for determining the absolute location of the robot in the

environment.

While our approach is not aimed at determining absolute locations, the idea underlying it is that

this weak odometric information, despite its noise and inaccuracy, still provides geometrical cues

that can help to distinguish between di(cid:11)erent states, as well as to identify revisitation of the

same state. Hence, such information enhances the ability to learn topological models. However,

168

Learning Geometrically-Constrained HMMs

the use of geometrical information requires careful treatment of geometrical constraints and

directional data. We demonstrate how the existing models and algorithms can be extended to

take advantage of the noisy odometric data and the geometrical constraints. The geometrical

information is directly incorporated into the probabilistic topological framework, producing a

signi(cid:12)cant improvement over the standard Baum-Welch algorithm, without the need for human-

provided model.

The rest of this paper is organized as follows: Section 2 provides a survey of previous work in

the area of learning maps for robot navigation, and brie(cid:13)y refers to earlier work on learning

automata; Section 3 presents the formal framework for this work; Section 4 presents the main

aspects of our iterative learning algorithm, while Section 5 describes the strategies for selecting

the initial point from which the iterative process begins; Section 6 presents experimental results

obtained from both simulated and real robot data in traditionally hard-to-learn environments.

The experiments demonstrate that our algorithm indeed converges to better models with fewer

iterations than the standard Baum-Welch method, and is robust in the face of data reduction.

2 Approaches to Learning Maps and Models

The work presented here lies in the intersection between the theoretical area of learning compu-

tational models|in particular, learning automata from data sequences|and the applied area of

map acquisition for robot navigation. We concentrate here on surveying the work in the latter

area, pointing out the distinction between our approach and its predecessors. We brie(cid:13)y review

some results from automata and computational learning theory. A more comprehensive review

of theoretical results is given by Shatkay (1999).

2.1 Modeling Environments for Robot Navigation

In the context of maps and models for robot navigation, a distinction is usually made between two

principal kinds of maps: geometric and topological. Geometric maps describe the environment

as a collection of objects or occupied positions in space, and the geometric relationships among

them. The topological framework is less concerned with the geometrical positions, and models

the world as a collection of states and their connectivity, that is, which states are reachable from

each of the other states and what actions lead from one state to the next.

We draw an additional distinction, between world-centric

maps that provide an \ob jective""

1

description of the environment independent of the agent using the map, and robot-centric models

which capture the interaction of a particular \sub jective"" agent with the environment. When

learning a map, the agent needs to take into account its own noisy sensors and actuators and try

to obtain an ob jectively correct map that other agents could use as well. Similarly, other agents

using the map need to compensate for their own limitations in order to assess their position

according to the map. When learning a model that captures interaction, the agent acquiring the

model is the one who is also using it. Hence, the noisy sensors and actuators speci(cid:12)c to the agent

are re(cid:13)ected in the model. A di(cid:11)erent model is likely to be needed by di(cid:11)erent agents. Most

of the related work described below, especially within the geometrical framework, is centered

around learning ob jective maps of the world rather than agent-speci(cid:12)c models. We shall point

out in this survey the work that is concerned with the latter kind of models.

Our work focuses on acquiring purely topological models, and is less concerned with learning

geometrical relationships between locations or ob jects, or ob jective maps, although geometrical

1. We thank Sebastian Thrun for the terminology.

169

Shatkay & Kaelbling

relationships do serve as an aid in our acquisition process. The concept of a state used in this

topological framework is more general than the concept of a geometrical location, since a state

can include information such as the battery level, the arm position etc. Such information, which

is of great importance for planning, is non-geometrical in nature and therefore cannot be readily

captured in a purely geometrical framework. The following sections provide a survey of work

done both within the geometrical framework and within the topological framework, as well as

combinations of the two approaches.

2.2 Geometric Maps

Geometric maps provide a description of the environment in terms of the ob jects placed in it

and their positions. For example, grid-based maps are an instance of the geometric approach.

In a grid-based map, the environment is modeled as a grid (an array), where each position in

the grid can be either vacant or occupied by some ob ject (binary values placed in the array).

This approach can be further re(cid:12)ned to re(cid:13)ect uncertainty about the world, by having grid cells

contain occupancy probabilities rather than just binary values. A lot of work has been done on

learning such grid-based maps for robot navigation through the use of sonar readings and their

interpretation, by Moravec and Elfes and others (Moravec & Elfes, 1985; Moravec, 1988; Elfes,

1989; Asada, 1991).

An underlying assumption when learning such maps is that the robot can tell (or (cid:12)nd out)

where it is on the grid when it obtains a sonar reading indicating an ob ject, and therefore can

place the ob ject correctly on the grid. A similar localization assumption, requiring the robot

to identify its geometrical location, underlies other geometric mapping techniques by Leonard

et al. (1991), Smith et al. (1991), Thrun et al. (1998b) and Dissanayake et al. (2001), even

when an explicit grid is not part of the model. Explicit localization can be hard to satisfy.

Leonard et al. (1991) and Smith et al. (1991) address this issue through the use of geometrical

beacons to estimate the location of the robot. In what is known as the Kalman (cid:12)lter method, a

Gaussian probability distribution is used to model the robot's possible current location, based

on observations collected up to the current point, (without allowing the re(cid:12)nement of previous

position estimates based on later observations). Research in this area has recently been extended

in two directions: Leonard and Feder (2000) partition the task of learning one large map into

learning multiple smaller map-sections, thus addressing the issue of computational e(cid:14)ciency.

Dissanayake et al. (2001) conduct a theoretical study of the approach and show its convergence

properties. The latter may lead to computational e(cid:14)ciency by identifying the cases for which a

steady-state solution can be readily obtained, accordingly bounding the number of steps required

by the algorithms to reach a useful solution in these cases.

Work by Thrun et al. (1998a) uses a similar probabilistic approach for obtaining grid-based maps.

This work is re(cid:12)ned (Thrun et al., 1998b) to (cid:12)rst learn the location of signi(cid:12)cant landmarks in

the environment and then (cid:12)ll in the details of the complete geometrical grid, based on laser range

scans. The latter work extends the approach of Smith et al. , by using observations obtained

both before and after a location has been visited, in order to derive a probability distribution

over possible locations. To achieve this, the authors use a forward-backward procedure similar

to the one used in the Baum-Welch algorithm (Rabiner, 1989), in order to determine possible

locations from observed data. The approach resembles ours both in the use of the forward-

backward estimation procedure, and in its probabilistic basis, aiming at obtaining a maximum

likelihood map of the environment.

It still signi(cid:12)cantly di(cid:11)ers from ours both in its initial

assumptions and in its (cid:12)nal results. The data assumed to be provided to the learner includes

170

Learning Geometrically-Constrained HMMs

both the motion model and the perceptual model of the robot. These consist of transition and

observation probabilities within the grid. Both of these components are learnt by our algorithm,

although not in a grid context but in a coarser-grained, topological framework. The end result of

their algorithm is a probabilistic grid-based map, while ours is a probabilistic topological model,

as further explained in the next section.

In addition to being concerned only with locations, rather than with the richer notion of state,

a fundamental drawback of geometrical maps is their (cid:12)ne granularity and high accuracy. Geo-

metrical maps, particularly grid-based ones, tend to give an accurate and detailed picture of the

environment. In cases where it is necessary for a robot to know its exact location in terms of

metric coordinates, metric maps are indeed the best choice. However, many planning tasks do

not require such (cid:12)ne granularity or accurate measurements, and are better facilitated through a

more abstract representation of the world. For example, if a robot needs to deliver a bagel from

o(cid:14)ce a to o(cid:14)ce b, all it needs to have is a map depicting the relative location of a with respect to

b, the passageways between the two o(cid:14)ces, and perhaps a few other landmarks to help it orient

itself if it gets lost. If it has a reasonably well-operating low-level obstacle avoidance mechanism

to help it bypass (cid:13)ower pots and chairs that it might encounter on its way, such ob jects do

not need to be part of the environment map. Just as a driver traveling between cities needs to

know neither his longitude and latitude coordinates on the globe, nor the location of the speci(cid:12)c

houses along the way, the robot does not need to know its exact location within the building

nor the exact location of various items in the environment, in order to get from one point to

another. Hence, the e(cid:11)ort of obtaining such detailed maps is not usually justi(cid:12)ed. In addition

the maps can be very large, which makes planning|even though planning is polynomial in the

size of the map|ine(cid:14)cient.

2.3 Topological Maps and Models

An alternative to the detailed geometric maps are the more abstract topological maps. Such

maps specify the topology of important landmarks and situations (states), and routes or tran-

sitions (arcs) between them. They are concerned less with the physical location of landmarks,

and more with topological relationships between situations. Typically, they are less complex and

support much more e(cid:14)cient planning than metric maps. Topological maps are built on lower-

level abstractions that allow the robot to move along arcs (perhaps by wall- or road-following),

to recognize properties of locations, and to distinguish signi(cid:12)cant locations as states; they are

(cid:13)exible in allowing a more general notion of state, possibly including information about the

non-geometrical aspects of the robot's situation.

There are two typical strategies for deriving topological maps: one is to learn the topological

map directly; the other is to (cid:12)rst learn a geometric map, then to derive a topological model

from it through some process of analysis.

A nice example of the second approach is provided by Thrun and B(cid:127)ucken (1996a, 1996b; Thrun,

1999), who use occupancy-grid techniques to build the initial map. This strategy is appropriate

when the primary cues for decomposition and abstraction of the map are geometric. However,

in many cases, the nodes of a topological map are de(cid:12)ned in terms of other sensory data (e.g.,

labels on a door or whether or not the robot is holding a bagel). Learning a geometric map (cid:12)rst

also relies on the odometric abilities of a robot; if they are weak and the space is large, it is very

di(cid:14)cult to derive a consistent map.

171

Shatkay & Kaelbling

In contrast, our work concentrates on learning a topological model directly, assuming that ab-

straction of the robot's perception and action abilities has already been done. Such abstractions

were manually encoded into the lower level of our robot navigational software, as described in

Section 6. Work by Pierce and Kuipers (1997) discusses an automatic method for extracting

abstract states and features from raw perceptual information.

Kuipers and Byun (1991) provide a strategy for learning deterministic topological maps. It works

well in domains in which most of the noise in the robot's perception and action is abstracted

away, learning from single visits to nodes and traversals of arcs. A strong underlying assumption

for these strategies, when building the map, is that the current state can be reliably identi(cid:12)ed

based on local information, or based on distance traversed from the previous well-identi(cid:12)ed

state. These methods are unable to handle situations in which long sequences of actions and

observations are necessary to disambiguate the robot's state.

Mataric (1990) provides an alternative approach for learning deterministic topological maps,

represented as distributed graphs. The learning process again relies on the assumption that the

current state can be distinguished from all other states based on local information which includes

compass and sonar readings. Uncertainty is not modeled through probability distributions.

Instead, matching of current readings to already existing states is not required to be exact, and

thresholds of tolerated error are set empirically. Another di(cid:11)erence from the work presented

here, is that while we learn the complete probabilistic topology of the environment, in Mataric's

work the overall topology of the graph is assumed in advance to be a linear list, and additional

edges are added during the learning process. No probability distribution is associated with the

edges, and a mechanism for choosing which edge to take is determined as part of the goal seeking

process, and is not part of the model itself.

Engelson and McDermott (1992) learn \diktiometric"" maps (topological maps with metric rela-

tions between nodes) from experience. The uncertainty model they use is interval-based rather

than probabilistic, and the learned representation is deterministic. Ad hoc routines handle prob-

lems resulting from failures of the uncertainty representation.

We prefer to learn a combined model of the world and the robot's interaction with the world;

this allows robust planning that takes into account likelihood of error in sensing and action. The

work most closely related to ours is by Koenig and Simmons (1996b, 1996a), who learn pomdp

models (stochastic topological models) of a robot hallway environment. They also recognize

the di(cid:14)culty of learning a good model without initial information; they solve the problem by

using a human-provided topological map, together with further constraints on the structure

of the model. A modi(cid:12)ed version of the Baum-Welch algorithm learns the parameters of the

model. They also developed an incremental version of Baum-Welch that can be used on-line.

Their models contain very weak metric information, representing hallways as chains of one-meter

segments and allowing the learning algorithm to select the most probable chain length. This

method is e(cid:11)ective, but results in large models with size proportional to the hallways' length,

and strongly depends on the quality of the human-provided initial model.

2.4 Learning Automata from Data

Informally speaking, an automaton consists of a set of states and a set of transitions that lead

from one state to another. In the context of this work, the automaton states correspond to the

states of the modeled environments, and the transitions, to the state changes due to actions

performed in the environment. Each transition of the automaton is tagged by a symbol from an

172

Learning Geometrically-Constrained HMMs

input alphabet, (cid:6), corresponding to the action or the input to the system that caused the state

transition. Classical automata theory (e.g., Hopcroft & Ullman, 1979) distinguishes between

deterministic and non-deterministic automata. If, for each alphabet symbol (cid:11), there is a single

edge tagged by it, going out of each state, the automaton is deterministic. Otherwise, the

transition between states is not uniquely determined by the input symbol and the automaton is

non-deterministic. If we augment each transition edge of a non-deterministic automaton with a

probability of taking it given a certain input, (cid:11), the resulting automaton is called probabilistic.

The basic problem of learning (cid:12)nite deterministic automata from given data can be roughly

described as follows: Given a set of positive and a set of negative example strings, S and T

respectively, over alphabet (cid:6), and a (cid:12)xed number of states k , construct a minimal deterministic

(cid:12)nite automaton with no more than k states that accepts S and does not accept T . This problem

has been shown to be np-complete (Gold, 1978). Despite the hardness, positive results have

been shown possible under various special settings. Angluin (1987) showed that if an oracle can

answer membership queries and provide counterexamples to conjectures about the automaton,

there is a polynomial time learning algorithm from positive and negative examples. Rivest

and Schapire (1987, 1989), provide several e(cid:11)ective methods, that under various settings, learn

deterministic automata that are correct with high probability. While the above work deals with

learning from noise-free data, Basye, Dean and Kaelbling (1995) presented several algorithms

that, with high probability, learn input-output deterministic automata, when the data observed

by the learner is corrupted by various forms of noise.

In all these cases, the learned automaton is deterministic rather than probabilistic. The basic

learning problem in the probabilistic context is to (cid:12)nd an automaton that assigns the same

distribution as the true one to data sequences, using training data S , that was generated by

the true automaton. Another form of a learning problem is that of (cid:12)nding a probabilistic

automaton (cid:21) that assigns the maximum likelihood to the training data S ; that is, an automaton

that maximizes Pr(S j(cid:21)).

Abe and Warmuth (1992) show that (cid:12)nding a probabilistic automaton with 2 states, even when

a small error with respect to the true model is allowed with some probability (the probably

approximately correct, or PAC, learning model), cannot be done in polynomial time with poly-

nomial number of examples, unless np = rp. From their work arises the broadly accepted

conjecture, which has not yet been proven, that learning hidden Markov Models is hard even

in the pac sense. There are two ways to address this hardness: one is to restrict the class of

probabilistic models learned, while the other is to learn unrestricted hidden Markov models with

good practical results but with no pac guarantees on the quality of the result.

Work by Ron et al. (1994, 1995, 1998) pursues the (cid:12)rst approach, learning restricted classes of

automata, namely, acyclic probabilistic (cid:12)nite automata, and probabilistic (cid:12)nite su(cid:14)x automata.

Both classes are useful for various applications related to natural language processing, and can

be learned in polynomial time within the pac framework.

The second approach, which is the one predominantly taken in this work, is to learn a model that

is a member of the complete unrestricted class of hidden Markov models. Only weak guarantees

exist about the goodness of the model, but the learning procedure may be directed to obtain

practically good results. This approach is based on guessing an automaton (model), and using

an iterative procedure to make the automaton (cid:12)t better to the training data. One algorithm

commonly used for this purpose is the Baum-Welch algorithm (Baum, Petrie, Soules, & Weiss,

1970), which is presented in detail by Rabiner (1989). The iterative updates of the model are

173

Shatkay & Kaelbling

based on gathering su(cid:14)cient statistics from the data given the current automaton, and the

update procedure is guaranteed to converge to a model that locally maximizes the likelihood

function P r(datajmodel). Since the maximum is local, the model might not be close enough

to the true automaton by which the data was generated, and a challenging problem is to (cid:12)nd

ways to force the algorithm into converging to higher-likelihood maxima, or at least to make

it converge faster, facilitating multiple guesses of initial models, thus raising the probability

of converging to higher-likelihood maxima. Such an approach is the one taken in the work

presented here.

We assume, throughout this paper, that the number of states in the model we are learning is

known. This is not a very strong assumption since there are methods for learning the number of

states. Regularization methods for deciding on the number of states and other model parameters,

are discussed, for instance, in Vapnik's book (1995). We do not address this issue here.

The rest of the work describes our approach to learning topological models. We use noisy

odometric information that is readily available in most robots. This geometrical information is

typically not used by topological mapping methods. We demonstrate how a topological model

and the algorithm used to learn it can be extended to directly incorporate this weak odometric

information. We further show that by doing so, we can avoid the use of human-provided a priori

models and still learn stochastic environment models e(cid:14)ciently and e(cid:11)ectively.

3 Models and Assumptions

This section describes the formal framework for our work. It starts by introducing the classic

hidden Markov model. The model is then extended to accommodate noisy odometric information

in its most na(cid:127)(cid:16)ve form, ignoring information about the robot's heading and orientation, and later

adapted to accommodate heading information.

We concentrate here on describing models and algorithms for learning hmms, rather than

pomdps. This means that the robot has no decisions to make regarding its next action at

every state; only one action can be executed at each state. In our experiments, a human opera-

tor gave the action command associated with each state to the robot when gathering the data.

Note that the action is not necessarily the same one for every state, e.g., the robot is told to

always turn right in state 1 and move forward at state 2. However, at each state only one ac-

tion can be taken. The extension to complete pomdps, which we have implemented, is through

learning an hmm for each of the possible actions; it is straightforward although notationally

more cumbersome, thus we limit the discussion here to hmms.

3.1 HMMs { The Basics

A hidden Markov model consists of states, transitions, observations and probabilistic behavior,

and is formally de(cid:12)ned as a tuple (cid:21) = hS; O ; A; B ; (cid:25)i, satisfying the following conditions:

(cid:15) S = fs

; : : : ; s

g is a (cid:12)nite set of N states.

0

N (cid:0)1

(cid:15) O = fo

; : : : ; o

g is a (cid:12)nite set of M possible observation values.

0

M (cid:0)1

174

Learning Geometrically-Constrained HMMs

(cid:15) A is a stochastic transition matrix, with A

= P r(q

= s

jq

= s

), where 0 (cid:20) i; j (cid:20) N (cid:0)1.

i;j

t+1

j

t

i

q

is the state at time t. For every state s

,

A

= 1.

t

i

i;j

j=0

N (cid:0)1

X

A

holds the transition probability from state s

to state s

.

i;j

i

j

(cid:15) B is a stochastic observation matrix, with B

= P r(v

= o

jq

= s

), where 0 (cid:20) j (cid:20) N (cid:0) 1;

j;k

t

t

j

k

M (cid:0)1

X

0 (cid:20) k (cid:20) M (cid:0) 1. v

is the observation recorded at time t. For every state s

,

B

= 1.

t

j

j;k

B

holds the probability of observing o

while being at state s

.

j;k

k

j

k=0

N (cid:0)1

X

(cid:15) (cid:25) is a stochastic initial distribution vector, with (cid:25)

= P r(q

= s

), 0 (cid:20) i (cid:20) N (cid:0) 1.

(cid:25)

= 1.

i

0

i

i

(cid:25)

holds the probability of being in state s

at time 0, when starting to record observations.

i

i

i=0

This model corresponds to a world whose actual state at any given time t, q

2 S , is hidden

t

and not directly observable, but some observable aspects of the state, v

2 O , are detected and

t

recorded when the state is visited at time t. An agent moves from one hidden state to the

next according to the probability distribution encoded in matrix A. The observed information

in each state is governed by the probability matrix B . Although our work is concerned with

discrete observations, the extension to continuous observations is straightforward and has been

well addressed in work on hidden Markov models (Liporace, 1982; Juang, 1985).

Simply stated, the problem of learning an hmm is that of \reverse engineering"" a hidden Markov

model for a stochastic system from the sampled data, generated by the system. We formalize

the learning task in Section 4.1. The next section extends hmms to account for geometric

information.

3.2 Adding Odometry to Hidden Markov Models

The world is composed of a (cid:12)nite set of states. There is a fundamental distinction in our

framework between the term state and the term location. The state of the robot does not

directly correspond to its location. A state may include other information, such as the robot's

battery level or its orientation in that location. A robot standing in the entrance to o(cid:14)ce 101

facing right is in a di(cid:11)erent state than a robot standing in the same place facing left; similarly,

a robot standing with a bagel in its arm is in a di(cid:11)erent state from the same robot being in the

same position without the bagel.

The dynamics of the world are described by state-transition distributions that specify the prob-

ability of making transitions from one state to the next as a result of a certain action. There

is a (cid:12)nite set of observations that can be perceived in each state; the relative frequency of each

observation is described by a probability distribution and depends only on the current state.

In our model, observations are multi-dimensional; an observation is a vector of values, each

chosen from a (cid:12)nite domain. That is, we factorize the observation associated with each state

into several components. For instance, as demonstrated in Section 6.1, we view the observation

recorded by the robot when standing in an o(cid:14)ce environment as consisting of three components,

corresponding to the three cardinal directions: front, left and right. In this example, the obser-

vation vector is thus 3-dimensional. It is assumed that the vector's components are conditionally

independent, given the state.

175

Shatkay & Kaelbling

In addition to the above components, each state is assumed to be associated with a position in a

metric space. Whenever a state transition is made, the robot records an odometry vector, which

estimates the position of the current state relative to the previous one. For the time being we as-

sume that the odometry vector consists of readings along the x and y coordinates of a global coor-

dinate system, and that these readings are corrupted with independent normal noise. The latter

independence assumption is not a strict one, and can be relaxed by introducing a complete co-

variance matrix, although we have not done this in this work. In Section 3.3 we extend the odom-

etry vector to include information about the heading of the robot, and drop the global coordinate

framework.

Note that the odometric relationship characterizes a transition rather than a state and, as

described below, receives a di(cid:11)erent treatment than the observations that are associated with

states.

There are two important assumptions underlying our treatment of odometric relations between

states: First, that there is an inherent \true"" odometric relation between the position of every

two states in the world; second, that when the robot moves from one state to the next, there

is a normal, 0-mean noise around the correct expected odometric reading along each odometric

dimension. This noise re(cid:13)ects two kinds of odometric error sources:

{ The lack of precision in the discretization of the real world into states (e.g. there is a rather

large area in which the robot can stand which can be regarded as \the doorway of the AI

lab"").

{ The lack of precision of the odometric measures recorded by the robot, due to slippage,

friction, disalignment of the wheels, imprecision of the measuring instruments, etc.

To formally introduce odometric information into the hidden Markov model framework, we

de(cid:12)ne an augmented hidden Markov model as a tuple (cid:21) = hS; O ; A; B ; R; (cid:25)i, where:

(cid:15) S = fs

; : : : ; s

g is a (cid:12)nite set of N states.

0

N (cid:0)1

Q

l

(cid:15) O =

O

is a (cid:12)nite set of observation vectors of length l. The ith element of an

i=1

i

observation vector is chosen from the (cid:12)nite set O

.

i

(cid:15) A is a stochastic transition matrix, with A

= P r(q

= s

jq

= s

), 0 (cid:20) i; j (cid:20) N (cid:0) 1.

i;j

t+1

j

t

i

q

is the state at time t. For every state s

,

A

= 1.

t

i

i;j

j=0

N (cid:0)1

X

A

holds the transition probability from state s

to state s

.

i;j

i

j

(cid:15) B is an array of l stochastic observation matrices, with B

= P r(V

[i] = o

jq

= s

);

i;j;k

t

k

t

j

1 (cid:20) i (cid:20) l; 0 (cid:20) j (cid:20) N (cid:0) 1; o

2 O

; V

is the observation vector at time t; V

[i] is its i

k

i

t

t

th

component.

B

holds the probability of observing o

along the i

component of the observation

i;j;k

k

th

vector, while being at state s

.

j

(cid:15) R is a relation matrix, specifying for each pair of states, s

and s

, the mean and variance

i

j

of the D -dimensional

odometric relation between them. (cid:22)(R

[m]) is the mean of the m

i;j

2

th

2. For the time being we consider D to be 2, corresponding to (x; y ) readings.

176

Learning Geometrically-Constrained HMMs

component of the relation between s

and s

and (cid:27)

(R

[m]), the variance. Furthermore,

i

j

i;j

2

R is geometrical ly consistent: for each component m, the relation (cid:22)

(a; b)

= (cid:22)(R

[m])

a;b

m

def

must be a directed metric, satisfying the following properties for all states a, b, and c:

m

(cid:5) (cid:22)

(a; a) = 0;

m

m

(cid:5) (cid:22)

(a; b) = (cid:0)(cid:22)

(b; a) (anti-symmetry); and

m

m

m

(cid:5) (cid:22)

(a; c) = (cid:22)

(a; b) + (cid:22)

(b; c) (additivity ) :

This representation of odometric relations re(cid:13)ects the two assumptions, previously stated,

regarding the nature of the odometric information. The \true"" odometric relation between

the position of every two states is represented as the mean. The noise around the correct

expected odometric relation, accounting for both the lack of precision in the real-world

discretization and the inaccuracy in measurement, is represented through the variance.

(cid:15) (cid:25) is a stochastic initial probability vector describing the distribution of the initial state.

For simplicity it is assumed here to be of the form h0; : : : ; 0; 1; 0; : : : ; 0i, implying that there

is one designated initial state, s

, in which the robot is always started.

i

This model extends the standard hidden Markov model described in Section 3.1 in two ways:

(cid:15) It facilitates observations that are factored into components, and represented as vectors.

These components are assumed to be conditionally independent of each other given the

state. Such factorization, together with the conditional independence assumption, allows

for a simple calculation of the probability of the complete observation vector from the

probabilities of its components. It therefore results in fewer probabilistic parameters in

the learnt model than if we were to view each observation vector, consisting of a possible

combination of component-values as a single \atomic"" observation.

(cid:15) It introduces the odometric relation matrix R and constraints over its components. Using

R and the constraints over it, as explained in Section 4, has proven useful for learning the

other model parameters, as demonstrated in Section 6.

3.3 Handling Directional Data

We further extend the model to accommodate directional changes in addition to the positional

changes. There are two issues stemming from directional changes while moving in an environ-

ment: the need for non-traditional distributions to model directional changes, and the need

to correct for the cumulative rotational error which severely interferes with location estimation

within a global coordinate framework. A detailed discussion of these two problems and their

solution is given in an earlier paper by the authors (Shatkay & Kaelbling, 1998). For the sake

of completeness, we brie(cid:13)y review these two issues here.

3.3.1 Circular Distributions

The robot's change in direction as it moves through the environment is expressed in terms of the

angular change with respect to its original heading. Since angular measures are inherently cir-

cular, treating them as \normally distributed"", and using the standard procedures for obtaining

su(cid:14)cient statistics from the data is not adequate. As a trivial example, if we were to average

177

Shatkay & Kaelbling

173 00

−179 00

−300

-1

1<x  , y >
1
2<x  , y >
2

3<x  , y >
3

θ
1

θ
2

θ
3

1

x

y

1

-1

Figure 1: Simple average of two angles, depicted

Figure 2: Directional data represented as angles

as vectors to the unit circle. The average angle is

and as vectors on the unit circle.

formed by the dashed vector.

the two angular readings, 173

and (cid:0)179

, using simple average we obtain the angle (cid:0)3

, which

(cid:14)

(cid:14)

(cid:14)

is far from the intuitive (cid:24) 180

, as illustrated in Figure 1.

(cid:14)

To address the circularity issue, we use the von Mises distribution, which is a circular version of

the normal distribution, to model the change in heading between two states, as explained below.

A collection of changes in heading within a two dimensional space can be represented in terms

of either Cartesian or polar coordinates. Using a Cartesian system, n changes in headings can

be recorded as a sequence of 2-dimensional vectors, (hx

; y

i; : : : hx

; y

i), on the unit circle,

1

1

n

n

as shown in Figure 2. The same changes can also be represented as the corresponding angles

between the radii from the center of the unit circle and the X axis, ((cid:18)

; : : : ; (cid:18)

), respectively.

1

n

The relationship between the two representations is:

x

= cos((cid:18)

);

y

= sin((cid:18)

) ;

(1 (cid:20) i (cid:20) n) :

i

i

i

i

The vector mean of the n points, hx; yi, is calculated as:

P

P

n

n

i=1

i=1

i

i

cos((cid:18)

)

sin((cid:18)

)

x =

;

y =

:

(1)

n

n

Using polar coordinates, we can express the mean vector in terms of angle, (cid:18) , and length, a,

where (except for the case x = y = 0):

(cid:18) = arctan(

);

a = (x

+ y

)

:

y

2

2

1

2

x

The angle (cid:18) is the mean angle, while the length a is a measure (between 0 and 1) of how

concentrated the sample angles are around (cid:18). The closer a is to 1, the more concentrated the

sample is around the mean, which corresponds to a smaller sample variance.

Intuitively, a satisfactory circular version of the normal distribution would have a mean for

which the maximum likelihood estimate is the average angle as calculated above.

In a way

analogous to Gauss' derivation of the Normal distribution, von Mises developed such a circular

version (Gumbel, Greenwood, & Durand, 1953; Mardia, 1972), which is de(cid:12)ned as follows:

De(cid:12)nition:

A circular random variable, (cid:18) , 0 (cid:20) (cid:18) (cid:20) 2(cid:25) , is said to have the von Mises

distribution with parameters (cid:22) and (cid:20), where 0 (cid:20) (cid:22) (cid:20) 2(cid:25) and (cid:20) > 0, if its probability density

178

Learning Geometrically-Constrained HMMs

function is:

f

((cid:18)) =

e

;

(cid:22);(cid:20)

1

(cid:20) cos((cid:18)(cid:0)(cid:22))

2(cid:25)I

((cid:20))

0

where I

((cid:20)) is the modi(cid:12)ed Bessel function of the (cid:12)rst kind and order 0:

0

1

X

1

1

2r

I

((cid:20)) =

(

(cid:20))

:

(2)

0

2

r !

2

r=0

The parameters (cid:22) and (cid:20) correspond to the distribution's mean and concentration respectively.

While other circular-normal distributions do exist, the von Mises has the desirable estimation

procedure alluded to earlier: Given a set of heading samples, angles (cid:18)

; : : : (cid:18)

, from a von Mises

1

n

distribution, the maximum likelihood estimate (cid:22) for (cid:22) is:

where y , x are as de(cid:12)ned in Equation 1.

y

(cid:22) = arctan(

) ;

x

The maximum likelihood estimate for the concentration parameter, (cid:20), is the (cid:20) that satis(cid:12)es:

I

((cid:20))

1

1

n

X

= max[

cos((cid:18)

(cid:0) (cid:22)); 0] ;

i

I

((cid:20))

n

0

i=1

where I

is the modi(cid:12)ed Bessel function of the (cid:12)rst kind and order 1:

1

1

X

1

1

2r+1

I

((cid:20)) =

(

(cid:20))

:

(3)

1

r !(r + 1)!

2

r=0

Further information about the estimation procedure is beyond the scope of this paper and can

be found elsewhere (Gumbel et al., 1953; Mardia, 1972).

To conclude, we assume that the change in heading (cid:1)(cid:18) is von Mises-distributed, around a mean

(cid:22) with concentration parameter (cid:20). This assumption is re(cid:13)ected in the model learning procedures

as explained later in Section 4.2.3. The change in heading h(cid:22)

(a; b); (cid:20)

(a; b)i between each pair

(cid:18)

(cid:18)

of states (a; b) completes the set of parameters included in the relation matrix R which was

introduced earlier in Section 3.2.

3.3.2 Cumulative Rotational Error

We tend to think about an environment as consisting of landmarks (cid:12)xed in a global coordinate

system and corridors or transitions connecting these landmarks. This idea underlies the typical

maps constructed and used in everyday life. However, this view of the environment may be

problematic when robots are involved.

Conceptually, a robot has two levels at which it operates; the abstract level, in which it centers

itself through corridors, follows walls and avoids obstacles, and the physical level in which motors

turn the wheels as the robot moves.

In the physical level many inaccuracies can manifest

themselves: wheels can be unaligned with each other resulting in a drift to the right or to the

left, one motor can be slightly faster than another resulting in similar drifts, an obstacle under

one of the wheels can cause the robot to rotate around itself slightly, or uneven (cid:13)oors may cause

179

Shatkay & Kaelbling

ε−ε

- actual position
- recorded position

Figure 3: A robot moving along the solid arrow, while correcting for drift in the direction of the dashed

arrow. The dotted arrow marks its recorded change in position.

the robot to slip in a certain direction. In addition, the measuring instrumentation for odometric

information may not be accurate in and of itself. At the abstract level, corrective actions are

constantly executed to overcome the physical drift and drag. For example, if the left wheel is

misaligned and drags the robot leftwards, a corrective action of moving to the right is constantly

taken in the higher level to keep the robot centered in the corridor.

The phenomena described above have a signi(cid:12)cant e(cid:11)ect on the odometry recorded by the robot,

if such data interpreted with respect to one global framework. For example, consider the robot

depicted in Figure 3. It drifts to the left (cid:0)(cid:15)

when moving from one state to the next, and

(cid:14)

corrects for it by moving (cid:15)

to the right in order to maintain itself centered in the corridor.

(cid:14)

Let us assume that states are 5 meters apart along the center of the corridor, and that the center

of the corridor is aligned with the Y axis of the global coordinate system. The robot steps back

and forth in the corridor from one state to the next. Whenever the robot reaches a state, its

odometry reading changes by hx; y ; (cid:18)i along the hX; Y ; headingi dimensions, respectively. As the

robot proceeds, the deviation with respect to the X axis becomes more and more severe. Thus,

after going through several transitions, the odometric changes recorded between every pair of

states, if taken with respect to a global coordinate system, become larger and larger. Similar

problems of inconsistent odometric changes recorded between pairs of states can arise along any

of the odometric dimensions. It is especially severe when such inconsistencies arise with respect

to the heading, since this can lead to mistakenly switching movement along the X and the Y

axes, as well as confusion between forwards and backwards movement (when the deviation in

the heading is around 90

or 180

respectively).

(cid:14)

(cid:14)

In early work (Shatkay & Kaelbling, 1997) we assumed perpendicularity of the corridors, which

was taken advantage of while the robot collected the data. Odometric readings were recorded

with respect to a global coordinate system, and the robot could re-align itself with the origin after

each turn. A tra jectory of odometry recorded under this perpendicularity assumption by our

robot Ramona, along the x and y axes is given in Figure 4. The sequence shown was recorded

while the robot drove repeatedly around a loop of corridors. Further details about the data

gathering process are provided in Section 6. In contrast, Figure 5 shows a tra jectory of another

sequence of odometric readings recorded by Ramona, driving through the same corridors, without

using the perpendicularity assumption. The data collected under the latter setting is sub jected

to cumulative rotational error.

180

Learning Geometrically-Constrained HMMs

3000

2500

2000

1500

1000

500

1200

1000

800

600

400

200

200

400

600

800

1000

-2500 -2000 -1500 -1000 -500

500

1000

Figure 4: Sequence gathered by Ramona, perpen-

Figure 5: Sequence gathered by Ramona, no per-

dicularity assumed.

pendicularity assumed.

Such data can be handled through state-relative coordinate systems (Shatkay & Kaelbling, 1998).

The latter implies that each state s

has its own coordinate system, as shown in Figure 6: the

i

origin is anchored in s

, the Y axis is aligned with the robot's heading in the state (denoted by

i

bold arrows in the (cid:12)gure), and the X axis is perpendicular to it. This is in contrast to a global

coordinate system which is anchored in the initial starting state. Within the global coordinate

system, the relations recorded may vary greatly among multiple instances of the same transition

between the same pair of states. By using the state-relative system, the recorded and learned

relationship between each pair of states, hs

; s

i, is reliable, despite the fact that it is based on

i

j

multiple transitions recorded from s

to s

.

i

j

Under state-relative coordinate systems, the geometric relation stored in R

, (which was in-

ij

troduced in Section 3.2), is expressed for each pair of states, s

and s

, with respect to the

i

j

coordinate system associated with state s

. Accordingly, the constraints imposed over the x and

i

y components of the relation matrix must be speci(cid:12)ed with respect to the explicit coordinate

system used, as explained below.

Given a pair of states a and b, we denote by (cid:22)

(a; b) the vector h(cid:22)(R

[x]); (cid:22)(R

[y ])i. Let

a;b

a;b

hx;yi

us de(cid:12)ne T

to be the transformation that maps an hx

; y

i point represented with respect to

ab

a

a

the coordinate system of state a, to the same point represented with respect to the coordinate

system of state b, hx

; y

i.

b

b

(cid:18)

More explicitly, let (cid:22)

be the mean change in heading from state a to state b. Applying T

to

ab

ab

a vector h

i results in the vector h

i as follows:

x

a

x

b

y

a

y

b

*

+

*

+

*

+

x

x

x

cos((cid:22)

) (cid:0) y

sin((cid:22)

)

b

a

a

a

ab

ab

(cid:18)

(cid:18)

= T

=

:

ab

(cid:18)

(cid:18)

y

y

x

sin((cid:22)

) + y

cos((cid:22)

)

b

a

a

a

ab

ab

The consistency constraints within this framework must be restated as:

hx;yi

(cid:5) (cid:22)

(a; a) = h0; 0i;

hx;yi

hx;yi

(cid:5) (cid:22)

(a; b) = (cid:0)T

[(cid:22)

(b; a)] (anti-symmetry);

ba

hx;yi

hx;yi

hx;yi

(cid:5) (cid:22)

(a; c) = (cid:22)

(a; b) + T

[(cid:22)

(b; c)] (additivity).

ba

181

Shatkay & Kaelbling

y

Si

∆

x

Sj

∆θ

∆

y

x

Figure 6: A robot in state S

, faces in the Y -axis direction; the relation S

,S

is wrt S

's coordinate

i

i

j

i

system.

These consistency constraints are the ones that need to be enforced by our learning algorithm

which constructs the hmm. It is important to note that the transformation T itself does not

constitute a set of additional parameters that need to be learnt. Rather, it is calculated in terms

of the heading-change parameter, (cid:22)

, which is already an integral part of the relation matrix we

(cid:18)

have de(cid:12)ned in Sections 3.2 and 3.3.1.

We have introduced the basic formal model that we use for representing environments and

the robot's interaction with them. In the following section we state the learning problem and

describe the basic algorithm for learning the model from data.

4 Learning HMMs with Odometric Information

This section formalizes the learning problem for hmms, and discusses how odometric information

is incorporated into the learning algorithm. An overview of the complete algorithm is provided

in the Appendix for this paper.

4.1 The Learning Problem

The learning problem for hidden Markov models can be generally stated as follows: Given an

experience sequence E, (cid:12)nd a hidden Markov model that could have generated this sequence and

is \useful"" or \close to the original"" according to some criterion. An explicit common statistical

approach is to look for a model (cid:21) that maximizes the likelihood of the data sequence E given

the model. Formally stated, it maximizes Pr(Ej(cid:21)). However, given the complicated landscape

of typical likelihood functions in a multi-parameter domain, obtaining a maximum likelihood

model is not feasible. All studied practical methods, and in particular the well-known Baum-

Welch algorithm (Rabiner (1989) and references therein) can only guarantee a local-maximum

likelihood model.

Another way of evaluating the quality of a learned model is by comparing it to the true model.

We note that stochastic models (such as hmms) induce a probability distribution over all obser-

vation sequences of a given length. The Kullback-Leibler (Kullback & Leibler, 1951) divergence

of a learned distribution from a true one is a commonly used measure for estimating how good a

182

Learning Geometrically-Constrained HMMs

learned model is. Obtaining a model that minimizes this measure is a possible learning goal. The

culprit here is that in practice, when we learn a model from data, we do not have any \ground

truth"" model to compare the learned model with. Still, we can evaluate learning algorithms by

measuring how well they perform on data obtained from known models. It is reasonable to ex-

pect that an algorithm that learns well from data that is generated from a model we do have, will

perform well on data generated from an unknown model, assuming that the models indeed form

a suitable representation of the true generating process. We discuss the Kullback-Leibler (kl)

divergence in more detail in Section 6.2 in the context of evaluating our experimental results.

To summarize, the learning problem as we address it in this work is that of obtaining a model

by attempting to (locally) maximize the likelihood, while evaluating the results based on the

kl-divergence with respect to the true underlying distribution, when such a distribution is

available.

4.2 The Learning Algorithm

The learning algorithm starts from an initial model (cid:21)

and is given an experience sequence E;

0

it returns a revised model (cid:21), which (locally) maximizes the likelihood P (Ej(cid:21)). The experience

sequence E is of length T ; each element, E

, for 0 (cid:20) t (cid:20) (T (cid:0) 1), is a pair hr

; V

i, where r

is the

t

t

t

t

observed relation vector along the x, y and (cid:18) dimensions, between the states q

and q

, and V

t(cid:0)1

t

t

is the observation vector at time t.

Our algorithm extends the standard Baum-Welch algorithm to deal with the relational in-

formation and the factored observation sets. The Baum-Welch algorithm is an expectation-

maximization (em) algorithm (Dempster, Laird, & Rubin, 1977); it alternates between

(cid:15) the E-step of computing the state-occupation and state-transition probabilities, (cid:13) and (cid:24) ,

at each time in the sequence given E and the current model (cid:21), and

(cid:15) the M-step of (cid:12)nding a new model, (cid:21), that maximizes P (Ej(cid:21); (cid:13) ; (cid:24) ),

providing monotone convergence of the likelihood function P (Ej(cid:21)) to a local maximum.

However, our extension introduces an additional component, namely, the relation matrix R. It

can be viewed as having two kinds of observations: state observations (as the ordinary hmm |

with the distinction that we observe integer vectors rather than integers) and transition observa-

tions (the odometry relations between states). The latter must satisfy geometrical constraints.

Hence, an extension of the standard update formulae, as described below, is required.

4.2.1 State-Occupation Probabilities

Following Rabiner (1989), we (cid:12)rst compute the forward ((cid:11)) and backward ((cid:12) ) matrices. (cid:11)

(i)

t

denotes the probability density value of observing E

through E

and q

= s

, given (cid:21); (cid:12)

(i) is

0

t

t

i

t

the probability density of observing E

through E

given q

= s

and (cid:21). Formally:

t+1

T (cid:0)1

t

i

(cid:11)

(i) = P r(E

; : : : ; E

; q

= s

j(cid:21)) ;

t

0

t

t

i

(cid:12)

(i) = P r(E

; : : : ; E

jq

= s

; (cid:21)) :

t

t+1

T (cid:0)1

t

i

When some of the measurements are continuous (as is the case with R), these matrices contain

probability density values rather than probabilities.

The forward procedure for calculating the (cid:11) matrix is initialized with

(

i

b

if (cid:25)

= 1

0

i

(cid:11)

(i) =

0

0

otherwise ;

183

Shatkay & Kaelbling

and continued for 0 < t (cid:20) T (cid:0) 1 with

N (cid:0)1

X

j

(cid:11)

(j ) =

(cid:11)

(i)A

f (r

jR

)b

:

(4)

t

t(cid:0)1

i;j

t

i;j

t

i=0

The expression f (r

jR

) denotes the density at point r

according to the distribution represented

t

i;j

t

by the means and variances in entry i; j of the relation matrix R, while b

is the probability of

j

Q

j

l

t

observing vector v

in state s

; that is, b

=

B

.

t

j

t

i=0

i;j;v

[i]

t

The backward procedure for calculating the (cid:12) matrix is initialized with (cid:12)

(j ) = 1, and continued

T (cid:0)1

for 0 (cid:20) t < T (cid:0) 1 with

N (cid:0)1

X

j

(cid:12)

(i) =

(cid:12)

(j )A

f (r

jR

)b

:

(5)

t

t+1

i;j

t+1

i;j

t+1

j=0

Given (cid:11) and (cid:12) , we now compute for each given time point t the state-occupation and state-

transition probabilities, (cid:13) and (cid:24) . The state-occupation probabilities, (cid:13)

(i), representing the

t

probability of being in state s

at time t given the experience sequence and the current model,

i

are computed as follows:

(cid:13)

(i) = Pr(q

= s

jE; (cid:21)) =

:

(6)

t

t

i

P

N (cid:0)1

(cid:11)

(i)(cid:12)

(i)

t

t

j=0

(cid:11)

(j )(cid:12)

(j )

t

t

Similarly, (cid:24)

(i; j ), the state-transition probabilities from state i to state j at time t given the

t

experience sequence and the current model, are computed as:

(cid:24)

(i; j ) = Pr(q

= s

; q

= s

jE; (cid:21))

t

t

i

t+1

j

(cid:11)

(i)A

b

f (r

jR

)(cid:12)

(j )

t

i;j

t+1

i;j

t+1

t+1

j

=

:

(7)

N (cid:0)1

N (cid:0)1

X

X

j

(cid:11)

(i)A

b

f (r

jR

)(cid:12)

(j )

t

i;j

t+1

i;j

t+1

t+1

i=0

j=0

These are essentially the same formulae appearing in Rabiner's tutorial (Rabiner, 1989), but

they also take into account the density of the odometric relations.

In the next phase of the algorithm, the goal is to (cid:12)nd a new model, (cid:21), that maximizes the likeli-

hood conditioned on the current transition and observation probabilities, Pr(Ej(cid:21); (cid:13) ; (cid:24) ). Usually,

this is simply done using maximum-likelihood estimation of the probability distributions in A

and B by computing expected transition and observation frequencies. In our model we must also

compute a new relation matrix, R, under the constraint that it remain geometrically consistent.

Through the rest of this section we use the notation v to denote a reestimated value, where v

denotes the current value.

4.2.2 Updating Transition and Observation Parameters

The A and B matrices can be straightforwardly reestimated. A

is the expected number of

i;j

transitions from s

to s

divided by the expected number of transitions from s

, and B

is the

i

j

i

i;j;k

expected number of times o

is observed along the ith dimension when in state s

, divided by

k

j

the expected number of times of being in s

:

j

P

T (cid:0)2

P

T (cid:0)1

t=0

(cid:24)

(i; j )

t

t=0

t

k

[V

[i]=o

]

t

(cid:14)

(cid:13)

(j )

A

=

; B

=

:

(8)

i;j

P

i;j;k

P

T (cid:0)2

T (cid:0)1

t=0

t=0

(cid:13)

(i)

(cid:13)

(i)

t

t

The expression (cid:14)

denotes an indicator function with value 1 if condition c is true and 0 otherwise.

c

184

Learning Geometrically-Constrained HMMs

Q

-6

-4

-2

2

P

4

6

7.5

5

2.5

P

-8

-6

-4

-2

2

4

6

8

-2.5

-5

Q

-7.5

Figure 7: Examples of two sets of normally distributed points with constrained means, in 1 and in 2

dimensions.

4.2.3 Updating Relation Parameters

When reestimating the relation matrix, R, the geometrical constraints induce interdependencies

among the optimal mean estimates as well as between optimal variance estimates and mean

estimates. Parameter estimation under this form of constraints is almost untreated in main-

stream statistics (Bartels, 1984) and we found no previous existing solutions to the estimation

problem addressed here. As an illustration for the issues involved in estimation under constraints

consider the following estimation problem of 2 normal means:

Example 4.1 The data consists of two sample sets of points P = fp

; p

; : : : ; p

g and Q =

1

2

n

fq

; q

; : : : ; q

g, independently drawn from two distinct normal distributions with means (cid:22)

; (cid:22)

1

2

k

P

Q

and variances (cid:27)

; (cid:27)

, respectively. We are asked to (cid:12)nd maximum likelihood estimates for the

P

Q

2

2

two distribution parameters. Moreover, we are told that the means of the two distributions are

related, such that (cid:22)

= (cid:0)(cid:22)

, as il lustrated in Figure 7. If not for the latter constraint, the task

Q

P

is simple (DeGroot, 1986), and we have:

P

P

n

n

2

i=1

i=1

2

p

(p

(cid:0) (cid:22)

)

i

i

P

(cid:22)

=

; (cid:27)

=

;

P

P

n

n

and similarly for (cid:22)

and (cid:27)

. However, the constraint (cid:22)

= (cid:0)(cid:22)

requires (cid:12)nding a single mean, (cid:22),

Q

P

Q

Q

2

and setting the other one to its negated value, (cid:0)(cid:22). Intuitively, when choosing such a maximum

likelihood single mean, the more concentrated sample should have more e(cid:11)ect, while the more

varied sample should be more \submissive."" Thus, the overal l sample deviation from the means

would be minimized and the likelihood of the data maximized. Therefore, there is a mutual

dependence between the estimation of the mean and the estimation of the variance.

Since the samples are independently drawn, their joint likelihood function is:

(cid:0)(p

(cid:0)(cid:22)

)

j

Q

2

(cid:0)(q

(cid:0)(cid:22)

)

2

i

P

2

2

2(cid:27)

n

k

2(cid:27)

Y

Y

Q

e

e

P

f (P ; Qj(cid:22)

; (cid:22)

; (cid:27)

; (cid:27)

) =

(cid:1)

:

p

p

P

Q

P

Q

2

2

i=1

j=1

2(cid:25)(cid:27)

2(cid:25)(cid:27)

P

Q

By taking the derivatives of this joint log-likelihood function, with respect to (cid:22)

, (cid:27)

and (cid:27)

, and

P

P

Q

equating them to 0, while using the constraint (cid:22)

= (cid:0)(cid:22)

, we obtain the fol lowing set of mutual

Q

P

equations for maximum likelihood estimators:

P

P

2

2

n

k

((cid:27)

p

) (cid:0) ((cid:27)

q

)

Q

P

i=1

j=1

i

j

(cid:22)

=

; (cid:22)

= (cid:0)(cid:22)

;

P

Q

P

2

2

n(cid:27)

+ k(cid:27)

Q

P

P

P

n

2

k

2

2

i=1

2

i

P

j=1

(p

(cid:0) (cid:22)

)

(q

+ (cid:22)

)

j

P

(cid:27)

=

; (cid:27)

=

:

P

Q

n

k

185

Shatkay & Kaelbling

By substituting the expressions for (cid:27)

and (cid:27)

into the expression for (cid:22)

, we obtain a cubic equa-

P

Q

P

tion which is cumbersome, but stil l solvable (in this simple case). The solution provides a maxi-

mum likelihood estimate for the mean and variance under the constraint (cid:22)

= (cid:0)(cid:22)

:

2

Q

P

We now proceed to the actual update of the relation matrix under constraints. For clarity, we

initially discuss only the (cid:12)rst two geometrical constraints, and discuss the additivity constraint in

Section 4.3. Recall that we concentrate here on the enforcement of global constraints, appropriate

under the perpendicularity assumption, although the same idea is applied in the case of state-

relative constraints.

Zero distances between states and themselves are trivially enforced, by setting all the diagonal

entries in the R matrix to 0, with a small variance.

Anti-symmetry within a global coordinate system is enforced by using the data recorded along

the transition from state s

to s

as well as from state s

to s

when reestimating (cid:22)(R

). As

j

i

i

j

i;j

demonstrated in Example 4.1, the variance has to be taken into account, leading to the following

set of mutual equations:

(cid:20)

(cid:21)

P

T (cid:0)2

t

t

t

t

r

[m](cid:24)

(i;j )

r

[m](cid:24)

(j;i)

t=0

((cid:27)

)

((cid:27)

)

m

m

2

2

(cid:0)

i;j

j;i

m

(cid:22)

=

;

(9)

(cid:20)

(cid:21)

i;j

P

T (cid:0)2

t

t

(cid:24)

(i;j )

(cid:24)

(j;i)

t=0

((cid:27)

)

((cid:27)

)

m

m

2

2

+

i;j

j;i

P

T (cid:0)2

m

2

m

2

t=0

i;j

t

t

[(cid:24)

(i; j )(r

[m] (cid:0) (cid:22)

)

]

((cid:27)

)

=

:

(10)

i;j

P

T (cid:0)2

t=0

t

(cid:24)

(i; j )

For the x and y dimensions, (m = x; y), this amounts to a complicated but still solvable cubic

equation. However, in the more general case, when accounting for the orientation of the robot,

and also when complete additivity is enforced, we do not obtain such closed form reestimation

formulae.

To avoid these hardships, we use a lag-behind update rule; the yet-unupdated estimate of the

variance is used for calculating a new estimate for the mean, and this new mean estimate is

used to update the variance, using Equation 10.

Thus, the mean is updated using a variance

3

parameter that lags behind it in the update process, and the reestimation Equation (9) needs to

use (cid:27)

rather than (cid:27)

as follows:

h

i

m

m

P

T (cid:0)2

r

[m](cid:24)

(i;j )

r

[m](cid:24)

(j;i)

t

t

t

t

m

i;j

j;i

t=0

((cid:27)

)

((cid:27)

)

m

2

m

2

(cid:0)

(cid:22)

=

:

(11)

h

i

i;j

P

T (cid:0)2

(cid:24)

(i;j )

(cid:24)

(j;i)

t

t

t=0

((cid:27)

)

((cid:27)

)

m

m

2

2

+

i;j

j;i

As we have shown (Shatkay, 1999), this lag-behind policy is an instance of generalized em (McLach-

lan & Krishnan, 1997). The latter guarantees monotone convergence to a local maximum of the

likelihood function, even when each \maximization"" step increases rather than strictly maxi-

mizes the expected likelihood of the data given the current model.

Similarly, the reestimation formula for the von Mises mean ((cid:22)) and concentration ((cid:20)) parameters

of the heading change between states s

and s

is the solution to the equations:

i

j

0

1

T (cid:0)2

X

B

C

t

t

i;j

t

j;i

[sin(r

[(cid:18)])((cid:24)

(i; j )(cid:20)

(cid:0) (cid:24)

(j; i)(cid:20)

)]

(cid:18)

t=0

B

C

B

C

(cid:22)

= arctan

i;j

B

C

T (cid:0)2

X

@

A

[cos(r

[(cid:18)])((cid:24)

(i; j )(cid:20)

+ (cid:24)

(j; i)(cid:20)

)]

t

t

i;j

t

j;i

t=0

3. A similar approach, termed one step late update, is taken by others applying em to highly non-linear opti-

mization problems (McLachlan & Krishnan, 1997).

186

Learning Geometrically-Constrained HMMs

(cid:18)

(cid:18)

P

T (cid:0)2

""

#

I

[(cid:20)

]

[(cid:24)

(i; j ) cos(r

[(cid:18)] (cid:0) (cid:22)

)]

1

t

t

i;j

i;j

t=0

= max

; 0

;

(12)

(cid:18)

T (cid:0)2

P

I

[(cid:20)

]

0

i;j

t=0

t

(cid:24)

(i; j )

where I

and I

are the modi(cid:12)ed Bessel functions as de(cid:12)ned by Equations 2 and 3 in Section 3.3.1.

0

1

Again, to avoid the need to solve the mutual equations, we take advantage of the lag-behind strat-

egy, updating the mean using the current estimates of the concentration parameters, (cid:20)

; (cid:20)

,

i;j

j;i

as follows:

(cid:18)

t=0

[sin(r

[(cid:18)])((cid:24)

(i; j )(cid:20)

(cid:0) (cid:24)

(j; i)(cid:20)

)]

t

t

i;j

t

j;i

P

T (cid:0)2

!

(cid:22)

= arctan

;

(13)

i;j

P

T (cid:0)2

t=0

[cos(r

[(cid:18)])((cid:24)

(i; j )(cid:20)

+ (cid:24)

(j; i)(cid:20)

)]

t

t

i;j

t

j;i

and then calculating the new concentration parameters based on the newly updated mean, as

the solution to Equation 12, through the use of lookup-tables.

A possible alternative to our lag-behind approach is to update the mean as though the assump-

tion (cid:27)

= (cid:27)

holds. Under this assumption, the variance terms in Equation 9 cancel out, and

j;i

i;j

the mean update is independent of the variance once again. Then the variances are updated as

stated in Equation 10, without assuming any constraints over them. This approach was taken

in earlier stages of this work (Shatkay & Kaelbling, 1997, 1998). The lag-behind strategy is

superior, both according to our experiments, and due to its being an instance of generalized em.

4.3 Enforcing Additivity

Note that the additivity constraint directly implies the other two geometrical constraints

. Thus,

4

enforcing it results in complete geometrical consistency. We present here the method for directly

enforcing additivity through the reestimation procedure along the x and y dimensions. For the

heading dimension we describe how complete geometrical consistency is achieved through the

pro jection of anti-symmetric estimates onto a geometrically-consistent space. As before, to

simplify the presentation, we focus on the case of global coordinate systems. The same basic

idea applies to state-relative coordinate systems, but the relationship used to recover the mean

(cid:22)

from individual state coordinates is more complex.

ij

4.3.1 Additivity in the x, y dimensions

The main observation underlying our approach is that the additivity constraint is a result of the

fact that states can be embedded in a geometrical space. That is, assuming we have N states,

s

; : : : ; s

, there are points on the X , Y and (cid:18) axes, x

; : : : ; x

, y

; : : : ; y

, (cid:18)

; : : : ; (cid:18)

,

0

N (cid:0)1

0

N (cid:0)1

0

N (cid:0)1

0

N (cid:0)1

respectively, such that each state, s

, is associated with the coordinates hx

; y

; (cid:18)

i. Assuming

i

i

i

i

one global coordinate system, the mean odometric relation from state s

to state s

can be

i

j

expressed as: hx

(cid:0) x

; y

(cid:0) y

; (cid:18)

(cid:0) (cid:18)

i.

j

i

j

i

j

i

During the maximization phase of the em iteration, rather than try to maximize with respect

2

X

Y

(cid:18)

to N

odometric relation vectors, h(cid:22)

, (cid:22)

, (cid:22)

i, we reparameterize the problem. Speci(cid:12)cally,

ij

ij

ij

we express each odometric relation as a function of two of the N state positions, and maximize

with respect to the unconstrained, N state positions. For instance, for the X dimension, rather

than search for N

maximum likelihood estimates for (cid:22)

, we use the maximization step to (cid:12)nd

2

x

ij

x

N 1-dimensional points, x

; : : : ; x

. We can then calculate (cid:22)

= x

(cid:0) x

. Moreover, since

0

N (cid:0)1

j

i

ij

all we are interested in is (cid:12)nding the best relationships between x

and x

, we can (cid:12)x one of

i

j

4. f(cid:22)(a; a) = (cid:22)(a; a) + (cid:22)(a; a)g ) ((cid:22)(a; a) = 0) ; f((cid:22)(a; a) = 0) ; ((cid:22)(a; a) = (cid:22)(a; b)+(cid:22)(b; a))g ) ((cid:22)(a; b) = (cid:0)(cid:22)(b; a)).

187

 
Shatkay & Kaelbling

the x

's at 0 (e.g. x

= 0), and (cid:12)nd optimal estimates for the remaining N (cid:0) 1 state positions.

i

0

The variance reestimation remains as before, and the lag-behind policy is used to eliminate the

interdependency between the update of the mean and the variance parameters.

4.3.2 Additive Heading Estimation

Unfortunately, the reparameterization described above is not feasible for estimation of changes

in heading, due to the von Mises distribution assumption over the heading measures. By repa-

rameterizing (cid:22)

as (cid:18)

(cid:0) (cid:18)

and trying to maximize the likelihood function with respect to the (cid:18)

ij

j

i

(cid:18)

parameters, we obtain a set of N(cid:0)1 trigonometric equations with terms of the form cos((cid:18)

)(cid:1) sin((cid:18)

)

j

i

which do not enable simple solution.

As an alternative, it is possible to use the anti-symmetric reestimation procedure described

earlier, followed by a perpendicular projection operator, mapping the resulting headings vector

(cid:18)

(cid:18)

(cid:18)

h(cid:22)

; : : : ; (cid:22)

; : : : ; (cid:22)

i, 0 (cid:20) i; j (cid:20) N (cid:0)1, which does not satisfy additivity, onto a vector of

00

ij

N (cid:0)1;N (cid:0)1

headings within an additive linear vector space. Simple orthogonal pro jection is not satisfactory

within our setting, since it simply looks for the additive vector closest to the non-additive one.

This procedure ignores the fact that some of the entries in the non-additive vector are based on

a lot of observations, and are therefore more reliable, while other, less reliable ones, are based on

hardly any data at all. Intuitively, we would like to keep the estimates that are well accounted

for intact, and adapt the less reliable estimates to meet the additivity constraint. More precisely,

there are heading-change estimates between states that are better accounted for than others, in

the sense that the transitions between these states have higher expected counts than transition

P

between other states (higher

(cid:24)

(i; j )). We would like to pro ject the non-additive heading

t

t

estimates vector onto a subspace of the additive vector space, in which the vectors have the same

values as the non-additive vector in the entries that are well-accounted for, that is, those with

P

the highest values of

(cid:24)

(i; j ). The di(cid:14)culty is that the latter subspace is not a linear vector

t

t

space (for instance, it does not satisfy closure under scalar multiplication), and the pro jection

operator over linear spaces cannot be applied directly. Still, this set of vectors does form an

a(cid:14)ne vector space, and we can pro ject onto it using an algebraic technique, as explained below.

5

De(cid:12)nition A (cid:18) R

is an n-dimensional a(cid:14)ne space if for al l vectors v

2A, the set of vectors:

a

n

def

A (cid:0) v

= fu

(cid:0) v

ju

2 Ag is a linear space.

a

a

a

a

Hence, we can pick a vector in an a(cid:14)ne space, v

2A, and de(cid:12)ne the translation T

: A ! V ,

a

1

a

where V is a linear space, V = A (cid:0) v

. This translation is trivially extended for any vector

a

1

0

n

0

0

n

v

2 R

, by de(cid:12)ning T

(v

) = v

(cid:0) v

. In order to pro ject any vector v 2 R

onto A, we apply

a

a

1

the translation T

to v and pro ject T

(v) onto V , which results in a vector P (T

(v)) in V . By

a

a

a

applying the inverse transform T

to it, we obtain the pro jection of v on A, as demonstrated

a

(cid:0)1

in Figure 8. The linear space in the (cid:12)gure is the two dimensional vector space fhx; yij y = (cid:0)xg,

and the a(cid:14)ne space is fhx; yij y = (cid:0)x + 4g. The transform T

consists of subtracting the vector

a

h0; 4i. The solid arrow corresponds to the direct pro jection of the vector v onto the point P (v)

of the a(cid:14)ne space. The dotted arrows represent the pro jection via translation of v to T

(v), the

a

pro jection of the latter onto the linear vector space, and the inverse translation of the result,

P (T

(v)), onto the a(cid:14)ne space.

a

5. Many thanks to John Hughes for introducing us to this technique.

188

Learning Geometrically-Constrained HMMs

<x,-x+4>

-2

6

4

2

-2

-4

P(v)

v

2

4
Ta (v)

P(Ta (v))

<x,-x>

Figure 8: Pro jecting v onto the a(cid:14)ne vector space fhx; yij y = (cid:0)x + 4g.

Although the procedure for preserving additivity over headings is not formally proven to pre-

serve monotone convergence of the likelihood function towards a local maximum, our extensive

experiments consisting of hundreds of runs have shown that monotone convergence is preserved.

5 Choosing an Initial Model

Typically, in instances of the Baum-Welch algorithm, an initial model is picked uniformly at

random from the space of all possible models, perhaps trying multiple initial models to (cid:12)nd dif-

ferent local likelihood maxima. An alternative approach we have reported (Shatkay & Kaelbling,

1997) was based on clustering the accumulated odometric information using the simple k-means

algorithm (Duda & Hart, 1973), taking the clusters to be the states in which the observations

were recorded, to obtain state and observation counts and estimate the model parameters.

If perpendicularity is assumed when collecting the data, as shown in Figure 4, the k-means

algorithm assigns the same cluster (state) to odometric readings recorded at close locations,

leading to reasonable initial models. However, when this assumption is dropped, as illustrated

in Figure 5, the cumulative rotational error distorts the odometric location recorded within a

global coordinate system, so that the location assigned to the same state during multiple visits

varies greatly and would not be recognized as \the same"" by a simple location-based clustering

algorithm. To overcome this, we developed an alternative initialization heuristics, which we call

tag-based initialization. It is based directly on the recorded relations between states, rather than

on states' absolute location. For clarity, the description here consists mostly of an illustrative

example, and concentrates on the case where global consistency constraints are enforced.

Given a sequence of observations and odometric readings E, we begin by clustering the odometric

readings into buckets. The number of buckets is at most the number of distinct state transitions

recorded in the sequence. The goal at this stage is to have each bucket contain all the odometric

readings that are close to each other along all three dimensions.

To achieve this, we start by (cid:12)xing a predetermined, small standard deviation value along the x,

y , and (cid:18) dimensions. Denote these standard deviation values (cid:27)

; (cid:27)

; (cid:27)

respectively, (typically

x

y

(cid:18)

(cid:27)

= (cid:27)

). The (cid:12)rst odometric reading is assigned to bucket 0 and the mean of this bucket is

x

y

set to be the value of this reading. Through the rest of the process the subsequent odometric

readings are examined. If the next reading is within 1:5 standard deviations along each of the

three dimensions from the mean of some existing non-empty bucket, add it to the bucket and

189

Shatkay & Kaelbling

< 2, 94, 92 >
< -4, 102, 91 >

<1994, 0, 88 >
< 1998, -5, 90 >

< 3, -93, 86 >
< -2, -106, 91 >

< -1999, -1, 94 > 
< -2003, 7, 87 >

µ1:

µ2:

µ3:

µ4:

<-1, 98, 91.5>

<1996, -2.5, 89>

<0.5, -99.5, 88.5>

<-2001, 3, 90.5>

1

2

3

4

Figure 9: The bucket assignment of the example sequence.

update the bucket mean accordingly. If not, assign it to an empty bucket and set the mean of

the bucket to be this reading.

Intuitively, by using this heuristic each of the resulting buckets is tightly concentrated about

its mean. We note that other clustering algorithms (Duda & Hart, 1973) could be used at the

bucketing stage.

Example 5.1 We would like to learn a 4-state model from a sequence of odometric readings,

hx; y ; (cid:18)i as fol lows:

h2 94 92i; h1994 0 88i; h3 (cid:0) 93 86i; h(cid:0)1999 1 94i;

h(cid:0)4 102 91i; h1998 (cid:0) 5 90i; h(cid:0)2 (cid:0) 106 91i; h(cid:0)2003 7 87i :

As a (cid:12)rst stage we place these readings into buckets. Suppose the standard deviation constant is

20. The placement is as shown in Figure 9. The mean value associated with each bucket is shown

as wel l.

2

The next stage of the algorithm is the state-tagging phase, in which each odometric reading,

r

, is assigned a pair of states, s

; s

, denoting the origin state (from which the transition took

t

i

j

place) and the destination state (to which the transition led), respectively. In conjunction, the

mean entries, (cid:22)

, of the relation matrix, R, are populated.

ij

Example 5.1 (cont.) Returning to the sequence above, the process is demonstrated in Fig-

ure 10. We assume that the data recording starts at state 0, and that the odometric change

through self transitions is 0, with some smal l standard deviation (we use 20 here as wel l). This

is shown on part A of the (cid:12)gure.

Since the (cid:12)rst element in the sequence, h2 94 92i, is more than two standard deviations away

from the mean (cid:22)[0][0] and no other entry in the relation row of state 0 is populated, we pick 1

as the next state and populate the mean (cid:22)[0][1] to be the same as the mean of bucket 1, to which

h2 94 92i belongs. To maintain geometrical consistency the mean (cid:22)[1][0] is set to (cid:0)(cid:22)[0][1], as

shown in part B of the (cid:12)gure. We now have populated 2 o(cid:11)-diagonal entries, and the state

sequence is h0; 1i. The entry [0][1] in the matrix becomes associated with bucket 1, and this

information is recorded for helping with tagging future odometric readings belonging to the same

bucket.

The next odometric reading, h1994 0 88i, is a few standard deviations from any populated mean

in row 1 (where 1 is the current believed state). Hence, we pick a new state 2, and set the mean

(cid:22)[1][2] to be (cid:22)2|the mean of bucket 2|to which the reading belongs (Figure 10 C). The entry

[1][2] is recorded as associated with bucket 2. To preserve anti-symmetry and additivity, (cid:22)[2][1]

is set to (cid:0)(cid:22)[1][2]. (cid:22)[0][2] is set to be the sum (cid:22)[0][1] + (cid:22)[1][2], and (cid:22)[2][0] is set to (cid:0)(cid:22)[0][2].

190

Learning Geometrically-Constrained HMMs

0

1

2

3

0

1

2

3

A

0

1

2

3

<0,0,0>

<0,0,0>

<0,0,0>

<0,0,0>

S: 0

C

0

1

2

3

<-1,
  98,
  91.5>

<0,0,0>

<0,0,0>

<    1,
  -98,
  -91.5>

<-1995,
 -95.5,
  179.5>

<-1996,
    2.5,
  -89>

<1995,
  95.5,
-179.5>
<1996,
  -2.5,
   89>

<0,0,0>

<0,0,0>

S: 0, 1, 2

Bucket(R[1][2]) =  µ2

0

1

2

3

0

1

2

3

B

2

3

0

<0,0,0>

<    1,
  -98,
  -91.5>

1
<-1,
  98,
  91.5>

<0,0,0>

<0,0,0>

<0,0,0>

S: 0. 1
Bucket(R[0][1]) =  µ1

D

0

<0,0,0>

<    1,
  -98,
  -91.5>

1
<-1,
  98,
  91.5>

<0,0,0>

<-1995,
 -95.5,
  179.5>

<-1996,
    2.5,
  -89>

2
<1995,
  95.5,
 -179.5>
<1996,
  -2.5,
   89>

3
<1995.5,
    -4,
    -91>

<1996.5,
 -102,
   177.5>

<0,0,0>

< 0.5,
 -99.5,
   88.5>

<0,0,0>

<-1995.5,
      4,
      91>

<-1996.5,
    102,
  -177.5>

<-0.5,
   99.5,
 -88.5>

S: 0,1,2,3
Bucket(R[2][3]) =  µ3

S: 0,1,2,3,0

Bucket(R[3][0]) = 

µ4

,..., S:0, 1, 2, 3, 0, 1, 2, 3, 0

Figure 10: Populating the odometric relation matrix and creating a state tagging sequence.

Similarly, (cid:22)[2][3] is updated to be the mean of bucket 3, causing the setting of (cid:22)[3][2], (cid:22)[1][3],

(cid:22)[0][3], (cid:22)[3][1], and (cid:22)[3][0]. Bucket 3 is associated with (cid:22)[2][3].

At this stage the odometric table is ful ly populated, as shown in part D of Figure 10. The state

sequence at this point is: h0; 1; 2; 3i. The next reading, h(cid:0)1999 (cid:0)1 94i, is within one standard

deviation from (cid:22)[3][0] and therefore the next state is 0. Entry [3][0] is associated with bucket 4,

(the bucket to which the reading was assigned), and the state sequence becomes: h0; 1; 2; 3; 0i.

The next reading, being from bucket 1, is associated with the relation from state 0 that is tagged

by bucket 1, namely, state 1. By repeating this for the last two readings, the (cid:12)nal state transition

sequence becomes h0; 1; 2; 3; 0; 1; 2; 3; 0i:

2

Note that the process described in the above illustration was simpli(cid:12)ed. In the general case,

we need to take into account the rotational error in the data, use state-relative coordinate

systems, and therefore populate the entries under the transformed anti-symmetry and additivity

constraints:

hx;yi

hx;yi

(cid:5) (cid:22)

(a; b) = (cid:0)T

[(cid:22)

(b; a)] ;

ba

hx;yi

hx;yi

hx;yi

(cid:5) (cid:22)

(a; c) = (cid:22)

(a; b) + T

[(cid:22)

(b; c)],

ba

as de(cid:12)ned in Section 3.3.2.

191

Shatkay & Kaelbling

It is possible that by the end of the tagging algorithm, some rows or columns of the relation

matrix are still unpopulated. This happens when there is too little data to learn from or when

the number of states provided to the algorithm is too large with respect to the actual model. In

such cases we can either \trim"" the model, using the number of populated rows as the number

of states, or pick random odometric readings to populate the rest of the table, improving these

estimates later. Note that the (cid:12)rst approach suggests a method for learning the number of states

in the model when this is not given, starting from a gross over-estimate of the number, and trun-

cating it to the number of populated rows in the odometric table after initialization is performed.

Once the state-transition sequence is obtained, the rest of the initialization algorithm is the same

as it is for k-means based initialization, deriving state-transition counts from the state-transition

sequence, assigning the observations to the states under the assumption that the state sequence

is correct, and obtaining state-transition and observation probabilities. The initialization phase

does not incur much computational overhead, and is equivalent time-wise to performing one

additional iteration of the em procedure.

6 Experiments and Results

The goal of the work described so far is to use odometry to improve the learning of topological

models, while using fewer iterations and less data. We tested our algorithm in a simple robot-

navigation world. Our experiments consist of running the algorithm both on data obtained

from a simulated model and on data gathered by our mobile robot, Ramona. The amount of

data gathered by Ramona is used here as a proof of concept but is not su(cid:14)cient for statistical

analysis. For the latter, we use data obtained from the simulated model. We gathered data and

used the algorithms both with and without the perpendicularity assumption (see Section 3.3.2),

and results are provided from both settings.

6.1 Robot Domain

The robot used in our experiments, Ramona, is a modi(cid:12)ed RWI B21 robot. It has a cylindrical

synchro-drive base, 24 ultrasonic sensors and 24 infrared sensors, situated evenly around its

circumference. The infrared sensors are used mostly for short-range obstacle avoidance. The

ultrasonic sensors are longer ranged, and are used for obtaining (noisy) observations of the

environment. In the experiments described here, the robot follows a prescribed path through

the corridors in the o(cid:14)ce environment of our department. Thus, there is no decision-making

involved, and an hmm is a su(cid:14)cient model, rather than a complete pomdp.

Low-level software

provides a level of abstraction that allows the robot to move through hallways

6

from intersection to intersection and to turn ninety degrees to the left or right. The software

uses sonar data to distinguish doors, openings, and intersections along the path, and to stop

the robot's current action whenever such a landmark is detected. Each stop|either due to the

natural termination of an action or due to a landmark detection|is considered by the robot to

be a \state"".

At each stop, ultrasonic data interpretation allows the robot to perceive, in each of the three

cardinal directions, (front, left and right), whether there is an open space, a door, a wall, or

something unknown.

Encoders on the robot's wheels allow it to estimate its pose (position and orientation) with re-

spect to its pose at the previous intersection. After recording both the sonar-based observations

6. The low-level software was written and maintained by James Kurien.

192

Learning Geometrically-Constrained HMMs

3

2

4

5

6

7

8

9

1

0

16

15

14

10

11

12

13

12
13

14 15

16

10
11

23

22
21

20

19

18
17

9
8

6

7

5
4

3

29
28

42

0

43

12

41

35

34

40

38
36
37

39

33
32

24
25

26 27

30 31

Figure 11: True model of the corridors Ra-

mona traversed. Arrows represent the pre-

scribed path direction.

Figure 12: True model of a prescribed path

through the simulated hallway environment.

and the odometric information, the robot goes on to execute the next prescribed action. The

action command is issued manually by a human operator. Of course, both the action perfor-

mance and the perception routines are sub ject to error. The path Ramona followed consists of

4 connected corridors in our building, which include 17 states, as shown in Figure 11.

In our simulation, we manually generated an hmm representing a prescribed path of the robot

through the complete o(cid:14)ce environment of our department, consisting of 44 states, and the

associated transition, observation, and odometric distributions. The transition probabilities

re(cid:13)ect an action failure rate of about 5 (cid:0) 10%. That is, the probability of moving from the

current state to the correct next state in the environment, under the predetermined action is

between 0:85 and 0:95. The probability of self transition is typically between 0:05 and 0:15.

Some small probability (typically smaller than 0:02) is sometimes assigned to other transitions.

Our experience with the real robot proves that this is a reasonable transition model, since

typically the robot moves to the next state correctly, and the only error that occurs with some

signi(cid:12)cant frequency is when it does not move at all, due to sonar interpretation indicating a

barrier when there is actually none. Once the action command is repeated the robot usually

performs the action correctly, moving to the expected next state. The observation distribution

typically assigns probabilities of 0:85 (cid:0) 0:95 to the true observation that should be perceived

by the robot at each state, and probabilities of 0:05(cid:0) 0:15 to other observations that might be

perceived. For example, if a door should actually be perceived, a door is typically assigned a

probability of 0:85(cid:0)0:9, a wall is assigned a probability of 0:09(cid:0)0:1 and an open space is assigned

a probability of about 0:01 to be perceived. The standard deviation around odometric readings

is about 5% of the mean.

Figure 12 shows the hmm corresponding to the simulated hallway environment. Observations

and orientation are omitted from the (cid:12)gure for clarity. Nodes correspond to states in the

environment, while directed edges correspond to the corridors; the arrows point at the direction

in which the corridors were traversed. Further interpretation of the (cid:12)gures is provided in the

following section.

193

Shatkay & Kaelbling

6.2 Evaluation Method

There are a number of di(cid:11)erent ways of evaluating the results of a model-learning algorithm.

None are completely satisfactory, but they all give some insight into the utility of the results.

In this domain, there are transitions and observations that usually take place, and are therefore

more likely than the others. Furthermore, the relational information gives us a rough estimate

of the metric locations of the states. To get a qualitative sense of the plausibility of a learnt

model, we can extract an essential map from the learnt model, consisting of the states, the

most likely transitions and the metric measures associated with them, and ask whether this map

corresponds to the essential map underlying the true world.

Figures 11 and 12 are such essential versions of the true models, while Figures 15 and 17, shown

later, are essential versions of representative learnt ones (obtained from sequences gathered

under the perpendicularity assumption). Black dots represent the physical locations of states,

and each state is assigned a unique number. Multiple state numbers associated with a single

location typically correspond to di(cid:11)erent orientations of the robot at that location. The larger

black circle represents the initial state. Solid arrows represent the most likely non-self transitions

between the states. Dashed arrows represent the other transitions when their probability is 0:2

or higher. Typically, due to the predetermined path we have taken, the connectivity of the

modeled environment is low, and therefore the transitions represented by dashed arrows are

almost as likely as the most likely ones. Note that the length of the arrows, within each plot, is

signi(cid:12)cant and represents the length of the corridors, drawn to scale.

It is important to note that the (cid:12)gures do not provide a complete representation of the models.

First, they lack observation and orientation information. We stress the fact that the (cid:12)gures

serve more as a visual aid than as a plot of the true model. We are looking for a good topological

model rather than a geometrical model. The (cid:12)gures provide a geometrical embedding of the

topological model. However, even when the geometry, as described by the relation matrix, is

di(cid:11)erent, the topology, as described by the transition and observation matrices, can still be valid.

Traditionally, in simulation experiments, the learnt model is quantitatively compared to the

actual model that generated the data. Each of the models induces a probability distribution

on strings of observations; the asymmetric Kullback-Leibler divergence (Kullback & Leibler,

1951) between the two distributions is a measure of how good the learnt model is with respect

to the true model. Given a true probability distribution P = fp

; :::; p

g and a learnt one

1

n

Q = fq

; :::; q

g, the kl divergence of Q with respect to P is:

1

n

n

X

def

p

i

D(P jjQ)

=

p

log

:

i

2

q

i

i=1

We report our results in terms of a sampled version of the kl divergence, as described by Juang

and Rabiner (1985). It is based on generating sequences of su(cid:14)cient length (5 sequences of 1000

observations in our case) according to the distribution induced by the true model, and comparing

their log-likelihood according to the learnt model with the true model log-likelihood. The total

di(cid:11)erence in log-likelihood is then divided by the total number of observations, accumulated

over all the sequences, giving a number that roughly measures the di(cid:11)erence in log-likelihood

per observation. Formally stated, let M

be the true model and M

a learnt one. By generating

1

2

K sequences S

; : : : ; S

, each of length T , from the true model, M

, the sampled kl-divergence,

1

K

1

D

is:

s

K

X

i=1

[log(Pr(S

jM

)) (cid:0) log(Pr(S

jM

))]

i

1

i

2

D

(M

jjM

) =

:

s

1

2

K T

194

Learning Geometrically-Constrained HMMs

1200

1000

800

600

400

200

200

400

600

800

1000

1000

500

-1500 -1250 -1000

-750

-500

-250

-500

-1000

-1500

Figure 13: Sequence gathered by Ramona,

Figure 14: Sequence generated by our simula-

perpendicularity assumed.

tor, perpendicularity assumed.

We ignore the odometric information when applying the kl measure, thus allowing comparison

between purely topological models that are learnt with and without odometry.

6.3 Results within a Global Framework

We let Ramona go around the path depicted in Figure 11 and collect a sequence of about

300 observations, while assuming perpendicularity of the environment, that is, at every turning

point the angle of turn is 90

. Thus at each turn Ramona realigns its odometric readings with

(cid:14)

its initial X and Y axes. Figure 13 plots the sequence of metric coordinates, gathered in this

way, while accumulating consecutive odometric readings, pro jected on hx; yi. We applied the

learning algorithm to the data 30 times. 10 of these runs were started from a k-means-based

initial model, 10 started from a tag-based initial model, and 10 started from a random initial

model. In addition we also ran the standard Baum-Welch algorithm, ignoring the odometric

information, 10 times.

(Note that there is non-determinism even when using biased initial

models, since the k-means clustering starts from random seeds, and low

random noise is added

7

to the data in all algorithms to avoid numerical instabilities, thus multiple runs give multiple

results). We report here the results obtained using the tag-based method, which is the most

appropriate initialization method in the general case. These results are contrasted with those

obtained when odometric information is not used at all. For a comparison of all four settings

the reader is referred to the complete report of this work (Shatkay, 1999).

Figure 15 shows the essential representations of typical learnt models starting from a tag-based

initial model. The geometry of the learnt model strongly corresponds to that of the true en-

vironment, and most of the states' positions were learnt correctly. Although the (cid:12)gure does

not show it, the learnt observation distributions at each state usually match well with the true

observations.

To demonstrate the e(cid:11)ect of odometry on the quality of the learnt topological model, we contrast

the plotted models learnt using odometry with a representative topological model learnt without

7. A random number between -1cm and 1cm is added to recorded distances that are typically several meters

long.

195

3
3

4
4

5
5

6
6

7

7

2
2

1
1

16
16

15
15

0

0

14
14

Shatkay & Kaelbling

8
8

9

9

10
10

11
11

12

12

13

13

16

10

15

8

13

5

0

7

11

6

4

12

14

1

3

9

2

Figure 15: Learnt model of the corridors Ra-

Figure 16: The topology of a model learnt

mona traversed.

without the use of odometry.

the use of odometric information. Figure 16 shows the topology of a typical model learnt without

the use of odometric information. In this case, the arcs represent only topological relationships,

and their length is not meaningful. The initial state is shown as a bold circle.

It is clear that

the topology learnt does not match the characteristic loop topology of the true environment.

For obtaining statistically su(cid:14)cient information, we generated 5 data sequences, each of length

1000, using Monte Carlo sampling from the hidden Markov model whose pro jection is shown in

Figure 12. One of these sequences is depicted in Figure 14. The (cid:12)gure demonstrates that the

noise model used in the simulation is indeed compatible with the noise pattern associated with

real robot data. We used four di(cid:11)erent settings of the learning algorithm:

(cid:15) starting from a biased, tag-based, initial model and using odometric information;

(cid:15) starting from a biased, k-means-based, initial model and using odometric information;

(cid:15) starting from an initial model picked uniformly at random, while using odometric infor-

mation;

(cid:15) starting from a random initial model without using odometric information (standard Baum-

Welch).

For each sequence and each of the four algorithmic settings we ran the algorithm 10 times. To

keep the discussion focused, we concentrate here on the (cid:12)rst and the last of these settings and

the reader is referred to a more extensive report (Shatkay, 1999) for a complete discussion.

In all the experiments, N was set to be 44, which is the \correct"" number of states; for gener-

alization, it will be necessary to use cross-validation or regularization methods to select model

complexity. Section 5 also suggests one possible heuristic for obtaining an estimate of the number

of states.

Figure 17 shows an essential version of one learnt model, obtained from the sequence shown

in Figure 14, using tag-based initialization. We note that the learnt model is not completely

196

Learning Geometrically-Constrained HMMs

26
14

25
33

24
23

32

22

21

31

20
19

30

34

15

16 27

29

17
18

28

13

6

5

12

7

34

8

9
0

2

1

11

42

10

43

41

40

35 36

37

38

39

Figure 17: Learnt model of the simulated hallway environment.

accurate with respect to the true model. However, there is an obvious correspondence between

groups of states in the learnt and true models, and most of the transitions (as well as the

observations, which are not shown) were learnt correctly. The quality of the geometry of the

learnt model in this simulated large environment varies, and the geometrical results are not as

uniformly good as was the case when learning the smaller environment from real robot data.

As the environment gets large, the global relations between remote states, which are re(cid:13)ected

in the geometrical consistency constraints, become harder to learn. Still, the topology of the

learnt model as demonstrated by our statistical experiments is good.

Table 1 lists the kl divergence between the true and learnt model, as well as the number

of runs until convergence was reached, for each of the 5 sequences for both the setting that

uses odometric information under tag-based initialization and the learning algorithm that does

not use odometric information, averaged over 10 runs per sequence. We stress that each kl

divergence measure is calculated based on new data sequences that are generated from the true

model, as described in Section 6.2. The 5 sequences from which the models were learnt do not

participate in the testing process.

The kl divergence with respect to the true model for models learnt using odometry, is about 5-6

times smal ler than for models learnt without odometric data. The standard deviation around

the means is about 0.2 for kl distances for models learnt with odometry and 1.5 for the no-

odometry setting. To check the signi(cid:12)cance of our results we used the simple two-sample t-test.

The models learnt using odometric information have statistically signi(cid:12)cantly (p (cid:28) 0:0005) lower

average kl divergence than the others.

Seq. #

1

2

3

4

5

With

kl

0.981

1.290

1.115

1.241

1.241

Odo

Iter # 16.70

20.90

22.30

12.70

27.50

No

kl

6.351

4.863

5.926

6.261

4.802

Odo

Iter # 124.1

126.0

113.0

107.4

122.9

Table 1: Average results of two learning settings with (cid:12)ve training sequences.

197

Shatkay & Kaelbling

In addition, the number of iterations required for convergence when learning using odometric

information is roughly 4-5 times smaller than that required when ignoring such information.

Again, the t-test veri(cid:12)es the signi(cid:12)cance of this result.

Under all three initialization settings, the models learnt are topologically somewhat inferior (and

this is with high statistical signi(cid:12)cance), in terms of the kl divergence, to those learnt without

enforcing additivity, reported in earlier papers (Shatkay & Kaelbling, 1997, 1998). This is likely

to be a result of the very strong constraints enforced during the learning process, which prevent

the algorithm from searching better areas of the learning-space, and restrict it to reach poor local

maxima. The geometry looks superior in some cases, but it is not signi(cid:12)cantly better. However,

there seems to be less variability in the quality of the geometrical models across multiple runs

when additivity is enforced.

While the details of an extensive comparison between the di(cid:11)erent initialization methods are

beyond the scope of this paper, we point out that our studies of both small and large models

show that when large models and long data sequences are involved, random initialization often

results in lower KL-divergence than the tag-based initialization. This again has to do with the

strong bias of tag-based initialization, which can lead to very peaked models compared with the

less-peaked distributions associated with the true model. Random initialization leads to (cid:13)atter

models. As the KL-divergence strongly penalizes models that are much more peaked than the

true ones, randomly initialized models are often closer, in terms of this measure, to the true

models than the very peaked ones learnt from other initial models. When learning small models,

where su(cid:14)cient training data is available, the tag-based initialization results in models that are

clearly superior to the random ones. Again, the reader is referred to the complete report of this

work (Shatkay, 1999) for a comparative study of all initialization methods under the various

settings.

6.4 Results within a Relative Framework

We applied the algorithm described in Section 4.3, extended to accommodate the state-relative

constraints (as listed in Section 3.3.2). The data used was gathered by the robot from the

same environment, and generated from the same simulated model as before (Figures 11, 12).

However, here the data is generated without assuming perpendicularity. This means that the x

and y coordinates are not realigned after each turn with the global x and y axes, but rather,

recorded \as-is."" The evaluation methods stay as described above.

Figure 18 shows the pro jection of the odometric readings that Ramona recorded along the

x and y dimensions, while traversing this environment. For obtaining statistically su(cid:14)cient

information, we generated 5 data sequences, each of length 800, using Monte Carlo sampling

from the hidden Markov model whose pro jection is shown in Figure 12. One of these sequences

is depicted in Figure 19.

Figure 20 shows a typical model obtained by applying the algorithm enforcing the complete

geometrical consistency, to the robot data shown in Figure 18, using tag-based initialization.

We note that the rectangular geometry of the environment is preserved, although state 0 does

not participate in the loop. This is explained by observing the corresponding area of the true

environment as depicted in Figure 11, consisting of the 4 states clustered at the bottom left

corner (0, 14, 15 and 16). Due to the relatively large number of states that are close together in

that area of the true environment, it was not recognized that we ever returned particularly to

state 0 during the loop. Therefore, there was only one transition recorded from state 0 to state

198

Learning Geometrically-Constrained HMMs

3000

2500

2000

1500

1000

500

1500

1000

500

-1500

-1000

-500

500

-500

-1000

-1500

-2500 -2000 -1500 -1000 -500

500

1000

Figure 18: Sequence gathered by Ramona, no

Figure 19: Sequence generated by our simula-

perpendicularity assumed.

tor, no perpendicularity assumed.

15

14

16

13

12

11

1

0

6

2

3

4

5

10

7

9

8

Figure 20: Learnt model of the corridors Ramona traversed. Initialization is tag-based.

1 according to the expected transition counts calculated by the algorithm. When pro jecting the

angles to maintain additivity, (as described in Section 4.3.2), the angle from state 0 to 1 was

therefore compromised, allowing geometrical consistency to maintain the rectangular geometry

among the more regularly visited states.

For the purpose of quantitatively evaluating the learning algorithm we list in Table 2 the kl

divergence between the true and learnt model, as well as the number of iterations until conver-

gence was reached, for each of the 5 simulation sequences with/without odometric information,

averaged over 10 runs per sequence. The table demonstrates that the kl divergence with re-

spect to the true model for models learnt using odometric data, is about 8 times smal ler than

for models learnt without it. To check the signi(cid:12)cance of our results we again use the simple

two-sample t-test. The models learnt using odometric information have highly statistically sig-

ni(cid:12)cantly (p (cid:28) 0:0005) lower average kl divergence than the others. In addition, the number of

199

Shatkay & Kaelbling

Seq. #

1

2

3

4

5

With

kl

1.46

1.18

1.20

1.02

1.22

Odo

Iter # 11.8

36.8

30.7

24.6

33.3

No

kl

6.91

9.93

10.03

9.54

12.43

Odo

Iter # 113.3

113.1

102.0

104.2

112.5

Table 2: Average results of 2 learning settings with 5 training sequences.

iterations required for convergence when learning using odometric information is smaller than

required when ignoring such information. Again, the t-test veri(cid:12)es the signi(cid:12)cance (p < 0:005)

of this result.

It is important to point out that the number of iterations, although much lower, does not auto-

matically imply that our algorithm runs in less time than the non-odometric Baum-Welch. The

ma jor bottleneck is caused by the need to compute within the forward-backward calculations,

as described in Section 4.2.1, the values of the normal and the von-Mises densities. These re-

quire the calculation of exponent terms rather than simple multiplications, slowing down each

iteration, under the current na(cid:127)(cid:16)ve implementation. However, we can solve this by augmenting

the program with look-up tables for obtaining the relevant values rather than calculating them.

In addition, we can take advantage of the symmetry in the relations table to cut down on the

amount of calculation required. It is also possible to use the fact that many odometric rela-

tions remain unchanged (particularly in the later iterations of the algorithm) from one iteration

to the next, and therefore values can be cached and shared between iterations rather than be

recalculated at each iteration.

6.5 Reducing the Amount of Data

Learning hmms obviously requires visiting states and transitioning between them multiple times,

to gather su(cid:14)cient data for robust statistical estimation. Intuitively, exploiting odometric data

can help reduce the number of visits needed for obtaining a reliable model.

To examine the in(cid:13)uence of reduction in the length of data sequences on the quality of the learnt

models, we took one of the 5 sequences and used its pre(cid:12)xes of length 100 to 800 (the complete

sequence), in increments of 100, as training sequences. We ran the two algorithmic settings over

each of the 8 pre(cid:12)x sequences, 10 times repeatedly. We then used the kl-divergence as described

above to evaluate each of the resulting models with respect to the true model. For each pre(cid:12)x

length we averaged the kl-divergence over the 10 runs.

The plot in Figure 21 depicts the average kl-divergence as a function of the sequence length for

each of the two settings. It demonstrates that, in terms of the kl divergence, our algorithm,

which uses odometric information, is robust in the face of data reduction, (down to 200 data

points). In contrast, learning without the use of odometry quickly deteriorates as the amount

of data is reduced.

We note that the data sequence is twice as \wide"" when odometry is used than when it is

not; that is, there is more information in each element of the sequence when odometry data is

recorded. However, the e(cid:11)ort of recording this additional odometric information is negligible,

and is well rewarded by the fact that fewer observations and less exploration are required for

obtaining a data sequence su(cid:14)cient for adequate learning.

200

Learning Geometrically-Constrained HMMs

50

40

30

20

10

KL

No Odometry

Odometry Used

0

200

400
Seq. Length

600

800

Figure 21: Average kl divergence as a function of sequence length.

7 Conclusions

Odometric information, which is often readily available in the robotics domain, makes it possible

to learn hidden Markov models e(cid:14)ciently and e(cid:11)ectively, while using shorter training sequences.

More importantly, in contrast to the traditional perception of viewing the topological and the

geometric models as two distinct types of entities, we have shown that the odometric information

can be directly incorporated into the traditional topological hmm model, while maintaining

convergence of the reestimation algorithm to a local maximum of the likelihood function.

Our method uses the odometric information in two ways. We (cid:12)rst choose an initial model,

based on the odometric information. An iterative procedure, which extends the Baum-Welch

algorithm, is then used to learn the topological model of the environment while learning an

additional set of constrained geometric parameters. The additional set of constrained parame-

ters constitutes an extension to the basic hmm/pomdp model of transitions and observations.

Even though we are primarily interested in the underlying topological model (transition and

observation probabilities), our experiments demonstrate that the use of odometric relations can

reduce the number of iterations and the amount of data required by the algorithm, and improve

the resulting model.

The initialization procedure and the enforcement of the additivity constraint over relatively

small models prove helpful both topologically and geometrically. An extensive study (Shatkay,

1999) shows that for long data sequences, generated from large models, enforcing only anti-

symmetry rather than additivity, leads to better topological models. This is because in these

cases, initialization is not always good, and additivity may over-constrain the learning to an

unfavorable area. Learning large models may bene(cid:12)t from enforcing only anti-symmetry during

the (cid:12)rst few iterations, and complete additivity in later iterations. Alternatively, we may use our

algorithm, enforcing additivity, to learn separate models for small portions of the environment,

combining them later into one complete model. A similar idea of combining small model-

fragments into a complete map of an environments was applied, in the context of geometrical

maps, in recent work by Leonard and Feder (2000).

201

Shatkay & Kaelbling

The work presented here demonstrates how domain-speci(cid:12)c information and constraints can be

enforced as part of the statistical estimation process, resulting in better models, while requiring

shorter data sequences. We strongly believe that this idea can be applied in domains other than

robotics. In particular, the acquisition of hmms for use in molecular biology may greatly bene(cid:12)t

from exploiting geometrical (and other) constraints on molecular structures. Similarly, temporal

constraints may be exploited in domains in which pomdps are appropriate for decision-support,

such as air-tra(cid:14)c control and medicine.

Acknowledgments

We thank Sebastian Thrun for his insightful comments throughout this work, John Hughes and Luis Ortiz

for their helpful advice, Anthony Cassandra for his code for generating random distributions, Bill Smart

for sustaining Ramona and Jim Kurien for providing the low level code for driving her. The presentation

in this paper has bene(cid:12)ted from the comments made by the anonymous referees to whom we are grateful.

This work was done while both authors were at the Computer Science department at Brown University,

and was supported by DARPA/Rome Labs Planning Initiative grant F30602-95-1-0020, by NSF grants

IRI-9453383 and IRI-9312395, and by the Brown University Graduate Research Fellowship.

202

Learning Geometrically-Constrained HMMs

Appendix A. An Overview of the Odometric Learning Algorithm

The algorithm takes as input an experience sequence E = hr; V i, consisting of the odometric

sequence r and the observation sequence V , as de(cid:12)ned in the beginning of Section 4.2. The

number of states is also assumed to be given.

Learn Odometric HMM(E)

1

Initialize matrices A; B ; R

(See Section 5)

2 max change   1

3 while ( max change > (cid:15))

4 do Calculate Forward probabilities, (cid:11)

(Equation 4)

5

Calculate Backward probabilities, (cid:12)

(Equation 5)

6

Calculate state-occupation probabilities, (cid:13)

(Equation 6)

7

Calculate State-transition probabilities, (cid:24) ;

(Equation 7)

8

Old A   A; Old B   B

9

A   Reestimate (A)

(Equation 8, left)

10

B   Reestimate (B )

(Equation 8, right)

11

R

  Reestimate (R

)

(Equations 12 and 13)

(cid:18)

(cid:18)

12

hR

; R

i   Reestimate(R

; R

)

(Equations 10 and 11)

x

y

x

y

13

max change   MAX(Get Max Change(A; Old A );

Get Max Change(B ; Old B ))

The equations referenced in Step 12 correspond to updates under the perpendicularity assump-

tion, where a global framework is used. See (Shatkay, 1999) for update formulae within a

state-relative framework.

If additivity is enforced, step 11 is followed by a pro jection of the reestimated R

onto an additive

(cid:18)

a(cid:14)ne space, as described in Section 4.3.2. In addition, step 12 is substituted by the procedure

described in Section 4.3.1. The reader is referred again to (Shatkay, 1999) for further detail.

Get Max Change is a function that takes two matrices and returns the maximal element-wise

absolute di(cid:11)erence between them. (cid:15) is a constant set to denote the margin of error on changes

in parameters. When the change in parameters is \small enough"", the model is regarded as

\unchanged"".

203

Shatkay & Kaelbling

References

Abe, N., & Warmuth, M. K. (1992). On the computational complexity of approximating distri-

butions by probabilistic automata. Machine Learning, 9 (2), 205{260.

Angluin, D. (1987). Learning regular sets from queries and counterexamples. Information and

Computation, 75, 87{106.

Asada, M. (1991). Map building for a mobile robot from sensory data. In Iyengar, S. S., &

Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 312{322. IEEE Computer Society Press.

Bartels, R. (1984). Estimation in a bidirectional mixture of von Mises distributions. Biometrics,

40, 777{784.

Basye, K., Dean, T., & Kaelbling, L. P. (1995). Learning dynamics: System identi(cid:12)cation for

perceptually challenged agents. Arti(cid:12)cial Intel ligence, 72 (1).

Baum, L. E., Petrie, T., Soules, G., & Weiss, N. (1970). A maximization technique occurring

in the statistical analysis of probabilistic functions of Markov chains. The Annals of

Mathematical Statistics, 41 (1), 164{171.

Cassandra, A. R., Kaelbling, L. P., & Kurien, J. A. (1996). Acting under uncertainty: Discrete

Bayesian models for mobile-robot navigation. In Proceedings of IEEE/RSJ International

Conference on Intel ligent Robots and Systems.

DeGroot, M. H. (1986). Probability and Statistics (2nd edition). Addison-Wesley.

Dempster, A. P., Laird, N. M., & Rubin, D. B. (1977). Maximum likelihood from incomplete

data via the EM algorithm. Journal of the Royal Statistical Society, 39 (1), 1{38.

Dissanayake, G., Newman, P., Clark, S., Durrant-Whyte, H. F., & Csorba, M. (2001). A solution

to the simultaneous localization and map building (SLAM) problem. IEEE Transactions

on Robotics and Automation, 17 (3).

Duda, R. O., & Hart, P. E. (1973). Unsupervised Learning and Clustering, chap. 6. John Wiley

and Sons.

Elfes, A. (1989). Using occupancy grids for mobile robot perception and navigation. Computer,

Special Issue on Autonomous Intel ligent Machines, 22 (6), 46{57.

Engelson, S. P., & McDermott, D. V. (1992). Error correction in mobile robot map learning.

In Proceedings of the IEEE International Conference on Robotics and Automation, pp.

2555{2560, Nice, France.

Gold, E. M. (1978). Complexity of automaton identi(cid:12)cation from given data. Information and

Control, 37, 302{320.

Gumbel, E. G., Greenwood, J. A., & Durand, D. (1953). The circular normal distribution:

Theory and tables. American Statistical Society Journal, 48, 131{152.

Hopcroft, J. E., & Ullman, J. D. (1979).

Introduction to Automata Theory, Languages, and

Computation. Addison & Wesley.

204

Learning Geometrically-Constrained HMMs

Juang, B. H. (1985). Maximum likelihood estimation for mixture multivariate stochastic obser-

vations of Markov chains. AT&T Technical Journal, 64 (6).

Juang, B. H., & Rabiner, L. R. (1985). A probabilistic distance measure for hidden Markov

models. AT&T Technical Journal, 64 (2), 391{408.

Koenig, S., & Simmons, R. G. (1996a). Passive distance learning for robot navigation.

In

Proceedings of the Thirteenth International Conference on Machine Learning, pp. 266{

274.

Koenig, S., & Simmons, R. G. (1996b). Unsupervised learning of probabilistic models for robot

navigation. In Proceedings of the IEEE International Conference on Robotics and Automa-

tion.

Kuipers, B., & Byun, Y.-T. (1991). A robot exploration and mapping strategy based on a se-

mantic hierarchy of spatial representations. Journal of Robotics and Autonomous Systems,

8, 47{63.

Kullback, S., & Leibler, R. A. (1951). On information and su(cid:14)ciency. Annals of Mathematical

Statistics, 22 (1), 79{86.

Leonard, J., Durrant-Whyte, H. F., & Cox, I. J. (1991). Dynamic map building for an au-

tonomous mobile robot. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots,

pp. 331{338. IEEE Computer Society Press.

Leonard, J. J., & Feder, H. J. S. (2000). A computationally e(cid:14)cient method for large-scale con-

current mapping and localization. In Hollerbach, J., & Kodischek, D. (Eds.), Proceedings

of the Ninth International Symposium on Robotics Research.

Liporace, L. A. (1982). Maximum likelihood estimation for multivariate observations of Markov

sources. IEEE Transactions on Information Theory, 28 (5).

Mardia, K. V. (1972). Statistics of Directional Data. Academic Press.

Mataric, M. J. (1990). A distributed model for mobile robot environment-learning and naviga-

tion. Master's thesis, MIT, Arti(cid:12)cial Intelligence Laboratory.

McLachlan, G. J., & Krishnan, T. (1997). The EM Algorithm and Extensions. John Wiley &

Sons.

Moravec, H. P. (1988). Sensor fusion in certainty grids for mobile robots. AI Magazine, 9 (2),

61{74.

Moravec, H. P., & Elfes, A. (1985). High resolution maps from wide angle sonar. In Proceedings

of the International Conference on Robotics and Automation, pp. 116{121.

Nourbakhsh, I., Powers, R., & Birch(cid:12)eld, S. (1995). Dervish: An o(cid:14)ce-navigating robot. AI

Magazine, 16 (1), 53{60.

Pierce, D., & Kuipers, B. (1997). Map learning with uninterpreted sensors and e(cid:11)ectors. Arti-

(cid:12)cial Intel ligence, 92 (1-2), 169{227.

205

Shatkay & Kaelbling

Rabiner, L. R. (1989). A tutorial on hidden Markov models and selected applications in speech

recognition. Proceedings of the IEEE, 77 (2), 257{285.

Rivest, R. L., & Schapire, R. E. (1987). Diversity based inference of (cid:12)nite automata.

In

Proceedings of the IEEE Twenty Eighth Annual Symposium on Foundations of Computer

Science, pp. 78{87, Los Angeles, California.

Rivest, R. L., & Schapire, R. E. (1989). Inference of (cid:12)nite automata using homing sequences. In

Proceedings of the Twenty First Annual Symposium on Theory of Computing, pp. 411{420,

Seattle, Washington.

Ron, D., Singer, Y., & Tishbi, N. (1994). Learning probabilistic automata with variable mem-

ory length. In Proceedings of the Seventh Annual Workshop on Computational Learning

Theory, pp. 35{46.

Ron, D., Singer, Y., & Tishbi, N. (1995). On the learnability and usage of acyclic probabilistic

(cid:12)nite automata. In Proceedings of the Eighth Annual Workshop on Computational Learning

Theory, pp. 31{40.

Ron, D., Singer, Y., & Tishby, N. (1998). On the learnability and usage of acyclic probabilistic

(cid:12)nite automata. Journal of Computer and Systems Science, 56 (2).

Shatkay, H. (1999). Learning Models for Robot Navigation. Ph.D. thesis, Department of Com-

puter Science, Brown University, Providence, RI.

Shatkay, H., & Kaelbling, L. P. (1997). Learning topological maps with weak local odometric

information. In Proceedings of the Fifteenth International Joint Conference on Arti(cid:12)cial

Intel ligence, Nagoya, Japan.

Shatkay, H., & Kaelbling, L. P. (1998). Heading in the right direction. In Proceedings of the

Fifteenth International Conference on Machine Learning, Madison, Wisconsin.

Simmons, R. G., & Koenig, S. (1995). Probabilistic navigation in partially observable environ-

ments. In Proceedings of the International Joint Conference on Arti(cid:12)cial Intel ligence.

Smith, R., Self, M., & Cheeseman, P. (1991). A stochastic map for uncertain spatial relation-

ships. In Iyengar, S. S., & Elfes, A. (Eds.), Autonomous Mobile Robots, pp. 323{330. IEEE

Computer Society Press.

Thrun, S. (1999). Learning metric-topological maps for indoor mobile robot navigation. AI

Journal, 1, 21{71.

Thrun, S., & B(cid:127)ucken, A. (1996a). Integrating grid-based and topological maps for mobile robot

navigation. In Proceedings of the Thirteenth National Conference on Arti(cid:12)cial Intel ligence,

pp. 944{950.

Thrun, S., & B(cid:127)ucken, A. (1996b). Learning maps for indoor mobile robot navigation. Tech. rep.

CMU-CS-96-121, School of Computer Science, Carnegie Mellon University, Pittsburgh,

PA.

Thrun, S., Burgard, W., & Fox, D. (1998a). A probabilistic approach to concurrent map acqui-

sition and localization for mobile robots. Machine Learning, 31, 29{53.

206

Learning Geometrically-Constrained HMMs

Thrun, S., Gutmann, J.-S., Fox, D., Burgard, W., & Kuipers, B. J. (1998b). Integrating topolog-

ical and metric maps for mobile robot navigation: A statistical approach. In Proceedings

of the Fifteenth National Conference on Arti(cid:12)cial Intel ligence, pp. 989{995.

Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer.

207"
Symmetry-Based Search Space Reduction For Grid Maps,"  In this paper we explore a symmetry-based search space reduction technique
which can speed up optimal pathfinding on undirected uniform-cost grid maps by
up to 38 times. Our technique decomposes grid maps into a set of empty
rectangles, removing from each rectangle all interior nodes and possibly some
from along the perimeter. We then add a series of macro-edges between selected
pairs of remaining perimeter nodes to facilitate provably optimal traversal
through each rectangle. We also develop a novel online pruning technique to
further speed up search. Our algorithm is fast, memory efficient and retains
the same optimality and completeness guarantees as searching on an unmodified
grid map.
",http://arxiv.org/pdf/1106.4083v1,1,"1
1
0
2

n
u
J

1
2

]
I

A
.
s
c
[

1
v
3
8
0
4
.
6
0
1
1
:
v
i
X
r
a

Symmetry-Based Search Space Reduction For
Grid Maps

Daniel Harabor, Adi Botea, and Philip Kilby

NICTA and The Australian National University
Email: ﬁrstname.lastname@nicta.com.au

September 11, 2018

Abstract

In this paper we explore a symmetry-based search space reduction technique
which can speed up optimal pathﬁnding on undirected uniform-cost grid maps by
up to 38 times. Our technique decomposes grid maps into a set of empty rectangles,
removing from each rectangle all interior nodes and possibly some from along
the perimeter. We then add a series of macro-edges between selected pairs of
remaining perimeter nodes to facilitate provably optimal traversal through each
rectangle. We also develop a novel online pruning technique to further speed up
search. Our algorithm is fast, memory efﬁcient and retains the same optimality and
completeness guarantees as searching on an unmodiﬁed grid map.

1

Introduction

Pathﬁnding on uniform-cost undirected grid maps is a problem commonly appearing
in the literature: for example in application areas such as robotics [7] artiﬁcial intelli-
gence [12] and video games [3, 11]. In such contexts it is often the case that queries
sent to the pathﬁnding system need to be solved as quickly as possible. Traditionally,
this requirement is met through the application of hierarchical decomposition tech-
niques that transform the search space into a much smaller approximate representation
[2, 11]. Such methods are very fast, particularly when compared to the classical A*
algorithm, but have the disadvantage that solutions found in the abstract state space
are often not optimal when mapped back to the original grid. An alternative speedup
method is to develop better heuristics to guide the search [1, 10, 5]. Though usually
fast, optimal and more effective than the popular Manhattan or Octile heuristic (both
analogous to Euclidean distance but optimised to 4 and 8-connected grids), they have
the disadvantage of requiring signiﬁcant memory overhead.

In this paper we present Rectangular Symmetry Reduction (RSR): a graph pruning
algorithm for undirected uniform-cost grid maps which is fast, memory efﬁcient, opti-
mality preserving and which can, in some cases, eliminate entirely the need to search.

1

 
 
 
 
 
 
2

The central idea that we will explore involves the identiﬁcation and elimination of path
symmetries from the search space.

To deal with path symmetries RSR makes use of an off-line empty rectangle de-
composition [6] that converts an arbitrary undirected uniform-cost grid map into an
equivalent one where only nodes from the perimeter of each empty rectangle need
to be explored during search. We extend this approach in several directions: (i) we
generalise the method from 4-connected grid maps to the 8-connected case where the
increase in branching factor makes effective symmetry elimination more challenging;
(ii) we develop a new ofﬂine pruning technique that reduces the number of nodes which
need to be explored during search; (iii) we give a novel online pruning strategy which
speeds up node expansion by selectively evaluating either all neighbours associated
with a particular node or only a small subset. We prove that in each case both optimal-
ity and completeness are preserved.

We perform a thorough empirical analysis, comparing RSR with three similar state-
of-the-art graph pruning algorithms on a number of synthetic and realistic benchmarks,
including one well known set from the popular roleplaying game Baldur’s Gate II.
Compared to Harabor and Botea’s method [6], we both extend the applicability and
improve the speed on the subset of instances where both algorithms are applicable. We
also compare RSR to the recent Swamps-based pruning method of Pochter et al [8]
and the enhanced Portal Heuristic of Goldenberg et al [5]. We show that RSR has
complementary strengths compared to both of these methods and identify classes of
instances where RSR is clearly the better choice, dominating convincingly across a
large number of instances.

2 Related Work

In the presence of symmetry, search algorithms often evaluate many equivalent states
and make little real progress toward the goal. The topic of how best to deal with sym-
metry has received signiﬁcant attention in other parts of the literature [9] but there are
very few works that explicitly identify and deal with symmetry in pathﬁnding domains
such as grid maps. The only work of which we are aware is Empty Rectangular Rooms
[6]: a symmetry breaking technique speciﬁc to 4-connected uniform-cost grid maps
which we refer to as 4ERR. We discuss the main differences between 4ERR and RSR
in Sections 1 and 3.

The dead-end heuristic [1] and Swamps-based pathﬁnding [8] are two closely-
related pruning techniques that identify areas in the search space not relevant for reach-
ing the goal. This is a similar yet complementary goal to RSR, which tries to reduce
the search effort involved in exploring any given area. Both methods decompose the
map into a series of obstacle-free areas. A preliminary online search in the decomposed
graph is then used to identify areas that can be ignored during a subsequent search in
the original grid.

The gateway heuristic [1] and the portal heuristic [5] are two similar memory-
based techniques which also attempt to speed up optimal pathﬁnding on grid maps.
Both decompose the map into a series of adjacent areas and both pre-compute a
database of exact distances between all pairs of nodes that transition from one area

3

to another (called variously “’portals” or “gates”). The main idea is to use this in-
formation to improve the accuracy of cost-to-go estimates during search as a way of
reducing the number states expanded by A*. Where the portal heuristic differs from
other similar works [1, 10] is in its use of the decomposed graph to further prune the
state space. A preliminary search identiﬁes portals relevant to the problem instance at
hand and, during a subsequent search in the original grid, any nodes from an area that
contains no relevant portals are ignored.

In the algorithm engineering community the problem of quickly computing opti-
mal shortest paths has received signiﬁcant attention. State of the art methods such
as Contraction Hierarchies [4] are based on a combination of Dijkstra’s algorithm to-
gether with memory-intensive abstractions. Such algorithms are very fast but they are
also highly optimised for road networks in which certain topological properties hold
true: for example, the existence of “highway” edges that appear on most shortest paths
between arbitrary pairs of nodes. Though mostly orthogonal to RSR, there has been
very little work applying these ideas to searching on grid maps. One recent result how-
ever [11] suggests they are not as effective when the underlying graph contains a high
degree of path symmetry.

3 Rectangular Symmetry Reduction

We begin by making precise the notion of a symmetric relationship between paths in a
uniform cost graph:

Deﬁnition 1. Two paths π1 and π2 are symmetric if they share the same start and goal
node and one can be derived from the other by interchanging the order of the moves.

When applying Deﬁnition 1 to an undirected uniform cost grid 1 we notice that each
node expanded can often be reached from one or more of its ancestors in the search tree
by several symmetric paths of equal length. If the nodes on these alternative paths have
an f -value smaller than the current node (even an equal f -value is often sufﬁcient), A*
will needlessly expand them. We address this problem using the high-level strategy in
Algorithm 1; which identiﬁes and eliminates path symmetries from the grid.

Our approach has similarities with 4ERR [6], a symmetry breaking algorithm lim-
ited to 4-connected grid maps. The main differences are: (i) we generalise 4ERR to
8-connected grid maps (ii) we give a stronger ofﬂine pruning operator to eliminate
more nodes from the grid (iii) we give a new online pruning operator that reduces a
node’s branching factor and further speeds up search.

The generalisation to uniform-cost 8-connected grids is more challenging than it
might look at a ﬁrst glance. On a 4-connected map no node requires more than one
macro-edge (to the closest node on the opposite side of the perimeter) to retain opti-
mality [6]. Thus, it is easy to maintain a low branching factor. As we show in the next
section, many more macro-edges are needed to preserve optimality on 8-connected
maps. We will identify a set of macro-edges that is necessary and sufﬁcient to ensure
that empty rectangles can be crossed optimally. Keeping the branching factor within

1We say uniform but infact straight moves cost 1 and diagonal moves cost approx.

√

2.

4

Algorithm 1 Graph reduction based on empty rectangles
Require: A grid map

1. Decompose the grid map into a series of disjoint rectangles that are free of any
obstacles. As per [6], the size and placement of the rectangles can vary across
a map, depending on the positions of obstacles.

2. Prune all tiles from the interior of each rectangle R and possibly some from

the perimeter (border).

3. Add to each rectangle R macro edges between selected pairs of tiles from
the perimeter. The cost of each edge is equal to the Octile (or Manhattan, on
4-connected grids) distance between endpoints.

4. During search, temporarily re-insert tiles back into the map to handle cases

where the start or goal is a location which has been previously pruned.

reasonable limits is a primary motivation for the enhancements reported in the next
sections.

4 Optimal Room Traversal with Macro-Edges

After interior nodes are eliminated, macro-edges between selected pairs of perime-
ter nodes have to be added to ensure that rectangles can be traversed optimally. A
straightforward approach would be adding a macro-edge between any two nodes on
the perimeter of a rectangle. We will call the subgraph resulting from such an opera-
tion a perimeter clique.

Although the perimeter clique approach guarantees optimality, it has the disadvan-
tage of creating up a large branching factor and slowing down search (the number of
necessary macro edges is quadratic in the number of perimeter nodes). We introduce
an alternative strategy, that creates much fewer macro-edges, by deﬁning a dominance
relation between macro-edges.

Deﬁnition 2. A macro-edge connecting two arbitrary nodes t1 and t2 in a perimeter
clique is non-dominated if all other paths between t1 and t2 in the perimeter clique
have a cost strictly larger than the macro-edge at hand.

By starting with a perimeter clique and applying Deﬁnition 2 it is easy to see that the
set of non-dominated macro-edges are precisely the ones that we identify below. There
are three cases to discuss: connections between nodes on the same rectangle side,
connections between orthogonal rectangle sides, and connections between opposite
rectangle sides. In the discussion that follows note that the length of each added macro-
edge is equal to the heuristic distance between its two endpoints – as measured using
Octile distance.

The ﬁrst case is simple: adjacent nodes on the same perimeter side are connected
just as in the original grid. In the second case, two nodes on orthogonal sides of the

5

Figure 1: (Left) Macro edges between nodes on orthogonal sides of an empty rectangle.
(Right) Each node on the perimeter is connected to a set of nodes on the opposite side.

perimeter of a rectangle R are connected iff the shortest path between them is a diag-
onal (45-degree) line; this is illustrated in Figure 1 (left). Notice that in both cases we
introduce no more than two macro edges per node. In the third case, we generate for
each perimeter node a “fan” of neighbours from the opposite side R. Figure 1 (right),
illustrates this idea. Starting from a node such as t1 we step to the closest neighbour
from the opposite side of R and extend the fan by progressing away from the middle in
both directions adding each node we encounter. The last node on either side of the fan
is placed diagonally, at 45 degrees, from t1 (such as t2) or located in the corner of the
perimeter (whichever we encounter ﬁrst). There is no need to add further nodes, such
as t3, as these can be reached optimally from t1 via the path {t1, t2, . . . , t3}.

In the rest of this paper, by macro-edge we will mean a non-dominated macro-
edge. We show next that the non-dominated macro-edges computed using our strategy
are both necessary and sufﬁcient to ensure optimal traversal between any two perimeter
nodes.

Proposition 1. All non-dominated macro-edges are necessary to ensure optimal paths
in a perimeter clique.

Proof. By deﬁnition, a non-dominated macro-edge e is the only way to travel optimally
between its end nodes in a perimeter clique. Therefore, dropping e would result in
losing path optimality in the perimeter clique.

Lemma 1. Let R be an empty rectangle in an 8-connected grid map. Let m and n be
two perimeter locations. Then, m and n can be connected optimally through a path
that contains only non-dominated macro-edges.

Proof. Sketch: We split the proof over the 3 cases discussed earlier: 1) m and n are on
the same side of the perimeter; 2) m and n are on orthogonal sides of the perimeter;
and 3) m and n are on opposite sides of the perimeter.

In the ﬁrst case we can simply walk along the perimeter from m to n; the optimality
of this path is immediate. In the second and third case we argue as follows: the two
nodes can be connected through an optimal path that has one diagonal macro-edge (at
one end of the path) and zero or more straight macro-edges. See again the example of
travelling from t1 to t3 in Figure 1 (Right).

Node Insertion: Sometimes a node from the interior of an empty rectangle is required
as a start or goal location for an agent. To handle such situations we give an online

6

procedure that temporarily re-inserts nodes back into the map for the duration of a
search. It proceeds as follows: If the start and goal are interior nodes in the same room
no insertion is necessary; an optimal path is trivially available. On the other hand, if
the start and goal are not in the same rectangle, add four “fans” (collections) of macro
edges. Each fan connects the start (goal) node to a set of nodes on one side of the
rectangle’s perimeter. Fans are built as shown earlier.

Given the simple geometry of rectangles, it is possible to identify in constant time
the set of nodes which the start or goal must be connected to. Further, these neighbours
could be generated on the ﬂy.

Lemma 2. Let R be an empty rectangle in an 8-connected grid map. For any nodes
m, n, with m a re-inserted interior node and n a node on the perimeter, it is always
possible to ﬁnd an optimal length path which mentions no interior nodes except for m.

Proof. Our re-insertion procedure connects the start or goal to a set of nodes on each
side of R. The procedure in each case is the same as the one given when connecting
two nodes on opposite sides of R. To prove optimality we can simply run the argu-
ment given for Step 3 of Lemma 1 for each node on the perimeter of R, in each case
substituting m for the newly inserted node.

We claim that eliminating symmetries as outlined earlier preserves the complete-

ness and the solution optimality:

Theorem 1. For every optimal path π on an original grid, there exists an optimal path
π(cid:48) on the modiﬁed graph with the property that π and π(cid:48) have the same cost.

Proof. Consider an optimal path π on the original map and a rectangle R that is crossed
by π. Let m and n be the two perimeter points along π. According to Lemma 1, there
is a way to connect m and n optimally in the modiﬁed graph. Thus, we can replace the
original segment [m . . . n] in π with the cost-wise equivalent segment that corresponds
to the modiﬁed graph. The case when m (or n) is the start or goal node is addressed
similarly using Lemma 2. By performing such a path segment replacement for all
rectangles intersected by π, we obtain a path π(cid:48) that satisﬁes the desired properties.

5 Reducing The Branching Factor Further

Consider an empty rectangle of width w and height h where w > h. After adding
all non-dominated macro edges, each node from the perimeter will have between h to
2h − 1 neighbours from the opposite side of the rectangle, up to 2 neighbours from
the same side of the rectangle and up to 5 other neighbours from adjacent rectangles.
Such a high branching factor is undesirable as individual node expansion operations
take longer.

In this section we study two branching factor reduction methods. The ﬁrst is an
ofﬂine technique that prunes nodes from the perimeter of each rectangle. The second
is an online pruning strategy which we apply during individual node expansion opera-
tions. We discuss both methods in the context of 8-connected grid maps however they
are equally applicable to 4-connected maps.

7

Figure 2: (Left) From each empty rectangle we prune all (dark grey) nodes which have
no neighbours in any adjacent rectangle. Remaining nodes are then connected directly.
(Right) Assume that t1 is the parent of t2. When t2 is expanded, there is no need to
generate its secondary neighbors. These can be reached directly from t1 on a shorter
or equal-length path.

Perimeter Reduction: We observe that in many cases there are nodes on the perimeter
of an empty rectangle which have no neighbours from any adjacent rectangle. These
nodes represent intermediate locations between entry and exit points that lead into and
out of each empty rectangle. To speed up search we propose pruning from the perimeter
of each rectangle all such nodes. To preserve optimality, we will connect the neigh-
bours of each pruned node directly to each other. The weight of each new edge is set
appropriately to the octile distance between the two neighbours. Figure 2 (Left) shows
an example. As we will see this optimisation can have a dramatic effect on the average
performance of A* on certain types of maps.

Lemma 3. Perimeter reduction preserves path optimality.

Proof. Sketch: Each time we prune a node from the perimeter we add a new edge
between all its neighbours with weight equal to the distance between each pair of
neighbours. Thus, if a path exists between a pair of nodes before the application of
perimeter reduction it is guaranteed to exist afterward. Further, the length of this path
is unchanged.

Online Node Pruning: Given a perimeter node n, let us partition its macro neigh-
bors (connected to n by macro-edges) on the perimeter into primary neighbours and
secondary neighbours. Secondary neighbours are those which are located on the op-
posite side of the perimeter to as compared to n (excluding any corner nodes). Primary
neighbours are all the rest.

When expanding an arbitrary node from the perimeter of a rectangle we observe
that it is not necessary to consider any secondary neighbours if both the node and its
predecessor belong to the same rectangle. Figure 2 (Right) shows an example of such a
situation; any path to a secondary neighbour is strictly dominated by an alternative path
through the predecessor. We apply this observation as follows: During node expansion,
determine which rectangle the parent of the current node belongs to. If the current node
has no parent or the parent belongs to a different rectangle, then process (i.e., generate)
all primary and secondary neighbours. Otherwise, process only primary neighbours.

Lemma 4. Online node pruning preserves path optimality.

8

Proof. Sketch: Let m be a node on the perimeter of a rectangle. Assume that its parent
p belongs to the same rectangle. Let n be a secondary successor of m. Recall that n
and m are on opposite sides of the rectangle. We argue below that passing through m
cannot possibly improve the best path between p and n. Therefore, there is no need to
consider (m, n) macro-edges when m and p belong to the same rectangle.

There are 4 cases when a node m and its parent p belong to the same rectangle. In
case 1, p is a re-inserted node from the interior of the rectangle. Obviously, the path
segment p, m, n is suboptimal, as we zigzag from p to m on one side of the rectangle
and then to n on the opposite side of the rectangle. In cases 2, 3, and 4, p and m are
on opposite sides, on orthogonal sides or on the same side of the rectangle. As in case
1, it is possible to check in each case that taking a detour through m does not improve
the shortest path from p to n.

6 Memory Requirements and Dynamic Environments

Memory Requirements:
In the most straightforward implementation, RSR requires
storing the id of the parent rectangle for each node in the original grid. This equates to
an O(|V |) memory overhead, where V is the set of nodes in the underlying graph. Due
to the simple geometric nature of empty rectangles, the set of macro edges associated
with each perimeter node can be computed on-the-ﬂy in constant time.
Dynamic Environments:
In many application areas, most notably video games, the
assumption of a static environment is sometimes unreasonable. For example: obstacles
may appear on the grid or existing obstacles may be destroyed as the game progresses.
In such cases the underlying graph representing the world must be updated. If a new
obstacle appears, or an existing one is destroyed, we can simply invalidate the affected
rectangles and recompute new ones. The repair operation must be very fast as most
such applications run in real time. As we will show, RSR appears particularly well
suited for this task.

7 Experimental Setup

We evaluate the performance of RSR on three benchmarks taken from the freely avail-
able pathﬁnding library Hierarchical Open Graph (HOG)2: Adaptive Depth is a set
of 12 maps of size 100×100 in which approximately 1
3 of each map is divided into
rectangular rooms of varying size and a large open area interspersed with large ran-
domly placed obstacles. Baldur’s Gate is a set of 120 maps taken from BioWare’s
popular roleplaying game Baldur’s Gate II: Shadows of Amn. Often appearing as a
standard benchmark in the literature [1, 6, 8] these maps range in size from 50×50 to
320×320 and have a distinctive 45-degree orientation. Rooms is a set of 300 maps of
size 256×256 which are divided into symmetric rows of small rectangular areas (7×7),
connected by randomly placed entrances. This benchmark has previously appeared in
[10, 8, 5]. As discussed later, we also use a variant of each benchmark where every

2http://www.googlecode.com/p/hog2

9

Benchmark
Adaptive Depth
Baldur’s Gate
Rooms

Avg. Nodes Avg. Edges

Preproc RSR Preproc Swamps

8765
4507
51437

32773
16557
166417

0.10
0.65
0.39

5.06
3.15
16.9

Table 1: Input map size and average pre-processing times (seconds).

map is scaled up by a factor of 3. In effect, our input data contains 864 maps in total,
with sizes up to 960 × 960.

Since our work is applicable to both 4 and 8 connected grid maps we used two
copies each map: one in which diagonal transitions are allowed and another in which
they are not. For each map we generated 100 valid problem instances, checking that
every instance could be solved both with and without the use of diagonal transitions.
Our test machine had a 2.93GHz Intel Core 2 Duo processor, 4GB RAM and ran OSX
10.6.2. Our implementation of A* is based on one provided in HOG, which we adapted
to facilitate our online node pruning enhancement.

8 Results

To evaluate RSR we use a generic implementation of A* and discuss performance in
terms of search time speedup. That is, the relative improvement to the average time A*
needs to solve an instance when running on a pruned vs. unpruned grid. For example,
a speedup of 2.0 is twice as fast (higher is better). Note that on approximately 2% of
all instances the start and goal are located in the same rectangle and RSR computes the
optimal solution without search. We exclude these instances from our results on the
basis that they are outliers, even though RSR solves them in constant time.

Pre-processing Times: Table 1 presents a summary of average pre-processing
times for each of our three (non-scaled) benchmarks. We also give the average number
of nodes and edges as an indication of map size. We notice that RSR takes very little
time to pre-process all input maps. We did not encounter any that took longer than a
second, and most required signiﬁcantly less than that. An interesting implication from
this result is that RSR appears well suited to pathﬁnding in dynamic environments as
outlined in Section 6.

Comparison to 4ERR: We now compare the performance RSR against the
4ERR [6] graph pruning algorithm. As 4ERR works only on 4-connected grids, here
we restrict our attention to this type of maps. To assess the individual impact of both
perimeter reduction (PR) and online node pruning (OP) we also develop and compare
two variant algorithms: 4ERR+PR and 4ERR+OP.

Figure 3 (A to C) presents our main result. Note that RSR shows a convincing speed
improvement over 4ERR and all its variants across all input maps. This allows us to
conclude that that RSR is the better choice on 4-connected maps. When analysing the
impact of each enhancement, we note that 4ERR+PR yields the biggest improvement
on all three benchmarks, speeding up A* by up to 20 times. 4ERR+OP compares well

10

Figure 3: Average A* speedup on each of our three benchmarks. Results are given in
terms of relative improvement to A* search time (i.e. speedup).

with 4ERR+PR on both Adaptive Depth and Baldur’s Gate but is of little beneﬁt on
Rooms where perimeter pruning has already reduced the branching factor.

The large performance variation from one benchmark to another can be attributed
to how effectively we can decompose the map. A good decomposition forms large
rectangles with few perimeter nodes after pruning. This is the case for Rooms. A poor
decomposition builds small rectangles with many transitionary perimeter nodes that
cannot be pruned. This is the case for Baldur’s Gate.

Comparison to Swamps: Next, we compare and contrast the performance of RSR
with the Swamps algorithm [8]. To evaluate Swamps we used the authors’ source code,
including their own implementation of A*. We then ran all experiments using their
recommended running parameters: a swamp seed radius of 6 and “no change limit”
of 2. Figure 3 (D to F) gives search time speedup results for both RSR and Swamps
running on the 8-connected variants of our three benchmark problem sets. On Adaptive
Depth and Rooms, where the terrain can be naturally decomposed into rectangles, RSR
achieves higher speedups and is shown consistently better than Swamps. On Baldur’s
Gate, where this is not the case, Swamps-based pruning is more effective.

Next, we scaled every map in each benchmark by a factor of 3 and randomly gen-
erated a new set of 100 problem instances per map. Scaling has the effect of producing
larger open areas and allows us to measure the impact of this variable on search time

50100150246810A. Search Time Speedup: Adaptive Depth (4C)Path LengthAvg. Speedup Factor4ERR4ERR+OP4ERR+PRRSR010020030040050012345B. Search Time Speedup: Baldur's Gate (4C)Path LengthAvg. Speedup Factor4ERR4ERR+OP4ERR+PRRSR0200400600800510152025C. Search Time Speedup: Rooms (4C)Path LengthAvg. Speedup Factor4ERR4ERR+OP4ERR+PRRSR50100150246810D. Search Time Speedup: Adaptive Depth (8C)Path LengthAvg. Speedup FactorRSRSwamps0100200300400246810E. Search Time Speedup: Baldur's Gate (8C)Path LengthAvg. Speedup FactorRSRSwamps0100200300400500246810F. Search Time Speedup: Rooms (8C)Path LengthAvg. Speedup FactorRSRSwamps1002003004005101520G. Search Time Speedup: Adaptive Depth Scaled (8C)Path LengthAvg. Speedup FactorRSRSwamps020040060080010001200246810H. Search Time Speedup: Baldur's Gate Scaled (8C)Path LengthAvg. Speedup FactorRSRSwamps0500100015002000010203040I. Search Time Speedup: Rooms Scaled (8C)Path LengthAvg. Speedup FactorRSRSwamps11

Algorithm Extra Memory Baldur’s Gate Rooms

PH-e
PH-e
RSR

2|V |
8|V |
|V |

3.16
3.07
2.8

11.9
17.54
18.2

Table 2: Avg. A* search time speedup: RSR vs PH-e. RSR ﬁgures are across all maps
on each benchmark. PH-e ﬁgures are for a small subset selected by its authors (1 of
120 from Baldur’s Gate and 5 of 300 from Rooms).

speedup. We present our ﬁndings in Figure 3 (G to I). We observe that while the
maximum speedup achieved by both algorithms has increased, the gain for Swamps is
very small while RSR shows dramatic improvement. Infact, if we limit our attention
to problems of similar length to those seen on the original maps we notice that the
performance of Swamps actually decreases.

The observed performance characteristics are not unexpected: Swamps prune out
areas that can be avoided without introducing a detour while rectangle-based symme-
try reduction allows for a faster exploration of areas that need to be searched. Since it
appears that the two algorithms are orthogonal, a natural extension of this work would
be to combine the two: ﬁrst, apply 4(or 8)ERR+PR (as appropriate) to a grid in order
to eliminate as many interior nodes as possible; then, apply a Swamps-based decom-
position to the resultant graph.

Comparison to Portal Heuristic: We now compare RSR with PH-e – the en-
hanced variant of the recent Portal Heuristic algorithm [5]. Although we did not have
access to a working implementation of this method we will discuss its performance
vs. RSR based on published results obtained by the original authors. As in [5] we
focus on the 4-connected variants of the Baldur’s Gate and Rooms benchmarks. Table
2 summarises the main result.

PH-e performs well when it can decompose the map into areas of similar size with
few transitionary nodes connecting them. RSR performs well when it can decompose
the map into large rectangles with few perimeter nodes. On Rooms, both decompo-
sition approaches are highly effective. On Baldur’s Gate both are comparatively less
effective. Notice however that PH-e requires up to 7 times more memory than RSR
to achieve similar results. As with Swamps, we believe PH-e is entirely orthogonal to
RSR and the two can be easily combined. For example, PH-e could be used to more
accurately guide search on a map pruned by RSR. Alternatively, symmetry elimina-
tion could be used to speed up pathﬁnding between successive pairs of portals during
PH-e’s reﬁnement phase.

9 Conclusion

We introduce RSR, a new search space reduction algorithm applicable to pathﬁnding
on uniform cost grid maps. RSR is fast, memory efﬁcient, optimality preserving and
can, in some cases, eliminate entirely the need to search. When running on a grid
pruned by RSR, A* is up to 38 times faster than otherwise.

12

We compare RSR with a range of search space reduction algorithms from the litera-
ture. Compared to 4ERR [6], on which it is based, RSR is shown signiﬁcantly faster on
the set of instances where both methods can be applied (i.e. 4-connected maps). Next,
we compare RSR to Swamps-based pruning [8] and show that the two algorithms have
complementary strengths. We ﬁnd that Swamps are more useful on maps with small
open areas while RSR becomes more effective as larger open areas are available on
a map. We also identify a broad range of instances where RSR dominates convinc-
ingly and is clearly the better choice. Finally, we compare RSR to the enhanced Portal
Heuristic [5]. We show that our method exhibits similar or improved performance but
requires up to 7 times less memory. As with Swamps, we ﬁnd that the two ideas are
complementary and could be easily combined.

Future work includes reducing the branching factor in RSR further through the
development of better map decompositions and stronger online node pruning strategies.
Another interesting topic is combining RSR with Swamps or the Portal Heuristic.

10 Acknowledgements

We would like to thank Alban Grastien and Patrik Haslum for providing feedback on
early drafts of this work. We also thank Ariel Felner and Meir Goldenberg for providing
us with assistance in comparing RSR with their enhanced Portal Heuristic algorithm.

NICTA is funded by the Australian Government as represented by the Department
of Broadband, Communications and the Digital Economy and the Australian Research
Council through the ICT Centre of Excellence program.

References

[1] Bj¨ornsson, Y., Halld´orsson, K.: Improved heuristics for optimal path-ﬁnding on

game maps. In: AIIDE. pp. 9–14 (2006)

[2] Botea, A., M¨uller, M., Schaeffer, J.: Near optimal hierarchical path-ﬁnding. J.

Game Dev. 1(1), 7–28 (2004)

[3] Davis, I.L.: Warp speed: Path planning for Star Trek Armada. In: AAAI Spring

Symposium (AIIDE). pp. 18–21 (2000)

[4] Geisberger, R., Sanders, P., Schultes, D., Delling, D.: Contraction hierarchies:
Faster and simpler hierarchical routing in road networks. In: WEA. pp. 319–333
(2008)

[5] Goldenberg, M., Felner, A., Sturtevant, N., Schaeffer, J.: Portal-based true-

distance heuristics for path ﬁnding. In: SoCS (2010)

[6] Harabor, D., Botea, A.: Breaking path symmetries in 4-connected grid maps. In:

AIIDE. pp. 33–38 (2010)

[7] Lee, J.Y., Yu, W.: A coarse-to-ﬁne approach for fast path ﬁnding for mobile

robots. In: IROS. pp. 5414 –5419 (2009)

13

[8] Pochter, N., Zohar, A., Rosenschein, J.S., Felner, A.: Search space reduction

using swamp hierarchies. In: AAAI (2010)

[9] Rossi, F., Beek, P.v., Walsh, T.: Handbook of Constraint Programming. Elsevier

Science Inc., New York, NY, USA (2006)

[10] Sturtevant, N.R., Felner, A., Barrer, M., Schaeffer, J., Burch, N.: Memory-based

heuristics for explicit state spaces. In: IJCAI. pp. 609–614 (2009)

[11] Sturtevant, N.R., Geisberger, R.: A comparison of high-level approaches for

speeding pathﬁnding. In: AIIDE. pp. 76–82 (2010)

[12] Wang, K.H.C., Botea, A.: Tractable multi-agent path planning on grid maps. In:

IJCAI. pp. 1870–1875 (2009)"
Feature Reinforcement Learning In Practice,"  Following a recent surge in using history-based methods for resolving
perceptual aliasing in reinforcement learning, we introduce an algorithm based
on the feature reinforcement learning framework called PhiMDP. To create a
practical algorithm we devise a stochastic search procedure for a class of
context trees based on parallel tempering and a specialized proposal
distribution. We provide the first empirical evaluation for PhiMDP. Our
proposed algorithm achieves superior performance to the classical U-tree
algorithm and the recent active-LZ algorithm, and is competitive with
MC-AIXI-CTW that maintains a bayesian mixture over all context trees up to a
chosen depth.We are encouraged by our ability to compete with this
sophisticated method using an algorithm that simply picks one single model, and
uses Q-learning on the corresponding MDP. Our PhiMDP algorithm is much simpler,
yet consumes less time and memory. These results show promise for our future
work on attacking more complex and larger problems.
",http://arxiv.org/pdf/1108.3614v1,1,"Feature Reinforcement Learning in Practice

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Research School of Computer Science, CECS, ANU
nmphuong@cecs.anu.edu.au
peter.sunehag,marcus.hutter@{anu.edu.au}

Abstract. Following a recent surge in using history-based methods for resolving
perceptual aliasing in reinforcement learning, we introduce an algorithm based
on the feature reinforcement learning framework called ΦMDP [14]. To create a
practical algorithm we devise a stochastic search procedure for a class of context
trees based on parallel tempering and a specialized proposal distribution. We pro-
vide the ﬁrst empirical evaluation for ΦMDP. Our proposed algorithm achieves
superior performance to the classical U-tree algorithm [21] and the recent active-
LZ algorithm [6], and is competitive with MC-AIXI-CTW [28] that maintains
a bayesian mixture over all context trees up to a chosen depth. We are encour-
aged by our ability to compete with this sophisticated method using an algorithm
that simply picks one single model, and uses Q-learning on the corresponding
MDP. Our ΦMDP algorithm is much simpler, yet consumes less time and mem-
ory. These results show promise for our future work on attacking more complex
and larger problems.

1 Introduction

Reinforcement Learning (RL) [27] aims to learn how to succeed in a task through trial
and error. This active research area is well developed for environments that are Markov
Decision Processes (MDPs); however, real world environments are often partially ob-
servable and non-Markovian. The recently introduced Feature Markov Decision Process
(ΦMDP) framework [14] attempts to reduce actual RL tasks to MDPs for the purpose
of attacking the general RL problem where the environment’s model as well as the set
of states are unknown. In [26], Sunehag and Hutter take a step further in the theoretical
investigation of Feature Reinforcement Learning by proving consistency results. In this
article, we develop an actual Feature Reinforcement Learning algorithm and empiri-
cally analyze its performance in a number of environments.

One of the most useful classes of maps (Φs) that can be used to summarize histories
as states of an MDP, is the class of context trees. Our stochastic search procedure, the
principal component of our ΦMDP algorithm GSΦA, works on a subset of all context
trees, called Markov trees. Markov trees have previously been studied in [22] but under
names like FSMX sources or FSM closed tree sources. The stochastic search procedure
employed for our empirical investigation utilizes a parallel tempering methodology [7],
[12] together with a specialized proposal distribution. In the experimental section, the
performance of the ΦMDP algorithm where stochastic search is conducted over the
space of context-tree maps is shown and compared with three other related context
tree-based methods.

1
1
0
2

g
u
A
8
1

]
I

A
.
s
c
[

1
v
4
1
6
3
.
8
0
1
1
:
v
i
X
r
a

 
 
 
 
 
 
2

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Our ΦMDP algorithm is brieﬂy summarized as follows. First, perform a certain
number of random actions, then use this history to ﬁnd a high-quality map by minimiz-
ing a cost function that evaluates the quality of each map. The quality here refers to
the ability to predict rewards using the created states. We perform a search procedure
for uncovering high-quality maps followed by executing Q-learning on the MDP whose
states are induced by the detected optimal map. The current history is then updated with
the additional experiences obtained from the interactions with the environment through
Q-Learning. After that, we may repeat the procedure but without the random actions.
The repetition reﬁnes the current “optimal” map, as longer histories provide more use-
ful information for map evaluation. The ultimate optimal policy of the algorithm is
retrieved from the action values Q on the resulting MDP induced from the ﬁnal optimal
map.

Contributions. Our contributions are: extending the original ΦMDP cost function pre-
sented in [14] to allow for more discriminative learning and more efﬁcient minimiza-
tion (through stochastic search) of the cost; identifying the Markov action-observation
context trees as an important class of feature maps for ΦMDP; proposing the GSΦA
algorithm where several chosen learning and search procedures are logically combined;
providing the ﬁrst empirical analysis of the ΦMDP model; and designing a specialized
proposal distribution for stochastic search over the space of Markov trees, which is of
critical importance for ﬁnding the best possible ΦMDP agent.

Related Work. Our algorithm is a history-based method. This means that we are utiliz-
ing memory that in principle can be long, but in most of this article and in the related
works is near term. Given a history ht of observations, actions and rewards we deﬁne
states st = Φ(ht) based on some map Φ. The main class of maps that we will consider
are based on context trees. The classical algorithm of this sort is U-tree [21], which
uses a local criterion based on a statistical test for splitting nodes in a context tree;
while ΦMDP employs a global cost function. Because of this advantage, ΦMDP can
potentially be used in conjunction with any optimization methods to ﬁnd the optimal
model.

There has been a recent surge of interest in history based methods with the intro-
duction of the active-LZ algorithm [6], which generalizes the widely used Lempel-Ziv
compression scheme to the reinforcement learning setting and assumes n-Markov mod-
els of environments; and MC-AIXI-CTW [28], which uses a Bayesian mixture of con-
text trees and incorporates both the Context Tree Weighting algorithm [31] as well as
UCT Monte Carlo planning [16]. These can all be viewed as attempts at resolving per-
ceptual aliasing problems with the help of short-term memory. This has turned out to be
a more tractable approach than Baum-Welch methods for learning a Partially Observ-
able Markov Decision Process (POMDP) [4] or Predictive State Representations [24].
The history based methods attempt to directly learn the environment states, thereby
avoiding the POMDP-learning problem [15], [20] which is extremely hard to solve.
Model minimization [8] is a line of works that also seek for a minimal representation
of the state space, but focus on solving Markovian problems while ΦMDP and other
aforementioned history-based methods target non-Markovian ones. It is also worthy to
note that there are various other attempts to ﬁnd compact representations of MDP state

Feature Reinforcement Learning in Practice

3

spaces [18]; most of which, unlike our approach, address the planning problem where
the MDP model is given

Paper Organization. The paper is organized as follows. Section 2 introduces pre-
liminaries on Reinforcement Learning, Markov Decision Processes, Stochastic Search
methods and Context Trees. These are the components from which the ΦMDP algo-
rithm (GSΦA) is built. In Section 3 we put all of the components into our ΦMDP algo-
rithm and also describe our specialized search proposal distribution in detail. Section 4
presents experimental results on four domains. Finally Section 5 summarizes the main
results of this paper, and brieﬂy suggests possible research directions.

2 Preliminaries

2.1 Markov Decision Processes (MDP)

An environment is a process which at any discrete time t, given action at ∈ A produces
an observation ot ∈O and a corresponding reward rt ∈R. When the process is a Markov
Decision Process [27]; ot represents the environment state, and hence is denoted by
st instead. Formally, a ﬁnite MDP is denoted by a quadruple hS,A,T ,Ri in which S
is a ﬁnite set of states; A is a ﬁnite set of actions; T = (T a
ss′ : s,s′ ∈ S, a ∈ A) is a
collection of transition probabilities of the next state st+1 = s′ given the current state
st = s and action at = a; and R = (Ra
ss′ =
E[rt+1|st = s,at = a,st+1 = s′]. The return at time step t is the total discounted reward
Rt = rt+1 +γrt+2+γ2rt+3 +..., where γ is the geometric discount factor (0 ≤ γ < 1).

ss′ : s,s′ ∈ S, a ∈ A) is a reward function Ra

Similarly, the action value in state s following policy π is deﬁned as Qπ(s,a) =
∞
k=0γkrt+k+1|st = s,at = a]. For a known MDP, a useful
Eπ[Rt|st = s,at = a] = Eπ[
way to ﬁnd an estimate of the optimal action values Q∗ is to employ the Action-Value
Iteration (AVI) algorithm, which is based on the optimal action-value Bellman equation
s′ T a
[27], and iterates the update Q(s,a) ←
If the MDP model is unknown, an effective estimation technique is provided by

ss′ +γmaxa′Q(s′,a′)].

ss′ [Ra

P

Q-learning, which incrementally updates estimates Qt through the equation

P

Q(st,at) ← Q(st,at)+αt(st,at)errt

where the feedback error errt = rt+1 +γmaxaQ(st+1,a)−Q(st,at), and αt(st,at) is
the learning rate at time t. Under the assumption of sufﬁcient visits of all state-action
pairs, Q-Learning converges if and only if some conditions of the learning rates are
met [2], [27]. In practice a small constant value of the learning rates (α(st,at) = η)
is, however, often adequate to get a good estimate of Q∗. Q-Learning is off-policy; it
directly approximates Q∗ regardless of what actions are actually taken. This approach
is particularly beneﬁcial when handling the exploration-exploitation tradeoff in RL.

It is well known that learning by taking greedy actions retrieved from the current
Q of Q∗ to explore the state-action space generally leads to suboptimal behav-
estimate
ior. The simplest remedy for this inefﬁciency is to employ the ǫ-greedy scheme, where
with probability ǫ > 0 we take a random action, and with probability 1−ǫ the greedy
action is selected. This method is simple, but has shown to fail to properly resolve the

b

4

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

exploration-exploitation tradeoff. A more systematic strategy for exploring the unseen
scenarios, instead of just taking random actions, is to use optimistic initial values [27],
[3]. To apply this idea to Q-Learning, we simply initialize Q(s,a) with large values.
Suppose Rmax is the maximal reward, Q initializations of at least Rmax
1−γ are optimistic
as Q(s,a) ≤ Rmax
1−γ .

2.2 Feature Reinforcement Learning

Problem description. An RL agent aims to ﬁnd the optimal policy π for taking action
at given the history of past observations, rewards and actions ht =o1r1a1...ot−1rt−1at−1otrt
in order to maximize the long-term reward signal. If the problem satisﬁes an MDP; as
can be seen above, efﬁcient solutions are available. We aim to attack the most challeng-
ing RL problem where the environment’s states and model are both unknown. In [13],
this problem is named the Universal Artiﬁcial Intelligence (AI) problem since almost
all AI problems can be reduced to it.
ΦMDP framework. In [14], Hutter proposes a history-based method, a general statis-
tical and information theoretic framework called ΦMDP. This approach offers a critical
preliminary reduction step to facilitate the agent’s ultimate search for the optimal pol-
icy. The general ΦMDP framework endeavors to extract relevant features for reward
prediction from the past history ht by using a feature map Φ: H → S, where H is the
set of all ﬁnite histories. More speciﬁcally, we want the states st = Φ(ht) and the re-
sulting tuple hS, A, Ri to satisfy the Markov property of an MDP. As aforementioned,
one of the most useful classes of Φs is the class of context trees, where each tree maps
a history to a single state represented by the tree itself. A more general class of Φ is
Probabilistic-Deterministic Finite Automata (PDFA) [29], which map histories to the
MDP states where the next state can be determined from the current state and the next
observation. The primary purpose of ΦMDP is to ﬁnd a map Φ so that rewards of the
MDP induced from the map can be predicted well. This enables us to use MDP solvers,
like AVI and Q-learning, on the induced MDP to ﬁnd a good policy. The reduction qual-
ity of each Φ is dictated by the capability of predicting rewards of the resulting MDP
induced from that Φ. A suitable cost function that measures the utility of Φs for this
purpose is essential, and the optimal Φ is the one that minimizes this cost function.

Cost function. The cost used in this paper is an extended version of the original cost
introduced in [14]. We deﬁne a cost that measures the reward predictability of each Φ,
or more speciﬁcally of the resulting MDP induced from that Φ. Based on this, our cost
includes the description length of rewards; however, rewards depend on states as well,
so the description length of states must be also added to the cost. In other words, the
cost comprises coding of the rewards and resulting states, and is deﬁned as follows:

Costα(Φ|hn) := αCL(s1:n|a1:n)+(1−α)CL(r1:n|s1:n,a1:n)

where s1:n = s1,...,sn and a1:n = a1,...,an and st = Φ(ht) and ht = ora1:t−1rt and
0 ≤ α ≤ 1. For coding we use the two-part code [30], [10], hence the code length (CL)
is CL(x) = CL(x|θ)+CL(θ) where x denotes the data sampled from the model speci-
ﬁed by parameters θ. We employ the optimal codes [5] for describing data CL(x|θ) =

Feature Reinforcement Learning in Practice

5

log(1/P rθ(x)), while parameters are uniformly encoded to precision 1/
ℓ(x) where
ℓ(x) is the sequence length of x [10]: CL(θ) = m−1
2 logℓ(x), here m is the num-
ber of parameters. The optimal Φ is found via the optimization problem Φoptimal =
argminΦCostα(Φ|hn).

p

Denote n• := [n1 n2... nl] (l is determined in speciﬁc context); n+ :=

are components of vector n•); |•| cardinality of a set; nar
(s,a,s′,r′), 1 ≤ t ≤ n}|; and H(p) = −
able with distribution p = [p1 p2. . . pl] where
functions can, then, be analytically computed as follows:

P

′

jnj (njs
ss′ := |{t : (st,at,st+1,rt+1) =
l
i=1pilogpi Shannon entropy of a random vari-
l
i=1pi = 1. The state and reward cost

P

P

CL(s1:n|a1:n) =

CL(na+

s• ) =

na+
s+ H

s,a
X
CL(r1:n|s1:n,a1:n) =

s,a
X
ss′ ) =

CL(na•

Xs,a,s′

Xs,a,s′

na+
s•
na+

s+ !

+

|S|−1
2

logna+
s+

na+
ss′ H

na•
ss′
na+
ss′ (cid:19)

(cid:18)

+

|R|−1
2

logna+
ss′

As we primarily want to ﬁnd a Φ that has the best reward predictability, the in-
troduction of α is primarily to stress on reward coding, making costs for high-quality
Φs much lower with very small α values. In other words, α ampliﬁes the differences
among high-quality Φs and bad ones; and this accelerates our stochastic search process
described below.

We furthermore replace CL(x) with CLβ(x) = CL(x|θ)+βCL(θ) in Costα to de-
ﬁne Costα,β for the purpose of being able to select the right model given limited data.
The motivation to introduce β is the following. For stationary environments the cost
function is analytically of this form C1 ×u(α)×O(n)+C2 ×v(α)×t(β)×O(log(n))
where C1,C2 are constants, and u,v,t are linear functions. The optimal Φ should be the
one with the smallest value of C1 × u(α), however, the curse here is that in practice
C2 ×v(α) is often big, so in order to obtain the optimal Φ with limited data, a small
value of β will help. We assert that with a very large number of samples n, α and β
can be ignored in the above cost function (use α = 0.5, β = 1 as the cost in [14]). The
choice of small α and β helps us more quickly to overcome the model penalty and ﬁnd
the optimal map. This strategy is a quite common practice in statistics, and even in the
Minimum Description Length (MDL) community [10]. For instance, AIC [1] uses a
very small β = 2/logn.

The interested reader is referred to [14] for more detailed analytical formulas, and

[26] for further motivation and consistency proofs of the ΦMDP model.

2.3 Context Trees

The class of maps that we will base our algorithm on is a class of context trees.

Observation Context Tree (OCT). OCT is a class of maps Φ used to extract relevant
information from histories that include only past observations, not actions and rewards.
The presentation of OCT is mainly to facilitate the deﬁnitions of the below Action-
Observation Context Tree.

 
6

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Deﬁnition. Given an |Ø|-ary alphabet Ø = {o1,o2,...,o|Ø|}, an OCT constructed from
the alphabet O is deﬁned as a |Ø|-ary tree in which edges coming from any internal
node are labeled by letters in O from left to right in the order given.

Given an OCT T constructed from the alphabet Ø, the state sufﬁx set, or brieﬂy
state set S = {s1,s2,...,sm} ⊆ Ø∗ induced from T is deﬁned as the set of all possible
strings of edge labels forming along a path from a leaf node to the root node of T . T
is called a Markov tree if it has the so-called Markov property for its associated state
set, that is, for every si ∈ S and ok ∈ Ø, siok has a unique sufﬁx sj ∈ S. The state set of
a Markov OCT is called Markov state set. OCTs that do not have the Markov property
are identiﬁed as non-Markov OCTs. Non-Markov state sets are similarly deﬁned.

Example. Figure 1(a)(A) and 1(a)(B) respectively represent two binary OCTs of depths
two and three; also Figures 1(b)(A) and 1(b)(B) illustrate two ternary OCTs of depths
two and three.

(a) Binary context trees

(b) Trinary context trees

Fig. 1. Context Trees

As can be seen from Figure 1, trees 1(a)(A) and 1(b)(A) are Markov; on the other
hand, trees 1(a)(B) and 1(b)(B) are non-Markov. The state set of tree 1(a)(A) is S(a)(A) =
{00,01,01,11}; and furthermore with any further observation o ∈ O and s ∈ S(a)(A),
there exists a unique s′ ∈S which is a sufﬁx of so. Hence, tree 1(a)(A) is Markov. Table
1(a) represents the deterministic relation between s, o and s′.

(a) Markov property of S (a)(A)
s 00 01 10 11 00 01 10 11
o
s′ 00 10 00 10 01 11 01 11

0

1

(b) Non-markov property of S (a)(B)
s 0 001 101 11
001 101 11
o
1
s′ 0 0

0 101 or 001 11 11 11

0

0

0

Table 1. Markov and Non-Markov properties

However, there is no such relation in tree 1(a)(B), or state set S(a)(B) ={0,001,101,11};

for s=0 and o=1, it is ambiguous whether s′ =101 or 001. Table 1(b) clariﬁes the non-
Markov property of tree 1(a)(B).

Similar arguments can be applied for trees 1(b)(A) and 1(b)(B) to identify their

Markov property.

Feature Reinforcement Learning in Practice

7

It is also worthy to illustrate how an OCT can be used as a map. We illustrate
the mapping using again the OCTs in Figure 1. Given two histories including only
6 = 211210, then Φ(a)(A)(h5) = 01,Φ(a)(B)(h5) =
past observations h5 = 11101 and h′
6) = 10, and Φ(b)(B)(h′
101,Φ(b)(A)(h′
6) = 210.

Action-Observation Context Tree (AOCT). AOCTs are extended from the OCTs pre-
sented above for the generic RL problem where relevant histories contain both actions
and observations.

Deﬁnition. Given two alphabets, Ø = {o1,o2,...,o|Ø|} named observation set, and A =
{a1,a2,...,a|A|} named action set, an AOCT constructed from the two alphabets is de-
ﬁned as a tree where any internal node at even depths has branching factor |Ø|, and
edges coming from such nodes are labeled by letters in Ø from left to right in the or-
der given; and similarly any internal node at odd depths has branching factor |A|, and
edges coming from these nodes are labeled by letters in A also from left to right in the
speciﬁed order.

The deﬁnitions of Markov and non-Markov AOCTs are similar to those of OCTs
except that a next observation is now replaced by the next action and observation. For-
mally, suppose T is an AOCT constructed from the above two alphabets; and S =
{s1,s2,...,sm} ⊆ (A×Ø)∗ ∪A×(A×Ø)∗ is the state sufﬁx set of the tree, then T is
deﬁned as a Markov AOCT if it has the Markov property, that is, for every 1 ≤ i ≤ m,
1 ≤ j ≤ |A|, and 1 ≤ k ≤ |Ø| there exist a unique 1 ≤ l ≤ m such that sl is a sufﬁx
of siajok. AOCTs that do not have Markov property are categorized as non-Markov
AOCTs.

The total number of AOCTs up to a certain depth d, K(d), can be recursively com-
puted via the formula K(d+2) = {[K(d)]|A|+1}|Ø|+1 where K(0) = 1,K(1) = 2. As
can be easily seen from the recursive formula, the total number of AOCTs is doubly
exponential in the tree depth.

An important point to note here is that in our four experiments presented in Section
4, the Φ space is limited to Markov AOCTs, since as explained above, the state sufﬁx set
induced from a non-Markov AOCT does not represent an MDP state set; to put it more
clearly, in non-Markov AOCTs, from the next action and observation, we cannot derive
the next state from the current one. The Markov constraint on AOCTs signiﬁcantly
reduces the search space for our stochastic search algorithm. In the U-tree algorithm
[21], no distinction of Marov and non-Markov trees is identiﬁed; the algorithm attempts
to search for the optimal tree over the whole space of AOCTs.

2.4 Stochastic search

While we have deﬁned the cost criterion for evaluating maps, the problem of ﬁnding
the optimal map remains. When the Φ space is huge, e.g. context-tree map space where
the number of Φs grows doubly exponentially with the tree depth, exhaustive search is
unable to deal with domains where the optimal Φ is non-trivial. Stochastic search is a
powerful tool for solving optimization problems where the landscape of the objective
function is complex, and it appears impossible to analytically or numerically ﬁnd the ex-
act or even approximate global optimal solution. A typical stochastic search algorithm

8

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

starts with a predeﬁned or arbitrary conﬁguration (initial argument of the objective func-
tion or state of a system), and from this generates a sequence of conﬁgurations based on
some predeﬁned probabilistic criterion; the conﬁguration with the best objective value
will be retained. There are a wide range of stochastic search methods proposed in the
literature [23]; the most popular among these are simulated-annealing-type algorithms
[19], [25]. An essential element of a simulated-annealing (SA) algorithm is a Markov
Chain Monte Carlo (MCMC) sampling scheme where a proposed new conﬁguration
˜y is drawn from a proposal distribution q(˜y|y), and we then change from conﬁgura-
tion y to ˜y with probability min{1, πT (y)q(y|ey)
πT (ey)q(ey|y) } where πT is a target distribution. In a
simulated-annealing (SA) algorithm where the traditional Metropolis-Hasting sampling
scheme is utilized, πT is proportional to e−f (x)/T if f is an objective function that we
want to minimize, and T is some positive constant temperature. q(y|ey)
q(ey|y) is called the
correction factor; it is there to compensate for bias in q.

The traditional SA uses an MCMC scheme with some temperature-decreasing strat-
egy. Although shown to be able to ﬁnd the global optimum asymptotically [9], it gen-
erally works badly in practice as we do not know which temperature cooling scheme is
appropriate for the problem under consideration. Fortunately in the ΦMDP cost function
we know typical cost differences between two Φs (Cβ×log(n)), so the range of appro-
priate temperatures can be signiﬁcantly reduced. The search process may be improved
if we run a number of SA procedures with various different temperatures. Parallel Tem-
pering (PT) [7], [12], an interesting variant of the traditional SA, signiﬁcantly improves
this stochastic search process by smartly offering a swapping step, letting the search
procedure use small temperatures for exploitation and big ones for exploration.

Parallel tempering. PT performs stochastic search over the product space X1 ×... ×
XI (Xi =X ∀1≤i≤I), where X is the objective function’s domain, and I is the parallel
factor. Fixed temperatures Ti (i = 1,... ,I, and 1 < T1 < T2 < ... < TI ) are chosen for
spaces Xi (i = 1,... ,I). Temperatures Ti (i = 1,...,I) are selected based on the following
formula ( 1
)|∆H| ≈ −logpa where ∆H is the “typical” difference between
Ti
function values of two successive conﬁgurations; and pa is the lower bound for the
swapping acceptance rate. The main steps of each PT loop are as follows:

− 1
Ti+1

I ) is the current sampling; draw u ∼ Uniform[0,1]

1 ,... ,x(t)

– (x(t)
– If u≤α0, update every x(t)
i
scheme like Metropolis-Hasting (Parallel step)

to x(t+1)
i

via some Markov Chain Monte Carlo (MCMC)

– If u > α0, randomly choose a neighbor pair, say i and i+1, and accept the swap of

x(t)
i

and x(t)

i+1 with probability min{1,

πTi (x(t)
πTi (x(t)

i+1)πTi+1 (x(t)
i )
i )πTi+1 (x(t)
i+1)

} (Swapping step).

The full details of PT are given in Algorithm 1.

Feature Reinforcement Learning in Practice

9

Algorithm 1 Parallel Tempering (PT)
Require: An objective function h(x) to be minimized, or equivalently the target distribution

πC α e−h(x)/C for some positive constant C

Require: Swap probability parameter α0
Require: A proposal distribution q(y|x)
Require: Temperatures T1,T2,...,TL, and number of iterations N
1: Initialize arbitrary conﬁgurations x(1,1),...,x(L,1)( {x(k,i): represents the ith value of x for

temperature Tk;})

2: xopt ← argminx=x(·,1) h(x)
3: for i = 1 to N do
4:
5:
6:

for k = 1 to L do
ey ← x(k,i−1)
Sample y from the proposal distribution q(y|ey)
(y)q(y|ey)
r ← min{1,
(ey)q(ey|y) } (Metropolis Hastings)
Draw u ∼ Uniform[0,1] and update
if u ≤ r(ey,y) then
x(k,i) ← y

πTk
πTk

else

x(k,i) ← ey

end if
if h(xopt) > h(x(k,i)) then

xopt ← x(k,i)

end if
end for
Draw u ∼ Uniform[0,1]
if u ≥ α0 then

Draw a Uniform {1,...,L−1} and let b = a+1

r ← min{1,

πTa (x(b,i) )πTb
πTa (x(a,i))πTb

(x(a,i))
(x(b,i))

}

Draw v ∼ Uniform[0,1]
if v ≤ r then

Swap x(a,i) and x(b,i)

7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:
19:
20:

21:

22:
23:
24:
25:
26:
end if
27: end for
Return xopt

end if

If its swapping phase is excluded, PT is simply the combination of a ﬁxed number
of Metropolis-Hastings procedures. The central point that makes PT powerful is its
swapping step where adjacent temperatures interchange their sampling regions. This
means that a good conﬁguration can be allowed to use a cooler temperature and exploit
what it has found while a worse conﬁguration is given a higher temperature which
results in more exploration.

10

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

3 The ΦMDP Algorithm

We now describe how the generic ΦMDP algorithm works. The general algorithm is
shown below (Algorithm 2). It ﬁrst takes a number of random actions (5000 in all our
experiments). Then it deﬁnes the cost function Costα,β based on this history. Stochastic
search is then used to ﬁnd a map Φ with low cost. Based on the optimal Φ the history is
transformed into a sequence of states, actions and rewards. We use optimistic frequency
estimates from this history to estimate probability parameters for state transitions and
rewards. More precisely, we use Rmax+r1+...+rm
to
estimate expected reward, where r1,...,rm are the rewards that have been observed for
a certain state-action pair, and Rmax is the highest possible reward. The statistics are
used to estimate Q values using AVI. After this the agent starts to interact with the
environment again using Q-learning initialized with the values that resulted from the
performed AVI. The switch from AVI to Q-Learning is rather obvious, as Q-Learning
only needs one cheap update per time step, while AVI requires updating the whole
environment model and running a number of value iterations. The ﬁrst set of random
actions might not be sufﬁcient to characterize what the best maps Φ look like, so it
might be beneﬁcial to add the new history gathered by the Q-Learning interactions with
the environment to the old history, and then repeat the process but without the initial
sampling.

instead of the average r1+...+rm

m+1

m

agentLearningLoops,

Algorithm 2 Generic Stochastic ΦMDP Agent (GSΦA)
initialSampleN umber,
Require: Environment;
stochasticIterations and additionalSampleN umber
1: Generate a history hinitial of length initialSampleN umber
2: h ← hinitial
3: repeat
4:
5:
6:
7:

Run the chosen stochastic search scheme for the history h to ﬁnd a ˆΦ with low cost
Compute MDP statistics (optimistic frequency estimates ˆR and ˆT ) induced from ˆΦ
Apply AVI to ﬁnd the optimal Q∗ values using the computed statistics ˆR and ˆT .
Interact with environment for additionalSampleN umber iterations of Q-Learning us-
ing Q∗ as initial values; the obtained additional history is stored in hadditional
h ← [h,hadditional]
agentLearningLoops ← agentLearningLoops−1

8:
9:
10: until agentLearningLoops = 0
11: Compute the optimal policy πoptimal from the optimal Φ and Q values
Return [Φoptimal, πoptimal]

In the ﬁrst four experiments in Section 4, PT is employed to search over the Φ space

of Markov AOCTs.

3.1 Proposal Distribution for Stochastic Search over the Markov-AOCT Space

The principal optional component of the above high-level algorithm, GSΦA, is a stochas-
tic search procedure of which some algorithms have been presented in Section 2.4. In

Feature Reinforcement Learning in Practice

11

these algorithms, an essential technical detail is the proposal distribution q. It is natu-
ral to generate the next tree (the next proposal or conﬁguration) from the current tree
by splitting or merging nodes. It is possible to express the exact form of our proposal
distribution, and based on this to explain how the next tree (next conﬁguration) is pro-
posed from the current tree (current conﬁguration). However, the analytical form of the
distribution is cumbersome to specify, so for better exposition we opt to describe the
exact behavior of the tree proposal distribution instead.

The stochastic search procedure starts with a Markov AOCT where all of the tree
nodes are mergeable, and splittable. However, in the course of the search, a tree node
might become unmergeable, but not the other way round; and a splittable node might
turn to be unsplittable and vice versa. These speciﬁc transfering scenarios are described
as follows. A mergeable tree node of the current tree becomes unmergeable if the cur-
rent tree is proposed from the previous tree by splitting that node, and the cost of the
current tree is smaller than that of the previous tree. A splittable leaf node of the cur-
rent tree becomes unsplittable if the state associated with that node is not present in the
current history; however, an unsplittable leaf node might revert to splittable when the
state associated with that node is present in the future updated history. The constraint
on merging is to keep good short-term memory for predicting rewards, while the other
on splitting is simply following the Occam’s razor principle.

Merge and split permits. Given some current tree at a particular point in time of the
stochastic search process, when considering the generation of the next tree proposal,
most of the tree nodes, though labeled splittable and/or mergeable, might have no split,
or merge permit, or neither. A node has split permit if it is a leaf node with splittable
label. When a leaf node has been split, we simply add all possible children for this
node, and label the edges according to the deﬁnition of AOCTs. As mentioned above,
the newly added leaf nodes might be labeled unmergeable if the cost of the new tree is
smaller than that of the old one; and these nodes might also be labeled unsplittable if
the states associated with the new leaf nodes are not present in the current history. A
node has merge permit if it is labeled mergeable, and all of its children are leaf nodes.
When a tree node is merged, all the edges and nodes associated with its children are
removed.

Markov-merge and Markov-split permits. Since our search space is the class of
Markov OACTs, whenever a split or merge occurs, extra adjustments might be needed
to make the new tree Markov. After a split, there might be nodes that make the tree vi-
olate the Markov assumption, and therefore, need to be split. After we split all of those
we have to check again to see if any other nodes now need to be split. This goes on until
we have a Markov AOCT again. The same applies to merging.

When a node is Markov-split, it and all of the leaf nodes that need to be split (in-
cluding recursive splits) as a consequence in order to make the tree Markov, are split. A
tree node is said to have Markov-split permit if it, and all the other nodes that would be
split in a Markov-split of the node, have split permits. This notion is best illustrated with
an example. First we deﬁne Markov and Non-Markov states of an AOCT. A state of an
AOCT is Markov if given any next action-observation pair, the next state is determined;
otherwise it is labeled as non-Markov. Now in Figure 2(A), suppose the current Markov
AOCT is the tree without dashed edges. Then after splitting the leaf node marked by

12

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Fig. 2. AOCT proposals

* (the node associated with state 00101), the state 001 becomes non-Markov so this
associated node needs to be split. However, after splitting this node (node associated
with state 001), state 0 becomes non-Markov, hence it needs splitting as well. In short,
to split the node marked by *, the two nodes associated with states 001 and 0 have to
be split as well so as to ensure the resulting tree is Markov after splitting. Similarly, a
tree node has Markov-merge permit if it, and all of the tree nodes that minimally and
recursively need to be merged after the original node is merged in order to make the tree
Markov, have merge permits. For example, in Figure 2(B), suppose the current tree is
the tree including both solid and dashed edges, then the node marked by * has Markov-
merge permit, if it itself, and the nodes associated with paths 001, 021 and 00101 that
need to be merged, have merge permits. When a node with Markov-merge permit is
Markov-merged, it and its Markov-merge-associated nodes are merged.

Our procedure to generate the next tree from the current tree (draw sample from

q(y|·)) in the space of Markov AOCTs consists of the following main steps:

– From the given tree, identify two sets: one is NS containing nodes with Markov-
split permits, and the other NM containing nodes with Markov-merge permits.
– Suppose that either NS or NM is non-empty otherwise the algorithm (GSΦA) must
stop; then if either NS or NM is empty, select a node uniformly at random from the
other set; otherwise select NS or NM randomly with probability 1
2 each, and after
that choose a tree node randomly from the selected set.

– Markov-split the node if it belongs to NS, otherwise Markov-merge it

Once we have drawn the new tree ˜y, the Metropolis Hastings correction factor can be
straightforwardly calculated via the formula

q(y|
q(

y)
y|y)
e

=




e
|
NM |
|NS|
e
|
NS|
|NM |

if

y is proposed from y by Markov-splitting

if

y is proposed from y by Markov-merging
e

NS and

here

set of nodes with Markov-merge permits of

e

y.

NM are respectively the set of nodes with Markov-split permits, and the
e

e

e

e

Feature Reinforcement Learning in Practice

13

Sharing. If the stochastic search algorithm utilized is PT, we apply another trick to ef-
fectively accelerate the search process. Whenever a node is labeled unmergeable, that
is, by splitting this node the cost function decreases, or in other words a good addi-
tional relevant short-term memory for predicting rewards is found, the states associated
with the new nodes created by the splitting are replicated in the trees with the other
temperatures.

4 Experiments

4.1 Experimental Setup

Parameter
α
β
initialSampleN umber
agentLearningLoops
Iterations
I
Ti, i ≤ I
α0
γ
η

Component
Costα,β
Costα,β
GSΦA
GSΦA
PT
PT
PT
PT
AVI, Q-Learning
Q-Learning

Value
0.1
0.1
5000
1
100
10
Ti = β ×i×log(n)
0.7
0.999999
0.01

Table 2. Parameter setting for the GSΦA algorithm

Below in this section we present our empirical studies of the ΦMDP algorithm
GSΦA described in Section 3. For all of our experiments, stochastic search (PT) is
applied in the Φ space of Markov AOCTs.

For a variety of tested domains, our algorithm produces consistent results using the
same set of parameters. These parameters are shown in Table 4.1, and are not ﬁne tuned.
The results of ΦMDP and the three competitors in the four above-listed environ-
ments are shown in Figures 3, 4 7, 8 and ??. In each of the plots, various time points are
chosen to assess and compare the quality of the policies learned by the four approaches.
In order to evaluate how good a learned policy is, at each point, the learning process
of each agent, and the exploration of the three competitors are temporarily switched
off. The selected statistic to compare the quality of learning is the averaged reward over
5000 actions using the current policy. For stability, the statistic is averaged over 10 runs.
As shown in more detail below, ΦMDP is superior to U-tree and active-LZ, and is
comparable to MC-AIXI-CTW in short-term memory domains. Overall conclusions are
clear, and we, therefore, omit error bars.

14

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

4.2 Environments and results

We describe each environment, the resulting performance, and the tree that was found
by ΦMDP in the cheese maze domain.
4×4 Grid. The domain is a 4×4 grid world. At each time step, the agent can move one
cell left, right, up and down within the grid world. The observations are uninformative.
When the agent enters the bottom-right corner of the grid; it gets a reward of 1, and is
automatically and randomly sent back to one of the remaining 15 cells. Entering any cell
other than the bottom-right one gives the agent a zero reward. To achieve the maximal
total reward, the agent must be able to remember a series of smart actions without any
clue about its relative position in the grid.

The context tree found contains 34 states. Some series of actions that take the agent
towards the bottom-right corner of the grid are present in the context tree. As shown in
the 4×4-grid plot in Figure 3, after 5000 experiences gathered from the random policy,
ΦMDP ﬁnds the optimal policy, and so does MC-AIXI-CTW and U-Tree. Active-LZ,
however, does not converge to an optimal policy even after 50,000 learning cycles.

Tiger. The tiger domain is described as follows. There are two doors, left and right;
an amount of gold and a tiger are placed behind the two doors in a random order. The
person has three possible actions: listen to predict the position of the tiger, open the right
door, and open the left door. If the person listens, he has to pay some money (reward of
-1). The probability that the agent hears correctly is 0.85. If the person opens either of
the doors and sees the gold, the obtained reward is 10; or otherwise he faces the tiger,
then the agent receives a reward of -100. After the door is opened, the episode ends;

Fig. 3. 4×4 Grid

Feature Reinforcement Learning in Practice

15

and in the next episode the tiger sits randomly again behind either the left or the right
door.

Fig. 4. Tiger

Our parallel tempering procedure found a context tree consisting of 39 states in-
cluding some important states where the history is such that the agent has listened a
few times before opening the door. It can be seen from the tiger plot in Figure 4 that
the optimal policy ΦMDP found after 5,000 learning experiences does yield positive
reward on average, while from time point 10,000 on, it achieves as high rewards as MC-
AIXI-CTW. U-Tree appears to learn more slowly but eventually manages to get posi-
tive averaged rewards after 50,000 cycles like ΦMDP and MC-AIXI-CTW. Active-LZ
is performing far worse. The optimal policy that ΦMDP, MC-AIXI-CTW, and U-Tree
ultimately found is the following. First listen two times, if the listening outcomes are
consistent, open the predicted door with gold behind; otherwise take one more listening
action, and based on the majority to open the appropriate door.

Cheese Maze. This domain, as shown in Figure 5, consists of a eleven-cell maze with a
cheese in it. The agent is a mouse that attempts to ﬁnd the cheese. The agent’s starting
position for each episode is at one of the eleven cells uniformly random. The actions
available to the agent are: move one cell left (0), right (1), up (2) and down (3). However,
it should be noticed that if the agent hits the wall, its relative position in the maze
remains unchanged. At each cell the agent can observe which directions among left,
right, up and down the cell is blocked by a wall. If wall-blocking statuses of each cell are
represented by 1 (blocked), and 0 (free) respectively; then an observation is described by

16

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Fig. 5. Cheese-maze domain

a four-digit binary number where the digits from left to right are wall-blocking statuses
of up, left, down and right directions. For example, 0101 = 5, 0111 = 7, ... as described
in Figure 5. The agent gets a reward of -1 when moving into a free cell without a cheese;
hitting the wall gives it a penalty of -10; and a reward of 10 is given to the agent when
it ﬁnds the cheese. As can be seen, some observations themselves alone are insufﬁcient
for the mouse to locate itself unambiguously in the maze. Hence, the mouse must learn
to resolve these ambiguities of observations in the maze to be able to ﬁnd the optimal
policy.

Fig. 6. Cheese-maze tree

Our algorithm found a context tree consisting of 43 states that contains the tree as
shown in Figure 6. The tree splits from the root into the 6 possible observations. Then
observations 5 and 10 are split into the four possible actions; and some of these actions,
the ones that come from a different location and not a wall collision, are split further

Feature Reinforcement Learning in Practice

17

into the 6 “possible” observations before that. This resolves which 5 or which 10 we are
at. The states in this tree resolve the most important ambiguities of the raw observations
and an optimal policy can be found. The domain contains an inﬁnite amount of longer
dependencies among which our found states pick up a small subset. The cheese-maze
plot in Figure 7 shows that after the initial 5000 experiences, ΦMDP is marginally
worse than MC-AIXI-CTW but is better than U-Tree and Active-LZ. From time point
10,000, there is no difference between ΦMDP and MC-AIXI-CTW. U-Tree and Active-
LZ remain inferior.

Fig. 7. Cheese maze

Kuhn Poker. In Kuhn poker [17] a deck of only three cards (Jack, Queen and King) is
used. The agent always plays second in any game (episode). After putting a chip each
into play, the players are dealt a card each. Then the ﬁrst player says bet or pass and
the second player chooses bet or pass. If player one says pass and player two says bet
then player one must choose again between bet and pass. Whenever a player says bet
they must put in another chip. If one player bets and the other pass the better gets all the
chips in play. Otherwise the player with the highest card gets the chips. Player one plays
according to a ﬁxed but stochastic Nash optimal strategy [11]. ΦMDP ﬁnds 89 states.
It can be observed from the Kunh-poker plot in Figure 8 that ΦMDP is comparable to
MC-AIXI-CTW and much better than U-Tree and Active-LZ, who loose money.

18

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

Fig. 8. Kuhn poker

5 Conclusions

Based on the Feature Reinforcement Learning framework [14] we deﬁned actual prac-
tical reinforcement learning agents that perform very well empirically. We evaluated a
reasonably simple instantiation of our algorithm that ﬁrst takes 5000 random actions
followed by ﬁnding a map through a search procedure and then it performs Q-learning
on the MDP deﬁned by the map’s state set.

We performed an evaluation on four test domains used to evaluate MC-AIXI-CTW
in [28]. Those domains are all suitably attacked with context tree methods. We deﬁned
a ΦMDP agent for a class of maps based on context trees, and compared it to three
other context tree-based methods. Key to the success of our ΦMDP agent was the de-
velopment of a suitable stochastic search method for the class of Markov AOCTs. We
combined parallel tempering with a specialized proposal distribution that results in an
effective stochastic search procedure. The ΦMDP agent outperforms both the classical
U-tree algorithm [21] and the recent Active-LZ algorithm [6], and is competitive with
the newest state of the art method MC-AIXI-CTW [28]. The main reason that ΦMDP
outperforms U-tree is that ΦMDP uses a global criterion (enabling the use of power-
ful global optimizers) whereas U-tree uses a local split-merge criterion. ΦMDP also
performs signiﬁcantly better than Active-LZ. Active-LZ learns slowly as it overesti-
mates the environment model (assuming n-Markov or complete context-tree environ-
ment models); and this leads to unreliable value-function estimates.

Below are some detailed advantages of ΦMDP over MC-AIXI-CTW:

Feature Reinforcement Learning in Practice

19

– ΦMDP is more efﬁcient than MC-AIXI-CTW in both computation and memory
usage. ΦMDP only needs an initial number of samples and then it ﬁnds the optimal
map and uses AVI to ﬁnd MDP parameters. After this it only needs a Q-learning
update for each iteration. On the other hand, MC-AIXI-CTW requires model updat-
ing, planning and value-reverting at every single cycle which together are orders of
magnitude more expensive than Q-learning. In the experiments ΦMDP ﬁnished in
minutes while MC-AIXI-CTW needed hours. Another disadvantage of MC-AIXI-
CTW is that it is a memory-hungry algorithm. ΦMDP learns the best tree repre-
sentation using stochastic search, which expands a tree towards relevant histories.
MC-AIXI-CTW learns the mixture of trees where the number of tree nodes grows
(and thereby the memory usage) linearly with time.

– ΦMDP learns a single state representation and can use many classical RL algo-

rithms, e.g. Q-Learning, for MDP learning and planning.

– Another key beneﬁt is that ΦMDP represents a more discriminative approach than
MC-AIXI-CTW since it aims primarily for the ability to predict future rewards and
not to fully model the observation sequence. If the observation sequence is very
complex, this becomes essential.

On the other hand, to be fair it should be noted that compared to ΦMDP, MC-AIXI-
CTW is more principled. The results presented in this paper are encouraging since they
show that we can achieve comparable results to the more sophisticated MC-AIXI-CTW
algorithm on problems where only short-term memory is needed. We plan to utilize the
aforementioned advantages of the ΦMDP framework, like ﬂexibility in environment
modeling and computational efﬁciency, to attack more complex and larger problems.

Acknowledgement

This work was supported by ARC grant DP0988049 and by NICTA. We also thank Joel
Veness and Daniel Visentin for their assistance with the experimental comparison.

References

1. Akaike, H.: A new look at the statistical model identiﬁcation. IEEE Transactions on Auto-

matic Control 19, 716–723 (1974)

2. Bertsekas, D.P., Tsitsiklis, J.N.: Neuro-Dynamic Programming. Anthena Scientiﬁc, Belmont,

MA (1996)

3. Brafman, R.I., Tennenholz, M.: R-max -a general polynomial time algorithm for near-
optimal reinforcement learning. Journal of Machine Learing Research 3, 213–231 (2002)
4. Chrisman, L.: Reinforcement learning with perceptual aliasing: The perceptual distinctions

approach. In: AAAI. pp. 183–188 (1992)

5. Cover, T.M., Thomas, J.A.: Elements of Information Theory. John Willey and Sons (1991)
6. Farias, V., Moallemi, C., Van Roy, B., Weissman, T.: Universal reinforcement learning. In-

formation Theory, IEEE Transactions on 56(5), 2441 –2454 (May 2010)

7. Geyer, C.J.: Markov chain Monte Calro maximum likelihood. In: Computing Science and
Statistics: the 23rd Symposium on the Interface. pp. 156–163. Interface Foundation, Fairfax
(1991)

20

Phuong Nguyen, Peter Sunehag, and Marcus Hutter

8. Givan, R., Dean, T., Greig, M.: Equivalence notions and model minimization in Markov

decision process. Artiﬁcial Intelligence 147, 163–223 (2003)

9. Granville, V., K˘riv´anek, M., Rasson, J.P.: Simulated annealing: A proof of convergence.
IEEE Transactions on Pattern Analysis and Machine Intelligence 16(6), 652–656 (June 1994)

10. Gr¨unwald, P.D.: The Minimum Description Length Principle. The MIT Press (2007)
11. Hoehn, B., Southey, F., Holte, R.C., Bulitko, V.: Effective short-term opponent exploitation

in simpliﬁed poker. In: AAAI. pp. 783–788 (2005)

12. Hukushima, K., Nemoto, K.: Exchange monte carlo method and application to spin glass

simulations. Journal of the Physical Socieity of Japan 65(4), 1604–1608 (1996)

13. Hutter, M.: Universal Articial Intelligence: Sequential Decisions based on Algorithmic Prob-

ability. Springer, Berlin (2005)

14. Hutter, M.: Feature reinforcement learning: Part I. Unstructured MDPs. Journal of General

Artiﬁcial Intelligence (2009)

15. Kaelbling, L.P., Littman, M.L., Cassandra, A.R.: Planning and acting in paritally observable

stochastic domains. Artiﬁcal Intelligence 101, 99–134 (1998)

16. Kocsis, L., Szepesv´ari, C.: Bandit based monte-carlo planning. In: The 17th European Con-

ference on Machine Learning. pp. 99–134 (2006)

17. Kuhn, H.W.: A simpliﬁed two-persion poker. In: Contributions to the Theory of Games. pp.

97–103 (1950)

18. Li, L., Walsh, T.J., Littmans, M.L.: Towards a uniﬁed theory of state abstraction for Mdps.
In: In Proceedings of the 9th International Symposium on Artiﬁcial Intelligence and Mathe-
matics (2006)

19. Liu, J.S.: Monte Carlo Strategies in Scientiﬁc Computing. Springer (2001)
20. Madani, O., Handks, S., Condon: On the undecidability of probabilistic planning and related

stochastic optimization problems. Artiﬁcal Intelligence 147, 5–34 (2003)

21. McCallum, A.K.: Reinforcement Learning with Selective Perception and Hidden State.

Ph.D. thesis, Department of Computer Science, University of Rochester (1996)

22. Rissanen, J.: A universal data compression system. IEEE Transactions on Information The-

ory 29(5), 656–663 (1983)

23. Schneider, J., Kirkpatrick, S.: Stochastic Optimization. Springer, ﬁrst edn. (2006)
24. Singh, S.P., James, M.R., Rudary, M.R.: Predictive state representations: A new theory for
modeling dynamical systems. In: Proceedings of the 20th Conference in Uncertainty in Ar-
tiﬁcial Intelligence. pp. 512–518. Banff, Canada (2004)

25. Suman, B., Kumar, P.: A survey of simulated annealing as a tool for single and multiobjecc-
tive optimization. Journal of the Operational Research Society 57, 1143–1160 (2006)
26. Sunehag, P., Hutter, M.: Consistency of feature Markov processes. In: Proc. 21st Interna-
tional Conf. on Algorithmic Learning Theory (ALT’10). LNAI, vol. 6331, pp. 360–374.
Springer, Berlin, Canberra (2010)

27. Sutton, R., Barto, A.: Reinforcement Learning. The MIT Press (1998)
28. Veness, J., Ng, K.S., Hutter, M., Uther, W., Silver, D.: A Monte-Carlo AIXI approximation.

Journal of Artiﬁicial Intelligence Research 40(1), 95–142 (2011)

29. Vidal, E., Thollard, F., Higuera, C.D.L., Casacuberta, F., Carrasco, R.C.: Probabilitic ﬁnite-
state machines. IEEE Transactions on Pattern Analysis and Machine Intelligence 27(7),
1013–1025 (July 2005)

30. Wallace, C.S., Dowe, D.L.: Minimum message length and komogorov complexity. Computer

Journal 42(4), 270–283 (1999)

31. Wilems, F.M.J., Shtarkov, Y.M., Tjalkens, T.J.: The context tree weighting method: Basic

properties. IEEE Transactions on Information Theory 41, 653–644 (1995)"
"Micromagnetic Simulation of Nanoscale Films with Perpendicular
  Anisotropy","  A model is studied for the theoretical description of nanoscale magnetic
films with high perpendicular anisotropy. In the model the magnetic film is
described in terms of single domain magnetic grains with Ising-like behavior,
interacting via exchange as well as via dipolar forces. Additionally, the model
contains an energy barrier and a coupling to an external magnetic field.
Disorder is taken into account in order to describe realistic domain and domain
wall structures. The influence of a finite temperature as well as the dynamics
can be modeled by a Monte Carlo simulation.
  Many of the experimental findings can be investigated and at least partly
understood by the model introduced above. For thin films the magnetisation
reversal is driven by domain wall motion. The results for the field and
temperature dependence of the domain wall velocity suggest that for thin films
hysteresis can be described as a depinning transition of the domain walls
rounded by thermal activation for finite temperatures.
",http://arxiv.org/pdf/cond-mat/9611218v1,2,"6
9
9
1

v
o
N
7
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
8
1
2
1
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Micromagnetic Simulation of nanoscale Films with perpendicular Anisotropy

U. Nowak
Theoretische Tieftemperaturphysik
Gerhard-Mercator-Universit¨at-Duisburg
47048 Duisburg/ Germany
e-mail: uli@thp.uni-duisburg.de
(October 21, 2018)

A model

is studied for the theoretical description of
nanoscale magnetic ﬁlms with high perpendicular anisotropy.
In the model the magnetic ﬁlm is described in terms of single
domain magnetic grains with Ising-like behavior, interacting
via exchange as well as via dipolar forces. Additionally, the
model contains an energy barrier and a coupling to an exter-
nal magnetic ﬁeld. Disorder is taken into account in order
to describe realistic domain and domain wall structures. The
inﬂuence of a ﬁnite temperature as well as the dynamics can
be modeled by a Monte Carlo simulation.

Many of the experimental ﬁndings can be investigated and
at least partly understood by the model introduced above.
For thin ﬁlms the magnetisation reversal is driven by domain
wall motion. The results for the ﬁeld and temperature de-
pendence of the domain wall velocity suggest that for thin
ﬁlms hysteresis can be described as a depinning transition
of the domain walls rounded by thermal activation for ﬁnite
temperatures.

75.60.-d, 75.40.Mg, 77.80.Dj

HD-05

I. INTRODUCTION

We focus on thin ferromagnetic ﬁlms with high per-
pendicular anisotropy like CoP t and M nBi which can
be used as magneto-optical storage media. In these ﬁlms
two diﬀerent mechanisms can be thought to dominate
the reversal process: either nucleation or domain wall
motion [1]. Which of these mechanisms dominates a re-
versal process depends on the interplay of the diﬀerent
interaction forces between domains with diﬀerent mag-
netic orientation.
In a recent experiment on Co28P t72
alloy ﬁlms [2,3] a crossover from magnetisation reversal
dominated by domain growth to a reversal dominated by
a continuous nucleation of domains was found depend-
ing on the ﬁlm thickness which was varied from 100˚A to
300˚A. Correspondingly, characteristic diﬀerences for the
hysteresis loops have been found. Similar results have
been achieved by simulations of a micromagnetic model
using energy minimization techniques [2,3] and Monte
Carlo methods, respectively [4].
It is the goal of this
paper to investigate the inﬂuence of the ﬁeld and the
temperature on the domain wall velocity for the case of
magnetisation reversal dominated by domain wall motion
by a Monte Carlo simulation of a micromagnetic model.

II. MICROMAGNETIC MODEL

Co28P t72 alloy ﬁlms have a polycrystalline structure
with grain diameters of 100-250˚A. For a theoretical de-
scription by a micromagnetic model [5] the ﬁlm is thought
to consist of cells on a square lattice with a square base of
size L × L where L = 200˚A and height h of 100˚A. Due to
the high anisotropy of the Co28P t72 alloy ﬁlm the grains
are thought to be magnetised perpendicular to the ﬁlm
only with a uniform magnetisation Ms which is set to the
experimental value of Ms = 365kA/m for the saturation
magnetisation in these systems [6]. The grains interact
via domain wall energy and dipole interaction. The cou-
pling of the magnetisation to an external magnetic ﬁeld
H is taken into account as well as an energy barrier which
has to be overcome during the reversal process of a single
cell.

From these considerations it follows that the change of
energy caused by reversal of a cell i with magnetisation
L2hMsσi with σi = ±1 is:

∆Ei = −

1
2

LhSw∆σi X
<j>
−µ0HL2hMs∆σi

σj +

µ0
4π

M

2

2
s Lh

∆σi X
j

v(σj , rij )

(1)

The ﬁrst term describes the wall energy ∆Ew. The
sum is over the four next neighbors and for Sw we use a
value of Sw = 0.0022J/m2 which is approximately 50%
of the Bloch-wall energy SB for this system [6]. The
reason for this reduction of the grain interaction energy
compared to the Bloch-wall energy is, that the crystalline
structure of the system is interrupted at the grain bound-
ary and also that due to their irregular shape the grains
are not connected via their complete surface Lh.

In the second term describing the dipole coupling ∆Ed
the sum is over all cells. rij is the distance between two
cells i and j in units of the lattice constant L. For large
distances it is v(σj , rij ) = σj
. For shorter distances a
r3
ij
more complicated form which is a better approximation
for the shape of the cells which we consider can be deter-
mined numerically and was taken into account.

The third term describes the coupling ∆EH to an ex-

ternal ﬁeld H.

Additionally, an energy barrier δi must be considered
which describes the fact that a certain energy is needed
to reverse an isolated cell by domain wall motion through
the grain (see also [7]). We assume that during the re-
versal process the energy barrier has its maximum value
LhSb when the domain wall is in the center of the cell, i.e.
when half of the cell is already reversed. Consequently,

1

 
 
 
 
 
 
the energy barrier which is relevant for the reversal pro-
cess is reduced to δ = max(0, LhSb − 1
2 |(∆Ew + ∆Ed +
∆EH )|). The simulations are in good qualitative agree-
ment with experiments using Sb = 0.0007J/m2.

In order to simulate the CoP t ﬁlms realistically disor-
der has to be considered. Obviously, the grain sizes are
randomly distributed [2]. In the model above this corre-
sponds to a random distribution of L which can hardly
be simulated exactly since it modulates the normalized
cell distance rij of the dipole interaction. Therefore, as a
simpliﬁed ansatz to simulate the inﬂuence of disorder we
randomly distribute L in the energy term that describes
the coupling to the external ﬁeld. Here a random ﬂuctu-
ation of L is most relevant, since this term is the only one
scaling quadratic ly with L. In the simulations we use a
distribution which is Gaussian with width ∆. Note, that
through this kind of disorder our model is mapped on a
random-ﬁeld model.

The simulation of the model above was done as in an
earlier publications [4,7] via Monte Carlo methods [8] us-
ing the Metropolis algorithm with an additional energy
barrier. Since the algorithm satisﬁes detailed balance and
Glauber dynamics it allows the investigation of thermal
properties as well as the investigation of the dynamics of
the system. For temperatures T → 0 the Monte Carlo
algorithm passes into a simple energy minimization al-
gorithm with single spin ﬂip dynamics, so that also the
case of zero temperature can be investigated.

The size of the lattice was typically 150 × 150. The
dipole interaction was taken into account without any
cut-oﬀ or mean ﬁeld approximation.

III. HYSTERESIS AND DYNAMICS

Fig. 1 shows a simulated hysteresis loop. The loop is
nearly rectangular. Here, the reversal is dominated by
domain wall motion [4]. Once a nucleus begins to grow
the domain wall motion does not stop until the magneti-
sation has completely changed. The nucleation ﬁeld for
the simulation is too high compared to the correspond-
ing experimental results [2,3]. There are several possible
reasons for this eﬀect. First, the nucleation ﬁeld which
in the case of domain wall motion dominated reversal is
the ﬁeld where domain wall motion starts depends on the
size and on the shape of the nucleus. In an experimen-
tal situation a nucleus can be very large e. g. a scratch
while there is no such artiﬁcial nucleus in our simulation
except of the disorder which leads only to nuclei of very
small size. However, it is not the aim of our simulations
to calculate the nucleation ﬁeld accurately. Rather, the
simulations are thought to contribute to a better under-
standing of the fundamental properties of the system.

Since the reversal is driven by domain wall motion, the
velocity of the domain wall is a central quantity which we
will investigate in the following. For the determination of
the domain wall velocity within the simulation we start
with a system that has a nucleus of circular shape with
a radius of 19 cells in the center of the 150 × 150 system.
When we switch on the driving ﬁeld, from the nucleus
a domain starts to grow. For the better observation of

the domain growth, in our ﬂip-algorithm we do not con-
sider cells that are not connected to the growing domain,
i. e. we exclude the possibility of additional nucleation.
Otherwise we have – at least for ﬁnite temperatures – the
problem that spontaneously new nuclei are build by ther-
mal activation which with increasing radius overlap with
the original domain. Fig. 2 shows a domain during the re-
versal. The black region is the reversed domain following
the magnetic ﬁeld. It has a circular shape with a rough
domain wall. From the domain conﬁgurations the mean
radius r of the domains can be determined through the
area F of the reversed domain as r = pF/π, assuming
that the domain has a circular shape.

In order to get a deeper understanding of the inﬂuence
of the temperature on the dynamics we simulated the
reversal for temperatures T = 0, 300, and 600K. Fig. 3
shows - as an example - the r(t) behavior from the sim-
ulations for T = 0K and diﬀerent ﬁelds. For r > 75
the domain reaches the boundary of the system and -
consequently - r(t) saturates. For zero temperature the
domain wall is pinned for lower ﬁelds, i. e. after a short
period of rearrangement of the domain wall the domain
wall movement stops and the radius remains constant.
The pinning of the domain wall is due to energy barri-
ers which follow from the disorder, the dipole ﬁeld, and
the intrinsic energy barrier of the single cell. For ﬁnite
temperatures, the domain wall velocity is always ﬁnite.
For 20 < r < 75 the slope of the r(t) curve is approx-
imately constant and v can be determined by ﬁtting to
a straight line. Fig. 4 shows the dependence of the do-
main wall velocity on the driving ﬁeld for T = 0, 300,
and 600K. For zero temperature there is a sharp depin-
ning transition [9] at a critical ﬁeld Hc from a pinned
phase with v = 0 to a phase with ﬁnite domain wall ve-
locity. This transition can be interpreted in terms of a
phase transition with v ∼ (H − Hc)θ for H > Hc where
in our case the critical exponent is θ ≈ 1, a value which
is the mean ﬁeld result for a moving elastic interface [10]
in a random ﬁeld. Also, this value has been observed in
simulations of a soft spin model with random-ﬁelds [11].
For ﬁnite temperatures the transition is smeared since
for ﬁnite temperatures there is even for H < Hc for each
energy barrier a ﬁnite probability that the barrier can
be overcome by thermal ﬂuctuations. The corresponding
waiting time can be expected to be exponentially large
so that for H < Hc the domain wall velocity should de-
crease like ln v ∼ (H − Hc)/T . To illustrate this in Fig.5
we show the corresponding semi-logarithmic scaling plot.
As we expect, the data for the two diﬀerent ﬁnite tem-
peratures collapse for H < Hc on a straight line. For
H > Hc thermal activation is obviously less relevant.
Here, the dynamics is dominated by the zero tempera-
ture depinning transition.

To conclude, the results for the domain wall velocity
suggest that for zero temperature the hysteresis driven
by domain wall motion can be understood as a depin-
ning transition of the domain walls. For ﬁnite tempera-
ture the transition is rounded and for ﬁelds smaller than
the depinning ﬁeld the domain wall movement is domi-
nated by thermal activation. A paper on a comparison
of these theoretical results with experimental measure-

2

ments of the domain wall velocity in CoP t alloy ﬁlms is
in preparation.

ACKNOWLEDGMENTS

The author thanks K. D. Usadel for helpful discussions

and for critically reading the manuscript.

[1] J. Pommier, P. Meyer, G. P´enissard, J. Ferr´e, P. Bruno,

and D. Renard, Phys. Rev. Lett. 65, 2054 (1990)

[2] T. Kleinefeld, J. Valentin, D. Weller, JMMM 148, 249

(1994)

[3] J. Valentin, T. Kleinefeld, D. Weller, J. Phys. D 29, 1111

(1996)

[4] U. Nowak, IEEE Trans. Mag. 31, 4169 (1995)
[5] W. Andr¨a, H. Danan, and R. Mattheis, Phys. Stat. Sol.

(a), 125 , 9 (1991)

[6] J. Harzer, RWTH Aachen, Ergebnisbericht (1992)
[7] U. Nowak, U. Ruediger, P. Fumagalli, G. G¨untherodt,

Phys. Rev. B 54, 13017 (1996)

[8] K. Binder, Monte Carlo Methods in Statistical Physics

(Springer-Verlag, Berlin 1979)

[9] M. Kardar and D. Ertas, in Scale Invariance, Interfaces,
and Non-Equilibrium Dynamics, edited by A. McKane,
M. Droz, J. Vannimenus, and D. Wolf, Plenum Press,
New York 1995, pa. 89

[10] H. Leschhorn, J. Magn. Magn. Mat. 104-107, 309 (1992)
[11] K. D. Usadel and M. Jost, J. Phys. A26, 1783 (1993)

FIG. 1. Hysteresis loop for a 100˚A ﬁlm; T = 300K

FIG. 2. Domain conﬁguration of a 150 × 150 system during

the reversal; T = 300K

FIG. 3. Radius of the domain versus time for the same

ﬁelds as in Fig. 4; T = 0; solid lines are best ﬁtted.

FIG. 4. Domain wall velocity versus driving ﬁeld for

T = 0, 300, and 600K; solid lines are guides to the eye.

FIG. 5. Scaling plot from Fig. 4.

3"
Thermal and Mechanical Properties of Pt-Rh Alloys,"  We utilize the many-body potentials developed by Sutton and Chen(1990) within
the context of the tight-binding approach to study the bulk properties of
metals and metal alloys in molecular dynamics (MD) simulations. In the
simulations of Pt-Rh alloys we used the MD algorithms based on an extended
Hamiltonian formalism from the works of Andersen(1980), Parrinello and
Rahman(1980), Nose(1984), Hoover(1985) and Cagin(1988).The simulator program
that we use generates information about various physical properties during the
run time, along with critical trajectory and stepwise information which need to
be analysed post production. The thermodynamical and mechanical properties are
calculated using the statistical fluctuation expressions over the MD.
",http://arxiv.org/pdf/cond-mat/9611241v1,2,"6
9
9
1

v
o
N
8
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
1
4
2
1
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Thermal and Mechanical Properties
of Pt-Rh Alloys

G. Dereli, T. C¸ a˘gın∗, M. Uludo˘gan, M. Tomak

Department of Physics, Middle East Technical University,

06531 Ankara, Turkey
∗Materials and Process Simulation Center, California Institute of Technology,

Pasadena, CA 91125 , U.S.A.

Abstract

We utilize the many-body potentials developed by Sutton and Chen
(1990) within the context of the tight-binding approach to study the
bulk properties of metals and metal alloys in molecular dynamics
(MD) simulations.
In the simulations of Pt-Rh alloys we used the
MD algorithms based on an extended Hamiltonian formalism from the
works of Andersen(1980), Parrinello and Rahman(1980), Nos´e(1984),
Hoover(1985) and C¸ a˘gın(1988). The simulator program that we use
generates information about various physical properties during the run
time, along with critical trajectory and stepwise information which
need to be analysed post production. The thermodynamical and me-
chanical properties are calculated using the statistical ﬂuctuation ex-
pressions over the MD.

0

 
 
 
 
 
 
1. Introduction

The development of advanced high-performance materials in the indus-
trial world is increasingly coupled with theoretical and computational mod-
elling.
In this process, focus is on research areas having direct impact on
innovative development of such materials. High-performance metallic alloys
ﬁnd use in various segments of materials and chemical industries as cata-
lysts, and as low-weight and high-strength structural materials. In partic-
ular, Pt-Rh alloy is important for catalytic reactions in controlling exhaust
gas emissions and NH3 oxidation reactions in fertilizer industries.

The theory and computational eﬀorts require and strive for i) a priori
determination of the ultimate properties of metals, metallic alloys, ii) simu-
lation and modelling of the processing conditions, and iii) investigating the
performance characteristics of these metals and alloys. All these are ex-
tremely important for timely, cost-eﬃcient and environmentally compliant
development of such advanced materials. With advances in computational
speed and emerging new computational algorithms, theoretical and computer
simulations are positioned in the midst of this innovative process.

Computer simulations on various model systems usually use simple pair
potentials. To account for the directionality of bonding, three-body inter-
actions are also often employed. However, the interactions in metals and
metal alloys cannot be represented by simple pairwise interactions. In these
systems the electron density plays a dominant role in the interactions and
resulting physical properties. Therefore interactions in metals and metal
alloys are dominated by many-body interactions. In simple sp-bonded met-
als this eﬀect may be represented by the interaction potentials derived from
model pseudopotentials using second-order perturbation theory (Harrison
1979,1980). Along these lines, we have developed interaction potentials and
utilized them to study the properties of simple alkali metal and alkali-metal
alloys (Dalgı¸c et al 1994). However, for d-band metal and metal alloys, the
model pseudopotential approach gives way to newer techniques evolved over
the past ten years to account for the many-body eﬀects. Among these ap-
proaches we can list the empirical many-body potentials based on Norskov’s
Eﬀective Medium Theory (Norskov 1982), Daw and Baskes’ Embedded Atom

1

Method (Daw and Baskes 1984), Finnis and Sinclair’s empirical many-body
potentials (Finnis and Sinclair 1984), and more recently the many-body po-
tentials developed by Sutton and Chen(1990) within the context of a tight
binding approach (Koleske and Sibener 1993).

In this work we utilized the Sutton-Chen potentials to study the bulk

properties of Pt-Rh alloy using molecular dynamics simulations.

2. Many-Body Potentials for fcc Metals and Methods

The Sutton-Chen interaction potential is given as the sum of a pairwise
repulsion term and a many-body density-dependent cohesion term (Sutton
and Chen 1990). The functional form of the interaction potential is as follows:

where

Ui = D(

1
2

X
j

u(rij) − cρi)

u(r) = (

)n

a
r

ρi = (X
j

φ(rij))

1
2

φ(r) = (

)m

a
r

The Sutton-Chen potential parameters D, c and m and n are optimized to ﬁt
to the 0K properties such as the cohesive energy, zero-pressure condition and
the bulk modulus of the fcc metals. We list the values of these parameters
for Rh and Pt in Table 1.

As mentioned above, the parametrization of the interaction potentials
for these fcc metals are based on the bulk properties at 0K. The functional
form is fairly simple in comparison to Embedded Atom Method potentials
and is moderately long ranged. The last property makes this set especially
attractive for surface and interface studies amongst others, since most of them
are very short ranged, (i.e. are ﬁtted up to ﬁrst or second nearest-neighbour
distances).

2

The above interaction potential can be generalized to describe binary
metal alloys in such a way that all the parameters in the Hamiltonian equa-
tions are obtained from the parameters of pure metals. The Sutton-Chen
interaction potential above is adopted by Raﬁi-Tabar and Sutton (1991) to
a random fcc alloy model in which sites are occupied by two types of atoms
completely randomly, such that the alloy has the required average concen-
tration. The equilibrium lattice parameter a∗ at 0K of the random alloy is
chosen as the universal length scale and the expectation value Et per atom
of the interaction Hamiltonian is given as a function of a∗. Raﬁi-Tabar and
Sutton (1991) determined the value of the equilibrium lattice parameter for
the random alloy, and calculated elastic constants and the enthalpy of mixing
by the static-lattice summation method. Once a∗ is found the enthalpy of
mixing ∆H per atom at 0K are also obtained from

∆H = Et − cAEA − cBEB

where EA and EB are the cohesive energies per atom of the elemental A and
B metals and the constants are such that cA + cB = 1.

The Molecular Dynamics(MD) and Monte Carlo(MC) simulation meth-
ods (Allen and Tildesley 1987) have long been very important in studying
statistical mechanics of many-body systems. In recent years, these methods
have increasingly been used in studying more realistic problems to investi-
gate the properties and behaviour of these systems at elevated temperatures
and pressures/applied stresses (C¸ a˘gın 1988a,1988b), in contrast to lattice
dynamics and minimization.

The algorithmic advances in the late 1980’s have enabled researchers to
simulate the dynamics of open systems for studying the phase equilibria
(C¸ a˘gın 1989). This is especially important for our goals; for instance the
phase segregation in metal alloys is one of the key problems in the develop-
ment of advanced high-performance metallic alloys.

In order to investigate the eﬀect of temperature and concentration on the
physical properties of random alloys, we use molecular dynamics method to
calculate the enthalpy of mixing, the density and the elastic constants at

3

six diﬀerent atomic concentrations (0, 20, 40, 60, 80, and 100% of Rh in Pt-
Rh alloy) at temperatures ranging from T = 300K to T = 1500K with 200K
increments. In contrast to static lattice sums, molecular dynamics inherently
takes into account the anharmonic eﬀects in computed physical properties.

In the following, we present the expressions speciﬁc to these many-body
potentials which are used in the computations. The many-body force on
atom i along a direction a(= x, y, z) is given as:

Fai = −D
2

∗

(

X
j

u′(r)

rija
rij

− ci
2

P

∗

j φ′(r) rija
rij
ρi

),

∂r and ∗ signiﬁes the exclusion of i = j from the sums.
where ′ denotes ∂
The anisotropic stress tensor including the contribution from the many-body
potential is calculated from

ΩPab = X
i

piapib
mi

− D
2

∗

(

X
i

X
j

u′(r)

rijarijb
rij

− ci
2

P

∗

j φ′(r) rijarijb
ρi

rij

),

The potential energy contribution to the elastic constants, the hypervirial

tensor χabcd, is given as

Ωχabcd =

D
2

∗

(

X
i

X
j

)

(u′′ − u′
rijarijbrijcrijd
r2
rij
ij
) rijarijbrijcrijd
r2
ij

rij

∗

j (φ′′ − φ′

P

∗
(P

ρi
j φ′ rijarijb
)(P
ρ3
i

rij

∗

k φ′ rikcrikd

rik

)

).

−ci
2

+

ci
4

In our computations at each concentration and at each temperature we
have ﬁrst determined the zero strain state, ho, of the system by performing
constant-temperature and constant-stress simulations (NPT) at zero stress.
This yields the reference shape and size matrix, ho in the Parrinello-Rahman
(1980) formalism. In determining the elastic constants, this reference state
is used in constant-temperature and constant-volume simulations (NVE) of

4

50000 steps for each state point. The elastic constants are evaluated using
the following statistical ﬂuctuation formulas (C¸ a˘gın and Ray 1988)

(< PabPcd > − < Pab >< Pcd >)

abcd = − Ωo
C T
kBT
2NkBT (δacδbd + δadδbc)
Ωo

+

+ < χabcd >

where <> denotes the averaging over time and Ωo = detho is the reference
volume for the model system.

We use the program Simulator developed by C¸ a˘gın that employs the
state of the art MD algorithms based on extended Hamiltonian formalisms
emerging from the works of Anderson(1980), Parrinello and Rahman(1980),
Nos´e(1984), Hoover(1985) and C¸ a˘gın and Pettitt(1991a,1991b). We used a
500-atom cubic system and the simulation started with atoms randomly dis-
tributed on a fcc lattice. The system is thermalized starting from 1K to the
target temperature using constant-enthalpy and constant-pressure (NHP)
ensemble by slowly heating while scaling velocities to increment the temper-
ature of 1K/step over the speciﬁc number of steps depending on the target
temperature. This is followed by strict velocity scaling at each target tem-
perature. We then performed NPT dynamics at this temperature for 20000
steps to calculate the volume, density and enthalpy of the system for each
concentration. The resulting zero-strain averaged matrix < h0 > is used in
calculating elastic constants over 50000 steps of NVE dynamics. A ﬁfth-order
Gear predictor-corrector algorithm is used with ∆t = 2 fs. The Parrinello-
Rahman piston mass parameter is chosen as W=400 and in NPT runs the
Nos´e-Hoover parameter is set to Q=100.

3. Results and Discussion

Here we present molecular simulation results obtained for the Pt-Rh alloy.
We calculated the density and volume of 500 atoms and enthalpy of mixing
for Pt-Rh alloy as a function of percent of atomic concentration of rhodium.
We have done the simulation under isothermal-isobaric condition (NPT) at
temperatures ranging from 300K to 1500K with 200K increments.

5

In Figure 1, the density and enthalpy at six diﬀerent atomic concentration
values 0, 20, 40, 60, 80, 100% of Rh in Pt-Rh alloy are given. At the end
points we found the density for Rh and Pt to be 12.3g/cm3 and 21.2g/cm3,
respectively, at 300K. These values show approximately 1.5% deviation from
the experimental values 12.45g/cm3 and 21.50g/cm3. In Figure 2 we have
drawn the calculated enthalpy of mixing with respect to atomic concentration
of Rh in Pt-Rh alloy at two temperature values of 300K and 1500K.

We also studied the thermal expansion behaviour of the Sutton-Chen
potential that we use. The percent change in the lattice parameter at each
temperature (the lattice parameter at 300K is used as the reference) are
given in Table 2. Comparison with the experiment indicate that for Pt the
theoretical thermal expansion coeﬃcient is approximately twice that of the
experimental value while for Rh it is around 1.3 higher.

In Figure 3 the elastic constants of Pt-Rh alloy at six diﬀerent concentra-
tion values are shown. In order to see the eﬀect of temperature, we repeated
the drawing at three diﬀerent temperatures (300K, 900K, 1500K). Thermal
softening of the alloy is observed as the temperature increases. In Figure 4
the calculated bulk modulus values at the same temperatures are shown.

In our calculations at each concentration and at each temperature we have
ﬁrst determined the zero-strain state of the system by performing constant-
temperature and constant-stress simulations. In determining the elastic con-
stants this reference state is used in constant-temperature, constant-volume
simulations of 50000 steps for each state point. Comparison with experimen-
tal results is possible only at the end points where Pt or Rh is pure. This we
have done in Table 3. The static results of Sutton and Chen(1990) are also
given to facilitate comparison.

To summarize, the potentials used in the present dynamic simulations
take account of the anharmonic eﬀects and give reasonably accurate descrip-
tion of the thermodynamic properties and the elastic constants of Pt-Rh
alloys. The system is quite stable and the sign of the enthalpy of mixing is
correct at all concentration values. For the concentrations and temperatures
at which we performed our simulations we found that mixing is enthalpically
favourable.

6

References

ALLEN,M.P., and TILDESLEY,D.J.,1987, Computer Simulation of Liq-

uids (Oxford: Oxford U.P.).

ANDERSON,H.J.,1980, J. Chem. Phys. 72, 2384.

C¸ A ˘GIN,T.,and RAY,J.R.,1988, Phys. Rev. B 38, 7940.

C¸ A ˘GIN,T.,1988a, Phys. Rev. A 37, 199.

C¸ A ˘GIN,T.,1988b, Phys. Rev. A 37, 4510.

C¸ A ˘GIN,T.,1989, ”Molecular Dynamics Methods in Studying Phase Equi-
libria”, in Computer Aided Innovation of New Materials Vol.II,
p 255-9, Eds. M. Doyoma, J. Kihara, M. Tanaka, R. Yamamoto
(Amsterdam:North-Holland).

C¸ A ˘GIN,T., and PETTITT,B.M.,1991a, Mol. Phys. 72, 169.

C¸ A ˘GIN,T., and PETTITT,B.M.,1991a, Molec. Simul. 6, 5.

DALGIC¸ ,S., DALGIC¸ ,S., DEREL˙I,G.,and TOMAK,M.,1994, Phys. Rev.

B, 50, 113.

DAW,M.S.,and BASKES,M.L.,1984, Phys. Rev. B, 29, 6443.

FINNIS,M.W.,and SINCLAIR,J.F.,1984, Phil. Mag. A,50, 45.

HARRISON,W.A.,1979, Solid State Theory (New York:Dover).

HARRISON,W.A.,1980, Electronic Structure and Properties of Solids

(New York:Dover).

HOOVER,W.G., 1985,Phys. Rev. A, 31, 1695.

KOLESKE,D.D., and SIBENER,S.J.,1993, Surf. Sci. 290, 179.

NORSKOV,J.K.,1982, Phys. Rev. B, 26, 2875.

7

NOS´E,S.,1984, J. Chem. Phys., 81, 511.

PARINELLO,M. and RAHMAN, A.,1980, Phys. Rev. Lett., 45, 1196.

RAFII-TABAR,H. and SUTTON,A.P.,1991, Phil. Mag. Lett., 63, 217.

SUTTON,A.P., and CHEN,J.,1990,, Phil. Mag. Lett., 61, 139.

8

Table 1: The interaction potential parameters for Pt and Rh.

a
(˚A)

3.92
3.80

D
(10−2 eV)

c

m

n

metal

1.98330
0.49371

34.428
145.658

8
6

10
12

Pt
Rh

Table 2: The percent change in the lattice parameter from simulation and
experiment. The changes are computed using the 300K lattice parameters
from simulation and experiment as reference, respectively.

Pt

Rh

T
(K) This work Experiment This work Experiment
500
700
750
900
1000
1100
1300
1500

0.26
0.54
0.61
0.83
0.98
1.13
1.46
1.80

0.18
0.38
0.42
0.59
0.70
0.81
1.04
1.29

0.35
0.73
0.83
1.14
1.36
1.59
2.10
2.72

0.18
0.39
0.46
0.61
0.73
0.84
1.11
1.38

9

Table 3:
Elastic constants and bulk modulus of Pt and Rh. All values
are in units of eV A−3. At each entry, the ﬁrst number gives the molecular
dynamics simulation result at 300K. The second number in round brackets is
the corresponding experimental value at 0K, while the third number in square
brackets is the statically calculated value from Sutton and Chen (1990) at
0K.

C11
1.81(2.23)[1.96]
2.01(2.63)[2.12]

C12
1.50(1.59)[1.61]
1.39(1.20)[1.45]

C44
0.41(0.48)[0.46]
0.82(1.21)[0.89]

B
1.60(1.80)[1.73]
1.60(1.68)[1.68]

Pt
Rh

3

)

m
c
/
g
(
Y
T
I
S
N
E
D

22

20

18

16

14

12

10

P t

P t

Rh

0:8

0:2

P t

Rh

0:6

0:4

P t

Rh

0:4

0:6

P t

Rh

0:2

0:8

Rh

300

500

700

900

1100

1300

1500

TEMPERATURE (K)

(a)

10

-510

-515

Rh

P t

Rh

0:2

0:8

P t

P t

Rh

0:4

0:6

P t

Rh

0:8

0:2

P t

Rh

0:6

0:4

)
l
o
m
/
J
k
(
Y
P
L
A
H
T
N
E

-520

-525

-530

-535

-540

-545

-550

-555

-560

300

500

700

900

1100

1300

1500

TEMPERATURE (K)

(b)

Figure 1:
diﬀerent atomic concentrations of Rh in Pt-Rh alloy.

(a) Density and (b) enthalpy as a function of temperature at

)
l
o
m
/
J
k
(

I

I

G
N
X
M
F
O
Y
P
L
A
H
T
N
E

0

-1

-2

-3

-4

-5

-6

-7

Pt-Rh

300 K

1500 K

0

20

40

60

80

100

% Rh

Figure 2: Enthalpy of mixing as a function of atomic concentration of Rh in
Pt-Rh alloy at two diﬀerent temperatures.

11

)
a
P
G
(

S
T
N
A
T
S
N
O
C
C
I
T
S
A
L
E

)
a
P
G

(

S
T
N
A
T
S
N
O
C
C
I
T
S
A
L
E

Pt-Rh 300 K

c

11

c

12

350

300

250

200

150

100

c

44

50

350

300

250

200

150

100

50

0

0

20

40

60

80

100

% Rh

(a)

Pt-Rh 900 K

c

11

c

12

c

44

0

20

40

60

80

100

% Rh

(b)

12

Pt-Rh 1500 K

)
a
P
G
(

S
T
N
A
T
S
N
O
C
C
I
T
S
A
L
E

300

250

200

150

100

50

0

c

11

c

12

c

44

0

20

40

60

80

100

% Rh

(c)

Figure 3: (a)-(b)-(c) Elastic constants as a function of atomic concentration
of Rh in Pt-Rh alloy at three diﬀerent temperatures

Pt-Rh

)
a
P
G

(

S
U
L
U
D
O
M
K
L
U
B

300

250

300 K

900 K

200

1500 K

150

100

0

20

40

60

80

100

% Rh

Figure 4: Bulk modulus as a function of atomic concentration of Rh in Pt-Rh
alloy at three diﬀerent temperatures.

13"
Scaling for the Coalescence of Microfractures before Breakdown,"  We study the behavior of fracture in disordered systems close to the
breakdown point. We simulate numerically both scalar (resistor network) and
vectorial (spring network) models with threshold disorder, driven at constant
current and stress rate respectively. We analyze the scaling of the
susceptibility and the cluster size close to the breakdown. We observe
avalanche behavior and clustering of the cracks. We find that the scaling
exponents are consistent with those found close to a mean-field spinodal and
present analogies between the coalescence of microfractures and the coalescence
of droplets in a metastable magnetic system. Finally, we discuss different
experimental conditions and some possible theoretical interpretations of the
results.
",http://arxiv.org/pdf/cond-mat/9612094v1,2,"6
9
9
1
c
e
D
0
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
4
9
0
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

SCALING FOR THE COALESCENCE OF MICROFRACTURES BEFORE
BREAKDOWN

S. ZAPPERI1, P. RAY2, H.E. STANLEY1 AND A. VESPIGNANI3
1 Center for Polymer Studies and Department of Physics, Boston University, Boston, MA
02215 ,USA 2The Institute of Mathematical Sciences, CIT Campus, Madras - 600 113, India
3 Instituut-Lorentz, University of Leiden, P.O. Box 9506 The Netherlands.

ABSTRACT

We study the behavior of fracture in disordered systems close to the breakdown point. We
simulate numerically both scalar (resistor network) and vectorial (spring network) models
with threshold disorder, driven at constant current and stress rate respectively. We analyze
the scaling of the susceptibility and the cluster size close to the breakdown. We observe
avalanche behavior and clustering of the cracks. We ﬁnd that the scaling exponents are
consistent with those found close to a mean-ﬁeld spinodal and present analogies between
the coalescence of microfractures and the coalescence of droplets in a metastable magnetic
system. Finally, we discuss diﬀerent experimental conditions and some possible theoretical
interpretations of the results.

INTRODUCTION

The breakdown of solids under external forces is a longstanding problem, that has practical
and theoretical relevance. The way a material breaks, under the eﬀect of an external electric
ﬁeld or under mechanical stress are closely related problems, due to the formal similarities in
the underlying laws governing those phenomena. The ﬁrst theoretical approach to fracture
mechanics dates back to the twenties with the work of Griﬃth [1], who formulated a theory
of crack formation, which is similar to the classical theory of nucleation in ﬁrst-order phase
transitions. Cracks grow or heal, depending on whether the external stress prevail over the
resistance at surface of the crack. Similarly in bubble nucleation [2], a critical droplet will
form when the change in free energy due to the bulk exceeds that of the surface. Griﬃth
theory assume the presence a single microcrack of a particular shape surrounded by an
homogeneous medium, and therefore is not appropriate in disordered systems, where cracks
can start from diﬀerent positions and coalescence may take place.

Spinodal nucleation [3], contrary to classical nucleation, is characterized by scaling prop-
erties and fractal droplets. The spinodal point in fact has some characteristics of a critical
point in second order phase transitions. The similarity between a solid driven to the thresh-
old of mechanical instability and spinodal nucleation has been discussed in the past. Rundle
and Klein [4], using a Landau-Ginzburg analysis of a single crack, showed that the crack
growth obeyed scaling laws expected for spinodal nucleation. Selinger et al. [5] have shown
by numerical simulations and mean-ﬁeld theory of thermally activated fracture that the
breakdown has the characteristics of a spinodal point.

In this paper we concentrate on disordered media and we disregard the eﬀect thermal
ﬂuctuations. The system is driven by an increasing external load to the point of global
failure. It has been experimentally observed that the response, detected by acoustic emission
(AE) measurements, to an increasing external stress takes place in bursts or avalanches
distributed over a wide range of scale. Examples of this are found in foam glasses [6], ﬁber
matrix composites [7], concretes [8], hydrogen precipitation [9] and volcanic rocks [10]. We

1

 
 
 
 
 
 
observe a similar behavior for two dimensional discrete models. We show that the scaling
behavior close to the breakdown is in quantitative agreement with the mean-ﬁeld theory and
it is suggestive of a ﬁrst-order transition. The values of the scaling exponents are consistent
with those found close to a spinodal point in thermally driven homogeneous systems.

THE MODELS

We study here two models, the random fuse model [11] for electric breakdown and a spring
network model [12] for fracture. In the random fuse model [11] each bond of a two dimen-
sional lattice is occupied by a fuse of conductivity σ = 1, which burns when the current
ﬂowing in it exceeds a quenched random threshold. We consider a rotated square lattice
with periodic boundary conditions in one direction. We impose a constant external current
on the two other edges of the lattice. The currents in each bond are computed solving the
kirchhoﬀ equations. This step corresponds to the minimization of the total energy dissipated
in the lattice

E({σ}) ≡

1
2

σi(∆V )2
i ,

X
i

(1)

where (∆V )i is the voltage drop in the bond i. We employ a multigrid relaxation algorithm
with precision ǫ = 10−10. When all the currents are below the threshold we increase the
current until the next bond reaches the threshold. The process is continued until a path
of broken bonds spans the lattice and no current ﬂows anymore. We chose a uniform
distribution of thresholds, D ∈ [0, 2].

The second model is an elastic network [12] which has central and rotationally invariant

bond-bending forces. The potential energy is

E =

a
2

X
i

(δri)2σi +

b
2

(δθij)2σiσj

X
<i,j>

(2)

where δri is the change in the length of the bond i and δθij is the change in the angle
between neighboring bonds i and j. The constant σi is equal to one if the bond is present
and it is zero otherwise. A slowly increasing external stress is applied on all the edges and
the lattice dynamics is obtained by numerically solving the equations of motion for each
spring. Bonds break when stretched beyond a randomly chosen threshold.

SIMULATION RESULTS

The response of the model to the increase of the external force takes place in widely dis-
tributed avalanches. The average size of the avalanches (i.e. the number of broken bonds)
increases when the global failure is approached. We were able to show [13] using mean-ﬁeld
theory that the average avalanche size hmi diverges at the breakdown as

hmi ∼ (fc − f )−γ

γ = 1/2.

(3)

where f is the stress or the current per unit length imposed on the lattice. We note that
the same scaling law is expected close to a spinodal point, in the case of thermally driven
ﬁrst-order transitions. The macroscopic quantities of the system (i.e. elasticity) have a
ﬁnite jump at the breakdown, indicative of a ﬁrst-order transition.

2

L = 128
L = 64
L = 32

0.10

 I/L

0.20

6.0

5.0

4.0

3.0

2.0

>
m
<

1.0

0.00

5e+03

4e+03

3e+03

f
d
/
φ
d

2e+03

0.00

0.05

0.10
f

0.15

0.20

Figure 1: a) The average avalanche size hmi is plotted as a function of f = I/L, the ﬁt is
done using the mean-ﬁeld value γ = 1/2. b) The “susceptibility” of the spring network with
the mean ﬁeld ﬁt (γ = 1/2). The parameter φ is the fraction of bond that are not broken.
The average avalanche size hmi is proportional to dφ/df .

We conﬁrm the validity of mean-ﬁeld scaling by computer simulations of two dimensional
models. For both models mean-ﬁeld theory is obeyed remarkably well (see Fig. 1a and
Fig. 1b).

The reason for the observed mean-ﬁeld behavior is probably due to the long-range nature
of elastic interactions. The formation of cracks in those models takes place by the coalescence
of several microcracks. This is conﬁrmed by the behavior of the average crack size which
does not diverge at the breakdown (see Fig 2).

DISCUSSION AND CONCLUSIONS

The breakdown of driven disordered media is described by scaling law which are reminiscent
of those found close to a spinodal point. It appears that the behavior of a driven disordered
system is similar to that of a thermally driven homogeneous system. This analogy is not
too strict since the concept of metastability and spinodal are not well deﬁned in the ﬁrst
case.

Despite several experimental investigations of avalanche dynamics in fractures [6, 7, 8,

3

 
4.0

3.0

2.0

>
s
<

L=128
L=64
L=32
L=16

1.0

0.0

10.0

I

20.0

30.0

Figure 2: The average crack size for the fuse model as a function of the current for diﬀerent
systems sizes. The crack size does not seem to diverge at the breakdown.

9, 10], there is not a clear theoretical interpretation of the results. We believe that diﬀerent
experimental conditions can all give rise to similar scaling behavior, but the underlying
physical mechanisms could be quite diﬀerent. We can distinguish the following experimental
setups:

1. A solid driven by a constant stress rate can be described in the framework discussed
in this paper. The system responds to the increase of the external load by AE bursts
of increasing size [7], diverging at the point of global failure. It would be interesting
to check if the scaling exponents agree with the mean-ﬁeld theory.

2. A solid subject to a constant load breaks because of thermal ﬂuctuations. The AE
is due to the formation of “droplets” and should be power law distributed close to
the limit of stability (spinodal). Scaling exponents consistent with those of spinodal
nucleation were observed in a recent experiment on cellular glass [6]. To conﬁrm this
interpretation it would be necessary to study the scaling for diﬀerent values of the
applied load.

3. A solid in a perfectly plastic state could respond to the increase of the external strain
by a stationary AE signal. In this case one can interpret the results as a manifestation
of self-organized criticality. Such a behavior was shown in numerical models [14, 15],
but to our knowledge it has not yet been observed in experiments.

We believe that extensive and systematic experiments along these lines can resolve these
longstanding problems.

ACKNOWLEDGMENTS

We wish to thank P. Cizeau, W. Klein, F. Sciortino and H. Strauven for useful discussions
and remarks. The Center for Polymer studies is supported by NSF.

References

4

[1] A. A. Griﬃth, Phil. Trans. Roy. Soc. London A 221, 163 (1920).

[2] J. D. Gunton, M. San Miguel and P. S. Sahini,

in Phase Transitions and
Critical Phenomena, Vol. 8, edited by C. Domb and J. L. Lebowitz (Academic, London,
1983).

[3] C. Unger and W. Klein, Phys. Rev. B 29, 2698 (1984); ibid.31, 6127 (1985); for a

review, see L. Monette, Int. J. of Mod. Phys B 8, 1417 (1994).

[4] J. B. Rundle and W. Klein, Phys. Rev. Lett. 63, 171 (1989)

[5] R. L. B. Selinger, Z.-G. Wang, W. M. Gelbart and A. Ben-Saul, Phys. Rev. A 43, 4396

(1991).

[6] H. Strauven, G. Claes, G. Heylen, G. Crevecoer and C. Maes,

in 22nd European

Conference on Acoustic Emission Testing Proceedings (Aberdeen, 1996)

[7] J.-C. Anifrani, C. Le Floc’h, D. Sornette and B. Souillard, J. de Phys. I 5, 631 (1995).

[8] A. Petri, G. Paparo, A. Vespignani, A. Alippi and M. Costantini, Phys. Rev. Lett. 73,

3423 (1994).

[9] G. Cannelli, R. Cantelli and F. Cordero, Phys. Rev. Lett. 70, 3923 (1993).

[10] P. Diodati, F. Marchesoni and S. Piazza, Phys. Rev. Lett. 67, 2239 (1991).

[11] L. de Arcangelis, S. Redner and H. J. Herrmann, J. Phys. Lett. (Paris) 46, L585 (1985);

P. Duxbury, P. D. Beale and P. L. Leath, Phys. Rev. Lett. 57, 1052 (1986).

[12] P. Ray and G. Date, Physica A 229, 26 (1996).

[13] S. Zapperi, P. Ray, H. E. Stanley and A. Vespignani, unpublished.

[14] S. Zapperi, A. Vespignani and H. E. Stanley in Fracture-Instability Dynamics,
Scaling and Ductile/Brittle Behavior, edited by R. B. Selinger, J. Mecholsky, E. R.
Fuller, Jr. and A. Carlsson (Mat. Res. Soc. Proc. 409, Pittsburgh, 1996) pp. 355-358.

[15] H. J. Tillemans and H. J. Herrmann, Physica A 217, 261 (1995).

5"
First-Order Transition in the Breakdown of Disordered Media,"  We study the approach to global breakdown in disordered media driven by
increasing external forces. We first analyze the problem by mean-field theory,
showing that the failure process can be described as a first-order phase
transition, similarly to the case of thermally activated fracture in
homogeneous media. Then we quantitatively confirm the predictions of the
mean-field theory using numerical simulations of discrete models. Widely
distributed avalanches and the corresponding mean-field scaling are explained
by the long-range nature of elastic interactions. We discuss the analogy of our
results to driven disordered first-order transitions and spinodal nucleation in
magnetic systems.
",http://arxiv.org/pdf/cond-mat/9612095v1,2,"6
9
9
1
c
e
D
0
1

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
5
9
0
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

First-Order Transition in the Breakdown of Disordered Media

Stefano Zapperi1, Purusattam Ray2, H. Eugene Stanley1 and Alessandro Vespignani3
1Center for Polymer Studies and Department of Physics, Boston University, Boston, Massachusetts 02215
2The Institute of Mathematical Sciences, CIT Campus, Madras - 600 113, India
3Instituut-Lorentz, University of Leiden, P.O. Box 9506, 2300 RA, Leiden, The Netherlands.
(April 23, 2018)

We study the approach to global breakdown in disordered media driven by increasing external
forces. We ﬁrst analyze the problem by mean-ﬁeld theory, showing that the failure process can be
described as a ﬁrst-order phase transition, similarly to the case of thermally activated fracture in
homogeneous media. Then we quantitatively conﬁrm the predictions of the mean-ﬁeld theory using
numerical simulations of discrete models. Widely distributed avalanches and the corresponding
mean-ﬁeld scaling are explained by the long-range nature of elastic interactions. We discuss the
analogy of our results to driven disordered ﬁrst-order transitions and spinodal nucleation in magnetic
systems.

PACS numbers: 5.70.Ln 64.60.Fr 62.20.Mk

The breakdown of solids under external forces is a long-
standing problem that has both theoretical and practical
relevance [1]. The ﬁrst theoretical approach to fracture
mechanics, proposed by Griﬃth [2] more than 75 years
ago, is similar to the classical theory of nucleation in
ﬁrst-order phase transitions [3]. An elastic solid under
stress is in a “metastable state” and will decay to the
“stable fractured state” by the formation of cracks. Re-
cently it has been shown [4] that the point of zero external
stress has the same mathematical properties as the con-
densation point in gas-liquid ﬁrst-order transitions.
In
the language of phase transitions, the stress imposed on
the solid plays the role of an external ﬁeld and cracks are
the analog of droplets of a new phase. The classical the-
ory of nucleation is expected to fail close to the limit of
stability, the spinodal point [5] and it has been suggested
[6–9] that a similar behavior should occur for fracture,
for large values of the external stress. Thus, the failure
threshold corresponds to the spinodal point of ﬁrst-order
phase transitions.

The Griﬃth theory and related calculations deal with
the situation in which fracture is thermally activated and
quenched disorder is absent or weak.
In many realis-
tic situations, however, the solid is not homogeneous,
and disorder, in the form of vacancies or microcracks,
strongly aﬀects the nucleation process [8,9]. There are
situations, encountered for example in material testing,
in which the system is driven by an increasing external
stress [10,11] and the time scale of thermal ﬂuctuations is
much larger than the time scale induced by the driving.
In those cases, the system can be eﬀectively considered
as being at zero temperature, so only quenched disorder
is relevant. It has been experimentally observed [10–14]
that the response (acoustic emission) of stressed disor-
dered media takes place in bursts of widely distributed
intensity, indicative of an internal avalanche dynamics.

The understanding of the breakdown of disordered sys-
tems has considerably progressed due to the use of large

scale simulations of lattice models [15]. These mod-
els have provided a good description of geometrical and
topological properties of cracks, leading to the introduc-
tion in this ﬁeld of scaling concepts. Recently, these
models have also been used to study the dynamic re-
sponse of the system before breakdown [16–20]. Scaling
and power-law avalanche distributions were observed, in
agreement with experiments, but a clear theoretical in-
terpretation of the results is still lacking. Here, we ad-
dress the problem by mean-ﬁeld calculations and numeri-
cal simulations. The picture that emerges from our anal-
ysis is that the breakdown in disordered media can be
described by a ﬁrst-order transition, similarly to the case
of thermally-activated homogeneous fracture. Since elas-
tic interactions are long-range, scaling behavior may be
present also in low dimensions, in analogy with spinodal
nucleation [5].

The models we will consider are deﬁned for a two-
dimensional lattice of linear size L. Each bond of the
lattice represent an elastic spring that breaks when it is
stretched beyond a threshold chosen from a given proba-
bility distribution. An external stress is imposed on the
system by suitably chosen boundary conditions. A simple
example, because of the scalar nature of the interactions,
is the random fuse model [21] for electric breakdown. To
each bond i is associated a resistor of unit conductivity
(σi = 1). When the current in the bond exceeds a thresh-
old Di the bond becomes an insulator (σi = 0). A slowly
increasing external current [22] is imposed on the lattice
and the voltage drops (∆V )i for each bond are computed
by minimizing the total dissipated energy

E({σ}) ≡

1
2

i
X

σi((∆V )2

i − D2
i ).

(1)

The dynamics of the model results from a double mini-
mization process. The voltage drops (∆V )i are obtained
by a global minimization of the energy at ﬁxed σi, while

1

 
 
 
 
 
 
the σi are then chosen to minimize the local bond en-
ergy. This last step corresponds to breaking the bonds for
which the current overcomes the threshold. The external
current is increased slowly until the lattice is no longer
conducting. We note that this dynamics is very similar
in spirit to that of a ﬁeld-driven random-ﬁeld Ising model
(RFIM), studied by Sethna et al. [23,24] in the context
of magnetic hysteresis. In that model, each spin chooses
the sign of the local ﬁeld.

To derive a mean-ﬁeld theory, it is useful to recast the
dynamics of the model in terms of the externally applied
current I. In full generality, we can rewrite the energy of
Eq. (1) as

E(I, {σ}) =

I 2
G({σ})

1
2  

, −

σiD

2
i

!

i
X

(2)

where G({σ}) is the total conductivity of the lattice and
is a complicated function of the local conductivities. We
can estimate G({σ}) using the eﬀective medium theory
[25], which in our case gives

2
G({σ}) = φ − Aφ(1 − φ) + O((1 − φ)

),

(3)

i σi/L2, and A ≃ 1.52. Using only the ﬁrst
where φ ≡
term of the expansion, we can express the energy as a
sum over “spins” interacting with eﬀective random ﬁelds
hi

P

EMF (I, {σ}) =

σihi =

i
X

1
2

σi

i
X

(cid:18)

I 2
(Lφ)2 − D

2
i

. (4)

(cid:19)

the value of φ can be computed self-consistently as

φ = P (hi > 0) = 1 −

I
Lφ

0
Z

ρ(D)dD,

(5)

where ρ(D) is the distribution of failure thresholds. The
solution of this equation can be expressed in terms of the
current per unit length f ≡ I/L. We can identify f with
the external ﬁeld and φ with the order parameter.

From considerations similar to those presented in
Ref. [24], we can show that for any analytic [26] nor-
malizable distribution function ρ Eq. (5) has a solution
for f < fc and, close to fc, φ scales as

φ − φc ∼ (fc − f )1/2.

(6)

This scaling law is also valid if we include higher order
terms from Eq. (3). The mean-ﬁeld theory we have pre-
sented can be exactly mapped to the democratic ﬁber-
bundle model (DFBM), an exactly solvable model for
fracture which has been studied extensively [27]. We can,
therefore, obtain the mean-ﬁeld avalanche size distribu-
tion from the exact results derived for the DFBM [27]

P (m) ∼ m

−τ f (m(fc − f )κ);

τ =

3
2

, κ = 1,

(7)

2

where m is the number of bonds that break as function
of the current. The average avalanche size hmi is propor-
tional to the “susceptibility” dφ/df [17], and therefore
diverges at the breakdown as
−γ

hmi ∼ (fc − f )

γ = 1/2.

(8)

The exponents we have introduced satisfy the scaling re-
lation κ(2 − τ ) = γ, which is consistent with the values
reported in Eq. (7) and Eq. (8). The mean-ﬁeld analysis
indicates that the system is undergoing a ﬁrst order tran-
sition since the order parameter has a discontinuity and
the conductivity at fc has a ﬁnite jump from G(φc) > 0
to zero. The approach to this transition is characterized
by avalanches of increasing size, diverging at the transi-
tion.

A similar behavior with the same scaling exponents is
observed in the mean-ﬁeld theory of the driven RFIM
[23,24] for small disorder.
In the RFIM, one observes
also a second order transition as the width of the disor-
der is increased. A similar transition does not seem to
be present in our system, at least not in the mean-ﬁeld
treatment.
It is also interesting to note that the same
scaling laws describe metastable systems close to a spin-
odal point. The quasistatic susceptibility diverges as in
Eq. (8) and droplets are distributed according to Eq. (7).
An important issue to address at this point is the
validity of mean-ﬁeld results in the case of real low-
dimensional systems. It is known that scaling does not
hold close to the ﬁrst-order transition for short-ranged
RFIM in dimensions d = 2, 3 [23,24]. Similarly, spinodal
singularities are observed when interactions are long-
range [28]. Elastic interactions are intrinsically long-
range, which leads to mean-ﬁeld behavior even for low
dimensions, as we will next show numerically. We sim-
ulate the random fuse model [21] on a tilted square lat-
tice, with periodic boundary conditions in the transverse
direction. The current in each bond is computed numer-
ically by solving the Kirchhoﬀ equations with a preci-
sion ǫ = 10−10. The distribution of thresholds is chosen
to be uniform in the interval [1 − ∆, 1 + ∆]. We made
the choice ∆ = 1 in order to avoid the “ductile-brittle”
crossover at a ﬁnite value of the lattice size [21]. Other
broad analytic distributions give rise to similar results.
We impose an external current I through the lattice and
we increase it at an inﬁnitesimal rate. When a bond fails,
we recompute the currents to see if other failures occur.
The system responds to the increase of the current with
avalanches whose size m diverges at the breakdown fc.
In Fig. 1 we plot the average avalanche size hmi versus
I/L and we see that the mean-ﬁeld exponent γ = 1/2 ﬁts
the data quite well. The data collapse is not perfect be-
cause logarithmic corrections are expected in d = 2 [21].
The avalanche size distribution, integrated over the entire
range of the current, is plotted in Fig. 2. We see that the
scaling is consistent with an exponent τ ′ = τ +1/κ = 5/2,
which results from the mean-ﬁeld calculations [Eq. (7)].
As expected the cutoﬀ of the distribution increases with
L.

We have studied the behavior of the average crack size
hsi as a function of the current. Although the crack size
grows with the current, it does not appear to diverge at
the breakdown when the system size is increased. This
implies that the ﬁnal macroscopic crack is formed by the
coalescence of several microcracks, rather than by the
growth of a single crack. In fact, by monitoring the dy-
namics, we observe that avalanches are not spatially con-
nected since interactions are long-range; this may be the
reason why mean-ﬁeld works so well for these systems.
Finally, we have checked that the conductivity of the lat-
tice displays a ﬁnite jump at the ﬁrst-order transition.

The mean-ﬁeld theory was derived for the case of a
scalar model, but the results do not only apply to scalar
models. We have numerically simulated a more com-
plex vectorial model, deﬁned in Ref. [18]. The model
is a spring network with central and bond bending
forces, with random failure thresholds associated with
each bond. The system is driven by an increasing exter-
nal stress f and the dynamics is obtained by numerically
integrating the equations of motion of the springs. The
model gives a more reliable description of the fracture
process, taking into account the tensorial nature of the
elastic interactions and a realistic relaxation dynamics.
In this case we also ﬁnd power-law distributed avalanches
and mean-ﬁeld exponents (see Fig. 3). A detailed account
of the results of this model, as well as a complete discus-
sion of the random fuse model, will be reported elsewhere
[29].

The results we have discussed clarify the nature of the
breakdown process in the presence of quenched disor-
der. We have shown that the breakdown corresponds to
a ﬁrst-order transition, with avalanche precursors char-
acterized by power laws. The scaling exponents are in
quantitative agreement with the prediction of mean-ﬁeld
calculations.
In mean-ﬁeld theory, driven disordered
systems behave similarly to their homogeneous, ther-
mally driven, counterparts, if we compare the scaling of
avalanches with that of the droplets. This applies to the
RFIM [23,24], which shows features similar to those of
spinodal nucleation [5], and to the fracture models we
have studied. However, one should be careful not to in-
terpret these analogies too strictly, since in driven disor-
dered systems the notions of metastability, spinodal point
and nucleation are not well deﬁned.

Finally, we comment on the applicability of self-
organized criticality (SOC) [30] to fracture problems. In
fact, ﬁrst-order transitions and SOC are becoming the
principal competing theoretical frameworks for the inter-
pretation of avalanche phenomena in disordered systems.
A striking example of this controversy is represented by
earthquake phenomena [31]. The deﬁnition of SOC im-
plies a slowly driven system with a critical stationary
state [32]. The only possibility to observe SOC behav-
ior in fracture phenomena is in the presence of a long
lived plastic state before rupture. Recently proposed
scalar models [33] of microfractures and molecular dy-
namics simulations of granular solids under shear [34]

have shown that the plastic stationary state is character-
ized by power law avalanche distributions suggestive of
SOC. On the other hand, the model studied in Ref. [19],
that was claimed to display SOC, has no stationary state,
like the models discussed here. Power laws without cutoﬀ
in this case arise not due to self-organization, but because
the control parameter is externally “swept” towards the
instability (as pointed out by Sornette [35]). We believe
that diﬀerent experimental conditions can all give rise
to similar scaling behavior, but the underlying physical
mechanisms could be quite diﬀerent.

The Center for Polymer Studies is supported by the
NSF. We thank P. Cizeau, W. Klein and F. Sciortino for
interesting discussions and remarks.

[1] K. K. Bardhan, B. K. Chakrabarti and A. Hansen (eds.),
Non-linearity and Breakdown in Soft Condensed Matter
(Springer-Verlag, Berlin/New York, 1994).

[2] A. A. Griﬃth, Phil. Trans. Roy. Soc. London A 221, 163

(1920).

[3] J. D. Gunton, M. San Miguel and P. S. Sahini, in Phase
Transitions and Critical Phenomena, Vol. 8, edited by C.
Domb and J. L. Lebowitz (Academic, London, 1983).
[4] A. Buchel and J. P. Sethna, Phys. Rev. Lett. 77, 1520

(1996); preprint cond-mat/9610008.

[5] C. Unger and W. Klein, Phys. Rev. B 29, 2698 (1984);
ibid. 31, 6127 (1985); for a review, see L. Monette, Int.
J. of Mod. Phys B 8, 1417 (1994).

[6] J. B. Rundle and W. Klein, Phys. Rev. Lett. 63, 171

(1989)

[7] R. L. B. Selinger, Z.-G. Wang, W. M. Gelbart and A.

Ben-Saul, Phys. Rev. A 43, 4396 (1991).

[8] R. L. B. Selinger, Z.-G. Wang and W. M. Gelbart, J.

Chem. Phys. 95, 9128 (1991).

[9] L. Golubovic and A. Pedrera, Phys. Rev. E 51, 2799
(1995); L. Golubovic and S. Feng, Phys. Rev. A 43, 5223
(1991).

[10] H. Strauven, G. Claes, G. Heylen, G. Crevecoer and C.
Maes, in 22nd European Conference on Acoustic Emis-
sion Testing Proceedings, (Aberdeen, 1996).

[11] J.-C. Anifrani, C. Le Floc’h, D. Sornette and B. Souil-

lard, J. de Phys. I 5, 631 (1995).

[12] A. Petri, G. Paparo, A. Vespignani, A. Alippi and M.

Costantini, Phys. Rev. Lett. 73, 3423 (1994).

[13] G. Cannelli, R. Cantelli and F. Cordero, Phys. Rev. Lett.

70, 3923 (1993).

[14] P. Diodati, F. Marchesoni and S. Piazza, Phys. Rev. Lett.

67, 2239 (1991).

[15] H.J. Herrmann and S. Roux (eds.), Statistical Models for
the Fracture of Disordered Media (North Holland, Ams-
terdam, 1990).

[16] F. Tzschichholz and H. J. Herrmann, Phys. Rev. E 51,

1961 (1995).

[17] M. Acharaya and B. K. Chakrabarti, Phys. Rev. E 53,

3

FIG. 1. The average avalanche size hmi

−1/γ is plotted as
a function of I/L, using the mean-ﬁeld value γ = 1/2. The
curves are averaged over several realizations of the disorder
(N = 500 for L = 32, N = 100 for L = 64, 128). The crit-
ical current of the random fuse model Ic/L has logarithmic
corrections, so the curves do not superpose.

100

10-1

10-2

10-3

10-4

)

m
(
P

10-5

100

L = 128
L = 16

101
m

102

FIG. 2. The avalanche size distribution for a random fuse
model of size L = 32 and L = 128 is plotted in log-log scale.
A line with the mean ﬁeld value τ ′ = 5/2 of the exponent is
plotted for reference. The cutoﬀ of the distribution increases
with the system size.

2.5e−07

γ
/
1
−

)
f
d
/
φ
d
(

1.5e−07

5e−08

0.00

0.05

f

0.10

FIG. 3. The suscptibility dφ/df for the spring network of
size L = 50, averaged over N = 100 conﬁgurations, is plot-
ted as function of the applied stress f . Mean-ﬁeld scaling
(γ = 1/2) appears to be very good also in this case.

140 (1996); M. Acharaya, P. Ray and B. K. Chakrabarti,
Physica A 224, 287 (1996)

[18] P. Ray and G. Date, Physica A 229, 26 (1996).
[19] G. Caldarelli, F. Di Tolla and A. Petri, Phys. Rev. Lett.

77, 2503 (1996).

[20] M. Sahimi and S. Arbabi, Phys. Rev. Lett. 77, 3689

(1996).

[21] L. de Arcangelis, S. Redner and H. J. Herrmann, J. Phys.
Lett. (Paris) 46, L585 (1985); P. Duxbury, P. D. Beale
and P. L. Leath, Phys. Rev. Lett. 57, 1052 (1986); B.
Kahng, G. G. Batrouni, S. Redner, L. de Arcangelis and
H. J. Herrmann, Phys. Rev. B 37, 7625 (1988); L. de
Arcangelis and H. J. Herrmann, Phys. Rev. B 39, 2678
(1989).

[22] The total current represents the electric analog of the
applied load, while the voltage drop corresponds to the
strain.

[23] J. P. Sethna, K. Dahmen, S. Karta, J. A. Krumhansl and

J. D. Shore, Phys. Rev. Lett. 70, 3347 (1993).

[24] K. Dahmen and J. P. Sethna, Phys. Rev. B 53, 14872

(1996).

[25] S. Kirkpatrik, Rev. Mod. Phys. 45, 574 (1973).
[26] The results are also valid in the case of the uniform dis-
tribution we use in simulations, as can be shown by a
direct calculation.

[27] H. E. Daniels, Proc. Roy. Soc. London A 183, 405 (1945).
S. L. Phoenix and H. M. Taylor, Adv. Appl. Prob. 5, 200
(1973); P. C. Hemmer and A. Hansen, J. Appl. Mech.
59, 909 (1992); D. Sornette J. Phys. A 22, L243 (1989);
J. Phys I (France) 2, 2089 (1992).

[28] D. Heermann, W. Klein and D. Stauﬀer, Phys. Rev. Lett.
49 1262 (1982); T. Ray and W. Klein, J. Stat. Phys. 61,
891 (1990).

[29] S. Zapperi, P. Ray, H. E. Stanley and A. Vespignani, to

be published.

[30] P. Bak, C. Tang and K. Wiesenfeld, Phys. Rev. Lett. 59,

381 (1987).

[31] A SOC model for earthquakes is presented in Z. Olami, H.
J. S. Feder and K. Christensen, Phys. Rev. Lett. 68, 1244
(1992). An interpretation of the phenomenon in terms of
spinodals and ﬁrst order-transitions is discussed in J. B.
Rundle, W. Klein and S. Gross, Phys. Rev. Lett. 76, 4285
(1996).

[32] A. Vespignani, S. Zapperi and V. Loreto, Phys. Rev. Lett.

77, 4560 (1996)

[33] S. Zapperi, A. Vespignani and H. E. Stanley, Mat. Res.

Soc. Proc. 409, 355 (1996).

[34] H. J. Tillemans and H. J. Herrmann, Physica A 217, 261

(1995).

[35] D. Sornette, J. Phys. I (France) 4, 209 (1994).

1.0

γ
/
1
−

0.5

>
m
<

L = 128
L = 64
L = 32

0.0

0.00

0.10

 I/L

0.20

4"
Modeling Acoustic Emission in Microfracturing Phenomena,"  It has been recently observed that synthetic materials subjected to an
external elastic stress give rise to scaling phenomena in the acoustic emission
signal. Motivated by this experimental finding we develop a mesoscopic model in
order to clarify the nature of this phenomenon. We model the synthetic material
by an array of resistors with random failure thresholds. The failure of a
resistor produces an decrease in the conductivity and a redistribution of the
disorder. By increasing the applied voltage the system organizes itself in a
stationary state. The acoustic emission signal is associated with the failure
events. We find scaling behavior in the amplitude of these events and in the
times between different events. The model allows us to study the geometrical
and topological properties of the micro-fracturing process that drives the
system to the self-organized stationary state.
",http://arxiv.org/pdf/cond-mat/9612096v1,2,"MODELING ACOUSTIC EMISSION IN MICROFRACTURING
PHENOMENA

1

S. ZAPPERI†, A. VESPIGNANI‡ AND H.E. STANLEY†
† Center for Polymer Studies and Department of Physics, Boston University, Boston, MA
02215 ,USA
‡ Instituut-Lorentz, University of Leiden, P.O. Box 9506 The Netherlands.

ABSTRACT

It has been recently observed that synthetic materials subjected to an external elastic stress
give rise to scaling phenomena in the acoustic emission signal. Motivated by this experimen-
tal ﬁnding we develop a mesoscopic model in order to clarify the nature of this phenomenon.
We model the synthetic material by an array of resistors with random failure thresholds.
The failure of a resistor produces an decrease in the conductivity and a redistribution of
the disorder. By increasing the applied voltage the system organizes itself in a stationary
state. The acoustic emission signal is associated with the failure events. We ﬁnd scaling
behavior in the amplitude of these events and in the times between diﬀerent events. The
model allows us to study the geometrical and topological properties of the micro-fracturing
process that drives the system to the self-organized stationary state.

INTRODUCTION

Acoustic Emission (AE) is produced by sudden movements in stressed systems. Several
experiments have recently observed this phenomenon on very diﬀerent length scales (from
the largest scale of an earthquake to the smallest one of dislocation motions) [1, 2, 3].
Unfortunately, the AE analysis is a rather elicate technique since each external stress is
unique and tests the whole sample. For instance, it is very diﬃcult to obtain in this way
insight on the microscopic dynamics of the fracturing phenomena. The statistical analysis,
however, gives rise to the hypothesis that AE is generated by fracturing phenomena which
are similar to critical points. Correlations develops leading to cascade events which drive
the systems into a critical stationary state. For this reason, as a working hypothesis, the
mechanism of Self-Organized Criticality (SOC) [4] has been invoked.

The understanding of this statistical behavior calls for a model that can simulate the
fracturing phenomenon. Unfortunately, the models usually considered describe the forma-
tion of a macroscopic crack [5]. These can therefore model AE of fracturing phenomena on
mesoscopic scale culminating in a large event that change the system’s properties dramati-
cally [6]. This is very diﬀerent from the stationary state generated by stressing the sample
below the breaking threshold of the system. In fact, in this case the fracturing phenomenon
produces an energy release that changes the physical properties in a non destructive way
(like the passage to a diﬀerent metastable state).

Here we show a statistical model for fracturing phenomena, where the rupture burst and
the following energy release changes the properties but does not destroy the system. This

6
9
9
1
c
e
D
0
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
6
9
0
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

 
 
 
 
 
 
S. Zapperi et. al., Mat. Res. Soc. Proc. Vol.409, pag. 355 (1996)

2

allows us to obtain a stationary state for AE of which we can investigate the statistical
properties in space, time and magnitude.

THE MODEL

The mesoscopic description of an elastic disordered medium is obtained discretizing macro-
scopic elastic equations. In the theory of linear elasticity, these equations relate the stress
tensor sαβ to the strain tensor ǫγδ via the Hooke tensor Cαβγδ. The full tensorial formal-
ism is quite heavy to handle numerically. A compromise is obtained by considering scalar
elastic equations. In fact the phenomenology of fractures in scalar models captures many
essential features of more complex tensorial models. Scalar elasticity is formally equivalent
to electricity, provided one identiﬁes the current I with the stress, the voltage V with the
strain and the conductivity σ with the Hooke tensor.

The discretization scheme we use corresponds to the study a resistor network. For
symmetry reason we will consider a rotated square lattice. The disorder, due to the inho-
mogeneity in the synthetic material, is introduced in the model in the failure thresholds
Ic of the resistors. For simplicity we will use an uniform distribution. The crucial part of
the model is the breaking criterion, which describe the dynamics of the micro-fracturing
process. Typically the breaking criterion is chosen so that if the current ﬂowing in a resistor
exceed the failure threshold the conductivity of the bond drops abruptly to zero. In this
way the system develops a macroscopic crack and the lattice breaks apart. To describe the
micro-fracturing phenomena in the stage preceding the onset of the macroscopic crack it
is useful to consider the concept of damage. For a macroscopic elastic material, in which
micro-fracturing processes are taking place, the damage D is a tensor relating the eﬀective
Hooke tensor ˆC to the Hook tensor of the undamaged material. The damage is deﬁned as
D = I − C ˆC −1. For scalar elasticity the damage is just a constant relating the eﬀective re-
sistance of the damaged material to that of the undamaged one. We generalize the concept
of damage from the macroscopic to the mesoscopic description, using it in the breaking cri-
terion. When the current in a bond exceeds the threshold we impose a permanent damage
to the bond. In other words, the conductivity of the bond drops by a factor a = (1 − D).
In the synthetic materials we are describing, after a micro-fracturing event, local rear-
rangements take place. We model this eﬀect by changing at random the breaking threshold
of the damaged bond as well as those of the neighboring bonds. This rearrangement of
the disorder emphasize the probability of breaking successively neighboring bonds. In crack
models this process is enforced by imposing the connectivity of the crack or by similar rules.

SIMULATION RESULTS

To simulate the model we start from an undamaged lattice where the conductivities are
equal to one for all the bonds. The breaking threshold are chosen at random between zero
and one. We then impose an external voltage between two edges of the lattice and we use
periodic boundary conditions in the other direction.

S. Zapperi et. al., Mat. Res. Soc. Proc. Vol.409, pag. 355 (1996)

3

The voltage is increased until the current in some bond exceed the threshold. When this
happens we apply the breaking rule and we check if subsequent failures occurs. In fact due to
the long range elastic interactions combined with the redistribution of the disorder, a single
failure can be followed by other similar events, thus generating an avalanche. We consider
the number of bonds that break in an avalanche to be proportional to the amplitude of the
emitted acoustic signal. In the early stage of the process only small avalanches occur and
the current carried by the material steadily increases. In this stage the damage is scattered
through the lattice in a random uniform way. After some time when some damage has
been accumulated into the system the activity starts to increase. Eventually the system
reaches a stationary state where the current does not increase anymore. In other words the
increase of the voltage is exactly balanced by the damage, in such a way that the current
is kept constant. In this state the damage is no longer homogeneously scattered, but tends
to be localized along lines. We are modeling an ideal case in which a bond can suﬀer a
very big damage without breaking completely. In fact we can slightly modify the model by
introducing a threshold in the conductivity after which the bond is consider broken (i.e. the
conductivity drops to zero). One can then easily understand that the regions of localized
damage are those where the macroscopic crack will eventually form and this is indeed what
we observe in our simulations.

The activity in this stationary state is highly ﬂuctuating and the distribution of ampli-
tude follows a power law. The scaling region increases with the system size and the fact is
a signature of an underlying critical state (see ﬁgure 1).

Another sign of the criticality of the system is provided by the distribution of time
intervals between subsequent avalanches. Since the voltage is increased linearly in time,
this corresponds to consider the distribution of voltage increases ∆V . The power law with
slope close to x = −1 is reminiscent of the Omori [7] law for fore-shocks in earthquakes.

CONCLUSIONS

In summary we have introduced a statistical model for fracturing phenomena. This model
describes on a mesoscopic scale the energy release and the following rearrangements in the
material produced by fracturing events. The simulations on the model show that the system
organizes itself in a stationary state where we can relate the AE signal with the rupture
events. We investigate the statistical properties of rupture sequences during fracturing and
their correlation properties. We ﬁnd that the stationary state develops critical correlations
and scaling behavior through a self-organization process. This kind of analysis is usually
considered in the study of experimentally detected AE signals and the proposed model could
give important clues in the understanding of the general scale invariance of the fracturing
phenomena. The Center for Polymer studies is supported by NSF.

References

S. Zapperi et. al., Mat. Res. Soc. Proc. Vol.409, pag. 355 (1996)

4

L=64
L=32
L=16

10-1

10-3

)
s
(
P

10-5

(b)

10-7

100

101

102
s

103

104

Figure 1: The avalanche distribution in the stationary state for diﬀerent system sizes.

[1] A. Petri, G. Paparo, A. Vespignani, A. Alippi and M. Costantini, Phys. Rev. Lett. 73,

3423 (1994)

[2] P. Diodati, F. Marchesoni and S. Piazza, Phys. Rev. Lett. 67 2239 (1991)

[3] G. Cannelli, R. Cantelli and F. Cordero, Phys. Rev. Lett. 70 3923 (1993)

[4] P.Bak ,C.Tang and K. Wiesenfeld, Phys. Rev. Lett. 59, 381 (1987).

[5] H.J. Herrmann and S. Roux (eds.), Statistical Models for the Fracture of Disordered

Media (North Holland, Amsterdam, 1990)

[6] F. Tzschichholtz and H. J. Herrmann, Phys. Rev. E, 51 1961 (1995).

S. Zapperi et. al., Mat. Res. Soc. Proc. Vol.409, pag. 355 (1996)
[7] F. Omori, J. Coll. Sci. Imper. Univ. Tokyo, 7, 111, (1894)

5"
Kinetics of Modulated and Ordered Structures in CuAu,"  A continuum model derived from an atomistic Hamiltonian is used to examine
the ordering kinetics in CuAu. A detailed description of the formation of the
low and high temperature ordered and modulated superlattice states is given.
The metastability of the modulated phase at low temperatures is shown to
severely hinder creation of the ordered superlattice. Formation of the
modulated superlattice is shown to results in interesting lamellar and
labyrinthine structures.
",http://arxiv.org/pdf/cond-mat/9612104v1,2,"6
9
9
1
c
e
D
1
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
4
0
1
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Kinetics of Modulated and Ordered Structures in CuAu.

K. R. Elder1,4, Nicholas A. Gross2, 3, Bulbul Chakraborty3 and Nigel Goldenfeld4.
1 Department of Physics, Oakland University, Rochester, MI, 48309-4401
2 Boston University, College of General Studies, 981 Commonwealth Ave., Boston, MA 02215.
3 Physics Department, Brandeis University, Waltham, MA 02254.
4 Department of Physics, University of Illinois at Urbana-Champaign, 1110 West Green Street, Urbana, Illinois 61801.
(August 15, 2018)

A continuum model derived from an atomistic Hamiltonian
is used to examine the ordering kinetics in CuAu. A detailed
description of the formation of the low and high tempera-
ture ordered and modulated superlattice states is given. The
metastability of the modulated phase at low temperatures is
shown to severely hinder creation of the ordered superlattice.
Formation of the modulated superlattice is shown to results
in interesting lamellar and labyrinthine structures.

05.70.Ln,64.60.Cn,81.30.Hd

The vast majority of synthetic and naturally occurring
materials contain long-lived non-equilibrium morpholo-
gies which determine material properties. Understand-
ing the non-equilibrium or kinetic processes that lead
to such microscopic structures is, therefore, one of the
most important tasks facing materials theory. The binary
alloy CuAu is an excellent material to study such pro-
cesses for the following reasons: the existence of a modu-
lated superlattice at intermediate temperatures gives rise
to a rich set of phase transformations and microstruc-
tures; the kinetics are accessible in x-ray scattering ex-
periments; and a continuum model for the kinetics has
been derived from a quantum mechanical description of
this alloy [1]. In this paper the continuum model will be
used to provide a detailed theoretical description of the
non-equilibrium processes that occur in CuAu. Thus pre-
dictions that can be veriﬁed experimentally are obtained
from a microscopic description of the alloy.

The continuum model predicts two ﬁrst order phase
transitions; one from a disordered superlattice to a mod-
ulated superlattice at T = TMD and the other from the
modulated phase to an ordered superlattice at T = TOM
(where TOM < TMD). The purpose of this paper is to
determine the transient morphologies that arise following
instantaneous temperature quenches that bring the sys-
tem from one equilibrium state to another. The results
of this study indicate that: the ordered superlattice is
diﬃcult to form just below TOM due to the creation of a
long-lived metastable modulated phase; the growth of an
ordered phase far below TOM is hindered by the presence
of ‘terminal’ droplets; and the nucleation of the modu-
lated phase from the low and high temperature phases
leads to labyrinthine and lamellar patterns respectively.
The appearance of the modulated superlattice was pre-
dicted from an atomistic model by Chakraborty and Xi

1

[1]. In this work, eﬀective medium theory [2,3] was em-
ployed to obtain an approximate classical Hamiltonian
from a full quantum mechanical model. A mean ﬁeld
analysis of this Hamiltonian was used to obtain the free
energy as a function of the average sublattice concentra-
tion (η) along one degenerate ordering direction. This
degeneracy can lead to interesting eﬀects but will not be
considered here. The free energy can be written,

F (η) = Fo + (2π/a)d

Z

d~r[aT η2 − uη4 + vη6

− e|~∇⊥η|2 + e| ~∇|||2 + f (∇2

⊥η)2],

(1)

where, aT = 0.042∆T meV /K, ∆T = T − To,
To = 1219K, u = 5.25meV , v = 6.1meV , e =
25.5meV /(2π/a)2 and f = 195.5meV /(2π/a)4 and a is
the shortest lattice parameter in the tetragonal struc-
ture of the low temperature CuAu(I) ordered phase. The
symbols ∇⊥ and ∇|| refer to gradients in the plane per-
pendicular and parallel to the ordering direction respec-
tively. At low, intermediate and high temperatures F
is minimized by ordered (i.e., η(~x) = ηo 6= 0), mod-
ulated (e.g., η(x, y, z) = η(x + λ, y, z)) and disordered
(i.e., η(~x) = 0) states respectively. The transitions from
the ordered to modulated phase and from the modulated
to disordered phase are both ﬁrst order and respectively
occur at ∆TOM ≈ −8.0K, and ∆TMD ≈ 44.4K [1,4].
The spinodal temperatures T S
M are deﬁned as the
temperatures above which the ordered and modulated
phases are unstable, while T S
D is deﬁned as the tempera-
ture below which the disordered state is unstable to the
modulated phase. The values of these temperatures are
O = To+35.7K, T S
M = To+52.6K and T S
T S
D = To+20.0K.
The kinetics are assumed to be relaxational and driven

O and T S

by minimization of the free energy:

∂η/∂t = −ΓδF /δη + ζ,

(2)

where ζ is a random Gaussian noise term with corre-
lations, hζ(~r, t)ζ(~r′, t′)i = 2kBT Γδ(~r − ~r′)δ(τ − τ ′) and
kB is the Boltzmann constant. It is convenient to intro-
duce the scaled variables; ~x = ~r/λo and τ = t/to where
2f /e and to = (a/2π)d2f /(e2Γ) to obtain;
λo =

p
∂η/∂τ = −(γ∆T + 2∇2

⊥ + ∇4

⊥ − 2∇2
+ u′η3 − v′η5 + ν.

||)η

(3)
Here, γ = 4aT f /e2, u′ = 8f u/e2, v′ = 12f v/e2,
hν(~x, τ )ν(~x′, τ ′)i = 2ǫδ(~x − ~x′)δ(τ − τ ′) and ǫ =

 
 
 
 
 
 
2kBT [a/2π]d[2f /e2][e/2f ]d/2. In these rescaled units the
modulated wavelength is simply 2π. To simplify calcula-
tions ordering in the parallel direction will be neglected.
The kinetics that follow a rapid quench are inﬂu-
enced by the modulated phase, even when the pre- and
post-quench temperatures are not within the modulated
regime. For example, consider the instantaneous quench
of a disordered state (Tinitial > TMD) into the ordered
regime (Tf inal < TOM ). The initial response will be to
form a modulated type structure, since linear stability
analysis predicts that the mode with q = 1 has the largest
growth rate [5]. For Tf inal < TOM the growth of the
q = 1 mode is much more rapid than q = 0, thus a ‘mod-
ulated’ structure is quickly formed. Further growth of the
q = 0 mode (i.e., the ordered phase) is inhibited by the
metastability of the modulated phase. Thus for quenches
just below TOM a long-lived transient modulated phase
should develop.

two dimensional nature of the ordering process.

To illustrate this eﬀect, consider the dynamics of a
single droplet of radius R in the limit R ≫ W , where W
is the domain wall thickness and is of the order 1. In this
limit η can be written η(r −R(τ )) ≈ η1d(r −R(τ )), where
η1d(x) is the one-dimensional solution of δF /δη = 0 with
boundary conditions η(x = ±∞) = ±ηo. Substituting
this result into Eq. (3), multiplying by (∂η1d/∂r) and
integrating from r = 0 to r = ∞ gives,

∂R/∂τ = 2(1 + σ3/σ1)R + 1/R3,

(4)

∞

0 dr(∂η1d/∂r)(∂iη1d/∂ri). The quantity
where σi ≡
2(1 + σ3/σ1) is less than zero for T < TOM . Thus the
R
droplet will shrink for R > RT and grow for R < RT ,
where RT is the ‘terminal’ droplet size and is equal to
RT = 1/
−2(1 + σ3/σ1). The growth rate of R is il-
lustrated in the inset of Fig. (1). While this calculation
correctly identiﬁes the existence of a terminal droplet, the
accuracy is hindered by the approximation R ≫ W . To
overcome this obstacle RT was determined numerically
and the results are shown in Fig. (1).

p

FIG. 1. In this ﬁgure the terminal droplet size is shown as
a function of temperature. The inset depicts the velocity of
the droplet radius as a function of R as described by Eq. (4).

For Tf inal ≪ TOM the diﬀerence between the q = 1
and q = 0 linear growth rates is insuﬃcient to cre-
ate a modulated structure. The subsequent dynamics
do not however reduce to that observed in standard or-
der/disorder transitions in which the average ordered do-
main size grows as t1/2 [6,7] and droplets shrink at a rate
proportional to the curvature. Here a droplet refers to
a spherical (or circular in 2-d) regime of one phase (e.g.,
η = −ηo) embedded in the other (e.g., η = +ηo).
In
CuAu, large droplets shrink but do not disappear. This
eﬀect can be traced to the fourth order spatial derivative
in the dynamics or equivalently, to the existence of the
length scale describing the modulated phase, and to the

FIG. 2. In this ﬁgure the linear dispersion for the position
of an antiphase domain boundary is shown as a function of
wavevector. The solid and open points represent wq in the
absence and presence of droplets respectively and the dashed
line corresponds to wq ∼ q2. In the inset ﬁgures (a) and (b)
show the interface relaxation in the absence of droplets and
in (c) and (d) in the presence of droplets at the same times.

The terminal droplets inﬂuence the late stage dynam-
ics by interfering with the motion of antiphase domain
walls or interfaces. For comparison it is useful to ﬁrst
consider the interface motion in the absence of droplets.
Consider a slowly varying interface such that η(x, y, τ ) ≈
ηo for x > h(y, τ ) and η(x, y, τ ) ≈ −ηo for x < h(y, t),

2

thus deﬁning the position of the antiphase domain wall
as h(y, t). If h(y, t) varies slowly in space it is simple to
show [4] that ∂h/∂τ = [−2(1 + σ3/σ1)∇2 + ∇4]h using
the methods discussed in the previous paragraph. The
solution in Fourier space is then; ˆh(q, τ ) = e−wqτ ˆh(q, 0),
where wq = −2(1+σ3/σ1)q2 +q4. In the long wavelength
limit (q ≪ 1) this reduces to the standard result for or-
der/disorder transitions (i.e., wq ∼ q2). To determine
the dispersion relationship (i.e., wq) in the presense of
terminal droplets numerical simulations were conducted
for the conﬁgurations shown in the inset of Fig. (2). The
results of these calculations (see Fig. (2)) indicate that
the relaxation of the antiphase domain walls is restrained
by the terminal droplets. This simple eﬀect will strongly
alter the late stage dynamics as the droplets tend to ac-
cumulate at interfaces [4]. This accumulation is not due
to an attraction between drops and interfaces, but rather
by droplets getting swept up by a relaxing interface.

The transient morphologies that emerge in the mod-
ulated regime depend on both the pre- and post-quench
states. If the pre-quench temperature is above TMD and
the post-quench temperature is between TOM and T S
D, η
is linearly unstable and a convoluted modulated struc-
ture will quickly emerge. Similar behavior will be ob-
served if the pre-quench temperature is below TOM and
the post-quench temperature is between T S
O and TMD.
In contrast, the kinetics are dominated by nucleation and
growth when the pre-quench state is metastable at the
post-quench temperature. In addition growth of the nu-
cleated droplets is not a simple process since there is
an internal structure within the drops. Each drop will
contain a lamellar structure that deﬁnes the modulated
phase. In general the velocity of the droplet fronts will
depend on the orientation of lamella with respect to the
droplet front and on the background matrix the droplet
is growing in. To understand this eﬀect it is useful to es-
timate the growth velocities in directions perpendicular
and parallel to the lamella as the drop grows into either
disordered or ordered backgrounds.

First consider the invasion of the modulated phase into
the ordered or disordered phase in a direction parallel to
the lamella. The velocity of this front will be denoted vO
||
and vD
for propagation into the ordered and disordered
||
phases respectively. To estimate vD
|| , η can be approxi-
mated as [ηo + η1d(y)]F O
|| (x, τ ) − ηo, where ηo is the value
of η in the ordered phase, η1d(y) is the one dimensional
modulated solution (i.e., η1d(y) ≈ A sin(qoy)) and the
overlap function F D
|| (x, τ ) takes the values 1 and 0 in the
modulated and ordered phases respectively. Substituting
this approximation into Eq. (3), multiplying by η1d(y),
and averaging over one wavelength in y gives,

∂F O

|| /∂τ = ( 1 − γ∆T + 3η
+ 2η2
+ 3(η2

3
ou′ − 5η
|| )2
o(10v′η2
o − 3u′)(F O
o + A2/4)(u′ − 10η2

ov′)(F O

|| )3

4
ov′ − ∂xxxx)F O
||

+ 5v′η2
− 5v′(η4

o + 3u′A2)(F O

o(4η2
o + 3ηoA2/2 + A4/8)(F O

|| )4

|| )5.

(5)

if η1d is approximated by a single Fourier mode. The
front velocity can be obtained by expanding around the
zero velocity limit which occurs at T = TOM . Substitut-
|| t) (were f O
ing the approximation, F O
||
is the solution of Eq. (5) at T = TOM , with boundary
conditions f O
|| (∞) = 0)) into Eq. (5)
and integrating over ∂f O

|| (−∞) = 1 and f O

|| (x, t) ≈ f O

ll (x − vO

|| (x)/∂x gives,

|| = 0.045(T − TOM )/σO
vO
|| ,

(6)

|| ≡

dx(∂f O

|| and leads to vD
dx(∂f D

The same tech-
|| =
|| (x)/∂x)2,
R
(5) with ηo = 0 at
|| (−∞) = 1 and
|| and σD
|| gives,

|| (x)/∂x)2.
where σO
R
niques can be used to estimate vD
|| , where σD
0.025(TMD − T )/σD
|| ≡
and f D
|| (x) is the solution of Eq.
T = TMD and boundary conditions f D
|| (∞) = 0. Numerically determining σO
f D
|| ≈ 0.13(T − TOM ) and vD
vO
Next consider growth in the direction perpendicular to
the lamella. For these calculations the velocities will be
denoted vO
⊥ for growth into the ordered and dis-
ordered regimes respectively. To estimate vD
⊥ , η can be
approximated as; η(x, τ ) ≈ η1d(x)F D
⊥ (x, τ ). Substituting
this expression into Eq. (3), multiplying by η1d(x), aver-
aging over one wavelength and assuming that F D
⊥ (x, τ )
varies slowly in space relative to the modulated wave-
length gives,

|| ≈ 0.12(TMD − T ).

⊥ and vD

∂F D

⊥ /∂τ = ( 1 − γ∆T + 4∂xx − ∂xxxx)F D
⊥

+ (3u′A2/4)(F D

⊥ )3 − (5v′A4/8)(F D

⊥ )5

(7)

⊥ numerically gives vD

if a one mode approximation for η1d is used. Employing
the method outlined above gives, vD
⊥ = 0.025(TMD −
T )/σD
Determining σD
⊥ ≈
⊥ .
0.19(TMD − T ). It is much more diﬃcult to estimate vO
⊥
since the solution can not be written as an overlap func-
tion times the modulated solution. Numerical attempts
to determine vO
⊥ indicate this velocity is extremely small,
in fact no growth in this direction was observed. Thus
to the accuracy of the current work vO
⊥ ≈ 0. The rea-
son for this slow growth is that the modulated solution
is very similar to the amplitude of the ordered solution
and consequently the spatial transition from the ordered
to modulated phase can be extremely sharp. In the limit
of an inﬁnitely sharp interface σ → ∞ and v → 0.

The results of these calculations indicate that for
quenches from the disordered phase the droplets will
grow asymmetrically in a direction perpendicular to the
leading to elongated lamella structures since
lamella,
vD
|| < vD
In contrast, for quenches from the ordered
⊥ .
phase vD
|| > vD
⊥ . Thus a small spherical nucleated droplet
will tend to sprout arms which will invade the neighbor-
ing territory. This growth leads to a labyrinth type struc-

3

ture similar to that observed in reacting chemical fronts
[8].

To illustrate the remarks of the preceding paragraphs
several numerical simulations were conducted, which are
illustrated in Fig. (3). The numerical algorithm is dis-
cussed in a previous paper [4] and is based on the cell
dynamics method [9]. Figures (3a) and (3b) respec-
tively show transient patterns that emerge from quenches
from the disordered regime to just below and far below
TOM . The highly interconnected morphology shown in
Fig.
(3a) is a long-lived metastable modulated struc-
ture that typically evolves only near defects. The deeper
quench (Fig. (3b)) shows that regions of high interface
curvature coincide with large concentrations of terminal
droplets, thus indicating the droplets inhibit interface re-
laxation and domain growth. Figures (3c) and (3d) are
transient patterns obtained by the nucleation of the mod-
ulated phase from quenches from the disordered and or-
dered regimes respectively. These ﬁgures show the lamel-
lar and labyrinthine type structures predicted in the pre-
ceding paragraphs.

dispersion will produce a modulated morphology. This
modulated structure will be long-lived since the mod-
ulated phase is metastable in the ordered regime. For
quenches far below TOM it was found that the formation
of the ordered phases are strongly inhibited by the ap-
pearance of terminal drops. Growth in this region will
be much slower than standard order/disorder transitions
since the droplets collect at antiphase boundaries and in-
hibit motion. For quenches into the modulated phases it
was found the initial state played an important role in
determining the transient morphologies. Quenches from
the ordered and disordered region respectively produced
labyrinthine and lamellar type structures.

Finally it is interesting to speculate on the asymp-
totic dynamics in the modulated regime.
In this case
the dynamics are controlled by the elimination of defects
and the relaxation of the orientation of the individual
lamella. Similar dynamics occur in the Swift Hohenberg
[10] model of Rayleigh-B´enard convection and lead to the
growth of domains of the same orientation growing at at
rate of t1/4 in the presence of thermal ﬂuctuations and
t1/5 in the absence of ﬂuctuations [11]. It is likely the
same growth exponent would be measured in this sys-
tem.

The authors would like to thank Bill Klein, Oana Malis
and Karl Ludwig for many useful discussions. KRE
acknowledges support of grant NSF-DMR-8920538 ad-
ministered through the U. of Illinois Materials Research
Laboratory. The work of BC and NAG was supported
by NSF grants DMR-9208084 (BC) and DMR-952093
(NAG). NG acknowledges support from NSF though
grant DMR-93-14938.

[1] B. Chakraborty and Z. Xi, Phys. Rev. Lett 68, 2039

(1992).

[2] K. W. Jacobsen, J. K. Norskov and M. J. Puska, Phys.

Rev. B 35, 7423 (1987)

[3] K. W. Jacobsen, Comments Cond. Mat. Phys. 14, 129

FIG. 3. Figures (a) and (b) are the transient patterns that
emerge following quenches from a disordered state. Figures
(a) and (b) are at τ = 182 and τ = 329 at quench tempera-
tures of T = TOM − 4K and T = TOM − 44K respectively.
Figure (c) is a pattern obtained by quenching from the disor-
dered state into the modulated regime at T = TOM + 39.5K
at τ = 57.3. Figure (d) is a pattern obtained by quench-
ing from the ordered state into the modulated regime at
T = TOM + 38K at τ = 84.0.

In summary several predictions for the kinetics of
phase transformations in CuAu have been made. For
quenches from the disordered to just below the or-
dered/modulated transition it is predicted that linear

4

(1988).

A224, 113 (1996).

[4] B. Chakraborty, K. Elder and N. Goldenfeld, Physica

[5] B. Chakraborty, Phys. Rev. B 49, 8608 (1994).
[6] S. Allen and J. Cahn, Acta Mettal. 23,1 (1975).
[7] J. D. Gunton, M. San Miguel and P. Sahni, in Phase
Transitions and Critical Phenomena, edited by C. Domb
and J. L. Lebowitz

[8] D. M. Petrich and R. E. Goldstein, Phys. Rev. Lett. 72,

1120 (1994).

[9] Y. Oono and S. Puri, Phys. Rev. A 58, 836 (1987).
[10] J. Swift and P. C. Hohenberg, Phys. Rev. A 15, 319

(1977).

[11] K. R. Elder, J. Vi˜nals and M. Grant, Phys. Rev. A 46,

7618 (1993); Phys. Rev. Lett. 68, 3024 (1992)."
Soliton and 2D domains in ultra-thin magnetic films,"  We show that many two dimensional domain patterns observed in Monte Carlo
simulations can be obtained from the many soliton solutions of the imaginary
time Sine Gordon equation. This opens the door to analytic physical
understanding of the micromagnetics in ultra-thin films.
",http://arxiv.org/pdf/cond-mat/9612204v1,2,"Soliton and 2D domains in ultra-thin magnetic ﬁlms

S. T. Chuia and V. N. Ryzhovb

a: Bartol Research Institute, University of Delaware, Newark, DE 19716

b:Institute for High Pressure Physics, Russian Academy of Sciences, 142 092 Troitsk, Moscow

region, Russia

Abstract

We show that many two dimensional domain patterns observed in Monte

Carlo simulations can be obtained from the many soliton solutions of the

imaginary time Sine Gordon equation. This opens the door to analytic phys-

ical understanding of the micromagnetics in ultra-thin ﬁlms.

There has been much experimental interest recently in the magnetism of ultra-thin ﬁlms.

[1,2] partly motivated by the possible integration of the semi-conductor microelectronics

technology with magnetic elements [1] and possible device applications with the giant mag-

netoresistive (GMR) eﬀect. From a fundamental physics viewpoint, these systems present

opportunities for studying new phenomena that are beginning to be uncovered. The inter-

action energy between the spins at positions R, R′ is

H = 0.5

Xij=xyz,RR′

Vij(R

−

R′)Si(R)Sj(R′)

where V = Vd + Ve + Va is the sum of the dipolar energy Vdij(R) = g

(1)

i

∇

∇

j(1/

R

|

|

); the

exchange energy Ve =

Jδ(R = R′ + d)δij; and the crystalline anisotropy energy Va. Here d

−

denotes the nearest neighbours. g and J are coupling constants. The form of the anisotropy

6
9
9
1
c
e
D
3
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
4
0
2
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

energy depends on the material of interest. It can be uniaxial (e.g. Va =

K

−

i S2

ix) or

P

four-fold symmetric (e.g. Va =

K

−

i[S2

ix −

P

iy]2/4), with the easy or hard axis aligned
S2

along speciﬁc directions. The dipolar interaction often lead to the formation of domains.

The pattern of the domains have recently received considerable interest under the context

1

 
 
 
 
 
 
of the “self-assembled” systems where electric dipoles lead to the formation of domains

in Langmuir ﬁlms. Whereas the electric dipoles are always perpendicular to the ﬁlm plane

in that case, the magnetic dipoles can be parallel or perpendicular to the plane [2–6]. For

discussions in this paper, we restrict our attention to those cases so that the spins lie in the

plane of the ﬁlm, the case of experimental interest in sensor type applications.

The domain pattern depends on the shape of the sample, which is especially important

for small structures. The physics of the pattern of domains in small magnetic structures is

the subject of the present paper. We have been studying the physics of spin reversals of

diﬀerent small structures [7], such as monolayer ﬁlms with perpendicular [8] and 4-fold in

plane [9] anisotropy, nanowires and particles [10], coupled ﬁlms [11] and the shape of the

nucleus [12]. This paper reports our ﬁndings that much of the domain patterns observed

in the numerical simulations can be reproduced as the analytic many soliton solutions

of the imaginary time Sine-Gordon equation. This is illustrated by two examples in Fig 1

and 2 where we show the simulation and analytic results side by side. These analytic results

have the potential for greatly improving understanding quantitatively the domain structure

and the switching process in small structures. Thus analytic calculations can be performed

to predict trends as the system parameters are changed. These analytic results can be used

as a starting point of a simulation, considerably shortening the simulation time; sometimes

the simulations become entirely unnecessary. We now explain our results in detail.

Mathematically in the

continuum approximation,

the dipolar

energy Ed

dRdR′Si(R)Sj(R′)

j(1/

R

i

|
S after two integration by parts and neglecting the boundary terms as Ed

∇

∇

−

|

≈
) can be written in terms of the magnetic charges

R′

g
2

dRdR′

∇·
). Thus the dipolar energy is reduced if the “magnetic charges”

≈

R

g
2

R

∇·
S(R)

S(R′)(1/

R

|

−

R′

|

∇ ·

are as small as possible. This is usually achieved when lines of dipoles form closed loops.

The orientation of the spin is determined by its angle φ. For example, when the azimuth

angle θ can be described as a vortex with φ = θ

π/2 the dipolar energy is minimized.

−

When this type of global constraint is satisﬁed, the domain structure is usually determined

by minimizing the exchange and the anisotropy energy; we obtain the equation:

2

2φ

∇

−

0.5K sin 4φ/ ¯J = 0,

(2)

Here ¯J

≈

zJ/4 is the eﬀective exchange. z is the number of nearest neighbours. It comes

from converting the discrete model to the continuum approximation. The exactly soluable

sine-Gordon equation (∂2

x −

∂2
t )φ

−

0.5K sin 4φ/ ¯J = 0 is formally the same as the above

equation (2) if we transform the y coordinate into the imaginary time it. In this way, we

can generate a 90 degree domain wall “soliton” solution as φ = tan−1 exp[

−q

2K/ ¯Jx] where

the angle φ changes by 90 degree as the wall is traversed and x changes sign. This solution

is one dimensional and is well known [13].

Many soliton solutions are known but have never been exploited in the understanding

of domain structures. A general two soliton solution of the sine-Gordon equation has the

form ( [14]):

1

−

φ = tan−1 


2K/ ¯J, t′ = t

q

1−u1u2−√(1−u2
1−u1u2+√(1−u2

1)(1−u2
2)
1)(1−u2
2)
1−u1t′

x′−x′

exp

(cid:20)−

√1−u2

1 (cid:21)

exp

(cid:20)−

+ exp

x′−x′

1−u1t′

x′−x′

2−u2t′

√1−u2
x′−x′

1 −
2−u2t′

√1−u2

2 (cid:21)

(cid:20)−

√1−u2

2 (cid:21)

.

(3)





Here x′ = x

Using the transformation u1 = iv, u2 =

(ln(1/v)

−

iπ/2)/γ + x′

0, y′

1 =

−

q

2K/ ¯J. This solution has 4 arbitrary constants u1, u2, x1, x2.
1), x′
y′

2 and choosing x′

−
iπ/(2vγ) + y′
0, we obtain the two soliton solution in the form:

iv, t′ = i(y′

1 = x′

1 =

−

φ = tan−1[sinh(γv

2K/ ¯J(y

q

y0))/(

−

v sinh(γ

−

2K/ ¯J(x

q

x0)))],

−

(4)

where v is a parameter, γ = 1/√1 + v2. This describes a closure domain. An example is

shown in Fig. 1B for a triangular lattice of 3600 spins for K = 0.2 and J = 2. A closure

domain can be viewed as the space-time trajectory of two solitons coming together and

eventually moving apart. The parameter v describes the orientation of the domain wall.

To ﬁt into a sample of aspect ratio r, one expects v = r, as we have veriﬁed directly by

numerical calculation. For a triangular lattice, the center of the defect, (x0, y0) for the

lowest energy conﬁguration sits in the middle of the triangle. This type of domain wall is

often observed in simulations in systems in zero external magnetic ﬁeld. A typical ﬁnite

temperature simulation result [11] is also shown in Fig. 1A for the same value of J and

3

K and g = 1, obtained from cooling a high temperature conﬁguration that starts oﬀ with

all spins aligned in the x direction. To study the possible eﬀect of the dipolar interaction

and the accuracy of the analytic formula, we have numerically minimized the total energy

of the system starting from the conﬁguration given by the analytic formula and using a

quasi-Newton algoraithm for a system with 400 spins. We have explored diﬀerent values

of g less than 1 and ﬁnd that the mean square diﬀerence between the initial and ﬁnal

azimuthal angles is less than 0.1 radian, out of a possible range of π. Thus the accuracy

is 3%; the analytic formula is indeed a good approximation. With this analytic formula,

it is much easier to investigate the physical properties of closure domains quantitatively.

For example, we have investigated the size dependence of the energy diﬀerence between the

closure domain and that with uniform magnetization along the x direction. The diﬀerence

in energy divided by the eﬀective coupling constants (g for the dipolar energy and √JK

for the sum of the exchange and the anisotropy energy) is shown in Fig. 3 as a function

of the sample size. For a rectangular sample of a triangular lattice with an aspect ratio of

0.866 and x dimension L1, the dipolar energy diﬀerence ∆Ep can be ﬁtted by the formula

g(109.5

−

10.54L1) with an error of less than 4% whereas the sum of the anisotropy and

exchange energy ∆Ew can be ﬁtted by the formula √JK(28.76 + 2.64L1) with an error

of less than 0.3%. The closure domain is lower in energy than the uniformly magnetized

state when the sum of these two energies become negative. For a ﬁlm of thickness d, we

expect that approximately g = g0d2, J = J0d, K = K0d where the subscript 0 refers to

the bare coupling per spin. Thus the closure domain is lower in energy for sample sizes

L1 > (109.5 + 2.876√J0K0/g0d)/(10.54

−

2.64√J0K0/g0d). This can only happen if the

denominator is positive; ie d > dc = 0.25

J0K0/g0. As an example, consider bcc Fe where

q

0.254K, K0 ≈
g0 ≈
thicknesses d > 4.3 layers.

0.038K, J0 ≈

500K. Thus the closure domain is lower in energy for

The solutions (4) is, strictly speaking, applicable to inﬁnite samples. The consideration of

the domain patterns in small structures require the imposition of ﬁnite boundary conditions.

The solutions of Eq. (2) which satisfy these boundary conditions can be obtained starting

4

from the ansatz suggested by Lamb [15] for the solution of the sine-Gordon equation. We

seek solutions of Eq. (2) having the form φ(x, y) = tan−1[f (x′)g(y′)], where f and g are,

in general, Jacobian elliptic functions deﬁned by [16] (f ′)2 = αf 4 + βf 2

γ and (g′)2 =

γg4

(β

1)g2 + α with α, β, and γ arbitrary constants, x′ =

−

−
an example, we consider conﬁgurations corresponding to edge domains with the boundary

−

q

q

2K/ ¯Jy. As

−
2K/ ¯Jx, y′ =

conditions that the spins point up (down) on the left (right) edge and horizontally on both

the top and the bottom edge.

φ = tan−1 

Atn(Ωx′, λf )


where k2

g = [A2Ω2(1

A2)]/[Ω2(1

A2)2

−

−

−

cn(v

1 + k2

q

dn(v

1 + k2

gy′, k1g)
gy′, k1g)

q
1g = A2Ω2(1
1], k2

f = [A2 + Ω2(1
λ2

A2)2]/[Ω2(1

−

−

A2)] and v2 = [Ω2(1

A2)2

−

−



,



(5)

−
1]/[1

A2)/(Ω2(1

A2)

1),

−
A2]. The parameters

−

−

A and Ω can be determined by requiring that the component of S normal to the surface

boundary be zero so that the dipolar energy is minimized.

Figure 2B shows the edge domain pattern obtained by using Eqs. (5) for a triangular

lattice 3600 spins for J = 2 and K = 0.2. In Figure 2A we show the Monte Carlo result [11]

for a bilayer system for a triangular lattice of 3600 spins for the same value of J and K and

g=1. Similar domain patterns are also seen in the zero ﬁeld remanent state for a system

with a single layer. [9]

To study the possible eﬀect of the dipolar interaction and the accuracy of the analytic

formula, we have numerically minimized the total energy of the system starting from the

conﬁguration given by the analytic formula and using a quasi-Newton algoraithm for a

system with 400 spins. When the dipolar interaction is too small, our algorithm recovers

the minimum energy state of uniform magnetization. As long as the dipolar interaction is big

enough the minimum energy conﬁguration from our algoraithm is essentially independent

of the strength of the dipolar interaction. We obtain a state that resembles our analytic

results. The mean square diﬀerence between the initial and ﬁnal azimuthal angles is less

than 10%. The analytic formula is indeed a good approximation, even though it is not as

good as that for the closure domains. With this analytic formula, we have investigated the

5

size dependence of the energy diﬀerence between the edge domain and that with uniform

magnetization along the x direction. The results are shown in Fig. 3. For a rectangular

sample of a triangular lattice with an aspect ratio of 0.866 and x dimension L1, the dipolar

energy diﬀerence ∆Ep can be ﬁtted by the formula g(52.87

3.97L1) with an error of less

−

than 5% whereas the sum of the anisotropy and exchange energy ∆Ew can be ﬁtted by the

formula √JK(10.46+1.9L1) with an error of less than 1%. The edge domain is thus of lower

energy when the sum of these two energies become negative. As expected, when compared

with the closure domains, the dipolar energy gained is less while the cost in the anisotropy

and exchange energy is also smaller. For a ﬁlm of thickness d, the edge domain is lower in

energy for sample sizes L1 > (52.87 + 10.46√J0K0/g0d)/(3.97

1.9√J0K0/g0d). This can

−

only happen if the denominator is positive; ie d > dec = 2

J0K0/g0. For bcc Fe, dec = 8.2

q

layers.

In this paper we have discussed two examples of analytic solutions for domain patterns.

Many possibilities remain to be explored. For example, consider

φ = tan−1[cos(γv

2K/ ¯J(y

q

−

y0))/(v sinh(γ

2K/ ¯J(x

q

x0))].

−

(6)

where γ = 1/√1

−

v2. This solution can be considered the analytic continuation of the

solution (4) with an imaginary v. When v is small, this solution describes two 90 degree

domain walls separated by a distance 2 ln(2/v)

¯J/2K/γ). As v is increased from zero, two

q

separated 90 degree domain wall merge to become a 180 degree domain wall with vortices in

between. This type of solutions is not the lowest energy conﬁguration in zero magnetic ﬁeld

but occurs as a rate limiting step in spin reversal processes at a ﬁnite magnetic ﬁeld. Our

solution provides for conﬁgurations that are local extrema of the exchange and anisotropy

energy. The ordinary 180 degree domain wall in zero ﬁeld, which conisists of two 90 degree

domain walls, is not a local extrema of the exchange and anisotropy energy.

It is only

stabilized by the magnetoelastic or dipolar energy. [5]

In summary, we have provided examples of how the many soliton solutions can be used

to understand the domain structures in ultra-thin ﬁlms. This opens the door to analytic

6

quantatitive understanding of the micromagnetics in these systems.

This work is supported in part by the Oﬃce of Naval Research under contract N00014-

94-1-0213. VNR acknowledges the ﬁnancial support from the Russian Science Foundation

through the Grant N96-02-16211 and the hospitality of the Bartol Research Institute.

7

REFERENCES

[1] G. Prinz, Science 1092, 250 (1990).

[2] B. Heinrich and J. F. Cochran, Adv. in Physics 42, 524 (19943).

[3] S. T. Chui, Phys. Rev. Lett. 74, 3896 (1995).

[4] S. T. Chui, Phys. Rev. B 50, 12599 (1994).

[5] A. Berger and H. P. Oepen, Phys. Rev. B 45, 12596 (1992).

[6] A. Berger and H. P. Oepen, J. Magn. Magn. Mater. 121, 102 (1993).

[7] S. T. Chui, “Micromagnetism in small structures” in NATO ASI proceeding on micro-

magnetism, 1996, Kluwer Pub.

[8] S. T. Chui, Jour. App. Phys. 79, 4951 (1995).

[9] S. T. Chui, Appl. Phys. Lett., 68, 3641 (1996).

[10] S. T. Chui and D. C. Tian, Jour. App. Phys. 78, 3965 (1995).

[11] S. T. Chui, to appear in Phys. Rev. B, (1996).

[12] S. T. Chui, to appear in J. Mag. Mag. Mat. (1996).

[13] C. Kittel, Rev. Mod. Phys., 21, 541, (1949).

[14] V. E. Zakharov, S. V. Manakov, S. P. Novikov, and L. P. Pitaevsky, Theory of Solitons

(Consultants Bureau, New York, 1984).

[15] G. L. Lamb, Jr., Rev. Mod. Phys. 43, 99 (1971).

[16] P. F. Byrd and M. D. Friedman, Handbook of Elliptic Integrals for Engineers and Physi-

cists (Springer-Verlag, Berlin, 1954).

8

FIG. 1. Closure domain conﬁguration for a rectangle from a 2 soliton solution. The analytic

results is in B. The ﬁnite temperature Monte Carlo results observed in ref. 11 is shown in Fig. A.

FIGURES

FIG. 2. Edge domain conﬁguration for a rectangle from a 2 soliton solution. The analytic

results is in B. The ﬁnite temperature Monte Carlo results observed in ref. 11 is shown in Fig. A.

FIG. 3. The energy diﬀerence between the domain conﬁguration and that with uniform magne-

tization as a function of the linear dimension of the sample. These energy diﬀerences are normalized

by the coupling constants, as is described in the text.

9

A

B

A

B"
Stressed backbone and elasticity of random central-force systems,"  We use a new algorithm to find the stress-carrying backbone of ``generic''
site-diluted triangular lattices of up to 10^6 sites. Generic lattices can be
made by randomly displacing the sites of a regular lattice. The percolation
threshold is Pc=0.6975 +/- 0.0003, the correlation length exponent \nu =1.16
+/- 0.03 and the fractal dimension of the backbone Db=1.78 +/- 0.02. The number
of ``critical bonds'' (if you remove them rigidity is lost) on the backbone
scales as L^{x}, with x=0.85 +/- 0.05. The Young's modulus is also calculated.
",http://arxiv.org/pdf/cond-mat/9612237v1,2,"Stressed backbone and elasticity of random central-force systems

C. Moukarzel ∗
H¨ochstleistungsrechenzentrum, Forschungszentrum J¨ulich,
D-52425 J¨ulich, Germany.

P. M. Duxbury
Dept. of Physics/Ast. and Center for Fundamental Materials Research,
Michigan State University, East Lansing, MI 48824, USA.

We use a new algorithm to ﬁnd the stress-carrying backbone of “generic” site-diluted triangular
lattices of up to 106 sites. Generic lattices can be made by randomly displacing the sites of a regular
lattice (see Fig. 1). The percolation threshold is pc = 0.6975±0.0003, the correlation length exponent
ν = 1.16 ± 0.03 and the fractal dimension of the backbone Db = 1.78 ± 0.02. The number of “critical
bonds” (if you remove them rigidity is lost) on the backbone scales as Lx, with x = 0.85 ± 0.05. The
Young’s modulus is also calculated.

6
9
9
1
c
e
D
9
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
7
3
2
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

∗

Present Address: Instituto de Fisica, Universidade Federal Fluminense, Niteroi RJ, Brazil.

e-mail: cristian@if.uﬀ.br

1

 
 
 
 
 
 
The forces between atoms can often be divided into two
classes “central forces” and “angular forces” (e.g. cova-
lent bonds). In engineering, structures composed of bars
connected at nodes (e.g. some bridges), get their rigid-
ity primarily from the tensile and compressive stiﬀness
of the bars (these are central-force terms). Structures
of this sort are called “trusses”, while those in which
the angle forces (or beam-bending) are important are
called “frames”. It is simple to see that systems which
are dominated by angle forces support an applied stress
as long as they are simply connected. In contrast, sys-
tems with only central forces require higher order con-
nectivity, the simplest rigid structure being a triangle.
In many applications; for example in granular media1,
glasses2, gels3,4 and in engineering design, the disorder in
a central-force structure is important and must be con-
sidered. The stress-bearing paths of central-force systems
have been primarily studied by brute-force solution of the
force equations5−8. Although useful and important, this
method is slow and subject to roundoﬀ errors for large
structures. An eﬃcient method for relating the connec-
tivity of a central-force structure to its ability to carry
stress is an important and, in general unsolved, problem.
One exception to this is two-dimensional random lattices,
for which exact conditions9−12 relating connectivity to
“rigidity” have existed for over a decade. However, till
recently13 there has been no eﬃcient implementation of
these conditions, and their associated algorithms in ei-
ther physics or engineering. This paper and the preced-
ing paper by Jacobs and Thorpe (JT)13 describe the ﬁrst
implementations of these ideas. We use our algorithm,
to calculate the stressed backbone, and in combination
with an iterative solver, to ﬁnd the elastic properties of
these backbones. We also identify the critical (red) bonds
as those whose removal would lead to loss of rigidity, and
study their scaling properties. For reasons outlined below
these methods apply to randomly displaced (or “generic”
- see Fig. 1a) central-force lattices.

a)

b)

FIG. 1. A conﬁguration that is unstable to shear on a reg-
ular lattice, but is stable on a displaced lattice (dotted lines in-
dicate absent bonds). a) The conﬁguration in the “bar-joint”
representation (28 joints and 53 bars). b) The conﬁguration
in the “body-bar” representation (2 bodies and 3 bars).

Our ability to determine, from connectivity informa-
tion alone, whether a central-force structure contains a
stress carrying path is based on Laman’s theorem9.
Laman’s theorem A random lattice (see below for a
precise deﬁnition) consisting of N nodes and B bonds so

2

b

−

≤

−

3 is violated.

that 2N
B = 3 is rigid if and only if there is no subset
of the lattice, consisting of n nodes connected by b bonds,
for which 2n
This is the “bar-joint” statement of Laman’s theorem.
The origin of the expression 2n
b = 3 is easy to under-
stand. Each node (joint) in two dimensions has two de-
grees of freedom (two translations), and each bond (bar)
is a constraint (for example in Fig. 1a, n = 28, b = 53).
In the expression 2n
b = 3, the 3 is there because in two
dimensions a rigid body (in this case the whole lattice or
cluster) has 3 degrees of freedom (two translations and
a rotation). 2n
b = 3 is the two dimensional version
of a general constraint counting argument introduced by
Maxwell.

−

−

−

>
c
P
<

0.79

0.78

0.77

0.76

0.75

0.74

0.73

0.72

0.71

0.70

0.69

10

100
L

1000

FIG. 2.

The rigidity threshold as a function of sample
size. AS with periodic boundary conditions (*), AS with open
boundary conditions(+), IS with open boundary conditions
(×) IS with periodic boundary conditions(◦). The lattice sizes
(L) (number of conﬁgurations) used are as follows; 16(2×105),
32(105), 64(8×104), 128(2×104), 256(1.2×104), 512(2×103),
1024(2 × 102).

−

However the new feature here is that constraint count-
ing is exact in two dimensions provided it is implemented
at all length scales (Unfortunately this result does not
extend to three dimsensions, where counterexamples12
to the three-dimensional extension of this argument,
3n
b = 6, are known to exist). However, even in 2-
d a naive algorithm must check all subclusters of a set
of N nodes and so is not polynomial complete. How-
ever Laman’s theorem may be implemented by using
the “bipartite matching” algorithm from graph theory12,
which, when reﬁned as described below, scales as N 1.15
for ﬁnding the stressed backbone at the rigidity percola-
tion point.
Our implementation of Laman’s theorem is a cluster la-
belling algorithm21. Although we do site percolation,
where p is the probability that a site is occupied, the
algorithm works by testing a newly added bond against
the conﬁguration of rigid clusters already on the lattice.
For a given p, we ﬁnd the site conﬁguration, and from it
the conﬁguration of present bonds. Then we start with
an empty lattice and add the present bonds one at a time.
Each rigid cluster is a “body” with 3 degrees of freedom,
so we must generalise the statement 2n
b = 3 of the
−
b = 3, where nbod is the num-
original lattice to 3nbod −

 
 
There are several ways to deﬁne the onset of stress trans-
mission through a lattice. The two which are most phys-
ically appealing are:

1. The point at which an applied stress (AS) is trans-

mitted across the lattice and;

2. The point at which internally stressed regions (IS)
connect together to form stressed clusters of macro-
scopic size.

Both of these deﬁnitions have simple representations in
terms of a lattice of Hooke’s springs. The ﬁrst (AS) cor-
responds to a random Hooke’s spring lattice to which, for
example, a tensile stress is applied, while the second (IS)
corresponds to the internal stresses in a random Hooke’s
spring lattice with random natural lengths. We study the
stressed backbone of these lattices as a function of site di-
lution. We also tested the eﬀect of boundary conditions
on these two deﬁnitions of rigidity percolation, because a
local change in rigidity (e.g. by adding a bond) can be
transmitted over long distances so boundaries might be
more important in this problem than in connectivity per-
colation. However, we ﬁnd that in the large-lattice limit
both the AS and IS percolation deﬁnitions lead to the
same, boundary condition independent, threshold. This
behavior is presented in Fig. 2, from which we ﬁnd that
0.0003. On regular lattices, previous work15
pc = 0.6975
using direct solution of the force equations lead to esti-
mates close to pc = 0.713 for samples of up to size L = 75.
As can be seen from Fig. 2, this is consistent with the
result on random lattices, although at that lattice size,
there is still considerable dependence on boundary con-
ditions. However, in general there is no reason to believe
that the percolation threshold on random lattices should
be the same as that on regular lattices. This diﬀerence
is illustrated by the conﬁguration of Fig. 1b. On a reg-
ular lattice that conﬁguration is not rigid to shear, but
if the lattice sites are displaced, it becomes rigid. That
is because on a regular lattice, the three bars are paral-
lel, so these constraints are “degenerate”. Thus for that
conﬁguration, the random lattice is more rigid than the
regular lattice.

±

ber of bodies (or rigid clusters) in a conﬁguration. For
example the conﬁguration of Fig. 1a, has two bodies and
3 bars (see Fig. 1b). A key component of the algorithm
is the realisation by Hendrickson12 that it is easy to de-
termine whether a bar (bond) is redundant with respect
to the bonds that are already in the lattice.

FIG. 3. The stressed (AS) backbone on a lattice of size

L = 1024 with open boundaries.

If the bonds of the lattice are replaced by Hooke’s
springs, a redundant bond leads to internal stresses in
the spring lattice. A redundant bond causes a violation
b = 3 by adding an extra spring to
of the condition 3nbod−
the lattice. The algorithm checks to see if 3nbod −
b = 3 is
satisﬁed by using “bipartite matching”12 or “the pebble
game”12,13 to see if each of the bodies’ degrees of freedom
can be “matched” to the bonds of the conﬁguration (note
that JT use the “pebble game” in the original bar-joint
representation).
If an extra or redundant spring is added to a cluster that
b = 3), the
is already rigid (i.e. already satisﬁes 3nbod −
matching algorithm identiﬁes the bonds which become
internally stressed when the extra spring is added. We
then give these internally stressed bonds the same cluster
label. In this way we ﬁnd “internally stressed (IS) clus-
ters”. Finally, an applied tensile stress can be mimiced by
adding two rigid beams to the two opposite sides of the
lattice, and then by adding a ﬁctitious bond between the
rigid beams. In this way, we determine when the lattice
can support an applied tensile stress. Full details of the
algorithm will appear elsewhere21. In JT, the bond prob-
ability is ﬁxed. Our algorithm is complimentary to theirs
as we add bonds one at a time, so we ﬁnd the percola-
tion concentration exactly for each sample. We chose this
method not only because it is very eﬃcient (comparable
to JT), but also so that we can ﬁnd the exact backbone
for each sample, and hence the “critical (or red) bonds”
of the backbone (see below).

3

1

0.1

0.01

0.001

s
d
n
o
b
f
o

n
o
i
t
c
a
r
F

0.0001

10

100
L

1000

FIG. 4. a) Finite-size-scaling plot of the normalised num-
ber of bonds NB/L2 on the stressed backbone at the percola-
tion point for: AS with periodic b.c.’s (*); AS with open b.c.’s
(+); IS with periodic b.c.’s (X) and ; IS with open b.c.’s (O).
b) Finite-size-scaling plot of the normalised number of “red”
bonds on the backbone, NR/L2 (AS with periodic b.c’s). The
lattice sizes used and number of conﬁgurations were the same
as for Fig. 2.

±

−

pc(
));
∞
pperiodic
) and;
c
< pc >2),

However it is easy to construct conﬁgurations which
are more rigid on a regular lattice (e.g. a sequence of
aligned bonds forming a “guy” wire), so it is unclear as
to whether displaced lattices have a lower or higher pc
than regular lattices.
From the variation in the percolation concentration
L−1/ν, we are able to ﬁnd the correlation length
∆pc ∼
exponent. We did this for three ways of deﬁning ∆pc,
namely:
a) (pc(L)
−
b) (popen
c
−
c) √(< p2
c >
and for several types of boundary conditions in each case.
From these extensive calculations, we ﬁnd ν = 1.16
0.03.
Although it is not the main focus of this paper, we note
that in JT, it is claimed that the inﬁnite cluster, P∞
(which includes internally stressed bonds (stressed back-
bone), and unstressed bonds which satisfy 2n
b = 3)
has a fractal dimension around Df ∼
If we assume a second order behavior in P∞ , we ﬁnd a
similar fractal dimension. However, a mean ﬁeld theory4
suggests that the rigidity transition is ﬁrst order (so
Df = 2 in 2-d), and similarly on Bethe lattices the rigid-
ity transition is ﬁrst order22. Thus we have also tested
the possibility of a ﬁrst order transition23 in P∞, and
ﬁnd that the data is consistent with a weakly ﬁrst-order
transition, with the ﬁrst-order jump ∆P∞
0.085 at pc.
However, even larger lattices (up to of order L = 10, 000)
are needed to determine convincingly whether, in 2-d, P∞
is ﬁrst order.
An example of a stressed backbone at the percolation
point is presented in Fig. 3. We measured the number
of bonds on backbones such as that shown in Fig. 3, and
the results of a scaling plot are presented in Fig. 4. From
this ﬁgure, we ﬁnd Db = 1.78
0.02. This backbone
dimension is diﬀerent than that for connectivity percola-
tion where the backbone dimension is 1.62
0.01, and it
is also considerably larger than that of the stressed back-

1.86.

±

±

∼

−

±

±

bone of regular triangular lattices 1.64
0.05 found by
direct solution8 on small lattices (up to L = 80). The
latter discrepancy could be due to a fundamental diﬀer-
ence between the random and regular lattices, but it also
could be due to imprecise estimates of the percolation
concentration in previous work due to ﬁnite size eﬀects
(see Fig. 2). At the percolation point, there are a set
of bonds whose removal leads to loss of backbone rigid-
ity. We calculated the number of these critical red bonds,
NR, and their scaling behavior at the percolation point
Lx, with
is also shown in Fig. 4. They scale as NR ∼
x = 0.85
0.05. This is consistent with x = 1/ν, although
we have no analytic argument for why this should be so.
Previous work on the elastic exponents of regular trian-
gular, central force, networks have produced conﬂicting
results. Although the early work5 gave an exponent in
the range, 1.3
2.0, later work suggested that
the central force and bond-bending (angular force) prob-
lems were in the same universality class8,15,16, so that17
3.0. There have even been suggestions15,16 that in
f /ν
2-d, site percolation has exponent near f /ν
1.0, while
∼
bond percolation has exponent near f /ν
3.0. Finally,
there is a recent mean ﬁeld theory4 which gives exponent
f
The diﬃculty in obtaining good estimates have been as-
cribed to: a) unusually strong accumulation of roundoﬀ
errors7, and b) lack of precision8 in the estimate of pc.
We ﬁnd that roundoﬀ errors are largely eliminated if we
use the graph theory method to remove all non-stressed
bonds before applying the conjugate gradient method.
In addition we know pc exactly for each conﬁguration, so
we do not have to study a range of p using an interative
solver. Thus we have been able to study the elastic con-
stants for lattice sizes which were previously inaccessible
(up to linear size L = 512 - see Fig. 5).

f /ν

1.5.

≤

≤

∼

∼

∼

1

0.1

0.01

0.001

0.0001

0.00001

s
u
l
u
d
o
M

s
’
g
n
u
o
Y

0.000001

10

100
L

1000

FIG. 5. Finite-size-scaling behavior of the Young’s modu-
lus for: regular lattices (+); lattices randomly displaced by
lattices with random bond angles (✷). The
0.2 (△) and;
lattice sizes used (number of conﬁgurations) were as follows;
16(20, 000), 32(10, 000), 64(1, 000 − 2, 000), 128(100 − 300),
256(20 − 40), 512(4 − 6).

As expected, a certain number of the “generic” back-
bones are not rigid on a regular lattice due to degenera-
cies. However, the fraction of the backbones that are non-
rigid on regular lattices increases very slowly with lattice
50% at L = 512. Now note that
size, and is still only

∼

4

 
 
 
if the sites of a generic backbone, which is non-rigid on
a regular lattice, are displaced by a small amount ∆, the
elastic modulus of that backbone is O(∆2). Thus, the
elastic constants of generic backbones are usually non-
universal, for sizes accessable to simulation, even for lat-
tices displaced by 0.2 (see Fig. 5).
To avoid the slow size eﬀect caused by proximity to the
regular lattice limit, we also studied a model where the
locations of the elements of the elastic matrix were set by
the connectivity of the backbone. To mimic the highly
displaced lattice (large ∆) limit, we assign each bond an
angle to the x-axis which is drawn from a random distri-
bution of angles (on the interval [0, 360], and calculate the
elastic constant using these angles in the force equations.
The results for this “random angle model” are also shown
in Fig. 5 (each present bond has unit spring constant).
We found that the value f /ν
1.45 is quite universal in
this limit.
Acknowledgements We acknowledge support from
PRF, by the DOE under contract DE-FG02-90ER45418,
and by the Humboldt foundation (PD). We thank Paul
Leath, Bruce Hendrickson, Mike Thorpe and Don Jacobs
for useful discussions.

∼

References
1 E. Guyon, S. Roux, A. Hansen, D. Bideau, J.-P. Troadec
and H. Crapo, Rep. Prog. Phys. 53, 373 (1990)
2 J.C. Phillips, J. Non-Cryst. Sol. 43, 37 (1981); M.F.
Thorpe, J. Non-Cryst. Sol. 57, 355 (1983)
3 M. Rubinstein, L. Leibler and J. Bastide, Phys. Rev.
Lett. 68, 405 (1992)
4 S.P. Obukhov, Phys. Rev. Lett. 74, 4472 (1995)
5 S. Feng and P.N. Sen, Phys. Rev. Lett. 52, 216 (1984)
6 M.A. Lemieux, P. Breton and A.-M.S. Tremblay, J. de
Physique 46, L-1 (1985)
7 A.R. Day, R.R. Tremblay and A.-M.S. Tremblay, Phys.
Rev. Lett. 56, 2501 (1986)
8 A. Hansen and S. Roux, Phys. Rev. B40, 749 (1989)
9 G. Laman, J. Eng. Math. 4, 331 (1970)
10 L. Lovasz and Y. Yemini, Siam J. Alg. Disc. Meth. 3,
91 (1982)
11 A. Recski, Disc. Math. 108, 183 (1992)
12 B. Hendrickson, Siam J. Comput. 21, 65 (1992); Bruce
Hendrickson, private communication.
13 D. Jacobs and M.F. Thorpe to be published
14 M.F. Thorpe and E.J. Garboczi, Phys. Rev. B35,
8579 (1987)
15 S. Arbabi and M. Sahimi, Phys. Rev. B47, 695 (1993)
16 M. Knackstedt and M. Sahimi, J. Stat. Phys. 69, 887
(1992)
17 J.G. Zabolitzky, D.J. Bergman and D. Stauﬀer, J. Stat.
Phys. 44, 211 (1986)
20 See for example: C. H. Papadimitriou and K. Steiglitz,
”Combinatorial Optimization: Algorithms and Complex-
ity”, Prentice Hall, 1982.
21 C. Moukarzel, J. Phs. A: Math. Gen. 29 (1996), 8097;
( physics/9612013).
22 C. Moukarzel, P.M. Duxbury and P.L. Leath, to be
published.
23 C. Moukarzel and P.M. Duxbury to be published.

5"
Reorientation transition of ultrathin ferromagnetic films,"  We demonstrate that the reorientation transition from out-of-plane to
in-plane magnetization with decreasing temperature as observed experimentally
in Ni-films on Cu(001) can be explained on a microscopic basis. Using a
combination of mean field theory and perturbation theory, we derive an analytic
expression for the temperature dependent anisotropy. The reduced magnetization
in the film surface at finite temperatures plays a crucial role for this
transition as with increasing temperature the influence of the uniaxial
anisotropies is reduced at the surface and is enhanced inside the film.
",http://arxiv.org/pdf/cond-mat/9701043v2,2,"7
9
9
1

g
u
A
8
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

2
v
3
4
0
1
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Physical Review B 55, 12309 (1997)

1

Reorientation transition of ultrathin ferromagnetic ﬁlms

A. Hucht∗ and K. D. Usadel†
Theoretische Tieftemperaturphysik, Gerhard-Mercator-Universit¨at, 47048 Duisburg, Germany
(Received 20 August 1996)

We demonstrate that the reorientation transition from out-of-plane to in-plane magnetization
with decreasing temperature as observed experimentally in Ni-ﬁlms on Cu(001) can be explained
on a microscopic basis. Using a combination of mean ﬁeld theory and perturbation theory, we de-
rive an analytic expression for the temperature dependent anisotropy. The reduced magnetization
in the ﬁlm surface at ﬁnite temperatures plays a crucial role for this transition as with increasing
temperature the inﬂuence of the uniaxial anisotropies is reduced at the surface and is enhanced
inside the ﬁlm.

PACS numbers: 68.35.Rh, 75.10.Hk, 75.30.Gw, 75.70.-i

The direction of the magnetization of thin ferromag-
netic ﬁlms depends on various anisotropic energy contri-
butions like surface anisotropy ﬁelds which often favor an
orientation1 perpendicular to the ﬁlm, dipole interaction
which favors an in-plane magnetization, and eventually
anisotropy ﬁelds in the inner layers. As a consequence of
these competing eﬀects, a temperature driven reorienta-
tion transition from an out-of-plane ordered state at low
temperatures to an in-plane ordered state at high tem-
peratures may be observed at appropriate chosen ﬁlm
thicknesses. Experimentally, this transition has been
studied in detail for various ultra-thin magnetic ﬁlms2–4.
Recently, it was found by Schulz and Baberschke5 that
ultra-thin Ni-ﬁlms grown on Cu(001) show an opposite
behavior: the magnetization is oriented in-plane for low
temperatures and perpendicular at high temperatures.

Phenomenological approaches for explaining the reori-
entation transition usually start from the energy (or the
free energy at ﬁnite temperatures) which is expanded
in terms of the orientation of the magnetization vector
relative to the ﬁlm introducing temperature dependent
anisotropy coeﬃcients Ki(T ). The temperature depen-
dence of these coeﬃcients is then studied experimentally
(for a recent review see6).

To better understand the mechanism responsible for
the temperature driven transition, several investigations
have been done in the framework of statistical spin mod-
els. The advantage of this approach is that only a few
microscopic parameters enter: besides an exchange inter-
action the dipole interaction and an uniaxial anisotropy
in the surface layers of the ﬁlm. While Moschel et al.7
showed that the temperature dependence of the reorien-
tation transition is well described qualitatively within a
quantum mechanical mean ﬁeld approach, most other au-
thors focused on classical spin models. Extended Monte
Carlo simulations on mono-layers8,9 as well as mean ﬁeld
calculations of both mono-layers10 and bilayers11 agree in
the sense that a temperature driven reorientation transi-
tion is obtained. Nevertheless, there is still a controversy
with respect to the order of this transition. While Chui8
measured the expectation value of the components of the
total magnetization and obtained a second order transi-
tion for a monolayer we found, using an improved simula-

tion algorithm and analyzing the Monte Carlo data with
a histogram method, a transition of ﬁrst order in agree-
ment with the mean ﬁeld calculations for this system9.
Furthermore, we could show that the order of the transi-
tion depends on the number of layers and on the distri-
bution of the uniaxial anisotropies11.

In all of these theoretical investigations a temperature
driven reorientation transition from a out-of-plane state
at low temperatures to an in-plane state at high temper-
ature is found for appropriate sets of parameters, which
is due to a competition of a positive surface anisotropy
and the dipole interaction. The interesting new result
for ultra-thin Ni-ﬁlms is argued5 to have its origin in
a stress-induced uniaxial anisotropy energy in the in-
ner layers with its easy axis perpendicular to the ﬁlm.
This anisotropy is in competition with the dipole in-
teraction and a negative surface anisotropy. While the
thickness-dependent transition could be explained with
these anisotropies5, the origin of the more interesting
temperature driven transition is not yet explained on a
microscopic basis. Note that the reversed reorientation
recently found by MacIsaac et al.12 has a diﬀerent origin
It
as it only occurs at vanishing exchange interaction.
is the purpose of this letter to show that the dipole in-
teraction together with uniaxial anisotropies in the ﬁlm
indeed may lead to a temperature driven second order re-
orientation transition from an in-plane magnetized ﬁlm
at low temperatures to a perpendicular magnetized ﬁlm
at high temperatures.

After submission of this letter we became aware of a
paper by Jensen and Bennemann13 on the same topic.
Starting from an expansion of the free energy in terms of
uniaxial anisotropy and dipole interaction and employ-
ing then a mean ﬁeld approximation following earlier
work14 they calculated numerically the temperature of
In contrast to
both types of reorientation transitions.
this calculation we develop in the present paper a fully
selfconsistent mean ﬁeld theory and analyse the reorien-
tation transition within this approach since only within
a nonlinear theory the canted phase and in particular its
width can be analyzed. Additionally, a selfconsistent cal-
culation of the quantities Ki(τ ) introduced below which
are crucial for an understanding of the nature of the tran-

 
 
 
 
 
 
Physical Review B 55, 12309 (1997)

sition is not possible. A linearization of the free energy
which is discussed in the last part of our paper agrees
with the results of Ref.13. Within such a linearized the-
ory the approximate location of the transition can be
obtained as a temperature somewhere within the canted
phase but it is not possible to calculate the width of this
phase. Thus, this calculation is only meaningful for a
situation where the canted phase occupies a rather small
temperature interval. Note, however, that this width can
be quite large for instance for strongly varying anisotropy
energies or certain parameter conﬁgurations11 in which
case a nonlinear approach is necessary.

The calculations are done in the framework of a classi-
cal ferromagnetic Heisenberg model consisting of L two-
dimensional layers on a simple cubic lattice. The Hamil-
tonian reads

H = −

J
2 Xhiji

~si · ~sj −

Xi

Dλi(sz

i )2

+

ω
2 Xij

ij ~si · ~sj − 3r−5
r−3

ij (~si · ~rij )(~rij · ~sj),

(1)

i , sz
i , ry

i , sy
where ~si = (sx
i ) are spin vectors of unit length at
i , rz
position ~ri = (rx
i ) in layer λi and ~rij = ~ri − ~rj . J
is the nearest-neighbor exchange coupling constant, Dλ
is the uniaxial anisotropy which depends on the layer
index λ = 1 . . . L, and ω = µ0µ2/4πa3 is the strength of
the long range dipole interaction on a lattice with lat-
tice constant a (µ0 is the magnetic permeability and µ is
the eﬀective magnetic moment of one spin). All energies
and temperatures are measured in units of J (kB = 1)
which is ﬁxed to J = 1 in this letter. Note that only sec-
ond order uniaxial anisotropies Dλ enter the Hamiltonian
Eq. (1). In our calculations we will restrict ourself to the
case that all anisotropies are the same except at one sur-
face, as this scenario is suﬃcient for explaining the basic
physics of the temperature driven reorientation transi-
tion. Furthermore we will focus on the case of L = 4
layers. A systematic investigation of the parameter and
thickness dependence of the reorientation transition and
in particular a calculation of the corresponding phase di-
agrams is under way15.

In the following we assume translational invariance
within the layers and therefore we set h~sii = ~mλ if ~si is a
spin in layer λ. For the Hamiltonian Eq. (1) a molecular-
ﬁeld approximation is implemented resulting in L eﬀec-
tive one particle Hamiltonians from which the free energy
functional can be obtained: the mean ﬁeld in layer λ is
given by ~hλ =
Xλµ ~mµ where Xλµ contains both ex-
change and dipole interaction. With the order parameter
M = ( ~m1, ..., ~mL) the Hamiltonian in layer λ becomes

P

µ

HMF
λ

(M) = ~hλ ·

1
2

(cid:18)

~mλ − ~sλ(cid:19)

− Dλ(sz

λ)2.

(2)

Integrating this mean ﬁeld Hamiltonian over the surface
of the unit sphere in each layer yields the free energy per
surface element,

1.0

0.5

0.0

n
o

i
t

a
z
i
t

e
n
g
a
M

my(τ)
mz(τ)
K2(τ)
K4(τ)

2

3

2

1

0

A
n
s
o

i

t
r
o
p
y
E
n
e
r
g
y

×

1
0
3

0.0

0.5
Reduced Temperature

-1

1.0

FIG. 1. Magnetization components and anisotropy en-
ergies for a Fe-type system with L = 4 layers. J = 1,
D1/J = 14 × 10−3, Dλ>1 = 0, ω/J = 38 × 10−5. The param-
eters are based on Iron.

F (T, M) = −T

L

Xλ=1

log

I

d~sλe−H

M F
λ

(M)/T .

(3)

λ and mz

Due to the in-plane rotational invariance of Eq. (2) we
can set mx
λ = 0 and thus the free energy in Eq. (3) de-
pends on the 2L components my
λ of M and is
stationary with respect to variations of these quantities.
This variation is done in two steps: First we minimize the
free energy Eq. (3) with the constraint that the azimuth
angle ϑ of the total magnetization ~m = L−1
λ ~mλ is
ﬁxed, and expand the resulting constrained free energy
in powers of cos(ϑ) to give the angle-dependent free en-
ergy

P

F (τ, ϑ) = F0(τ ) − K2(τ ) cos2(ϑ)

−K4(τ ) cos4(ϑ) − ...

(4)

with the reduced temperature τ = T /Tc (Tc is the Curie
temperature of the ﬁlm) and temperature dependent ex-
pansion coeﬃcients Ki(τ ). These quantities are usu-
ally introduced phenomenologically. However in our ap-
proach we can calculate these coeﬃcients Ki(τ ) from the
microscopic parameters of the system. The equilibrium
free energy is then obtained as the minimum of Eq. (4)
with respect to ϑ.

In this notation, the two reorientation transition tem-
r , where my → 0, are

r , where mz → 0, and τ y

peratures τ z
given by the conditions

0 = K2(τ z
0 = K2(τ y

r ),
r ) + 2K4(τ y

r ).

(5a)
(5b)

Fig. 1 shows the temperature dependence of the compo-
nents of the total magnetization ~m(τ ) and the anisotropy

 
 
 
 
 
 
 
Physical Review B 55, 12309 (1997)

3

1.0

0.5

0.0

n
o

i
t

a
z
i
t

e
n
g
a
M

2

1

0

-1

A
n
s
o

i

t
r
o
p
y
E
n
e
r
g
y

×

1
0
4

my(τ)
mz(τ)
K2(τ)
K4(τ)

0.0

0.5
Reduced Temperature

-2

1.0

FIG. 2. Magnetization components and anisotropy en-
ergies for a Ni-type system with L = 4 layers. J = 1,
D1/J = −3.5 × 10−3, Dλ>1/J = 1.5 × 10−3, ω/J = 5 × 10−5.
The parameters are based on Nickel.

coeﬃcients K2(τ ) and K4(τ ) for a situation where one
of the layers (the surface layer) has a positive uniaxial
anisotropy, D1 > 0, and the others are set to Dλ>1 = 0.
K6(τ ) and higher order terms are nearly two magnitudes
smaller than K2(τ ) and therefore are not depicted. This
is the situation encountered for instance in ultra-thin Fe-
ﬁlms. The ground-state magnetization of the system is
Increasing the temperature
perpendicular to the ﬁlm.
the magnetization switches continuously from the per-
pendicular direction at a temperature τ y
r to the in-plane
direction at τ z
r .

For Ni-ﬁlms on Cu(001) there is a positive uniaxial
volume anisotropy in the inner layers favoring perpen-
dicular orientation, and eventually a negative anisotropy
on the surface5. In competition to these energies is the
dipole interaction which always favors in-plane magneti-
zation. Fig. 2 shows the temperature dependence of the
components of the total magnetization vector and the
anisotropy coeﬃcients Ki(τ ) for a Ni-type system with
L = 4 layers. The exchange interaction J is estimated
from the Curie temperature of bulk Nickel, the dipole
constant ω is calculated from the ground state magnetic
moment and the lattice constant, and the anisotropy en-
ergies are taken from the experiment5. For these pa-
rameters with increasing temperature the magnetization
starts to cant at a temperature τ z
r and reaches the per-
pendicular state at τ y
r as observed experimentally in Ni-
ﬁlms. These results were obtained numerically by solving
the corresponding mean ﬁeld equations.

In order to understand both the normal and the re-
versed reorientation transition we additionally applied
a perturbation theory to the mean ﬁeld Hamiltonian

Eq. (2) considering ω and Dλ as small perturbations of
the pure isotropic Heisenberg Hamiltonian which is jus-
tiﬁed in view of the smallness of these parameters. We
will only give the results of these calculations in this let-
ter, the complete derivation will be reported in detail in
a forthcoming paper15.

The total anisotropy K(τ ) of the system is deﬁned as
the diﬀerence of the free energies of the in-plane state
and the out-of-plane state

K(τ ) = F (τ, π/2) − F (τ, 0)

= K2(τ ) + K4(τ ) + ... .

(6)

When we neglect the narrow canted phase, the reorienta-
tion temperature τr is given by the condition K(τr) = 0.
If the ﬁrst derivative ∂τ K(τr) < 0, we have a normal
transition from out-of-plane to in-plane magnetization
direction, otherwise the transition is reversed.

In the framework of a perturbation theory we can
derive an analytical expression for K(τ ) involving the
absolute value of the layer magnetizations mλ(τ ) and
the ﬂuctuations transversal to the magnetization direc-
λ )2i(τ ), both calculated with the unper-
tion qλ(τ ) = h(s⊥
turbed Hamiltonian:

K(τ ) = Kq(τ ) + Km(τ )

L

=

Dλ (1 − 3qλ(τ ))

Xλ=1

−

3ω
4

L

Xλ,λ′=1

mλ(τ )Φ|λ−λ′|mλ′ (τ ).

(7)

The constants Φδ contain the eﬀective dipole inter-
action between the layers and can be calculated nu-
merically to give Φ0 = 9.0336, Φ1 = −0.3275⋆, and
Φδ>1 = O(e−2π(δ−1)).

At the critical temperature K(τ ) vanishes and hence
K(τ ) must be curved in order to have another zero at a
temperature τr < 1. Furthermore, a positive curvature
is necessary for a normal reorientation transition while a
negative curvature of K(τ ) is necessary for a reversed re-
orientation. Hence we will focus on the second derivatives
of Eq. (7) and start with the dipole part Km(τ ). It turns
out that ∂2
τ Km(τ ) > 0 for all ﬁlm thicknesses and tem-
peratures since ω is positive and the main contribution of
λ(τ ) which always has
the sum is proportional to
a negative curvature. Thus the dipole interaction always
P
favors the normal reorientation and can never lead to a
reversed transition in an exchange dominated system.

λ m2

Now we will examine Kq(τ ). First note that qλ(0) = 0
and qλ(1) = 1/3 in the unperturbated case. For L = 1
and L = 2 we have qλ(τ ) = τ /3 in mean ﬁeld approxi-
λ Dλ(1 − τ ), i.e. the second
mation, and then Kq(τ ) =
derivative vanishes in this case. Consequently in systems
P
with L ≤ 2 layers we only ﬁnd normal reorientation tran-
sitions from out-of-plane direction at low temperatures to
an in-plane direction at higher temperatures.

 
 
 
 
 
 
 
 
Physical Review B 55, 12309 (1997)

4

10

0

4
0
1

×

y
g
r
e
n
E

-10

0.0

K(τ)
Km(τ)
Kq(τ)

τ

r

0.5
Reduced Temperature

1.0

FIG. 3. Total anisotropy K(τ ) and its two parts Kq(τ )
and Km(τ ) from Eq. 7 for a Ni-type system. The model
parameters are the same as in Fig. 2.

This is not the case for L > 2 layers since then, due to
the reduced surface magnetization at ﬁnite temperatures,
the transversal ﬂuctuations in the surface layers qs(τ ) are
enhanced (qs(τ ) ≥ τ /3, ∂2
τ qs(τ ) < 0). Combined with a
negative surface anisotropy Ds this may lead to a neg-
ative curvature of Kq(τ ). Furthermore, the transversal
ﬂuctuations in the inner layers are reduced by this eﬀect
(qb(τ ) ≤ τ /3, ∂2
τ qb(τ ) > 0) and, when combined with a
positive uniaxial anisotropy in the inner layers enhance
the negative curvature of Kq(τ ).

In Fig. 3 K(τ ) is depicted together with the two com-
peting parts Kq(τ ) and Km(τ ) from Eq. (7) for the same
parameters as in Fig. 2. A transition is obtained with in-
creasing temperature because Kq(τ ) tends slower to zero
than Km(τ ).

In summary we have shown that the temperature
driven reorientation transitions seen in ultra-thin ferro-
magnetic ﬁlms are well described within a mean ﬁeld
approximation if second order uniaxial anisotropies and
the dipole interaction are included in the Hamiltonian.
In particular we can relate the unusual transition seen
in Ni-ﬁlms to a microscopic model in which a positive
uniaxial anisotropy energy is present in the inner lay-
ers. Additionally we can calculate the parameters Ki(T )
usually introduced phenomenologically from microscopic
parameters of the system.

The L = 4 layer ﬁlm considered serves as a simple
system showing the Ni-type transition, while the Fe-type
transition is already observed in mono layers if the pa-
rameters are adjusted properly. This has a rather inter-
esting physical origin: For systems with L = 1 or L = 2
layers the unperturbed system is homogeneous as every
lattice site has the same environment. It turns out that in

this case only a reorientation transition from out-of-plane
to in-plane can occur, provided the exchange interaction
is large with respect to the uniaxial anisotropies and the
dipole interaction. When the ﬁlm thickness L > 2, the
magnetization is not homogeneous through the ﬁlm as
the surface layers have a reduced magnetization at ﬁ-
nite temperatures. This leads to an enhancement of the
transversal ﬂuctuations at the surface and to a reduc-
tion of these ﬂuctuations in the inner of the ﬁlm. Hence
the inﬂuence of the uniaxial anisotropies is reduced at
the surface and enhanced inside the ﬁlm favoring a spin
orientation parallel to the easy axis of the inner layer.
This eﬀect may lead to a temperature driven reorienta-
tion transition of the type observed in Nickel.

This work was supported by the Deutsche Forschungs-
gemeinschaft through Sonderforschungsbereich 166. The
authors would like to thank S. L¨ubeck and A. Moschel
for fruitful discussions.

∗ Electronic address: fred@thp.Uni-Duisburg.DE
† Electronic address: usadel@thp.Uni-Duisburg.DE
1 L. N´eel, J. Phys. Radiat. 15, 376 (1954).
2 R. Allenspach, J. Magn. Magn. Mater. 129, 160 (1994),

3 D. P. Pappas, K.-P. K¨amper, and H. Hopster, Phys. Rev.

and references therein.

Lett. 64, 3179 (1990).

70, 1006 (1993).

4 Z. Q. Qiu, J. Pearson, and S. D. Bader, Phys. Rev. Lett.

5 B. Schulz and K. Baberschke, Phys. Rev. B 50, 13467

(1994), K. Baberschke, Appl. Phys. A 62, 417 (1996).

6 U. Gradmann, in Handbook of magnetic Materials, Volume
7, Chapter 1, edited by K. H. J. Buschow (Elsevier Science
Publishers 1993).

7 A. Moschel and K. D. Usadel, Phys. Rev. B 49, 12868

8 S. T. Chui, Phys. Rev. B 50, 12559 (1994), Phys. Rev. Lett.

(1994).

74, 3896 (1995).

5 4527 (1993).

423 (1996).

100, 585 (1996).

187, 715 (1969).

9 A. Hucht, A. Moschel, and K. D. Usadel, J. Magn. Magn.

Mater. 148, 32 (1995).

10 M. B. Taylor and B. L. Gyorﬀy, J. Phys: Condens. Matter

11 A. Hucht and K. D. Usadel, J. Magn. Magn. Mater. 156,

12 A. B. MacIsaac, J. P. Whitehead, K. De’Bell, and P. H.

Poole, Phys. Rev. Lett. 77, 739 (1996).

13 P. J. Jensen and K. H. Bennemann, Solid State Commun.

14 L. M. Levinson, M. Luban, and S. Shtrikman, Phys. Rev.

15 A. Hucht and K. D. Usadel, (unpublished).

⋆ Erratum: In the publication this constant has the wrong

value Φ1 = −0.65493."
Comparison of rigidity and connectivity percolation in two dimensions,"  Using a recently developed algorithm for generic rigidity of two-dimensional
graphs, we analyze rigidity and connectivity percolation transitions in two
dimensions on lattices of linear size up to L=4096. We compare three different
universality classes: The generic rigidity class; the connectivity class and;
the generic ``braced square net''(GBSN). We analyze the spanning cluster
density P_\infty, the backbone density P_B and the density of dangling ends
P_D. In the generic rigidity and connectivity cases, the load-carrying
component of the spanning cluster, the backbone, is fractal at p_c, so that the
backbone density behaves as B ~ (p-p_c)^{\beta'} for p>p_c. We estimate
\beta'_{gr} = 0.25 +/- 0.02 for generic rigidity and \beta'_c = 0.467 +/- 0.007
for the connectivity case. We find the correlation length exponents, \nu_{gr} =
1.16 +/- 0.03 for generic rigidity compared to the exact value for connectivity
\nu_c = 4/3. In contrast the GBSN undergoes a first-order rigidity transition,
with the backbone density being extensive at p_c, and undergoing a jump
discontinuity on reducing p across the transition. We define a model which
tunes continuously between the GBSN and GR classes and show that the GR class
is typical.
",http://arxiv.org/pdf/cond-mat/9702249v2,2,"8
9
9
1

p
e
S
1
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

2
v
9
4
2
2
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Comparison of rigidity and connectivity percolation in two dimensions

C. Moukarzel∗
Instituto de F´ısica, Universidade Federal Fluminense,
CEP 24210-340, Niteroi RJ, Brazil.

P. M. Duxbury
Dept. of Physics/Ast. and Center for Fundamental Materials Research,
Michigan State University, East Lansing, MI 48824, USA.

Using a recently developed algorithm for generic rigidity of
two-dimensional graphs, we analyze rigidity and connectivity
percolation transitions in two dimensions on lattices of linear
size up to L = 4096. We compare three diﬀerent universal-
ity classes: The generic rigidity class; the connectivity class
and; the generic “braced square net”(GBSN). We analyze the
spanning cluster density P∞, the backbone density PB and the
density of dangling ends PD. In the generic rigidity and con-
nectivity cases, the load-carrying component of the spanning
cluster, the backbone, is fractal at pc, so that the backbone
density behaves as B ∼ (p − pc)β
for p > pc. We estimate
′
′
c = 0.467 ± 0.007
gr = 0.25 ± 0.02 for generic rigidity and β
β
for the connectivity case. We ﬁnd the correlation length ex-
ponents, νgr = 1.16±0.03 for generic rigidity compared to the
exact value for connectivity νc = 4/3. In contrast the GBSN
undergoes a ﬁrst-order rigidity transition, with the backbone
density being extensive at pc, and undergoing a jump discon-
tinuity on reducing p across the transition. We deﬁne a model
which tunes continuously between the GBSN and GR classes
and show that the GR class is typical.

′

I. INTRODUCTION

Scalar Percolation is a simple model for disordered sys-
tems, and has received much attention in the last two
decades [1–3]. This model describes the transmission of
a scalar conserved quantity (for example electric charge,
or ﬂuid mass) across a randomly diluted system. How-
ever in the calculation of mechanical properties force (
i.e. a vector) must be transmitted across the system [4].
It was originally suggested [6] that the critical behavior
of the elastic moduli of a percolating system should be
equivalent to that of its conductivity, but this is only
valid for the scalar limit of the Born model of elastic-
ity [5], a model which is not rotationally invariant and
in many cases inappropriate. Elastic percolation is not
in general equivalent to scalar percolation. This was ﬁrst
made clear by the work of Feng and Sen [7], which showed
that central-force elasticity percolation was in a diﬀerent
universality class than scalar percolation, and provided
the starting point for a renewed interest in this problem.
It soon became clear that the elasticity problem can
be divided in two categories [13], according to the kind of
forces which hold the lattice together. If angular forces
are important [8–12,15], a singly-connected path across
the lattice is enough to ensure rigidity, so any conﬁg-
In
uration of bonds which is connected is also rigid.
this case, the geometry of the elastic backbone is ex-
actly the same as that of the scalar percolation prob-
lem [9,11,12,15]. This is the case for bond-bending [8,9]
and beam [10,15] models. Thus, the elasticity percola-

1

tion problem with angular forces is now well understood
and that understanding has borrowed much from the ge-
ometrically equivalent scalar percolation problem.
It is
the purpose of this paper to analyze the more challeng-
ing central-force rigidity percolation transition, stressing
the similarities and diﬀerences between this problem and
scalar percolation.

a

b

c

d

e

f

FIG. 1. The six bodies shown in this ﬁgure are rigidly
connected, i.e. they belong to the same rigid cluster. But the
removal of any bond (thin black lines) leads to the collapse of
the structure, which is then reduced to a collection of six in-
dependent rigid clusters (no two are rigidly connected). This
means that the existence of a rigid connection between for ex-
ample clusters e and f cannot be decided on local information
only, since it depends on the presence of ’far away’ bonds, i.e.
bonds not connected to clusters e or f .

forces alone (e.g.

If rigidity [7,14,18,20–23,25,24,32,35] is provided by
rotatable springs), single-
central
connectedness is not enough to ensure rigidity.
In this
case a lattice that is conducting usually would not sup-
it would not be rigid). This
port an applied stress (i.e.
was ﬁrst shown by Feng and Sen [7] who found that the
rigidity threshold is signiﬁcantly larger than the conduc-
tivity threshold. An exception worth mentioning is the
case of elastic lattices under tension, or equivalently, sys-
tems in which all springs have zero repose length [16].
For such systems, conductivity and Young modulus are
equivalent, i.e. rigidity appears at the scalar percolation
point. It has been recently emphasized [17] that entropic
eﬀects can give rise to similar eﬀects in central-force sys-
tems with nonzero repose length and ﬁnite temperature,
although the connection with ref. [16] was not established.
The main diﬃculties associated with central-force elas-
ticity are as follows: Whereas in the scalar connectivity
case it is a trivial problem to determine when two sites be-
long to the same connected cluster, in the case of central-
force rigidity it is not in general easy to decide whether
two objects are rigidly connected. For example it takes
some thinking to see that the six bodies in Fig. 1 form
a rigid unit. Thus it is not easy to see how a computer
algorithm can be devised to identify rigid clusters.

In the scalar connectivity problem, the removal of a

 
 
 
 
 
 
singly-connected bond leads to the separation of a con-
nected cluster into two clusters. In the rigidity case, the
removal of an analogous “cutting bond” may produce the
collapse of a rigid cluster to a collection of an arbitrarily
large number of smaller ones (we call this the house-of-
cards mechanism). Fig. 1 shows a simple example of this
situation. Due to this fact, the transmission of rigidity
can be “non-local” [14,32], since a bond added between
two clusters on one side of the sample may induce rigidity
between two clusters on the other side of a sample.

a)

b)

FIG. 2. Three bars are in general enough to form a rigid
connection between two rigid bodies (case a), but for partic-
ular, degenerate cases (case b), rigidity fails even when the
system has the right number of bars. Case b fails to be rigid
because the three bars happen to have a common point. A
structure formed by two bodies connected by three bars is
generically rigid in two dimensions if it is rigid “for most ge-
ometrical arrangements”, i.e. leaving aside degenerate conﬁg-
urations such as b), which occur with probability zero in the
conﬁguration space.

A second source of diﬃculties in the problem of central-
force rigidity is the existence of particular geometrical
arrangements for which a system may fail to be rigid [39]
even if it is rigid for most other cases [28,27,30,32]. Take
for example two rigid bodies connected by three bars in
two dimensions, as shown in Fig. 2. This structure is
in general rigid, but if the three bars happen to have
a common point, then the structure is not rigid, since
this common point is the center of relative rotations [32]
between the two bodies.

Particular geometrical arrangements (such as Fig. 2b),
which are non-rigid even when the structure is rigid for
most other conﬁgurations, are called degenerate conﬁg-
urations. Degenerate conﬁgurations appear with proba-
bility zero if the lattice locations are “randomly chosen”.
A lattice is thus said to be generically rigid, if it is rigid
for most geometrical arrangements of its sites. Generic
rigidity only depends on the topology of the underlying
graph, i.e.
ignores the possibility of degeneracies. Since
degenerate conﬁgurations are always possible on perfectly
regular lattices, we will assume our lattice sites to have
small random displacements, in which case generic rigid-
ity applies.

Up to recently, no simple algorithms existed for the
determination of the rigid-cluster structure of arbitrary
lattices. Due to this, direct solving of the elastic equa-
tions was one of the few methods [4] available to obtain
information on the structure of rigidly connected clus-
ters. But this is very time-consuming and did not allow
the study of large lattices. Previous simulations were
for example not suﬃciently precise to conﬁrm or reject
the proposal [18–20] that bond-bending and central-force

2

elastic percolation might after all still be in the same uni-
versality class. This suggestion was not inconsistent with
some numerical results obtained on small-sized systems
[18–22].

Recently there has been a breakthrough in the sys-
tem sizes accessible to numerical analysis [23–25], fol-
lowing the development of eﬃcient graph-theoretic meth-
ods for the problem or generic rigidity in two dimensions
[27,30,31]. Using such methods, we study the central-
force rigidity percolation problem on randomly diluted
triangular lattices of linear size up to L = 3200, and con-
nectivity percolation and body-joint rigidity percolation
on site-diluted square lattices of size up to L = 4096. Our
numerical algorithm [30] is complementary to the “pebble
game” [24,31], which is an implementation of Hendrick-
son’s matching algorithm in the original “joint-bar” rep-
resentation of the network [27](see below). This paper is
an elaboration and extension of our two recent letters on
this subject [23,25]. We extend and elaborate upon the
numerical data presented there in several ways: by com-
paring rigidity and connectivity percolation, by studying
signiﬁcantly larger lattices for rigidity percolation, by giv-
ing data on site and bond diluted lattices with a variety
of boundary conditions; by presenting results on a new
body-joint model which is in the universality class of bar-
and-joint rigidity percolation and; by presenting detailed
results for a model which continuously tunes between the
braced square lattice (which has a ﬁrst order rigidity tran-
sition) and the isotropic triangular lattice (which has a
second order rigidity transition).

The numerical method is brieﬂy described in Section II.
In Section III, our results are presented and their implica-
tions discussed. A comparison is made with other avail-
able numerical and analytical results for the central-force
rigidity percolation problem. We also discuss the issue of
ﬁrst-order rigidity, which has been the subject of a com-
ment and reply in physical review letters [26]. Section IV
contains our conclusions.

II. THE NUMERICAL METHOD

We take an initially depleted triangular lattice and add
bonds (in the bond-diluted case) or sites (in the site-
diluted case) to it one at a time, and use a graph-theoretic
matching algorithm [30] in order to identify the rigid clus-
ters that are formed in the system. For the case of bond
dilution, p is the density of present bonds, while in site
dilution it indicates the density of present sites. In the
site-diluted problem, a bond is present if the two sites it
connects are.

We use the body-bar version [30] of a recently proposed
rigidity algorithm [27]. This algorithm, being combina-
torial in nature, allows us to identify sets of sites which
are rigidly connected, without providing any information
on the actual values of the stresses when an external load
is applied. The body-bar algorithm sees the lattice as
a collection of rigid clusters (or “bodies”) connected by
bars, instead of points connected by bars as proposed
in the original algorithm [27] and as implemented in the
“pebble game” [31]. The body-bar representation allows
a more eﬃcient use of CPU and memory, as each rigid
cluster is represented as one object. The matching iden-
tiﬁes rigid clusters and condenses them to one node as
new bonds are added to the network.

In two-dimensional rigidity, a rigid cluster has 3 degrees

of freedom, while a point-like joint has 2. Therefore the
minimum number of bonds needed to rigidize n joints in
2d is (2n − 3). Matching algorithms [27,30,31] are based
on this sort of constraint-counting.

FIG. 3.

Inﬁnite percolation clusters which lie in diﬀerent
universality classes: a) Connectivity percolation (g = G = 1)
on a triangular lattice; b) Rigidity percolation (g = 2, G = 3)
on a triangular lattice; c) Rigidity percolation (g = 2, G = 3)
on a braced square lattice. For a) and b), boundary conditions
are periodic in the horizontal direction while for c) they are
free. The system size L = 64 and rigid bus-bars are set on
the upper and lower ends of the sample. The backbone, is
composed of ’blobs’ of internally stressed bonds (thick black
lines), rigidly interconnected by cutting bonds (gray lines).
Cutting bonds are also called red bonds. Removing one of
them produces the collapse of the system. Dangling ends (thin
lines) are rigidly connected to the backbone, but do not add
to the ability of these networks to carry a DC external load
(or current).

The body-bar algorithm [30], can be extended to han-

3

dle “rigidity problems” with arbitrary values of g (num-
ber of degrees of freedom of a joint) and G (degrees of
freedom of a rigid cluster). Connectivity for example,
is just a special (simple) case of rigidity with g = 1 and
G = 1: the minimum number of bonds needed to connect
n points is n − 1 in any dimension. Connectivity perco-
lation can thus be studied using this algorithm. More
details on the application of matching algorithms for the
speciﬁc case of connectivity percolation can be found in
Ref. [43].

There are several ways to deﬁne the onset of global
rigidity in a network [23]. We have used two distinct
methods. First we determine whether an externally ap-
plied stress can be supported by the network, which we
call applied stress (AS) percolation. Secondly we studied
the percolation of internally-stressed (IS) regions.

At the AS percolation point, an applied stress is ﬁrst
able to be transmitted between the lower and upper sides
of the sample. As we add bonds one at a time, we are
able to exactly detect this percolation point by perform-
ing a simple test [30] which consists in connecting an
additional ﬁctitious spring between the upper and lower
sides of the system. This auxiliary spring mimics the ef-
fect of an external load, and therefore the ﬁrst time that
a macroscopic rigid connection exists, a globally stressed
region (the backbone) appears.

The IS critical point is deﬁned as the bond- or site
density at which internal stresses percolate through the
system. This means that the upper and lower sides of
the system belong to the same self-stressed cluster [23],
and this is trivially detected within the matching algo-
rithm [30]. The AS and IS deﬁnitions of percolation are
in principle diﬀerent, but we found [23] that the average
percolation threshold and the critical indices coincide for
large lattices. Similar deﬁnitions apply to the connectiv-
ity case, with the AS case being the usual deﬁnition, i.e.
the onset of electric conductivity, and IS being percola-
tion of “Eddy currents”.

We deﬁne the spanning cluster (Fig. 3) as the set of
bonds that are rigidly connected to both sides of the
sample. However only a subset of these bonds carry the
applied load. This subset is called the backbone. The
backbone will in general include some cutting bonds, so
named because the removal of any one of them leads to
the loss of global load carrying capability. Cutting bonds
attain their maximum number exactly at pc [38]. The
backbone bonds which are not cutting bonds are parts of
internally overconstrained blobs. In the rigidity case, the
smallest overconstrained cluster on a triangular lattice is
the complete hexagonal wheel (twelve bonds), while in
the connectivity case it is a triangle (i.e.
the smallest
possible loop). The spanning cluster also contains bonds
which are rigidly connected to both ends of the sample
but which do not carry any of the applied load. These
are called dangling ends. This classiﬁcation is standard
in connectivity (scalar) percolation [37].

In this work we analyze several other boundary condi-
tions, particularly in the generic rigidity case on triangu-
lar lattice. In that case, for site dilution we analyze: AS
with rigid bus-bars at the ends of the sample, AS with-
out bus bars (any-pair rigidity), and IS with bus-bars.
For bond dilution, only the AS with bus-bars case was
studied. We determine the exact percolation point (AS
or IS) for each sample, so we can identify and measure
the diﬀerent components of the spanning cluster exactly
at pc for each sample. This should be contrasted with

usual numerical approaches, in which averages are done
at ﬁxed values of p, and < pc > is obtained from ﬁnite-
size scaling (e.g. data collapse). In that case, it is known
that slight diﬀerences in the estimation of < pc > can
lead to important deviations in critical indices [18]. This
source of error is absent in our measurements. Sample
averages are done over approximately 108/L2 samples.

III. RESULTS

We ﬁrst analyze the size dependence of the three key
probabilities PB, the backbone density, PD, the dangling
end density and P∞, the inﬁnite cluster density, exactly
at their percolation thresholds as described in the previous
section. In Fig. 4a-c, this data is presented for the three
diﬀerent universality classes in Figs. 3a-c.

1.00

0.10

1.00

0.10

0.01

a

c

10

100
                                L(cid:12)

1000

b

d

10

100

1000

FIG. 4.

Density of backbone bonds (circles), dan-
gling bonds (squares) and inﬁnite cluster bonds (diamonds)
at the AS critical point for: a) Connectivity percolation
(g = G = 1) on a site-diluted square lattice; b) Rigidity
percolation (g = 2, G = 3) on a site-diluted triangular lattice;
c) Rigidity on a randomly braced square lattice; d) Body
rigidity (G = g = 3) on a site-diluted square lattice .

Case c corresponds to the generic braced square net
(GBSN), which is a square lattice to which diagonals are
added at random with probability p. The non-generic
version of this problem has been studied by many au-
thors [33–35], and it is well known that the number of di-
agonals needed to rigidize it is not extensive: pc ∼ 0 when
L → ∞. This is conﬁrmed by our numerical simulations,
which correspond to the bus-bar boundary condition.

In Fig. 4d we also present data for the rigidity case
g = 3, G = 3 on a square lattice, to further test whether
the rigidity class is universal in two dimensions. In this
model each site of a square lattice is a body and so has
g = 3 degrees of freedom. Each of these bodies is con-
nected to each adjacent body by two bonds or bars, i.e.
two contiguous bodies are pinned at a common point.
Maxwell counting [46] then implies f = 3 − 4p, so that
the Maxwell estimate of the bond percolation threshold
is 3/4. Our numerical estimate is pc = 0.74877 ± 0.00005,
thus conﬁrming the accuracy of the Maxwell approxima-
tion.

4

One clear feature of Fig. 4 is that the BSN (Fig. 4c) has
a qualitatively diﬀerent behavior than the other cases.
For the BSN, PB, P∞ and PD all have a ﬁnite density
at large L, indicating that the rigidity transition is ﬁrst
order in this case.
In contrast, in both the connectiv-
ity(Fig. 4a) and rigidity cases (Figs. 4b,d), PB and P∞
are decreasing in a power law fashion over the available
size ranges. However the behavior of PD is more complex.
First we discuss the behavior of PB.

At a second order phase transition, ﬁnite-size scal-
ing theory predicts PB(pc) ∼ L−β
/ν . Taking into ac-
count correction-to-scaling terms, which we assume to be
power-law, we may generally write

′

PB = C1L

−e(1 + C2L

−ω).

(1)

This expression is ﬁtted to our numerical data by
choosing the set of parameters {C1, C2, e, ω} that min-
imize the error

P measured

B

− P f it
B

P measured

B

2

.

!

E =

X

(2)

A plot of −log(PB)/log(L) vs. 1/log(L) should then
have an asymptotic (L → ∞) intercept equal to the lead-
ing exponent e. Similar ﬁtting procedures were used to
produce Figures 5 and 8, where the leading exponent is
β/ν and 1/ν respectively.

A ﬁt of the data in Fig. 4b,d produces a rather universal
estimate β′
gr/ν = 0.22 ± 0.02. In consequence the rigid
backbone is fractal at pc, with a fractal dimension DB =
1.78±0.02. In the connectivity case (Fig. 4a), we ﬁnd [43]
β′/ν = 0.350 ± 0.005, or DB = 1.650 ± 0.005, which is
consistent with the most precise prior work [44,45].

Now we consider P∞ and PD. In the connectivity case
(Fig. 4a), an analysis of the dangling ends and inﬁnite
cluster probabilities (Fig. 5a) both lead to the estimate
β/ν = 0.10 − 0.11, in agreement with the exact result
5/48. In the rigidity case however, there are strong ﬁnite
size eﬀects and even at sizes of L = 3200 (joint-bar rigid-
ity, Fig 4b), and L = 4096 (body-joint rigidity, Fig. 4d,
it looks as though the dangling probability may be satu-
rating, while the inﬁnite cluster density continues to de-
crease. Since P∞ = PB + PD, it is expected that asymp-
totically P∞ and PD must behave in the same manner.

Clearly the numerical results for the range of system
sizes currently available are still controlled by ﬁnite size
eﬀects, and the results depend on the analysis method
chosen. Jacobs and Thorpe [24] chose to interpret the
inﬁnite cluster probability as being key. A ﬁt to the P∞
data of Fig. 4b,d yields β/ν = 0.147±0.005 (See Fig. 5b,c)
in agreement with Jacobs and Thorpe. But a similar ﬁt
of the dangling end density gives β/ν ∼ 0.03 for the joint-
bar rigidity case (Fig. 5b) and β ∼ 0.01 for the body-joint
rigidity case (Fig. 5c). In our previous work [25] we were
guided by the Cayley tree results [36] which indicated a
ﬁrst order jump in the inﬁnite cluster probability. We
thus chose to interpret Fig. 4b,d as indicating a satu-
ration of the inﬁnite cluster probability at the dangling
end value of about 0.1. Having extended our data from
L = 1024 to L = 4096, it now looks more likely that a
small value of β occurs in the rigidity case (Fig. 5b,c),
though much larger simulation sizes are required to ﬁnd
β/ν precisely.

Due to the slow ﬁnite size eﬀects found in the analysis
of the inﬁnite cluster and dangling end probabilities, it
is natural to be concerned about the eﬀect of boundary

 
conditions and other, usually non-universal, parameters
on the observed results. For generic joint-bar rigidity case
on triangular lattices we thus tested a variety of diﬀer-
ent boundary conditions for both site and bond dilution.
This data is presented in Fig. 6, from which it is seen
that the conclusions drawn from the case of rigidity per-
colation with applied bus bars are quite robust.

β/ν

β/ν

β/ν

1.0

0.8

0.6

0.4

0.2

0.0

1.2

0.8

0.4

0.0

1.0

0.8

0.6

0.4

0.2

0.0

0.0

0.2

0.4

0.6

0.8

1.0

1/log(L)

0.0

0.2

0.4

0.6

0.8

1.0

1/log(L)

0.0

0.2

0.4
1/log(L)

0.6

0.8

no dangling ends. There then must be a maximum in
the density of dangling ends between pc and p = 1. As
seen in Fig. 7, the interesting feature is the abrupt drop
in the dangling density at pc, a feature that appears to
become more pronounced with increasing sample size. It
is tempting to interpret this as deﬁnitive evidence of a
ﬁrst order rigidity transition, but it is also consistent with
the strong ﬁnite size eﬀects seen in Figs. 4b,d and Fig. 6,
so we must await large lattice simulations for a deﬁnitive
analysis.

1.00

0.10

0.01

10

100
L

1000

FIG. 6.

Backbone density PB (solid lines) and dan-
gling-end density PD (dashed lines) as a function of sam-
ple size at the percolation threshold of each sample, on tri-
angular lattices for: bond-diluted AS with bus-bars (cir-
cles), site-diluted AS with bus-bars (diamonds), site-diluted
AS without bus-bars (triangles) and site-diluted IS without
bus-bars. The AS percolation point without bus-bars is de-
ﬁned as the concentration of sites or bonds for which there is
for the ﬁrst time a rigid connection between at least one pair
of points on opposite sides of the sample.

0.10

0.08

0.06

0.04

0.02

FIG. 5.

The spanning cluster density exponent β/ν as
numerically estimated for a) connectivity percolation on a
square lattice (Lmax = 4096), b) rigidity percolation on a
triangular lattice (Lmax = 3200) and c) body rigidity on a
square lattice (Lmax = 4096). Two estimates result in each
case from ﬁtting the scaling of spanning cluster density (tri-
angles) and dangling end density (circles). Solid lines are ﬁts
using Eq. (1)

0.00

0.60

0.70

0.80
P

0.90

1.00

FIG. 7. Fraction of dangling ends on the (g = 2, G = 3)
for
generic rigidity inﬁnite cluster, as a function of p,
site-diluted triangular lattices of size L = 32, 64, 128, 256,
512 and 1024. Data shown here are for the AS case with
bus-bars.

Finally, the behavior of the dangling end density as a
function of p is also quite striking. This data is presented
in Fig. 7. At very high p, nearly all bonds belong to the
backbone, so the dangling end density approaches zero.
Below pc, there is no inﬁnite cluster, so there are again

Now we turn to the calculation of the correlation
length exponent for rigidity percolation. When there
is a second-order rigidity transition,
there is a di-
verging correlation length ξ ∼ |p − pc|−ν. We can
ﬁnd the exponent ν of this divergence by measuring

5

the sample-to-sample ﬂuctuations in pc as a function
L),
of L. The dispersion σ(L) =
and according to ﬁnite-size-scaling σ(L) ∼ L−1/ν.

c >L − < pc >2

( < p2

p

1.2

1.1

1.0

0.9

0.8

0.7

0.6

1/ν

0.5

0.0

0.2

0.4

0.8

1.0

1.2

0.6
1/log(L)

1.6

1.4

1/ν

1.2

1.0

0.8

0.0

0.2

0.4

0.8

1.0

0.6
1/log(L)

1.20

1.10

1/ν

1.00

0.90

0.80

0.8

0.0

0.6

0.2

0.4
1/log(L)
FIG. 8. The thermal exponent 1/ν as numerically esti-
mated for a) connectivity percolation (g = G = 1) on square
lattice, b) rigidity percolation (g = 2, G = 3) on a triangular
lattice and c) body rigidity on a square lattice (G = g = 3).
Two independent estimates result in each case from ﬁtting the
scaling of red bonds (triangles) and ﬂuctuations in pc (circles).

An asymptotic analysis for σ(L) is shown in Fig. 8a for
connectivity percolation, in 8b for joint-bar rigidity and
in 8c for body-joint rigidity. From these ﬁgures we esti-
mate 1/ν = 0.75 ± 0.01 (the exact value is 1/ν = 3/4) for
connectivity percolation and 1/ν = 0.85±0.02 for rigidity
percolation. This provides further strong evidence that
rigidity percolation is second order in two dimensions,
though not in the same universality class as scalar perco-
lation. In the case of the ﬁrst order rigidity on the braced
square net (Fig. 9c), the variations in pc behave as L−3/2,
in accordance with analytical results for this model [40].

6

1.00

0.10

10

100
L

1000

1.0000

0.1000

0.0100

0.0010

0.0001

1.0000

0.1000

0.0100

0.0010

0.0001

10

100
L

1000

10

100
L

1000

FIG. 9.

The volume fraction of a) backbone bonds b)
cutting bonds, and c) the ﬂuctuation σ(pc) at the rigidity
threshold for: Square lattice with q = 0 - this is the braced
square net (ﬁlled squares); Square lattice with q = 0.1 (cir-
cles); Square lattice with q = 0.40 (squares); Triangular lattice
with bond dilution (diamonds) and Triangular lattice with site
dilution (triangles).

Our algorithm also identiﬁes the cutting (also called
red or critical) bonds at the percolation point, for the
case of AS percolation. The number NR of red bonds
scales at pc as Lx. Coniglio [38] has shown that x =
1/ν exactly, for scalar percolation. Numerical evidence
suggesting that x = 1/ν also in rigidity percolation was
ﬁrst presented in [23].
It is in fact possible to extend
Coniglio’s reasoning to the case of central-force rigidity
percolation [40].
It turns out that x = 1/ν has to be
rigorously satisﬁed also in this case, and therefore σ(L)
and 1/NR(L) must have the same slope in a log-log plot.
Analysis of the number of cutting bonds is also presented
in Fig. 8, and yields values of 1/ν consistent with the
analysis of variations in percolation thresholds described

in the previous paragraph.

Since the Cayley tree model [36] gives behavior quite
similar to the braced square net [35], i.e. a ﬁrst-order
rigidity transition, it is interesting to ask whether the
rigidity transition is “usually” like that on the braced
square net (i.e. ﬁrst order), or whether the second order
transition found on triangular lattices is more typical. In
order to probe this issue, we analyze a model which inter-
polates between the braced square net and the triangular
lattice. In the braced square net, the random diagonals
are present with probability pd, to make the lattice rigid
it is suﬃcient (though not necessary) to add one diagonal
to every row of the square lattice. The probability that
a spanning cluster exists is then P+ = (1 − (1 − pd)L)L,
from which we ﬁnd pd∗ ∼ lnL/L.

We generalize this model by randomly adding the di-
agonals (with probability pd) to a square lattice whose
bonds have been diluted with probability q. The braced
square net is q = 0, while if q = 1 − pd this model is
equivalent to the bond-diluted triangular lattice. Typi-
cal results for various values of q are presented in Fig. 9.
It is seen that even for a small amount of dilution of the
square lattice, e.g. q = 0.10, the rigidity transition re-
turns to the behavior characteristic of the homogeneously
diluted triangular case (see Fig. 9). We ﬁnd that for suf-
ﬁciently large lattice sizes, the universal behavior found
in the other rigidity cases holds for any ﬁnite q < 0.5 (for
larger values of q it is not possible to rigidize the lattice
by randomly adding diagonals), and we suggest that the
“fully-ﬁrst-order” transition (i.e. a ﬁrst-order backbone)
only occurs in the special case of a perfect (undiluted)
square lattice.

IV. CONCLUSIONS

We have compared three types of percolation transi-
tion in two dimensions: the connectivity transition and;
the generic rigidity transition on the triangular lattice
and; the generic rigidity transition on the braced square
lattice. A summary of our understanding is as follows:
(i) The generic rigidity transition on triangular lattices
is second order with ν = 1.16 ± 0.03, 0 ≤ β ≤ 0.2,
β′ = 0.25 ± 0.02 and; (ii) The rigidity transition on
the braced square net is ﬁrst order with ﬁnite backbone,
spanning cluster and cutting bond densities at the per-
colation threshold. Only the value of β for the generic
rigidity transition on triangular lattices remains contro-
versial, due to the very strong ﬁnite size eﬀects in that
case.

To illustrate the fact that our data is inconsistent with
a ﬁrst order backbone in the site-joint rigidity case, we
have developed the following scaling argument.

Assume that the backbone mass [41] scales as MB ∼
LDB at pc. If the backbone is compact then DB = d, the
dimension of the system. The backbone mass is com-
posed of red (or cutting) bonds plus “blobs” of over-
constrained, or self-stressed bonds (See Fig. 3). There-
fore MB = Mred + Mblobs. The number of red bonds
in the backbone scales as Mred ∼ L1/ν, as analytical
results [38,40] and the simulations reported here show.
Let us furthermore write Mblobs = nblobs × mblobs where
nblobs is the number of blobs in the backbone, and mblobs
be the average number of bonds in a blob. Therefore
LDB ∼ L1/ν + nblobsmblobs. Now, the AS backbone is an
exactly isostatic body-bar structure, formed by rigid clus-

ters (blobs) joined by bars (red bonds) so that count-
ing of degrees of freedom is exact on it and so Mred =
3nblobs + 2ns − 3 [30]. Here ns is the number of sites in
the backbone, that do not belong to a blob (see Fig. 3).
This identity is known as Laman’s condition [29,30], and
results from the fact that each red bond acts as a bar
and therefore restricts one degree of freedom, while each
blob has three degrees of freedom and isolated sites have
two. The backbone is a rigid cluster and therefore has
three overall degrees of freedom. We do not need to
know ns for our argument. It is enough to notice that
nblobs ≤ Mred/3 ∼ L1/ν. We can thus write

LDB ≤ L1/ν(1 + mblobs/3)

(3)

To this point, we have made no assumption about the
character (compact or fractal) of the backbone, so it is
valid in general. If the transition is second-order, there is
a divergent length (for example, the size of rigid clusters),
and we expect mblobs to diverge with system size. There-
fore a non-trivial value results for DB, as we ﬁnd numer-
ically. If on the other hand there is no diverging length
in the system, then mblobs → constant for large systems
and DB = d = 1/ν exactly. We thus see that a compact
backbone requires an extensive number of cutting bonds,
and this in turn can only be satisﬁed if ν = 1/d exactly
[42]. This is completely inconsistent with our data, and
so the possibility of a ﬁrst order backbone is remote in
two dimensions.

The ﬁrst order rigidity transition exhibited by the
braced square net seems to be atypical as we illustrated
using a model which tunes continuously from that limit
toward the generic triangular lattice. We found that even
a small deviation from the braced square lattice limit
leads to a behavior similar to that of the triangular lat-
tice. It would be intriguing if there were a tricritical point
at which ﬁrst order rigidity ceases and second order rigid-
ity sets in, but we have not found a model which exhibits
that behavior. Nevertheless there are a large number of
other rigidity models in two dimensions, so the possibility
is not yet ruled out.

C. M. acknowledges ﬁnancial support of CNPq and
FAPERJ, Brazil. This work has been partially supported
by the DOE under contract DE-FG02-90ER45418, and
the PRF. We are grateful to HLRZ J¨ulich for the contin-
ued use of their computational resources.

[1] D. Stauﬀer and A. Aharony, Introduction to Percolation
Theory, 2nd. Edition (Taylor and Francis, London), 1994.
[2] J. W. Essam, Percolation Theory, Rep. Prog. Phys. 43

(1980), 53.

[3] A. Bunde and S. Havlin, Fractals and Disordered Systems,

(Springer, Berlin), 1991.

[4] M. Sahimi, Progress in Percolation Theory and its Appli-
cations, in: ”Annual Reviews of Computational Physics
II”, edited by D. Stauﬀer, (World Scientiﬁc), 1995.

[5] M. Born and K. Huang, Dynamical Theory of Crystal

Lattices (Oxford Univ. Press, New York), 1954.

[6] P. G. de Gennes,On a relation between percolation theory
and the elasticity of gels, J. Physique Lett. (France) 37
(1976), L1.

[7] S. Feng and P. Sen, Percolation on Elastic Networks: New

7

Exponent and Threshold, Phys. Rev. Lett. 52 (1984),
216.

[8] Y. Kantor and I. Webman, Elastic Properties of Random
Percolating Systems, Phys. Rev. Lett. 52 (1984), 1891.
[9] S. Feng, P. Sen, B. Halperin and C. Lobb, Percolation
on two-dimensional elastic networks with rotationally in-
variant bond-bending forces, Phys. Rev. B 30 (1984),
5386.

[10] S. Feng, Percolation properties of granular elastic net-
works in two dimensions, Phys. Rev. B 32 (1985), 510.
[11] M. Sahimi, Relation between the critical exponent of elas-
tic percolation networks and the conductivity and geomet-
rical exponents, J. Phys. C: Solid State 19 (1986), L79-
L83.

[12] J. Zabolitsky, D. Bergmann and D. Stauﬀer, Precision
Calculation of Elasticity for Percolation, J. Stat. Phys.
44 (1986), 211.

[13] M. F. Thorpe, Rigidity Percolation, in “Physics of Disor-
dered Materials”, edited by D. Adler, H. Fritzsche, and
S. Ovishinsky (Plenum, New York), 1985.

[14] A. Day, R. Tremblay and A.-M. Tremblay, Rigid Back-
bone: A New Geometry for Percolation, Phys. Rev. Lett.
56 (1986), 2501.

[15] S. Roux, Relation between elastic and scalar transport ex-
ponent in percolation, J. Phys. A: Math. Gen. 19 (1986),
L351.

[16] W. Tang and M. F. Thorpe, Mapping between ran-
dom central-force networks and random resistor networks,
Phys. Rev. B 36 (1987), 3798; Percolation of elastic net-
works under tension, Phys. Rev. B 37 (1988), 5539.
[17] M. Plischke and B. Jo´os, Phys. Rev. Lett. 80 (4907),
1998, B. Jo´os, M. Plischke, D.C. Vernon and Z. Zhou in
Rigidity theory and applications, Edited by M.F. Thorpe
and P.M. Duxbury (Plenum 1998).

[18] S. Roux and A. Hansen, Transfer-Matrix Study of the
Elastic Properties of Central-Force Percolation, Euro-
phys. Lett. 6 (1988), 301.

[19] A. Hansen and S. Roux, Multifractality in Elastic Perco-

lation, J. Stat. Phys. 55 (1988), 759.

[20] A. Hansen and S. Roux, Universality class of central-force

percolation, Phys. Rev. B 40 (1989), 749.

[21] M. Knackstedt and M. Sahimi, On the Universality of
Geometrical and Transport Exponents of Rigidity Perco-
lation. , J. Stat. Phys. 67 (1992), 887.

[22] S. Arbabi and M. Sahimi, Mechanics of disordered solids.
I. Percolation on elastic networks with central forces. ,
Phys. Rev. B 47 (1993), 695.

[23] C. Moukarzel and P. M. Duxbury, Stressed backbone
of random central-force systems, Phys. Rev. Lett. 75
(1995), 4055.

[24] D. J. Jacobs and M. F. Thorpe, Generic Rigidity Perco-
lation: The Pebble Game, Phys. Rev. Lett. 75 (1995),
4051. D. J. Jacobs and M. F. Thorpe, Generic rigidity
percolation in two dimensions, Phys. Rev. E 53 (1996),
3683.

[25] C. Moukarzel, P. M. Duxbury and P. Leath, Inﬁnite clus-
ter geometry in central-force networks, Phys. Rev. Lett.
78 (1997), 1480.

[26] D. J. Jacobs and M. F. Thorpe, Phys. Rev. Lett. 80
(1998), 5451; P. M. Duxbury, C. Moukarzel and P. L.
Leath, Phys. Rev. Lett. 80 (1998), 5452.

[27] Bruce Hendrickson, Conditions for unique graph realiza-

tion, SIAM J. Comput. 21(1992), 65.

[28] H. Crapo Structural Rigidity, Structural Topology

1(1979), 26.

[29] G. Laman, On Graphs and Rigidity of Plane Skeletal

Structures, J. Eng. Math. 4, (1970), 331-340.

[30] C. Moukarzel, An eﬃcient algorithm for testing the rigid-
ity of graphs in the plane, J. Phys. A: Math. Gen. 29

8

(1996), 8097.

[31] D. Jacobs and B. Hendrickson, An algorithm for
two-dimensional rigidity percolation: The pebble game,
J. Comp. Phys. 137 (1997), 346.

[32] E. Guyon et al., Non-local and non-linear problems in the
mechanics of disordered systems: application to granular
media and rigidity problems, Rep. Prog. Phys. 53 (1990),
373-419.

[33] E. Bolker and H. Crapo, How to brace a one-story build-
ing, Environment and Planning B 4 (1977), 125; A. Rec-
ski, Applications of combinatoris to statics, Disc. Mathe-
matics 108 (1992), 183; N. Chakravarty et. al., One-story
buildings as tensegrity frameworks, Structural Topology
12 (1986), 11.

[34] A. K. Dewney, The theory of rigidity, Scientiﬁc Ameri-

can, May issue 1991, p. 126

[35] S. P. Obukov, First order rigidity transition in random

rod networks, Phys. Rev. Lett. 74 (1995), 4472.

[36] C. Moukarzel, P. M. Duxbury and P. L. Leath, First-
order rigidity on Cayley Trees, Phys. Rev. E 55 (1997),
5800; P. M. Duxbury, D. Jacobs, M. F. Thorpe and
C. Moukarzel, 1998 ppt. (cond-mat/9807073).

[37] H. E. Stanley, Cluster shapes at the percolation thresh-
old: an eﬀective cluster dimension and its connection with
critical exponents, J. Phys. A: Math. Gen. 10 (1977),
L211; R. Pike and H. E. Stanley, J. Phys. A: Math. Gen.
14 (1981), L169.

[38] A. Coniglio, Thermal phase transition of the dilute s-state
Potts and n-vector models at the percolation threshold,
Phys. Rev. Lett. 46 (1981), 250; Cluster structure near
the percolation threshold,
J. Phys. A: Math. Gen. 15
(1982), 3829.

[39] We refer in this paper to “inﬁnitesimal rigidity” as rigid-
ity for short. Inﬁnitesimal rigidity is a stronger condition
than rigidity, and implies that no transformation, even
an inﬁnitesimal one, leaves all bar lengths invariant. See
e.g. Refs. [28,27,30]

[40] C. Moukarzel,(1996) unpublished.
[41] We deﬁne the mass of the backbone as the number of
bonds belonging to it. It is not correct to count sites in
rigidity percolation, since they can simultaneously belong
to several rigid clusters.

[42] The randomly braced square lattice model has an exten-
sive number of cutting bonds, but 1/ν 6= 2. Therefore
it apparently violates Coniglio’s relation. The explana-
1/ν only holds for the number of
tion is that NR ∼ L
diagonals that are cutting bonds. There are, in addition
to those, the cutting bonds which belong to the square
2
lattice substrate, and these are O(L
). The reason for a
completely ﬁrst-order transition in this model is therefore
the existence of an homogeneous, almost rigid substrate;
the square lattice, which provides an extensive number of
cutting bonds.

[43] C. Moukarzel (1998), “A fast algorithm for backbones”,

Int. J. Mod. Phys. C, to appear; (cond-mat/9801102).

[44] M. Rintoul and H. Nakanishi, A precise determination of
the backbone fractal dimension on two-dimensional perco-
lation clusters, J. Phys. A: Math. Gen. 25 (1992), L945.
[45] P. Grassberger, Spreading and backbone dimension of 2d
percolation, J. Phys. A: Math. Gen. 25 (1992), 5475.
[46] The Maxwell approximation consists in ignoring the exis-
tence of redundant bonds, i.e. assuming that each present
bond eliminates one degree of freedom from a total of
F = gN . The critical concentration is then obtained by
equating f = F/N to zero."
Effect of Size Dispersity On the Melting Transition,"  We present a molecular dynamics simulation study of the liquid-solid
transition in a two dimensional system consisting of particles of two different
sizes interacting via a truncated Lennard-Jones potential. We work with equal
number of particles of each kind and the dispersity $\Delta$ in the sizes of
the particles is varied by changing the ratio of the particle sizes only. For
the monodisperse case ($\Delta = 0$) and for small values of $\Delta$, we find
a first order liquid-solid transition on increasing the volume fraction $\rho$
of the particles . As we increase $\Delta$, the first-order transition
coexistence region weakens gradually and completely disappears at high
dispersities around $\Delta = 0.10$ . At these values of dispersity the high
density phase lacks long range translational order but possesses orientational
order with a large but finite correlation length. The consequences of this
effect of dispersity on the glass transition and on the melting transition in
general are discussed.
",http://arxiv.org/pdf/cond-mat/9703054v1,2,"EFFECT OF SIZE DISPERSITY ON THE MELTING TRANSITION

M.R. SADR-LAHIJANY1, P. RAY2,S. T. HARRINGTON 1 AND H.E. STANLEY1
1 Center for Polymer Studies and Department of Physics, Boston University, Boston, MA
02215 ,USA 2The Institute of Mathematical Sciences, CIT Campus, Madras - 600 113, India

ABSTRACT

We present a molecular dynamics simulation study of the liquid-solid transition in a two
dimensional system consisting of particles of two diﬀerent sizes interacting via a truncated
Lennard-Jones potential. We work with equal number of particles of each kind and the
dispersity ∆ in the sizes of the particles is varied by changing the ratio of the particle sizes
only. For the monodisperse case (∆ = 0) and for small values of ∆, we ﬁnd a ﬁrst order
liquid-solid transition on increasing the volume fraction ρ of the particles . As we increase
∆, the ﬁrst-order transition coexistence region weakens gradually and completely disappears
at high dispersities around ∆ = 0.10 . At these values of dispersity the high density phase
lacks long range translational order but possesses orientational order with a large but ﬁnite
correlation length. The consequences of this eﬀect of dispersity on the glass transition and
on the melting transition in general are discussed.

INTRODUCTION

The liquid-solid transition in a system of densely-packed interacting particles has attracted
considerable attention in recent years[1]. Such a system undergoes a transition from a
disordered liquid phase to an ordered solid phase on increasing the volume fraction of the
particles.
It was further observed that polydispersity in the sizes of the particles has a
profound eﬀect on the transition. With increasing dispersion, the solid structure becomes
unstable and above a certain degree of dispersity the solid cannot form at all[2]. The
consequence of this should be very important from the experimental point of view since
colloidal suspensions in general do have particles of various sizes and show the liquid-solid
transition [3] and in the simulations of glass transition, particles of diﬀerent sizes are always
considered [4]. Still, the eﬀect of size dispersity on the liquid-solid transition has not received
suﬃcient attention. In this paper, we study the eﬀect of size-dispersity on the liquid-solid
transition for interacting particles in two dimensions.

The instability of the solid phase with increasing size dispersity is not striking, as one
would intuitively expect that a high dispersity naturally destroys the crystal order needed
to form a solid. But molecular dynamics (MD) simulation studies in three dimensions [2],
and similar recent studies in two dimensions [5], consistently show the gradual weakening
of the ﬁrst order transition with increasing dispersity ∆ and ﬁnd the existence of a critical
value ∆c where the line of ﬁrst-order transitions ends. At ∆c, one does not see the ﬁrst
order transition. This prediction also arises from a study employing the density functional
theory[6] and simpler models of crystals[7]. The phase diagram is remarkably similar to the
ﬁrst order transitions ending in a critical point that one observes in the temperature driven
liquid-gas transition. We study the transition at and around ∆c by carefully examining the
nature of the phases obtained at diﬀerent densities and dispersities.

7
9
9
1

r
a

M
5

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
4
5
0
3
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

1

 
 
 
 
 
 
PRESSURE AS A FUNCTION OF DENSITY

N=10000,kT=1.0,different dispersities

0.003

0.002

0.001

)

2
σ
/
ε
(

P

∆=0.00
0.06
0.07
0.10

0.0000

0.000

0.60

0.70

0.80

0.90

1.00

1.10

density ρ

Figure 1: Pressure versus density plots for diﬀerent dispersities. The small dispersity curves
show the ﬁrst order phase transition from the low density liquid phase to the high density
2d-solid phase with the intermediate ﬂat coexistence region. The inset is a blow up of the
coexistence regions at diﬀerent dispersities.

MODEL AND SIMULATION

We report a molecular dynamics simulation study of a 50 − 50 mixture of Lennard-Jones
(LJ) particles of two diﬀerent sizes. The particles are contained in a two dimensional box
of linear size L with periodic boundary condition used on all walls. We have performed
our simulations for N = 400, 2500 and 10000 particles. To each particle we assign a radius
proportional to its LJ diameter and deﬁne the density ρ as the ratio of the total area
occupied by the particles to the total area of the box.

The degree ∆ of size dispersity is quantiﬁed by the relative width of the bimodal particle
size distribution function. Here we present results for dispersities ∆ = 0, 0.06, 0.07 and 0.10.
All physical quantities are measured in reduced units in which the average LJ diameter σ,
LJ energy scale ǫ and the mass of each particle are one. Our results are all collected from
the isothermal hyper-surface of the phase space with kT = 1.0, where k is the Boltzmann
constant. Pressure P is computed using the virial relation[8].

RESULTS

Fig. 1 shows the P − ρ diagrams for diﬀerent dispersities ∆. For small ∆, we observe the
ﬂat coexistence region which is a characteristic feature of ﬁrst order phase transition. This
region shrinks as ∆ increases and near ∆ = 0.1 disappears completely.

Fig. 2 shows the mean square displacement (MSD) of the particles at diﬀerent phases
for ∆ = 0 and 0.1. The plots for ∆ = 0 essentially have three features: (i) a late time
diﬀusive regime for low densities (ii) a frozen regime where the diﬀusion is very small for
high densities (iii) a sudden change in the MSD behavior between the two regimes on varying
the density. This jump is one of the characteristic features of a ﬁrst-order phase transition.
We observe these features for other ∆ values but with increasing ∆, the magnitude of the
jump in the MSD plot decreases and the system goes from liquid to solid regime rather

2

 
∆=0(monodisperse)

104

103

102

101

100

10−1

>
2

)
)
0
(
X
−
)
t
(

X
(
<

ρ=0.7

0.85

0.87

0.9

0.95

1.0

∆=0.10

104

103

102

101

100

10−1

101

102

103

104

105

106

101

102

time

ρ=0.7

0.85

0.95

1.0

105

106

103

104

time

Figure 2: Mean square displacement of the particles versus time at diﬀerent densities ρ
(denoted at the end of the curve) for ∆ = 0 and ∆ = 0.10.

continuously. On the other hand the MSD plot for ∆ = 0.10 shows that at high dispersity,
the system does not become solid even at ρ = 1.0.

In order to study the translational symmetry at diﬀerent phases, we measure the total
pair distribution function g(r) (Fig. 3). The form of g(r) for the low density phase has a
liquid-like structure. On the other hand for ∆ = 0, the solid phase at high densities shows
a clear 2d solid-like structure with pronounced peaks, and deep dips which persist up to
long distances, with the amplitude of the peaks decreasing slowly. This quasi-long-range
translational symmetry is expected for solids in two dimensions [9]. For large values of
disperstiy around ∆ = 0.10 and high density the system does not show the solid structure
mentioned above and lacks translational order.

Next, we study the orientational order of the phases by measuring the hexagonal order
parameter ψ6 [10] which characterizes the local bond orientational order around particles.
The absolute value of ψ6 increases from a small positive value to one as the structure changes
from disorder to an ordered triangular lattice. We have plotted the distribution of |ψ6| for
all particles (see Fig. 4). The liquid phase has a ﬂat distribution, thus not showing any
local orientational order [10]. The solid phase shows a high degree of local orientational
order, since it forms a nearly perfect triangular lattice. On the other hand for ∆ = 0.10
the ρ = 1.0 system shows a hump near unity but also a big tail extending down to zero.
The hump conﬁrms the existence of local hexagonal order which has also been observed
in experiments on bidisperse hard spheres[11]. The presence of the long tail indicates that
there are many orientational defects in the system, as a result of size dispersity. These
defects are disclinations and appear as distorted hexagonal or pentagonal and heptagonal
neighboring particle arrangements around the particles.

CONCLUSION

We ﬁnd that a geometrical factor like the dispersity ∆ in the particle sizes has a similar
eﬀect on the liquid-solid transition as the temperature (thermal energy) has on the liquid-

3

6.0

4.0

2.0

)
r
(
g

∆=0.0

ρ=0.7

ρ=0.87

ρ=0.88

ρ=0.95

ρ=1.0

6.0

4.0

2.0

∆=0.10

ρ=0.85

ρ=0.9

ρ=0.93

ρ=0.95

ρ=1.0

0.0

0.0

10.0

r

20.0

30.0

0.0

0.0

10.0

r

20.0

30.0

Figure 3: Total pair distribution function for two diﬀerent dispersities, all graphs are cen-
tered around g(r) = 1.0 but are shifted to make comparison easier; In monodisperse systems,
the low density plots show the characteristics of liquid and the high density ones that of
solid. For ∆ = 0.10 systems, even the highest density studied , ρ = 1.0 does not show the
quasi-long-range order which is characteristic of a 2d solid.

gas transition. ∆ weakens the ﬁrst order transition from the liquid state to the solid state
driven by the volume fraction ρ of the particles. This observation supports the earlier similar
observations in diﬀerent systems like in elastic disk systems[5] and in colloidal systems [2]
with polydispersity in the sizes of the particles. We further observe that at high values of ∆,
the system always remains at the ﬂuid phase. This is the region where one can observe glass
transition. Our study provides a quantitative measure of the size dispersity ∆, which would
be needed to observe the glass transition. It further indicates that there may not be any true
phase transition (in the thermodynamic sense) in the process of glass transition. We will
provide detailed evidence for this conclusion elsewhere[12] ( see also [13]). However, much
detailed study, specially on the eﬀect of temperature is needed to say anything conclusively.

ACKNOWLEDGMENTS

We wish to thank L. Amaral, B. Kutnjak-Urbanc and W. Kob for useful discussions and
remarks. The Center for Polymer studies is supported by NSF.

REFERENCES

[1] M. A. Glaser and N. A. Clark , Adv. Chem. Phys. 83, 543 (1993)

[2] E. Dickinson and R. Parker, Chem. Phys. Lett. 79, 3 (1981);E. Dickinson, R. Parker

and M. Lal, ibid, 578

[3] In Proceedings of the Winter Workshop on Colloidal Crystals, edts. P. Pieran´ski and

F. Rothan, J. Physique Colloq. C 3, 46 (1985)

4

0.10

0.08

0.06

)
|

6

Ψ

|
(

P

0.04

0.02

∆=0.0(monodisperse)

ρ=1.0

ρ=0.7

∆=0.10

0.10

0.08

0.06

0.04

0.02

ρ=1.0

ρ=0.7

0.00

0.0

0.2

0.4

0.6

0.8

1.0

|Ψ
6|

0.00

0.0

0.2

0.4

0.6

0.8

1.0

|Ψ
6|

Figure 4: |ψ6| distribution for two diﬀerent dispersities; For monodisperse systems, ρ = 0.7
plot belonging to the liquid phase shows no orientational order, ρ = 0.875 plot has a
developing hump along with a very fat tail indicating the coexistence of the solid and liquid
phases, ρ = 0.9 to ρ = 1.0 on the other hand have pronounced peak near one and diminishing
tails , indicating a triangular lattice arrangement of the particles. On the other hand, for
∆ = 0.1, even at ρ = 1.0, we ﬁnd a long tail in the distribution indicating the presence of
many defects in the form of dislocations and disclinations and absence of true long range
orientational order.

[4] W. Kob and H. C. Andersen, Phys. Rev. 52, 4134 (1995)

[5] W. Verm¨ohlen and N. Ito , Phys. Rev. E 51, 4325 (1995)

[6] J. L. Barrat and J. P. Hansen, J. Physique 47, 1547 (1986)

[7] P. N. Pusey, J. Physique 48, 7.9 (1987)

[8] M.P. Allen, D.J. Tildesley Computer Simulation of Liquids, (Oxford University Press,

New York, 1989)

[9] K. Strandburg, Rev. of Mod. Phys. 60, 161 (1988)

[10] M. A. Glaser and N. A. Clark, in Geometry and Thermodynamics, edts. J. C. Tol´edano,
p. 193 (Plenum Press, New York, 1990);M. A. Glaser, N. A. Clark, A.J. Armstrong and
P.D. Beale, in Springer Proceedings in Physics, Vol. 52: Dynamics and Patterns in Com-
plex Fluids, edts. A. Onuki, K. Kawasaki, p. 141 (Springer-Verlag Berlin,Heidelberg
1990)

[11] D. R. Nelson, M. Rubinstein and F. Spaepen, Phil. Mag. A 46, 105 (1982)

[12] M. R. Sadr-Lahijany, P. Ray and H. E. Stanley, unpublished

[13] C. Dasgupta, A. V. Indrani, S. Ramaswamy and M. K. Phani, Europhys. Lett. 15 (3),

307 (1991)

5"
Noise-assisted Mound Coarsening in Epitaxial Growth,"  We propose deposition noise to be an important factor in unstable epitaxial
growth of thin films. Our analysis yields a geometrical relation H=(RWL)^2
between the typical mound height W, mound size L, and the film thickness H.
Simulations of realistic systems show that the parameter R is a characteristic
of the growth conditions, and generally lies in the range 0.2-0.7. The
constancy of R in late-stage coarsening yields a scaling relation between the
coarsening exponent 1/z and the mound height exponent \beta which, in the case
of saturated mound slope, gives \beta = 1/z = 1/4.
",http://arxiv.org/pdf/cond-mat/9703056v1,2,"7
9
9
1

r
a

M
6

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
6
5
0
3
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Noise-assisted mound coarsening in epitaxial growth

Lei-Han Tang(1,3), P. ˇSmilauer(1,2), and D. D. Vvedensky(1)
(1) The Blackett Laboratory, Imperial College, London SW7 2BZ, United Kingdom
(2) Institute of Physics, Cukrovarnick´a 10, 162 00 Praha 6, Czech Republic
(3) Department of Physics, Hong Kong Baptist University, Kowloon Tong, Hong Kong
(June 21, 2021)

We propose deposition noise to be an important factor in unstable epitaxial growth of thin ﬁlms.
Our analysis yields a geometrical relation H = (RW L)2 between the typical mound height W ,
mound size L, and the ﬁlm thickness H. Simulations of realistic systems show that the parameter
R is a characteristic of the growth conditions, and generally lies in the range 0.2-0.7. The constancy
of R in late-stage coarsening yields a scaling relation between the coarsening exponent 1/z and the
mound height exponent β which, in the case of saturated mound slope, gives β = 1/z = 1/4.

68.55.-a, 05.70.Ln, 81.10.Aj, 85.40.Ux

One of the currently-contemplated applications of va-
por phase epitaxy is the fabrication of nanoscale quan-
tum dots or wires. Under suitable conditions, pyramids
or mounds form spontaneously on the ﬁlm surface as a
result of unstable growth. From the device point of view,
the basic challenges lie in one’s ability to (i) control the
size and shape of individual mounds and (ii) enforce great
regularity and uniformity in the mound array. To achieve
these ends, an understanding of the relation between the
growth morphology and the underlying atomic processes
under nonequilibrium growth conditions is desirable.

Moderate surface modulations, as opposed to isolated
three-dimensional islands, are observed when there is ei-
ther a small lattice mismatch between the ﬁlm and sub-
strate, or a surface diﬀusion barrier at step edges, known
as the Ehrlich-Schwoebel (ES) barrier [1]. The second
mechanism, which is the focus of this paper, is purely
kinetic in origin and thus operates also in homoepitaxy.
Villain [2] pointed out that presence of the ES barrier
leads to a nonequilibrium uphill surface mass current
which, in the case of a low Miller index surface, ampliﬁes
weak height ﬂuctuations during growth. Atomistic and
continuum models which incorporate this eﬀect indeed
develop the growth instability [3–6]. Numerical simula-
tions have shown that, after an initial transient period,
mounds of ﬁnite slope appear at the ﬁlm surface, as il-
lustrated in Fig. 1. The pattern of mounds is surpris-
ingly regular, with a characteristic mound size L which
coarsens with the ﬁlm thickness H as

L ∼ H 1/z.

(1)

The exponent 1/z generally lies in the range 0.15-0.25.
The typical height of the mounds W can also be ﬁtted
to a power-law,

W ∼ H β,

(2)

where the exponent β can be as small as 0.25, or as big as
0.5. Both the mound patterns seen in simulations and the

range of exponent values correlate well with some exper-
imental ﬁndings [7,8], but the theoretical understanding
of the coarsening characteristics is still incomplete.

L

δ

H

W

H

film

substrate

FIG. 1. Schematic illustration of the mound morphology
during epitaxial growth. The typical mound size L increases
with the ﬁlm thickness H.

Previous analytical studies of mound coarsening have
focused on deterministic, nonlinear evolution equations
derived from a phenomenological, slope dependent sur-
face current [3,4,9–12]. Analogies have been made to
domain coarsening in magnetic systems, which is itself
a diﬃcult and open problem. In this Letter we suggest
an alternative scenario of mound coarsening assisted by
noise in the deposition ﬂux. We describe some of the
measurable consequences based on this kinetic pathway,
and discuss the interplay between noise-driven ﬂuctua-
tions and deterministic surface evolution. It is hoped that
these considerations will lead to a quantitative scheme for
assessing the eﬀect of growth conditions on mound mor-
phology in both atomistic modelling and experiments.

The mound morphology illustrated in Fig. 1 is usually
characterized by two parameters: the lateral mound size
L and the typical mound height W . (In this paper we fo-
cus on the isotropic case, where mounds typically have a
nearly circular shape.) For the purpose of the following
discussion, we introduce a third parameter, the typical

1

 
 
 
 
 
 
height diﬀerence between neighboring mounds δH. To
see if the deposition noise is a signiﬁcant factor in coars-
ening, let us ﬁrst consider a simpliﬁed model, assuming
(i) δH is solely due to ﬂuctuations in the local deposi-
tion rate, and (ii) δH is a ﬁxed fraction of W .
(The
justiﬁcation of these assumptions will be considered be-
low.) After H layers of material have been deposited,
the number of deposited atoms in the column under a
given mound has a ﬂuctuation δN ≃ (HLd)1/2, where
both L and H are measured in units of atomic spacing,
and d is the dimensionality of the surface. This yields
the estimate

δH ≃ δN/Ld = (H/Ld)1/2.

From assumption (ii), we obtain,

H ≃ W 2Ld.

(3)

(4)

In the regime where the power-laws (1) and (2) are well
obeyed, Eq. (4) yields,

2β
d

+

1
z

=

1
d

.

(5)

If the mound slope s ≃ W/L saturates to a constant, the
above equation gives,

β =

1
z

=

1
d + 2

.

(6)

Kawakatsu and Munakata [13] carried out a detailed
study of a one-dimensional noise-driven coarsening model
which conﬁrms the scaling result derived above. In that
model, the slope s saturates to a ﬁnite value after an ini-
tial transient. From Eq. (6) one obtains z = 3 which
agrees with their analysis. In comparison, the noiseless
model yields a much slower (logarithmic) coarsening law
for d = 1 [10].

In the physically relevant case d = 2, we have checked
that Eq. (5) is consistent with existing numerical stud-
ies. For models which exhibit a saturated mound slope,
several groups have concluded that β = 1/z = 1/4 [4,6],
as suggested by (6). Higher values [5] of β (and hence
lower values of 1/z) are obtained if the slope s continues
to increase with the ﬁlm thickness H, in agreement with
Eq. (5).

The apparent success of the simpliﬁed model points
to the relevance of the deposition noise in the coarsen-
ing process, contrary to the prevailing belief in the lit-
erature. To appreciate the signiﬁcance of the noise on
a more quantitative level, one needs to examine various
surface mass transport processes, and see how they might
modify the assumptions of the simpliﬁed model. In gen-
eral terms, surface mass transport is governed by bonding
energies of atoms at steps, and by various activation en-
ergies for hopping on the terrace, along a step (or ledge),
and up or down a step, etc. The resulting surface mass

current has a deterministic component whose direction
is mainly determined by the distribution of bonding sites
and their strengths, often modelled by a chemical poten-
tial ﬁeld, and a stochastic component due to the intrinsic
random nature of the hopping process. It is understood
that the substrate temperature has a dramatic inﬂuence
on the kinetic coeﬃcient which controls the magnitude
of the current. In what follows we shall only consider the
deterministic component of the surface current.

The surface dynamics described above plays a domi-
nant role in the initial development of the growth insta-
bility, and also sets the saturated (or quasi-stationary)
slope of the mounds in the late-stage coarsening pro-
cess. However, the ability of the surface dynamics in
promoting mass transport is greatly reduced after quasi-
stationary mounds are well-developed. This is because
the very shape of the mounds is chosen to minimize
the surface current either uphill or downhill [9]. In this
regime, each mound has acquired a form of metastabil-
ity regarding its shape. Fluctuations in the amount of
deposited material can be incorporated by enlarging the
overall size of the mound, with minimal amount of inter-
mound mass transport. In such a situation, the mounds
can be treated as independent ﬂuctuating entities, as
in the simpliﬁed model. The height diﬀerence between
neighboring mounds, however, is subject to the geomet-
rical constraint δH ≤ W .
In the absence of other re-
quirements, we arrive at assumption (ii) of the simpliﬁed
model.

To elaborate on this view, we estimate now the mag-
nitude of the deterministic mass transport between two
neighboring mounds due to the surface dynamics for the
geometry illustrated in Fig. 2. The center of each mound
consists of roughly concentric rings of steps, and the dis-
tance between the two centers is denoted by L. The two
mounds are joined by a “ridge terrace”. The outer rim
of the ridge terrace has convex parts on either side and
concave parts in the middle. Sites on the concave parts
on average oﬀer better lateral bonding, and hence are en-
ergetically more favorable. This eﬀect can be modelled
by a chemical potential diﬀerence δµ between the con-
vex and concave parts, which should be proportional to
the curvature, i.e., ∆µ ∼ 1/L. An inward mass current
is thus expected to appear, as shown in Fig. 2, with a
magnitude

js ≃ Ds∆µ/L,

(7)

where Ds is a kinetic transport coeﬃcient. If we ignore
interlayer mass transport, which is a reasonable assump-
tion given the instability, the kinetic pathways which con-
tribute to js are then (a) diﬀusion along the step, and (b)
detachment of atoms from the step to the terrace, which
in this case is a narrow strip one layer below the ridge ter-
race, followed by diﬀusion on the terrace. In both cases
the transport is essentially a one-dimensional process so

2

Ds does not depend appreciably on L, but it may depend
on the strip width (which is inversely proportional to the
mound slope s) if (b) dominates. The same mechanism is
expected to operate also on other layers below the ridge
terrace, though js decreases due to decreasing curvature.
Assuming the eﬀect extends to Q layers, the total inward
mass current is given by,

Js ≃ Qjs ≃ Ds∆µ

Q
L

.

(8)

ridge terrace

outer rim

strip

js

FIG. 2. Top view of two neighboring mounds of unequal
size. Better lateral bonding for surface atoms is achieved at
the concave parts of the closed steps. This mechanism results
in an inward mass current js.

If we compare the shape of the ridge terrace, each time
after exactly one monolayer of atoms is deposited, we are
likely to see a rounding of the ridge terrace due to the
current js. From the geometry, it is seen that rounding
encourages the upper rings of the two mounds to move
towards each other, as the inner part of the ridge ter-
race receives increasingly more ﬂux of atoms from the
beam. This eventually drives the two mounds to merge
with each other. Although details of the coarsening pro-
cess are likely to be complicated, an estimate of the time
scale τs can be obtained by equating the total mass M
carried by Js to the volume of the gap between the two
mounds, i.e., M ≃ L2W . This yields a time scale for
coarsening due to surface dynamics,
τs = M/Js ≃ L4 W
DsQ

(9)

.

It is interesting to see that, taking Q ≃ W , Eq. (9) also
yields z = 4, suggesting that surface transport driven by
bonding energies may play an equally important role in
the coarsening process. One should note, however, that
the eﬀectiveness of this mechanism is governed by the ki-
netic coeﬃcient Ds, which is a strong function of the sub-
strate temperature. In addition, in the presence of other
mounds, there are competing tendencies for the surface
mass ﬂow, resulting in an increase of τs and further lim-
iting the eﬀectiveness of surface dynamics. It is natural
to expect the latter eﬀect to be particularly signiﬁcant
when mounds are of nearly equal size.

Our estimate of the coarsening time (9) based on sur-
face dynamics alone is consistent with the results in a

3

recent paper by Rost and Krug [11], who gave an up-
per bound 1/4 for the coarsening exponent 1/z based on
the analysis of a deterministic continuum model. Hence
for the case d = 2, the timescale set by the determinis-
tic surface dynamics is slow enough to allow a role for
deposition noise in the actual coarsening process.

A plausible scenario in the noisy case can thus be
stated as follows.
In the late-stage coarsening regime
where mounds have acquired their quasi-stationary
shape, deposition noise is responsible for the height diﬀer-
ence (or equivalently, size diﬀerence) between neighbor-
ing mounds when this diﬀerence is small. In this case,
the height of each mound ﬂuctuates independently (i.e.,
each mound dances up and down in a random fashion).
A “cap value” (or threshold) exists on the height diﬀer-
ence, either due to the geometry (as assumed in the sim-
pliﬁed model), or due to a crossover to a relatively rapid,
surface-dynamics-driven merging when the disparity in
mound size becomes too big to sustain.

As a quantitative measure of the cap value, we intro-

duce the ratio,

R =

δH
W

=

H 1/2
W Ld/2 .

(10)

It is easy to see that R also measures the ratio between
the excess material in a given mound due to ﬂuctuations
in the deposition rate, δN , and the total mound volume
W Ld. A constant R during growth can be interpreted
as supporting the noise-assisted coarsening picture pro-
posed above, while a decreasing R with H would suggest
a diminishing role of deposition noise in late-stage coars-
ening.

The geometrical parameters L and W in Eq. (10) can
be deﬁned precisely through the height correlation func-
tion [8],

G(x, t) = hh(x0, t)h(x0 + x, t)i,

(11)

where h(x, t) is the height ﬂuctuation at point x on the
surface at time t. The width of the surface W can be
identiﬁed with the root-mean-square deviation of h, i.e.,
W = G1/2(0, t). For a mounded surface, h becomes anti-
correlated over a distance of mound size. We can thus
identify L with the mound radius, i.e., where the spheri-
cally averaged G(x, t) reaches its ﬁrst zero starting from
[For an isotropic surface G(x, t) = G(|x|, t),
the origin.
and hence L satisﬁes G(L, t) = 0.]

Using the above deﬁnition, we have computed R from
both published [5] and unpublished [14] simulations. Fig-
ure 3 shows part of our data for two sets of growth param-
eters at various temperatures. The ﬁrst set, with growth
parameters simulating homoepitaxy of GaAs(001) at a
deposition rate F = 1
6 monolayers (ML)/s, are for sub-
strate temperatures T = 678 K (ﬁlled diamond), 778 K
(ﬁlled square), and 828 K (ﬁlled circle). The typical

mound slope in this case is of the order of 0.05, and
the mound size can be as big as 50 lattice constants af-
In the second set,
ter depositing 1000 ML’s of atoms.
the growth parameters were chosen to model Pt(111) ho-
moepitaxy at a deposition rate F = 1
40 ML/s, and sub-
strate temperatures T = 350 K (open diamond) and
400 K (open circle). Here the mounds are typically much
smaller, but the slopes are much higher, in accordance
with Eq. (4). Apart from statistical ﬂuctuations, it is
seen that in each case the parameter R reaches a con-
stant after an initial transient. The value of R falls in
the range 0.2–0.7. Within a given set of surface energy
parameters, we see that R decreases with increasing tem-
perature, in agreement with our expectation that surface
dynamics plays a more important role at higher temper-
atures due to a much larger kinetic coeﬃcient Ds. We
have also examined the data with the same surface acti-
vation energies as those shown but diﬀerent values for the
ES barrier, or a diﬀerent transient dynamics for an im-
pinging adatom. It is found that the latter parameters,
although have very strong eﬀects on the mound slope,
do not change the R value as signiﬁcantly as the growth
temperature T . Details of the analysis will be published
elsewhere [14].

the ﬁlm thickness H, with a proportionality constant R
of order unity when these parameters are measured in
atomic units. The constancy of R reveals a scaling re-
lation between the mound coarsening exponent 1/z and
the mound height exponent β, which agrees with previous
simulation results. Simulations of realistic growth condi-
tions indeed show the constancy of R during growth, but
the saturated value decreases with increasing substrate
temperature. This is supported by our semi-quantitative
analysis of surface mass transport driven by bonding en-
ergies.

It is diﬃcult to over-emphasize the utility of Eq. (10)
in experiments where one wishes to predict quantitatively
the mound size as a function of the ﬁlm thickness. Know-
ing the mound slope and the coeﬃcient R, which is a
function of the growth conditions only, it is possible to
calculate L for a given ﬁlm thickness H. Our preliminary
investigation shows that the most signiﬁcant inﬂuence on
the value of R comes from the substrate temperature. In
addition, a smaller value of R indicates a weaker varia-
tion in the height or size of the mounds, which may be
desirable for certain optical device applications.

P.ˇS. acknowledges ﬁnancial support of the Grant No.
202/96/1736 of the Grant Agency of the Czech Republic.

r
e
t
e
m
a
r
a
p
-
R

0.80

0.60

0.40

0.20

0

200

400

600

800

1000

Thickness (ML)

FIG. 3. Simulation data showing the constancy of the
parameter R during growth. Filled symbols correspond to
GaAs(001) surface at a deposition rate 1/6 ML/s and sub-
strate temperatures T = 678 K (diamond), 778 K (square),
and 828 K (circle). Open symbols correspond to Pt(111) sur-
face at a deposition rate 1/40 ML/s and substrate tempera-
tures T = 350 K (diamond) and 400 K (circle).

The main conclusion of our study is that deposition
noise is an important factor in driving mound coarsening
after the initial growth instability due to the ES bar-
rier is well-developed. The picture we developed leads
to an important geometric relation between the parame-
ters L and W characterizing the mound morphology, and

[1] G. Ehrlich and F.G. Hudda, J. Chem. Phys. 44, 1039
(1966); R.L. Schwoebel and E.J. Shipsey, J. Appl. Phys.
37, 3682 (1966).

[2] J. Villain, J. de Physique I 1, 1 (1991).
[3] M.D. Johnson, C. Orme, A.W. Hunt, D. Graﬀ, J. Sudi-
jono, L.M. Sander, and B.G. Orr, Phys. Rev. Lett. 72,
116 (1994).

[4] M. Siegert and M. Plischke, Phys. Rev. Lett. 73, 1517

(1994); Phys. Rev. E 53, 307 (1996).

[5] P. ˇSmilauer and D. D. Vvedensky, Phys. Rev. B 52, 14263

(1995).

[6] A review is given in J. Krug, “Origins of scale invariance
in growth processes”, to appear in Advances in Physics.
[7] K. Th¨urmer, R. Koch, M. Weber, and K.H. Rieder, Phys.

Rev. Lett. 75, 1767 (1995).

[8] J.A. Stroscio, D.T. Pierce, M. Stiles, A. Zangwill, and

L.M. Sander, Phys. Rev. Lett. 75, 4246 (1995).

[9] J. Krug, M. Plischke and M. Siegert, Phys. Rev. Lett.

70, 3271 (1993).

[10] P. Politi and J. Villain, Phys. Rev. B 54, 5114 (1996).
[11] M. Rost and J. Krug, preprint cond-mat/9611206

(http://babbage.sissa.it/).

[12] L. Golubovi´c, Phys. Rev. Lett. (to appear).
[13] T. Kawakatsu and T. Munakata, Prog. Theor. Phys. 74,

262 (1985).

[14] P. ˇSmilauer, L.-H. Tang, and D. D. Vvedensky (in prepa-

ration).

4"
Thermodynamic Theory of Weakly Excited Granular Materials,"  We present a thermodynamic theory of weakly excited two-dimensional granular
systems from the view point of elementary excitations of spinless Fermion
systems. We introduce a global temperature T that is associated with the
acceleration amplitude \Gamma in a vibrating bed. We show that the
configurational statistics of weakly excited granular materials in a vibrating
bed obey the Fermi statistics.
",http://arxiv.org/pdf/cond-mat/9703075v1,2,"7
9
9
1

r
a

M
7

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
5
7
0
3
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Thermodynamic Theory of Weakly Excited Granular Systems

Hisao Hayakawa1∗ and Daniel C. Hong2†

1Graduate School of Human and Environmental Studies, Kyoto University, Yoshida, Sakyo,

2 Department of Physics, Lewis Laboratory, Lehigh University, Bethlehem, Pennsylvania 18015

Kyoto 606-01, Japan

Abstract

We present a thermodynamic theory of weakly excited two-dimensional gran-

ular systems from the view point of elementary excitations of spinless Fermion

systems. We introduce a global temperature T that is associated with the ac-

celeration amplitude Γ in a vibrating bed. We show that the conﬁgurational

statistics of weakly excited granular materials in a vibrating bed obey the

Fermi statistics.

P.A.C.S. numbers 81.35.+k,46.10.+z,05.70.-a,05.20.Dd

Granular system is robust to thermal disturbances because its entity is a macroscopic

object. [1] For this reason, the granular system is eﬀectively in the ground state at any ﬁnite

temperature and the excitation may be achieved by subjecting the system to vibration or

shaking. Such an external stimulus will inject energy at a constant rate but the energy will

be dissipated via collisions, leading the system to reach a steady state. Dynamics of such

a steady state are quite complex, where convection [2], density waves [3], segregation [4],

anomalous sound propagation [5] and even turbulent behaviors [6] have been observed.

There are some indications that ﬂuctuations in physical quantities of granular systems

persist over the size of the system [7] and intrinsically nonequilibrium clustering instabilities

∗E-mail address: hisao@phys.h.kyoto-u.ac.jp

†E-mail address: dh09@lehigh.edu

1

 
 
 
 
 
 
appear for particles with large coeﬃcient of restitution [8]. In such cases, we may eventually

have to question the validity of the hydrodynamics [9] with the aid of kinetic theory [10],

though some attempts have been made to capture some of the essential features of granular

convections based on phenomenological hydrodynamics models [11].

In spite of the above negative signs, the validity of the thermodynamics concept has

been suggested by several theoretical papers [12,13] and experimental papers [14–17]. In

particular, Knight et al [17] have observed a logarithmic relaxation in compaction processes

in a three dimensional vibrating bed, which can be understood as the consecutive transi-

tions among the metastable (glassy) conﬁgurations. This suggests the validity of the free

volume (or hole) theory [18] used for the dense liquid theory as will be shown later. In two

dimensions, in particular, the situation is much simpler than in three dimensions, because

the particles can form a lattice structure without glassy conﬁgurations. For example, the

experiment by Clement and Rajchenbach [14] has suggested that nontrivial and distinctive

conﬁgurational statistics appear to exist for excited granular systems in a vibrating bed.

The experiment was conducted with steel balls that have small coeﬃcient of restitution and

was monitored carefully to suppress the convection with a suitable choice of the boundary

condition. They then observed that the ensemble-averaged density proﬁle obeys a universal

function that is independent of the phase of oscillations. The experimental result in Ref.

[14] has been recovered by a simulation based on the distinct element method [15] and has

been generalized to the case of strong excitions. [16] The existence of such a distinctive

conﬁgurational statistics, which resembles the problem of packing, appears to be a fairly

convincing evidence that kinetic aspects of the vibrating bed might have been decoupled

from the statistical conﬁgurations averaged over many ensembles and time sequences.

Such a simple observation in two dimensional weak dissipation cases enables one to make

some progress in characterizing the excitation of vibrating beds in two ways: ﬁrst, if the

kinetics is indeed separated out, then the conﬁgurational properties should be determined by

the principle of maximum entropy or equivalently the minimization of free energy. Second,

2

the validity of such variational methods should be carefully checked against experiments.

The test may lead to further conceptual advances, establishing the fact that a weakly driven

nonequilibrium dissipative vibrating bed with the vibration intensity Γ may be viewed as

a thermodynamic equilibrium state at a ﬁnite temperature T in the near elastic limit, if

one’s focus is exclusively on the conﬁgurational properties. The precise relation between

Γ and T , however, has yet to be determined. The purpose of this Letter is to advance

such a simple observation into systematic investigations and to formulate a thermodynamic

theory of powders, at least, in two dimensional systems, from the view point of elementary

excitations such as the Fermi liquid theory [19] in condensed matter physics. Our formulation

may open a way to visualize the invisible quantum behaviors of Fermions or the microscopic

behaviors of dense ﬂuids through the manipulation of granular materials.

The starting point of our thermodynamic formulation [20] is the recognition that granular

state in a vibrating bed is an excited state and the degree of the excitation is controlled

by the global parameter Γ. Since we are concerned here with the conﬁgurational property

of such a system, it is natural to associate a similar global temperature T , but a care must

be taken here because the global temperature T must have a well deﬁned thermodynamic

meaning. One of the essential requirement is that T must satisfy the statistical deﬁnition

of the thermodynamic temperature, namely: T = ∂U/∂S, where U is the total energy and

S is the entropy of the system. Notice that the conventional kinetic temperature, which is

in general a local function, is not identical to the thermodynamic temperature. In fact, T

can be nonzero without kinetic energy, because U contains the potential which is a function

of the entropy. When the contribution from the kinetic energy is much smaller than the

potential energy, the global temperature may be more appropriate than the local granular

temperature to characterize the state of granules as the idea used in the free volume theory

[18]. One can easily show that this parameter T is almost identical with the compactivity X

deﬁned through the free volume introduced by Edwards and his coworkers. [12] While the

compactivity X has never been computed nor related in any manner with the experimental

3

control parameters such as Γ, our formulation will enable us to determine the explicit relation

between T and Γ. To be more speciﬁc, we ﬁrst view the system of granular particles as the

lattice gas, which can be regarded as the simplest version of the free volume (hole) theory

[18]. We now assign virtual lattice points by dividing the vibrating bed of width L and

the height µD into cells of D × D with the diameter of the grain D. Each row, i, is then

associated with the potential energy ǫi = mgzi with zi = (i − 1/2)D and m the mass of the

grain. The degeneracy, Ω, of each row is Ω = L/D. For a weakly excited system with Γ ≈ 1,

the kinetic energy may be neglected and the potential energy dominates, for which case the

most probable conﬁguration should be determined by the state that maximizes the entropy

in the microcanonical ensemble approach.

The entropy, S, is deﬁned as S = ln W with W the total number of ways of distributing

N particles into a system. Excluded volume interactions do not allow two grains to occupy

the same states and thus the statistics is given by the Fermi statistics. We ﬁnd:

W = Πi[Ω!/Ni!(Ω − Ni)!].

(1)

We now maximize S with constraints that characterize the system, namely the ﬁxed number

of particles N and the mean steady state system energy < U(T (Γ)) >, namely

Ni = N, X

i

X
i

Niǫi = U.

(2)

The maximization of S then yields that the density proﬁle, φ(z), which is the average number

of occupied cells at a given energy level, must be given by the Fermi distribution:

φ(z) = Ni/Ω = 1/[1 + exp(β(z − µ))],

(3)

where β → mgD/T in the low temperature limit, the height z = zi/D and the Fermi energy

µ measured in units of D is the initial number of layers. Note that both z and µ are measured

from the bottom layer. The Fermi analogy is valid when µ ≫ nl with nl is the number of

ﬂuidized layer. For a non-interacting electron gas, this ratio is of order 10 to 102. Now,

since the injected energy,Ei, to the system is of order mA2ω2/2 and the potential energy,

4

Ep, to ﬂuidize particles on the top nl layers is of order mgnlD, by equating the two, we ﬁnd

a necessary condition for the ﬂuidization of the top nl layers, namely: nl ∼ Γ(A/2D). For

Γ ∼ 1, the Fermi statistics will be valid, if µ ≫ A/D.

Our only remaining task is then to relate the temperature T to the control parameter Γ.

Here we do not calculate the entropy and the energy directly, because nonequilbrium and

kinetic characteristics may appear in the relation between the temperature T and Γ. Since

we have determined the density proﬁle, we ﬁnd from (2) the energy per particle:

¯u(T ) =

U(T )
N

=

mgDµ2
2

[1 +

π2
3

(

T
mgDµ

)2] + · · · ,

(4)

where the ﬁrst term is the ground state energy and the second term is the increase in energy

due to thermal expansion, which results in the shift in the center of mass, ¯h(T ) = ¯u(T )/mg.

π2
3
with h(0) = Dµ2/2. We now make a crucial observation that for a weakly excited gran-

¯h(T ) = h(0)[1 +

T
mgDµ

)2] + · · ·

(5)

(

ular system, most excitations occur near the Fermi surface, which may be eﬀectively well

represented by the motion of a single particle on the Fermi surface that is in contact with

the vibrating plate. If the maximum height that a single ball bouncing in a vibrating plate

with the intensity Γ is denoted by H0(Γ), then H0(Γ) is determined by the equation that

describes the trajectory of a single ball on a vibrating plane with the intensity Γ. [11,21]

The relative distance, ∆(t), between the ball and the vibrating plate is given by:

∆(t) = Γ(sin(t0) − sin(t)) + Γ cos(t0)(t − t0) − 1
2

(t − t0)2

(6)

in units of g = ω = 1,where t0 = sin−1(1/Γ). The maximum, H0(Γ), can be obtained

from (6) numerically and it is eﬀectively equivalent to the expansion of the volume due

to kinetics. Since the Fermi distribution near T = 0 can be approximated by a piecewise

linear function and H0(Γ) is thought to be the edge of the function, we expect H0(Γ) ≈

∆h/2 = (¯h(T ) − h(0))/2. By equating the thermal expansion, (5),to the kinetic expansion,

H0(Γ)g/ω2 in physical units, we now complete our thermodynamic formulation by presenting

the explicit relation between T and Γ = Aω2/g:

5

T =

mg
πω

(3DgH0(Γ))1/2.

(7)

We point out that the energy is an extensive quantity along the horizontal direction, but is

not in vertical direction where strong anisotropy is present due to gravity. Further, T has

a gap at T = 0 because the time between the launching and landing of the ball is always

ﬁnite for Γ > 1. Figure 1 shows the ﬁtting of the experimental density proﬁle for Γ = 4

of Clement and Rajchenbach [14] by the scaled Fermi distribution, φ(y) = ρ(y)/ρc, with

ρc ≈ 0.92 the closed packing density for the hexagonal packing. The ﬁtting value of T /mg

is 2.0[mm] with µD = 30.5[mm], while eq.(7) yields T /mg ≈ 2.6[mm] [22]. The agreement

between the two is fairly good in spite of such a simple calculation. This expression also

agrees with the simulation result [15]. Note that the detailed expression of H0(Γ) depends on

the manner by which the grains are excited and we expect that our main scaling prediction

of eq.(7), namely T ∝ g3/2D1/2/ω, will hold even for systems driven not by sinusoidal waves.

Next, it is well known that the speciﬁc heat per particle, Cv = d¯u/dT , can be written as the

ﬂuctuations in the energy, namely < (∆¯u)2 >=< (¯u(z) − ¯u)2 >= T 2Cv and thus we predict

the scaling relation for the ﬂuctuations in potential energy, or in the center of mass,

< (∆¯u)2 >=

π2
3

T 3
mgD

∝ g7/2D1/2ω−3.

(8)

Certainly, more experiments or simulations would be desirable to test our theory.

Three comments are in order: First, in three dimensional systems the situations become

far more complex and our ideal Fermi description based on simple lattice gas picture certainly

requires modiﬁcation, primarily for two reasons: ﬁrst, holes are not equivalent to particles

and second, many metastable conﬁgurations exist, which results in the hysteresis-dependent

density proﬁle as observed in the experiment of Knight et al. [17] Even in this case, however,

lattice picture may be valid because the mean free path of the grains is of order of a few

particle diameters and the basic granular state is not a gas but a crystal. Hence, the

free energy approach adopted in this paper is more appropriate than the kinetic theory in

studying the granular state. Such an approach is consistent with the free volume theory of

6

liquid state [18], which assumes that the dominant process involving particle rearrangement

is a hopping with the rate determined by the activation energy A. Within this picture, the

probability of the hopping of a particle from a position r is proportional to exp[−A(r)/T ]

with A(r) ≃ aφ(r)/(1−φ(r)). The relevant time scale τ that determines the time evolution of

the compaction is then given by τ /τ0 ≃ exp[bφ/(1−φ)] with b = a/T , or φ(t) ≃ ln(t/τ0)/(b+

ln(t/τ0)), where we have replaced τ by t. This is consistent with the experimental result

reported by Knight et al. [17] Notice that such an activation dominated process does not have

smooth increase of the density. Although this kind of slow relaxation may not be unexpected

even in two dimensional systems, the strong geometrical constraint may suppress such a

slow process. We point out that attempts have been made to determine the thermodynamic

temperature deﬁned in this paper by measuring the eﬀective viscosity for ﬂuidized beds

with a mixture of gas and particles. The results [23] seem to support the validity of the free

volume theory. This is an indirect conﬁrmation of the validity of our free Fermion picture

based on the free volume theory even in three dimensional systems.

Second, interactions among particles.

It is known that even for hard core particles,

an eﬀective attractive interaction exists through the direct correlation function [24], which

will induce the curvature term. In the presence of such a curvature term, while it may be

diﬃcult to quantitatively compute the surface tension due to the spatial inhomogeneity, it

is nevertheless obvious that we can deﬁne surface tension for excited granular materials in a

vibrating bed. We may need more systematic experiments and careful theoretical argument

to resolve the question of surface tension in excited granular materials [2].

Third, the eﬀect of dissipation. For a simple one-dimensional system of N(≫ 1) particles

connected by springs, where the end particle at the bottom is driven by an external sinusoidal

force, the equation of motion for n−th bead is then given by: m¨zn + mζ ˙zn − k∂2
nzn =
mAω2 cos ωtδn,0. For such a linear system, the eﬀective amplitude Aef f felt by the particle

at the top is expressed by Aef f = A/q1 + (ζ/ω)2, where the dissipation constant ζ =
−(ω/π) ln e with the restitution constant e [25]. Thus, the correction for A is very small.

7

After we have submitted this Letter, we became aware of two recent papers in which

thermodynamic concepts such as one developed in this paper are useful in highly excited

vertical vibration of granular materials [26] and in horizontal vibration of granular materials

[27]. In these papers, the authors have demonstrated that stationary nonequilibrium state of

the vibrating bed exhibits similarities with the thermally equilibrated ﬂuid, consistent with

the assumption of this paper, and the spatial correlation function (two-point correlation)

can be an index of solid-ﬂuid transition of granular materials and can be approximated by

the equilibrium distribution function in the ﬂuid phase.

We would like to express our sincere gratitude to N.Goldenfeld for his encouragement of

this study during HH’s stay at U. of Illinois and his collaboration in the early stage of this

study, Y. Oono, G. Baym, and H.J.Herrmann for helpful discussions concerning the Fermi

liquid theory, Ryan Mitchell for graphical assistance, and J. A. McLennan on various aspects

of the kinetic theory of dense gases. HH is, in part, supported by Grant-in-Aid for Scientiﬁc

Research from Japanese Ministry of Education, Science and Culture (No. 08226206 and

08740308).

8

REFERENCES

[1] For recent reviews, see: H.M.Jaeger, S.R.Nagel and R.P.Behringer, Physics Today, 49,

32 (1996), Rev.Mod.Phys. 68, 1259 (1996); H.Hayakawa, H. Nishimori, S. Sasa and Y-h.

Taguchi, Jpn. J. Appl. Phys. Part 1, 34, 397 (1995) and references therein.

[2] P. Evesque and J. Rajchenbach, Phys. Rev. Lett. 62, 44 (1989); E. Clement, J. Du-

ran and J. Rajchenbach, Phys. Rev. Lett. 69, 1189 (1992); F. Melo, P. Umbanhowar

and H. Swinney, Phys. Rev. Lett. 72, 172 (1994), Phys.Rev.Lett. 75, 3838 (1995);

P.Umbanhowar, F.Melo and H.L. Swinney, Nature 382, 793 (1996).

[3] G.W.Baxter, R.P.Behringer, T.Fagert and G.A.Johnson. Phys. Rev. Lett. 62, 2825

(1989); T. Poschen. J. Phys. (Paris) 3, 24 (1993).

[4] J.C.Williams. Powder Tech. 15, 245 (1976); J. Knight, H.Jaeger, and S. Nagel. Phys.

Rev. Lett. 70, 3728 (1993) and reference therein.

[5] C-h Liu and S.R.Nagel, Phys. Rev. Lett. 62, 40 (1989).

[6] Y-h Taguchi. Europhys. Lett. 24, 203 (1993); K.Ichiki and H.Hayakawa, Phys.Rev.E

51, 658 (1995).

[7] R.P.Berhinger, Bull. Amer. Phys. Soc. 41, No.1, 684 (1996).

[8] S. McNamara and W. R. Young, Phys. Fluids A 4 496 (1992), Phys.Rev.E 53, 5089

(1996), ; I. Goldhirsch and G. Zanetti, Phys. Rev. Lett. 70, 1619 (1993).

[9] Y.Du, H.Li and L.P.Kadanoﬀ, Phys.Rev.Lett.74, 1268 (1995).

[10] J.T.Jenkins and S.B.Savage, J.Fluid Mech. 130, 187 (1983): B. Bernu, F. Deylon,

and R. Dazighi, Phys. Rev. E. 50, 4551 (1994): J.J.Brey, F.Moreno and J.W.Dufty,

Phys.Rev.E 54, 445 (1996).

[11] M.Bourzutscky and J.Miller, Phys.Rev.Lett. 74, 2216 (1995); H. Hayakawa, S.Yue and

D.C.Hong, Phys.Rev.Lett.75, 2328 (1995).

9

[12] S.F.Edwards and R.B.S. Oakeshott, Physica A 157, 1080 (1989); A.Mehta and

S.F.Edwards, Physica A 168, 714 (1990).

[13] H.J.Herrmann, J.de Physique (Paris) II 3, 427 (1993).

[14] E. Clement and J. Rajchenbach. Europhys. Lett. 16, 133 (1991)

[15] J.A.C.Gallas, H.Herrmann, and S.Sokolowski, Physica A 189, 437 (1992).

[16] S.Warr, J.M. Huntley and G.H. Jacques, Phys.Rev. E 52, 5583 (1995).

[17] J.B.Knight, C.G.Fandrich, C.N.Lai, H.M.Jaeger and S.R.Nagel, Phys.Rev. E 51, 3957

(1995).

[18] see e.g. T.L.Hill, Statistical Mechanics (Dover, New York,1987) Chap.8; See also, H.

Caram and D. C. Hong, Phys. Rev. Lett. 67, 828 (1991)

[19] L.D.Landau, J. Phys. USSR. 10, 25 (1946).

[20] Preliminary argument of the Fermi analogy was ﬁrst presented at the International Con-

ference on Nonlinear Dynamics and Chaos, July, 1995, Pohang, Korea, by H. Hayakawa

and D.C. Hong,Proceedings to be published in Int. J. Bifurcations and Chaos.

[21] J.M. Luck and A.Mehta, Phys. Rev. E 48, 3988 (1993) and references therein.

[22] This good agreement may be a little surprising for strong excitation. For Γ = 4, t0 =

0.25268, and the solution of d∆(t)/dt = 0 is given by tmax = 4.59483, for which case

H0(4) = 12.3623. In ref. [14] D = 3[mm] and ω/(2π) = 20[Hz]. For Γ = 4, the bouncing

solution becomes chaotic.

[23] K.Ichiki and H.Hayakawa(unpublished). For earlier experiment, see; J. Furukawa and

T. Ohmae, Ind. Emg. Chem. 50, 821 (1958).

[24] J.-P. Hansen and McDonald, Theory of Simple Liquids, 2nd Edition (Academic, London,

1986).

10

[25] Y-h.Taguchi, Phys.Rev.Lett. 69, 1367 (1992).

[26] S.Warr and J-P. Hansen, preprint.

[27] G.H.Ristow, G.Strassburger and I.Rehberger, preprint.

11

Figure Caption

Fig. 1. Comparison between the experiment and the theoretical prediction. The circles are

the data by Clement and Rajchenbach(ref.14) and the dotted line is the Fermi distribution

function φ(z) (eq.(3)).

12

(z)
DATA

20

z

.5

0

0

f
f"
Two Hydrodynamic Models of Granular Convection,"  We present two continuum models A and B to study the convective instability
of granular materials subjected to vibrations. We carry out the linear
stability analysis for model A and uncover the instability mechanism as a
supercritical bifurcation of a bouncing solution. We also explicitly determine
the onset of convection as a function of control parameters. The results of
simulations are in excellent agreement with the stability analysis. Additional
feature of the model B is the inclusion of the relaxation term in the momentum
equation, which appears to be crucial in capturing what is missing in model A,
in particular, in reproducing experimental convection patterns for large aspect
ratio, both vertically, in which case convective rolls move toward the surface,
and horizontally, in which case convective rolls survive near the wall but are
suppressed in the bulk region.
",http://arxiv.org/pdf/cond-mat/9703086v1,2,"7
9
9
1

r
a

M
9

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
6
8
0
3
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Two Hydrodynamic Models of Granular Convection

Hisao Hayakawa
Graduate School of Human and Environmental Studies, Kyoto
University, Kyoto 606-01 Japan
Daniel C. Hong
Physics, Lewis Laboratory Lehigh University, Bethlehem, PA
18015 USA

ABSTRACT: We present two continuum models A and B to study the con-
vective instability of granular materials subjected to vibrations. We carry out
the linear stability analysis for model A and uncover the instability mecha-
nism as a supercritical bifurcation of a bouncing solution. We also explicitly
determine the onset of convection as a function of control parameters. The
simulations results are in excellent agreement with the stability analysis.
Additional feature of the model B is the inclusion of the relaxation term in
the momentum equation, which appears to be crucial in capturing what is
missing in model A, in particular, in reproducing experimental convection
patterns for large aspect ratio, both horizontally, in which case convective
rolls move toward the surface, and vertically in which case convective rolls
survive near the wall but are suppressed in the bulk region.

1. INTRODUCTION

It was Faraday who discovered the convective instability in a vibrated
granular bed in 1831. Initially the ﬂat surface of the granular pile develops
a heap upon vibrations, along the surface of which grains roll down causing
small or large scale avalanches. Once formed, such a heap is stable, because
of the simultaneous formation of permanent convective rolls inside the heap.
Unlike Rayleigh-Bernard convection in ﬂuids, however, the origin of this in-
stability has remained relatively unexplored since its discovery, but recently

1

 
 
 
 
 
 
two simultaneous push from experimental side ( Clement et al, 1992; Pak and
Behringer, 1994) with the use of MRI or X-ray method (Knight et al, 1993)
from large scale computer simulations based on the distinct element method
(Taguchi, 1992; Gallas et al, 1992) have aided our understanding through
visualization. However, the theoretical eﬀorts(Haﬀ,1983; Bourzutschky and
Miller, 1995) to uncover the basic mechanism of this convective instabil-
ity have not been remarkable, still largely focused on producing convective
patterns through computer models and simulations. We have recently under-
taken steps, based on two continuum models, to remedy this situation, which
appear to have captured the essence of granular convection. Considering a
potentially important industrial application of size segregation and a recent
evidence (Knight et al, 1993) of the convection connection in conjunction
with the conventionally held reorganization of grains, we consider the search
for the origin of granular convection quite important. This is a brief sum-
mary of our eﬀort along this direction. For details, see Hayakawa et al(1995)
and Yue(1995).

2. MODEL A

We have studied two models. Both are based on Navier-Stokes type
continuum eqs, but ignore temperature equation assuming the existence of a
global temperature throughout the bed. We ﬁrst present the model A.

The staring point of model A is the recognition that the most fundamental
aspect of the vibrating bed, apart from the obvious ﬁxed bed solution with
no external driving, is the existence of a uniform bouncing of a collection of
particles, a solid or a ﬂuidized block with no internal degrees of freedom. In
such a case, the bouncing solution, represented by the motion of a ball on
a vibrating platform, satisﬁes ¨z = (−1 + Γ sin t)θ(−1 + Γ sin t) where z is
the vertical coordinate of the granular block and the θ(x) = 1 for x > 0 and
θ(x) = 0 for otherwise. Next, in the presence of internal degrees of freedom
such as rotation and/or translation, we deﬁne two coarse-grained dynamical
variables: the density ρ(r, t) and the velocity v(r,t) of the granular system.
In the box ﬁxed frame, eq. then modiﬁes into:

∂tρ + ∇ · (ρv) = 0

(1)

2

∂tv + (v · ∇)v = ˆz(Γ sin t − 1 − λ) −

∇P

1
ρ
[∇2v + χ∇(∇ · v)]

+

(2)

1
R
where ˆz is the unit vector in the vertical direction and λ is the Lagrange
multiplier. λ = 0 for free motion and λ = Γ sin t − 1 for stationary state.
Note that the ﬁrst term in the right hand side of (2) is due to the uniform
bouncing and the third term is the energy dissipation eﬀectively represented
by the Reynolds number R and the bulk viscosity χ. The pressure term P
requires some discussion(Hayakawa et al, 1995) but the Van der Waals model
P = T ρ/(1 − bρ) is a reasonable choice, where T represents the eﬀective
temperature which might be a global variable and b is a constant of order
unity.

To check the validity of our picture, we have solved (1) and (2) numeri-
cally in two dimension with no slip boundary conditions at the side walls as
well as at the top and the bottom plates. Note that the top plate suppresses
complicated surface motion of vibrating beds and allows us to use the simpli-
ﬁed picture. Since the granular ﬂuid is conﬁned in a box, we do not introduce
λ explicitly in the simulations. The absence of λ and the presence of the top
wall is expected to cause the appearance of the bouncing solution for Γ ≤ 1
in contrast with the real situation but its omission would not change the
essence of the dynamics. In the same spirit, we have ignored χ and b in our
simulations.

For Γ < Γc, the bouncing solution is expected to appear inside the bed
and the density and the velocity at a given point oscillates with the same
frequency of the vibration.( Fig.2) Upon increasing Γ further to Γ = 1.2,
which is beyond the predicted Γc = 1.12 determined by σM (Γc) = 0, we ﬁnd
that the bouncing solution has disappeared and the permanent convective
rolls have developed inside the bulk (Fig.3). The wavelength of the most
unstable mode by the linear stability analysis is about qm ≈ 0.4, which is not
far from the actual wavelength of the convective rolls: q = 2π/λ = 2π/L ≈
0.6.

3. MODEL B

3

We now introduce another model as Model B. Although the mass conser-
vation remains same as in (1), the momentum conservation (2) now changes
into

∂tvx + (v · ∇)vx = −(c2
∂tvz + (v · ∇)vz = (V (ρ, t) − vz))/τ

0/ρ)∂xρ + µ∇2vx

−(c2

0/ρ)∂zρ + µ∇2vz

(3)

(4)

where c2
0 ≃ T is the sound speed. The diﬀerence between model A and B is
the presence of a relaxation term in the z direction (4), which is represented
by an average function V (ρ) with the relaxation time τ . The origin of such
a term has been discussed in Hong et al(1994) in an attempt to introduce
correlations among grains or voids in the diﬀusing void model(DVM). In
the DVM, the void speed is only a function of the local density, namely
vz = V (ρ) + diﬀusion term. However, a void is a compressible hydrodynamic
object that changes and adjusts its shape to conform to the surrounding, not
instantaneously, but in a given time. So, it may be more appropriate to write
down the time dependent equation for the velocity in a manner given by (4)
than simply assuming a ﬁxed value at a given local density. The presence
of such relaxation process may be eﬀectively equivalent to assuming a drag
force acting on a void.

These coupled equations (3) and (4) are also known as the traﬃc model or
two-phase model for ﬂuidized beds that have been widely used for mixtures
of gas and granular particles. Functions in the model may be inferred from
the Enskoq equation; namely −vz/τ is the drag term imposed externally on
the particle. In the case of no interstitial ﬂuid, its origin lies in the frictions
of the front and the rear glass of the container and from the wall. Further,
the Enskoq pressure, T ρ(1 + f (ρ)ρ/2) with f (ρ) the correlation function,
produces an extra term V (ρ) in addition to the hard sphere pressure T ρ. In
this case, the coeﬃcient of V (ρ) is proportional to the gravity g. The net
eﬀect is for the void (or particle) to adjust its speed, vz, around the average
value V (ρ) in a given time τ . While deriving the exact form for the function
V (ρ) is nontrivial, we know it must be a decreasing function of density and
have a cut oﬀ at the closed packed density ρc. Hence, we have chosen a
simple form: V (ρ) = Vo(ρ)(−1 + Γ sin(ωt)) Vo(ρ) = (ρc − ρ)βθ(ρc − ρ) with
θ function and β ≤ 1. We have investigated the eqs.(3) and (4) numerically.

4

The mechanism for the convection seems to be similar to model A, namely
the superciritcal bifurcation of a bouncing solution. However, two notable
diﬀerences emerge. First, when the aspect ratio increases vertically from,
say one to two, the convection rolls that initially occupied the whole box
move toward the surface as shown in Fig.3 and the motion of the particles
are fairly conﬁned near the surface. This is consistent with the experiments
and MD simulations.

Second, when the aspect ratio increases horizontally, then convective rolls
inside the bulk are suppressed and they appear only near the wall, which is
not shown here. This again is consistent with the MD simulation results of
Taguch(1992). Hence, the role of drag appears to be important in granular
convection.

4. DISCUSSION

First, the bouncing solution as a basic state for granular convection seems

to have been conﬁrmed in the simulations of both models A and B.

Second, the role of boundary conditions. We have employed no slip
boundary conditions at the walls and the plate. Further, we have put the
rigid wall at the top and thus suppressed the surface motion. Granular mate-
rials have been shown to exhibit very diﬀerent motion near the wall in a zet
ﬂow experiment under gravity(Caram and Hong, 1993) and there has been
some attempt to use the negative or positive slip to control the convective
patterns (Bourzutschky and Miller, 1995). More detailed studies to derive
reasonable boundary conditions at the wall are required.

Third, the role of interstitial ﬂuid. Our model A assumes no interstitial
ﬂuid such as air, and it predicts a series of rolls for the vertically large aspect
ratio. Model B on the other hand predicts that the convection is suppressed
in the bulk region but is conﬁned near the surface, which is in accordance with
experiments and with the results of the two-ﬂuid model with an interstitial
ﬂuid. Perhaps, the origin of drag, whether it is coming from friction at the
walls, or from the viscous eﬀect of the interstitial ﬂuid, may not be relevant
once it is present. The suppression of the convection in the bulk is due to
the locking mechanism of grains for near closed packed density, which was
taken into account in model B by a cut oﬀ in V (ρ), namely V (ρ) = 0 for
ρ ≥ ρc. We need more extensive studies of both models A and B to make

5

quantitative comparison with experiments.

HH is, in part, supported by Grant-in-Aid for Scientiﬁc Research from
Japanese Ministry of Education, Science and Culture (No. 08226206 and
08740308).

REFERENCES

Bourzutschky, M. & Miller,J. 1995. Granular convection in a vibrating ﬂuid.
Phys. Rev. Lett.

74: 2216-2219.

Caram,H., & Hong, D. 1992. Diﬀusing void model for granular ﬂow. Mod.
Phys. Lett. B. Vol.(6):761-771.

Clement,E., Duran J., & Rajchenbach,J. 1992. Experimental study of heaping
in a two dimen- sional sand pile. Phys. Rev. Lett. 69:1189- 1192.

Gallas,J., Hermann,H.,& Sokolowski,S. 1992. Convection cells in vibrating
granular media. Phys. Rev. Lett. 69: 1371-1374.

Haﬀ,P. 1983. Granular ﬂow as a ﬂuid mechanical phenomena. J. Fluid.
Mech. 134: 401

Hayakawa,H,S. Yue,& Hong,D. 1995. Hydrodynamic description of granular
convection. Phys. Rev. Lett. 75:2328-2331.

Hong et al. 1994. Granular relaxation under tapping and the traﬃc equation.
Phys. Rev. E. 50: 4123-4135.

Knight, J., Jaeger.H, & Nagel,S. 1993. Vibration induced size separation in
granular media: convection connection Phys. Rev. Lett. 70: 3728-3731.

Taguch,Y-h. 1992. New origin of a convective motion. Phys. Rev. Lett. 69:
1367-1369.

Yue,S 1995. Nonlinear phenomena in materials failure and granular dynam-
ics. Ph.D thesis, Lehigh University.

6

Figure Captions

Figure 1:The eﬀective growth rate σef f (q) as a function of the wave number
q for Γ = 1.05(diamond),for which σef f (q) < 0 for all values of q, while for
Γ = 1.2 > Γc = 1.12, σef f (q) becomes positive for a band of q(square). Γc
is determined by the condition that the maximum of σef f (q) becomes zero
at Γc.(cross) The parameters used are: Te = R = 10 and L = 10.(Figure is
missing. Please see PRL 75,2328, 1995)

Figure 2: For Γ = 1.2 > Γc = 1.12, the bouncing solution becomes unstable
and the permanent convective rolls appear inside the box. The arrows are
the velocity vectors pointing upward.

Figure 3:For Γ = 1.2 > Γc and for large aspect ratio along the vertical, the
convective rolls move toward the surface.

Figure 4:For Γ = 1.2 > Γc and for large aspect ratio along the horizontal, the
convective rolls in the bulk are suppressed and survive only near the wall.

7

30

25

20

15

10

5

0

5

10

15

20

25

30

8

60

50

40

30

20

10

0

10

20

30

9

20

0

20

40

60

80

100

120

10"
Langevin dynamics of the Lebowitz-Percus model,"  We revisit the hard-spheres lattice gas model in the spherical approximation
proposed by Lebowitz and Percus (J. L. Lebowitz, J. K. Percus, Phys. Rev.{\
144} (1966) 251). Although no disorder is present in the model, we find that
the short-range dynamical restrictions in the model induce glassy behavior. We
examine the off-equilibrium Langevin dynamics of this model and study the
relaxation of the density as well as the correlation, response and overlap
two-time functions. We find that the relaxation proceeds in two steps as well
as absence of anomaly in the response function. By studying the violation of
the fluctuation-dissipation ratio we conclude that the glassy scenario of this
model corresponds to the dynamics of domain growth in phase ordering kinetics.
",http://arxiv.org/pdf/cond-mat/9703095v2,2,"7
9
9
1

g
u
A
9
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
5
9
0
3
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Langevin Dynamics of the Lebowitz-Percus Model

F. G. Padilla(*) and F. Ritort(**)
(*) Departamento de Matem´aticas,
Universidad Carlos III, Butarque 15
Legan´es 28911, Madrid (Spain)
(**) Institute for Theoretical Physics,
University of Amsterdam
Valckenierstraat 67,
1018XE Amsterdam (The Netherlands)
E-Mail: padilla@dulcinea.uc3m.es,ritort@phys.uva.nl
(August 6, 2018)

We revisit the hard-spheres lattice gas model

in the spherical approximation proposed by
Lebowitz and Percus (J. L. Lebowitz, J. K. Percus, Phys. Rev. 144 (1966) 251). Although no
disorder is present in the model, we ﬁnd that the short-range dynamical restrictions in the model
induce glassy behavior. We examine the oﬀ-equilibrium Langevin dynamics of this model and study
the relaxation of the density as well as the correlation, response and overlap two-time functions.
We ﬁnd that the relaxation proceeds in two steps as well as absence of anomaly in the response
function. By studying the violation of the ﬂuctuation-dissipation ratio we conclude that the glassy
scenario of this model corresponds to the dynamics of domain growth in phase ordering kinetics.

I. INTRODUCTION

The nature of slow relaxation in frustrated systems has seen a large increase of activity in the recent years. In
particular much eﬀort has been done in the study of relaxational dynamics in spin glasses1. These are disordered
systems where slow relaxation appears as a consequence of the frustration induced by the disorder. At low enough
temperatures the system explores a rugged free energy landscape with high energy barriers, hence dynamics is slowed
down. But nature oﬀers a large variety of systems where dynamics can be exceedingly slow in the absence of disorder.
Structural glasses are examples in this class of systems. When fast cooled, glasses do not crystallize and leave the
undercooled liquid line when the typical relaxation time exceeds the inverse of the cooling rate. A possible scenario for
the origin of the glassy state in the absence of quenched disorder has been recently proposed in the framework of some
solvable mean-ﬁeld models2,3. These models show the existence of three characteristic temperatures: the melting
ﬁrst-order transition temperature Tm, a dynamical transition temperature Td reminiscent of a spinodal instability
and a thermodynamic glass transition Ts where the conﬁgurational entropy vanishes and replica symmetry breaks5.
A detailed study of the dynamical equations of these mean-ﬁeld models4 shows that these indeed correspond to the
mode coupling equations of G¨otze and collaborators for the structural glass problem6. One of the main results in this
approximation is the existence of a dynamical singularity (Td) where dynamics is arrested and ergodicity broken. The
existence of this singularity relies on the mean-ﬁeld character of such approximation and it would be highly desirable
to understand how to include short range eﬀects in the theory in a systematic way.

To address this problem it is useful the study of solvable microscopic models for a better understanding of the
mechanisms responsible for slow relaxation, the universal properties of the oﬀ-equilibrium dynamics10,12 as well as
its connections with the Mode Coupling approach. In this paper we study the oﬀ-equilibrium behavior of a solvable
spherical model introduced long time ago by Lebowitz and Percus7. The model has not disorder built in and is suitable
to study the role of short-range dynamical constraints in glassy systems. We will show that the oﬀ-equilibrium behavior
of this model shares the same common features (and in some sense, belongs to the same universality class) as those
mean-ﬁeld spin glass models characterized by the absence of anomaly in the response function. Quite remarkably the
glassy scenario of the model corresponds to the domain growth21. We should stress also that the model introduced
by Lebowitz and Percus is not enough to provide a complete description of the glass transition where phenomena like
stretching and the characteristic two step form above Tc in the liquid (disordered) phase are absent. In the language
of Mode Coupling theory this is due to the absence of discontinuity at Tc of the ergodicity parameter6,22.

But still this model deserves its interest. The new feature which this model furnishes to the study of glassy dynamics
is the eﬀect of dimensionality and short range dynamical constraints in the mechanisms for glassy dynamics. This
kinetic eﬀect has been proposed in the past as a possible explanation of the glass transition9. The Lebowitz-Percus
model (hereafter referred as LP model) incorporates the eﬀect of spatial correlations in the system. This allows for
an extension of the dynamical equations to include the wave vector dependency.

The paper is divided as follows. In the section II we deﬁne the model as well as its thermodynamic properties and

1

 
 
 
 
 
 
write down the dynamical equations in the Langevin approach. In section III we close the dynamical equations for
one time quantities. Section IV presents the solution of the dynamical equations for the correlation, response and
overlap two-time functions. Section V discusses some numerical experiments of the model which allow for a clear
identiﬁcation of the glassy scenario. Section VI discusses the nature of relaxation processes as well as violations of
the ﬂuctuation-dissipation relation. Finally we present the main conclusions.

II. THE LEBOWITZ-PERCUS (LP) MODEL

Let us consider a lattice gas in the spherical approach. Lattice gas models are deﬁned on a lattice of ﬁnite dimensions
where local densities ρ(x) are attached to every site of the lattice. In the hard spheres lattice gas every site of the
lattice can be either occupied or empty. In this case the local densities ρ(x) can take only the values 0 or 1. Lebowitz
and Percus7 relax these conditions on the local densities allowing them to take any continuous value but satisfying a
global spherical constraint. Following their work we also introduce the additional restriction that the density-density
correlation function between nearest neighbors vanishes. This restriction mimics some kind of extended hard core.
So the restrictions on the system are,

ρ(x)2

σ1 ≡ Xx
σ2 ≡ Xx Xq

ρ(x) = 0

− Xx

ρ(x)ρ(x + q) = 0

(1)

(2)

where x is a discrete variable that runs over the sites of a D-dimensional lattice and q are the vectors that join a
site to its nearest neighbors. The thermodynamics of this system is very well known for the general case considered
by Lebowitz and Percus7 where a pairwise interaction potential was also studied. For simplicity, here we will not
introduce any interaction potential between particles or additional restrictions over the local densities. We will see
that in this case the dynamics of the model is simply enough to be solvable displaying a non trivial relaxational
dynamics. Short range dynamical constraints are such that relaxation turns out to be slow when a reorganization of
local densities is necessary to reach the equilibrium density of the system. We start by solving the thermodynamics.
After, we deﬁne the dynamical equations of the model and ﬁnd the stationary solutions of the dynamics.

In the grand canonical ensemble the partition function of the LP model is given by,

A. The thermodynamics.

and Qn(β) is the partition function computed in the canonical ensemble,

ZGC =

∞

Xn=1

zn Qn(β)

Qn(β) =

X
′
ρl
}
{

δσ1,0δσ2,0

(3)

(4)

{

ρl}

satisfy the global constraint

where σ1 and σ2 have been deﬁned previously in eqs.(1,2). The prime in the sum of eq.(4) indicates that the set
N
l=1 ρl = n where n is the total number of particles and N the total
of densities
number of sites in the lattice. Note that the thermodynamics of this system is determined solely by the entropy
because there is no interaction energy between the particles (like in the general case of hard spheres systems13).
Substituting the canonical partition function eq.(4) into the grand partition function eq.(3) we obtain in the large
n, N limit with n/N ﬁxed,

P

ZGC =

N

∞

Xρl=

−∞

Yl=1

zρlδ(σ1)δ(σ2)

(5)

Introducing the integral representation of the delta function we obtain,

2

=

Z

Z

N

Yl=1

dρl Z

exp[β

Xl,l′

ˆC(xl, xl′ )ρl(1

ρl′ ) +

−

Xl

γρl]

(6)

xl′ ) = λ1 when xl −

where z is the fugacity z = exp(γ) = exp(µβ) and ˆC(xl, xl′ ) = λ(xl −
and λ(xl −
The quadratic exponent can be diagonalized using the Fourier transform and the partition function can be exactly
evaluated in terms of the Lagrange multipliers. The equations for the multipliers can be obtained noting that
Z∂λ0 = σ1 and ∂ log
∂ log
Z∂λ1 = σ2 which yield eq.(1,2). Using these constraints we obtain the following equations for the
Lagrange multipliers,

xl′ = q, otherwise λ(xl −

xl′ ). In our case, λ(xl −

xl′ ) = λ0 when xl = xl′

xl′ ) = 0.

1
N Xk

T

=

cos (kx)
2 ˜λ(k)
˜λ(k) = λ0 + 2 λ1

ρ
h

[δ(x)
i

ρ

− h

]
i

cos(k.q)

Xq

(7)

(8)

where x = 0 or x = qi with i = 1, D. In what follows we will drop out the brackets in the notation for the average
density writing ρ instead of < ρ >. These equations can be readily solved. In the disordered high temperature phase
eq.(7) takes the simple form,

2π

1
(2π)D Z
0

dkD T cos(k
2˜λ

·

x)

= ρ(δ(x)

ρ)

−

(9)

(10)

where again x = 0 or x = qi, (1
D). A condensation phase transition is found above two dimensions. This result
can be easily inferred after examination of eqs. (7),(8). The phase transition corresponds to the condensation in the
Kc = π(1, 1, .., 1) direction due to the positivity of λ0 and λ1. At the transition point ˜λ(K) = 0, i.e. λ0 = 2λ1D = λ.
The critical temperature Tc and the value of the Lagrange multiplier λ are solutions to the equations,

≤

≤

i

2π

1
(2π)D Z
0

dkD

Tc cos(k

x)
q cos(k.q))

·

2λ(1 + 1
D

P

= ρ(δ(x)

ρ)

−

(11)

D). Below the critical temperature, condensation on the mode K = π(1, 1, .., 1) develops and
x = 0 or x = qi, (1
the Lagrange multipliers remain ﬁxed to their critical values. The condensed mass aK as a function of temperature
satisﬁes the equation,

≤

≤

i

aK cos(K

x) +

·

2π

1
(2π)D Z
0

dkD

T cos(k

x)

2λ(1 + 1
D

·
q cos(k.q))

P

= ρ(δ(x)

ρ)

−

(12)

(13)

i

≤

≤

where x = 0, qi, (1
D). The mechanism for the condensation transition in the LP model is the same as in the
spherical model of Berlin and Kac14 and appears only for D > Dl = 2 which is the lower critical dimension of the
model. For D = 3 previous equations can be solved and we ﬁnd Tc = 20.158. We should also note that the entropy
of this model diverges as log(T ) at low temperatures, hence violates the third law of thermodynamics. This implies a
ﬁnite speciﬁc heat and a ﬁnite compressibility at zero temperature. This is not a serious drawback since this is related
to the continuous character of the local densities. To suppress this undesirable eﬀect one should include quantum
eﬀects11 but this is beyond the scope of the present paper.

B. The dynamics.

The eﬀective Hamiltonian of the LP model which takes into account the restrictions (1) and (2) imposed on the

system reads,

Hef f (
{

x
}

) = λ0(t)

(ρ(x)2

−

Xx

ρ(x)) + λ1(t)

nv

Xx

Xl=1

ρ(x)ρ(x + ql)

(14)

3

where nv is the number of nearest neighbors, and ql are the vectors that join each point with their nearest neighbors.
We propose the following diﬀerential equation for the dynamical evolution of the density in an open system that

can interchange particles with a reservoir,

∂ρ(x′, t)
∂t

= µ

x
∂Hef f (
{
}
∂x′

−

, t))

+ η(x′, t)

(15)

where β is the inverse temperature and µ is the chemical potential of the thermal bath. η(x, t) is a white noise
η(x, t)η(x′, t′)
uncorrelated in time and space such that
t′) where the brackets
i
h
indicate realizations over the thermal noise. From now on, we will only specify the temporal dependence when two
diﬀerent times appear dropping the explicit time dependence for one time dynamical quantities.

η(x, t)
i
h

= 2 T δ(x

= 0 and

x′)δ(t

−

−

We stress that in the LP model there is no energy but only entropy and that the role of the parameters λ0(t), λ1(t)
in the eﬀective Hamiltonian eq.(14) is to make the dynamical evolution for the densities to fulﬁll the dynamical
constraints eqs(1,2) for all times. Note that the role of the chemical potential (µ > 0) in the dynamical equation (15)
is to increase the local densities in the lattice as much as possible. Obviously the density cannot increase indeﬁnitely
because of the dynamical constraints. Starting from an empty lattice the dynamics turns out to be slow when the
density of the system approaches the equilibrium density. This slowing down is a purely entropic eﬀect and is direct
consequence of the decrease in the number of available conﬁgurations in phase space. In the rest of the paper and
without lost of generality, we can set the chemical potential equal to 1 in (15). The dynamical equations read,

˙ρ(x) = 1

λ0(2ρ(x)

1)

−

−

λ1

−

(ρ(x + ql) + ρ(x

ql)) + η(x)

−

Xl

Due to the spatial translational invariance, it is easy to diagonalize the system using the Fourier transform,

The Fourier transformed global restrictions (1) and (2) are,

˜ρ(k) =

1
√N Xr

exp (ik.r)ρ(r)

σ1 =

2

˜ρ(k)
|

|

−

Xk

√N ˜ρ(0) = 0

σ2 = D

˜ρ(k)
|

|

Xk

2γ(k) = 0

(16)

(17)

(18)

(19)

with γ(k) = 1
D

P

D
l=1 cos (k.ql). In terms of the Fourier components the eﬀective Hamiltonian eq.(14) is diagonal,

H(ρ(k)) = λ0(t)(

Xk

2

˜ρ(k)
|

|

−

√N ˜ρ(0)) + 2D λ1(t)

2γ(k)

˜ρ(k)
|

|

Xk

and the equations of motion for the Fourier transformed densities are

˙˜ρ(k) = √N δ(k)

λ0(2 ˜ρ(k)

−

−

√N δ(k))

−
˜η(k) =

4λ1D ˜ρ(k)γ(k) + ˜η(k)
1
√N Xx

exp (ik.x)η(x)

(20)

(21)

(22)

This set of equations involve diﬀerent uncoupled Fourier modes and can be formally integrated for each mode like
in the Sherrington-Kirkpatrick spherical model16. Here we will follow a diﬀerent strategy and write a linear partial
diﬀerential equation for the evolution of the density. This is done in the next section. Before we will ﬁnd the stationary
states of the dynamics. Due to the absence of disorder we can also investigate the existence of crystal states in the
system.

The stationary states of the model can be obtained by setting to zero the time derivative in (21) and multiplying

the equation by the complex conjugate of ˜ρ. This yields,

1. Stationary states

4

where we have used the regularization of the response function8,

˜ρeq(k)
|

|

2 =

T + δ(k)N ρ(λ0 + 1)
2λ0 + 4D λ1γ(k)

Using that

˜ρ(0)
|

|

2 = N ρ2, we note that

lim
t′
t
→

< η(t′)ρ(t) >= 2T Θ(t

t′)

−

< η(t′)ρ(t′) >= T .

ρ =

λ0 + 1
2λ0 + 4D λ1

+ O(

1
N

).

The restrictions, σ1 = 0 and σ2 = 0 eqs.(18,19) yield,

1
N Xk
1
N Xk

T
2λ0 + 4λ1Dγ(k)

= ρ(1

ρ)

−

T γ(k)
2λ0 + 4D λ1γ(k)

=

ρ2

−

(23)

(24)

(25)

(26)

(27)

(28)

These are the equations originally derived by Lebowitz and Percus7 for the thermodynamics described in section
II.A. At ﬁnite temperature we ﬁnd that the only stationary solutions are given by the equilibrium states. This is not
true at zero temperature where ergodicity is broken. In this case we expect the appearance of several crystalline states
which nevertheless are metastable at ﬁnite temperature. Note that the phase transition in this model is diﬀerent from
the usual structural glass transformation where there is a melting ﬁrst-order phase transition from a liquid to a crystal
state. In the LP model the transition is a condensation one for D > 2 without any latent heat.

2. Crystalline states

At zero temperature, we note that there are many stationary states (its number being proportional to the size of
the system N ). These can be obtained by setting T = 0 in eq.(21) which yields, after multiplying the equation by the
complex conjugate of ˜ρ,

(2λ0 + 4D λ1γ(k))
|

˜ρ(k)
|

2 = N ρδ(k)(1 + λ0)

(29)

For k = 0 this equation yields (2λ0 + 4λ1D)ρ = (1 + λ0) but for k
= 0 we ﬁnd diﬀerent solutions depending on the
k where the term (2λ0 + 4λ1Dγ(k)) vanishes. Then the crystal states are characterized by a non
value of k and
−
vanishing value of ˜ρ(0), ˜ρ(k) and ˜ρ(
k) = ˜ρ(k)∗ , all the other modes being zero. The ﬁrst term is the average density
of particles while the second and third ones yield the crystal conﬁguration. We still have to impose the conditions
σ1 = 0 and σ2 = 0 eqs. (18, 19). Then we obtain that γ(k) should be smaller than zero for such a solution to exist.
1
γ(k) (with k diﬀerent from zero) and the equilibrium density is given by,
We also obtain that λ0 = 1, and 2 λ1 D =

−

−

ρ =

γ(k)

γ(k)

1

−

(30)

The number of stationary states is then proportional to the volume of the lattice since for each value of k such that
γ(k) < 0 there is a stationary state. We will not extend further on details about the crystalline ground states but
limit our discussion to the 1D case. In this case, the simplest way to construct crystalline states is to assign a density
equal to one to each point in the lattice every p sites. If p is a prime number, in the resulting periodic conﬁguration
only ˜ρ(k = 0), ˜ρ(k = 2 π
1
p ) and ˜ρ(k = 2 π(1
p )) are diﬀerent from zero. Then, the condition γ(k) < 0 implies that k
2 , 3 π
lies in the interval ( π
2 ). So, only the states with p = 2 (maximum ﬁlling of the lattice ρ = 1/2) and p = 3 (partial
ﬁlling of the lattice with ρ = 1/3) are crystal states and fulﬁll the dynamical restrictions. All other periodic states
with a larger value of p have γ(k) > 0 and decay to a new k-state with γ(k) < 0.

−

5

6
III. DYNAMICAL SOLUTION FOR ONE TIME QUANTITIES.

To study the relaxation towards the equilibrium, we will focus our attention in the one times quantities as the
density. We will need them later to study the evolution of two time quantities (correlation function, response function
and the overlap among replicas). Dynamics is such that the global constraints σ1 = 0 (18) and σ2 = 0 (19) are
satisﬁed for all times, hence ˙σ1 = 0 and ˙σ2 = 0. These conditions determine the time dependent value of the Lagrange
multipliers.

2 ρ

λ0 + 4 D λ1 ρ

1 + 2 R0 = 0
4 λ1 D T2 + ρ + 2 R1 = 0

−

−
λ0ρ

−

(31)
(32)

where ρ is the average density (ρ =< ρ >). The quantities Tn are correlations density-density, and the Rn quantities
are correlations density-noise. They are deﬁned as follows,

Tn(t) =

1
N Xk

2γ(k)n

˜ρ(k)
|

|

Rn(t) =

1
2N Xk

(˜ρ(k)˜η∗(k) + ˜η(k)˜ρ∗(k))γ(k)n

(33)

(34)

where n is any integer number. Note that these quantities are invariant under translations which is the main symmetry
of the eﬀective Hamiltonian eq.(14). We will see the usefulness of all these quantities later on. We can do some remarks
on the values and physical meaning of some of them. First of all, we note that T0 is (due to the spherical restriction)
equal to the average density ρ. T1 is proportional to the ﬁrst neighbor correlation, which is equal to zero. T2 is some
kind of second neighbor correlation. This is a time dependent quantity that needs to be calculated in order to solve
the evolution of the density. We will see that the time evolution of the quantity T2 depends on T3, that T3 depends
on T4 and so on. In the thermodynamic limit and using the regularization of the noise-ﬁeld correlation (25) we ﬁnd
for the Rn,

which are time independent quantities vanishing for odd values of n.

Rn(t) = T

1
N Xk

γ(k)n

We are now interested in the evolution of the average density of the system. Taking into account that

order 0( 1
√N

); we get,

˙ρ = 1

λ0(2ρ

1)

−

−

−

4D λ1ρ

(35)

is of

η
h

i

(36)

In order to solve the equations for the evolution of the density (31,32,36), we need to know the dependence of T2

on time. It is easy to write the dynamical equations for the Tn,

˙Tn = 2ρ(1 + λ0)

4λ0Tn −

−

8 D λ1Tn+1 + 2Rn

(37)

As previously said, each Tn depends on Tn+1. To close this hierarchy of equations, we multiply all of them by
x
n! Tn+1(t), we get a partial

n! Tn(t) and using that ∂gT (x,t)

∂x =

∞n=0

∞n=0

x

n

n

1

n! xn and sum over n. Deﬁning gT (x, t) =
diﬀerential equation for gT (x, t),

P

P

∂gT (x,t)

∂t =

gN (x) =

∂gT (x,t)

8 D λ1
n! xnRn = T

∂x −
N

1

−
n

4λ0gT (x, t) + 2ρ(1 + λ0)ex + 2gN (x)
k exp (x γ(k))

P

P

We can formally integrate this partial diﬀerential equation using the method of the characteristic curves,

t
0 [2ρ(1 + λ0) exp (x
R

− R

gT (t, x) = g0(x
− R
t
t′ 8 D λ1dt′′) + 2gN (x

t
0 8 Dλ1dt′) exp (

t
0 4λ0dt′)+
t
t′ 8 D λ1dt′′)] exp (

− R

− R

t
t′ 4λ0dt′′)dt′

− R

(38)

(39)

where the g0 function is determined by the initial condition, gT (0, x) = g0(x). Once the value of gT (t, x) is known,
we can obtain the diﬀerent elements of the hierarchy by taking derivatives with respect to x, Tn(x, t) = ∂
|x=0.

gT (x,t)
∂xn

n

6

IV. THE HIERARCHY OF EQUATIONS FOR TWO TIME QUANTITIES.

In this section, we write the dynamical equations for the correlation, response and overlap functions. These are

deﬁned by,

G(t, t′, x) =

C(t, t′, x) =

1
N Xx′
1
N Xx′

ρ(x′ + x, t)η(x′, t′) =

ρ(x′ + x, t)ρ(x′, t′) =

1
N Xk
1
N Xk

˜ρ(k, t)˜η(

−

k, t′) exp (ik.x)

˜ρ(k, t)˜ρ(

−

k, t′) exp (ik.x)

Q(t, t′) =

1
N Xx′

ρ1(x′ + x, t)ρ2(x′, t) =

1
N Xk

˜ρ1(k, t)˜ρ2(

−

k, t)

(40)

(41)

(42)

C(t, t′) (41) is the density-density correlation function and measures how fast the conﬁgurations decorrelate in time.
The response function (40) measures the change of the local density in a point of the lattice at time t when the chemical
17. Finally the overlap function (42)
potential is locally changed in another point of the lattice at distance x at time t′
measures how fast two diﬀerent copies of the system (initially in the same conﬁguration at t′, i.e. ρ1(x, t) = ρ2(x, t′))
16,24. From now on and in the rest
decorrelate in time when submitted to diﬀerent realizations of the noise for t > t′
of the paper we will take the convention t > t′. To obtain their time evolution we proceed as in the case of the density
and deﬁne hierarchies for two time quantities as follows,

Gn(t, t′, x) =

Cn(t, t′, x) =

1
N Xk
1
N Xk

˜ρ(k, t)˜η(

−

˜ρ(k, t)˜ρ(

−

k, t′)γ(k)n cos (k.x)

k, t′)γ(k)n cos (k.x)

Qn(t, t′) =

1
N Xk

˜ρ1(k, t)˜ρ2(

−

k, t)γ(k)n

Using (21) we get the following equations,

∂Gn
∂t

(t, t′, x) =

−

4 D λ1(t)Gn+1(t, t′, x)

2λ0(t)Gn(t, t′, x)

−

∂Cn
∂t

(t, t′, x) =

−

4 D λ1(t)Cn+1(t, t′, x)

−

2λ0(t)Cn(t, t′, x) + ρ(t′)(1 + λ0(t))

∂Qn
∂t

(t, t′) =

−

8 D λ1(t)Qn+1(t, t′)

−

4λ0(t)Qn(t, t′) + 2ρ(t)(1 + λ0(t))

For the response function we have < ρ(t′)η(t) >= 0. Deﬁning the following generating functions,

ΓG(t, t′, x, y) =

ΓC(t, t′, x, y) =

yn
n!

yn
n!

∞

Xn=0

∞

Xn=0

Gn(t, t′, x)

Cn(t, t′, x)

ΓQ(t, t′, y) =

yn
n!

∞

Xn=0

Qn(t, t′)

we can close the hierarchies (49),(50) and (51),

∂ΓG
∂t

(t, t′, x, y) =

4 D λ1(t)

−

∂ΓG
∂y

(t, t′, x, y)

−

2λ0(t)ΓG(t, t′, x, y)

∂ΓC
∂t

(t, t′, x, y) =

4 D λ1(t)

−

∂ΓC
∂y

(t, t′, x, y)

−

2λ0(t)ΓC (t, t′, x, y) + ρ(t′)(1 + λ0(t))ey

∂ΓQ
∂t

(t, t′, y) =

8 D λ1(t)

−

∂ΓQ
∂y

(t, t′, y)

−

4λ0(t)ΓQ(t, t′, y) + 2ρ(t)(1 + λ0(t))ey

7

(43)

(44)

(45)

(46)

(47)

(48)

(49)

(50)

(51)

(52)

(53)

(54)

The initial condition in equations (43,44,45) is obtained setting t = t′. Using the regularization of the ﬁeld-noise

correlation at t = t′ (25), the initial condition for the response function Γ(0)

G (t′, x, y) is given by

Γ(0)
G (t′, x, y) = ΓG(t′, t′, x, y) =

∞

Xn=0

yn
n!

T
N Xk

γ(k)n cos (k.x)

For the correlation function, we have,

Γ(0)
C (t′, x, y) = ΓC (t′, t′, x, y) =

∞

Xn=0

yn
n!

1
N Xk

˜ρ(k, t′)
|

|

2γ(k)n cos (k.x)

(55)

(56)

In particular, for x = 0 we have Γ(0)
the initial condition for the generating function of the correlation.
The same initial condition needs to be used for the generating function for the overlap between replicas,

C (t′, 0, y) = gT (t′, y). So we must use the generating function for the density as

Γ(0)
Q (t′, y) = ΓQ(t′, t′, y) = gT (t′, y)

(57)

Equations (52,53,54) with their initial conditions (55,56,57) can be formally solved as we did for the generating

function for the hierarchy of the density (38).

3. The equilibrium solution.

Using the integral expressions for ΓC , ΓG and ΓQ, we can ﬁnd the equilibrium values for the two time quantities.
In equilibrium, ρ, λ0 and λ1 are time independent, and the integral expressions can be simpliﬁed. Imposing also the
equilibrium solutions as initial condition and using equation (23) we get the following results,

Γeq
C (t, t′, x, y) =

1
N Xk

T cos (k.x) exp ((y

4 D λ1(t

t′))γ(k)

−
2 λ0 + 4 D λ1γ(k)

−

2 λ0(t

t′))

−

−

+ ρ2 exp (y)

Γeq
G (t, t′, x, y) =

1
N Xk
T cos (k.x) exp ((y

T cos (k.x) exp ((y

4 D λ1(t

t′))γ(k)

2 λ0(t

t′))

−

−

−

−

8 D λ1(t

t′))γ(k)

−
2 λ0 + 4 D λ1γ(k)

−

4 λ0(t

t′))

−

−

+ ρ2 exp (y)

Γeq
Q (t, t′, x, y) =

1
N Xk

(58)

(59)

(60)

It can be readily seen that the equilibrium solution is time translational invariant and that the Fluctuation Dissi-
pation Theorem (hereafter denoted as FDT) for the generating function is satisﬁed, i.e. ∂ΓC (t,t
= ΓG(t, t′, x, y).
∂t′
This implies the validity of the FDT for any of the elements of the hierarchy of equations. In particular, for the usual
response and correlation functions we get ∂C0(t,t
t′, x, y)
∂t′
as expected24.

= G0(t, t′, x). Also we note that Γeq

t′), x, y) = Γeq

C (2(t

Q (t

,x,y)

−

−

,x)

′

′

In the thermodynamic limit the previous discrete sums in eqs.(58,59,60) become integrals. In the condensed phase

we obtain the following expressions,

2π

Γeq
C (t
−
0 dkD T cos(k
·
R
Γeq
G (t

1
(2π)D

1
(2π)D

t′, x, y) = aK cos(K
x) exp ((y

4 D λ1(t

x) exp (y)+
′
))
2 λ0(t
t

−
2λ(1+ 1
D

′
t

·
))γ(k)
−
cos(k.q))

−

g

−

ρ2 exp (y)

−

2π

P

−
0 dkDT cos(k
R
1
(2π)D

t′, x, y) = aK cos(K
x) exp ((y
·
Γeq
Q (t
0 dkD T exp ((y
R

t′, y) = aK exp (y)+
))γ(k)
4 λ0(t
8 D λ1(t
cos(k.q))

−
−
2λ(1+ 1
D

·
4 D λ1(t

−

−

2π

′
t

−

−

q

x) exp (y)+
t′))γ(k)

−

′
t

))

−

ρ2 exp (y)

P

2 λ0(t

t′))

−

−

(61)

where the values of λ and aK are determined by equations (12). Above the critical temperature in the disordered
phase the expressions for ΓC , ΓG and ΓQ are very similar to the previous ones except for the Lagrange multipliers
which do not verify λ0 = 2 D λ1 and aK = 0. In this case the Lagrange multipliers are determined by equations (9).

8

V. DYNAMICAL SOLUTION

A. General Method

The solution to the previous equations is quite involved in the oﬀ-equilibrium regime and cannot be exactly cal-
culated even if some results can be obtained in the asymptotic long time limit. While it is possible to simplify the
analytical expressions using Laplace transformations the analytical analysis of the dynamical equations appears to
be tedious. Here we follow a diﬀerent and more straightforward strategy and numerically investigate the solution to
the dynamical equations. To understand the nature of the oﬀ-equilibrium behavior of the model we have numerically
integrated the dynamical equations by truncating the hierarchy up to a given ﬁnite number of elements. We have
investigated the cases D =1 and 3. In the ﬁrst case, there is no phase transition while there is a transition in the
second one. For the numerical integration of the equations we have considered between 100 and 500 elements of the
hierarchy for D = 1 and between 5000 and 20000 elements in the condensed phase in D = 3 (where relaxation is
slower). We note that all ﬁgures in this section when plotted in a logarithmic scale are always in base log10. In all
the cases, the integration was performed with an Euler method of second order. Some of this results were tested with
a fourth order Euler method.

B. One time quantities

1. Relaxation of the density

The ﬁrst behavior we can study is the relaxation of the density to its equilibrium value. In one dimension we ﬁnd that
the relaxation is exponential with time for T diﬀerent from zero as expected in the disordered phase. For T = 0, we
ﬁnd diﬀerent behaviors depending on the initial condition as found in the spherical Sherrington-Kirkpatrick model16.
If the initial condition has a macroscopic projection on the equilibrium state then the relaxation is exponential. If
the projection on the equilibrium state is zero, then the density of the system relaxes to the equilibrium with a power
law, t−

1.

In three dimensions, starting from a non-equilibrium initial condition the system relaxes exponentially fast above
1 power
the critical temperature in the disordered phase. In the condensed phase the relaxation is algebraic with a t−
law (ﬁgure 1). The behavior of the density in the LP model is very similar to the relaxation of the energy in the
disordered spherical SK model16.

0.0

−1.0

−2.0

)
ρ
−
q
e

ρ
(
g
o

l

−3.0

−4.0

−5.0

−6.0

−4.0

−2.0

0.0
log(t)

2.0

4.0

FIG. 1. Time dependent density in 3D ρeq − ρ (from top to bottom) T = 0.0001, 0.1,1 and 10, with homogeneous initial
condition. The equilibrium densities at T = 0.0001 is 0.499950, at T = 0.1 is 0.454950, at T = 1. is 0.309017 and at T = 10. is
0.256246.

9

2. Hysteresis eﬀects.

We have performed some temperature cycling experiments in our system. Starting from a random high temperature
conﬁguration (for D = 3 we start above the condensation transition temperature) we let the system equilibrate at this
temperature and later on we decrease the temperature at a ﬁnite rate. As far as we are mainly interested in the slow
cooling regime, to integrate the equations we change the temperature in the diﬀerential equations on constant steps
of ∆T . The cooling rate is given by r = ∆T
t∗ , where t∗ is the time the system spends in a given constant temperature.
We observe that the system departs from the equilibrium line at a temperature T ∗ which decreases as the cooling
rate decreases. The inverse of the cooling rate yields an estimate of the relaxation time at that temperature T ∗ .
Below T ∗ the system fails to relax to the equilibrium and remains at a density lower than the equilibrium value. Once
we reach zero temperature, we start to increase it at the same rate. We ﬁnd that the non-equilibrium line crosses
the equilibrium one which indicates that the system also fails to relax to the equilibrium but now it remains at a
density higher than the equilibrium value. Finally, the non equilibrium line merges again the equilibrium line at a
temperature of the same order of T ∗. This behavior can be observed in 1-D (ﬁgure 2) as well as in 3-D (ﬁgure 3). In
these experiments there is no apparent diﬀerence between the 3-D and the 1-D case indicating that this is a general
non-equilibrium eﬀect unsensitive to the existence of a phase transition. Similar eﬀects are observed in the 1-D Ising
model18 as well as in the Backgammon model19.

0.0

−1.0

−2.0

−3.0

)
y
t
i
s
n
e
d
−
5
.
0
(
g
o

l

−4.0

−3.0

−2.0

−1.0
log(T)

0.0

1.0

FIG. 2. Cooling experiment in 1-D. 0.5-density versus temperature. We show the equilibrium value for density (continuous

line) and the value for the density at diﬀerent cooling rates. These are (from top to bottom) 0.1,0.01 and 0.001.

10

0.0

−1.0

−2.0

)
ρ
−
5
0
(
g
o

.

l

−3.0

−3.0

−2.0

−1.0

0.0

1.0

2.0

log(T)

FIG. 3. Cooling experiment in 3-D. 0.5-density versus temperature. We show the equilibrium value for density (continuous

line) and the value for the density at diﬀerent cooling rates. These are (from top to bottom) 0.1,0.01 and 0.001.

3. Heating Experiments

An striking feature of this system is that although no potential energy has been introduced there appear to be a
large number of stable crystalline states at zero temperature which have an inﬁnite lifetime. To see the eﬀect of these
crystalline states on the dynamics we have done some heating experiments. At T = 0 an in 1-D, we have constructed
diﬀerent periodic crystalline initial conditions (putting the density every p sites equal to one). As we have shown in
section (II B), crystalline conﬁgurations with p = 2, 3 are metastable states at zero temperature. Numerically we ﬁnd
that the conﬁgurations where p = 4 and p = 6 decay to the conﬁguration p = 2, and that p = 5 and p = 7 does not
decay to p = 2 or p = 3, but to solutions with densities between 1
3 (p = 3). These results are simply
explained noting that, although the restriction σ2 = 0 is a global one, apparently the only way to fulﬁll this restriction
is imposing that every occupied site is surrounded by empty sites.

2 (p = 2) and 1

At ﬁnite temperature, the metastable states have a ﬁnite lifetime and decay to the equilibrium state. However, at
low temperatures, the lifetime of metastable states can be very large and their eﬀects on the dynamics can then be
observed. Suppose we prepare the system in such a way that the initial condition belongs to the basin of attraction
of one of these stationary states. If we perform a heating experiment in which we raise the temperature of the system
at a ﬁnite rate, then we ﬁnd that the system is trapped for some time near the basin of attraction. In ﬁgure 4, we
show the case where we start from a non metastable state with p = 5. We see that ﬁrst it decays to the crystal state
(the ﬁrst plateau seen in the ﬁgure) an later on it relaxes to the equilibrium line.

11

0.0

−1.0

)
ρ
−
5
0
(
g
o

.

l

−2.0

−3.0

−4.0

−4.0

−3.0

−2.0

−1.0

0.0

1.0

log(T)

FIG. 4. Heating experiment in 1-D. 0.5-density versus temperature. Starting from a 5 period 1-D crystal initial condition.
We show the equilibrium value for density (continuous line) and the value for the density at diﬀerent cooling rates. These are
(from top to bottom) 0.1,0.01, 0.001 and 0.0001.

4. Kinetic growth.

In the LP model, contrarily to the case of the spherical Sherrington-Kirkpatrick model15, it is possible to investigate
kinetic growth phenomena, i.e. how the condensed domains grow as time goes by. This is interesting because allows
to ascertain how relevant is dimensionality in non equilibrium phenomena. Let us consider the densities in Fourier
space eq.(17). Using equation (21) we obtain its time evolution,

1
2

d

2

˜ρ(k)
|
d t

|

= N δ(k)ρ

λ0(2

2

˜ρ(k)
|

|

−

−

N δ(k)ρ)

4λ1D

˜ρ(k)
|

|

−

2γ(k) + T

(62)

Integrating this equation with the values for the Lagrange multipliers obtained from the hierarchy of the density,
we get the Fourier transformed densities for the inﬁnite system. During the evolution from a non-equilibrium initial
condition, we see how a peak around k = π is formed (in 3-D, around k = (π, π, π)). As temperature decreases the
peak becomes sharper. For a better understanding of the results, we can appeal to the equilibrium relations. Using
2. Obviously, in equilibrium, all of them
(23), (27) and (28) we can calculate an eﬀective temperature for any
will have the same eﬀective temperature, the equilibrium one.

˜ρ(k)
|

|

In ﬁgure 5, we show the values of the eﬀective temperature for values of k = k (1, 1, 1), with k ranging from 0 to
π in the 3-D case (the ﬁgure is symmetric around k = π). For times larger than a typical time t∗
1 a plateau
appears in the eﬀective temperature and its value decays very fast to T , the temperature of the heat bath. For values
of k ranging from zero up to a given value kmax, all the modes have approximately the same eﬀective temperature
which is the equilibrium one20. There is a given value of k (let us call it k∗) where the eﬀective temperature becomes
inﬁnite and above this value of kmax the eﬀective temperature is not deﬁned (This means that there does not exist
an equivalent equilibrium system described by the dynamical densities

2).

≃

˜ρ(k)
|

|

12

0.5

0.4

0.3

0.2

0.1

e
r
u

t

a
r
e
p
m
e

t

e
v
i
t
c
e

f
f

E

0.0

0.0

1.0

2.0

3.0 π

k

FIG. 5. Eﬀective temperatures versus k in 3-D and at T = 0.1. It is shown for diﬀerent values of time: 0.01,0.1,1,10,100,1000.

The vertical line on the right of the plot is k = π.

correlation length diverges as t

With the value of kmax we can also estimate the correlation length using the relation ξ

1
kmax . We ﬁnd that the
1
2 typical of domain growth in ferromagnets with non conserved dynamics (ﬁgure 6).
The dynamics in the LP model can be intuitively understood in the framework of the kinetic growth scenario21.
For times less than t∗ there is no plateau in the eﬀective temperature because the system is nearly empty and the
system is ﬁlling the lattice in a random and uncorrelated way. As soon as the density becomes large enough, any
change of the density in a site of the lattice is correlated with that of the nearest neighbors and any change in the
density requires a reorganization of the local densities inside a given domain. So, a critical and ﬁnite time t∗ is
needed till the ﬁrst domains appears. At times larger than t∗ correlated domains start to grow in time. At length
scales smaller than the growing correlation length ξ the system is in local equilibrium (the eﬀective temperature is
the equilibrium temperature) while it is completely disordered (the eﬀective temperature is inﬁnite) at larger length
scales. The domain growth scenario is nicely reproduced in the LP model.

≃

−

π

0.5

0.0

)
ξ
/
1
(
g
o

l

−0.5

−1.0

−1.5

0.0

1.0

2.0
log(t)

3.0

4.0

FIG. 6.

Inverse of the correlation length, 1/ξ, against time in 3-D and at T = 0.1 (dotted line) and 1 (dashed line). The

straight lines show t

−1/2 behavior.

13

 
C. Two Times Quantities.

1. The Correlation and Response Functions.

In this section, we are going to study the correlation and response functions in equations (47) and (48) with x = 0.

We consider the following normalized correlation function,

C0(t, t′, x = 0)
C0(t′, t′, x = 0)

ρ2
eq
ρ2
eq

C0(t, t′, x = 0)
ρ2
ρ0 −
eq

ρ2
eq

Cnorm(t, t′) =

−
−
where ρ0 is the initial density at time t′ and ρeq is the equilibrium density corresponding to the system at temperature
T .
In what follows we redeﬁne the time variables t′ = tw and consider the behavior of correlation functions for
diﬀerent values of tw.

(63)

=

−

−

−

(D

≤

∼

−

−

(T

2/(D

Tc)−

2), η = 0 (D

2)/z, i.e. like t−

Our results conﬁrm the simplest Mode Coupling scenario where relaxation proceeds in two steps, the α and β
relaxation processes. A comment now seems to be appropriate. Originally Mode Coupling theory was devised to
understand the equilibrium dynamics of liquids in the vicinity of the glass transitions. G¨otze and collaborators6
have proposed a general mathematical framework for the understanding of equilibrium relaxational processes which
take place in the vicinity of a bifurcation instability. The model we propose here is a very simpliﬁed version of
the glass scenario where there is no discontinuity of the ergodicity parameter in the bifurcation point (i.e. at the
condensation phase transition temperature). In fact, above Dl = 2 the LP model exhibits a usual second order phase
transition with classical critical exponents ν = 1/(D
4). The dynamical critical exponent is z = 2
typical of mean-ﬁeld theory. This implies that the relaxation time diverges close to the transition temperature Tc
1/2 for
2). In the critical point equilibrium time correlations decay like t−
like τ
D = 3. Among other results these scaling relations led naturally to the 1/t decay found in ﬁgure 1 for the density
2)/zf (t/τ ) holds
in all dimensions at the critical point and below it. Above Tc the scaling behavior C(t)
where τ is the divergent characteristic time scale and the superposition principle is then valid. We want to stress
that, contrarily to other scenarios for glassy relaxations (see the discussion by G¨otze22) in this case there is only
one relaxation process above Tc since there is not discontinuity in the ergodicity parameter at Tc. But still it is
quite interesting to investigate the extension of the Mode Coupling scenario to the oﬀ-equilibrium dynamics below
Tc. In this case, it is necessary to consider the initial time dependence in the dynamical equations. This implies
the emergence, among others, of new oﬀ equilibrium phenomena like aging, i.e. the dependence of the evolution of
the system on the initial time state. Also below Tc oﬀ-equilibrium correlation functions are expected to display the
characteristic two steps form since the ergodicity parameter (i.e. the Edwards-Anderson parameter) is already ﬁnite.
We will consider tw larger than t∗, i.e. the typical time needed to reach a macroscopic density in the lattice starting
from a nearly empty lattice. For values of tw < t∗, the system is quite far from the asymptotic long time regime and
obviously the two step form is hardly seen. There are qualitative diﬀerences between the 1-D and 3-D cases since in
3-D there is a condensed phase while the system is always disordered in the 1-D case. The oﬀ-equilibrium correlation
1/2 and
function in 3-D decays in two steps: the β process or stationary part with a decay to a plateau with a t−
3
the slow α process where the density-density correlation function decays like t−
2 . In the β process the relaxation is
stationary and depends only on the time diﬀerence t
tw while in the slow α process there is aging and the correlation
functions depend on both t and tw (ﬁgure 7). The scaling behavior t/tw is well reproduced in the oﬀ-equilibrium
regime (ﬁgure 8). In 1-D the behavior is similar except for the plateau which is absent (only a small inﬂexion for the
correlation function at short times is observed). In 3-D the plateau persists over an arbitrarily long time scale which
grows with tw whereas for 1-D aging is interrupted and disappears when tw is of the order of the ﬁnite relaxation
time.

t−

∼

−

(D

−

14

1.0

0.8

0.6

)

w

t
,
t
(

C

0.4

0.2

0.0

−2.0

0.0

2.0

4.0

log(t−tw)

FIG. 7. Correlation function versus t − tw in 3-D at T = 0.1. Diﬀerent waiting times are shown. From top to bottom

tw = 10000,1000,300,100,30,10,3,1.

0.0

−1.0

)
)

w

t
,
t
(
m
r
o
n

C
(
g
o

l

−2.0

−10.0

−8.0

−6.0

−4.0

−2.0
log((t−tw)/tw)

0.0

2.0

4.0

FIG. 8.

Correlation function versus (t − tw)/tw in 3-D and T=0.1.

Diﬀerent waiting times are shown,
tw = 1000,300,100,30,10,3,1. For times larger than 1, all of them merge in one curve except for tw = 1 (the lines on the
left) which is too short.

The dynamical scenario in the LP model can be inferred from a study of the response function. In any dimension
the response function decays very fast to zero showing no aging in the asymptotic long time regime. Indeed, in 3D
1/2. This
we see that G(t, tw) decays like t−
is an indication of the short-time memory of the system. In the context of glassy dynamics this indicates that the LP
model has no anomaly in the response function24.

3/2 for long times and then the integrated response function decays as t−

15

0.0

−2.0

−4.0

−6.0

)
)

w

t
,
t
(

G
(
g
o

l

−8.0

−2.0

0.0

2.0

4.0

log(t−tw)

FIG. 9. Response function, G(t, tw), versus t − tw in 3-D and for T = 0.1. Diﬀerent waiting times are shown. From top to

bottom tw = 10,100,1000,10000.

D. The Fluctuation Dissipation Theorem.

Once we know the values of the correlation and response functions, we can study the ﬂuctuation-dissipation ratio,

X(t, tw) =

G0(t, tw)
∂C0(t,tw)
∂tw

.

(64)

This ratio is equal to 1 in equilibrium (recall that, by deﬁnition, a factor T has been absorbed in the response
tw < tw, showing that the system is in
function). Roughly, we ﬁnd that X(t, tw) is approximately equal to 1 for t
local equilibrium in the stationary regime. For times t
tw larger than tw the X decays to zero very fast. We ﬁnd
the same qualitative behavior in 1-D and 3-D. This is expected in the absence of anomaly since the response function
decays very fast to zero in this regime. If we look more carefully (see ﬁgure 10), we ﬁnd that there are two diﬀerent
1 when the lattice starts to be ﬁlled of particles), the value of X decreases
regimes. For small values of tw (tw < t∗
monotonically; but for larger values of tw, X increases with t until it reaches a maximum and after decreases very fast.
Numerically, we can extrapolate that for tw tending to inﬁnity and t
X(t, tw)
tends to zero as (t

tw < tw (i.e. in the β-regime) the 1

1.

−

−

≃

−

−

3/2 and that the X(t, tw)
1, we can conclude
Using the fact that for long times the response functions decays as t−
1/2. This result has been checked directly by
that the correlation function decays to the plateau with a power law t−
ﬁtting the decay of the correlation function to the plateau (see below for an estimate of the value of the plateau) for
large values of tw.

≃

tw)−

−

16

0.0

−1.0

−2.0

)
)

w

t
.
t
(

X
−
1
(
g
o

l

−3.0

−2.0

0.0

2.0

4.0

log(t−tw)

FIG. 10. 1-X(t, tw) versus t − tw. Diﬀerent waiting times are shown. From top to bottom tw=1,3,10,30,100,300,1000,10000.

The straight continuous line shows

1

t−tw behavior.

We can also study the evolution of X(t, t′) as a function of C(t, t′). Qualitatively we ﬁnd very similar results in all
dimensions: in the β-regime X is close to 1 while in the α-regime it decays very fast to zero. The 1-D and 3-D cases
are depicted in ﬁgures 11 and 12 respectively. Interestingly enough in the 3-D case we also ﬁnd (ﬁgure 12) that all
the curves (except tw = 1 which is a too short time) cross at C∗ = Cnorm(t, tw)
0.75 (the value of C∗ increases for
0.25 . The value C∗ corresponds to the value of Cnorm(tw, t) in
lower temperatures) corresponding to a value of X ∗
the plateau in the β-regime (see ﬁgure 7). It is possible to make all diﬀerent curves (corresponding to diﬀerent values
of tw) collapse in a universal one. We ﬁnd that the scaling law,

≃

≃

X(t, tw) = X((C∗

Cnorm(t, tw)) t0.4
w )

−

(65)

In this β-regime the system is in local equilibrium. For Cnorm(tw, t) < C∗ we ﬁnd X

for Cnorm(tw, t) < 0.75 nicely ﬁts data for all diﬀerent values of tw (inset in ﬁgure 12). We can interpret naturally
the value of X in the two regimes as a ratio between the temperature of the system and an eﬀective temperature Tf .
1 and the eﬀective temperature of the system coincides with the temperature
For Cnorm(tw, t) > C∗ we ﬁnd X
0
of the thermal bath.
which means that the eﬀective temperature is inﬁnite. This is a conﬁrmation of the results obtained in section V.B
interpreted within the kinetic domain growth scenario. In that case it was found that the eﬀective temperature outside
equilibrated domains was also inﬁnite. Note that the deﬁnition of an eﬀective temperature is not free of inconsistencies
in the most general case and there is not evidence a priori that both eﬀective temperatures (in the α regime) for the
one time quantities and the eﬀective temperature obtained for the two time quantities coincide. A result of this type
was found in the Backgammon model for the physical interpretation of the violation ﬂuctuation dissipation ratio23.

≃

≃

17

1.0

0.8

0.6

0.4

0.2

)

w

t
,
t
(

X

0.0

−6.0

−4.0

−2.0

0.0

log(1−Cnorm(t,tw))

FIG. 11. X(t, tw) versus Cnorm(t, tw) in 1D at T = 0.0001. Diﬀerent waiting times are shown. From top to bottom

tw = 1000, 300, 100, 10.

1.0

)

w

t
,
t
(

X

0.5

0.0

0.0

0.5
1−Cnorm(t,tw)

1.0

FIG. 12. X(t, tw) versus 1 − Cnorm(t, tw) in 3-D at T = 0.1. Diﬀerent waiting times are shown. From bottom to top
tw = 1, 3, 10, 30, 100, 300, 1000, 10000. In the inset we show the collapse of the data using the scaling relation eq.(65) for various
values of tw = 30, 100, 300, 1000.

1. Correlation Between Replicas.

Up to now we have found qualitatively similar results in the oﬀ-equilibrium behavior in 1-D and 3-D. The question
arises if it is possible to infer from the dynamics the existence of a condensed growing phase which could distinguish
the 1-D from the 3-D behavior at ﬁnite T. It has been recently suggested24 that it is possible to characterize the
dynamical behavior in terms of the overlap between two replicas which start in the same initial conﬁguration and
eq for diﬀerent values
follow diﬀerent noise realizations. We have analyzed the quantity, Q(tw, t)

Qeq where Qeq = ρ2

−

18

−

of tw. In a disordered phase we expect that Q(tw, t)
Qeq should decay to zero for long times because the two replicas
depart one from each other even if they are at the same initial condition at tw. This is the behavior we ﬁnd in 1D
(ﬁgure 13). In the 3-D case in the condensed phase (see ﬁgure 14) the situation is diﬀerent. Now the two replicas
remember they were in the same conﬁguration at tw and do not depart indeﬁnitely one from each other. The system
is then constrained to follow something similar to gutters or channels in phase space24. Intuitively it is not diﬃcult
to interpret this result in terms of a domain growth process. We already now that the dynamics of the LP model is
essentially dominated by the growth of correlated domains. In the 1-D case domains appear and disappear in time
because the system is in the disordered phase. In this case the typical length of domains grow in time (we are at
low temperatures) but domains can always appear and disappear. The pattern structure of domains is in some sense
continuously changed in time. In the 3-D case, once domains start to grow, they are not destroyed again. During
the condensation process the pattern structure of domains is essentially unchanged and it is only rescaled in time.
Consequently the two-replicas overlap Q(tw, t)

Qeq does not decay to zero for long times.

−

0.0

−1.0

−2.0

−3.0

−4.0

)
)

w

t
,
t
(

Q
−
q
e

Q

(

g
o

l

−5.0

−2.0

0.0

2.0

4.0

log(t−tw)

FIG. 13. Correlation between replicas, Q(t, tw) − Qeq against t − tw in 1D and T = 0.0001. Diﬀerent waiting times are

shown. From top to bottom tw = 1,10,100,1000.

0.20

q
e

Q
−
)

t
,
t
(

w

Q

0.15

0.10

−2.0

0.0

2.0

4.0

log(t−tw)

19

 
FIG. 14. Correlation between replicas, Q(t, tw) − Qeq against total menus waiting time 3-D and T = 0.1. Diﬀerent waiting

times are shown. From bottom to top tw = 1,3,10,30,100,300,1000.

VI. CONCLUSIONS

We have analyzed in detail the dynamical properties of the LP model originally introduced to understand the
thermodynamic properties of hard spheres lattice gases in the spherical approximation. From the viewpoint of the
dynamics this is an interesting model because it is exactly solvable allowing a detailed investigation of the oﬀ-
equilibrium scenario. The model has no built-in disorder and slow dynamics appears as a consequence of the short
range dynamical constraints present in the system. The dynamics of this model shares a large number of features
with the oﬀ-equilibrium dynamics of the spherical Sherrington-Kirkpatrick model15 where dynamics is driven by the
macroscopic condensation of the system on the disordered ground state. This gives support to the result that disorder
is not an essential ingredient for the dynamical glassy scenario2,3 to be valid.

We have presented a detailed investigation of the dynamical equations of the model by considering the one time
and two time quantities. One advantage of the model is that it includes short-range eﬀects which are not present in
other type of mean-ﬁeld models like the spherical SK model15. If the initial conﬁguration has density far from its
equilibrium value then there is a short-time regime where the system is ﬁlled very fast in a spatially uncorrelated way.
The typical time t∗ for this ﬁlling process is of order 1. It is only after that time that slow relaxation starts when the
system is spatially correlated and needs to reorganize large regions in order to increase its density.

For values of time larger than t∗, we see that the dynamics of the model shows striking similarities to the kinetics
of domain growth of ferromagnets with non conserved dynamics21. This is expected since the dynamics proposed in
eq.(15) corresponds to the coarsening dynamics in the so called model B in phase ordering kinetics. In particular we
have seen that for length scales smaller than a typical correlation length ξ (which grows in time) the system is in local
equilibrium and spatial ﬂuctuations are determined by the equilibrium temperature. Above the correlation length ξ
the system is completely disordered, hence the typical temperature associated to spatial ﬂuctuations is inﬁnite. The
correlation length ξ is an accurate measure of the typical size of the growing domains. It would be interesting to
investigate the dynamics of the LP model with the conserved dynamics of kinetic growth. In this case, we expect that
a similar scenario would apply but with diﬀerent exponents.

Further support to this domain growth scenario has been obtained from the study of the two time quantities. In
particular we ﬁnd that oﬀ-equilibrium relaxation proceeds in two well deﬁned steps: a fast β relaxation process where
the ﬂuctuation dissipation relation is obeyed, followed by a slow α process where time translation invariance is lost and
the ﬂuctuation dissipation ratio is zero. The physical meaning of the α and β process is quite appealing in terms of
domain growth kinetics. The fast β-process is associated to local rearrangements of densities inside domains whereas
the slow α-process is associated to the growth of the typical size of these domains. On the other hand, the response
function shows no aging and decays very fast to zero. This is the scenario of glassy dynamics without anomaly in
the response function typical of glassy systems with short term memory. A study of the replica-replica overlap has
also revealed that the growth mechanism is diﬀerent in the presence or absence of condensation transition. In 1-D
where there is no condensation phase transition (the system is always in the disordered phase) the domains appear
and disappear in time even if their typical size increases. In the 3-D case the domains always tend to grow and the
Q(tw, t) is ﬁnite24.
pattern structure of domains is always maintained. In this last case we ﬁnd that limtw
We want to note that the relaxation of the density as well as correlation functions do not display the phenomena
of stretching characteristic of glasses. This is due to the oversimpliﬁcation inherent to the model where only entropy
barriers are introduced through global constraints (while in the classical hard-spheres model constraints are always
local). It would be very interesting to introduce some kind of local constraint which could restore the main features
observed in real glasses. In this direction, it would be quite interesting to extend this research by considering the
LP model with the dynamics recently proposed by Dean where local densities can never become negative, a feature
which is not considered in the present dynamics25. This requires the introduction of noise correlated with the local
densities, a kind of local constraint. Also it would be interesting if such a dynamics could be exactly solved.

limt

→∞

→∞

Acknowledgments. We acknowledge Luis Bonilla, Enrique Diez and Silvio Franz for stimulating discussions on
this and related subjects. F. G. P acknowledges to the Universiteit van Amsterdam for the facilities during his stay
there. The work by F.G.P. has been supported by the DGCyT The work by F.R has been supported by FOM under
contract FOM-67596 (The Netherlands).

20

1 H. Rieger, Annual Reviews of Computational Physics II, p.295 (World Scientiﬁc, Singapore 1995); J. P. Bouchaud, L. F.
Cugliandolo, J. Kurchan and M. Mezard, Out of Equilibrium dynamics in Spin Glasses and other Glassy systems Preprint
cond-mat 9702070

2 J. P. Bouchaud and M. Mezard, J. Physique I (Paris) 4, 1109 (1994);
3 E. Marinari, G. Parisi and F. Ritort, J. Phys. A (Math. Gen.) 27 7615 (1994); J. Phys. A (Math. Gen.) 27 7647 (1994);
4 S. Franz and J. Hertz, Phys. Rev. Lett 74 2114 (1995).
5 T. R. Kirkpatrick and D. Thirumalai, Phys. Rev. B36 5388 (1987). T. R. Kirkpatrick and P. G. Wolynes Phys. Rev. B36

8552 (1987).

6 For review see, W. G¨otze, Liquid, freezing and the Glass transition, Les Houches (1989) J. P. Hansen, D. Levesque, J.
Zinn-Justin editors, North Holland; W. G¨otze and L. Sjogren, Rep. Prog. Phys. 55, 241 (1992); C. A. Angell, Science, 267,
1924 (1995)

7 J. L. Lebowitz and J. K. Percus, Phys. Rev. 144, 251 (1966).
8 J. Zinn-Justin. Quantum ﬁeld theory and critical phenomena. Oxford. Claredon Press, 1989, chap. 3.
9 G. H. Fredrickson and H. C. Andersen, Phys. Rev. Lett. 53, 1244 (1984); E. Follana and F. Ritort, Phys. Rev. B 54, 930

(1996).

10 L. F. Cugliandolo and J. Kurchan, Phys. Rev. Lett. 71 173 (1993); J. Phys. A (Math. Gen.) 27 5649 (1994);
11 Th. M. Nieuwenhuizen, Phys. Rev. Lett. 74 4293 (1995).
12 S. Franz and M. M´ezard, Europhys. Lett. 26, 209 (1994); Physica A210, 48 (1994).
13 For a recent discussion see, R. Monasson and O. Pouliquen, Entropy of particle packings: an illustration on a toy model

Preprint cond-mat 9702027.

14 T. H. Berlin and M. Kac, Phys. Rev. 86, 821 (1952).
15 J. M. Kosterlitz, D. J. Thoules and R. C. Jones; Phys. Rev. Lett. 36 1217 (1976).
16 S. Ciuchi and F. De Pascuale, Nucl. Phys. B 300 31 (1988); L. F. Cugliandolo and D. S. Dean, J. Phys. A (Math. Gen.) 28,

4213 (1995);

′

17 Compared to the usual deﬁnition of the response function ∂ρ(x
18 J. J. Brey and A. Prados, Physica A, 197, 569 (1993); J. J. Brey, A. Prados and M. J. Ruiz-Montero, J. Non-Cryst. Solids,

∂η(x′,t′) both deﬁnitions diﬀer only in a factor T .

+x,t)

172-174, 371 (1994);

19 F. Ritort, Phys. Rev. Lett 75, 1190 (1995); S. Franz and F. Ritort, Europhys. Lett. 31, 507 (1995);
20 We have deﬁned this kmax as the value of k in which the eﬀective temperature is 10% larger than the average value in the

plateau

21 A. J. Bray, Adv. Phys. 43, 357 (1994)
22 W. G¨otze, J. Stat. Phys. 83, 1183 (1996).
23 S. Franz and F. Ritort, J. Phys. A (Math. Gen.) 30 L359 (1997).
24 A. Barrat, R. Burioni and M. Mezard, J. Phys. A (Math. Gen.) 29, 1311 (1996); A. Barrat, Ph. D. Thesis (Universite Paris

VI), 1996.

25 D. Dean, J. Phys. A (Math. Gen.) 29, L613 (1996)

21"
Structure and metastability of superheated Al(111),"  The high-temperature properties of the Al(111) surface are studied by
molecular-dynamics simulation. This surface does not melt below the bulk
melting point, but can be superheated. Superheating of metal surfaces has been
recently observed in several experiments. A molecular-dynamics study of the
structural properties reveals how after going through the superheating regime
melting occurs over the whole crystal in a narrow temperature range. The
temperature dependence of the surface stress, the mean-square vibrational
amplitudes and the anomalous outward expansion of the distance between two top
layers are calculated. A transition from superheated to liquid state is
analyzed using kinetic description for the formation of liquid nuclei by the
Fokker-Planck equation and conservation of heat at the liquid-solid interface.
",http://arxiv.org/pdf/cond-mat/9704045v1,2,"7
9
9
1

r
p
A
5

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
5
4
0
4
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Structure and metastability of superheated Al(111)

G. Bilalbegovi´c
Fakult¨at f¨ur Physik, Universit¨at Bielefeld, D-33615 Bielefeld, Germany
(October 4, 2018)

The high-temperature properties of the Al(111) surface are studied by molecular-dynamics simula-
tion. This surface does not melt below the bulk melting point, but can be superheated. Superheating
of metal surfaces has been recently observed in several experiments. A molecular-dynamics study
of the structural properties reveals how after going through the superheating regime melting occurs
over the whole crystal in a narrow temperature range. The temperature dependence of the sur-
face stress, the mean-square vibrational amplitudes and the anomalous outward expansion of the
distance between two top layers are calculated. A transition from superheated to liquid state is
analyzed using kinetic description for the formation of liquid nuclei by the Fokker-Planck equation
and conservation of heat at the liquid-solid interface.

68.35.Rh,64.60.My,64.70.Dv

I. INTRODUCTION

The question of how melting occurs, in spite of its long history and importance, remains to a large extent unanswered.
Although various metastable phases of diﬀerent materials are present in nature, for some time it was a common belief
that metastability is not possible at the solid-to-liquid transition. The argument was that a free surface of any material
in contact with vapor acts as a nucleus of a liquid phase and suppresses superheating, i.e., nonmelting above the bulk
melting temperature. Nevertheless, superheating was recently observed in several materials. For metal crystals it is
especially diﬃcult to achieve superheating. The viscosity of liquid metals is low and the liquid-solid interface rapidly
propagates into the bulk. Several ways to suppress melting of metals were found. One way was to enclose the metal
crystal into another metal with higher melting temperature. For example, superheating up to 62 K was observed for
small Pb precipitates in Al1. It was checked that the Pb particles of mean size ∼ 200 ˚A remain superheated at 18
K above the bulk melting point for more than 21 hours1. The Ag spheres were coated with Au and superheated by
25 K for a period of about one minute2. Such a behavior was modeled in molecular-dynamics (MD) simulation using
the Lennard-Jones potentials and diﬀerent strength of interaction3.

Techniques to superheat clean metal surfaces were also developed. It is known that at the temperatures below the
bulk melting point some metal surfaces exhibit surface melting. Using medium–energy ion scattering it was found
that the Pb(110) surface melts and that the thickness of liquid layer diverges when the temperature approaches the
bulk melting point4. On the contrary, Pb(111) does not melt and Pb(100) exhibits incomplete melting characterized
by the presence of liquid diﬀusion only in one or two topmost layers4. Similar behavior show low-index surfaces of
other fcc metals, in particular surfaces of aluminum5. It was also found that some close-packed metal surfaces under
special conditions may exhibit superheating. Herman and coworkers have found superheting by 120 K for Pb(111)6,
90 K for Bi(0001)7, and even 15 K for incompletely melted Pb(100)8. Superheating of these surfaces was studied
by time-resolved reﬂection high-energy electron diﬀraction. Melting was prevented by rapid heating with a pulsed
laser beam. Using laser pulses of the width ∼ 102 ps it was possible to bypass melting by inducing large heating
and cooling rates of about 1011 K/s. By applying the same procedure it was not possible to superheat the Pb(110)
surface9,10. Superheating was also found in MD simulation of laser-pulse irradiation for Cu(111)11. For a development
of new methods in materials processing by the laser beams it is important to understand the properties of superheated
surfaces.

Small crystallites bounded by nonmelting facets show superheating. For example, nonequilibrium octahedral lead
crystallites on graphite (made up of the (111) facets and small round parts) exhibit superheating by several K and for
several hours12. Similar superheating was also observed in MD high-temperature studies for Au(111)13, Al(111)14,
Cu(111)15, and Pb(111)16. DiTolla and coworkers have performed MD simulation for deposition of a liquid aluminum
cluster on the melting Al(110) and nonmelting Al(111) surfaces14. They used these results and thermodynamic
arguments to connect superheating with the wetting angle and the non-melting induced faceting angle16. The type
of superheating related to fcc(111) is enabled by the exclusive presence of these non-melted surfaces on the specially
prepared crystallites and on MD slabs. On equilibrium crystals the surface-melted facets (such as fcc(110)) are also
present. They act as a nucleus of the liquid phase and prevent superheating of the whole crystal.

1

 
 
 
 
 
 
Till now the studies of superheating phenomena have been mainly concentrated on the means to achieve the
superheated state. In this work MD simulation method was used to study the properties of this metastable state,
in particular the superheated Al(111) surface. The analysis of the mean-square displacements, surface relaxation,
MD particle trajectories, and surface stress has been carried out. The results of kinetic theory based on the Fokker-
Planck equation17 and an analysis of the heat transport at the liquid-solid interface18,19 were used to estimate the
maximum superheating temperature for aluminum. This analysis employed several quantities that were experimentally
determined and deduced from MD simulations. In the following the MD simulation method is described in Sec. II.
Results of simulation and discussion are presented in Subsec. III A. Subsection III B deals with the kinetic analysis
of transition from the superheated to liquid state. A summary and conclusions are given in Sec. IV.

II. MOLECULAR-DYNAMICS COMPUTATIONS

The structure of the aluminum surface at high temperatures was studied by MD simulation. The interatomic
interactions were derived from a classical many-body potential20. This form of potentials gives a proper physical
picture of metallic bonding21. The optimal set of parameters in the potential was found by the force-matching ﬁtting
to ab initio electronic structure calculations using a numerical optimization procedure20. The data used for ﬁtting
were generated from diﬀerent geometries, both at T = 0 K and for ﬁnite temperatures. As a result the potential is
characterized by a good transferability. This potential was already used in MD simulations and it reproduced well
experimental results for bulk and surface properties of aluminum14,20,22. The melting point Tm = 939 ± 5 K is in
good agreement with the experimental value of 933.52 K23. The calculated bulk melting temperature was precisely
determined by simulating coexisting liquid and solid phases under constant energy24,25.

The simulation of the high-temperature properties of the Al(111) surface started at T = 0 K. The MD box of 1600
particles was used. These atoms were arranged in the usual single slab geometry with the thickness of Nz = 16(111)
layers (i.e., ∼ 35˚A), and a 10 × 10 square lattice in each layer. As in other classical MD studies of surfaces, the slab
was extended along x and y by using periodic boundary conditions and no boundary conditions were used along z.
The three bottom layers of the slab were kept ﬁxed to simulate the bulk. The lattice constant was changed with
temperature according to the expansion coeﬃcient found in MD simulation under zero pressure. The time step of
2.64 × 10−15 s was used. Most runs were carried out at the constant temperature (i.e., in the canonical ensemble).
The temperature was controlled by rescaling the particle velocities at each time step. At each temperature at least
104 time steps were performed to ensure thermal equilibration. In the superheating regime the length of the runs was
much longer, i.e., up to 106 time steps. In this regime simulations at ﬁxed energy were also performed and the same
results as in the canonical ensemble were obtained.

The stress analysis often shows important changes of surface properties. The surface stress tensor σij is given by

σij = γδij +

∂γ
∂ǫij

,

(1)

where γ is the surface free energy per unit area, δij is the Kronecker symbol, ǫij is the surface strain tensor, and i, j
are directions in the surface plane26. The surface stress can be obtained from the components of the pressure tensor
calculated during MD simulation27. In the computation of the stress MD boxes equilibrated for at least 105 time
steps were used.

III. RESULTS AND DISCUSSION

A. Structure

The studies of the various structural properties of the Al(111) surface (such as the density, the static structure
factor, the orientational order parameter, and MD particle trajectories) were done. The detailed analysis of these
properties between 0 K and 1500 K shows that at ∼ 1120 K melting starts on a typical MD simulation time scale.
The temperature of 1050 K was selected for a detailed analysis of the superheating regime. At this temperature the
surface stays superheated after 106 time steps. The static structure factor, the density and order parameter plots
(not presented here), as well as the MD particle trajectories in Fig. 1 show that the superheated Al(111) surface at
1050 K and after 106 time steps is crystalline and well ordered. It was found that in the superheating regime single
adatoms often appear above the surface (see Fig. 1 (b)). These adatoms have a very short life time (∼ 10−12 s).
This is in contrast with the results obtained using the same type of potentials for the high-temperature behavior of

2

fcc(110) (surface melting)28 and fcc(100) (incomplete melting)29. For these surfaces the formation of adatoms was not
observed. The Al(111) surface at T=1120 K stays superheated for a long time of 4 × 105 MD steps. In the interval of
(40 − 45) × 104 time steps melting begins and develops. It was found that at this temperature melting proceeds with
diﬀerent speed in diﬀerent MD runs. For example, while in one run eleven layers were melted after 42 × 104 MD steps,
in another one after 45 × 104 time steps only ﬁve top layers of MD box were melted. Internal energy as a function of
temperature is shown in Fig. 2. The jump region on the caloric curve between the crystalline and liquid states is less
abrupt than usually for melting transitions. The maximum superheating temperature estimated in this simulation is
180 K. DiTolla and coworkers reported ∼ 150 K for the same surface, using the same potential and similar simulation
times14. This is a result of diﬀerent shape and size of MD boxes used in these simulations. A dependence of the
calculated bulk melting temperature on the size, shape, and orientation of the samples is well known problem in MD
simulation24,25.

The surface stress was calculated and its temperature dependence is presented in Fig. 3. The (111) surface is
isotropic, the xx and yy components of the stress tensor are approximately equal and therefore the stress is represented
by their mean values. The stress of 0.056 eV ˚A−2 was found for the relaxed surface at T = 0 K. This is 3.3 times less
than the average stress for Au(110) at the same temperature and for the same type of potential30. The calculated
stress for Al(111) at T = 0 K is in excellent agreement with 0.059 eV ˚A−2 obtained for the same surface in MD
simulation using the Sutton-Chen potential31. These MD results should be compared with two ab initio electronic
structure calculations for Al(111). The value of 0.078 eV ˚A−2 was found by Needs and Godfrey32 and 0.090 eV ˚A−2
by Feibelman33. Schmid and coworkers calculated surface stress for some low-index fcc metal surfaces using MD
simulation and eﬀective medium theory potentials34. They found that MD generally gives lower values compared to
electronic structure calculations. Figure 3 shows that surface stress for Al(111) is almost constant between T = 0 K
and T = 900 K. The stress is always tensile. The components of any type of stress (or pressure) tensor calculated in
MD simulation exhibit large ﬂuctuations35. In Fig. 3 the errors increase with the temperature and the maximum of
statistical uncertainty for the points is 20%. Same trend in the distribution of the values (i.e., that the stress remains
almost constant over the wide temperature region and also that pronounced scatter of the data exists) was found in
MD simulation for the (111) surface of the Lennard-Jones crystal27. It is well known that surface stress [see Eq. (1)]
for a liquid becomes equal to the surface free energy (i.e., ∂γ/∂ǫij = 0). The value 0.05 eV ˚A−2, obtained in this
simulation for the liquid surface at T = 1500 K, is equal to the surface free energy of liquid aluminum4.

The mean-square vibrational amplitudes for the surface atoms are shown in Table I. The values of mean-square
displacements are presented at two temperatures below the bulk melting point (300 K and 900 K) and also at 1050 K,
i.e., for a typical temperature in the superheating region. The last row of this table is obtained for the solid surface
at the onset of melting at T = 1120 K. The values found for temperatures below the bulk melting point are in a
good agreement with other MD simulation results29,36,37. The mean-square vibrational amplitudes at the end of the
superheating region (not studied elsewhere) are ∼ 10 times larger than below the bulk melting temperature. The
mean-square amplitudes of vibration are isotropic at all temperatures. Most MD simulations of the high-temperature
properties of fcc metal surfaces also show that the mean-square vibrational amplitudes are isotropic36,37. In recent
experimental studies38 and MD simulation29 of two fcc(100) surfaces it was found that the mean-square amplitudes
of vibration are anisotropic. Out-of-plane vibrational amplitudes were found to be smaller than in-plane ones. This
reveals lateral disordering typical for incomplete melting. Isotropic mean-square vibrational amplitudes found here
for Al(111) show that after superheating regime melting proceeds in similar way along all directions.

Most low-index metal surfaces relax inwards at lower temperatures. It is known that the Al(111) surface exhibits
an anomaly in relaxation, i.e., that at low temperatures the distance between the two outmost layers expands in
comparison with the bulk layers39. The potential for aluminum used in this paper gives good description of the
Al(111) relaxation, i.e., it gives the experimental value for surface relaxation +0.9% at T = 90 K20,39. In this work
the temperature dependence of surface relaxation was studied and results are also presented in Table I. It was found
that this unusual outward expansion of the distance between the two top layers increases with temperature. This
increase is ∼ 1% along the superheating temperature region. The maximum of surface relaxation is +3.3% at the
onset of melting.

B. Metastability

The fundamental questions of conditions and limits for the existence of any metastable state deserve further in-
vestigation. For metastable Al(111) it is important to consider a maximum of the superheating temperature as a
function of aluminum properties. For fcc metal crystals the maximum of superheating should occur at the close packed
non-melted (111) surfaces. MD simulation presented above shows that the mean-square vibrational amplitudes are
isotropic at the transition from the superheated to liquid state (see Table I). Moreover, drops form everywhere, and

3

the liquid front rapidly propagates into the bulk. In the following estimate of the maximum superheating temperature
small anisotropy of the solid-liquid interface free energy is not taken into account. Therefore, the spherical liquid
nuclei are analyzed.

The kinetic theory of ﬁrst order phase transitions provides a description of transformation from a metastable to
stable phase17. This transition proceeds via ﬂuctuation induced formation of the nuclei of the stable phase. If the
radius r of the nucleus is smaller than some critical value rc such nucleus disappears, if it is bigger the nucleus grows.
The radius of the spherical liquid critical nucleus is

where α is the solid-liquid interface free energy and L is the latent heat of melting40. It is possible to describe the
growth of the nucleus by the kinetic Fokker-Planck equation for the distribution function f (r, t)

rc =

2α
L

Tm
T − Tm

,

(2)

where w is the ﬂux density. The phase transition corresponds to the stationary solution of Eq. (3), where w = const.
Such solution is17

∂f
∂t

= −

∂w
∂r

,

(3)

w = 2

α
T

r

B(rc)f0(rc).

In this equation B is diﬀusion type coeﬃcient and f0(rc) is

f0(rc) = const exp

−4παr2
c
3T (cid:19)

.

(cid:18)

(4)

(5)

Equation (4) gives the rate for formation of a critical nucleus. The goal here is to calculate the maximum of super-
heating, i.e., the temperature at which melting occurs. Therefore, at this temperature w ∼ 1. The coeﬃcient B(rc)
in Eq. (4), is given by17

B(r) =

T
8πα(r − rc)

dr
dt

,

(6)

and can be calculated [for r → rc as in Eq. (4)] by considering a particular metastable state.

For a transition from the superheated to liquid state it is necessary to consider the diﬀusive transport of heat at

the liquid-solid interface18,19. It is convenient to deﬁne the dimensionless ﬁeld

where T∞ is the temperature of the solid inﬁnitely far from the growing nucleus and Cp is the speciﬁc heat. Then the
diﬀusion equation is

u =

Cp
L

(T∞ − T ),

(7)

∂u
∂t

= D ▽2 u,

(8)

where D is the thermal diﬀusion constant at T ∼ Tm. One boundary condition is the heat conservation at the
liquid-solid interface

where ˆ~n is the unit normal directed outward from the nucleus and vn is the normal growth velocity. There is also a
requirement of local thermodynamic equilibrium that gives the dimensionless temperature ul at the interface

vn = −Dˆ~n · ▽u,

(9)

where

ul = △ − d0K,

△ =

Cp
L

(T∞ − Tm)

4

(10)

(11)

is proportional to superheating. In the second term in Eq. (10) (i.e., in the Gibbs-Thomson correction for the melting
temperature at a curved surface) K is the curvature and d0 = αCpTmL−2. The solution for the growth rate of a
spherical nucleus is19

Therefore, using Eqs. (5), (6), (12), and T∞ = T , condition w ∼ 1 for Eq. (4) gives

∼

D
r2 (△rc − 2d0).

r→rc

dr
dt (cid:12)
(cid:12)
(cid:12)
(cid:12)

aT

1/2

3
(T − Tm)

2
exp{−[b/T (T − Tm)

]} = 1,

(12)

(13)

23, speciﬁc heat Cp

m and b = 16πα3T 2

m/3L2. Equation (13) was solved numerically using the experimental
where a = DLCp/16πα5/2T 2
23, and
data for interface free energy α4, latent heat of melting L4, bulk melting temperature Tm
diﬀusion constant D41. The value ∼ 23 K was obtained for the maximum of superheating. This value is smaller than
the maximum superheating temperature of 180 K estimated in MD simulation for a model of the Al(111) surface.
Part of this disagreement is the result of the approximate kinetic analysis and even possibly poor accuracy of some
experimental data for Al. There is also a possibility that the value for the maximum of superheating found in MD
simulations is in part the result of a limited time evolution. Although long runs of 106 time steps were performed in the
superheating regime, much longer (nowadays not feasible) simulation times may give the maximum of the superheating
temperature in accordance with the kinetic result. Using the kinetic analysis presented above, the same literature
sources for α, L, Tm, Cp, and diﬀusion constant D from Ref.42, the value of ∼ 47 K was obtained for the maximum
superheating temperature of Pb. For aluminum a similar Fokker-Planck analysis was done using quantities deduced
from the simulations. As in Ref.31, it was found that the bulk energy is slightly nonlinear function of temperature and
that therefore it can be ﬁtted by the second-order polynomial. Using this procedure31, the value of Cp = 1120 J/(K
kg) was obtained, whereas the experimental value for the speciﬁc heat is 902 J/(K kg) [23]. For diﬀusion constant
the value of D = 0.3 × 10−5 cm2/s was found (see also43). This is much lower than the experimental value 3 × 10−5
cm2/s41. When in Eq. (13) the quantities obtained in MD simulations for Cp, D, L = 0.105 eV/atom20, Tm = 939
K20, and α = 10 meV ˚A−214,43 were used, then 48 K was calculated for the maximum superheating temperature of
aluminum. It is important to point out that smaller values for the maximum superheating temperature were found
in the experiments on the crystallites1,2,12, whereas larger superheating was induced by a laser beam6–8,10.

IV. SUMMARY AND CONCLUSIONS

The properties of a surface in the superheated state were studied using MD simulation and a reliable many-body
interatomic potential. Superheated Al(111) was used as a model of superheated surfaces, such as ones obtained by a
pulsed laser beam6–8,10, or on the crystallites12. A detailed analysis of the Al(111) surface from room temperature
to 1500 K (i.e., well above the bulk melting point) was carried out. The results for lower temperatures are in a good
agreement with available experimental observations and other MD simulations and electronic structure calculations
for metal surfaces. It is possible to superheat the sample by ∼ 180 K for typical longest simulation times used in
classical MD (> 2.5 ns). In the superheating regime the Al(111) surface is remarkably well ordered, although single
adatoms sometimes appear. The sample melts over the narrow temperature interval. Anomalous outward expansion
between two top layers increases slowly with the temperature: from +0.9% at T = 0, up to +3.3% at the end of the
superheating region. The mean-square vibrational amplitudes are isotropic for all temperatures and ∼ 10 times larger
at the end of the superheating region than below the bulk melting point. It was shown that kinetic theory based
on the Fokker-Planck equation and analysis of heat conservation at the liquid-solid interface for aluminum gives the
maximum superheating temperature of 23 K when experimentally determined parameters where used. The maximum
superheating temperature of 48 K was obtained when parameters deduced from MD simulations where applied in the
Fokker-Planck analysis. This analysis of kinetics and process of disordering observed in MD simulation shows that
superheated Al(111) and bulk Al below the surface are an example of metastability at the solid-to-liquid transition.
The kinetics of this transition is the same as in other better known examples of metastability17. Superheated surfaces
of other metals should exhibit similar behavior.

I would like to thank F. Ercolessi, B. Gumhalter, and E. Tosatti for discussions.

ACKNOWLEDGMENTS

5

1 L. Gr˚abek, J. Bohr, E. Johnson, A. Johansen, L. Sarholt-Kristensen, and H. H. Andersen, Phys. Rev. Lett. 64, 934 (1990).
2 J. Daeges, H. Gleiter, and J. H. Perepezko, Phys. Lett. A 119, 79 (1986).
3 J. Q. Broughton, Phys. Rev. Lett. 67, 2990 (1991).
4 J. F. van der Veen, B. Pluis, and A. W. Denier van der Gon, in Chemistry and Physics of Solid Surfaces VII, edited by R.

Vanselow and R. F. Howe (Springer, Berlin, 1988), p. 455.

5 J. A. W. Denier van der Gon, R. J. Smith, J. M. Gay, D. J. O’ Connor, and J. F. van der Veen, Surf. Sci. 227, 143 (1990).
6 J. W. Herman and H. E. Elsayed-Ali, Phys. Rev. Lett. 69, 1228 (1992).
7 E. A. Murphy, H. E. Elsayed-Ali, and J. W. Herman, Phys. Rev. B 48, 4921 (1993).
8 J. W. Herman, H. E. Elsayed-Ali, and E. A. Murphy, Phys. Rev. Lett. 71, 400 (1993).
9 J. W. Herman and H. E. Elsayed-Ali, Phys. Rev. Lett. 68, 2952 (1992).
10 J. W. Herman and H. E. Elsayed-Ali, Phys. Rev. B 49, 4886 (1994).
11 H. H¨akkinen and U. Landman, Phys. Rev. Lett. 71, 1023 (1993).
12 J. J. Metois and J. C. Heyraud, J. Phys. 50, 3175 (1989).
13 P. Carnevali, F. Ercolessi, and E. Tosatti, Phys. Rev. B 36, 6701 (1987).
14 F. D. Di Tolla, F. Ercolessi, and E. Tosatti, Phys. Rev. Lett. 74, 3201 (1995).
15 H. H¨akkinen and M. Manninen, Phys. Rev. B 46, 1725 (1992).
16 G. Bilalbegovi´c, F. Ercolessi, and E. Tosatti, Europhys. Lett. 17, 333 (1992).
17 E. M. Lifshitz and L. P. Pitaevskii, Physical Kinetics (Pergamon, Oxford, 1981), Chap. XII.
18 J. S. Langer, in Chance and Matter, edited by J. Souletie, J. Vannimenus, and R. Stora (North-Holland, Amsterdam, 1987),

Les Houches, Series XLVI, p. 629.

19 H. Muller-Krumbhaar and W. Kurz, in Phase Transformations in Materials, edited by P. Haasen (VCH-Verlag, Weinheim,

1991), p. 553.

20 F. Ercolessi and J. B. Adams, Europhys. Lett. 26, 583 (1994).
21 M. S. Daw and M. I. Baskes, Phys. Rev. B 29, 6443 (1984).
22 A. M. Raphuthi, X. Q. Wang, F. Ercolessi, and J. B. Adams, Phys. Rev. B 52, 5554 (1995).
23 J. Emsley, The Elements, (Oxford University Press, Oxford, 1996), 3rd edition, and G. W. C. Kaye and T. H.
Laby, Tables of physical and chemical constants, (Longman, London, 1993), 15th edition, as discussed in WebElements,
http://www.shef.ac.uk/∼chem/web-elements/, (University of Sheﬃeld, Sheﬃeld, 1996).

24 J. R. Morris, C. Z. Wang, K. M. Ho, and C. T. Chan, Phys. Rev. B 49, 3109 (1994).
25 F. Ercolessi, O. Tomagnini, S. Iarlori, and E. Tosatti, in Nanosources and Manipulation of Atoms under High Fields and
Temperatures: Applications, edited by Vu Thien Binh, N. Garcia, and K. Dransfeld (Kluwer, Dordrecht, 1993), NATO ASI
Series E, Vol. 235, p. 185.

26 R. C. Cammarata, Prog. Surf. Sci. 46, 1 (1994).
27 J. Q. Broughton and G. H. Gilmer, J. Chem. Phys. 79, 5105 (1983).
28 F. Ercolessi, S. Iarlori, O. Tomagnini, E. Tosatti, and X. J. Chen, Surf. Sci. 251/252, 645 (1991).
29 G. Bilalbegovi´c and E. Tosatti, Phys. Rev. B 48, 11240 (1993).
30 G. Bilalbegovi´c, Phys. Rev. B 53, 1616 (1996).
31 B. D. Todd and R. M. Lynden-Bell, Surf. Sci. 281, 191 (1993).
32 R. J. Needs and M. J. Godfrey, Phys. Rev. B 42, 10933 (1990).
33 P. J. Feibelman, Phys. Rev. B 50, 1908 (1994).
34 M. Schmid, W. Hofer, P. Varga, P. Stoltze, K. W. Jacobsen, and J. K. Nørskov, Phys. Rev. B 51, 10937 (1995).
35 S. M. Thompson, K. E. Gubbins, J. P. R. B Walton, R. A. R. Chantry, and J. S. Rowlinson, J. Chem. Phys. 81, 530 (1984);

M. P. Allen and D. J. Tildesley, Computer Simulation of Liquids (Clarendon, Oxford,1987).

36 L. Yang, T. S. Rahman, and M. S. Daw, Phys. Rev. B44, 13725 (1991).
37 Y. Beaudet, L. J. Lewis, and M. Persson, Phys. Rev. B50, 12084 (1994).
38 Q. T. Jiang, P. Fenter, and T. Gustafsson, Phys. Rev. B 44, 5773 (1991); B. M. Ocko, D. Gibbs, K. G. Huang, D. M. Zehner,

and S. G. J. Mochrie, ibid. 44, 6429 (1991).

39 H. B. Nielsen and D. L. Adams, J. Phys. C 15, 615 (1982).
40 L. D. Landau and E. M. Lifshitz, Statistical Physics (Pergamon, Oxford, 1980), Sec. 162.
41 W. Ludwig, Diploma work, University of M¨unster, M¨unster, 1969, as discussed in W. Schommers, C. Mayer, H. G¨obel, and

P. von Blanckenhagen, J. Vac. Sci. Technol. A 13, 1413 (1995).

42 N. H. Nachtrieb, Ber. Bunsenges. 80, 678 (1976), as discussed in J. W. M. Frenken, B. J. Hinch, J. P. Toennies, and Ch.

W¨oll, Phys. Rev. B 41, 938 (1990).

43 F. D. Di Tolla, Ph.D. thesis, SISSA Trieste, 1996.

6

TABLE I. Mean-square vibrational amplitudes for the Al(111) surface (in units of ˚A2): u2

x (along the [1¯10] direction), u2
y
z (along the vertical axis). The surface relaxation d12 between the two top layers is also shown

(along the [11¯2] direction) and u2
(in %).

Temperature
300 K
900 K
1050 K
1120 K

u2
x
0.014
0.074
0.118
0.839

u2
y
0.022
0.064
0.119
0.708

u2
z
0.018
0.075
0.101
0.731

d12
+1.1
+2.2
+2.4
+3.3

FIG. 1. Particle trajectories showing the superheated surface after 106 MD steps of time evolution at 1050 K (i.e., 110 K
above the bulk melting temperature): (a) top view, (b) side view with an adatom above the surface. Trajectory plots refer to
a time span of ∼ 3 ps and include only moving atoms.

FIG. 2. The caloric curve. The vertical line represents the calculated bulk melting temperature.

FIG. 3. Surface stress as a function of temperature. The dashed vertical lines enclose the superheating region.

7

This figure ""Fig1.gif"" is available in ""gif""(cid:10) format from:

http://arxiv.org/ps/cond-mat/9704045v1

−2.80

−2.90

−3.00

−3.10

−3.20

−3.30

)

V
e
(

m
o
t
a

r
e
p

y
g
r
e
n
e

−3.40

0.0

200.0 400.0 600.0 800.0 1000.0 1200.0 1400.0

temperature (K)

 Fig. 2                                
 G. Bilalbegovic                         

 
 
 
)

/

2
Å
V
e
(

s
s
e
r
t
s

e
c
a
f
r
u
s

0.100

0.090

0.080

0.070

0.060

0.050

0.040

0.030

0

200

400

600

800
temperature (K)

1000

1200

1400 1600

 Fig. 3                                
 G. Bilalbegovic"
Damping of Oscillations in Layer-by-Layer Growth,"  We present a theory for the damping of layer-by-layer growth oscillations in
molecular beam epitaxy. The surface becomes rough on distances larger than a
layer coherence length which is substantially larger than the diffusion length.
The damping time can be calculated by a comparison of the competing roughening
and smoothening mechanisms. The dependence on the growth conditions,
temperature and deposition rate, is characterized by a power law. The
theoretical results are confirmed by computer simulations.
",http://arxiv.org/pdf/cond-mat/9705100v1,2,"Damping of Oscillations in Layer-by-Layer Growth

H. Kallabis (∗), L. Brendel (∗), J. Krug (∗∗), D. E. Wolf (∗)

(*) HLRZ, Forschungszentrum J¨ulich, D-52425 J¨ulich, Germany

and

FB 10, Gerhard – Mercator – Universit¨at, D-47048 Duisburg, Germany

(**) Fachbereich Physik, Universit¨at GH Essen, D-45117 Essen, Germany

Abstract

We present a theory for the damping of layer-by-layer growth oscillations in molecular

beam epitaxy. The surface becomes rough on distances larger than a layer coherence length

which is substantially larger than the diﬀusion length. The damping time can be calcu-

lated by a comparison of the competing roughening and smoothening mechanisms. The

dependence on the growth conditions, temperature and deposition rate, is characterized by

a power law. The theoretical results are conﬁrmed by computer simulations.

7
9
9
1

y
a
M
2
1

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
0
0
1
5
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

1

 
 
 
 
 
 
I. INTRODUCTION

Basic questions of crystal growth have been a source of inspiration in physics for many

years [1]. Several concepts of general theoretical importance were originally developed in

this area, but a good deal of the fascination is also due to the technological relevance.

Here we want to address layer-by-layer growth or Frank-van der Merwe growth, as it is

also called [2]. This is a growth mode in molecular beam epitaxy which allows well controlled

manipulation of e.g. chemical composition in layers down to atomic thickness. It is therefore

particularly suited for the fabrication of electronic devices.

In the most elementary model of layer-by-layer growth atoms are deposited under high

vacuum conditions onto a (100) or (111) surface, for instance. The adatoms diﬀuse on

the surface until they meet one another to form dimers which then grow into islands of

monoatomic height. Their edges capture most of the adatoms during the deposition of one

monolayer. When the available island edges become less due to coalescence, the formation of

dimers and islands in the next layer begins. Hence the density of atomic steps like all other

quantities which are sensitive to the surface morphology oscillate. These oscillations are

the real hallmark of layer-by-layer growth. They can be used to monitor the ﬁlm thickness

easily.

In step ﬂow growth of a vicinal surface, where the nucleation of islands on the terraces

can be neglected, as well as for rough surfaces the oscillations are absent. In practice, one

cannot prepare substrates without a miscut. It may happen to be very weak, but it cannot

be controlled. Layer-by-layer growth with its oscillations can only be seen if some terraces

between steps are wide enough to allow for the formation of islands.

Generically, the oscillations are damped: Layer-by-layer growth is only a transient. The

reason can be either the emergence of a smooth surface with step ﬂow or of roughness [3],

two entirely diﬀerent diagnoses for the same symptom. However, increasing the temperature

the damping should become stronger in the ﬁrst and weaker in the second case, allowing to

discriminate the two. Roughness itself can have two diﬀerent reasons. If interlayer transport

2

is inhibited by step edge barriers, adatoms accumulate on top of islands, and one obtains

the growth instability predicted by J. Villain [4], demonstrated and analysed in computer

simulations [5] and observed in many experiments [6]. If no instability occurs, the surface

may still roughen due to ﬂuctuations in the beam intensity (shot noise). This is the case

which will be discussed below in more detail.

Layer-by-layer growth is also possible if one starts from a patterned substrate rather

than a perfectly smooth one, and one may wish to optimize the growth conditions such that

the pattern stays intact for several layers. This optimization process is nontrivial: On one

hand, the islands nucleate with a characteristic distance l, which sets the spatial resolution

for the pattern in subsequent layers. On the other hand, deposition, diﬀusion and island

nucleation are stochastic processes and lead to the accumulation of errors in the pattern,

the thicker the ﬁlm grows. Often, reducing these errors implies an increase of l and hence a

worse resolution of the pattern.

In order to understand layer-by-layer growth, one therefore has to investigate spatial

correlations, temporal correlations and ﬁnally the emergence of surface roughness, which

determines, for how many layers the oscillations can be seen.

The spatial correlations in layer-by-layer growth manifest themselves through the char-

acteristic distance l of nucleation events within a layer mentioned above. The dependence

of l on growth conditions has already been well studied [7–13], and the key result needed

later is

l ∝ (D/F )γ,

(1)

where D and F are the surface diﬀusion constant and the deposition rate, respectively. The

exponent γ depends on the adatom diﬀusion process and the (fractal) dimension of the

islands. It also depends on whether or not desorption of adatoms or diﬀusion of dimers or

larger clusters are negligible, as we assume in the simulations presented below. Finally, γ

is a function of the critical island size i∗, which is deﬁned by the size i∗ + 1 of the smallest

island, which is stable enough that it never decays before capturing the next adatom.

3

The temporal correlations are interesting, because they determine how well a nucleation

pattern is reproduced in subsequent layers. For example there is a high probability that

the ﬁrst island nucleates on top of the ﬁrst one of the previous layer, because this is the

area where adatoms accumulate most likely. In fact, it was shown that the autocorrelation

function of the ﬁrst nucleation events decays rather slowly with time like t−1/2 [14]. Of

course, this power law is only valid as long as layer-by-layer growth persists. It will be cut

oﬀ by the time ˜t, which characterizes the damping of the oscillations.

The main subject of this paper is the emergence of surface roughness responsible for the

damping of the oscillations. The simulation results show that layer-by-layer growth goes on

forever if the linear size of the system is smaller than a layer coherence length ˜l. Up to this

length the layers grow coherently, for larger distances they get out of phase. Remarkably,

˜l is much larger than the characteristic distance between islands, l. The surface becomes

rough on scales larger than ˜l rather than the diﬀusion length l.

In order to study kinetic roughening one may average the ﬁlm thickness over the distance

˜l. Then one cannot resolve individual islands any more, but still sees the dephasing between

layers. Phenomena on this scale can be described by continuum equations, which provide the

most transparent theoretical framework in which to discuss the smoothening mechanisms

competing with the shot noise. The layer coherence length ˜l as well as the damping time

˜t play an important rˆole for kinetic roughening as natural cutoﬀs of the continuum growth

equation at small length and time scales. This idea will be worked out in section II.

Recently, it has been discovered [15,12] that ˜t depends on the growth conditions like

F ˜t ∝ (D/F )δ.

(2)

This law will be explained in section III based on the results of section II. Both sections,

II and III rely on dimensional arguments. In section IV the key results of the preceding

section are rederived avoiding dimensional arguments. Section V contains a discussion of

crossovers due to diﬀerent smoothening mechanisms, and section VI reviews the numerical

results conﬁrming the theoretical picture.

4

II. A THEORY FOR THE LAYER COHERENCE LENGTH AND THE

DAMPING TIME

The transition from layer-by-layer growth with its oscillations to kinetic roughening

happens at time ˜t, when the ﬁlm thickness varies over the distance ˜l by about one atomic

layer. For t > ˜t one expects that the surface shows self aﬃne scaling [16]:

w(t) ≈ a⊥(ξ(t)/˜l)ζ

with

ξ(t) ≈ ˜l (t/˜t)1/z.

(3)

Here, w is the root mean square variation of the ﬁlm thickness, a⊥ the thickness of one atomic

layer, and ξ the correlation length up to which the surface roughness has fully developed

until time t. ζ is the roughness exponent and z the dynamical exponent.

˜t is the time at which a continuum description of kinetic roughening becomes appropriate.

Whenever desorption and the formation of defects in the growing ﬁlm can be neglected the

equation of motion must have the form

∂th = −∇ · j + η,

(4)

where h is the deviation of the ﬁlm thickness from its average value and η(x, t) denotes the

shot noise with correlator

hη(x, t)η(x′, t′)i = F δd(x − x′)δ(t − t′).

(5)

d is the surface dimension. In the conserved KPZ (cKPZ) equation, which has been widely

discussed [4,17–19] in the context of molecular beam epitaxy, the adatom current has two

terms, one driven by diﬀerences in the surface curvature and the second one by diﬀerences

in the squared surface tilt:

j = ∇[K∇2h + λ(∇h)2].

(6)

Eq.(3) shows that the only characteristic length, time and height entering the description

of the rough surface (coarse grained on scale ˜l) are ˜l, ˜t and a⊥, respectively. Therefore K,

λ and F must be functions of these three quantities. For example, λ has the dimension

5

length4 height−1 time−1. This implies that it must be the product of a dimensionless factor

and ˜l4/a⊥˜t. Similarly one obtains

K ≈ a⊥λ ≈ ˜l4/˜t

(7)

According to (4), η has the dimension height/time. Taking the dimensions of the δ-functions

in (5) (length−d and time−1, respectively) into account, one ﬁnds that F is

F ≈ a2

⊥˜ld/˜t,

(8)

up to a dimensionless factor.

III. CONNECTION WITH SUBMONOLAYER PHYSICS

In order to derive (2) from (7), (8) one has to know, how K (or a⊥λ) and F depend on

D and F . This question will be answered in the following.

The physics of kinetic roughening should be determined by the same microscopic pro-

cesses that are also responsible for the phenomena in the submonolayer regime. There, the

characteristic time is the layer completion time,

τ = (F ad)−1,

(9)

and there are two characteristic lengths, the diﬀusion length, l, and the lattice constant

along the surface, a. Therefore, it must be possible to express K, λ and F in terms of l, a,

τ and a⊥.

The coeﬃcients λ and K characterize the morphology dependence of the nonequilibrium

adatom density, which drives the surface current (see Section IV). The most important

morphological feature is the typical distance between islands. Therefore it is natural to

assume that K and a⊥λ are only functions of l and τ . The only dimensionally correct

expressions are then [20]

K ≈ a⊥λ ≈ l4/τ.

6

(10)

By contrast, the shot noise cannot depend on surface diﬀusion. Therefore, the diﬀusion

length l cannot enter, and F /a2

⊥ can only be a function of a and τ . The only dimensionally

correct expression is then

F ≈ a2

⊥ad/τ = F (a⊥ad)2

.

Comparing (10,11) with (7,8) one ﬁnds that

˜l4/˜t ≈ l4/τ

and

˜ld/˜t ≈ ad/τ.

This, ﬁnally, leads to the central result of this paper,

˜l/a ≈ (l/a)4/(4−d)

and

F ad˜t = ˜t/τ ≈ (l/a)4d/(4−d).

(11)

(12)

(13)

Note in particular that the layer coherence length ˜l ≫ l. With (1) the exponent δ deﬁned

in (2) is

δ = γ

4d
4 − d

,

(14)

provided the cKPZ equation is the appropriate continuum equation for the growth process.

At the upper critical dimensionality d = dc = 4 the scales ˜l and ˜t depend exponentially on

l, while for d > dc the oscillations persist forever and the surface remains smooth.

IV. THE ADATOM CURRENT AND THE SHOT NOISE RECONSIDERED

In this section (10) and (11) will be rederived without using dimensional arguments.

First we give a microscopic derivation of the nonlinear contribution to the adatom current

(6) (see also [21]).

It was proposed by Villain [4] that in growth processes far from equilibrium, where local

chemical potentials along the surface are ill deﬁned, diﬀusion currents should be driven by

gradients in the growth-induced, nonequilibrium adatom density n,

7

j = −Da⊥ad ∇n.

(15)

The factor ada⊥ is the atomic volume and enters because (4) expresses volume rather than

mass conservation.

On a singular surface the balance between deposition and capture of adatoms at steps

leads to a stationary adatom density n = n0 of the order [10]

n0 ≈ (F/D)l2.

(16)

On a vicinal surface the adatom density is reduced due to the presence of additional steps;

however this eﬀect is felt only if the miscut m = |∇h| exceeds a⊥/l, in which case (16) is

replaced by n ≈ (F/D)(a⊥/m)2. In terms of a coarse grained description of the surface this

implies that the local adatom density depends on the local miscut or surface tilt. A useful

interpolation formula which connects the regimes m ≪ a⊥/l and m ≫ a⊥/l is [20]

n(∇h) =

n0

1 + (l∇h/a⊥)2 ≈ (F/D)l2 − (F/D)l4(∇h/a⊥)2 + . . .

(17)

Inserting the leading quadratic term of this gradient expansion into (15), which is appropriate

for describing long wavelength ﬂuctuations around the singular orientation, we obtain

j = ∇λ(∇h)2

with λ = F adl4/a⊥, which agrees with the result (10) of the previous section.

Now we rederive (11) for the shot noise, which can be written as

˜ld/˜t = F a2d

(18)

(19)

by inserting (8) and (9). This follows from considering the number of particles deposited

during time ˜t into area ˜ld, F ˜t ˜ld ± (F ˜t ˜ld)1/2. Each particle contributes a volume ada⊥, so

that the ﬂuctuation of the ﬁlm thickness over the distance ˜l is

w(˜t) ≈

F ˜t ˜ld ada⊥/˜ld.

q

(20)

At ˜t this should be the thickness of about one atomic layer, w(˜t) ≈ a⊥, which results in (19).

8

V. COMPETING MECHANISMS

Whereas for our computer simulation model the theoretical arguments given in the pre-

ceding sections are perfectly appropriate, the question arises how relevant these results are

in general experimental situations. It has been argued that generically one should expect

nonequilibrium contributions to the surface current which are driven by a height diﬀerence

[4,17,22]. To leading order in a gradient expansion one gets an adatom current of the form

j = −ν∇h.

(21)

Eq.(4) with such a current is known as the Edwards-Wilkinson (EW) equation [23].

Tilt induced nonequilibrium surface currents originate from step edge barriers of Ehrlich-

Schwoebel-type [24], as well as kick-out or diﬀusion exchange processes at step edges.

Whereas the latter two lead to a downhill current stabilizing the surface (ν > 0), the

former generates an uphill current (ν < 0) and consequently an instability which will not be

considered in the following.

In the case of kick-out processes the coeﬃcient ν cannot depend on the diﬀusion length,

because they are caused by deposition events in the immediate vicinity of a downward step.

The only dimensionally correct expression is therefore

ν = a2/τ = F ad+2.

(22)

The corresponding current is proportional to the local step density ∇h and the deposition

rate F . Such contributions will be absent in the simulations discussed in the next section.

In general, the adatom current will contain the terms (6) as well as (21). The latter

one dominates the surface roughness on large scales. Whether or not it inﬂuences the

damping of the growth oscillations, however, depends on the crossover time tλν from cKPZ-

(λ-dominated) at early to EW- (ν-dominated) behaviour at late times. If the oscillations

are damped out before the crossover takes place, the λ-term determines the damping, hence

the above result applies. Let ˜tλ and ˜tν denote the damping times if only the λ- or the ν-term

were present in the continuum equation of motion. Then (13) and (14) hold if

9

˜tλ ≤ tλν.

(23)

If, however, this is not the case, then ˜tλ is replaced by ˜tν, as long as no further terms in the

continuum description provide further time scales.

The crossover time tνλ is estimated in the following way: First we calculate the typical

height ﬂuctuation hν(t) after time t, if the λ-term would be absent. Similarly, hλ(t) is the

ﬂuctuation amplitude, if ν = 0. Equating hλ and hν then gives tλν. By dimensional analysis

one gets (see appendix)

F tλν ≈

4/(d+2)

λ
F !

(cid:18)

(d+8)/(d+2)

F
ν (cid:19)

≈ a2

⊥ad

16/(d+2)

,

l
a !

where (9-11) and (22) have been used to replace the parameters λ, F and ν.

This has to be compared with (13),

F ˜tλ ≈ a2

⊥ad

4d/(4−d)

.

l
a !

(24)

(25)

For d ≤ 2 the damping time ˜tλ is smaller or of equal order of magnitude as the crossover time

tλν. This implies that kick-out processes at step edges, although leading to an EW-term

in the growth equation and hence modifying the later roughness, do not change our results

(13) for the layer coherence length and the damping time.

However, if for example the sticking probability at an up step would be much smaller

than at a down step (e.g. due to a step decoration by surfactant atoms [25]), one would

expect a downhill current depending on l rather than the lattice constant a, i.e. with

ν ≈ l2/τ

instead of (22). In this case (24) is replaced by

F tλν ≈ a⊥ad

−2d/(2+d)

,

l
a !

which is never larger than F ˜tλ. The damping time should then be given by (39)

F ad˜tν ≈

2d/(2−d)

.

l
a !

10

(26)

(27)

(28)

 
 
 
 
 
VI. NUMERICAL RESULTS

We carried out simulations with a simpliﬁed model: Atoms are deposited onto a one-

dimensional surface with a deposition rate F and diﬀuse with a diﬀusion constant D until

they meet other adatoms or a cluster of adatoms. If the encountered cluster consists of i∗

or more atoms, the atom is incorporated into this cluster, and a stable, immobile island is

formed. Clusters of size i∗ or less are allowed to decay. There are no barriers for interlayer

transport (Ehrlich-Schwoebel barriers [24]) and no overhangs or holes are allowed (solid-

on-solid condition).

In the simulations we use a and a⊥ as length and height unit, i.e.

a = a⊥ = 1.

The squared surface width w2 = hh2i − hhi2 as a function of time for various D/F and

i∗ = 1 is shown in ﬁg. 1 (h. . .i denotes the ensemble and spatial average).

101

2

w

100

10−1

100

101

102

103

Ft

FIG. 1. Squared surface width at integer and half-integer times (in units of the layer completion

time τ = 1/F ) for diﬀerent values of the parameter D/F = 105 . . . 1010 (from top to bottom).

For a given D/F , the oscillations in the surface width persist up to a coverage F ˜t, which

increases with D/F . Beyond F ˜t, the crossover to kinetic roughening is observed, where w2

11

 
approaches a power law t2β with the cKPZ prediction of β = 1/3 in one dimension [4,18,19].

Rescaling F t by F ˜t = (D/F )1/3 in ﬁg.2 we ﬁnd an excellent collapse of the crossover regions

for all curves of ﬁg.1. This means that δ = 1/3 within numerical accuracy, in agreement

with (14) and γ = 1/4 [11].

101

2

w

100

10−1

10−4

10−2

100

t/(D/F)1/3

102

FIG. 2. Curves from ﬁg. 1, with time scaled by (D/F )1/3.

We measured the damping time for diﬀerent values of i∗ by determining the coverage

F ˜t, where w = 0.71, 0.57 or 0.65 for i∗ = 1, 2, 3, respectively. It depends on l measured

as the system size divided by the total number of nucleation events which occurred in one

layer. Fig.3 shows that F ˜t ∼ l4/3, independent of the values i∗ = 1, 2, 3, in agreement with

the theoretical result (13).

12

 
~

t

F

103

102

101

101

i*=1 
i*=2 
i*=3 

102

103

104

l

FIG. 3. Coverage F ˜t, at which the surface width reaches a given value (see text), as a function

of the diﬀusion length l for diﬀerent values i∗. The straight lines are ﬁts to the last four data

points in each set of data. Their slopes are 1.39 ± 0.09, 1.34 ± 0.09 and 1.38 ± 0.09 for i∗ = 1, 2, 3,

respectively.

In order to check that the damping time and the layer coherence length are the appro-

priate scales also for other quantities showing oscillations during the layer-by-layer growth

we investigated the Bragg intensity or kinematic intensity I = h(neven − nodd)2i where neven

(nodd) denotes the number of surface sites in even (odd) layers. It is related to the RHEED

intensity in experiments. Fig. 4 shows I at integer times, rescaled in the same way as in ﬁg.2.

Again, we ﬁnd that the number of observable oscillations varies with the growth conditions

as described by (13).

13

 
0.8

0.6

I

0.4

0.2

0.0

10−4

10−2

100

t/(D/F)1/3

102

FIG. 4. Maxima of the kinematic intensity for D/F = 105 . . . 1010 (right to left), and i∗ = 1.

Time is scaled by (D/F )1/3.

Finally, we carried out a ﬁnite size analysis to measure the layer coherence length ˜l

explicitly. As mentioned in section I, the surface does not roughen when the system size

L is smaller than ˜l. Then, the oscillations of the surface width w persist forever. After a

transient time, the amplitude of the oscillations becomes stationary. We take the variance

of the surface width w(t) during the layer completion time τ = 1/F ,

A(t)2 = hw2i[t,t+τ ] − hwi2

[t,t+τ ],

(29)

as a measure of the squared amplitude of the oscillations. h. . .i[t,t+τ ] means the time average

over the interval [t, t+ τ ]. If this variance becomes equal to the ensemble ﬂuctuations of w at

ﬁxed time, no oscillations can be observed. We ﬁnd that A(t) approaches a stationary value

which decreases with increasing system size. For system sizes larger than a certain value ˜L

A(t) is equal to the statistical ﬂuctuations of w itself. This means that in a system of size

L > ˜L the oscillations can die out (or rather cannot be distinguished from noise anymore for

long times). Therefore, ˜L can be identiﬁed with ˜l. According to (13) and (1) with γ = 1/4

14

in one dimension for i∗ = 1 [11], one expects ˜L ∼ (D/F )1/3. Indeed, the simulation results

shown in ﬁg. 5 are in excellent agreement with the theoretical prediction.

103

~

L

102

101

104

105

106

107

D/F

FIG. 5. ˜L as a function of D/F . The ﬁt has a slope of 0.339 ± 0.006.

VII. ACKNOWLEDGEMENTS

Useful discussions with M. Schroeder, P. ˇSmilauer and J. Villain are gratefully acknowl-

edged. We acknowledge support by DFG within SFB 166 Strukturelle und magnetische

Phasen¨uberg¨ange in ¨Ubergangsmetall-Legierungen und Verbindungen (D.E.W.) and SFB 237

Unordnung und grosse Fluktuationen (J.K.).

APPENDIX

We consider the following continuum equation :

∂h
∂t

= ν∇2h − K(∇2)2h − λ∇2(∇h)2 + η + ηc

(30)

15

 
where η and ηc are gaussian distributed random forces with zero mean and second moment

hη(x, t)η(x

′

hηc(x, t)ηc(x

′

′

, t

′

, t

)i = F δd(x − x

′

′

) δ(t − t

),

)i = −D ∇2 δd(x − x

′

′

) δ(t − t

),

(31)

(32)

which describe the shot noise and the diﬀusion noise [26], respectively. Dimensional argu-

ments as in section III together with (16) and (11)lead to the well known expression

D ≈ F l2 ≈ Dn0 (ada⊥)2

(33)

for the correlator of the conserved noise [19]. This implies that the conserved noise dominates

the ﬂuctuations only on distances shorter than the typical diﬀusion length l [27]. As we are

dealing with larger length scales, the conserved noise may be neglected in the following.

The physical dimensions of the remaining parameters in (30) are

[ν] = x2t−1, [K] = x4t−1, [λ] = x4t−1h−1, [F ] = xdt−1h2.

Comparing those of ν and F one gets

hν(t) = (F /ν)d/4(F t)(2−d)/4,

comparing those of λ and F one gets [28]

hλ(t) = (F /λ)d/(8+d)(F t)(4−d)/(8+d),

and ﬁnally comparing those of K and F one gets

hK(t) = (F /K)d/8(F t)(4−d)/8.

(34)

(35)

(36)

(37)

The dimensional analysis of the linear equations, leading to (35) and (37), already gives

the right scaling behaviour of h as function of t, due to the non-renormalisation of the

parameters ν, K and F [21].

Setting hλ(tλν) = hν(tλν) gives the crossover time tλν in (24). In the same fashion, by

setting hK(tKλ) = hλ(tKλ) one gets

16

F tKλ =

(cid:18)

(8+d)/(4−d)

K
F (cid:19)

8/(4−d)

F
λ (cid:19)

(cid:18)

= a⊥ad

l
a !

4d/(4−d)

(38)

for the crossover time from K− to λ−dominated roughening. In the last equality eqns. (10)

and (11) have been used. Then the crossover time agrees with the expression (25), consistent

with the fact, that the K-term and the λ-term give the same result.

Finally, one can ask for the typical times, where hK, hλ or hν become ≃ 1, i.e. the times

which can be interpreted as the damping times, if only the corresponding term is present:

F ˜tK = a2
⊥

d/(4−d)

Ka2
⊥
F !

, F ˜tλ = a2
⊥

d/(4−d)

λa3
⊥
F !

, F ˜tν = a2
⊥

d/(2−d)

νa2
⊥
F !

.

(39)

[1] J. Villain, A. Pimpinelli: Physique de la Croissance Cristalline (´Editions Eyrolles et CEA,

1995)

[2] E. Bauer, Z. Kristallogr. 110, 372 (1958)

[3] H.C. Kang and J.W. Evans, Surf. Sci. 271, 321 (1992); M.C. Bartelt and J.W. Evans,

Phys. Rev. Lett. 75, 4250 (1995).

[4] J. Villain, J. Phys. France I 1, 19 (1991).

[5] M. Siegert and M. Plischke, Phys. Rev. Lett. 68, 2035 (1992); ibid. 73, 1517 (1994); P. ˇSmilauer

and D.D. Vvedensky, Phys. Rev. B 52, 14263 (1995).

[6] K. Th¨urmer, R. Koch, M. Weber and K.H. Rieder, Phys. Rev. Lett.75, 1767 (1995); J.A.

Stroscio, D.T. Pierce, M. Stiles, A. Zangwill and L.M. Sander, Phys. Rev. Lett. 75, 4246

(1995); J.E. Van Nostrand, S.J. Chey, M.-A. Hasan, D.G. Cahill and J.E. Greene, Phys. Rev.

Lett. 74, 1127 (1995).

[7] G. Zinsmeister, Thin Solid Films 2, 497 (1968); ibid. 4, 363 (1969); ibid. 7, 51 (1971).

17

 
 
 
 
[8] S. Stoyanov and D. Kashchiev in Current Topics in Material Science, edited by E. Kaldis

(North-Holland, Amsterdam, 1981), Vol. 7, pp. 69 - 141.

[9] J. A. Venables, G. D. Spiller and M. Hannbrucken, Rep. Prog. Phys. 47, 300 (1984).

[10] J. Villain, A. Pimpinelli and D. Wolf, Comments Cond. Mat. Phys. 16, 1 (1992).

[11] A. Pimpinelli, J. Villain, D. E. Wolf, Phys. Rev. Lett. 69, 985 (1992).

[12] D. E. Wolf, in: Scale Invariance, Interfaces, and Non-Equilibrium Dynamics, eds. A. McKane,

et al. (Plenum, New York, 1995) pp. 215 - 248.

[13] P. Jensen, H. Larralde and A. Pimpinelli, cond-mat/9610001

[14] E. Somfai, J. Kert´esz and D. E. Wolf, J. Phys. I France 6, 393 (1996).

[15] L. Brendel: Fluktuationsschw¨achung in Wachstumsmodellen f¨ur Molekularstrahlepitaxie,

Diplomarbeit, Gerhard-Mercator-Univ. Duisburg, 1994.

[16] F. Family and T. Vicsek (eds.): Dynamics of Fractal Surfaces (World Scientiﬁc, Singapore

1991).

[17] D. E. Wolf and J. Villain, Europhys. Lett. 13, 389 (1990).

[18] Z.-W. Lai and S. Das Sarma, Phys. Rev. Lett. 66, 2348 (1991).

[19] L. - H. Tang and T. Nattermann, Phys. Rev. Lett. 66, 2899 (1991).

[20] P. Politi and J. Villain, Phys. Rev. B 54, 5114 (1996).

[21] J. Krug, Adv. Phys. (in press).

[22] J. Krug, M. Plischke and M. Siegert, Phys. Rev. Lett. 70, 3271 (1993).

[23] S.F. Edwards and D.R. Wilkinson, Proc. Roy. Soc. London A 381, 17 (1982).

[24] G. Ehrlich and F. G. Hudda, J. Chem. Phys. 44, 1039 (1966); R. L. Schwoebel and

E. J. Shipsey, J. Appl. Phys. 37, 3682 (1966).

18

[25] I. Markov, Phys. Rev. B 50, 11271 (1994)

[26] T. Sun, H. Guo and M. Grant, Phys. Rev. A 40, 6763 (1989).

[27] K. Moser and D. E. Wolf, in: Surface Disordering: Growth, Roughening, and Phase Transi-

tions, eds. R. Jullien, J. Kert´esz, P. Meakin, and D. E. Wolf (Nova Science, Commack, 1992)

p. 21

[28] J. Amar and F. Family, Phys. Rev. A 45, 5378 (1992)

19"
Nucleation Theory of Magnetization Switching in Nanoscale Ferromagnets,"  A nucleation picture of magnetization switching in single-domain
ferromagnetic nanoparticles with high local anisotropy is discussed. Relevant
aspects of nucleation theory are presented, stressing the effects of the
particle size on the switching dynamics. The theory is illustrated by Monte
Carlo simulations and compared with experiments on single particles.
",http://arxiv.org/pdf/cond-mat/9705189v1,2,"7
9
9
1

y
a
M
9
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
9
8
1
5
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

NUCLEATION THEORY OF MAGNETIZATION SWITCHING
IN NANOSCALE FERROMAGNETS

PER ARNE RIKVOLD1,2,3, M.A. NOVOTNY2 AND M. KOLESIK2
1Center for Materials Research and Technology, 2Supercomputer
Computations Research Institute, and 3Department of Physics
Florida State University
Tallahassee, FL 32306-3016, USA

AND

HOWARD L. RICHARDS
Max-Planck-Institut f¨ur Polymerforschung
D-55128 Mainz, Germany

Abstract. A nucleation picture of magnetization switching in single-domain
ferromagnetic nanoparticles with high local anisotropy is discussed. Rele-
vant aspects of nucleation theory are presented, stressing the eﬀects of the
particle size on the switching dynamics. The theory is illustrated by Monte
Carlo simulations and compared with experiments on single particles.

1. Introduction

The dynamics of magnetization switching in nanometer-sized particles of
highly anisotropic ferromagnets is interesting, from both the scientiﬁc and
technological points of view. The basic scientist sees in such particles a lab-
oratory to study the decay of a metastable phase towards equilibrium, while
the technologist sees a promising material for ultrahigh-density magnetic
recording media. Although ferromagnetic nanoparticles have been studied
experimentally for a long time [1], until recently this was only possible
with powders. However, with modern techniques of nanofabrication [2] and
ultrahigh-resolution methods to detect the magnetization, such as Magnetic
Force Microscopy (MFM) [3] Lorentz microscopy [4] and micro-SQUID de-
vices [5], one can now synthesize and study such particles individually.

 
 
 
 
 
 
2

The most common description of magnetization switching is a mean-
ﬁeld approach, originally due to N´eel [6] and Brown [7]. To avoid an energy
barrier due to exchange interactions of strength J, uniform rotation of all
the atomic moments in the particle is assumed. The remaining energy bar-
rier, ∆, is caused by magnetic anisotropy, which is a combination of crystal-
ﬁeld and magnetostatic eﬀects. The equilibrium thickness of a wall between
J/∆. For particles smaller than ξ,
oppositely magnetized domains is ξ ∝
the uniform-rotation picture is reasonable. If the anisotropy is largely mag-
netostatic, the resulting demagnetizing ﬁeld causes particles larger than ξ
to form oppositely magnetized domains, and switching is achieved through
the ﬁeld-driven motion of preexisting domain walls. However, if the an-
isotropy is largely due to the local crystalline environment, there exists a
window of particle sizes that are larger than ξ but smaller than the size
at which the particle becomes multidomain. [This is for instance often the
case in ultrathin ﬁlms.] Such particles can be modeled as Ising systems with
local spin variables, si = ±1. Depending on the degree of anisotropy, these
spins can either represent the z component of individual atomic moments,
or one can coarse grain the system by rescaling all lengths in terms of ξ, so
that the si represent block spins. The Ising Hamiltonian is

p

H0 = −J

sisj − H

si .

(1)

Xhi,ji

Xi

Here J > 0 is the ferromagnetic exchange interaction, H is the applied
hi,ji and
magnetic ﬁeld times the local magnetic moment, and the sums
i run over all nearest-neighbor pairs and all sites on a suitable lattice, re-
spectively. Here we only report numerical results for two-dimensional square
P
lattices, but our theoretical arguments are valid for general spatial dimen-
sion. The order parameter is the dimensionless magnetization,

P

m = N −1

si ,

i
X

(2)

where N is the total number of Ising spins in the particle.

In the highly anisotropic nanoscale ferromagnets described by Eq. (1)
[and modiﬁcations discussed below], the state of uniform magnetization op-
posite to the applied ﬁeld is properly viewed as a metastable phase. This
nonequilibrium phase decays by neither uniform rotation nor by the motion
of preexisting domain walls, but rather by the thermal nucleation and sub-
sequent growth of localized droplets, inside which the magnetization is par-
allel with the ﬁeld [8]. This decay mechanism yields results very similar to
eﬀects observed in recent experiments on well-characterized single-domain
ferromagnets in the nanometer range. In this paper we concentrate on a
maximum in the switching ﬁeld (or coercivity) vs. particle size [3]. Another

3

quantity which is often measured in experiments, is the probability that
the particle has not switched within a speciﬁed waiting time [4, 5]. Results
concerning this quantity can be found in Refs. [8] and [9].

The Ising model does not have an intrinsic dynamic. To simulate the
eﬀects of thermal ﬂuctuations we therefore use a local stochastic dynamic
which does not conserve the order parameter, such as the ones proposed by
Metropolis et al. [10] or Glauber [11]. In order to perform simulations on
the very long timescales necessary to observe metastable decay, we use a
so-called “rejection-free” Monte Carlo (MC) algorithm [12]. The basic time
scale of the MC simulation [MC Steps per Spin (MCSS)] is not known from
ﬁrst principles and must be ﬁtted to experiments. It is expected to be on
the order of a typical inverse phonon frequency, 10−9–10−13 s.

2. Nucleation and Growth

This section is a brief primer on the theory of nucleation and growth as it
applies to systems in the dynamic universality class of kinetic Ising models
with nonconserved order parameter. For further details, see Refs. [8, 13, 14,
15, 16].

2.1. BACKGROUND

The central problems in nucleation theory are to identify the ﬂuctuations
that lead to the decay of the metastable phase and to obtain their free-
energy cost, relative to the metastable phase. For Ising-like systems with
short-range interactions, these ﬂuctuations are compact droplets of radius
R. The magnetization inside the droplet is parallel with the applied ﬁeld and
has a magnitude near the temperature dependent zero-ﬁeld magnetization,
msp(T ), which is nonzero below the critical temperature, Tc. The free energy
of the droplet has two competing terms: a positive surface term ∝ Rd−1,
and a negative bulk term ∝ |H|Rd, where d is the spatial dimension. The
competition between these terms yields a critical droplet radius,

Rc(H, T ) =

(d − 1)σ(T )
2|H|msp(T )

,

(3)

where σ(T ) is the surface tension. Droplets with R < Rc most likely decay,
whereas droplets with R > Rc most likely grow further to complete the
switching process. The free-energy cost of the critical droplet (R = Rc) is

∆FSD(H, T ) = Ωdσ(T )d

d−1
2|H|msp(T ) !

d−1

,

(4)

where Ωd is a weakly T dependent shape factor such that the volume of
a droplet of radius R equals ΩdRd. The subscript SD stands for Single

 
4

Droplet, as explained below. Nucleation is a stochastic process, and the
nucleation rate per unit volume is given by a Van’t Hoﬀ-Arrhenius relation:

I(H, T ) ∝ |H|K exp

−

(cid:20)

∆FSD(H, T )
kBT

(cid:21)

≡ |H|K exp

−

(cid:20)

Ξ(T )
kBT |H|d−1

(cid:21)

,

(5)

where kB is Boltzmann’s constant, and Ξ(T ) is the H-independent part of
∆FSD. The prefactor exponent K equals 3 for the two-dimensional Ising
model and −1/3 for the three-dimensional Ising model [16, 17, 18].

2.2. EFFECTS OF FINITE PARTICLE SIZE

For particles of ﬁnite linear size, L, an important crossover occurs for combi-
nations of H, T , and L, such that Rc ≈ L. This yields a T and L dependent
crossover ﬁeld called the Thermodynamic Spinodal (ThSp) [15, 16]:

HThSp(T, L) ≈

(d − 1)σ(T )
2msp(T )L

.

(6)

For |H| < HThSp, Rc would exceed L. This is called the Coexistence
(CE) regime because the critical ﬂuctuation in such weak ﬁelds resem-
bles two coexisting slabs of opposite magnetization [15, 16]. The average
metastable lifetime in the CE regime is approximately

τCE(H, T, L) ∼ exp

2σ(T )Ld−1 − 2Amsp(T )|H|Ld
kBT

""

,

#

(7)

where A is a nonuniversal constant. Since |H| ≤ HThSp ∼ L−1, the domi-
nant size dependence is an exponential increase with Ld−1. This behavior
also holds for more general boundary conditions than the periodic boundary
conditions used to obtain Eq. (7) [14].

For |H| > HThSp (but not too large, as we shall see below), the lifetime

is dominated by the inverse of the total nucleation rate,

τSD(H, T, L) ≈

LdI(H, T )
(cid:17)
(cid:16)

−1

∝ L−d|H|K exp

Ξ(T )
kBT |H|d−1

(cid:20)

(cid:21)

.

(8)

It is inversely proportional to the particle volume, Ld. The subscript SD
stands for Single Droplet and indicates that in this regime the switching is
completed by the ﬁrst droplet whose radius exceeds Rc.

A second crossover, called the Dynamic Spinodal (DSp) [15, 16], is pre-
dicted when one observes that a supercritical droplet grows at a ﬁnite
velocity, which for large droplets is proportional to the ﬁeld: v ≈ ν|H|. A
reasonable criterion to locate the DSp is that the average time between

nucleation events, τSD, should equal the time it takes a droplet to grow to
a size comparable to L. This leads to the asymptotic relation

HDSp(T, L) ∼

(d − 1)
2msp(T ) ""

Ωdσ(T )d
(d + 1)kBT ln L #

1
d−1

.

(9)

5

For |H| > HDSp, the metastable phase decays through many droplets
which nucleate and grow independently in diﬀerent parts of the system.
This is called the Multidroplet (MD) regime [15, 16]. A classical theory
of metastable decay in large systems [19, 20, 21] gives the lifetime in this
regime,

τMD(H, T ) ≈

I(H, T )Ωd(ν|H|)d
(d + 1) ln 2

""

#

− 1
d+1

,

(10)

which is independent of L.

The switching ﬁeld, Hsw(tw, T, L), is the ﬁeld required to observe a
speciﬁed average lifetime, tw. It is found by solving Eqs. (7), (8), and (10)
for H with tw for the respective average lifetimes, τCE, etc. The resulting
L dependence of Hsw is illustrated by the MC data shown in Fig. 1(a).
It consists of a steep increase with L in the CE regime, peaking at the
ThSp, followed by a decrease in the SD regime towards a plateau in the
MD regime.

3. Numerical Results

In this section we present some representative results of simulations of
two-dimensional Ising ferromagnets, which we compare with the theoretical
predictions of the previous section and with experiments.

3.1. PURE SYSTEM WITH PERIODIC BOUNDARY CONDITIONS

The simplest model considered is a two-dimensional square-lattice Ising
system with periodic boundary conditions. The switching ﬁelds for this
model at T = 0.8 Tc are shown in Fig. 1(a) for tw = 100 and 1000 MCSS.
The L and tw dependencies expected from the results of Sec. 2.2 are clearly
seen. We emphasize that the decrease in the SD region is not due to an
equilibrium domain structure. It is an entropy eﬀect of purely dynamical
origin, arising from the volume factor in Eq. (8) [14]. Analogous corrections
to nucleation rates in ﬂuids were proposed by Lothe and Pound [22].

For qualitative comparison we show in Fig. 1(b) eﬀective switching ﬁelds
for nanoscale Ba-ferrite particles, obtained by MFM experiments [3]. We
propose that the peak observed in the switching ﬁeld may be of the same
purely dynamical origin as in kinetic Ising models.

6

Figure 1.
Switching ﬁelds vs. particle size. (a): MC simulations for a two-dimensional
Ising ferromagnet with periodic boundary conditions. The dotted line is the ThSp, and
the dashed line is the DSp. After Ref. [8]. (b): Eﬀective switching ﬁelds for nanoscale
Ba-ferrite particles. Data digitized from Fig. 5 of Ref. [3].

3.2. EFFECTS OF A DEMAGNETIZING FIELD

A reasonable objection to the model deﬁned by Eq. (1) is the absence of
dipolar interactions, which causes it to be single domain for all L. To address
this shortcoming without the large computational expense of recalculating
dipole sums at every step in the dynamical simulation, a model was in-
troduced in which the demagnetizing ﬁeld was approximated by adding a
weak long-range antiferromagnetic term: HD = H0 + DLdm2 [13]. Particles
smaller than LD ≈ 2σ(T )/D remain single domain [23], but the demagne-
tizing factor D decreases the free-energy barrier towards nucleation of the
equilibrium phase. Addition of the demagnetizing factor was found to re-
duce the average lifetime by an analytically predictable amount, as shown
in Fig. 2. However, no qualitative diﬀerences from the behavior described
above were observed.

3.3. HETEROGENEOUS NUCLEATION

Next we discuss ways in which the homogeneous nucleation observed in pure
systems with periodic boundary conditions is modiﬁed by heterogeneous
nucleation at the particle surface or at quenched inhomogeneities.

3.3.1. Modiﬁed Boundary Conditions
The use of periodic boundary conditions allows one to study bulk nucleation
without complications due to the particle surface. Since the surface can be
modiﬁed in various ways by reconstruction, adsorption, oxidation, etc., one
cannot in general predict whether it will enhance or inhibit nucleation.
However, even addition to the Ising model of a surface ﬁeld or modiﬁed ex-
change interactions at the surface produces complicated crossovers between

7

 (a) 

Figure 2. Relative changes in the average metastable lifetime versus the reduced demag-
netizing factor, x = 2Dmsp(T )/|H|, at T = 0.8Tc. The solid curves are analytical results
that only require parameters determined for D = 0. After Ref. [13]. (a): SD regime,
|H| = 0.2J, L = 10. (b): MD regime, L = 100.

surface and bulk nucleation [14]. In general, the changes reduce the height
of the peak in Hsw vs. L, but for a wide range of modiﬁcations it remains
clearly discernible. Examples are shown in Fig. 3(a).

3.3.2. Quenched Randomness
Another way in which heterogeneous nucleation may dominate, is through
quenched impurities. An exploratory study was presented in Ref. [24]. Bond
dilution was observed to reduce Hsw by a factor approximately independent
of L, as shown in Fig. 3(b), while random spin magnitudes led to non-self-
averaging behavior and a wide distribution of lifetimes.

3.3.3. Coercivity of Fe Sesquilayers on W(110)
Much interest has recently been devoted to ultrathin iron ﬁlms on W(110)
substrates [25, 26, 27, 28, 29]. The so-called sesquilayer systems, which
consist of islands of a second monolayer of Fe on top of an almost perfect
ﬁrst monolayer [27], have particularly interesting magnetic properties [28,
29, 30]. Around an Fe coverage of approximately 1.5 monolayers (ML), the
coercivity exceeds that of a monolayer or a bilayer by more than an order
of magnitude [29].

Magnetization switching in this system is expected to occur through
the ﬁeld-driven motion of preexisting domain walls, which are pinned at
the second-layer islands. Based on this picture, the coercivity has been
calculated by micromagnetic methods [28, 29]. However, those calculations
did not consider thermal eﬀects and were also essentially static.

To account for thermal depinning and the dependence of the coercivity
on the frequency of the applied ﬁeld, a two-layer Ising model has been de-
veloped for this system [31]. This is a reasonable approximation since the

8

J
/
W
S
H
d
l
e
i
F
g
n
i
h
c
t
i

w
S

0.3

0.2

0.1

0.0

(a)

J
/
W
S
H
d
l
e
i
F
g
n
i
h
c
t
i

w
S

0.3

0.2

0.1

0.0

(b)

0%

5%

10%

10

100

Linear System Size, L

10

100
Linear System Size, L

Figure 3.
Eﬀects of heterogeneous nucleation on Hsw at T ≈ 0.57 Tc with
tw = 30000 MCSS. For comparison, the top curve in both panels corresponds to ho-
mogeneous nucleation in a pure system with periodic boundary conditions. (a): Eﬀects
of boundary conditions in a pure system. Middle curve: square system with periodic
boundary conditions in one direction and free boundary conditions in the other. Bottom
curve: circular system with free boundary conditions. Data from Ref. [14]. (b): Eﬀects of
random bond dilution in a system with periodic boundary conditions. After Ref. [24].

crystal-ﬁeld anisotropy for Fe monolayers on W(110) is almost two orders
of magnitude larger than for bulk Fe [25]. Simulations were performed on
a computational lattice in which the second-layer island morphology was
reproduced using STM images of real systems [27], and the exchange in-
teractions were chosen to reproduce the experimentally observed critical
temperature of an Fe monolayer, Tc = 230 K [26].

Two simulation snapshots of the magnetic domain wall moving across a
sesquilayer are shown in Figs. 4(a) and (b). The wall moves intermittently,
spending most of its time pinned against the “windward” side of the islands.
Thermally nucleated depinning events are followed by rapid advances to
the next metastable position. The coercivity is estimated from the average
domain-wall velocity. Estimated coercivities for two diﬀerent temperatures
and driving frequencies are shown vs. the Fe coverage in Fig. 4(c). The
experimentally observed nonmonotonic coverage dependence [29] is repro-
duced, as well as the temperature [28] and frequency [30] dependencies. The
model yields an approximately linear dependence of the inverse coercivity
on the logarithm of the frequency, shown in Fig. 4(d). Over a few decades
of frequency, this is hard to distinguish numerically from a power law [30].

4. Conclusions

We have presented a brief overview of a nucleation theory of magnetiza-
tion switching in single-domain ferromagnets in the nanometer range. We
emphasized the dependence of the switching ﬁeld or coercivity on the par-
ticle size and demonstrated that the model is capable of reproducing the

 
 
 
 
9

(a)

(b)

(c)

0.5

0.4

0.3

0.2

0.1

]
a
l
s
e
T
[

y
t
i
v
i
c
r
e
o
c

0.0

0.9

1.1

T=184K,ω
T=184K,103ω
T=132K,ω

1.5

1.3
1.9
coverage [monolayers]

1.7

2.1

]
a
l
s
e
T
/
1
[

C
H
/
1

15

10

5

0

(d)

T=184K

1.56 ML
1.26 ML
1.13 ML

10-1

100

101
ω/ω0

102

103

Figure 4.
Simulations of magnetization switching in Fe sesquilayers on W(110). After
Ref. [31]. (a) and (b): Snapshots of a domain wall propagating across a sesquilayer with
coverage 1.26 ML. The high-contrast region represents the growing equilibrium phase.
The area shown is 654 ˚A × 610 ˚A [109 × 102 computational cells], and the island con-
ﬁguration was digitized from Fig. 1 j) of Ref. [27]. The simulated temperature and ﬁeld
correspond to 132 K and 0.26 T, respectively. The time elapsed between the two snapshots
−6 s. A movie of this simula-
is approximately 1.5×106 MCSS, corresponding to 1.5×10
tion is found at http://www.scri.fsu.edu/∼rikvold. (c): Sesquilayer coercivity vs. Fe
coverage, estimated by extrapolation to weak ﬁelds. The lower curve should be compared
with Fig. 3 of Ref. [29]. (d): The frequency dependence of the estimated coercivity.

experimentally observed maximum in the switching ﬁeld vs. particle size.
Our discussion places the switching dynamics of nanoscale ferromagnets
in the context of metastable decay in ﬁnite systems. This interdisciplinary
ﬁeld is experiencing a renaissance due to new methods of nanofabrication
and observation of individual systems. In addition to magnets, results have
recently been published for systems as diﬀerent as liquid mixtures [32] and
semiconductor nanocrystals [33].

Acknowledgements

Supported in part by Florida State University through the Center for Mate-
rials Research and Technology and the Supercomputer Computations Re-
search Institute (Department of Energy Contract DE-FC05-85ER25000),
and by National Science Foundation Grants DMR-9520325 and DMR-
9315969. Computing resources at the National Energy Research Supercom-

 
 
10

puter Center were provided by the Department of Energy.

References

1. E.F. Kneller and F.E. Luborsky, J. Appl. Phys. 34, 656 (1963).
2. A.D. Kent, T.M. Shaw, S. von Moln´ar, and D.D. Awschalom, Science 262, 1249

(1993).

3. T. Chang, J.-G. Zhu, and J.H. Judy, J. Appl. Phys. 73, 6716 (1993).
4. C. Salling, S. Schultz, I. McFadyen, and M. Ozaki, IEEE Trans. Magn. 27, 5184

(1991).

5. W. Wernsdorfer, et al., Phys. Rev. Lett. 78, 1791 (1997); Phys. Rev. B 55, 11552

6. L. N´eel, Ann. G´eophys. 5, 99 (1949).
7. W.F. Brown, J. Appl. Phys. 30, 130S (1959); Phys. Rev. 130, 1677 (1963).
8. H.L. Richards, S.W. Sides, M.A. Novotny, and P.A. Rikvold, J. Magn. Magn. Mater.

(1997).

150, 37 (1995).

9. M.A. Novotny, M. Kolesik, and P.A. Rikvold, submitted to J. Magn. Magn. Mater.
10. N. Metropolis, A.W. Rosenbluth, M.N. Rosenbluth, A.H. Teller, and E. Teller, J.

Chem. Phys. 21, 1087 (1953).

11. R.J. Glauber, J. Math. Phys. 4, 294 (1963).
12. M.A. Novotny, Comput. Phys. 9, 46 (1995); Phys. Rev. Lett. 74, 1 (1995); erratum

13. H.L. Richards, M.A. Novotny, and P.A. Rikvold, Phys. Rev. B 54, 4113 (1996).
14. H.L. Richards, M. Kolesik, P.-A. Lindg˚ard, P.A. Rikvold, and M.A. Novotny, Phys.

75, 1424 (1995).

Rev. B 55, 11521 (1997).

15. H. Tomita and S. Miyashita, Phys. Rev. B 46, 8886 (1992); P.A. Rikvold, H. Tomita,

S. Miyashita, and S.W. Sides, Phys. Rev. E 49, 5080 (1994).

16. P.A. Rikvold and B.M. Gorman, in Annual Reviews of Computational Physics I,

edited by D. Stauﬀer (World Scientiﬁc, Singapore, 1994), p. 149.

17. J.S. Langer, Ann. Phys. (N.Y.) 41, 108 (1967); Ann. Phys. (N.Y.) 54, 258 (1969).
18. N.J. G¨unther, D.A. Nicole, and D.J. Wallace, J. Phys. A 13, 1755 (1980).
19. A.N. Kolmogorov, Bull. Acad. Sci. USSR, Phys. Ser. 1, 355 (1937).
20. W.A. Johnson and P.A. Mehl, Trans. Am. Inst. Mining and Metallurgical Engineers

135, 416 (1939).

21. M. Avrami, J. Chem. Phys. 7, 1103 (1939); 8, 212 (1940); 9, 177 (1941).
22. J. Lothe and G.M. Pound, J. Chem. Phys. 36, 2080 (1962).
23. C. Kittel, Phys. Rev. 70, 965 (1946).
24. M. Kolesik, H.L. Richards, M.A. Novotny, P.A. Rikvold, and P.-A. Lindg˚ard, J.

Appl. Phys. 81, 5600 (1997).

25. H.J. Elmers and U. Gradmann, Appl. Phys. A 51, 255 (1990).
26. H.J. Elmers, J. Hauschild, H. H¨oche, U. Gradmann, H. Bethge, D. Heuer, and

U. K¨ohler, Phys. Rev. Lett. 73, 898 (1994).

27. H. Bethge, D. Heuer, Ch. Jensen, K. Resh¨oft, and U. K¨ohler, Surf. Sci. 331-333,

878 (1995).

Lett. 77, 2566 (1996).

28. D. Sander, R. Skomski, C. Schmidthals, A. Enders, and J. Kirschner, Phys. Rev.

29. R. Skomski, D. Sander, A. Enders, and J. Kirschner, IEEE Trans. Magn. 32, 4570

(1996).

30. J.H. Suen and J.L. Erskine, Phys. Rev. Lett. 78, 3567 (1997).
31. M. Kolesik, M.A. Novotny, and P.A. Rikvold, in preparation.
32. C. Lalaude, J.P. Delville, S. Buil, and A. Ducasse, Phys. Rev. Lett. 78, 2156 (1997).
33. C.-C. Chen, A.B. Herhold, C.S. Johnson, and A.P. Alivisatos, Science 276, 398

(1997)."
Dispersity-Driven Melting Transition in Two Dimensional Solids,"  We perform extensive simulations of $10^4$ Lennard-Jones particles to study
the effect of particle size dispersity on the thermodynamic stability of
two-dimensional solids. We find a novel phase diagram in the dispersity-density
parameter space. We observe that for large values of the density there is a
threshold value of the size dispersity above which the solid melts to a liquid
along a line of first order phase transitions. For smaller values of density,
our results are consistent with the presence of an intermediate hexatic phase.
Further, these findings support the possibility of a multicritical point in the
dispersity-density parameter space.
",http://arxiv.org/pdf/cond-mat/9705218v1,2,"7
9
9
1

y
a
M
1
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
8
1
2
5
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Dispersity-Driven Melting Transition in Two Dimensional Solids

M. Reza Sadr-Lahijany1, Purusattam Ray2 and H. Eugene Stanley1
1Center for Polymer Studies and Department of Physics, Boston University, Boston, Massachusetts 02215
2The Institute of Mathematical Sciences, CIT Campus, Chennai - 600 113, India
(May 15, 1997)

We perform extensive simulations of 104 Lennard-Jones particles to study the eﬀect of particle
size dispersity on the thermodynamic stability of two-dimensional solids. We ﬁnd a novel phase
diagram in the dispersity-density parameter space. We observe that for large values of the density
there is a threshold value of the size dispersity above which the solid melts to a liquid along a
line of ﬁrst order phase transitions. For smaller values of density, our results are consistent with
the presence of an intermediate hexatic phase. Further, these ﬁndings support the possibility of a
multicritical point in the dispersity-density parameter space.

PACS numbers: 64.70.Dv,64.60.Cn,02.70.Ns,61.20.Ja,05.70.Fh

Recently there has been considerable interest in what
happens to the liquid-solid transition in a system if the
constituent particles are not all identical but have dif-
ferent sizes. The question was ﬁrst raised in the con-
text of colloidal solutions[1], and subsequently addressed
for other systems [2–4]. These studies mainly focused
on the eﬀect of size dispersity ∆ on the P − ρ equa-
tion of state, where P and ρ denote pressure and density.
On increasing ∆ from zero, the density discontinuity at
the transition decreases, eventually vanishing at a critical
value ∆ = ∆c above which there is no liquid-solid density
discontinuity. This remarkable phenomenon— similar to
the eﬀect of temperature T on the conventional liquid-gas
phase transition[5]—occurs in both two and three dimen-
sions, and for various forms of interaction potentials and
size distributions[4].

These seminal studies leave some questions unan-
swered. First, what are the structures of the phases?
Second, can one pass continuously from solid to liq-
uid “around the critical point” at ∆c, just as one can
pass continuously from liquid to gas “around the critical
point” at Tc? A “yes” answer would not be consistent
with the common picture of melting as a ﬁrst order phase
transition (which cannot have a critical point because of
symmetry mismatch of the two phases [6]). A “no” an-
swer would lead to a natural third question: In the ∆ − ρ
parameter space, what is the location and nature of the
phase boundary between crystalline and liquid phases?
The third question has not gone unnoticed—indeed, Ref.
[7] simulates a binary mixture of 108 “soft” disks, and
shows that upon increasing ∆ the crystal undergoes a
transition to an amorphous solid at a threshold disper-
sity ∆th, suggesting that the transition is of ﬁrst order.
Here we address all three questions by simulating a
relatively large system comprised of N = 104 Lennard-
Jones particles of two diﬀerent radii in a square box of
edge L0 with periodic boundary condition. With each
particle i, we associate a size parameter σi, and deﬁne
the distance scale for the interaction between particles i
and j to be σij ≡ σi + σj. We assign to half the par-
ticles the value σi = σ0(1 + ∆), and to the other half

12

6
− (σij /rij)

the value σi = σ0(1 − ∆). If particles i and j are at a
distance rij smaller than a cutoﬀ distance rc, they in-
teract via a “shifted-force Lennard-Jones” potential [8]
i + f (rij ). Here f (rij )
Φij = 4ǫ h(σij /rij)
is a linear function whose coeﬃcients are chosen such
that Φij and its gradient, the force, continuously van-
ish at rij = rc. Since Φij takes its minimum value at
rij = Rij ≡ 21/6 × σij , we consider this equilibrium
distance to be the sum of the radii of the two particles
i and j, Rij = Ri + Rj, so the radius of particle i is
Ri = 21/6 × σi and the average radius is 21/6 × σ0.

We perform molecular dynamics (MD) simulations us-
ing the velocity Verlet integrator method [8]. We record
the results in reduced units in which σ0 is 0.5, and the
Lennard-Jones energy scale ǫ, the particle mass, and
In these units, we
Boltzmann constant are all unity.
choose rc = 2.5 and the length of each MD time step
δt = 0.01. The system is ﬁrst thermalized at T = 1,
using the Berendsen rescaling method [8], for a period
of length τ ; typically τ = (5 × 104)δt. Then we run
the system for an additional period τ as a constant NVE
system (micro-canonical ensemble). We continuously cal-
culate P, T and energy E, and we consider the system to
be in equilibrium only when the ﬂuctuations of all three
quantities are less than 1% of their average values. The
thermalization time τ is chosen to be more than the time
it takes for the system to equilibrate.

N

P

i )/L2

i=1(πR2

We deﬁne the size dispersity to be the ratio of the size
distribution variance to its average [3], which equals ∆
in our model, and we deﬁne ρ ≡
0, the ra-
tio of the total area assigned to the disks to the system
area. For each value of ∆, we start by placing the 104
particles randomly on the sites of a square lattice of edge
L0 ≈ 150; higher density states are obtained by gradu-
ally compressing the system by reducing L0. Typically
the starting density is ρ = 0.7, and we increase ρ to 1.05
through approximately 10 intermediate densities, equili-
brating the system at each[9].

We present our results for the state points with T = 1,
ρ = 0.90 − 1.05 and ∆ = 0 − 0.12. At these densities,

1

 
 
 
 
 
 
the ∆ = 0 system is a 2D-solid with a triangular or-
der, but at large ∆ the system becomes disordered and
a liquid. By probing the translational and orientational
order, we determine the phase of each state point and we
locate the transition between the two phases. To study
translational order, we calculate the total pair correla-
tion function g(r), as well as the partial functions g11(r),
g22(r) and g12(r) [8]. Here g(r) is the probability dis-
tribution of ﬁnding two particles at a distance r, and
gij(r) is the same for an (i, j) pair (i = 1 stands for
small and i = 2 for large particles). We ﬁnd that all
three gij(r) display behavior similar to g(r), indicating
that the system maintains its substitutionally-disordered
conﬁguration and does not tend toward de-mixing.

In Fig. 1(a) we show the eﬀect of tuning ∆ on transla-
tional order. We observe that the monodisperse (∆ = 0)
system shows the quasi-long-range translational order ex-
pected for a 2D-solid[10], characterized by a power-law
decay of the envelope of g(r) and the persistence of the
solid structure periodicity up to very large distances. For
∆ < ∆th(ρ), where ∆th(ρ) is the threshold value at ﬁxed
ρ, the solid maintains this quasi-long-range order, al-
though the decay exponent appears to increase somewhat
with ∆. For ∆ > ∆th(ρ), we observe a qualitative change
in the structure: the quasi-long-range translational order
disappears, and is replaced by an exponential decay of
the envelope of g(r), which at very long distances shows
the uniform distribution of a structureless liquid. We ob-
serve this behavior for all densities between ρ = 0.96 and
ρ = 1.05, and ﬁnd that 0.09 < ∆th(ρ) < 0.10 for all ρ.

Next we study the local bond orientational order by
calculating for each particle j the sixfold orientational
order parameter[11]

(ψ)j ≡

1
z

z

X
k=0

ei6θjk .

(1)

The sum runs over all z nearest neighbors k of j, and θjk
is the angle of the bond joining particles j and k with
respect to a ﬁxed axis. We identify the nearest neigh-
bors as the particles that are closer than the location of
the ﬁrst minimum of g(r). The modulus of (ψ)j will be
unity if the neighbors form a perfect hexagon around j,
which occurs for all particles in a triangular lattice, the
close-packed conﬁguration of a 2D-solid. For a distorted
hexagon or a diﬀerent polygon, |(ψ)j| < 1— e.g.
for a
liquid, the distribution of |(ψ)j | centers around 0.5 [12].
We deﬁne the continuous order parameter ﬁeld ψ(r) as
the value of (ψ)j if the position of particle j is rj = r, and
we calculate the orientational correlation function[13]
g6(|r − r0|) ≡ hψ(r)ψ(r0)i,

(2)
where h...i denotes an average over r, r0 and time.
Fig. 1(b) shows that if ∆ is small and ρ is large, the sys-
tem displays the long-range orientational order of a solid
in that limr→∞ g6(r) 6= 0. Noteworthy is that for each
value of ρ, orientational order disappears upon a small in-
crease in dispersity near ∆th(ρ). For ∆ > ∆th(ρ), g6(r)

appears to decay exponentially, which identiﬁes the sys-
tem as a liquid. Similar plots for other large values of
ρ suggest that near ρ = 1.0, there is a ﬁrst order phase
transition from solid to liquid, driven by an increase in
∆. This observation is in agreement with the results of
Ref. [7]. Fig. 1 shows that the small dispersity system has
the ordered structure of a solid while the large dispersity
system has the disordered structure of a liquid—providing
an answer to the ﬁrst of the three questions.

Since identifying phases relies on the behavior of the
system in the thermodynamic limit, we apply ﬁnite size
scaling to the moments of the orientational order param-
eter ψ, which is the average value of ψ(r). We use stan-
dard techniques originally developed for the Ising model
[14], and recently applied to the 2D melting transition
In order to calculate the moments of ψ at a
[15, 16].
scale b ≡ L0/M , we divide the system into M 2 blocks of
edge b and we deﬁne ψb for each block as the absolute
value of the average of ψ(r) over the block. Then we ﬁnd
the moments of ψb by averaging over all blocks and all
conﬁgurations of the system after equilibration[15].

To explore the precise location of the phase transition,

we calculate the cumulant [15]

Ub ≡ 1 −

hψ4
b i
b i2 .
3hψ2

(3)

For a completely ordered (solid) system, Ub = 2/3 in the
thermodynamic limit, while for a disordered (liquid) sys-
tem Ub → 0. For an inﬁnite system, Ub jumps between
these two limiting values at the phase transition point
and for ﬁnite systems, this jump becomes rounded. Still,
one can determine the location of a phase transition by
ﬁnding the point at which the Ub curves for diﬀerent sys-
tem sizes intersect [15]. In Fig. 2, we plot Ub versus ∆,
for diﬀerent scales b at a ﬁxed ρ. We ﬁnd the transition
from the value 2/3 to lower values upon passing through
the phase transition. Moreover, we estimate ∆th(ρ) from
the crossing point of the curves. In the phase diagram
of Fig. 3, the line Lth is the locus of all such threshold
points separating solid and liquid phases and shows that
for ρ > 0.96, ∆th(ρ) ≈ 0.097 is essentially independent
of ρ.

Next we study the ﬁnite size scaling of hψ2

b i. Because
of the qualitative diﬀerence in the form of g6(r) between
solid and liquid, the behavior of hψ2
b i as a function of
In the liquid
b changes drastically upon melting [16].
for b ≫ ξ, where ξ is the correlation length, hψ2
b i de-
cays as b−2, while for the solid, hψ2
b i remains constant.
Fig. 4(a) shows that for ρ = 1.0, the behavior of the
system changes abruptly from solid (given by the line
with zero slope) to liquid at ∆th, which is consistent
with our previous studies of g(r), g6(r) and Ub. The
∆ = 0.10 liquid curve shows long-range correlation for
b < ξ, which crosses over to short-range correlation (slope
−2) for b ≫ ξ (ξ ≈ 0.6L0 for this curve). The correspond-
ing plots for larger ∆ show that ξ shrinks upon increasing

2

∆. For ρ = 0.9 (Fig. 4(b)), we observe both solid behav-
ior for ∆ < 0.06 and liquid behavior for ∆ > 0.06. For
∆ = 0.06, Fig. 4(b) shows an algebraic decay for the cor-
relation function, with exponent −1/4. This “intermedi-
ate” behavior is reminiscent of the hexatic phase[16], for
which the orientational correlation decays algebraically
while the system does not possess quasi-long-range trans-
lational order. In Fig. 3 we have speciﬁed as the I phase
the locus of the points showing this intermediate behav-
ior.

In summary, we have studied a melting transition
driven not by T but by ∆. We have simulated rela-
tively large systems and applied ﬁnite size scaling (Figs 2,
4) arriving at a phase diagram for this dispersity-driven
melting (Fig. 3). Melting takes place from a 2D or-
dered phase to a disordered liquid phase, similar to
the conventional temperature-driven melting processes.
Moreover, at large values of ρ, melting is a ﬁrst order
phase transition at a threshold dispersity value ∆th(ρ) =
0.097±0.005. Our study of the mean square displacement
of the particles shows that this melting is accompanied
by a transition from a frozen solid to a diﬀusive liquid,
distinguishing it from the glass transition observed in [7].
The threshold line Lth extends almost horizontally down
to the point C with coordinates ∆c ≈ 0.097, ρc ≈ 0.96.
Below ρc, ﬁnite size scaling of the orientational order pa-
rameter suggests the existence of an intermediate “hex-
atic” phase between the solid and liquid phases. Thus
we hypothesize that point C is a multicritical point,
where two lines of continuous transitions (separating
liquid/“hexatic” and “hexatic”/solid phases) meet the
line of ﬁrst order transitions Lth (separating liquid/solid
phases) as shown in Fig. 3[17]. Fig. 3 provides an an-
swer to the last two of the three questions: one can not
pass continuously from solid to liquid “around the crit-
ical point” C, because the two phases are separated by
the line of ﬁrst order phase transitions Lth. A similar
horizontal line of order-disorder transition has been ob-
served in the study of the eﬀect of quenched impurities
on the structure of 2D-solids [18].

We thank N. Ito for generously introducing us to this
topic, S. T. Harrington for signiﬁcant assistance in the
formative stages of this research, J. L. Barrat for bring-
ing Ref.[7] to our attention, L. A. N. Amaral, N. Clark,
W. Kob, B. Kutnjak-Urbanc and D. R. Nelson for ex-
tremely helpful criticism, NSF for ﬁnancial support and
the Boston University Center for Computational Science
for computational resources.

[1] E. Dickinson, Chem. Phys. Lett. 57, 148 (1978); J. Chem.
Soc. Faraday II 75, 466 (1979); E. Dickinson and R.
Parker, Chem. Phys. Lett. 79, 578 (1981); E. Dickinson,
J. Phys. Lett. (France) 46, L29 (1985).

3

[2] J. L. Barrat and J. P. Hansen, J. Phys. (France) 47, 1547

(1986).

[3] P. N. Pusey, J. Physique 48, 709 (1987).
[4] W. Verm¨ohlen and N. Ito, Phys. Rev. E 51, 4325 (1995);

N. Ito, Int. J. Mod. Phys. C7, 275 (1996).

[5] Note that ∆ is not a thermodynamic control parame-
ter like T , but is a geometric parameter which changes
the interaction Hamiltonian. In this respect, ∆ is sim-
ilar to bond or site concentration in a diluted Ising
model, which modiﬁes the phase diagram and changes
the position of the phase transition (see e.g. A. Coniglio,
Phys. Rev. Lett. 46, 250 (1981)).

[6] L. D. Landau and E. M. Lifshitz, Statistical Physics,
Translated by J. B. Sykes and M. J. Kearsley, 3rd ed.
(Pergamon Press, 1980); H. E. Stanley, Introduction to
Phase Transitions and Critical Phenomena (Oxford Uni-
versity Press, New York, 1971).

[7] L. Bocquet, J. P. Hansen, T. Biben and P. Madden, J.

Phys. Cond. Matt. 4, 2375 (1992).

[8] M. P. Allen and D. J. Tildesley, Computer Simulation of
Liquids (Oxford University Press, New York, 1989).
[9] The average simulation speed on Boston University’s SGI
power challenge array is 50µs per particle update, so each
of the 70 state points studied here requires 16 hours on
one processor (over 103 hours total computational time).
[10] D. R. Nelson, in Phase Transitions and Critical Phenom-
ena, Vol. 7, edited by C. Domb and J. L. Lebowitz (Aca-
demic, London, 1983).

[11] D. R. Nelson and B. I. Halperin, Phys. Rev. B 21, 5312

(1980).

[12] M. A. Glaser and N. A. Clark, in Geometry and Ther-
modynamics, edited by J. C. Tol´edano (Plenum Press,
New York, 1990), p. 193; M. A. Glaser, N. A. Clark, A.
J. Armstrong and P.D. Beale, in Dynamics and Patterns
in Complex Fluids, edited by A. Onuki and K. Kawasaki
(Springer-Verlag, Berlin, 1990), p. 141.

[13] D. Frenkel and J. P. McTague, Phys. Rev. Lett. 42, 1632
(1979); J. P. McTague, D. Frenkel and M. P. Allen, in Or-
dering in Two Dimensions, edited by S. K. Sinha (North-
Holland, New York, 1980), p. 147.
[14] K. Binder, Z. Phys. B 43, 119 (1981).
[15] H. Weber, D. Marx and K. Binder, Phys. Rev. B 51,

14636 (1995).

[16] K. Bagchi, H. C. Andersen and W. Swope, Phys. Rev.
Lett. 76, 255 (1996); Phys. Rev. E 53, 3794 (1996).
[17] A similar phase diagram has been observed for the con-
ventional (temperature-driven) melting transition of dis-
location vector systems, in which the nature of the tran-
sition depends on the core energy Ec of the dislocations.
These studies show that at large Ec, melting takes place
through the formation of the hexatic phase, whereas for
small Ec the transition is predominantly ﬁrst order. The
resulting phase diagram in the T − Ec parameter space
is similar to our phase diagram in the ∆ − ρ parameter
space (Fig. 3), with the existence of a multicritical point
at the junction of the liquid, hexatic and solid phases.
[Y. Saito, Phys. Rev. Lett. 48, 1114 (1982); Phys. Rev
B26, 6239 (1982)].

[18] D. R. Nelson, Phys. Rev. B 27, 2902 (1983); M.-C. Cha
and H. A. Fertig, Phys. Rev. Lett. 74, 4867 (1995).

LIQUID

c

Lth

∆

0.10

0.05

I

SOLID

0.00

0.85

0.90

1.00

1.05

0.95
ρ
FIG. 3. Phase diagram in the ∆ − ρ (dispersity-density)
parameter space. Squares represent solid points and circles
liquid points. The threshold line Lth connects crosses, which
are the ﬁrst order phase transition points derived from the
cumulant analysis. The triangles are the points of the inter-
mediate (I) phase, showing a hexatic behavior. The large
diamond marks the multicritical point C.

4

)
>
2

0

L

Ψ
<
>
2

/

2

∆=0.10

b

Ψ
<
(
n

l

∆<0.10

0

(a) ρ=1.0

(b) ρ=0.9

∆=0.10

∆=0.07

∆=0.06

∆<0.06

0

0

−2

−2

−1
ln(b/L0)
FIG. 4. Log-log plots of hψ2

−1
ln(b/L0)
b i versus b for diﬀerent disper-
sities ∆. Both axes are normalized by their values at system
size L0, which causes the curves to meet at the origin and fa-
cilitates comparing their asymptotic slopes. Dashed lines con-
necting the data points are guides to the eye. Solid straight
lines are reference lines with slopes −2 and −1/4.
(a) For
ρ = 1.0 there is an abrupt change from asymptotic slope of
0 (data lying on the abscissa) to −2, which corresponds to a
solid-liquid transition on increasing the dispersity above ∆th.
(b) For ρ = 0.9, the ∆ = 0.06 curve falls between the solid
and liquid regimes, and shows a slope of −1/4 characteristic
of the hexatic phase.

3.5

2.5

)
r
(
g

1.5

0.5

0

1.0

)
r
(
g
/
)
r
(

6
g

0.5

∆=0.00

∆=0.06

∆=0.09

∆=0.10

40

0.0

0

(a)

20
r

(b)

∆=0.00

∆=0.06

∆=0.09

∆=0.10

20
r

40

FIG. 1. Eﬀect of dispersity ∆ on translational and orien-
tational order at ρ = 1.0. (a)Total pair correlation function
g(r) as a function of distance r. All curves oscillate around the
value g(r) = 1, so we have separated them to facilitate com-
parison. We ﬁnd that a transition from solid to liquid struc-
ture occurs on increasing the dispersity between ∆ = 0.09 and
∆ = 0.10. (b) Normalized orientational correlation function
versus r. The change between ∆ = 0.09 and ∆ = 0.10 cor-
responds to the transition from an orientationally long-range
correlated solid to a short-range correlated liquid. Both sets
of curves show that for ρ = 1.0 the solid-liquid transition oc-
curs at a value of dispersity between 0.09 and 0.10 which is
consistent with the observations based on Figs. 2 − 4.

Ub

0.6

0.5

ρ=1.0

M=6
13
28
63

0.4

0.00

0.05

∆

∆

th

0.10

FIG. 2. Cumulant Ub of the bond orientational order pa-
rameter ψ as a function of dispersity ∆ for ρ = 1.0. Diﬀerent
curves correspond to diﬀerent scales b, where b ≡ L0/M is
the block size, so smaller M corresponds to larger scale. The
dotted lines connecting the data points are guides to the eye.
We identify the threshold value of ∆ to be the point where
all the curves for diﬀerent scales intersect.

4"
Interplay between kinetic roughening and phase ordering,"  We studied interplay between kinetic roughening and phase ordering in 1+1
dimensional single-step solid-on-solid growth model with two kinds of particles
and Ising-like interaction. Evolution of both geometrical and compositional
properties was investigated by Monte Carlo simulations for various strengths of
coupling. We found that the initial growth is strongly affected by interaction
between species, scaling exponents are enhanced and the ordering on the surface
is observed. However, after certain time, ordering along the surface stops and
the scaling exponents cross over to exponents of the Kardar-Parisi-Zhang
universality class. For sufficiently strong strength of coupling, ordering in
vertical direction is present and leads to columnar structure persisting for a
long time.
",http://arxiv.org/pdf/cond-mat/9706034v1,2,"7
9
9
1

n
u
J

4

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
4
3
0
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

EUROPHYSICS LETTERS
Europhys. Lett., ?? (?), pp. 1-∞ (1997)

1 ? 1997

Interplay between kinetic roughening and phase ordering

Miroslav Kotrla1 and Milan Pˇredota2
1Institute of Physics, Academy of Sciences of the Czech Republic,
Na Slovance 2, 180 40 Praha 8, Czech Republic
2Institute of Chemical Process Fundamentals, Academy of Sciences of the Czech Republic,
165 02 Praha 6, Czech Republic

(received ; accepted )

PACS. 05.70L – Nonequilibrium thermodynamics, irreversible processes.
PACS. 75.70Kw – Domain structure.
PACS. 75.40M – Numerical simulation studies.

Abstract. – We studied interplay between kinetic roughening and phase ordering in 1+1
dimensional single-step solid-on-solid growth model with two kinds of particles and Ising-like
interaction. Evolution of both geometrical and compositional properties was investigated by
Monte Carlo simulations for various strengths of coupling. We found that the initial growth
is strongly aﬀected by interaction between species, scaling exponents are enhanced and the
ordering on the surface is observed. However, after certain time, ordering along the surface
stops and the scaling exponents cross over to exponents of the Kardar-Parisi-Zhang universality
class. For suﬃciently strong strength of coupling, ordering in vertical direction is present and
leads to columnar structure persisting for a long time.

Recently there has been considerable interest in growth induced surface rough-
ening called kinetic roughening [1] and in phase ordering [2] independently.
In kinetic roughening one is interested in the evolution of roughness during
a nonequilibrium growth process. Phase ordering deals with the approach to
equilibrium of a system quenched from a homogeneous high temperature phase
into a two-component region. In both ﬁelds concept of scaling allowed to classify
physical processes into universality classes. However, not very much is known
so far about scaling exponents in systems where both processes, roughening as
well as ordering, are relevant.

Growth of many-component systems is in fact quite common situation. Many
real materials are composed of two or more components but often the dynamics of
one component is dominant and one can use a single-component growth model.
For example, one can consider only kinetics of Ga atoms in studies of GaAs
growth [3]. We are interested here in a more complex case when dynamics of
Typeset using EURO-LaTEX

 
 
 
 
 
 
2

EUROPHYSICS LETTERS

both components is important. It is a problem of practical interest, for example,
microscopic understanding of growth of alloys is desirable [4, 5, 6]. One can study
diﬀerent aspects: kinetics, morphology, scaling behaviour etc. We are not going
to model growth of any speciﬁc material but we shall concentrate on the scaling
behaviour. The problem of growth in a system with two or more components
is interesting from pure statistical-mechanical point of view, because growth
process may belong to a new universality class [7, 8, 9]; such system might also
exhibit a nonequilibrium phase transition between the low and high temperature
region.

2

Let us consider a surface in a d-dimensional space given by a single valued
function h(r, t) of a d′-dimensional (d=d′+1) substrate coordinate r. The surface
roughness is described by the surface width w(t, L) = hqh2 − h
i, where t is
the time, L is the linear system size and the bar denotes a spatial average,
h...i a statistical average. The surface roughness often obeys dynamical scaling
law w(t, L)∝Lζf (t/Lz) where the scaling function f (x) has properties: f (x)=
const., x≫1 and f (x)∝xβ, x≪1 (β=ζ/z). The exponents ζ and z (or ζ and
β) characterize scaling behaviour of the surface width in a particular model and
determine its universality class [1]. This universal behaviour has been observed in
a wide variety of growth models and there has been considerable eﬀort in ﬁnding
diﬀerent possible universality classes. Many of the growth models studied so far
(for example ballistic deposition, Eden model, restricted solid-on-solid model,
etc.) belong to the Kardar-Parisi-Zhang (KPZ) universality class [10].

There is a large menagerie of single-component growth models which can
be potentially generalized to heterogeneous case. Moreover, there are diﬀerent
possible ways of generalization. Nevertheless, little is known so far about kinetic
roughening in two-component growth models. This problem was probably ﬁrst
considered by Ausloos et al. [7]. They introduced a generalization of the Eden
model coined as magnetic Eden model (MEM), which contains two types of
particles with probabilities of growth given by Ising-like interaction. Ausloos
et al.
found a variety of morphologies, and they also measured the perimeter
growth exponent [7]. They suggested that the model does not belong to the KPZ
universality class. Recently Wang and Cerdeira [8] studied kinetic roughening
in two 1+1 dimensional two-component growth models with varying probability
of deposition of a given particle type. They did not found, however, a new
universal behaviour. Although the phase ordering was apparently present it was
not studied in these works. The characteristic length in phase ordering is a
It increases with time according to a power law, D ∝ tψ, ψ
domain size D.
being one of the exponents specifying a universality class. Phase ordering is
usually a bulk process, but growth induced ordering may be present just on the
surface. Then evolution of the domain size on the surface is of interest. The
scaling in this case has been recently studied by Saito and M¨uller-Krumbhaar
[9] in another generalization of the Eden model (diﬀerent from MEM). They

M. KOTRLA et al.: INTERPLAY BETWEEN KINETIC ETC.

3

obtained ψ = 2/3 for growth of domain size, but they did not investigate kinetic
roughening.

In this Letter we study interplay between kinetic roughening and phase order-
ing. We introduce a new growth model with two types of particles suitable for
the study of scaling and present results of simulations in 1+1 dimensions. Our
model is based on the single-step solid-on-solid (SOS) model, a discrete model
with constraint that the diﬀerence of heights between two neighbouring sites
is restricted to +1 or −1 only. Advantage of this choice is that in contrast to
cluster geometry, kinetic roughening can be more easily studied and that the
single-step constraint allows simple interpretation of the deposition process in
a binary system. We consider two types of particles, and denote the type of
a particle by a variable σ which assumes values +1 or −1 (not to be confused
with the step size). It is convenient to use an analogy with magnetic systems
and to consider σ as a spin variable. We shall use this terminology in the
following, but it should be warned that in the context of crystal growth this may
be misleading because magnetic interactions of atoms are rather weak and do
not usually control the growth process. One should rather think in terms of two
types of particles with diﬀerent bonding energies in this case. Therefore we shall
call our model two-component single-step (TCSS) model.

We describe our growth model for simplicity in 1+1 dimensions but it can
be straightforwardly generalized to any dimension. Several realization of the
single-step geometry diﬀering by the number of nearest neighbours for a new
particle are possible. Here we consider a variant with three nearest neighbours
which can be represented as stacking of rectangular blocks with the height twice
the width. During growth, particles are only added, there is neither diﬀusion
nor evaporation. Once a position and a type of a particle are selected, they
are ﬁxed forever. Due to the single step constraint, particles can be added
only at sites with a local heigh minimum, called growth sites. The probability
of adding a particle with a spin σ to a growth site i depends only on its
local neighbourhood in a way analogous to rules used in the magnetic Eden
model [7]. It is proportional to exp(−∆E(i, σ)/kBT ), where kB is Boltzmann’s
constant, T , and ∆E(i, σ) denote thermodynamic temperature and change of
energy associated with deposition of a new particle, respectively. The energy
∆E(i, σ) is given by Ising-like interaction of a new particle with particles on
the surface within nearest neighbours of a growth site (which are three in the
selected realization - left, bottom and right). When we denote the spin of a
particle on the top of a column of spins at site i (surface spin) by σ(i) then
∆E(i, σ) = −Jσ [σ(i − 1) + σ(i) + σ(i + 1)] −Hσ. Here J is a coupling strength
and H is an external ﬁeld. In the following we use for convenience dimensionless
constants K = J/kBT and h = H/kBT .

We studied both geometrical and compositional properties. Geometry is de-
scribed by the surface width w(t, L) or by height-height correlation function

4

EUROPHYSICS LETTERS

L

L P

L P

i=1h[h (i + r, t) −h (i, t)]2i. Evolution of geometry is aﬀected by
G (r, t) = 1
composition of the surface and vice versa. Therefore we introduce quantities
characterizing composition on the surface. We concentrate only on ordering on
the surface, we do not study bulk properties here. We consider the average
domain size along the surface D(t), the spin correlation function of surface spins
L
L
i=1hσ(i + r, t)σ(i, t) i, and magnetization M(t) = 1
S(r, t) = 1
i=1hσ(i, t)i.
L P
We performed simulations for various coupling strengths K in both ferromagnetic
(K > 0) and antiferromagnetic (K < 0) regimes, mostly for zero external ﬁeld h.
System sizes ranged from L = 250 to L = 80000, time was up to 3×105 monolay-
ers (ML). Presented results are averages over ten or more independent runs. We
start from the ﬂat surface as usual, but in two-component models the evolution
strongly depends on initial composition of the substrate. We considered various
possibilities (ferromagnetic, antiferromagnetic, random composition) and ﬁnally
we have used growth on a neutral substrate, i.e. a substrate composed of particles
with zero spin, and we let the system to evolve spontaneously in order to avoid
initial transient eﬀects.

Fig. 1 shows examples of time evolution of morphologies obtained for selected
couplings. We can see that with the increasing coupling the surface becomes
more and more rough (facetted) and at the same time larger and larger domains
of the same type of surface particles are formed. Notice also that for the larger
coupling there is correlation between domain walls and changes of the local slope,
and a columnar structure is observed. The time dependence of the surface width
and the average domain size for L = 10000 are shown in Fig. 2 and Fig. 3,
respectively. When the coupling is weak evolution of the roughness is almost
the same as in the ordinary single-step model (β = β(KP Z) = 1/3). For a larger
coupling it can be seen that the average surface width at a given time is an
increasing function of the coupling and that ordering leads to an enhancement
of the exponent βeﬀ. However, after a time tcross, that increases with the coupling
strength, the exponent βeﬀ crosses over back to β(KP Z) = 1/3. To be sure that
this unexpected crossover is not a ﬁnite size eﬀect we performed for K = 1
the calculation for signiﬁcantly larger system size L = 80000 and observed the
same crossover (see inset in Fig. 2). When the coupling is even stronger the
enhanced exponent βeﬀ is observed during the whole simulation; for K = 2 we
have βeﬀ = 0.52 ± 0.02 for times up to 3 × 105 ML.

The crossover can be understood from behaviour of the average domain size.
It increases initially according to a power law D ∝ tψeﬀ , ψeﬀ being an increasing
function of K; ψeﬀ = 0.33 for K = 1.1. However, after a certain time t(D)
sat , D
saturates to Dsat(K). We have checked that when the saturation is observed
it is not a ﬁnite size eﬀect (see inset in Fig. 3), rather an intrinsic property
of the model. For large K the domain size increases during whole simulation,
after some transient eﬀect we observe ψeﬀ = 0.44 for K = 2. The calculation
of the spin-spin correlation function, and the correlation length ξs derived from

M. KOTRLA et al.: INTERPLAY BETWEEN KINETIC ETC.

5

it, leads to similar results: during ordering the correlation length increases as a
power law ξs(t, K) ∝ tκeﬀ ; κeﬀ ≈ 1/2 for K = 2. Then after a time increasing
with the coupling ordering stops, and ξs saturates to ξs
sat ∝ eγK; γ = 3.25 ± 0.08.
Both eﬀects, the crossover in time dependence of roughness and the saturation
of the domain size (correlation length), are apparently related, tcross ≈ t(D)
sat (see
inset in Fig. 2).

To complete the picture we need to know the second exponent for kinetic
roughening, the roughening exponent ζ. We measured it from the spatial depen-
dence of the height-height correlation function G (r, t) at t(w)
sat (not shown here).
The exponent has a value close to ζ (KP Z) = 1
2 for a weak coupling, but for a
larger coupling we have found that there is a crossover behaviour provided the
system is suﬃciently large. We observed that the exponent ζeﬀ is increasing with
the coupling (ζeﬀ = 0.7 for K = 0.7) on distances smaller than the correlation
length ξs, and ζeﬀ crosses over to ζ (KP Z) = 1
2 on a larger distances. If the coupling
is strong we again do not see the crossover but only larger exponent, ζeﬀ ≈ 1
for K = 2, because the simulated system sizes are not large enough to get into
the regime r > ξs. Exponent ζ = 1 is the same as in some models with surface
diﬀusion in which often anomalous scaling is observed [11]. However, this cannot
be the case here since the step size is restricted.

1

sat (K) ∝ e7K, e.g. t(D)

2 with the ﬁt we obtain that t(D)
sat

Our results show that for suﬃciently strong coupling the TCSS model exhibits
an intermediate growth regime with new scaling exponents which we estimate
as β = 1/2, ζ = 1 (z = 2) and ψ = 1/2. However, these exponents are
only eﬀective and there is a crossover to the KPZ exponents for the medium
coupling strengths. We estimated the dependence of t(D)
sat (≈ tcross) on K. We
have found that the saturated domain size as a function of K can be well ﬁtted
in the form Dsat(K) = 1 + 1
2(e3.5K + e0.7K) (see inset in Fig. 3). Comparing
Dsat ∝ (t(D)
is a rapidly increasing function of
sat )
K, t(D)
sat (K = 2) ≈ 106. Due to the progressively increasing
time and system sizes needed for simulation we cannot exclude that there is a
phase transition to a new true asymptotic phase at some value Kc. However,
we expect that the crossover in the roughness is present for any value of K,
but that it is hard to see it for strong coupling because tcross is larger than any
possible simulation time. When K = ∞ then the model becomes trivial: type
of a new particle added to a growth site is dictated by the majority of particle
types in the neighbourhood and evolution of composition is fully determined by
the initial conﬁguration. So far all results were for zero external ﬁeld. Non-zero
ﬁeld leads to nonzero surface (as well as bulk) magnetization, or in the context
of alloy growth to changing stoichiometry. We can still deﬁne the exponent
ψ for growth of the dominant domain size as well as the exponents for kinetic
roughening. Eﬀect of this symmetry breaking on the values of exponents remains
to be studied.

6

EUROPHYSICS LETTERS

One would like to know if the crossover to the KPZ exponents is generic
behaviour or if facetted phase can be present also in the asymptotic regime. We
have also tested a diﬀerent variant of two-component growth, namely the single-
step model which corresponds to stacking of squares rotated by 45 degrees in
which a new particle interacts with only two instead of three nearest neighbours.
We observed the crossover as well, stronger coupling was needed to see enhanced
exponents and for the same coupling the crossover time was smaller than in
the variant with three nearest neighbours. Is is of interest to examine kinetic
roughening and phase ordering in a diﬀerent two-component growth model, in
particular to reexamine the MEM model in the strip geometry since in the
cluster geometry used by Ausloos et al. ﬁnite size eﬀect are expected to be
stronger. Situation in higher dimensions can be investigated by straightforward
generalization. Finally, there is question of continuous description of the two-
component growth.

In conclusion we have generalized the single-step SOS model to two-component
growth model.
It can be considered as a model for growth of binary alloys
from a ﬂuid containing two types of particles, or for growth of a colony of two
kinds of bacteria etc. The introduction of two kinds of interacting particles
leads to new phenomena, like an increase of the roughness with the increasing
coupling strength, larger eﬀective scaling exponents and ordering on the surface
with corresponding pattern formation during growth. However, after a certain
time new behaviour stops and ordinary dynamic behaviour is restored. Hence,
In the ﬁrst, ordering is
growth of a crystal can be divided into two stages.
essential and inﬂuences the evolution of geometric properties.
In the second
stage, after saturation of domain size, the evolution of geometric properties is
similar to that of the ordinary single-step model. Crossover time between two
regimes is independent of system size and is a rapidly increasing function of
coupling so that practically only the ﬁrst regime may be observed. Patterns of
the grown material in saturation regime are similar to lamellar structure observed
in eutectic growth [4]. At the moment, it is not clear why ordering stops and
the characteristic length (given by the saturated domain size) is selected.

***

We thank F. Slanina and N. Vandewalle for useful discussion. This work was

supported by grant No. A 1010513 of the GA AV ˇCR.

REFERENCES

[1] For reviews on kinetic roughening see e.g. Krug J., Adv. Phys., (to be published); Barab´asi
A.-L., and Stanley H. E., Fractal concepts in Surface Growth, (Cambridge University Press,
Cambridge 1995); Halpin-Healy T., and Zhang Y.-C., Phys. Rep., 254 (1995) 215.

[2] Bray A. J., Adv. Phys., 43 (1994) 357.
[3] Shitara T., Vvedensky D. D., Wilby M. R., Zhang J., Neave J. H. and Joyce B. J.,

Phys. Rev. B, 46 (1992) 6815.

M. KOTRLA et al.: INTERPLAY BETWEEN KINETIC ETC.

7

[4] Hunt J. D. and Lu S. -L,, in Handbook of crystal growth, edited by Hurle D. T., Vol. 1

Fundamentals, (North-Holland, Amsterdam) 1994 pp. 1113.

[5] Smith, Jr J. R. and Zangwill A., Phys. Rev. Lett., 76 (1996) 2097.
[6] Tersoff J., Phys. Rev. Lett., 77 (1996) 2017.
[7] Ausloos M., Vandewalle N. and Cloots R., Europhys. Lett., 24 (1993) 629.
[8] Wang W. and Cerdeira H. A., Phys. Rev. E, 52 (1995) 6308.
[9] Saito Y. and M¨uller-Krumbhaar H., Phys. Rev. Lett., 74 (1995) 4325.
[10] Kardar M., Parisi G. and Zhang Y.C., Phys. Rev. Lett., 56 (1986) 889.
[11] Kotrla M. and ˇSmilauer P., Phys. Rev. B, 53 (1996) 13777.

8

EUROPHYSICS LETTERS

Fig. 1. – Examples of evolution of surface proﬁles for several values of coupling strength,
K = 0.3, 0.7, 1.1, 2.0 and zero external ﬁeld. Surface proﬁles at various times increasing
as powers are shown by white lines. Only part of the substrate close to the surface is shown at
given time, black and grey correspond to diﬀerent types of particles. System size is L = 250.

Fig. 2. – Surface width w vs. time t for several values of coupling strength, K = 0.0, 0.3, 0.7,
1.1, 2.0 and zero external ﬁeld, L = 10000. Inset: Comparison of the time dependence of the
surface width and the domain size for K = 1.0 and L = 80000.

Fig. 3. – Time evolution of the surface domain size for coupling strengths K = 0.0, 0.3, 0.7,
1.1, 2.0 and zero external ﬁeld, L = 10000. Inset: Saturated surface domain size as function
of coupling for diﬀerent system sizes L = 250, L = 1000 and L = 10000. The solid line is the
ﬁt (see text).

1000

100

10

2

0 .3

=

β

β = 0.45

100

1

1

100

10000

5

0 . 4

=

β

3

0 . 3

=

β

0.5

=

β

1

0 . 3

=

β

K=0.0
K=0.3
K=0.7
K=1.1
K=2.0

10

100

1000

10000

100000

Time

s
s
e
n
h
g
u
o
R

=

10

1

1

1000

L=250
L=1000
L=10000

100.0

100

t
a
s

D

e
z
i
s
n
i
a
m
o
D

0.0

-2.0

-1.0

1.0

0.0
K

10

3

0 . 3

=

ψ

= 0.4 4

ψ

K=0.0
K=0.3
K=0.7
K=1.1
K=2.0

1

1

10

100

1000

Time

10000

100000"
"Effects of pressure on diffusion and vacancy formation in MgO from
  non-empirical free-energy integrations","  The free energies of vacancy pair formation and migration in MgO were
computed via molecular dynamics using free-energy integrations and a
non-empirical ionic model with no adjustable parameters. The intrinsic
diffusion constant for MgO was obtained at pressures from 0 to 140 GPa and
temperatures from 1000 to 5000 K. Excellent agreement was found with the zero
pressure diffusion data within experimental error. The homologous temperature
model which relates diffusion to the melting curve describes well our high
pressure results within our theoretical framework.
",http://arxiv.org/pdf/cond-mat/9706130v1,2,"7
9
9
1

n
u
J

2
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
0
3
1
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Eﬀects of pressure on diﬀusion and vacancy formation in MgO from non-empirical
free-energy integrations.

Joel Ita and Ronald E. Cohen
Geophysical Laboratory and Center for High Pressure
Research, Carnegie Institution of Washington, 5251 Broad Branch Road,
NW, Washington, DC 20015-1305
(March 22, 2018)

The free energies of vacancy pair formation and migration in MgO were computed via molecular
dynamics using free-energy integrations and a non-empirical ionic model with no adjustable param-
eters. The intrinsic diﬀusion constant for MgO was obtained at pressures from 0 to 140 GPa and
temperatures from 1000 to 5000 K. Excellent agreement was found with the zero pressure diﬀusion
data within experimental error. The homologous temperature model which relates diﬀusion to the
melting curve describes well our high pressure results within our theoretical framework.

61.72.Bb,62.50.+p,66.30.Dn,91.60.Ed,91.60.Gf

Diﬀusion and vacancy formation are critical to kinetic
processes in materials, yet little is known about diﬀusion
at ultra-high pressures due to experimental diﬃculties.
Rheology of oxide minerals at high pressures is also cru-
cial in geophysics and is dependent on diﬀusive behav-
ior which is only available experimentally at relatively
low pressures [1].
In ionic systems such as MgO, the
dominant intrinsic defect is the pair vacancy [2–4] with
Mg and O sites vacant. Previous work on vacancies in
MgO used pseudopotential computations [5] or lattice dy-
namics or the Mott-Littleton approach with a variety of
semi-empirical potentials [6,7] . The accuracy of quasi-
harmonic lattice dynamics calculations degrades above
the Debye temperature and the Mott-Littleton procedure
and pseudopotential computations were restricted to 0 K.
We used molecular dynamics (MD) with non-empirical
potentials to determine the self-diﬀusion coeﬃcient D
where [2]

D = Zf

Zm
6

l2ν exp(

∆Gf
W + ∆Gm
kbT

)

(1)

Zf is the number of equivalent ways of forming a vacancy
type, Zm is the number of equivalent diﬀusion paths, l
is the jump distance, ν is the attempt frequency, ∆Gf
and ∆Gm are the energies of formation and migration,
respectively and W is the solubility factor for polyatomic
materials. If the sites are uncorrelated (Schottky defect),
then, for rocksalt structured (B1) crystals such as MgO,
W = 2, Zf = 1, Zm = 12. Highly correlated defects
(bound pair) require W =1 and Zf = 6. Symmetry and
energy considerations determine the value of Zm. In ei-
ther case, l2 = a2/2 where a is the cubic cell parameter.
induced breathing (VIB)
model which reliably gives the thermal properties and
equation of state of M gO [8] to compute the energetics
and interatomic forces. The VIB model is a Gordon-
Kim type model [9] in which the total charge density is

We used the variational

modeled by overlapping ionic charge densities which are
computed using the local density approximation (LDA)
[10]. The total energy is a sum of three terms:
(a)
the long-range electrostatic energy computed using the
Ewald method, (b) the self-energy of each atom and (c)
the short range interaction energy, the sum of the ki-
netic, short-range electrostatic and exchange-correlation
energies from the LDA. There are three approximations
beyond the LDA [11]: (1) The charge density is modeled
rather than computed self-consistently. Comparisons
with accurate linearized augmented plane wave (LAPW)
computations show this is a good approximation for MgO
[12]; (2) the pair approximation is used for the short-
range interactions (c) which is a good approximation as
long as closed shell ions are used [13]; (3) the Thomas-
Fermi kinetic energy is used for the short-range overlap
kinetic energy. The self-energy (b) includes the correct
LDA Kohn-Sham kinetic energy. O2− is not stable in the
free state and is stabilized by introducing a sphere of 2+
charge (Watson sphere) around it in the LDA atomic cal-
culations. Interactions are obtained for overlapping ion
pairs at diﬀerent distances with diﬀerent Watson sphere
radii on the O’s. For eﬃciency, the interactions were ﬁt
with a 21 parameter analytical expression as functions of
r, the interatomic distance, and Ui = zi/Ri where Ui, zi,
and Ri are the Watson sphere potential, charge (2+) and
radius for atom i, respectively. During the simulations,
the total energy was variationally optimized with respect
to all of the Watson sphere radii at each time step.

The attempt frequency ν was determined by Fourier
transforming the trajectories of the diﬀusing ion pro-
jected onto the shortest path to the vacancy. We con-
sidered two models: (1) the lowest frequency peak in the
spectrum, assuming that the diﬀusive motion is mostly
from the lowest energy mode and (2) the average fre-
quency computed from the Fourier transform.
In the
ﬁrst case we found that ν = 5.2 THz and is independent

1

 
 
 
 
 
 
of P and T over the range studied. The second case gave
an attempt frequency that is within a factor 2 of the low
frequency value . Given the uncertainties in the calcula-
tions and experimental determinations, the diﬀerence in
the ﬁnal results between these two approaches is small
and we adopted case (1) below.

Free energies were computed with the ﬁnite time vari-
ational or “adiabatic switching” thermodynamic integra-
tion method [14]. The free energy diﬀerence between the
initial and ﬁnal state is

∆F =

1

∂F (λ)
∂λ

Z
0

dλ =

1

h

∂H(λ)
∂λ

Z
0

iλdλ

(2)

where λ is a progress variable which ranges from 0 to 1 as
the system “switches” from its initial to ﬁnal state, H is
the system Hamiltonian, and hiλ represents an ensemble
average. In order to obtain ∆Gf , we ﬁrst calculated the
free energy diﬀerence between an ideal crystal at volume,
VI , giving the desired average P at T and an Einstein
crystal at the same V and T . This was repeated for
a defective crystal with a bound vacancy pair in each
periodic cell at VD corresponding to P . Then for an N
atom periodic cell

∆Gf = F N −L

D
+P

(VD) − N −L
N VI

VD − N −L
(cid:2)

N F N

I (VI )

D

(cid:3)
where F N −L
(VD) is the Helmholtz free energy of a de-
fective crystal with L vacant sites and F N
I (VI ) is the
Helmholtz free energy of the ideal crystal. The Hamilto-
nian took the form

(3)

H(λ) = HVIB × (1 − λ) + Heinλ.

(4)

where Hein is the Hamiltonian for an Einstein crystal [15]
which can be written as

Hein = K + Uo +

N

Xi=1

1
2

miωein,i(−→xi − −→xi0)2

(5)

where K is the kinetic energy, Uo is the static contribu-
tion to the potential, mi, −→xi , −→xi0, and ωein,i are the mass,
position, static lattice position, and Einstein frequency of
the ith particle, respectively. The form of λ as a function
of the scaled time, τ , is

λ(τ ) = τ 5(70τ 4 − 315τ 3 + 540τ 2 − 420τ + 126)

(6)

where τ = t/ts, t is the elapsed time, and ts is the total
switching time [15].

Migration free energies were calculated using the adi-
abatic switching procedure at constant P and T . We
computed the energy it takes to push the atom out of
one lattice site and into another vacant lattice site [16].
The force on the migrating atom due to HV IB in the mi-
gration direction was set to zero and the negative of this
force was evenly distributed among the rest of the atoms

2

so that the force on the center of mass was zero. The
position of the migrating atom was then incremented in
the migration direction. Forces on the the atom in the
plane perpendicular to the migration direction were not
artiﬁcially constrained so that the path the migrating
atom took did not lie on a direct line between the initial
position of the atom and the vacancy site. ∆Gm was de-
termined by summing the diﬀerence in HVIB before and
after incrementing the position of the migrating atom
with the other atomic positions held ﬁxed. We found
that the barriers to migration for ions that do not have
a vacancy as a nearest neighbor were lower than for ones
who do. Thus the value of Zm is 8 in MgO.

MD was performed using a timestep of 1 fs with a 5th
order Gear predictor-corrector scheme [17] in an isobaric-
isothermal ensemble generated using the extended sys-
tem method [18] for 10 ps equilibration times followed by
a 10(15) ps switching time for the formation(migration)
energy. Convergence with respect to our nominal 216
atom system size was veriﬁed for systems with up to
1000 atoms to be within 1%. Doubling the integra-
tion time resulted in free energy variations of 1% while
halving it increased the calculated free energy change
by 10%. The computationally eﬃcient ﬁrst principles
method used here lends itself to demanding convergence
tests, especially with respect to system size, that would
prove too time-consuming with self-consistent methods
[5].

Values of ∆Gf for bound pairs and ∆Gm are given
in Table I. At 0 GPa, these energies are within 5% of
those derived from previous theoretical and experimen-
tal results [3,4,6]. To determine the dominant vacancy
mechanism, we calculated the binding energy ∆Gb of a
bound pair from the diﬀerence in ∆Gf between bound
vacancy pairs and those with the largest possible dis-
tance between vacant Mg and O sites in a 1000 atom
supercell corrected for image forces [20] and found ∆Gb
= 2.5×10−19J at 0 GPa and 2000 K and 7.0×10−19J at
140 GPa and 3000 K. No signiﬁcant changes in migration
energy relative to the bound pair simulation were found.
Assuming that the variation in binding energy is linear
in pressure and independent of temperature and taking
into account the conﬁgurational entropy, we calculated
the vacancy concentration and Gibbs free energy change
for crystals containing bound and disassociated pairs rel-
ative to the perfect crystal [2]. This analysis shows that
Schottky defects dominate at 1000 K or above due to
entropy contributions (lower temperatures will favor the
bound state). Ionic conductivity measurements indicate
that Mg diﬀusion (DMg) is controlled by impurities [19]
whereas O diﬀusion (DO) is intrinsic in nature and di-
rectly comparable to our analysis. We ﬁnd that our pre-
dicted DO agrees with experiment within mutual error
(Fig. 1).

Fitting our diﬀusion constants with the relation

TABLE I. Free Energies of Formation and Migration and

Cell Parameter

P
(GPa)

0
0
20
20
80
80
80
140
140
140

T
(K)

1000
2000
2000
3000
2000
3000
4000
2000
3000
5000

∆Gf
−19

(10

J)

a
(˚A)

8.19 ± 0.39
7.88 ± 0.23
12.04 ± 0.40
11.57 ± 0.56
21.20 ± 0.60
21.01 ± 0.90
20.75 ± 0.71
26.96 ± 0.82
25.29 ± 1.11
23.44 ± 1.76

4.2495
4.3073
4.1312
4.1687
3.8610
3.8803
3.9031
3.7071
3.7210
3.7509

∆Gm
−19

(10

J)

Mg
3.36 ± 0.10
2.72 ± 0.12
3.75 ± 0.10
3.60 ± 0.10
5.16 ± 0.10
4.99 ± 0.11
4.55 ± 0.10
6.39 ± 0.10
5.99 ± 0.15
4.80 ± 0.30

O
3.75 ± 0.11
3.16 ± 0.12
4.09 ± 0.10
4.06 ± 0.12
5.84 ± 0.17
5.86 ± 0.07
5.61 ± 0.16
6.91 ± 0.10
6.21 ± 0.21
5.69 ± 0.41

FIG. 1. Predicted pressure and temperature dependence
of the self-diﬀusion coeﬃcients in MgO. Curves represent the
best ﬁt to the coeﬃcients using the activation energy-volume
relation given by Equation 7. Vertical symbol size of experi-
mental datum taken from Ref. [4] represents uncertainty.

ln D = ln(a2ν) + S∗
o + P 2V ∗′
o + P V ∗
−(E∗

o + P S∗′
o
o )/kbT

(7)

gives the zero pressure activation entropy S∗
o =3-
(4)kb, its pressure derivative S∗′
o =0.03-(0.02)kb, activa-
o =9.0-(9.4) ×10−19 J, activation volume
tion energy E∗
o =16.0-(16.7) ˚A3, and its pressure derivative V ∗′
V ∗
o =-
0.031-(-0.038) ˚A3/GPa for Mg-(O). The activation vol-
ume varies as a function of pressure consistant with pre-
vious discussions [20–22]. The activation entropy is of
the same order as previous estimates of the formation
entropy at 0 GPa but varies much less drastically with
pressure than a previous estimate [20].

Finally, we considered the homologous temperature re-

lation

D = Do exp(gTm/T )

(8)

commonly used to model the dependence of diﬀusion on
P and T [23]. Because of the similarity of behavior in
diﬀusion of Mg and O, we used the eﬀective diﬀusion co-
eﬃcient, Def f = 2DMgDO/(DMg + DO) for D [24]. We
tested this model using the theoretical melting curve of
Cohen and Weitz [25] obtained with the same VIB po-
tential as used here, and the extrapolated experimental
melting curve of Zerr and Boehler [26] which has a lower
dP/dT . Good global ﬁts were found using the theoret-
ical melting curve, but the experimental melting curve
is not consistent with the present diﬀusion results. As
discussed in Ref. [25] the experimental results may be in-
ﬂuenced by Ar solubility in MgO melt at high pressures.

Theoretical estimates of the melting curve are generally
consistent with each other and with expected thermody-
namic parameters.

We also tested the use of zero pressure diﬀusion re-
sults only in Eq. 8 and found that extrapolations to high
pressure using the melting curve were reasonably reliable
although some accuracy was lost compared to the results
from direct high pressure simulations. This gives justiﬁ-
cation for use of melting curves in estimating high P and
T diﬀusion in oxides. In addition, we found that g was
less than 14 while the average value for alkali halides is
24 [27] indicating that conclusions based on a systematic
value for this parameter may be invalid.

In summary, we found (1) excellent agreement with
experimental results, (2) that defects are formed from
Schottky pairs as opposed to neutral divacancies, and
(3) the homologous temperature relation holds within our
theoretical framework. These results will help constrain
rheological properties of the deep Earth and provide con-
straints for pressure eﬀects on kinetics in oxides.

ACKNOWLEDGMENTS

We thank W.P. Reinhardt and V. Heine for helpful
discussions. This work was supported by NSF grant
EAR94-18934. Computations were performed on the
Cray J916/12-1024 at the Geophysical Laboratory, CIW,
purchased with support from NSF grant EAR95-12627.

[1] S. Karato, P. Li, Science, 255, 1238 (1992)
[2] R.J.D. Tilley, Defect crystal chemistry and its applica-

tions (Blackie, Glasgow and London, 1987)

[3] K. Ando, in Rheology of Solids and of the Earth, edited by
S. Karato and M. Toriumi(Oxford Univ. Press, Oxford,
1989)

[4] M.H. Yang and C.P. Flynn, Phys. Rev. Let., 73, 1809

(1994)

3

[5] A. De Vita, M.J. Gillan, J.S. Lin, M.C. Payne, I. ˇStich

and L.J. Clarke, Phys. Rev. B, 46, 12964 (1992)

[6] L. Voˇcadlo, A. Wall, S.C. Parker, and G.D. Price, Phys.

Earth Planet. Int., 88, 193 (1995)

[7] W.C. Mackrodt and R.F. Stewart, J. Phys. C, 12, 5015

(1979)

[8] I. Inbar and R.E. Cohen, Geophys. Res. Let., 22, 1533

(1995)

[9] R.G. Gordon, and Y.S. Kim, J. Chem. Phys., 56, 3122

(1972)

[10] R.E. Cohen, L.L. Boyer, and M.J. Mehl, Phys. Rev. B,

35, 5749 (1987)

[11] L. Hedin and B.I. Lundqvist, J. Phys. C, 4, 2064 (1971)
[12] M.J. Mehl, R.E. Cohen and H. Krakauer, J. Geophys.

Res., 93, 8009 (1988)

[13] L.L. Boyer, M.J. Mehl, J.L. Feldman, J.R. Hardy, J.W.
Flocken, and C.Y. Fong, Phys. Rev. Lett., 54, 1940
(1985)

[14] J.E. Hunter, W.P. Reinhardt, and T.F. Davis, J. Chem.

Phys., 99, 6856 (1993)

[15] M. de Koning and A. Antonelli, Phys. Rev. E, 53, 465

(1996)

[16] V. Milman, M.C. Payne, V. Heine, R.J. Needs, J.S. Lin,

and M.H. Lee, Phys. Rev. Lett., 70, 2928 (1993)

[17] C.W. Gear, Numerical and initial value problems in or-
dinary diﬀerential equations (Prentice-Hall, Englewood
Cliﬀs, NJ, 1971)

[18] G.J. Martyna, D.J. Tobias and M.L. Klien, J. Phys.

Chem., 101, 4177 (1994)

[19] D.R. Sempolinski and W.D. Kingery, J. Amer. Ceram.

[20] D.R. Mills, S.C. Parker and A. Wall, Phil. Mag. A, 64,

Soc., 63, 664 (1980)

1133 (1991)

[21] S. Karato, Phys. Earth Planet. Inter., 24, 1 (1981)
[22] J.P. Poirier and R.C. Liebermann, Phys. Earth Planet.

Inter., 35, 283 (1984)

[23] C.G. Sammis, J.C. Smith and G. Schubert, J. Geophys.

Res., 86, 10707 (1981)

[24] J.P. Poirier, Creep of crystals (Cambridge University

Press, Cambridge, UK, 1985)
[25] R.E. Cohen and J.S. Weitz,

in High Pressure-
Temperature Research: Properties of Earth and Plane-
tary Materials, edited by M.H. Manghnani and T. Yagi
(American Geophysical Union, 1997).

[26] A. Zerr and R. Boehler, Nature, 371, 506 (1994)
[27] S. Karato, Phys. Earth Planet. Inter., 25, 38 (1981)

4"
Rotational Reconstruction of Sapphire (0001),"  The structure of the $(\sqrt{31}\times \sqrt{31})R\pm9^\circ$ reconstructed
phase on sapphire (0001) surface is investigated by means of a simulation based
on the energy minimization. The interaction between Al adatoms is described
with the semi-empirical many-body Sutton-Chen potential, corrected for the
charge transfer between the metallic overlayer and the substrate. The
interactions between the Al adatoms and sapphire substrate are described with a
simple three-dimensional potential field which has the hexagonal periodicity of
sapphire surface. Our energy analysis gave evidence that the structure which is
observed at room temperature is in fact a frozen high-temperature structure. In
accordance with the X-ray scattering, a hexagonal domain pattern separated by
domain walls has been found. The Al adatoms, distributed in two monolayers, are
ordered and isomorphic to metallic Al(111) in the domains and disordered in the
domain walls. The main reason for the rotational reconstruction is the lattice
misfit between the metallic Al and sapphire.
",http://arxiv.org/pdf/cond-mat/9706131v1,2,"7
9
9
1

n
u
J

2
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
1
3
1
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Rotational Reconstruction of Sapphire (0001)

Igor Vilfan, a Fr´ed´eric Lan¸con b and Jacques Villain b

aJ. Stefan Institute, P.O. Box 3000, SI-1001 Ljubljana, Slovenia

e-mail: igor.vilfan@ijs.si

bD´epartement de Recherche Fondamentale sur la Mati`ere Condens´ee,

CEA-Grenoble, F-38054 Grenoble cedex 9, France

PACS numbers: 68.35 Bs, 68.35 Md, 61.50 Ah, 68.10 Jy

Abstract

The structure of the (√31

√31)R

×

±

9◦ reconstructed phase on sapphire (0001)

surface is investigated by means of a simulation based on the energy minimization.

The interaction between Al adatoms is described with the semi-empirical many-

body Sutton-Chen potential, corrected for the charge transfer between the metallic

overlayer and the substrate. The interactions between the Al adatoms and sapphire

substrate are described with a simple three-dimensional potential ﬁeld which has

the hexagonal periodicity of sapphire surface. Our energy analysis gave evidence

that the structure which is observed at room temperature is in fact a frozen high-

temperature structure. In accordance with the X-ray scattering, a hexagonal domain

pattern separated by domain walls has been found. The Al adatoms, distributed in

two monolayers, are ordered and isomorphic to metallic Al(111) in the domains and

disordered in the domain walls. The main reason for the rotational reconstruction

is the lattice misﬁt between the metallic Al and sapphire.

Key words: Surface relaxation and reconstruction. Sapphire. Surface

thermodynamics. Computer simulations.

Preprint submitted to Elsevier Preprint

8 October 2018

 
 
 
 
 
 
1

Introduction

Sapphire α

Al2O3 is a technologically important material with a variety of

−

(0001) surface reconstructions. Upon heating in UHV, the nonreconstructed

1) surface is stable up to

(1

×

∼

1250 C. Above this temperature, oxygen grad-

ually evaporates whereas Al stays on the surface [1]. As a consequence, the

surface ﬁrst reconstructs to (√3

√3) rotated by 30◦ (or (2

×

2), as reported

×

by Gautier et al [4]), then to (3√3

×
20 minutes at 1350 C, to the (√31

×
∼
last reconstruction which will be the subject of the present paper. The LEED

±

√31)R

9◦ structure [1,2]. It is this

3√3) rotated by 30◦ and ﬁnally, after

pattern was ﬁrst investigated by French and Somorjai [1] who found a cubic

Al-rich surface structure over the hexagonal-symmetry bulk. More recently,

Vermeersch et al. [3] obtained the same reconstruction after evaporating up to

2 ML of Al on clean non-reconstructed sapphire surface. Gautier et al. [4]

∼
measured the electron energy loss spectra and found a small hump in the sap-

phire band gap region. This hump is an indication of metallic character of the

Al-rich surface layer. Renaud et al. [2] made very precise grazing-incidence X-

ray diﬀraction (GIXD) measurements and were the ﬁrst to propose a possible

atomic structure of the (√31

×

√31) structure. However, the Fourier trans-

form of the GIXD provides the Patterson map and not the real-space atomic

structures. The lateral positions of Al atoms in the disordered regions could

not be uniquely determined. In addition, the GIXD measurements could not

tell the altitude of individual atoms above the substrate. Nevertheless, Renaud

et al. [2] found that the Al overlayer forms a hexagonal domain pattern. Al

atoms are ordered in two compact (111) planes of an FCC lattice, character-

istic of metallic Al monolayers, within the domains and highly disordered in

the “domain walls” between them. Whereas the origin of the domain pattern

was attributed to the lattice misﬁt between Al overlayer and the substrate,

2

the reason for the

9◦ rotation was less clear.

±

Interestingly enough, evaporation of two topmost planes of oxygens from sap-

phire crystal leaves behind 5 Al atoms per surface unit cell, very close to the

density observed by Renaud et al. [2].

A mechanism of rotational reconstruction was proposed theoretically by No-

vaco and McTague [5] and conﬁrmed experimentally for several systems, in-

cluding rare gases (physisorbed) and alkali metals (chemisorbed) on graphite

[6,7] and metals on metals [8,9]. In the Novaco and McTague model, rotational

reconstruction was attributed to lattice misﬁt combined with weak coupling

between the overlayer and the substrate. This caused a weak sinusoidal lateral

distortion of the overlayer lattice. Interestingly enough, rotational reconstruc-

tion was observed for lattice misﬁts as large as 15 % [8].

Rotational reconstruction on sapphire, on the other hand, is diﬀerent and

cannot be completely explained by the Novaco-McTague model. The origin

of the reconstruction is still the lattice misﬁt between the overlayer and the

substrate, but now the distortion seems to be so strong that some atoms in

the domain walls have lower coordination. This strong disorder could be the

consequence of strong overlayer–substrate interactions and not of large lattice

misﬁt. For the (√31

×

√31) reconstruction the misﬁt between the sapphire

bulk and the Al metal overlayer is only

4 % and is substantially less than

∼

in some other rotationally reconstructed systems [8]. On the other hand, the

interaction is strong also for some other rotationally reconstructed systems like

Cs chemisorbed on graphite [7]. There is another important diﬀerence between

the reconstructed sapphire and other systems: the overlayer on sapphire is

composed of two monolayers [2] whereas in the other systems, it is composed

of only one monolayer. Evidently, the origin of rotational reconstruction and

3

Surface Oxygen

Deeper Oxygen

Aluminum on 
(1 x 1) surface
Al added to get
1 compact layer

Fig. 1. Unit cell of non-reconstructed sapphire (0001). Al atoms (black circles) in

the topmost plane are followed by an oxygen plane (open circles). Al atoms in the

bulk of sapphire are not displayed whereas the next oxygen layer is shown with

smaller open circles. Upon evaporation of oxygen, the density of surface Al atoms

increases. Shaded circles represent added Al atoms if sapphire were covered with

one compact in-register Al monolayer.

of strong disorder in the domain walls is not clear.

In this paper we report on a simulation of the (√31

√31) rotational re-

×

construction of sapphire with the aim of better understanding the processes

of rotational reconstruction on the sapphire and similar surfaces and to help

resolve some of the above open questions.

2 The Model

The unit cell of clean, nonreconstructed sapphire (0001) surface is shown in

Fig. 1. It is terminated with an Al plane with one Al atom per surface unit

cell (black disc; 1/3 of a compact monolayer (ML) coverage) [10]. Also shown

(shaded discs) are Al atoms which have to be added to get one unexpanded

compact monolayer, in register with sapphire.

4

The reconstructed surface unit cell has about 157 Al atoms in the overlayer

[2], so one has to simulate rather large surface unit cells. This is possible only

with eﬃcient potentials, therefore we describe the interaction between the

overlayer atoms with the semi-empirical Sutton-Chen potential [11,12] which

has been also used in studying surface properties, including reconstruction, of

FCC metals [13]. These potentials are many-body potentials with elements of

two-body terms in it and are written in the form:

U =

1
2

ǫ

Xi6=j

n

a
rij !

−

ǫC

√ρi

i
X

(1)

(rij is the separation between the atoms i and j). The ﬁrst term in (1) rep-

resents the core repulsion potential and the second term the bonding energy

mediated by the electrons. ρi is an eﬀective local electron density at the site i

and is written as:

m

.

a
rij !

ρi =

Xj6=i  

(2)

ǫ and C are parameters of the model which, together with the exponents n

and m, determine the repulsive and cohesive energies, respectively. a is the

lattice constant of an Al FCC crystal. Sutton and Chen [11] published the

following values for the potential parameters of Al:

m = 6, n = 7,

ǫ = 33.147 meV,

ǫC = 16.399 meV.

(3)

We truncated the potential continuously (with a ﬁfth order polynomial) be-

tween r/r0 = 3.17 and 3.32 (r0 is the nearest-neighbour distance). In this way
the cutoﬀ is between the 10th and 11th shells of neighbours. That meant that

interaction with 68 neighbours were included if Al were perfectly ordered in

two FCC(111) planes. With this set of parameters, the cohesive energy in the

bulk Al is 3.313 eV/atom, compared to 3.34 eV/atom in [11]. The diﬀerence

5

 
comes from diﬀerent cutoﬀ radii.

The origin of bonding is in the electrons of the overlayer. On the reconstructed

surface, there are about 5 Al atoms per nonreconstructed unit cell, on the

average. Each Al atom has two 3s and one 3p electrons which all contribute

to the cohesive energy. Out of these 5 atoms, one is already present on the

non-reconstructed surface and is ionically bound to the sapphire substrate.

This reduces the eﬀective density of the electrons in the conduction band

by 1/5 and thus scales the constant ǫC in equation (1) by a factor

4/5

(i.e., ǫC = 14.668 eV). ǫC can be additionally reduced by the charge transfer

q

between the metallic overlayer and the insulating substrate [4]. It is not known

how strong the charge transfer is, therefore we treated the constant C as an

adjustable parameter.

The interaction between the overlayer and the substrate was modelled by a

simple periodic potential. The substrate is much stiﬀer than the Al overlayer,

therefore the relaxation of the substrate caused by the overlayer was neglected

in the simulations. The substrate potential was expanded in a power series

and only the six lowest-order terms were retained, similarly as in the studies

of noble gases on graphite,

US =

UL

−

cos(~k1

·

~r) cos(~k3

·

~r)

·

ULJ (z).

~r) cos(~k2
UL
1

−
(√3,

~k1 =

2π
as

(0, 1),

~k2 =

π
as

1),

−

~k3 =

π
as

(

√3,

−

1)

−

(4)

(5)

are the unit vectors in the plane of the surface, and as the substrate lattice

constant. UL controls the lateral modulation of the potential, and ULJ ,

ULJ (z) = U0

12

z0
z (cid:19)

""(cid:18)

6

z0
z (cid:19)

,

#

2

−

(cid:18)

(6)

its z

dependence, in the direction perpendicular to the surface. This depen-

−

6

2

1.5

1

0.5

0

0

0.5

1

1.5

2

Fig. 2. The substrate potential has six equally deep minima (white) around each

maximum (black) which is located above the last layer of oxygens.

dence is necessary because the overlayer is more than one monolayer thick.

In the Lennard-Jones potential (6), U0 is the depth of the substrate potential

and z0 determines the position of the minimum and the width of the potential

in the vertical direction. Thus, the overlayer – substrate potential is described

by three variational parameters, UL, U0, and z0. This potential, shown in Fig

2, has six equally deep minima around each topmost oxygen atom of sapphire

substrate. The potential (4) is not deeper on the sites, already occupied by

Al atoms on the unreconstructed (0001) surface. This simpliﬁcation is backed

by a careful inspection of the real-space overlayer structure obtained from the

diﬀraction data [2]. During the process of reconstruction, the original Al atoms

also moved to other positions. They are not stronger bound than any other

Al atoms coming to the surface during oxygen evaporation.

We simulated a box with the base plane of √93a

√31a. Such a rectan-

×

gle accommodates exactly two reconstructed surface unit cells under periodic

7

boundary conditions for the overlayer and substrate. The in-plane symme-

try axis of the substrate is rotated with respect to the rectangle by α =
sin−1(√93/62)

8.9◦. In the initial conﬁgurations the Al atoms were put on

≈

two planes and positioned close to the positions found by Renaud et al. [2]. We

started with this conﬁguration because of the problems with metastability.

Our results have been compared with the GIXD result of Renaud et al. [2]

who found 157 adatoms in a surface unit cell, distributed in two monolayers.

In their analysis, however, some atomic sites could have been only partially

occupied. Therefore we performed simulations with the number of Al atoms

in the overlayer varying from 302 to 318 adatoms (in two unit cells).

For a given set of the potential parameters C, UL, U0 and z0, the equilibrium

Al atomic positions were calculated by the energy minimization. Once the

atomic positions were determined, we calculated the corresponding diﬀraction

pattern, given by the structure factors Sc( ~Q) of the Bragg peaks at ~Q = (h, k),

and compared it with the experimental Se( ~Q) [2,15]. To evaluate the quality
of the ﬁt we ﬁrst scaled Sc( ~Q) with a factor s and then calculated the residue,

introduced as

χ2 =

P

Q[Se( ~Q)

sSc( ~Q)]2

−
Q[Se( ~Q)]2

.

The scaling factor s was chosen to minimise the residue χ2:

P

s =

Q[Se( ~Q)Sc( ~Q)]
Q[Sc( ~Q)]2

.

P

P

(7)

(8)

Summation over the ﬁrst 17

×

16 nonequivalent diﬀraction peaks in the recip-

rocal space was performed. The parameters C, UL, U0 and z0 were then varied
to ﬁnd the minimal χ2.

In the process of relaxation towards the (local) minimum energy conﬁgura-

8

tion with the lowest residue, severe problems with hysteresis and local energy

minima (metastability) were encountered. This is not too surprising since the

“domain wall” region is full of lattice defects. To avoid trapping in a metastable

state, the relaxed structure was shaken randomly and relaxed again.

3 Results

The best agreement between the calculated and experimental diﬀraction pat-

terns was found, and the most extensive simulations have been done for the

structure with 314 adatoms (157 per reconstructed surface unit cell). The best

ﬁt between with 314 atoms was obtained for

ǫC = 13.87eV

UL = 4.56

U0 = 1.35eV

z0 = 2.64˚A.

(9)

The energy of this structure is E =

3.21 eV/adatom. The average core

−

repulsion energy between the adatoms is 1.65 eV, the bonding energy between

them is

3.95 eV, and the average interaction energy with the substrate is

−
0.92 eV.

−

The real-space structure with the best ﬁt is seen in Fig. 3. Comparison of the

real-space structures obtained from the simulation and from the GIXD shows

that the simulated structure is substantially more ordered and that the simu-

lated disordered regions, domain walls are broader and less pronounced. The

two domains in the simulated box do not have the same structure after relax-

ation although their initial conﬁgurations were identical. This is an indication

of many metastable states in the disordered regions.

9

Fig. 3. Structure of the Al overlayer obtained in the simulation of 314 atoms in a

rectangle of the size √93a

×

√31a with periodic boundary conditions. The corners

of the underlying triangles show the positions of the topmost oxygens of sapphire,

where the substrate potential is maximal. The potential is minimal in the centres of

the triangles. The grey circles represent the Al atoms and their radii are proportional

to the altitude of the atom above the substrate. The Al atoms are arranged in two

monolayers, the larger circles show the atoms in the upper layer and the smaller

circles the atoms of the lower layer. The atoms are more ordered and closer to the

minima of the substrate potential in the hexagonal domains and more disordered

close to the walls (dashed lines) separating the domains. Notice that the two domains

do not have the same structure in the disordered regions.

The residue can be compared with the experimental uncertainty σ, deﬁned as

σ2 =

Q[σ( ~Q)]2
Q[Se( ~Q)]2 ,

P

P

(10)

where σ( ~Q) are the experimental uncertainties of the structure factors at the

Bragg points ~Q. Using the experimental data of Renaud [15], we found σ =

10

16

12

k

8

4

0

4

8

12

16

h

Fig. 4. Calculated (left-hand semicircles) and experimental (right-hand semicircles)

[2] diﬀraction patterns, indexed in the reciprocal space of the reconstructed surface

unit cell. Small black disks are the bulk allowed reﬂections.

0.28 whereas our best ﬁt had χ = 0.5. Comparison of the calculated and

experimental structure factors, Fig. 4 shows good agreement of the intense

peaks around the substrate Bragg peaks. Some discrepancy is observed for

less intense peaks further away from the substrate Bragg peaks. The biggest

diﬀerence in the structure factors is found for ~Q = (7, 3). The reason is most

probably in the simple substrate potential used, so one cannot expect to ﬁnd

exactly the same structure as on a real sapphire surface.

4 Discussion

The simulations were done by energy minimization. In principle, however,

the energy minimization is acceptable only for low temperatures, when the

entropy is small, and one should minimize the free energy. It is expected that

11

the structure observed in the experiment at room temperature has minimal

free energy at the freezing temperature which is substantially higher than

the room temperature. At the freezing temperature, the contribution of the

entropy is signiﬁcant. This – together with the simpliﬁed overlayer-substrate

potential – possibly explains why the more disordered structure with the best

ﬁt has higher energy than some other – more ordered – structures with worse

ﬁt. Indeed, the energy diﬀerence between diﬀerent structures, simulated with

the same variational parameters, was of the order 0.01 eV/atom (if distributed

uniformly among 314 atoms) and is of the same order as the contribution of

the entropy to the free energy at the freezing temperature.

Another mechanism which would lead to a metastable overlayer structure

could be channeling, transport of Al atoms directly into a strongly metastable

state on the surface during the process of oxygen evaporation. However, it

is very unlikely that the metastable potential minima would be so deep that

diﬀusion at

1000 K couldn’t bring the overlayer structure to an equilibrium.

∼

Renaud et al. were not able to tell in their paper [2] which Al plane is higher.

They did, however, distinguish between the more ordered and more disordered

planes. On the basis of preliminary numerical relaxation they anticipated that

the more disordered layer was the lower plane. Our simulation does not support

this distinction, we found both planes equally disordered.

if the simulations were done with 314 Al atoms, 158 atoms were found in

the lower layer, which is much ﬂatter than the upper layer. In the hexagonal

domains, the Al atoms are well ordered in both planes like in metallic Al(111).

In the domain walls, the Al atoms are strongly disordered. In the simulation,

the disorder is manifested also in such a way that equivalent atoms in diﬀerent

reconstructed unit cells had diﬀerent positions, the translational symmetry of

12

the reconstructed unit cell was broken.

Simulations with diﬀerent number of Al atoms, NAl, show a strong increase

in χ if NAl > 314 and a small increase if NAl < 314. For NAl > 314, Al atoms

very often moved into the third plane.

In our “best ﬁt” structure, Fig. 3, the disordered regions (domain walls) were

less pronounced than in the structure proposed by Renaud et al. [2]. Our

structure has a smoother transition between the domains, one could say that

our domain walls are broader. It is not clear to which extent this diﬀerence is

the consequence of approximate description of the substrate potential.

With the substrate potential described by Eq. (4), one cannot study the pro-

cess of oxygen evaporation, we cannot say whether two overlayers of Al are

stable or only a transient state and more Al layers are formed upon further

heating. A stabilizing mechanism, discussed in detail by Chen et al. [16], is

based on the attraction between two surfaces across a thin metal, similar to

the Casimir eﬀect. This attraction is described by the Hamaker constant. We

estimated the Hamaker constant of Al metal between sapphire insulator and

vacuum, H

3.7

≈ −

×

10−2 eV. The corresponding energy gain is of the order

10−3 eV/(Al atom). We conclude that this mechanism of attraction between

the two adjacent interfaces is too weak to stop the overlayer growth at two

monolayers. In fact, the experimentalists observe that further heating in UHV

brings more Al atoms to the surface [15], the two-layer (√31

√31)R

9◦

±

×

reconstructed structure is thus not an equilibrium state of sapphire at 1350 C.

Thus, in UHV, more Al atoms build next monolayers whereas heating under

oxygen atmosphere oxidizes and deconstructs the surface.

The fact that a metallic type potential, Eq. (1), leads to a good model of this

reconstructed sapphire surface is consistent with the metallic character of its

13

Al overlayer. The minor discrepancy in some diﬀraction peaks is probably due

to the oversimpliﬁed substrate potential which cannot lead to the exact details

of the reconstruction. But the good overall agreement of the diﬀraction pat-

terns shows that we have used reasonable interatomic interaction ingredients

to simulate this reconstruction.

Acknowledgements

The authors are indebted to G. Renaud for many interesting discussions and

for providing them his experimental results. The ﬁnancial support of the

French-Slovenian programme Proteus is deeply acknowledged.

References

[1] T. M. French and G. A. Somorjai, J. Phys. Chem. 74, 2489 (1970).

[2] G. Renaud, B. Villette, I. Vilfan, and A. Bourret, Phys. Rev. Lett. 73, 1825

(1994).

[3] M. Vermeersch, R. Sporken, P. Lambin, and R. Caudano, Surf. Sci. 235, 5

(1990).

[4] M. Gautier, J. P. Duraud, L. Pham Van, and M. J. Guittet, Surf. Sci. 250 , 71

(1991).

[5] A. D. Novaco and J. P. McTague, Phys. Rev. Lett. 38, 1286 (1977); J. P.

McTague and A. D. Novaco, Phys. Rev. B 19, 5299 (1979).

[6] C. G. Shaw, S. C. Fain, Jr., and M. D. Chinn, Phys. Rev. Lett. 41, 955 (1978).

[7] N. J. Wu, Z. P. Hu, and A. Ignatiev, Phys. Rev. B 43, 3805 (1991).

14

[8] M. F. Toner et al., Phys. Rev. B 42, 5594 (1990).

[9] D. Fisher and R. D. Diehl, Phys. Rev. B 46, 2512 (1992).

[10] P. W. Tasker, Adv. Ceram. 10, 176 (1988); I. Manassidis, A. De Vita, and M.

J. Gillan, Surf. Sci. Lett. 285, L517 (1993).

[11] A. P. Sutton and J. Chen, Phil. Mag. Lett. 61, 139 (1990).

[12] M. W. Finnis and J. E. Sinclair, Phil. Mag. A 50, 45 (1984).

[13] B. D. Todd and R. M. Lynden-Bell, Surf. Sci. 281, 191 (1993).

[14] N. W. Ashcroft and N. D. Mermin, Solid State Physics, Holt, Rinehart and

Winston (Philadelphia, 1976).

[15] G. Renaud, private information.

[16] X. J. Chen, A. C. Levi and E. Tosatti, Il Nuovo Cimento 13 D, 919 (1991).

15"
Speckle from phase ordering systems,"  The statistical properties of coherent radiation scattered from
phase-ordering materials are studied in detail using large-scale computer
simulations and analytic arguments. Specifically, we consider a two-dimensional
model with a nonconserved, scalar order parameter (Model A), quenched through
an order-disorder transition into the two-phase regime. For such systems it is
well established that the standard scaling hypothesis applies, consequently the
average scattering intensity at wavevector _k and time t' is proportional to a
scaling function which depends only on a rescaled time, t ~ |_k|^2 t'. We find
that the simulated intensities are exponentially distributed, with the
time-dependent average well approximated using a scaling function due to Ohta,
Jasnow, and Kawasaki. Considering fluctuations around the average behavior, we
find that the covariance of the scattering intensity for a single wavevector at
two different times is proportional to a scaling function with natural
variables mt = |t_1 - t_2| and pt = (t_1 + t_2)/2. In the asymptotic large-pt
limit this scaling function depends only on z = mt / pt^(1/2). For small values
of z, the scaling function is quadratic, corresponding to highly persistent
behavior of the intensity fluctuations. We empirically establish a connection
between the intensity covariance and the two-time, two-point correlation
function of the order parameter. This connection allows sensitive testing,
either experimental or numerical, of existing theories for two-time
correlations in systems undergoing order-disorder phase transitions. Comparison
between theory and our numerical results requires no adjustable parameters.
",http://arxiv.org/pdf/cond-mat/9706140v2,2,"7
9
9
1

p
e
S
6
1

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

2
v
0
4
1
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Speckle from phase ordering systems

Gregory Brown1,2, Per Arne Rikvold1,2,3, Mark Sutton1, Martin Grant1
1Physics Department and Centre for the Physics of Materials, Rutherford Building, McGill University, 3600 rue University,
Montr´eal, Qu´ebec, Canada H3A 2T8
2Center for Materials Research and Technology, Supercomputer Computations Research Institute, and Department of Physics,
Florida State University, Tallahassee, Florida 32306-3016, USA
3Department of Fundamental Sciences, Faculty of Integrated Human Studies, Kyoto University, Kyoto 606, Japan
(August 23, 2021)

The statistical properties of coherent radiation scattered from phase-ordering materials are stud-
ied in detail using large-scale computer simulations and analytic arguments. Speciﬁcally, we consider
a two-dimensional model with a nonconserved, scalar order parameter (Model A), quenched through
an order-disorder transition into the two-phase regime. For such systems it is well established that
the standard scaling hypothesis applies, consequently the average scattering intensity at wavevector
2τ .
k and time τ is proportional to a scaling function which depends only on a rescaled time, t
|
We ﬁnd that the simulated intensities are exponentially distributed, and the time-dependent aver-
age is well approximated using a scaling function due to Ohta, Jasnow, and Kawasaki. Considering
ﬂuctuations around the average behavior, we ﬁnd that the covariance of the scattering intensity for
a single wavevector at two diﬀerent times is proportional to a scaling function with natural variables
and ¯t = (t1 + t2)/2. In the asymptotic large-¯t limit this scaling function depends only
δt =
on z = δt/¯t 1/2. For small values of z, the scaling function is quadratic, corresponding to highly per-
sistent behavior of the intensity ﬂuctuations. We empirically establish that the intensity covariance
(for k
= 0) equals the square of the spatial Fourier transform of the two-time, two-point correlation
function of the order parameter. This connection allows sensitive testing, either experimental or
numerical, of existing theories for two-time correlations in systems undergoing order-disorder phase
transitions. Comparison between theoretical scaling functions and our numerical results requires no
adjustable parameters.

t1
|

∼ |

−

t2

k

|

I. INTRODUCTION

A scattering experiment, using neutrons or X-rays for example, is one of the most direct measures of the structure
of materials. Naively, this comes about because in the Born approximation, which usually applies for X-rays and
neutrons, the intensity in scattering measurements is proportional to the Fourier transform of a density-density
correlation function. It is the wavelike properties of the scattering probe which produces the Fourier transform. For a
deeper understanding of the relationship between scattering intensity and structure one must realize that this direct
correspondence applies precisely only for coherent waves. Indeed, for conventional sources, a given point in the incident
wave is only coherent within a small volume of neighboring points. This coherence volume has transverse dimensions
determined by how parallel the wavefronts are and a longitudinal length determined by how monochromatic the wave
is. In a standard scattering experiment the diﬀerent coherence regions of the incident beam scatter independently.
The intensity measured thus depends on an incoherent average over diﬀerent regions of the scattering volume. By
restricting the scattering volume of the sample to less than the coherence volume of the beam, one can eliminate this
incoherent average, and thus learn more about the material’s structure. Of course, the experimental diﬃculty which
arises is to obtain suﬃcient diﬀracted intensity to measure a signal. Recently, it has been demonstrated that coherent
diﬀraction experiments can be performed with X-rays using high-brilliance synchrotron sources [1]. For coherent
diﬀraction, the scattering from an inhomogeneous material displays a characteristic speckled scattering pattern. For
instance, the random distribution of phase-ordering domains shown in Fig. 1 and discussed below, results in the
speckle pattern shown in Fig. 2. As the domains change shape, the speckle pattern changes, and this time dependence
of the speckle oﬀers a unique method for studying the evolution of inhomogeneous materials.

Motivated by these advances in experimental techniques, we have undertaken a theoretical study of intensity
ﬂuctuations caused by scattering from a nonequilibrium system undergoing phase ordering by domain growth. When
a disordered homogeneous material is rapidly brought to a new set of conditions, corresponding to the coexistence of
two equilibrium phases, a spatial pattern of domains of the two phases develops [2]. This change of conditions is often
accomplished by a rapid quench from a high temperature to a low one below a miscibility gap. The quench from a
homogeneous state with local ﬂuctuations creates a microstructure of interconnecting, interlocking domains through

1

 
 
 
 
 
 
6
the kinetics of a ﬁrst-order phase transition. As time goes on the domains grow, so as to minimize the area of the
domain walls that separate the phases.

When the average domain size R(τ ) at time τ is large compared to all other relevant lengths, except for the extent
L of the system itself, the system looks invariant if all lengths are measured in units of that domain size. In this case
the structure of these many domains is said to “scale” with R(τ ). Experimentally, the growing domain structure is
often studied by means of the scattering intensity [3], whose width is proportional to the inverse of R(τ ). When the
average scattering intensity is scaled in units of this time-dependent length, one obtains the scattering function for late
times in the form of a time-independent scaling function. The time-dependence then enters only through R(τ ), which
τ n. This scaling hypothesis has been found to
can typically be described in terms of an exponent n, such that R
apply to a large range of systems, and to be unaﬀected by many of the microscopic details of speciﬁc materials. That
is, the scaling function and the growth exponent n are two features which are common to a large number of systems,
collectively called a universality class. Universality classes for phase ordering by domain growth are delineated chieﬂy
by the presence or absence of conservation laws. Indeed, many aspects of this nonequilibrium process can be described
by relatively simple theoretical models. For example, for systems described by a nonconserved scalar order parameter,
often called Model A [2], the growth exponent is found to be n = 1/2. Systems included in this class are the Ising
model with spin-ﬂip dynamics, binary alloys undergoing an order-disorder transition, and some magnetic materials
with uniaxial anisotropy. Model B [2] refers to systems in which the scalar order parameter is conserved, and the
only growth mechanism is diﬀusion. Systems in this universality class have n = 1/3 and include the conserved Ising
model, as well as binary alloys undergoing phase separation.

∼

In the present paper we investigate the time-dependent ﬂuctuations around this scaling behavior, and we demon-
strate how to study these ﬂuctuations experimentally through analysis of the time-dependent scattering. The ﬁrst
theoretical study of such behavior is given in Ref. [4]. The scattering intensity is related to the Fourier transform
of the order parameter ψ(r, τ ), the scalar ﬁeld describing the inhomogeneity of a speciﬁc sample of the scattering
material, by

where we ignore the proportionality constant for convenience. The average of I(k, τ ) over an ensemble of initial
conditions is the structure factor,

I(k, τ ) =

ˆψ(k, τ )
|

|

2 ,

(1.1)

Here, the ensemble average expresses the distinction between coherent scattering, given by I, and incoherent scattering,
given by S. Fluctuations around the average scattering are the main topic of interest in this paper. The structure
factor can also be expressed as the Fourier transform of the correlation function of ψ(r, τ ),

S(k, τ ) =

I(k, τ )
i
h

.

(1.2)

C(r, τ ) =

ψ(0, τ )ψ(r, τ )
i
h

.

(1.3)

k
|
As mentioned above, scaling by the domain size R

|

Because of these relationships, the scattering intensity and structure factor have been important tools for studying
the dynamics of materials far from equilibrium. If a system is isotropic, then its average scattering properties depend
= k.
only on the magnitude of the scattering wavevector,

τ n implies that correlations are time independent when
measured in units of R. Speciﬁcally, for an isotropic system, C(r, τ ) = C(r/R(τ )), where C(r) is one form of the
scaling function. Fourier transformation gives the average scattering intensity in terms of another form of the scaling
function, which depends only on a scaled time t

τ k1/n,

∼

∝

kdS(k, τ ) = F1(t) ,

(1.4)

where d is the spatial dimension of the scattering material. The speciﬁc form of F1(t) depends on the dynamic
universality class.

As discussed above, when the scattering involves coherent radiation, I(k, τ ) is directly measured without self-
averaging. The scattering from an inhomogeneous material displays a characteristic speckled scattering pattern much
like the one in Fig. 2, which shows the squared norm of the Fourier transform of the conﬁguration in Fig. 1. The
intensity of each speckle in I(k, τ ) is due to correlations in the inhomogeneous sample, and I
S gives the
ﬂuctuations around the average scattering intensity.

I
− h

= I

−

i

For materials in equilibrium, deviations of I around the structure factor are induced by thermal ﬂuctuations in ψ.
In fact, ﬂuctuations in the speckle patterns from scattered laser light have been used as the standard basis of photon
correlation experiments at wavelengths ranging from the ultraviolet to the infrared [5,6]. With the advent of high-
brilliance synchrotron photon sources, experiments involving coherent X-rays have become possible. For example,

2

Brownian diﬀusion rates in gold colloids have been determined from the time required for a change in an X-ray
speckle pattern [7,8]. Speckle from coherent X-rays has also been used to study equilibrium ﬂuctuations in Fe3Al near
an order-disorder transition [9], and in micellar block-copolymer systems [10]. X-rays can probe materials on much
smaller length scales than is currently possible with lasers, and their greater penetration allows the study of optically
opaque materials.

In the present paper, we present a theoretical study of ﬂuctuations in the scattering intensity from a nonequilibrium
system undergoing phase ordering by domain growth. For such systems the intensity ﬂuctuates around a time-
dependent structure factor [4,11,12]. The time evolution of the intensity at a speciﬁc wavevector for one particular
quench can be normalized by the average behavior. A typical example of such a normalized time series, obtained
from a simulation at zero temperature, is presented in Fig. 3. It is the correlations of such time series, averaged over
many individual speckles and quenches, that can be used to study the pattern formation process in phase-ordering
materials.

In Fig. 3 we also show a “Brownian” function which was constructed to have the same single-time probability density
and an exponential two-time covariance with the same characteristic time as the normalized nonequilibrium scattering
intensity. Qualitative diﬀerences are immediately evident in the two time series. The Brownian function ﬂuctuates
quickly, with large amplitude variations, while the intensity ﬂuctuations produced by the phase-ordering system
vary slowly, with markedly less variation in amplitude on short time scales [12]. This property of the nonequilibrium
intensity ﬂuctuations is called persistence [13], and it indicates a qualitative diﬀerence between the two-time correlation
functions for the two processes [14].

For the remainder of this paper, we specialize to Model A as a simple model for systems undergoing phase ordering
following a quench through a second-order order–disorder phase transition. Some preliminary numerical results from
simulations less extensive than the ones used here were presented in Ref. [15].

The outline of the rest of this paper is as follows. Section II describes the details of our numerical approach, which
uses a standard time-dependent Ginzburg-Landau equation with a nonconserved order parameter. In Sec. III the
time-time covariance of individual speckle intensities is discussed, using analysis readily adaptable to experimental
data. The equality between this covariance and the square of the two-time structure factor of the nonequilibrium
material is argued in Sec. IV, and comparisons to speciﬁc two-time theories follow in Sec. V. There an analytic
expression for the universal scaling form for the intensity covariance at late times is obtained. Finally, our results are
summarized in Sec. VI.

II. METHOD

The dynamics of speckle in k-space were simulated by generating successive scattering patterns from a real-space
simulation of the dynamics of phase ordering following a quench through an order-disorder phase transition. The
conﬁguration of the real-space system is described by a nonconserved scalar order-parameter ﬁeld ψ(r, τ ), and its
dynamics are governed by the following time-dependent Ginzburg-Landau equation,

∂ψ(r, τ )
∂τ

δ

[ψ(r, τ )]

F
δψ(r, τ )

=

Γ

−

+ ζ(r, τ ) .

(2.1)

The ﬁrst term on the right-hand side of this Langevin equation corresponds to deterministic relaxation, with rate
[ψ(r, τ )]. Thermal noise, which we neglect, is
constant Γ, towards a minimum value of the free-energy functional
modeled by the random variable ζ, whose intensity is proportional to Γ and temperature by virtue of a ﬂuctuation-
dissipation theorem [2]. We neglect ζ because the most important sources of noise here are the initial conditions,
which give the random domain morphology. The main eﬀect of thermal noise at low temperatures far below any
critical point, is only to thermally roughen the domain walls.

F

We employ the standard Ginzburg-Landau-Wilson free energy [2],

[ψ(r, τ )] =

F

dr

"" −

a
2

Z

ψ2(r, τ ) +

ψ4(r, τ ) +

u
4

c
2 |∇

ψ(r, τ )
|

2

.

#

(2.2)

For a > 0, the local part of the integrand in Eq. (2.2) represents a bistable potential, and the parameters of the model
deﬁne an equilibrium ﬁeld magnitude,
ψ0|
=
2c/a, and a characteristic
a/u, a thermal correlation length, ξ0 =
evolution time, τ0 = (aΓ)−1. The model can be rescaled by choosing a new ﬁeld ˜ψ = ψ/
, a new length ˜r = √2r/ξ0,
and a new time ˜τ = τ /τ0. Dropping the tilde from the rescaled quantities for convenience, we get the rescaled
dynamical equation,

ψ0|
p

p

|

|

3

∂ψ(r, τ )
∂τ

=

1 +

2
∇

ψ(r, τ )

−

ψ3(r, τ ) ,

(2.3)

which has no adjustable parameters. Since thermal ﬂuctuations are explicitly omitted in the simulation, the only
randomness comes from the high-temperature state the system is in before the quench. This was implemented by an
initial condition such that ψ(r, 0) consists of independent random numbers uniformly distributed between

0.1.

The simulations were conducted on square lattices with periodic boundary conditions, lattice constant ∆r = 1 ,
and a system size of Lx = Ly = L = 1024. The Laplacian in Eq. (2.3) was implemented using the eight-neighbor
discretization [16,17]

±

(cid:0)

(cid:1)

2ψ =

∇

1
2(∆r)2

ψNN +

1
2

X

X

ψNNN −

6ψ

,

!

(2.4)

where ψNN are the four nearest neighbors of ψ (along the lattice directions), and ψNNN are its four next-nearest
neighbors (diagonally). A simple Euler integration scheme with ∆τ = 0.05 was used to collect data up to a maximum
rescaled time of τ = 2000 for 100 separate sets of initial conditions.

Usually, the order parameter takes the values

everywhere except at the domain walls, which are negligibly thin
compared to the domains themselves. After our rescaling, domain walls have a soft nonzero width of approximately
√2. To minimize the eﬀect of this nonzero, though small, width, we use a nonlinear mapping of the rescaled order
parameter to

1 before taking the Fourier transform. The transformed ﬁeld, ˆψ, is deﬁned by

ψ0|

±|

±

ˆψ(k, τ ) =

1
√Ld

sign

ψ(r, τ )
(cid:17)

(cid:16)

r
X

eik·r

,

(2.5)

where the fact that the lattice spacing is unity in all directions has been used. The Brillouin zone in two dimensions is
deﬁned by the discrete set of wavevectors, kx, ky = 2πj/L with j
. The scattering
1,
±
intensity I(k, τ ) =
2 and its average over initial conditions is the time dependent structure factor, S(k, t),
as described in Sec. I. To be consistent with the numerical integration, the magnitude of the scattering wavevector,
k(k), is deﬁned using the operator relation

ˆψ(k, τ )
|

1), L/2

2, . . . ,

(L/2

∈ {

0,

−

±

±

}

|

k2(k) ˆψ(k, τ ) =

−

1
√Ld

r
X

eik·r

2ψ(r, τ ) .

∇

Substituting the discrete version of the Laplacian from Eq. (2.4), one obtains for d = 2

k2(k) = 3

cos kx −

cos ky −

−

1
2

cos (kx + ky)

1
2

−

cos (kx −

ky) .

(2.6)

(2.7)

This method has been used to calculate the magnitude of the wavevector for scaling structure factors and data binning.
Because of lattice eﬀects we consider only those wavevectors with 0 < k(k)

0.75.

In order to apply the scaling ansatz, one must know the characteristic length at time τ . Often R(τ ) is estimated
from the structure factor, however we have found an analytic expression that works well. Indeed, one advantage of our
numerical approach, as compared to Monte Carlo or cell dynamical simulations, is that we can test theories without
using any free parameters. In particular, Ohta, Jasnow, and Kawasaki [18] found that the time dependence of the
domain size obeyed R(τ ) = √4ρdτ , with ρd = (d
1)/d. Furthermore, they found that the structure factor scaled,
and they gave an explicit form for the scaling function F1(t). In comparison, the theory of Kawasaki, Yalabik, and
Gunton [19] gives the same form of F1(t), but the factor ρd does not appear in their result for R(τ ). Our present
simulations agree with the amplitude given by Ohta et al., and so we choose a scaled time t given by

−

≤

t(k, τ ) = [kR(τ )]2 = 4ρdk2τ .

(2.8)

III. TWO-TIME CORRELATION FUNCTIONS

A quantity to which experiments give ready access is the ﬂuctuation in the speckle intensity as a function of time.
The relationship between an individual speckle at two diﬀerent times τ1 and τ2 is, on average, described by the
intensity covariance,

4

 
Covk(k, τ1, τ2) =

I(k, τ1)I(k, τ2)
E

D

−

D

I(k, τ1)

I(k, τ2)
E

ED

.

(3.1)

For random systems, the covariance is maximum in the equal-time limit, τ1 = τ2, and as the two measurement times
become widely separated, the values of the intensity become stochastically independent and the covariance decays to
zero. For this relaxational system, negative values are not expected. The scaling ansatz extended to this situation
allows collapse of the covariance at diﬀerent (k, τ1, τ2) by

k2dCovk(k, τ1, τ2) = Cov(t1, t2)

(3.2)

where Cov(t1, t2) is the scaling function for the covariance.

The simulated scattering intensities were analyzed in the following way. In Eq. (3.2), the ensemble average over
initial conditions is scaled to the universal form. To make estimates of Cov(t1, t2) from the simulations, we changed
the order of the averaging and used the single-simulation averages M1(t) and M2(t1, t2). M1(t) is the scaled intensity,
kdI(k, τ ), averaged over all pairs of (k, τ ) that map onto t, and M2(t1, t2) is the scaled product of the intensities at
two diﬀerent times, k2dI(k, τ1)I(k, τ2), averaged over all triples (k, τ1, τ2) that map onto (t1, t2). Due to the large
amount of data involved in the present study, samples for M1(t1), M1(t2) and M2(t1, t2) were accumulated in a two-
dimensional structure of bins organized by a pair of variables related to (t1, t2) as described below. After accumulation
into the bins (t1, t2), averaging over independent runs, i.e., over diﬀerent initial conditions, was performed to further
improve our statistics. These averages were then used to ﬁnd the scaling function Cov(t1, t2). It should be noted that
all the quantities used here are also readily obtained experimentally, except for two unknown proportionality constants
that depend on details of the experimental system. One occurs in the equation for the scaled time, corresponding
to 4ρd in Eq. (2.8). The other is the proportionality constant between the measured scattering intensity and the
squared-norm of the Fourier transform of the order parameter, which we have ignored in Eq. (1.2). Neither of these
should be a barrier to comparing our results to experiments.

The normalized analog of the covariance is the correlation function [20],

Corr(k, τ1, τ2) =

I(k, τ1)I(k, τ2)
E
I(k, τ1)
E

D
I 2(k, τ1)
E

−

D

−
2

I(k, τ1)

I(k, τ2)
E
I(k, τ2)
E

−

D

D

rD

ED
I 2(k, τ2)
E

rD

.

2

(3.3)

Corr(k, τ, τ ) is unity by construction, which removes the equal-time variations in the covariance as τ changes. Using
the deﬁnitions of M1 and M2 above, the scaled version can be expressed as

Corr(t1, t2) =

M2(t1, t2)

M1(t1)

M1(t2)

−

D

M2(t1, t1)

E
M1(t1)

D
2

ED
M2(t2, t2)

E
M1(t2)

2

−

rD

−

,

(3.4)

(cid:11)

(cid:10)

(cid:10)

(cid:11)

E

h· · ·i

ED
where
denotes averaging over initial conditions as before. The contour plot of Corr in the (t1, t2)-plane, Fig. 4,
shows how the correlations in individual speckle intensities decay. In this ﬁgure, the line Corr(t1, t2) = 1 extends
along the diagonal. Moving away from that line, contours at values of 0.7, 0.2, 0.07, and 0.02 are shown. The scatter
in the data is apparent for the last contour and becomes dominant for values of the correlation less than that. The
striking feature of this ﬁgure is that the correlations increase in a nontrivial way as the phase-ordering continues.
Thus, normalization by the time-dependent intensity is not suﬃcient to convert the speckle intensity to a stationary
time series.

A more natural set of variables for studying this eﬀect is ¯t = (t1 + t2)/2 and δt =

. A constant value of ¯t
corresponds to a line perpendicular to the t1 = t2 diagonal, while δt measures the distance (in units of scaled time)
away from the diagonal. The symmetry under exchange of t1 and t2 is retained. These variables were used for the
binning of simulation results that produced Fig. 4, with data grouped into 250 equally wide series for 0
1000;
each ¯t series having 100 equal-width bins with 0
δt

t2 −

t1|

2¯t.

≤

≤

¯t

|

The characteristic time diﬀerence, δtc, required for the scaled intensity covariance, Cov(t1, t2), to decay to half its
maximum value can be found as a function of ¯t. (The normalized correlation function, Corr(t1, t2), does not decay
to 1/2 for small values of ¯t .) Here, results for M1 and M2 for 0
2 (in 10 series, with 25 bins within each
series) were collected in addition to those previously mentioned. The value of δtc for each ¯t was determined by linear
interpolation, and the dependence of δtc on ¯t is presented in log-log form in Fig. 5. In this ﬁgure, two asymptotic
limits giving diﬀerent algebraic relationships are obvious. For small values of ¯t the relationship is linear, with the
0.01 for ¯t < 1. At large values of ¯t, a least-squares ﬁt for ¯t > 200
exponent determined by least squares being 1.00
0.02. The estimates of error here are from obtaining the exponents from diﬀerent ranges
gives an exponent of 0.49

±

≤

≤

¯t

≤

≤

±

5

of ¯t in the simulation data; statistical error is an order of magnitude smaller than these estimates. The exponents
we obtain are in good accord with theories discussed in Sec. V below, which give them to be 1 and 1/2, respectively.
However, the connection to theory requires some further justiﬁcation, given in the following section.

IV. CORRELATIONS IN THE SCATTERING MATERIAL

While experiments can measure time correlations readily through the covariance or the correlation of intensities, Cov

or Corr, theories to date have made use of the two-point, two-time order-parameter correlation function, C(r, τ1, τ2)
≡
ψ(0, τ1)ψ(r, τ2)
. In this section we argue for, and empirically demonstrate, equality between the intensity covariance
h
i
for k
= 0, which involves fourth moments of the order parameter, and the square of the spatial Fourier transform of
the two-time order-parameter correlation function in our model.

The relationship is exact when ˆψ(k) is a joint Gaussian random number, with its real and imaginary parts in-
dependent and Gaussian, as we will show below. However, establishing ˆψ(k) to be approximately Gaussian in the
present case is not trivial. Gaussian variables are a natural consequence of the central-limit theorem, which requires a
large number of uncorrelated contributions to the variable (with some restrictions on the properties of the individual
contributions). For example, in a disordered system in equilibrium, correlations exist only on the scale of a small
length ξ, so a system of edge-length L consists of on the order of (L/ξ)d independent, uncorrelated parts. Then the
central-limit theorem applies, and ˆψ(k) is a complex, Gaussian variable. For an ordered system in equilibrium, this
argument applies to the ﬂuctuations around the ordered state. The present nonequilibrium situation has some rough
analogies to a disordered equilibrium state. At a given time, the average domain size is R(τ ), and so the number of
independent parts at a given time is approximately (L/R(τ ))d, which can be large. It therefore seems reasonable to
expect the central-limit theorem to apply, and indeed, we ﬁnd empirically that ˆψ(k) is Gaussian. However, unlike a
disordered system, the distribution of domains of diﬀerent sizes is broad in this case due to the initial long-wavelength
instability and, furthermore, it is clear that domains interact as they grow. The degree to which this correlation
is important is a nontrivial issue; below, we test it numerically and ﬁnd these correlations to be negligible for the
two-point quantities of interest in this work.

If ˆψ(k) is Gaussian, it is straightforward to relate the intensity covariance Covk to the order-parameter correlation

function C. Wick’s theorem can be used to decompose the intensity-intensity average as

I(k, τ1)I(k, τ2)
E

D

=

=

D

∗
ˆψ(k, τ1) ˆψ

∗
(k, τ1) ˆψ(k, τ2) ˆψ

∗
ˆψ(k, τ1) ˆψ

(k, τ1)

D

D

+

+

∗
ˆψ(k, τ1) ˆψ

(k, τ2)

ED

∗
ˆψ

ˆψ(k, τ1) ˆψ(k, τ2)

ED
∗
ˆψ

(k, τ2)
E
∗
ˆψ(k, τ2) ˆψ

(k, τ2)
E
(k, τ1) ˆψ(k, τ2)
E
(k, τ2)
E

∗
(k, τ1) ˆψ

= (1 + δk,0)S2(k, τ1, τ2) + S(k, τ1)S(k, τ2) .

ED

D

Here S(k, τ1, τ2) is the two-time structure factor corresponding to the two-point, two-time order-parameter correlation
function

S(k, τ1, τ2) =

∗
ˆψ(k, τ1) ˆψ

(k, τ2)
E

C(r, τ1, τ2) .

dreik·r

=

D

Z

For k

= 0, Eq. (4.3) can be rewritten as

Covk(k, τ1, τ2) = S2(k, τ1, τ2) ,

which equates the speckle intensity covariance with the square of the two-time structure factor of the system. Finally,
the scaling ansatz deﬁnes a universal two-time form

and

F2(t1, t2) = kdS(k, τ1, τ2)

Cov(t1, t2) = F 2

2 (t1, t2) .

6

(4.7)

(4.8)

(4.1)

(4.2)

(4.3)

(4.4)

(4.5)

(4.6)

6
6
Our numerical tests show that this equality holds well in these simulations for k

= 0. In computer simulations,
unlike scattering experiments, the two-time structure factor can be found directly using Eq. (4.4). Generally, the
product ˆψ(k, τ1) ˆψ∗(k, τ2) is a complex number, but the mean value of the imaginary part is zero, so the two-time
structure factor is real valued. In our simulation data, the imaginary part of S(k, τ1, τ2) is found to be zero, within
our accuracy. Results for the real part at τ1 = 25 and τ2 = 50 are presented on a log-log scale in Fig. 6. The direct
measurements of the two-time structure factor and the square-root of the intensity covariance agree quite well, except
at very large values of k, where lattice eﬀects are important.

Another consequence of our proposed decoupling, leading to the relationship between Covk and S, can be tested

by simulation. When τ1 = τ2, Eq. (4.6) is simply

I 2(k, τ )

I(k, τ )
i

− h

2 =

I(k, τ )
i
h

2 ,

(4.9)

(cid:10)

(cid:11)

Cov(t, t). These are compared in Fig. 7, where the agreement
and scaling can be applied to give F1(t) = F2(t, t) =
is clearly quite good. As an aside, since the variance does not depend on the system size, Eq. (4.9) demonstrates
that I(k, τ ) is a spatially non-self-averaging quantity [21]. Because of this, increasing the system size L will not
improve the estimate of S(k, τ ) given by a speciﬁc number of speckles. However, this is compensated by the fact that
more independent speckles are available in a given range of k for each trial. Numerical results obtained by Shinozaki
and Oono in a study of spinodal decomposition in three dimensions using the cell-dynamical method appear to be
consistent with this result [22]. We also note that the normalization of the two-time intensity correlation function,
Eq. (3.3), can be simpliﬁed using Eq. (4.9).

p

Equation (4.9) is a property of exponentially distributed variables, and to the extent that ˆψ(k, τ ) is a Gaussian
random number, I(k, τ ) will be an exponentially distributed random number. That is, the probability density for the
normalized intensities, s(k, τ ) = I(k, τ )/S(k, τ ), should satisfy

P (s) = exp (

−

s) ,

(4.10)

independent of (k, τ ). The probability density P (s) is normalized and has unit mean and standard deviation. Since
P (s) is identical for all values of (k, τ ), only one density function needs to be constructed. The results for all
0.024 < k(k) < 0.75 are presented for two times in log-linear form in Fig. 8. The histogram for s is constructed
with a bin size of 0.1, and the normalized intensity is found using the circular average of I(k, τ ) from the same trial.
The lower bound on k is chosen such that at least 20 speckles contribute to this circular average. This histogram is
accumulated over all 100 trials and then normalized; for each histogram on the order of 106 samples are available.
s). For the earlier time the probability density is exponential for
The solid line is the expected density, P (s) = exp(
all s. At the latest simulation time the density is exponential only for s <
5, with a higher than expected occurrence
∼
of speckles brighter than this. Still, less than 0.5% of the points lie this far into the tail, and the deviation is inferred
to be a ﬁnite-size eﬀect because it becomes more pronounced as our simulation continues. This agrees with earlier
simulations [15], in which increasing the system size eliminated the deviation. We believe this eﬀect is an artifact of
the periodic boundary conditions which allow stabilization of slab-like domain patterns [23], producing “frozen-in”
interference patterns that remain bright while the average intensity steadily decreases. No k dependence is found for
P (s).

−

V. TWO-TIME THEORIES

Two theoretical predictions for the two-point, two-time order-parameter correlation function exist, which will be
described and then compared to our simulation results. The ﬁrst is an analytic theory, due to Yeung and Jasnow [24],
which is an extension of the analysis by Ohta, Jasnow and Kawasaki [18,25]. The second theory, developed by Liu
and Mazenko [26], is numerical. Both theories produce approximations for the two-point, two-time order parameter
correlation function, C(r, τ1, τ2), in the asymptotic limit. These then give the structure factor through the general
relation for the Fourier transform of a spherically symmetric function f (r) in d dimensions,

0
Z
where Jν is a Bessel function of the ﬁrst kind of order ν.

Z

dreik·r

f (r) = (2π)

−d

d
2 k

∞

du u

d
2 J d

2

−1(u) f (u/k) ,

(5.1)

In the scaling regime, where the domain-wall thickness can be ignored, the Yeung-Jasnow correlation function is

[24],

7

6
CYJ(r, τ1, τ2) =

2
π

arcsin

With the previously deﬁned variables, δt =

""(cid:18)
t1 −

|

2R(τ1)R(τ2)
R(τ1)2 + R(τ2)2

d
2

exp

(cid:19)

(cid:18)

r2
−
R(τ1)2 + R(τ2)2

.

(cid:19)#

and ¯t = (t1 + t2)/2, this yields

t2|

F2,YJ(δt, ¯t ) =

∞

du u

(2π)

d
2

2
π

0
Z

d

2 J d

2

−1(u) arcsin

"" 

1

−

2

δt
2¯t
(cid:17)

(cid:16)

!

d
4

exp

u2
−
2¯t

(cid:16)

,

#

(cid:17)

Expansion of arcsin(x) about x = 0, followed by term-wise integration, gives

F2,YJ(δt, ¯t ) =

(2π)

d

2 ¯t

d
2

2
π

∞

j=0
X

d(2j+1)
4

2

(2j)!

1

δt
2¯t

−
(cid:17)
22j(j!)2(2j + 1)
(cid:0)

(cid:16)

(cid:1)

d+2
2

exp

−

(cid:18)

¯t
2(2j + 1)

.

(cid:19)

(5.2)

(5.3)

(5.4)

This inﬁnite series is convergent for all physical values of δt and ¯t; however, its terms are in general nonmonotonic
in j. Only as one or both of the scaled times t1 and t2 approaches zero, is the series well approximated by the j=0
term. The asymptotic early-time form,

F2,YJ(δt, ¯t )

2
π

≈

(2π)

d
2

1

−

d
4

¯t

d
2 exp

¯t
2

−

2

δt
2¯t
(cid:17)

!

(cid:17)
is therefore a good approximation to Eq. (5.3) only in the very restricted region,

(cid:16)

(cid:16)

,

(5.5a)

1

0

≤

−

(cid:18)

2

δt
2¯t

(cid:19)

2
d 3 exp

6

≪

2¯t
−
3d

(cid:19)

(cid:18)

,

(5.5b)

near the t1 and t2 axes or the origin.

A more useful, analytical result is obtained in the limit of large ¯t and small δt. Then, the largest terms in the series
occur in a relatively wide range of j near ¯t/2(d + 3). For large ¯t, the exponential factors in Eq. (5.4) suppress the
small-j terms. The series can then be converted to an integral, and the factorials can be approximated by Stirling’s
formula to give

F2,YJ(δt, ¯t )

≈

d−3
2 4

d+1

2 ¯t

− 1
2

π

∞

0
Z

d−1
2

dw w

1

−

(cid:18)

δt
2¯t

(cid:19)

¯td
8w

2

exp (

−

w) .

!

The identity limm→∞(1

x/m)m = exp(

−

−

x) is used to obtain the explicitly integrable form,

F2,YJ(z, ¯t )

≈

d−3
2 4

d+1

2 ¯t

− 1
2

π

∞

0
Z

dw w

d−1
2 exp

z2d
32w

−

(cid:20)

(cid:18)

+ w

,

(cid:19)(cid:21)

(5.6)

(5.7)

where z = δt/√¯t. We note that the full Yeung-Jasnow result, Eq. (5.3), as well as the early-time approximation,
Eq. (5.5a), depends on δt only through the scaling combination δt/¯t. However, in the asymptotic late-time approx-
imation, Eq. (5.7), the natural scaling combination is z = δt/√¯t. As we shall see below, this analytical result is in
excellent agreement with our numerical simulations. Equation (5.7) is readily integrated to yield the explicit large-¯t
asymptotic scaling function,

¯t

1

2 F2,YJ(z, ¯t )

≈

d−3
2 2

π

d+3
2

z

d+1
2

d
8 !

r

K d+1

2  

d
8 !

,

z

r

(5.8)

where Kn is a modiﬁed Bessel function of the second kind. The right-hand side of this equation depends only on z.
In this large-¯t limit, the asymptotic forms of this scaling function with respect to z are

¯t

1

2 F2,YJ(z, ¯t ) =






d−3
2 Γ

π

d+1
2

d+1
2

4

d−2
2 2

π

(cid:16)
d+2
2

(cid:17)
z

d
(cid:16)
2

d
8

1

−
exp

1
16

d

d−1 z2

z

−

(cid:17)
d
8

q

(cid:17)

(cid:16)

q

(cid:17)

(cid:16)

8

for z

for 1

1

z

≪

≪

.

2√¯t

≪

(5.9)

 
 
 
The ﬁrst line of this equation is exact for z = 0, where it gives the asymptotic Porod-tail limit of the Ohta-Jasnow-
Kawasaki result for t1/2F1(t). Note that, in the limit δt = 2¯t, the second line gives a nonzero value, in contrast to the
proper result given in Eq. (5.5a). When z is on the order of √¯t, F2,YJ diverges from the small-z approximation given
in Eq. (5.9).

A nonrigorous scaling argument [28] suggests that the order-parameter correlation function should depend on
δt/¯t (1−n), when δt
¯t. The scaling variable z obtained above
wavevector and time through k
is consistent with this since n = 1/2 for Model A. In fact, the z = δt/¯t (1−n) result is obtained in the asymptotic
large-¯t limit if one repeats the above calculation for general n, considering the Yeung-Jasnow form for the correlation
function, Eq. (5.2), simply as an integrable approximation valid for small r.

R(τ1)

R(τ2)

| ∝

≪

−

|

The second theory for two-time correlations in Model A is due to Liu and Mazenko [26]. It is an extension of a
theory developed by Mazenko [27] to predict the universal part of the two-point, one-time scaled order-parameter
correlation function C(r/R(τ )). The heart of the Liu-Mazenko theory is the scaling ansatz

and the partial diﬀerential equation

C

r, τ1, τ2

= CLM

r/R(τ2), τ2/τ1

(cid:16)

(cid:17)

(cid:16)

(cid:17)

(5.10)

∂CLM(x, τ ′)
∂τ ′

′

1
µ∗ tan

π
2

′

=

) +

2
∇

) + 2x

xCLM(x, τ

· ∇xCLM(x, τ
In Eq. (5.11), CLM is considered a function of the rescaled variables x = r/(2√τ ) and 4τ ′ = ln (τ2/τ1). Note that
these deﬁnitions are in terms of the physical quantities, but the connections to the rescaled variables used in this
work are straightforward. We have found numerical solutions in terms of Liu and Mazenko’s units, which we then
converted so that all results shown here are in terms of the rescaling given in Section II. The Mazenko theory for
one-time correlations [27] serves to provide input into the Liu-Mazenko model through the scaled order-parameter
correlation function CM(x) = CLM(x, τ ′=0) and the numerically obtained eigenvalue µ∗. Since the system is assumed
isotropic, Eq. (5.11) can be reduced to a single partial diﬀerential equation in terms of a radial distance x and the
logarithmic time ratio τ ′.

CLM(x, τ

(5.11)

(cid:17)

(cid:16)

)

.

′

The scaled order-parameter correlation function in the Liu-Mazenko theory is normalized to CLM(0, 0) = 1, which
causes the tangent term in Eq. (5.11) to diverge. Use of the transformation G = sin (πC LM/2) leads to the small-time
solution

CLM(0, τ

′

) =

2
π

arcsin

exp

π
2µ∗(d

′

τ

.

!!

1)

−

  −

(5.12)

This solution is only needed to avoid numerical diﬃculties at x = 0 for the ﬁrst time increment. Aside from this,
Eq. (5.11) can be solved numerically using a ﬁnite diﬀerencing scheme that is implicit with respect to the derivatives,
but evaluates the tangent term explicitly. Using ∆x = 0.01µ∗ and ∆τ ′ = 10−5 we have reproduced Fig. 1 of
Ref. [26]. In addition, the exponent for the autocorrelation CLM(0, τ ′) (which will be discussed later) is recovered.
The Liu-Mazenko results can be compared to the theory presented here by taking ¯t to be a parameter and noting
that δt = 2¯t tanh (2τ ′). The two-time structure factor predicted by the Liu-Mazenko theory, found using the Fourier
transform in Eq. (5.1), is

F2,LM(δt(¯t, τ

′

), ¯t ) = (2π)

d
2

2¯t
ρd(1 + exp (

−

d+2
4

4τ ′)) !

×

∞

0

Z

dx x

d
2 J d

2

−1

x

s

2¯t
ρd(1 + exp (

−

C LM(x, τ

4τ ′)) !

′

) ,

(5.13)

where the scaling function CLM(x, τ ′) itself depends on d.

The two-point, two-time order-parameter correlation functions predicted by the two theories can be compared
directly with our simulation, without adjustable parameters. Both theories describe the data well in some instances,
and poorly in others. Our results are presented in Fig. 9 for τ1 = 100 and τ2 = 200. Data from our simulation are
circularly averaged with bins of width one in the rescaled distance units, then averaged over 80 trials. The agreement
between the Yeung-Jasnow theory and our simulation is quite good for this choice of times, while the Liu-Mazenko
result is only qualitatively correct.

9

 
 
 
For larger separations in time, the Yeung-Jasnow theory does not work as well, most noticeably in predicting the

autocorrelation function,

A(τ1, τ2)
which is equivalent to C(r = 0, τ1, τ2). Fisher and Huse [29] have argued that for τ2 ≫
the power-law

ψ(r, τ1)ψ(r, τ2)
i

≡ h

,

(5.14)

τ1 the autocorrelation obeys

[R(τ1)/R(τ2)]λ

λ

≤

≤

∝

=

∼

2n tanh

A(τ1, τ2)

τ n, the variables used in this paper give ln

0.02 for d = 2. A recent experiment [30] found λ = 1.246

(5.15)
−1 δt/2¯t.)
R(τ1)/R(τ2)
for late times. (Note that, since R
d. They point out that λ = 1 for the d = 1 Glauber model
Fisher and Huse give physical arguments for d/2
(cid:3)
τ1, the Yeung-Jasnow
and conjecture that λ = 5/4 for the two-dimensional spin-ﬂip Ising model. In the limit τ2 ≫
theory gives λ = d/2, as is easily seen by setting r = 0 in Eq. (5.2). The Liu-Mazenko theory yields λ
1.2887 and
1.6726 for two and three dimensions, respectively [26]. Cell-dynamical simulations performed by Liu and Mazenko
[26] gave λ = 1.246
0.079 for a two-dimensional nematic
liquid crystal using video techniques. For our simulations we measured A(τ1, τ2) for several values of τ1. The results
are presented on a log-log scale versus τ2/τ1 in Fig. 10.
[In this measurement we did not employ the nonlinear
transformation ψ
sign(ψ). This accounts for the fact that A(τ1, τ1) < 1, but does not otherwise seem to aﬀect
the results.] In the ﬁgure, the data appear to support a power-law decay at the latest time, and the exponent found
by ﬁtting the 48 points τ2 > 1800 for τ1 = 20 is λ
1.24, which is in good agreement with the experiment and the
simulations by Liu and Mazenko. However, the local eﬀective value of λ, λeﬀ = 2d ln A/d ln(τ1/τ2), which is shown
vs. τ2/τ1 in the inset in Fig. 10, does not show a clear convergence to an asymptotic limit, especially for larger values
of τ1. Here λeﬀ is obtained as a three-point ﬁnite-diﬀerence estimate around τ2, but estimates that smooth the data
over wider intervals yield similarly irregular results. The estimates of λ obtained from our present simulations are
thus somewhat uncertain. However, the Yeung-Jasnow prediction, λ = 1, is clearly violated.

→

≈

−

≈

±

±

(cid:2)

The predictions of the two theories for the two-time structure factor are compared to our simulation data in Fig. 6.
The Liu-Mazenko theory is in semi-quantitative agreement with our simulations at small k, but falls oﬀ much more
rapidly at large k. In addition the shoulder present both in our simulation result and in the Yeung-Jasnow theory
is absent in the Liu-Mazenko result. The Yeung-Jasnow theory agrees much better with our simulation, although it
does not fall oﬀ as fast at large k, and its overestimation around the shoulder is seen consistently throughout our
simulations.

0.002 and ˜D3 = 1.633

The prediction for the characteristic scaled time separation, δtc, deﬁned in Sec. III, for both theories is compared
to our simulation results in Fig. 5. All three agree that δtc = ˜Dd¯t for small ¯t. Least-squares ﬁts give ˜D2 = 1.36
0.02
±
for our simulation, ˜D2 = 1.325
0.02 for Liu-
±
Mazenko. At large ¯t, the δtc = Dd¯t 1/2 behavior of the Yeung-Jasnow approach results naturally from Eq. (5.8). This
2.187 in two and three dimensions, respectively. Our
equation can be solved numerically to ﬁnd D2 ≈
simulation results give D2 = 2.12
0.01. The value of ¯τ separating the two scaling behaviors corresponds quantitatively
to the value for which the ﬁrst term no longer dominates the series expansion of the Yeung-Jasnow result, given by
the relation (5.5b). The agreement between the Yeung-Jasnow theory and our simulation is quite remarkable. On the
other hand, for ¯t not small the Liu-Mazenko theory crosses over to a region where δtc is independent of ¯t and then
into another linear region; neither of these relationships is seen in our simulations.

0.006 for Yeung-Jasnow, and ˜D2 = 1.00

2.156 and D3 ≈

±

±

±

The analytic expression for the universal form of the two-time structure factor deduced from the Yeung-Jasnow
theory for large ¯t is given in Eq. (5.8). It is tested for several values of ¯t in Fig. 11, which shows good collapse of
the simulation data for ¯tCov(δt, ¯t ) in terms of the scaling variable z = δt/¯t 1/2. The data also agree quite well with
the Yeung-Jasnow scaling function, ¯tF 2
2,YJ for z < 5. Indeed, the slow quadratic decay of correlations near z = 0 is
another signature of persistence in the phase-ordering system. In contrast, Brownian ﬂuctuations give exponential
decay from δt = 0. The agreement with the Yeung-Jasnow theory is remarkable since the scaling of the simulation
data uses an analytic expression for the characteristic length, and no adjustable parameters are employed.

VI. CONCLUSIONS

Using both numerical and analytic methods, we have investigated time-time correlations in the scattering intensity
for a two-dimensional system undergoing an order-disorder transition. The correlations are found to obey scaling in
and ¯t = (t1 + t2)/2. In the large ¯t limit, the correlation data collapse onto a
terms of the variables δt =
universal curve which is a function only of δt/√¯t.

t2 −

t1|

|

We argue for, and establish numerically, an exponential distribution for the scattering intensity, Eq. (4.10), and
equality between the scattering intensity covariance and the square of the two-time structure factor of the order

10

parameter, Eq. (4.6), for k
= 0. We use this equality to test theories for the two-time structure factor due to Yeung
and Jasnow, and Liu and Mazenko. Both theories describe the data well in some instances, and poorly in other
cases. The Yeung-Jasnow theory is very similar to our simulation results, so long as δt is not too large. For τ2 ≫
τ1,
the Liu-Mazenko theory gives a better estimate for the autocorrelation exponent λ. For large ¯t, however, the Liu-
Mazenko theory does not show the same scaling as our simulation results, where the Yeung-Jasnow theory compares
quantitatively well.

Our numerical simulations indicate that a deﬁnitive experimental treatment of time-correlations during an order-
disorder transition is possible by intensity-correlation spectrometry of scattering speckle. Analysis of experimental
correlation data should be similar to the procedures discussed for the simulation data in Sec. III. For non-conserved
systems, the experimental scaling function should be well approximated by Eq. (5.5a), for small k, with one adjustable
parameter for each axis. With a similar adjustable parameter scheme, the scaling function should be described by
Eq. (5.8) for data in the Porod tail.

Finally, we expect that the equality between the intensity covariance and the squared two-time structure factor
also occurs in other phase-ordering systems; in particular, we expect that it occurs for conserved systems. That
would allow the experimental study of, for example, time correlations in binary alloys undergoing phase separation
by spinodal decomposition, which are representative of Model B. Indeed, preliminary numerical work we have done
indicates this. Experiments on such systems would be of considerable value.

ACKNOWLEDGMENTS

We would like to acknowledge useful discussions with K. Kawasaki, Y. Oono, M. M. Sano, H. Tomita, and partic-
ularly B. Morin and K. R. Elder. P. A. R. is grateful for hospitality and support at McGill and Kyoto Universities.
Research at McGill University was supported by the Natural Sciences and Engineering Research Council of Canada
and le Fonds pour la Formation de Chercheurs et l’Aide `a la Recherche du Qu´ebec. Research at Florida State Univer-
sity was supported by the Center for Materials Research and Technology and by the Supercomputer Computations
Research Institute (under U.S. Department of Energy Contract No. DE-FC05-85ER25000), and by U.S. National
Science Foundation grants No. DMR-9315969 and DMR-9634873. P. A. R.’s stay at Kyoto University was supported
by the Japan Foundation’s Center for Global Partnership through U. S. National Science Foundation Grant No. INT-
9512679. Supercomputer time at the U. S. National Energy Research Supercomputer Center was made available by
the U. S. Department of Energy.

[1] M. Sutton, S. E. Nagler, S. G. Mochrie, T. Greytak, L. E. Bermann, G. Held, and G. B. Stephenson, Nature, 352, 608

(1991).

[2] A comprehensive review is given by J. D. Gunton, M. San Miguel and P. S. Sahni, in Phase Transitions and Critical
Phenomena, Vol. 8, edited by C. Domb and J. L. Lebowitz (Academic, London, 1983). Ideas of scaling in domain growth
follow similar ideas in critical dynamics, P. C. Hohenberg and B. I. Halperin, Rev. Mod. Phys. 49, 435 (1977). A recent
specialized review is given by A. J. Bray, Adv. Phys. 43, 357 (1994).

[3] S. E. Nagler, R. F. Shannon, Jr., C. R. Harkless, and M. A. Singh, Phys. Rev. Lett. 61, 718 (1988); R. F. Shannon, Jr.,

S. E. Nagler, C. R. Harkless, and R. M. Nicklow, Phys. Rev. B 46, 40 (1992).

[4] C. Roland and M. Grant, Phys. Rev. Lett. 63, 551 (1989).
[5] B. Chu, Laser Light Scattering (Academic Press, New York, 1974).
[6] L. Mandel and E. Wolf, Optical Coherence and Quantum Optics (Cambridge University Press, Cambridge, 1995).
[7] S. B. Dierker, R. Pindak, R. M. Fleming, I. K. Robinson, and L. Berman, Phys. Rev. Lett. 75, 449 (1995).
[8] B. Chu, Q.-C. Ying, F.-J. Yeh, A. Patkowski, W. Steﬀen, and E. W. Fischer, Langmuir 11, 1419 (1995).
[9] S. Brauer, G. B. Stephenson, M. Sutton, R. Br¨uning, E. Dufresne, S. G. J. Mochrie, G. Gr¨ubel, J. Als-Nielsen, and D. L.

Abernathy, Phys. Rev. Lett. 74, 2010 (1995).

[10] S. G. J. Mochrie, A. M. Mayes, A. R. Sandy, M. Sutton, S. Brauer, G. B. Stephenson, D. L. Abernathy, and G. Gr¨ubel,

Phys. Rev. Lett. 78, 1275 (1997).

[11] E. Hern´andez-Garc´ıa and M. Grant, J. Phys. A 25, L1195 (1993).
[12] E. Dufresne, Ph. D. thesis (McGill University, 1995); E. Dufresne, M. Sutton, K. Elder, B. Morin, M. Grant, B. Rodricks,
G. B. Stephenson, G. B. Held, C. Thompson, S. G. J. Mochrie, S. E. Nagler, L. E. Berman, and R. Headrick (preprint,
1997).

[13] J. Feder, Fractals (Plenum Press, New York, 1988).

11

6
[14] A rough, quantitative measure of the diﬀerent degrees of persistence can be obtained by application of Range/Scale (R/S)
analysis [13] to the short sample time series shown in Fig. 3. This yields a Hurst exponent of approximately 0.54 for
the “Brownian” function (near the expected value of 1/2), and a signiﬁcantly larger value of approximately 0.74 for the
normalized scattering intensity. However, the correlation times of these normalized time series are slowly increasing. Thus,
the processes are not stationary, and the direct application of R/S analysis is only to be regarded as an approximate way
of estimating the degree of persistence.

[15] G. Brown, P. A. Rikvold, and M. Grant, Physica A 239, (1997).
[16] Y. Oono and S. Puri, Phys. Rev. Lett. 58, 836 (1987).
[17] H. Tomita, Prog. Theor. Phys. 85, 47 (1991).
[18] T. Ohta, D. Jasnow, and K. Kawasaki, Phys. Rev. Lett. 49, 1223 (1982).
[19] K. Kawasaki, M. C. Yalabik, and J. D. Gunton, Phys. Rev. A 17, 455 (1978).
[20] It is natural to normalize the covariance by the standard deviations. In dynamic light-scattering, the autocorrelation

function is normalized by the average intensity. For random Gaussian ﬂuctuations, these are equal. See Eq. (4.9).

[21] A. Milchev, K. Binder, and D. W. Heermann, Z. Phys. B 63, 521 (1986).
[22] A. Shinozaki and Y. Oono, Phys. Rev. E 48, 2622 (1993).
[23] N. B. Wilding, C. M¨unkel and D. W. Heerman, Z. Phys. B, 94, 301 (1994).
[24] C. Yeung and D. Jasnow, Phys. Rev. B 42, 10523 (1990).
[25] T. Ohta, Ann. Phys. (NY) 158, 31 (1984).
[26] F. Liu and G. F. Mazenko, Phys. Rev. B 44, 9185 (1991).
[27] G. F. Mazenko, Phys. Rev. B 42, 4487 (1990).
[28] C. Yeung, M. Rao and R. C. Desai, Phys. Rev. E 53, 3073 (1996).
[29] D. S. Fisher and D. A. Huse, Phys. Rev. B 38, 373 (1988). See also, S. N. Majumdar, D. A. Huse, and B. D. Lubachevsky,

Phys. Rev. Lett. 73, 182 (1994).

[30] N. Mason, A. N. Pargellis, and B. Yurke, Phys. Rev. Lett. 70, 190 (1993).

12

FIG. 1. A typical conﬁguration of domains, taken from one of the simulations reported here. Here all systems are 1024

and this picture is for the latest simulation time, τ = 2000.

1024,

×

FIG. 2. Example of the speckled scattering intensity; this pattern corresponds to the domain structure shown in Fig. 1. The
200 section from
intensity is shown on a logarithmic scale with darker shades indicating brighter speckles. This is a 200
1024 pattern with the k = 0 origin at the center of the ﬁgure. Speckles do not shift in k-space, but their
the full 1024
intensities ﬂuctuate strongly around the (k, τ )-dependent average value. The rays are present in individual patterns, but are
not correlated between trials.

×

×

13

)
τ
(
s

4

3

2

1

0

0

Brownian
I(k,τ)/S(k,τ)

100

200

300

400

500

τ

FIG. 3. Time evolution of the scattering intensity at one wavevector for one quench to zero temperature. The intensity
has been normalized by the time-dependent structure factor determined over all 100 simulations considered here. The dotted
line is a synthetic “Brownian” function constructed to have an exponential single-time probability density and an exponential
two-time covariance with a characteristic time corresponding to that of the simulated intensity. Compared to the “Brownian”
function, the persistence of the scattering intensity is apparent [13,14].

FIG. 4. Contour plot of the scaled two-time intensity correlation function, Corr(t1, t2). The correlation at t1 = t2 is unity by
construction. The contours moving away from this diagonal are at 0.7, 0.2, 0.07, and 0.02. The ﬁgure shows that the speckle
intensity stays correlated for larger values of δt =

as ¯t = (t1 + t2)/2 increases.

t1

t2
|

−

|

14

102

101

100

c

t
δ

Simulation
Liu−Mazenko
Yeung−Jasnow
_
1.325 t_
2.156 t1/2

10−1

10−1

100

101

102
_
t

103

104

105

FIG. 5. The characteristic decay time diﬀerence, δtc, as a function of ¯t = (t1 + t2)/2. Power-law behavior is seen at small and
large values of ¯t. Least-squares ﬁts to the simulation data yield a linear relationship at small ¯t and δtc
1/2 at large
1.325¯t,
¯t. The heavy solid line is the analytic prediction of the Yeung-Jasnow theory. The broken line is its small-¯t limit δtc
and the light solid line is the large-¯t approximation δtc
2.156√¯t. The the ¯t associated with the change in behavior agrees well
with Eq. (5.5b). The results of the Liu-Mazenko theory are represented as circles connected by a dot-dashed line; least-squares
ﬁts show them to be nearly linear at both small and large ¯t.

¯t α with α

≈

≈

∼

≈

103

102

101

100

10−1

10−2

10−3

)

2

τ
,

1

τ
,
k
(
S

10−4

10−2

S(k,25,50)
(Covk(k,25,50))1/2
Yeung−Jasnow
Liu−Mazenko

10−1

k

100

FIG. 6. The two-time structure factor for τ1 = 25 and τ2 = 50. The simulation results are found directly as S(k, τ1, τ2)
Covk(k, τ1, τ2) (diamonds). The Liu-Mazenko theory agrees semi-quantitatively at small k. The

(squares), and indirectly as
Yeung-Jasnow theory agrees much better, even reproducing the second shoulder qualitatively.

p

15

100

)
t
(

1
F

10−1

<M1(t)>
(Cov(t,t))1/2
Mazenko
OJK

10−2

10−2

10−1

100

101

102

103

t

FIG. 7. Estimates of the scaling function for the structure factor, F1(t), obtained from the simulation data using the average
scaled scattering intensity,
Cov(t, t) (diamonds). The agreement between
the two measurements is a direct consequence of the intensity being an exponentially distributed random variable. The forms
obtained from the Yeung-Jasnow (solid line) and Mazenko (dashed line) theories are also included.

(circles), and the square-root of its variance,

M1(t)

p

i

h

100

10−1

10−2

10−3

10−4

)
s
(
P

10−5

0

τ=100
τ=2000

5

10

15

s

FIG. 8. The probability density of the normalized speckle intensity, s = I(k, τ )/S(k, τ ), for τ = 100 (circles) and τ = 2000
(triangles). The solid line is the theoretical density of an exponentially distributed random variable. The deviation at large s
of the latest time result is due to ﬁnite-size eﬀects.

16

100

)

2

τ
,

1

τ
,
r
(

C

10−1

10−2

10−3

0

Simulation
Yeung−Jasnow
Liu−Mazenko

1

2

3

r/R(τ

2)

FIG. 9. The two-time correlation function C(r, τ1, τ2) with τ1 = 100 and τ2 = 200 presented on a semi-log scale. The
characteristic length R(τ2) is determined analytically as described in the text. The agreement between the simulation (circles)
and the Yeung-Jasnow theory (solid line) is quite good for this choice of parameters; the Liu-Mazenko theory (dashed line) is
noticeably diﬀerent. The agreement between simulations and Yeung-Jasnow is not as good for larger time separations.

1.0

)

2

τ
,

1

τ
(
A

1.3

1.2

f
f

e

λ

1.1

1.0

0.9

0

τ
τ
τ
τ

1=20
1=50
1=100
1=200

50
2/τ
τ

1

100

0.1

100

101
2/τ
τ

1

102

≈

FIG. 10. The autocorrelation function A(τ1, τ2). A least-squares ﬁt for τ2 > 1800 for the τ1 = 20 data gives the exponent
λ
1.24. Fits for later τ1 give progressively smaller values, but are still larger than 1. The latest time value is approached
from below, and the asymptotic value may not be obtained for the simulation times considered here. For two dimensions, the
Liu-Mazenko value of λ is found numerically to be approximately 1.2887, while a recent experiment gives 1.246
0.079. The
Yeung-Jasnow prediction is unity. The local eﬀective exponent, λeﬀ, estimated from a three-point ﬁnite diﬀerence appear in
the inset. They characterize the uncertainty in our estimate of λ, but show that the Yeung-Jasnow prediction is violated.

±

17

_

)
t
,
t
δ
(
v
o
C

_

t

16

12

8

4

0

0

_
t=102
_
t=202
_
t=302
_
t=402
_
t=502
_
t=602
_
t=702
_
t=802
_
t=902
_
t=998
(32/π)[(z/2)3/2K3/2(z/2)]2

5
_
z=δt/t 1/2

10

FIG. 11. Plot of the intensity-covariance scaling function, ¯tCov(δt, ¯t ), versus z = δt/√¯t for diﬀerent values of ¯t. The data
2,YJ(δt, ¯t ),

collapse onto a single curve for a large range of ¯t. The solid curve is the corresponding analytic scaling function, ¯tF 2
predicted from the Yeung-Jasnow result in Eq. (5.8). It agrees quite well with the simulation data.

18"
Domain Dynamics of Magnetic Films with Perpendicular Anisotropy,"  We study the magnetic properties of nanoscale magnetic films with large
perpendicular anisotropy comparing polarization microscopy measurements on
Co_28Pt_72 alloy samples based on the magneto-optical Kerr effect with Monte
Carlo simulations of a corresponding micromagnetic model. We focus on the
understanding of the dynamics especially the temperature and field dependence
of the magnetisation reversal process. The experimental and simulational
results for hysteresis, the reversal mechanism, domain configurations during
the reversal, and the time dependence of the magnetisation are in very good
qualitative agreement. The results for the field and temperature dependence of
the domain wall velocity suggest that for thin films the hysteresis can be
described as a depinning transition of the domain walls rounded by thermal
activation for finite temperatures.
",http://arxiv.org/pdf/cond-mat/9706253v1,2,"7
9
9
1

n
u
J

5
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
3
5
2
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Domain Dynamics of Magnetic Films with Perpendicular Anisotropy

U. Nowak
Theoretische Tieftemperaturphysik, Gerhard-Mercator-Universit¨at Duisburg, 47048 Duisburg, Germany
e-mail: uli@thp.uni-duisburg.de

J. Heimel and T. Kleinefeld
Angewandte Physik, Gerhard-Mercator-Universit¨at Duisburg, 47048 Duisburg, Germany

D. Weller
IBM Almaden Research Center, San Jose/CA, USA
(July 18, 2018)

We study the magnetic properties of nanoscale magnetic
ﬁlms with large perpendicular anisotropy comparing polar-
ization microscopy measurements on Co28Pt72 alloy samples
based on the magneto-optical Kerr eﬀect with Monte Carlo
simulations of a corresponding micromagnetic model. In our
model the magnetic ﬁlm is described in terms of single-domain
magnetic grains, interacting via exchange as well as via dipo-
lar forces. Additionally, the model contains an energy barrier
which has to be overcome in order to reverse a single cell and
a coupling to an external magnetic ﬁeld. Disorder is taken
into account.

We focus on the understanding of the dynamics especially
the temperature and ﬁeld dependence of the magnetisation
reversal process. The experimental and simulational results
for hysteresis, the reversal mechanism, domain conﬁgurations
during the reversal, and the time dependence of the magneti-
sation are in very good qualitative agreement. The results
for the ﬁeld and temperature dependence of the domain wall
velocity suggest that for thin ﬁlms the hysteresis can be de-
scribed as a depinning transition of the domain walls rounded
by thermal activation for ﬁnite temperatures.

75.60.Ch, 75.60.Ej, 75.40.Mg

I. INTRODUCTION

In recent years great eﬀort was focused on the mag-
netisation reversal process in magnetic thin ﬁlms with
perpendicular anisotropy because of their potential ap-
plication as high density recording media. In particular
CoPt alloy ﬁlms were found to be a very promising com-
pound for magnetic and magneto-optic storage [1].

Two diﬀerent mechanisms can be thought of to dom-
inate the reversal process: either nucleation or domain
wall motion [2]. Which of these mechanisms dominates
a reversal process depends on the interplay of the dif-
ferent interaction forces between domains with diﬀerent
magnetic orientation. In recent experiments on Co28Pt72
alloy ﬁlms [3,4] a crossover from magnetisation reversal
dominated by domain growth to a reversal dominated by
a continuous nucleation of domains was found depend-
ing on the ﬁlm thickness which was varied from 10nm to

30nm. Correspondingly, characteristic diﬀerences for the
hysteresis loops have been found. Similar results have
been achieved by simulations of a micromagnetic model
using zero temperature dynamics [3,4] and Monte Carlo
methods respectively [5].

It is the goal of this paper to work out the relation
between experiments and simulations. An exact, quanti-
tative description of the experimental results is hindered
by the facts that the observable length scales in exper-
iment and simulation are diﬀerent and that there is no
straight forward mapping of the time scale of a Monte
Carlo simulation on experimental time scales. However,
the emphasis of our work is on a deeper qualitative under-
standing of the dynamical aspects of the magnetization
reversal and especially on the principal inﬂuence of the
ﬁeld and the temperature on the domain wall velocity.
We ﬁnd that for thin ﬁlms these dynamics is governed
by a depinning transition of the domain walls rounded
by thermal activation for ﬁnite temperatures.

II. EXPERIMENTAL METHODS

The CoPt alloy ﬁlms were prepared under UHV condi-
tions at low deposition rates on Si substrates covered with
a 20nm Pt buﬀer layer. In order to achieve a dominant
perpendicular anisotropy the ﬁlms were grown at rather
high substrate temperatures of about 220◦C. The compo-
sition of 28 at.% Co and 72 at.% Pt is known to exhibit
the maximum of the polar Kerr rotation for the whole
range of alloys [1]. Structural characterization reveals
a predominant fcc(111) texture. The ﬁlms were usually
found to form a polycrystalline microstructure. Scanning
tunneling microscopy was used to determine the average
grain size. The preparation process yields rather uniform
grain size of the order of 20nm almost independent of the
ﬁlm thicknesses, which cover the range of 5 to 50nm.

X-ray analysis reveals a dispersion of the crystalline
c-axis in the range of about 3 degrees. For the mag-
netic characterization we applied magneto-optic Kerr mi-
croscopy at very high spatial resolution of about 1µm [4].
The typical Kerr rotation for the CoPt alloy ﬁlms is rang-
ing from 0.1◦ to 0.3◦. High speed image processing tech-

1

 
 
 
 
 
 
nique using a low noise CCD camera is able to acquire
domain patterns with millisecond time resolution. The
experimental setup permits to gain complete hysteresis
loops with applied external magnetic ﬁeld up to 0.5T.
An electrical heater assembly provides the variation of
the sample temperature by direct heating using a biﬁ-
lar heat wire. Image processing software was developed
to determine the domain wall motion and the average
magnetisation of the sample.

III. MICROMAGNETIC MODEL

Co28Pt72 alloy ﬁlms have a polycrystalline structure.
For a theoretical description by a micromagnetic model
[6] the ﬁlm is thought to consist of cells on a square lattice
with a square base of size L × L where L = 20nm. The
height h of the cells is varied from 10nm to 30nm. Due
to the large anisotropy of the CoPt alloy ﬁlm the cells
are thought to be magnetised perpendicular to the ﬁlm
only with a uniform magnetisation Ms which is set to the
experimental value of Ms = 365kA/m for the saturation
magnetisation in these systems [7]. The cells interact via
domain wall energy and dipole interaction. The coupling
of the magnetisation to an external magnetic ﬁeld H is
taken into account as well as an energy barrier which has
to be overcome during the reversal process of a single
cell.

From these considerations it follows that the change of
energy caused by reversal of a cell i with magnetisation
L2hMsσi with σi = ±1 and ∆σ = σ(new) − σ(old) = ±2
is:

∆Ei = −

1
2

LhSw∆σi X
hji

σj

+

µ0
4π

M 2

s Lh2∆σi X

v(σj , rij )

j

−µ0HL2hMs∆σi

(1)

The ﬁrst term describes the wall energy ∆Ew and the
sum is over the four next neighbors. One can expect
that the grain interaction energy density Sw is a reduced
Bloch-wall energy density SB since the crystalline struc-
ture of the system is interrupted at the grain boundary
and also since there may be a chemical modulation of the
CoPt alloy at the grain boundary. We varied the value of
Sw in the simulation and got the best agreement with ex-
perimental results for a value of Sw = 0.0022J/m2 which
is approximately 50% of the Bloch-wall energy SB for
this system [7].

In the second term describing the dipole coupling ∆Ed
the sum is over all cells. rij is the distance between two
cells i and j in units of the lattice constant L. For large
distances it is v(σj , rij ) = σj
. For shorter distances a
r3
ij
more complicated form which is a better approximation
for the shape of the cells which we consider can be deter-
mined numerically and was taken into account.

The third term describes the coupling ∆EH to an ex-

ternal ﬁeld H.

Additionally, an energy barrier δi must be considered
which describes the fact that a certain energy is needed
to reverse an isolated cell. Two reversal mechanisms can
be taken into account as limiting cases: (i) coherent ro-
tation of the magnetisation vector described by an angel
θ: In this case the anisotropy leads to an energy barrier
of L2hKu where Ku is the anisotropy constant which is
Ku = 200kJ/m3 [7].
(ii) domain wall motion through
the grain: In this case the energy barrier is LhSb due
to the fact that the domain wall energy is lowered at
the grain boundary. The highest possible value for Sb
is the Bloch-wall energy mentioned above but it can be
assumed that the for the energy barrier relevant value
is smaller than the value above since a Bloch wall is
thicker than the size of the cell. Comparing these two
energies for the reversal mechanism of a CoPt grain one
ﬁnds that here domain wall motion through the grains
has the lower energy barrier so that from now on only
this mechanism will be taken into account. We assume
that during the reversal process the energy barrier has
its maximum value LhSb when the domain wall is in the
center of the cell, i.e. when half of the cell is already
reversed. Consequently, the energy barrier which has to
be considered in a Monte Carlo simulation is reduced to
δ = max(0, LhSb − 1
2 |(Ew + Ed + EH )|). The simula-
tions are in good agreement with the experiments using
Sb = 0.0007J/m2.

Note, that we have introduced two diﬀerent wall energy
densities, Sw for the nearest neighbor interaction, and
Sb for the intrinsic energy barrier. They have the same
physical origin but they have to be handled separately in
our model: e. g., the limit of a system of isolated grains
is described by Sw → 0 but then there is still a ﬁnite Sb
due to the existence of energy barriers which are relevant
for the ﬂip of the isolated cells. The opposite limit is a
system without grain boundaries. Here it is Sb = 0, i. e.,
there is no energy barrier but the domain wall has still
a constant, ﬁnite energy density Sw which in this limit
does not depend on the position of the wall.

Obviously, the grain sizes in the CoPt alloy are ran-
domly distributed [3].
In order to be realistic, in our
simulation disorder has to be considered (see also [8] for
a discussion of the role of disorder in a similar simula-
tion). In the model above this corresponds to a random
distribution of L which can hardly be simulated exactly
since it modulates the normalized cell distance rij of the
dipole interaction. Therefore, as a simpliﬁed ansatz to
simulate the inﬂuence of disorder we randomly distribute
L in the energy term that describes the coupling to the
external ﬁeld. Here a random ﬂuctuation of L is most
relevant, since this term is the only one scaling quadrat-
ically with L. In the simulations we use a distribution
which is Gaussian with width ∆ = 0.1. Through this
kind of disorder our model is mapped on a random-ﬁeld
model. Other possible origins of disorder in the CoPt
ﬁlms are e. g. ﬂuctuations of the easy axis of the grains

2

or ﬂuctuations of the saturation magnetisation. Interest-
ingly these kinds of disorder would also predominantly
inﬂuence the last term in Eq. 1 and hence can be gath-
ered in the random ﬁeld.

The simulation of the model above was done as in ear-
lier publications [5,8] via Monte Carlo methods [9] using
the Metropolis algorithm with an additional energy bar-
rier. Since the algorithm satisﬁes detailed balance and
Glauber dynamics it allows the investigation of thermal
properties as well as the investigation of the dynamics of
the system. Note that in the limit of low temperatures
the Monte Carlo algorithm passes into a simple energy
minimization algorithm with single spin ﬂip dynamics,
so that also the case of zero temperature can be investi-
gated.

The size of the lattice was typically 150 × 150. The
dipole interaction was taken into account without any
cut-oﬀ or mean ﬁeld approximation.

IV. HYSTERESIS AND THE REVERSAL
MECHANISM

We start our analysis by comparing the hysteresis loop
from simulations for T = 300K, Fig. 1, with the corre-
sponding experimental hysteresis loop for room temper-
ature, see Ref. [3,4].

s

M
=
M

1

0

-1

1

0

-1

30nm

10nm

The qualitative agreement is very good. In both cases,
experiment as well as simulation the hysteresis loop of
the thin ﬁlm is nearly rectangular. For the thicker ﬁlm
the loop has a ﬁnite slope, especially at the end of the
hysteresis. This can be understood through the diﬀerent
reversal mechanisms. The reversal of the 10nm ﬁlm is
dominated by domain wall motion. Once a nucleus be-
gins to grow the domain wall motion does not stop until
the magnetisation has completely changed. For the 30nm
ﬁlm the enhanced dipolar forces stabilize a mixed phase
which can be changed only by a further increase of the
external ﬁeld [3–5]. The reason for the enhanced inﬂu-
ence of the dipolar forces can be seen in Eq.1 where the
dipole term is the only term that scales quadraticly with
the ﬁlm thickness h which means that the inﬂuence of the
dipole coupling is neglectable for h → 0 and on the other
hand strongly growing with increasing ﬁlm thickness.

Quantitatively, the agreement of the simulation with
the experimental results is reasonable only for the 30nm
ﬁlm while the nucleation ﬁeld is much to high for the
simulation of the 10nm ﬁlm. There are several possible
reasons for this eﬀect. First, the nucleation ﬁeld which
in the case of domain wall motion dominated reversal is
the ﬁeld where domain wall motion starts depends on the
size and on the shape of the nucleus. In an experimental
situation point-like defects which are not visible in the
optical regime can act as nuclei while there is no such
artiﬁcial nucleus in our simulation. Second, some of the
parameters of our model like the disorder or the Bloch-
wall energy which inﬂuences the prefactors in Eq.1 may
depend on the ﬁlm thickness.
In our simulation, they
are thought to be constant – for simplicity and since we
do not have more information about the thickness de-
pendence of these parameters. Third, the time scale at
which a hysteresis loop is observed may play an impor-
tant role. This time scale is a few minutes in the exper-
iments and around 60000 MCS in the simulations. To
our knowledge, there is no straight forward way to map
Monte Carlo simulation time on realistic time scales so
that the observation-time windows might be diﬀerent in
experiment and simulation leading to diﬀerent nucleation
ﬁelds. Changing the sweeping rates changes the nucle-
ation ﬁelds due to thermal activation, experimentally as
well as in simulations, but this does not change the qual-
itative behavior.

However, it is not the aim of our simulations to calcu-
late the nucleation ﬁeld accurately. Rather, the simula-
tions are thought to contribute to a better understanding
of the fundamental properties of the system, especially to
a better understanding of the dynamics.

-300

-200

-100

0

100

200

300

H [kA/m]

V. DYNAMICS AND TEMPERATURE
DEPENDENCE

FIG. 1. Simulated hysteresis loops for a 30nm and a 10nm

ﬁlm at T = 300K.

The diﬀerent reversal mechanisms we mentioned in the
previous section manifest themselves also in a change of

3

the dynamical behavior. We focus on the reversal dynam-
ics, i. e. the time dependence of the magnetisation after
a rapid change of the ﬁeld to a value which destabilizes
the initial direction of magnetisation. The corresponding
experimental and simulational time dependences of the
magnetisation are compared in Fig. 2. The time-axis is
normalized to that time at which half of the system is
reversed.

mains grows quadratic in time as long as the domains are
so small that they do not overlap, M (t) − M0 ∼ −(vt)2.
Consequently, the central quantity of the magnetisation
reversal driven by domain wall motion is the domain wall
velocity. Therefore, in the following we will investigate in
detail the dependence of the domain wall velocity on the
driving ﬁeld and the inﬂuence of the temperature. Hence
from now on we restrict ourselves to the investigation of
the 10nm ﬁlm.

]
.
u
.
a
[

M

M
=
M

s

1

100

A

(cid:23)

0.5

a)

0

-0.5

-1

1

300

A

(cid:23)

100

A

(cid:23)

0.5

b)

0

-0.5

-1

300

A

(cid:23)

0

1

2

3

4

5

6

7

8

t=t

50%

FIG. 2. Magnetisation versus time from measurement, a),
after a rapid change of the ﬁeld to 19.33kA/m (10nm) and
13.29kA/m (30nm) and from simulations, b), after a rapid
change to 260 kA/m (10nm) and 220 kA/m (30nm).

For the case of the thin ﬁlms the (absolute) value of
the reversed ﬁeld is larger than the coercive ﬁeld while
for the thicker ﬁlm in the experimental situation a value
above the nucleation ﬁeld but below the coercive ﬁeld
had to be chosen since for larger ﬁelds the reversal is
to fast to be observed with this experimental technique.
Consequently, the long time limit of the corresponding
experimental curve is above -1. Apart from that the ex-
perimental results and the results from simulations agree.
For the case of the 30nm ﬁlm, i. e. for the nucleation
driven reversal there is a rapid change of the magneti-
sation at the beginning of the reversal process. This
demonstrates that the reversal process is dominated by
nucleation and not by domain growth processes. In the
limit of a constant nucleation rate R and no growth pro-
cesses the change of the magnetisation can be expected
to be exponential [11].

On the other hand for the case of domain growth the
change of magnetisation is slow at the beginning.
If a
constant number of nuclei and a constant domain wall ve-
locity v is assumed, the magnetisation of the reversed do-

4

a)

b)

FIG. 3. Domain image from MOKE measurements of a
10nm ﬁlm 236, 313, and 468s after a rapid quench to a ﬁeld
of 17.7kA/m, a), and simulated domain conﬁgurations, of a
150 × 150 system during the reversal of a 10nm ﬁlm 10, 40,
and 60 MCS after a rapid quench to a ﬁeld of 245 kA/m, b)

For the determination of the domain wall velocity
within the simulation we start with a system that has
a nucleus of circular shape with a radius of 19 cells in
the center of the 150 × 150 system. When we switch
on the driving ﬁeld from the nucleus a domain starts to
grow. For the better observation of the domain growth,
in our ﬂip-algorithm we do not consider cells that are
not connected to the growing domain, i. e. we exclude
the possibility of spontaneous nucleation. Otherwise we
had – at least for ﬁnite temperatures – the problem that
spontaneously new nuclei are build by thermal activa-
tion which with increasing radius overlap with the origi-
nal domain. Fig. 3 illustrates the time development of a
domain which follows from the method described above
and compares it with experimental domain images. The
black regions are reversed domains following the mag-
netic ﬁeld. The domains look similar although their size
is diﬀerent (the linear size of the pictures is 3 µm in the
simulation and 150µm experimental). This and also a
more detailed analysis [12] leads to the conclusion that
the domain walls are rough and hence self-similar (see
[13] for a review on self similar interfaces). The shape of
the domains is - within the simulations - inﬂuenced by
the strength of the disorder. Note, however, that frozen
disorder is not the only possible reason for the rough-
ening of a domain wall. Other possible sources are the

3

3

2

+

2

2

+

0

3

20

200

210

220

230

240

250

dipolar interactions as well as the dynamics of the model
(see e.g. [14] for a discussion of the shape of domains in
a model without disorder).

From both, the domain conﬁgurations from simula-
tions and from experimental domain images the mean
radius r of the domains can be determined through the
area F of the reversed domain as r = pF/π, assum-
ing that the domain has a circular shape. Additionally,
the domain radius of the experimental domain images
has been determined as the mean distance of the domain
boundary from the center of the domain. Both deﬁnitions
of r lead to the same results.

Fig. 4a shows the time dependence of the radius mea-
sured at T = 299K after a rapid change of the ﬁeld to
H = 17.7, 18.0, and 18.8kA/m. Obviously, the domain
wall velocity is constant and from the slope of the curves
v can be determined.

]

m
(cid:22)
[
r

]

m
(cid:22)
[
r

60

50

a)

40

3

30

3

3

3

3

3

3

3

3

10

3

3

3

0

50

100

150

200

250

300

350

400

450

500

t [s]

2

1.8

b)

1.6

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

1.4

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

33

3

3

3

3

3

3

3

3

3

333

33333333333

3

3

3

3

3

3

3

3

3

3

3

3

3

3

1.2

3

3

3

3

3

3

3

3

3

3

3

3

1

3

3

3

3

3

3

3

3

3

3

3

3

3

3

0.8

3

3

3

3

3

3

3

3

3

3333

33333333333333333333333

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

0.6

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3

3
3

0.4

0.2

0

100

200

300

400

500

600

t [MCS]

FIG. 4. Measured radius of a domain versus time for
H = 17.7, 18.0, 18.8 kA/m.
T = 299K, a), and ra-
for
the domain versus
dius of
H = 225, 230, 235, 240, 245 and zero temperature. The solid
lines are best ﬁtted.

time from simulations

In order to get a deeper understanding of the inﬂu-
ence of the temperature on the dynamics apart from the
“experimental temperatures” (T ≈ 300K) we also simu-
lated “extreme temperatures” (T = 0K and T = 600K).
Fig. 4b shows - as an example - the r(t) behavior from
the simulations for T = 0K and diﬀerent ﬁelds. For the
lowest ﬁeld shown the domain wall is pinned, i. e. after
a short period of rearrangement of the domain wall its

5

movement stops and the radius remains constant. The
pinning of the domain wall is due to energy barriers which
follow from the disorder, the dipole ﬁeld, and the intrinsic
energy barrier of the single cell. For ﬁnite temperatures,
the domain wall velocity is always ﬁnite (see discussion
below).

For r > 150L/2 = 1.5µm the domain reaches the
boundary of the system and - consequently - r(t) satu-
rates. For smaller r the slope of the r(t) curve is approx-
imately constant and v can be determined by ﬁtting to a
straight line. Fig. 5 shows the resulting dependence of the
domain wall velocity on the driving ﬁeld for T = 0, 300,
and 600K.

0.15

0.1

0.05

]
S
C
M
=
m
(cid:22)

[
v

+

3

2

+

2

3

+

2

3

2

+

+

3

2

H [kA/m]

FIG. 5. Simulated domain wall velocity versus driving ﬁeld
for T = 600, 300, and 0K (from above). The solid lines are
guides to the eye.

For zero temperature there is a sharp depinning tran-
sition [13] at a critical ﬁeld Hc from a pinned phase with
v = 0 to a phase with ﬁnite domain wall velocity. This
transition can be interpreted in terms of a dynamic phase
transition with v ∼ (H − Hc)θ for H > Hc where in our
case the critical exponent is θ ≈ 1, a value which is the
mean ﬁeld result for a moving elastic interface [15] in
a random-ﬁeld. Also, this value has been observed in
simulations of a soft spin model with random-ﬁelds [16].
Hence, it seems to be reasonable to consider the depin-
ning transition we found to be in the universality class of
a driven interface in the random-ﬁeld Ising model. This
fact is further conﬁrmed by a dynamical scaling analysis
of the structure of the domain walls in CoPt [12]. The
central quantity in this analysis is the time dependent
roughness of the domain wall which - following the the-
ory of driven interfaces [13] - is characterized by a certain
set of critical exponents. For the case of the CoPt alloy
these exponents are also the same as those characterizing
a driven interface in a random-ﬁeld Ising model.

Note that in the models mentioned above the only ori-
gin for the depinning transition is the disorder. Here, the
value of Hc without disorder is zero. In our model, Hc
depends additionally on the dipole ﬁeld and the intrinsic
energy barrier of the single cell. A detailed analysis of
these dependencies must be left for the future.

0.1

+

2

+

2

+

2

2

+

+

2

]
S
C
M
=
m
(cid:22)

[
v

0.01

2

+

2

2

+

0.001

-0.05

0

0.05

0.1

(H (cid:0) H

)=T [kA/Km]

c

FIG. 6. Scaling plot from Fig. 5.

For ﬁnite temperatures the transition is smeared since
for ﬁnite temperatures there is even for H < Hc for each
energy barrier a ﬁnite probability that the barrier can be
overcome by thermal ﬂuctuations. Hence, for ﬁnite tem-
peratures we expect a crossover from the dynamics of the
zero temperature depinning transition explained above to
a dynamics dominated by thermal activation where the
corresponding waiting times are exponentially large. For
H < Hc the domain wall velocity should decrease like
ln v ∼ (H − Hc)/T . To illustrate this in Fig.6 we show
the corresponding semi-logarithmic scaling plot. As we
expect, the data for the two diﬀerent ﬁnite temperatures
collapse for H < Hc on a straight line. For H > Hc ther-
mal activation is obviously less relevant since for these
values of the driving ﬁelds even for zero temperature the
domain walls move. Consequently, also for ﬁnite temper-
ature but H > Hc the domain wall dynamics is domi-
nated by the zero temperature depinning transition, i.e.
v ∼ H − Hc.

measurements at higher ﬁelds since for higher ﬁelds new
domains build up spontaneously and overlap each other
so that it is not possible to follow one single domain for
the analysis of the domain wall velocity.

VI. CONCLUSIONS

By comparing microscopy measurements on Co28Pt72
alloy samples based on the magneto-optical Kerr eﬀect
with Monte Carlo simulations we show that a micromag-
netic model can be used for the understanding of mag-
netic properties of nanoscale magnetic ﬁlms with high
perpendicular anisotropy. The experimental and simula-
tional results of the hysteresis, the reversal mechanism,
the domain conﬁgurations during the reversal, the time
dependence of the magnetisation and the temperature
and ﬁeld dependence of the domain wall velocity are in
very good qualitative agreement.

For thin ﬁlms the reversal is dominated by a growth
of domains the dynamics of which can be described by
the domain wall velocity. The results for the domain
wall velocity suggest that for zero temperature the hys-
teresis can be understood as a depinning transition of
the domain walls. For ﬁnite temperatures the transition
is rounded by thermal activation and for ﬁelds smaller
than the depinning ﬁeld the domain wall movement is
dominated by thermal activation.

ACKNOWLEDGMENTS

Work supported by the Deutsche Forschungsgemein-

schaft through Sonderforschungsbereich 166

2

+

1

]
s
/
m
(cid:22)

[

v

+

3

2

0.1

2

3

+

3

-0.075

-0.07

-0.065

(H (cid:0) H

)=T [kA/Km]

c

FIG. 7. Scaling plot for the measured domain wall veloci-

ties at T = 299, 335, and 394K.

Fig. 7 shows the same scaling plot for the experimental
data. Obviously, all data are in the regime H ≪ Hc, so
that the scaling for thermal activation works. We are far
away from the regime H ≈ Hc where the crossover to zero
temperature depinning dynamics would start since from
Fig. 7 it follows Hc ≈ 40kA/m. There is no possibility for

6

[1] D. Weller, R. F. C. Farrow, J. E. Hurst, H. Notarys,
H. Br¨andle, M. R¨uhrig, and A. Hubert, Opt. Neural Net-
works 3(4), 353 (1994)

[2] J. Pommier, P. Meyer, G. P´enissard, J. Ferr´e, P. Bruno,

and D. Renard, Phys. Rev. Lett. 65, 2054 (1990)

[3] T. Kleinefeld, J. Valentin, and D. Weller, JMMM 148,

249 (1994)

[4] J. Valentin, T. Kleinefeld, and D. Weller, J. Phys. D, 29,

1111 (1996)

[5] U. Nowak, IEEE Trans. Mag. 31, 4169 (1995)
[6] W. Andr¨a, H. Danan, and R. Mattheis, Phys. Stat. Sol.

(a), 125 , 9 (1991)

[7] J. Harzer, RWTH Aachen, Ergebnisbericht (1992)
[8] U. Nowak, U. R¨udiger, P. Fumagalli, and G. G¨untherodt,

Phys. Rev. B 54, 13017 (1996)

[9] K. Binder and D. W. Heermann, Monte Carlo Simula-
tions in Statistical Physics (Springer-Verlag, Berlin 1988)

[10] R. D. Kirby, J. X. Shen, R. J. Hardy, and D. J. Sellmyer,

Phys. Rev. B 49, 10810 (1994)

[11] E. Fatuzzo, Phys. Rev. 127, 1999 (1962)
[12] M. Jost and Th. Kleinefeld, submitted to Phys. Rev. B
[13] M. Kardar and D. Ertas, in Scale Invariance, Interfaces,
and Non-Equilibrium Dynamics, edited by A. McKane,
M. Droz, J. Vannimenus, and D. Wolf, Plenum Press,
New York 1995, pa. 89

[14] A. Lyberatos, J. Earl, and R. W. Chantrell, Phys. Rev. B

53, 5493 (1996)

[15] H. Leschhorn, J. Magn. Magn. Mat. 104-107, 309 (1992)
[16] K. D. Usadel and M. Jost, J. Phys. A26, 1783 (1993)

7"
"Static and dynamic properties of frictional phenomena in a
  one-dimensional system with randomness","  Static and dynamic frictional phenomena at the interface with random
impurities are investigated in a two-chain model with incommensurate structure.
Static frictional force is caused by the impurity pinning and/or by the pinning
due to the regular potential, which is responsible for the breaking of
analyticity transition for impurity-free cases. It is confirmed that the static
frictional force is always finite in the presence of impurities, in contrast to
the impurity-free system. The nature of impurity pinning is discussed in
connection with that in density waves. The kinetic frictional force of a steady
sliding state is also investigated numerically. The relationship between the
sliding velocity dependence of the kinetic frictional force and the strength of
impurity potential is discussed.
",http://arxiv.org/pdf/cond-mat/9706271v1,2,"7
9
9
1

n
u
J

6
2

]
h
c
e
m

-
t
a
t
s
.
t
a
m
-
d
n
o
c
[

1
v
1
7
2
6
0
7
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Static and dynamic properties of frictional phenomena

in a one-dimensional system with randomness

Takaaki Kawaguchi

Department of Technology, Faculty of Education, Shimane University

Hiroshi Matsukawa

Department of Physics, Graduate School of Science, Osaka University

(August 11, 2018)

Abstract

Static and dynamic frictional phenomena at the interface with random

impurities are investigated in a two-chain model with incommensurate struc-

ture. Static frictional force is caused by the impurity pinning and/or by the

pinning due to the regular potential, which is responsible for the breaking of

analyticity transition for impurity-free cases. It is conﬁrmed that the static

frictional force is always ﬁnite in the presence of impurities, in contrast to

the impurity-free system. The nature of impurity pinning is discussed in con-

nection with that in density waves. The kinetic frictional force of a steady

sliding state is also investigated numerically. The relationship between the

sliding velocity dependence of the kinetic frictional force and the strength of

impurity potential is discussed.

81.40.Pq, 46.30.Pa

Typeset using REVTEX

1

 
 
 
 
 
 
I. INTRODUCTION

Friction is an old but unsettled problem in physics [1]. The Coulomb-Amonton’s law of

friction is one of the most well-known laws in physics. It has been examined that the law

holds well under usual conditions, but breaks in some cases. It is still unsuccessfull, however,

to clarify the conditions of Coulomb-Amonton’s law to hold and the physical mechanism of

friction. On the other hand, recent experimental measurement techniques of frictional phe-

nomena have made great progress. One of the direction of such studies of friction tends to

investigate nano-scale frictional phenomena. For example, atomic and frictional force micro-

scope measurements at nanometer scale and quartz-microbalance measurements of frictional

phenomena of monolayers have been performed extensively [2–4]. Stimulated by these ex-

periments, theoretical approaches based on a microscopic model have been investigated

extensively [5].

As a simple microscopic model of friction, the Frenkel-Kontorova model (FK model) [6]

has been employed in several works [7–10]. The FK model consists of atoms interacting with

each other via a harmonic force under a periodic potential, which is originally sinusoidal.

In the case that the ratio between the mean atomic spacing and the period of the potential

is irrational, i.e., in an incommensurate case, the FK model shows a phase transition that

is called the breaking of analyticity transition or Aubry transition [7]. When the amplitude

of sinusoidal potential is smaller than a certain critical value, the maximum static frictional

force vanishes. Otherwise it becomes ﬁnite. The existence of this phase transition was

originally pointed out in a one-dimensional incommensurate FK model by Aubry [7].

In

three-dimensions, the peculiar frictional nature of the incommensurate FK model was found

by Hirano and Shinjo [8,9]. They pointed out the possibility of the appearance of a super-

lubrication state, that is the vanishing static frictional force state, between incommensurate

surfaces in real materials. Matsukawa and Fukuyama investigated the static and kinetic

properties of friction in a one-dimensional model [11]. The model employed in their study

consists of two atomic chains, where interchain force works between atoms in one chain and

2

those in another and harmonic force works between neighber atoms in each chain. The eﬀect

of energy dissipation and the relaxation of atoms in both chains are taken into accout prop-

erly. On the basis of their model, a deﬁnitive expression of both static and kinetic frictional

force can be derived. They found that the critical value of the potential strength of the

breaking of analyticity transition depends strongly on the rigidity of the chains. In the case

that atoms in the lower chain are ﬁxed periodically, which corresponds to the FK model,

that critical value is large. When atoms in the lower chain can relax, that critical value

decreases and the parameter range for the state with vanishing maximum static frictional

force becomes small. They also found that the sliding velocity dependence of the kinetic

frictional force becomes weaker as the maximum static frictional force increases.

In these theoretical studies of friction, surface randomness has not been taken into ac-

count. In a realistic system, however, there always exists surface randomness. The eﬀects of

surface randomness should be taken into consideration to understand frictional phenomena

in realistic systems. Based on a variational method and a perturbational analysis, Mat-

sukawa and Fukuyama showed that the state with vanishing maximum static frictional force

becomes unstable against surface randomness [12]. The frictional transition is smeared out

because the randomness breaks the translational symmetry of the system. Hence a ﬁnite

maximum static frictional force appears even if the interatomic interaction is suﬃciently

small [13].

While ﬁnite static frictional force is expected to appear in systems with surface ran-

domness, the magnitude of the maximum static frictional force has not been clariﬁed yet.

Furthermore, surface randomness inﬂuences the kinetic friction. The velocity dependence of

the kinetic frictional force would be diﬀerent from that of the system with clean surfaces.

In this paper, using a one-dimensional incommensurate model, we investigate the static and

kinetic frictional forces subject to surface randomness.

This paper is organized as follows.

In section II we deﬁne a one-dimensional incom-

mensurate model of friction and introduce surface randomness. Based on a numerical study

and the impurity pinning theory of density waves, we discuss the static frictional force in

3

section III. The kinetic frictional force, in particular its velocity dependence, is investigated

in section IV. Section V is devoted to summary and discussion.

II. THEORETICAL MODEL OF FRICTION

In order to calculate frictional force, we consider a one-dimensional model of friction

proposed by Matsukawa and Fukuyama [11]. This model can deal with the friction between

two deformable atomic chains interacting each other. To simplify the problem, however,

we here assume that one of the two chains is ﬁxed and the other chain can be deformed.

The atoms of the ﬁxed chain are periodically arranged at a regular position. We call the

deformable chain the upper body and the ﬁxed chain the lower body. The atoms in the

upper body have a one-dimensional degree of freedom in the direction parallel to the chain.

The interatomic force of the upper body is approximated by the harmonic one. The eﬀect

of the energy dissipation is taken into account by the term in the equation of motion which

is proportional to the diﬀerence between the velocity of each atom and that of the center

of gravity. The external force is applied to the upper body to the horizontal direction.

Assuming an overdamped condition, we get the equation of motion of the i-th atom of the

upper body as follows.

maγa{ ˙ui − h ˙uiii}

= Ka{ui+1 + ui−1 − 2ui} +

FI(ui − vj) + Fex,

(1)

Xj∈b

where ui (vi) is the position of the i-th atom of the upper (lower) body, m the atomic

mass, γ the parameter of energy dissipation, Ka the strength of the interatomic froce,

and h ˙uiii represents the average of

˙ui with respect to i. FI and Fex are the interchain

force between atoms in diﬀerent chains and the external force, respectively. We adopt the

following interchain potential:

UI = −

KI
2

exp

−4
""

2

x
cb (cid:19)

,

#

(cid:18)

4

(2)

where KI is the interchain potential strength and cb the mean atomic spacing of the lower

body. The interchain force is given by FI(x) = − d

dx UI. Since we now consider the case

where all the atoms of the lower body are ﬁxed, the total interchain force that acts on the

i-th atom of the upper body is a function of ui only, which is obtained by summing up the

contribution from all the atoms of the lower body.

This means that the present model corresponds to the kinetic FK model with energy dissi-

FI (ui − vj) = ˜FI(ui).

j∈a
X

(3)

pation.

Now we consider surface randomness such as impurities. It is assumed that the interchain

potential consists of two parts, i.e., the original regular potential and the impurity potential,

which is distributed randomly. Furthermore we assume that the impurity potential has the

same form as the original one except for the potential strength. Hence the total interchain

potential is given by

Nb

NI

UI

T (ui) =

UI(ui − vj) +

UI

imp(ui − vj),

(4)

j=1
Xj=impurity sites
X
where UI represents the original interatomic potential, UI

imp the impurity potential and NI

is the number of impurities. The impurity potential, UI

imp, is written as

U imp
I

(x) = −

K imp
I
2

exp

−4

""

(cid:18)

where K imp

I

is the strength of the impurity potential.

2

,

x
cb (cid:19)
In this model, the frictional force

(5)

#

Ffric in a steady state can be calculated by the following equation: Ffric = −

hFI(ui)it ,

where h. . .it means the temporal average and FI(x) = − d

dx UI

T (x). Because the system is in

i∈a
X

a steady state Ffric is equal to the total external force, NaFex.

The equation of motion is numerically solved using the Runge-Kutta formula. In the

calculation the periodic boundary condition, ui = ui+N + L, is adopted, where L is the

system size. Then the ratio ca/cb is equal to the ratio Nb/Na, where ca is the mean lattice

spacing of the upper body and Na and Nb are the number of atoms of the upper and lower

bodies, respectively.

5

We here consider an incommensurate system with periodic boundary condition and de-

termine the ratio ca/cb based on the continued-fraction expansion of the golden mean.

ca
cb

=

Nb
Na

=

144
89

= 1.6179 · · · ,

(6)

where the expansion is truncated at the tenth order. The parameters of the present model

are set as

ca =

144
89

, cb = 1, m = Ka = γ = 1, NI = 70.

(7)

The number of impurities NI is ﬁxed throughout the present numerical simulation. With

increasing external force, the maximum static frictional force, i.e., the threshold force at

which the upper body starts to slide, is numerically estimated. The kinetic frictional force

is evaluated in steady sliding states with constant velocities [11].

III. MAXIMUM STATIC FRICTIONAL FORCE AND IMPURITY PINNING

EFFECTS

For convenience of the following discussion, we deﬁne some energy scales that characterize

the present model. The impurity potential energy, the elastic energy, and the coupling energy

to the external force per impurity are expressed as Ei, Eel, and Ef , respectively, and are

given by

Ei =

Eel =

1
2
1
2

KI

imp,

Ka × NI/Nb,

Ef = Fex × Nb/NI.

(8)

(9)

(10)

For the comparison between these energy scales it is convenient to introduce the parameters

εi and εf as follows:

εi = Ei/Eel,

εf = Ef /Eel.

6

(11)

(12)

The strengths of the impurity potential and the external force are discussed in terms of εi

and εf , respectively. According to the impurity pinning theory of density waves [14–16] the

nature of the impurity pinning is quite diﬀerent whether εi ≫ 1 or εi ≪ 1.

We now attempt to interpret the impurity pinning eﬀect as the origin of static friction.

The scenario is as follows. For large εi the eﬀect of the impurity potential overcomes those

of the elastic energy, and strong pinning states, in which each impurity pins the chain and

the large lattice distortion is accompanied, are preferred. Maximum static frictional force is

expected to be proportional to the pinning energy, which is the sum of the impurity potential

energy and the elastic energy in the pinned state. Hence, the normalized maximum static

frictional force εm.s.

f

behaves as

εm.s.
f ∝ εi.

(13)

On the other hand, for small values of εi each impurity cannot pin the upper body due to

the resulting large loss of elastic energy. Instead collection of impurities in a ﬁnite domain

pin the upper body. The size of the domain is determined so as to minimize the pinning

energy. In each domain the system can gain the impurity energy in the scale of ﬂuctuation.

Then we get

εm.s.
f ∝ εi

4

3 ,

(14)

in the case of one-dimensions.

The consideration above, however, does not take into accout the eﬀect of the originally

underlying regular potential UI. Even for impurity-free cases there can exist the pinning

behavior in the present system, i.e., the appearance of the ﬁnite maximum static frictional

force due to the Aubry transition for KI larger than a certain critical value. This eﬀect is

crucial in considering the static frictional force.

Figs. 1(a)-(c) show εm.s.

f

versus εi curves for the several strengths of the interchain

potential KI, where the maximum static frictional forces obtained are averaged over 3 to

10 samples. For KI = 0.05 (Fig. 1(a)), the weak impurity pinning relation (εm.s.

f ∝ εi

4

3 )

7

and the strong impurity pinning relation (εm.s.

f ∝ εi) hold well in the regimes εi ≤ 10 and

εi > 20, respectively. There exists a crossover point between the two characteristic impurity

pinning states around εi ∼ 20. Additional crossover behavior appears for KI = 1 where the

corresponing clean systems have ﬁnite static frictional force. As observed in Fig. 1(b), the

crossover between weak and strong impurity pinning states found for KI = 0.05 apparently

exist around εi ∼ 20 even for KI = 1. The regime of the weak impurity pinning states

for KI = 1, however, is rather narrowed, and apparent deviation from the weak impurity

pinning behavior is observed for εi ≤ 2. This deviational behavior is considered a crossover

between the weak impurity pinning state and an another state. The latter is the state pinned

mainly by the regular potential and is close to the breaking of analyticity state due to the

Aubry phase transition in the impurity-free case. In this regime the impurity potential is

considered approximately to be a weak perturbation to the impurity-free state. However,

in the regimes εi > 2, the eﬀect of the impurity potential becomes dominant, and then the

weak pinning state appears. The deviation point from the weak pinning state shifts to the

large εi regime as KI increases. For a strong interaction (KI = 6, Fig. 1(c) ), the weak

pinning regime is not observed. It is conﬁrmed from the fact that the exponent of εm.s.

f

on

εi in the regime εi ≤ 10 is quite diﬀerent from that of the weak pinning state. The weak

pinning states are destroyed by the regular interchain potential because this potential always

dominates the impurity potential in the weak impurity pinning regimes εi ≤ 10.

IV. KINETIC FRICTIONAL FORCE

In this section we investigate the eﬀect of the impurity potential on the velocity de-

pendence of the kinetic frictional force. Figs.2(a-b) show the velocity(v) dependence of the

kinetic frictional force for various strengths of the impurity potential. These values of the im-

purity potential correspond to the weak pinning regime. In addition to the ﬁnite εi cases we

show the kinetic frictional force of the clean system(εi = 0) for comparison. In a weak regular

interchain interaction case, KI = 0.05(Fig.2(a)), it is obviously observed that the kinetic fric-

8

tional force for εi = 0 exhibits velocity strengthening(Ffric ∝ v) and weakening(Ffric ∝ v−1)

features in low and high velocity regimes, respectively. Such behavior is excellently explained

by a perturbational analysis [17,18]. In the case of ﬁnite εi, the behavior is quite diﬀerent

and the frictional force tends to a ﬁnite value in the limit of vanishing velocity [19]. It is an

eﬀect of the impurity potential. For small εi the eﬀect is more signiﬁcant at low velocities

than at high velocities, and additional velocity-weakening kinetic frictional force appears in

the low volocity regime. As the strength of the impurity potential increases the maximum

static frictional force becomes larger than the kinetic frictional force. We here note that

the behavior of kinetic frictional force in disordered systems was discussed theoretically by

Sokoloﬀ [20]. When applying his method to one-dimensions, a velocity-weakening feature

of kinetic frictional force can be deduced based on the perturbation theory for a general

disordered potential. The result is, however, obtained in the underdamped regime, while

the present results are obtained in the overdamped regime. Fig.2(b) shows the result on the

kinetic frictional force for KI = 1 where there exists large maximum static frictional force.

In this case the kinetic frictional force for εi = 0 shows a similar velocity dependence to that

for ﬁnite εi, that is, almost velocity-independent behavior in the low-velocity regime and

inversely proportional behavior to the sliding velocity in the high-velocity regime. In both

cases of Figs.2(a) and (b) the strength of the kinetic frictional force monotonically increases

with increasing εi.

The kinetic frictional force in the sliding states evolved from strong impurity pinning

states is shown in Fig.3. Under this condition, a very large maximum static frictional force

appears and the static and kinetic friction is mainly caused by the interaction between the

chain and the impurities. The kinetic frictional force in Fig.3 is similar to that in Fig.2(b),

i.e., the velocity-independent and velocity-weakening features. No distinct qualitative diﬀer-

ence in the behavior of the kinetic frictional force is observed between the diﬀerent strengths

of the interchain potential, KI = 0.05 and 1.

From the above results on kinetic frictional force, we found that the velocity-weakening

behavior in the high-velocity regime is a common feature of the present model and the

9

velocity-independent behavior in the low-velocity regime is peculiar to the system with

large maximum static frictional force.

V. SUMMARY AND DISCUSSION

We have calculated the static frictional force by computer simulations using a one-

dimensional incommensurate model of friction. It has been numerically conﬁrmed that the

randomness due to impurities destroys the vanishing static frictional force states and the

maximum static frictional force always becomes ﬁnite. This is consistent with the variational

calculation by Matsukawa and Fukuyama [12].

We have also found that frictional phenomena have a close relationship to impurity pin-

ning phenomena in density wave systems. For the case of weak regular interchain interaction

the nature of impurity pinning states changes from weak pinning to strong pinning as the

strength of impurity potential increases. Similar behavior is also observed in density waves

[14,21]. For a strong regular interchain interaction the maximum static frictional force is

ﬁnite even in impurity-free systems. The feature of the impurity pinning in the weak pin-

ning regimes is modiﬁed. In this case the pinning is caused essentially by the strong regular

potential rather than by the impurity potential. The crossover behavior of the maximum

static frictional force has been found from the pinned sate aﬀected by the regular potential

to the weak or strong impurity pinning state as the impurity potential is strengthened.

We have also investigated the kinetic frictional force in the presence of impurities. It

has been found that surface randomness is crucial to the velocity dependence of the kinetic

frictional force. The behavior of the kinetic frictional force in the present work should be

compared with that of the Coulomb-Amonton’s law, i.e., the kinetic frictional force is less

than the maximum static frictional force and does not depend on the sliding velocity. In the

case of large maximum static frictional force the velocity-independent behavior of kinetic

frictional force is observed in the low-velocity regime. The magnitude of the kinetic frictional

force is, however, equal to the maximum static frictional force.

10

In a realistic system there are several complicated factors that are not taken into consid-

eration in the present theoretical model. For example, the eﬀect of other types of randomness

such as steps on surfaces is not examined here. Such an eﬀect may be also an important

factor, but we expect that the velocity dependence of the kinetic frictional force would not

depend on the details of the randomness and would show a similar behavior to that of the

present model because the major contribution to the kinetic frictional force comes from the

excitation of phonons with long wavelength. Nevertheless several important issues are left

unsolved and therefore we need further investigation to compare the detailed features of the

friction model with those of realistic systems.

ACKNOWLEDGMENTS

We would like to thank Professor H. Fukuyama, Professor M. Robbins, and Dr. M.

Hirano for valuable discussions.

APPENDIX:

We make some comments on Eqs.

(13) and (14). As mentioned in the text, these

relations are derived using the impurity pinning theory of density waves. Concerning the

analogy between the present model and the model of density waves, the following points

should be noted. In the case of density waves [16], the average impurity energy vanishes

when density waves are rigid and have perfect periodicity. The energy gain due to the

impurity potential arises from the distortion of density waves. On the other hand, since the

present model has the attractive potential U imp

I

, the energy gain always exists even without

the distortion of the chain. This energy, however, does not aﬀect the frictional force because

the amount of the energy is independent of the position of the chain. In both systems the

energy cost caused by the distortion is relevant to the pinning eﬀect. Hence, in the present

model, the same behavior of the impurity pinning as that in density waves is observed.

11

REFERENCES

[1] F. P. Bowden and D. Tabor, The Friction and Lubrication of Solids (Clarendon Press,

Oxford, 1954).

[2] G. Binnig, C. F. Quate, and Ch. Gerber, Phys. Rev. Lett. 56, 930 (1986).

[3] J. Krim, Comments on Cond. Mat. Phys. Part B 17, 263 (1995).

[4] B. N. J. Persson, Comments on Cond. Mat. Phys. Part B 17, 281 (1995).

[5] For example, see theoretical articles in Physics of sliding friction (B. N. J. Persson and

E. Tosatti eds., Kluwer Academic Publishers, Dordrecht, 1996) and references therein.

[6] Y. Frenkel and T. Kontrova, Zh. Eksp. Teor. Fiz. 89, 1340 (1938); 89, 1349 (1938).

[7] M. Peyrard and S. Aubry, J. Phys. C 16, 1593 (1983).

[8] M. Hirano and K. Shinjo, Phys. Rev. B 41, 11837 (1990).

[9] K. Shinjo and M. Hirano, Surf. Sci. 283, 473 (1993).

[10] E. Granato, M.R. Baldan, and S.C. Ying, in Physics of sliding friction, B. N. J. Persson

and E. Tosatti eds., (Kluwer Academic Publishers, Dordrecht, 1996). T. Strunz and F.J.

Elmer, ibid, M. Weiss and F.J. Elmer, ibid.

[11] H. Matsukawa and H. Fukuyama, Phys. Rev. B 49, 17286 (1994).

[12] H. Matsukawa and H. Fukuyama, in Physics of sliding friction, B.N. J. Persson and E.

Tosatti eds., (Kluwer Academic Publishers, Dordrecht, 1996).

[13] In three-dimensional systems with impurities at the surface, the instability of the states

with vanishing static frictional force is considered to be marginal. That is, in three-

dimensional systems, the appearance of pinning by impurities only at the surface de-

pends on the impurity strength. M. Robbins, private communication.

[14] H. Matsukawa, J. Phys. Soc. Jpn. 57, 3463 (1988).

12

[15] H. Fukuyama, J. Phys. Soc. Jpn. 41, 513 (1976).

[16] H. Fukuyama and P.A. Lee, Phys. Rev. B 17, 535 (1978).

[17] J.B. Sokoloﬀ, Phys. Rev. B 42, 760 (1990), J. Appl. Phys. 72, 1262 (1992).

[18] T. Kawaguchi and H. Matsukawa, to be published.

[19] It is to be noted that in our calculation the limiting value of the kinetic frictional force

to vanishing velocity coincides with the maximum static frictional force. A similar rela-

tionship between kinetic and static frictional forces has been found also in a theoretical

study based on an elastic responce of asperities by Caroli and Nozieres. C. Caroli and

P. Nozieres, in Physics of sliding friction, B. N. J. Persson and E. Tosatti eds., (Kluwer

Academic Publishers, Dordrecht, 1996).

[20] J.B. Sokoloﬀ, Phys. Rev. B 51, 15573 (1995).

[21] J.W. Brill, N.P. Ong, J.C. Eckert, J. Savage, S.K. Khanna, and R.B. Somoano, Phys.

Rev. B 23, 1517 (1981).

Fig. 1. εi versus εm.s.

f

. The solid and dashed lines represent the relations: εm.s.

f ∝ εi

4

3 and

f ∝ εi, respectively. When εi = 0(K imp
εm.s.

I = 0), εm.s.

f = 0, 0.760, and 18.0 for KI = 0.05, 1,

and 6 respectively.

Fig.

2. The velocity dependence of kinetic frictional force for weak pinning.

(a)

KI = 0.05. Squares, circles, diamonds, triangles, and crosses represent the results for

εi = 0.926, 0.309, 0.0617, 0.0206, and 0 (K imp

I = 0.45, 0.15, 0.03, 0.01, and 0), respectively. (b)

KI = 1. Squares, circles, triangles and crosses represent the results for εi = 18.5, 6.17, 0.411,

and 0 (K imp

I = 9, 3, 0.2, and 0), respectively. Arrows indicate the maximum static frictional

force.

13

Fig. 3. The velocity dependence of kinetic frictional force for strong pinning. Circles and

triangles represent the results for εi = 51.3 (K imp

I = 24.95) and KI = 0.05 and for εi = 90.5

(K imp

I = 44) and KI = 1, respectively. Arrows indicate the maximum static frictional force.

14

Fig. 1 (a)

Kawaguchi and Matsukawa

 = 0.05
(a) K
I

104

1000

100

10

1

0.1

.
s
.
m
ε

f

0.01

0.001

0.01

0.1

1

10

100

1000

ε

i

Fig. 1(b)

Kawaguchi and Matsukawa

 = 1
(b) K
I

105

104

1000

100

10

1

.
s
.
m
ε

f

0.1

0.1

1

10

100

1000

104

ε

i

Fig. 1(c)

Kawaguchi and Matsukawa

 = 6
(c) K
I

105

104

1000

100

10

1

.
s
.
m
ε

f

0.1

0.1

1

10

100

1000

104

ε

i

Kawaguchi and Matsukawa

Fig. 2(a)

(a)

F
r
i
c
t
i

o
n
a

l

F
o
r
c
e

0.1

0.01

0.001

0.0001

10-5

0.001

0.01

0.1

1

10

100

Velocity

 
Fig. 2(b)

Kawaguchi and Matsukawa

(b)

10

1

0.1

0.01

F
r
i
c
t
i

o
n
a

l

F
o
r
c
e

0.001

100

0.01

0.1

1

Velocity 

10

 
Fig. 3

Kawaguchi and Matsukawa

100

10

F
r
i
c
t
i

o
n
a

l

F
o
r
c
e

1
100

0.1

1

10

Velocity"
On the global hydration kinetics of tricalcium silicate cement,"  We reconsider a number of measurements for the overall hydration kinetics of
tricalcium silicate pastes having an initial water to cement weight ratio close
to 0.5. We find that the time dependent ratio of hydrated and unhydrated silica
mole numbers can be well characterized by two power-laws in time, $x/(1-x)\sim
(t/t_x)^\psi$. For early times $t < t_x$ we find an `accelerated' hydration
($\psi = 5/2$) and for later times $t > t_x$ a `deaccelerated' behavior ($\psi
= 1/2$). The crossover time is estimated as $t_x \approx 16 hours$. We
interpret these results in terms of a global second order rate equation
indicating that (a) hydrates catalyse the hydration process for $t<t_x$, (b)
they inhibit further hydration for $t > t_x$ and (c) the value of the
associated second order rate constant is of magnitude 6x10^{-7} - 7x10^{-6}
liter mol^{-1} s^{-1}. We argue, by considering the hydration process actually
being furnished as a diffusion limited precipitation that the exponents $\psi =
5/2$ and $\psi = 1/2$ directly indicate a preferentially `plate' like hydrate
microstructure. This is essentially in agreement with experimental observations
of cellular hydrate microstructures for this class of materials.
",http://arxiv.org/pdf/cond-mat/9612099v1,3,"6
9
9
1
c
e
D
1
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
9
9
0
2
1
6
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

On the global hydration kinetics of tricalcium silicate cement

F. Tzschichholz1,2 and H. Zanni2
1 Department of Physics, Norwegian University of Science and Technology,
N–7034 Trondheim, Norway
2 Laboratoire de Physique et M´ecanique des Milieux H´et´erog`enes (CNRS, URA 857),
´Ecole Sup´erieure de Physique et de Chimie Industrielle de la Ville de Paris,
10 rue Vauquelin, 75231 Paris Cedex 05, France
(June 24, 2021)

We reconsider a number of measurements for the overall hydration kinetics of tricalcium
silicate pastes having an initial water to cement weight ratio close to 0.5. We ﬁnd that the time
dependent ratio of hydrated and unhydrated silica mole numbers can be well characterized by
two power–laws in time, x/(1 − x) ∼ (t/t×)ψ. For early times t < t× we ﬁnd an ‘accelerated’
hydration (ψ = 5/2) and for later times t > t× a ‘deaccelerated’ behavior (ψ = 1/2). The
crossover time is estimated as t× ≈ 16 hours. We interpret these results in terms of a global
second order rate equation indicating that (a) hydrates catalyse the hydration process for
t < t×, (b) they inhibit further hydration for t > t× and (c) the value of the associated
second order rate constant is of magnitude 6 · 10−7 − 7 · 10−6 liter mol−1 s−1. We argue, by
considering the hydration process actually being furnished as a diﬀusion limited precipitation
that the exponents ψ = 5/2 and ψ = 1/2 directly indicate a preferentially ‘plate’ like hydrate
microstructure. This is essentially in agreement with experimental observations of cellular
hydrate microstructures for this class of materials.

PACS number(s):81.30.Mh, 61.43.-j, 81.35.+k

I. INTRODUCTION

Heterogeneous solid–state transformations are of
great importance and practical interest in industrial
and technological applications. Perhaps most promi-
nent examples are transformations within alloys and
steels playing a so crucial role for their mechanical and
durabillity properties. Solid–state transformations are
frequently accompanied by microstructural changes
within the material in form of precipitating (segre-
gating) phases from (solid) solutions. In its simplest
form the transformation takes place between a major
component acting as a solvent and an initially solvated
phase. The precipitation process of the solvated phase
is usually considered to happen in three main stages;
phase nucleation, phase growth, and ﬁnally a coarsen-
ing process leading to a homogenisation of microstruc-
tural geometrical properties [1,2]. Further below we
will employ basic concepts of solid–state transforma-
tion in order to interpret the experimentally observed
hydration kinetics of cement, See Section III.

The massive introduction of hydraulic binders into
daily engineering problems challenges a better under-
standing on how these materials work. Beside this are
cementing processes also of great importance for cer-
tain geological problems, i.e., for the formation, prop-
erties and behaviour of sedimentary bassins [3]. Typi-
cal hydraulic binders are plaster, cement, mortar, and
In the following we will focus on the hy-
concrete.
dration of neat Portland cement (tricalcium silicate)
more closely.

Basic phenomenological aspects of cement hy-
Initially
dration can be characterized as follows.
ﬁne grained cement powder (here tricalcium silicate,
C3S ≡ Ca3SiO5, with grain diameters typically rang-
ing between 5 µm and 50 µm [4]) is mixed well with
water. Tricalcium silicate is a well crystallized com-
pound ( ρ = 3.21 g cm−3) and the employed pow-

1

ders typically have speciﬁc surface areas of order of
3 · 103 cm2 g−1 [5]. Rapidly after mixing the ce-
ment particles start to dissolve. The principal re-
action products are solvated ions (Ca2+, OH − and
H2SiO2−
4 ) diﬀusing within the solvent. The ion
concentrations are bounded themselve by ﬁnite sol-
ubility products above which hydrate phases start
to precipitate from solution, preferable on surfaces
of already existing hydrates. There are two associ-
ated hydrates, a) the cement hydrate (C1.5SH2.5 ≡
(CaO)1.5 (SiO2) (H2O)2.5) and b) the Portlandite
(CH ≡ Ca(OH)2), which compete for the common
calcium and hydroxyl ions. The cement hydrate (
ρ = 2.35 g cm−3) is amorphous in contrast to the crys-
talline Portlandite ( ρ = 2.24 g cm−3).

The process of cement dissolution, ion diﬀusion, and
hydrate precipitation is usually referred as ‘cement
hydration’. The ion diﬀusion represents the phys-
ical coupling between the chemical dissolution and
precipitation reactions leading to a complex physico–
chemical evolution of hydrate microstructure.

In Fig. 1 we show a hydrated microstructure after
40 hours of hydration time. Typical is the leaf/foil–
like structure.

In the following we shall propose on the basis of
already published NMR measurements an empirical
global reaction rate law for the hydration of cement
pastes for initial water to cement weight ratios w/c =
0.5. The observed values for the kinetics exponents
can be understood – in parts – by classical solid–state
transformation theory.

II. EXPERIMENTAL RESULTS AND KINETIC
RELATIONSHIPS

The hydration of cement is spontaneous (exother-
mic) and irreversible and can be characterized by the
global net reaction [5,6],

 
 
 
 
 
 
C3S(s) + 4H2O(ℓ)

k⇀ C1.5SH2.5(s) + 1.5CH(s), (2.1)

where k denotes an eﬀective rate constant charac-
terizing the solid to solid conversion rate. Because
Eq. (2.1) describes a net reaction originating from
various subprocesses the stoichiometric numbers in
Eq. (2.1) are not related to the kinetic exponents of
the overall reaction rate law. The kinetics of cement
hydration has been experimentally studied to some
extent by calorimetric and conductimetric measure-
ments [5,7], by X-ray diﬀraction [8,9], by Raman spec-
troscopy [10], as well as by NMR spectroscopy [11–14].

A. NMR Measurements

29Si NMR spectroscopy has been used to exper-
imentally determine the CSH growth rate [11–14].
The employed method (Single Pulse Excitation with
Magic Angle Spinning (MAS/SPE)) is based on the
fact that in the NMR spectrum the signal of the C3S
silicon nuclei (monomer) is separated from those of
CSH silicon nuclei (dimers and trimers) [15]. The
distinction of dimer (silicon chain ends) and trimer
(inside silicon chains) signals has been used to inves-
tigate the polymerization process within the cement
hydrate, see for example Ref. 12.

In order to enhance the signal/noise ratio one gen-
erally needs to accumulate a great number of times
the NMR signal. To achieve these accumulations and
in order to obtain quantitative information about the
populations of the diﬀerent chemical species present in
the specimen, one needs to strictly respect the relax-
ation of each population between subsequent accumu-
lations. We have selected from the literature results
obtained taking this condition into account [11–13].
NMR signal intensities, Ik, are in general proportional
to the absolute number nk of excited silicon nuclei of
species k within the sample, Ik = Γnk, with Γ being
the constant of the measurement (species k denotes
a silicon nuclei belonging to a monomer, dimer, or
trimer silicon cluster). The proportionality constant
is usually eliminated by considering relative signal in-
Pj Ij which correspond to mole fractions
tensities Ik/
Pj nj deﬁnes the ab-
xk = nk/
solute silicon mass scale. The NMR measurements
we refer to, provide plots of the time-dependent mole
fractions for monomer, dimer and trimer silicon nuclei
[11–13]. However, plots for mole fractions show, as
will be demonstrated below, more complex algebraic
behavior.

Pj nj. The constant

B. Schematic Representation

In order to get an idea about the global hydration
kinetics of cement we consider the chemical net reac-
tion (2.1) in a more schematic representation,

A k⇀ B,

(2.2)

where the species A and B refer to silica nuclei of
C3S and CSH respectively. We denote the anhydrous
C3S (monomer) mole fraction as xA(t) and the CSH

(dimer as well as trimer) mole fraction as xB(t), i.e.,
xA(t) + xB(t) = 1.

The reader is reminded that Eq. (2.2) describes pre-
cisely a solid–state transformation as mentioned in the
introduction, however, there is one fundamental diﬀer-
ence in that the dimeric and trimeric silicon nuclei B
are not initially solvated within the silicon monomers
A. The B nuclei become rather formed within the
liquid solution which does not appear in Eq. (2.2).

It is here the place to say something about the
range of validity, the similarities, and the diﬀerences
of Eqs. (2.1) and (2.2).

Strictly speaking, the above net reactions can only
hold, if the employed water to cement weight ratio
is not too high, that is to say the number of sol-
vated ions should be always orders of magnitudes
lower than the number of molecules belonging to the
solid state, i.e., Eqs. (2.1) and (2.2) are inconsistent
in the limit of inﬁnite dilution. A proximate condi-
tion for this is a comparison of the cement to water
concentration with the solubility of Portlandite, SCH,
nC3S(t0)/VH2O(t0) ≫ SCH ≈ 2 · 10−2 mol liter−1, or
w/c ≪ 200. The here considered experimental data
certainly fulﬁll this condition, i.e., w/c ≈ 0.5.

Furthermore Eq. (2.1) describes a solid–liquid to
solid transformation, however, Eq. (2.2) a solid to
solid transformation. It is thus natural that both reac-
tions describe very diﬀerent things, if the initial water
to cement ratio is so low that the water severely be-
comes a limiting reactant for the hydration process
(case of very thick pastes). To be more speciﬁc, the
hydration following Eq. (2.1) cannot be completed for
chemical reasons, if 4nC3S(t0) > nH2O(t0) or equiv-
alently if w/c < (w/c)∗ = 0.31. It is, a priori, diﬃ-
cult to judge whether the employed experimental wa-
ter/cement ratio w/c = 0.5 is suﬃciently large in or-
der to exclude a systematic eﬀect on hydration due to
limiting water. However, as we will see further below,
considering the kinetics of the ‘deacceleration’ period,
water is very unlikely a chemically limiting reactant.
It is, however, not possible to determine from the con-
sidered measurements any water-speciﬁc kinetic expo-
nent for the associated rate law of Eq. (2.1). The de-
termination of such a dependency, would require a set
of experiments, conducted for diﬀerent initial water
to cement ratios. Similarly it is not possible to deter-
mine kinetic exponents for Portlandite (CH) from the
considered measurements, because nCSH is directly
proportional to nCH at every instant. In order to iso-
late the kinetic inﬂuence of precipitated Portlandite
on the overall hydration kinetics one needs to break
up the direct proportionality between nCSH and nCH.
Preferable this could be done by examination of the
hydration rate dependence for diﬀerent initial CH ad-
mixtures, i.e., nCH(t0) > 0. Bearing the foregoing
caveats in mind, it should be obvious why we consider
the schematic reaction (2.2). We are only in position
to characterize the kinetic inﬂuence of reactants and
products on the cement hydration. But already this
limited information will be, in our opinion, informa-
tive.

2

C. Kinetic Relationships

and

In the following we consider the ratio of silica mole

fractions,

f (t) = xB(t)/xA(t),

(2.3)

varying between 0 (no hydrates at time t = 0) and
∞ (complete hydration at time t = ∞). Figure 2
shows a double-logarithmic plot of f (t) versus the
hydration time. This ﬁgure reveals several interest-
ing facts about the hydration kinetics which will be
addressed in this paper. We note that the consid-
ered experimental data have been taken from three in-
dependent publications obeying similar experimental
conditions (room temperature, normal pressure, ge-
ometry of specimens, and initial water/cement weight
ratio w/c = 0.5), see [11–13] for details. The rela-
tively narrow scatter of the data over order of magni-
tudes demonstrates consistent and reproducible mea-
surements.

We observe, within in the scatter, two power laws
separated by a sharply deﬁned characteristic time
t× = 16 hours with value f× ≡ f (t×) = 0.6. For
the ‘early’ hydration period (t < t×) we obtain,

f (t) = f× (

t
t×

)γ,

(2.4)

with an exponent γ = 2.5. Below 5 hours of hydra-
tion time there are no quantitative NMR data avail-
able, because of the bad signal/noise ratio for the
CSH. Above t× = 16 hours the hydration dramat-
ically slows down,

f (t) = f× (

t
t×

)δ,

(2.5)

with δ = 0.5. This second period takes place from
16 hours to at least 8 · 103 hours of hydration time.
Equations (2.4) and (2.5) deﬁne a continuous depen-
dency in time. However, the ﬁrst derivative of f (t)
taken at t× is not continuous, which might appear
unphysical. The discontinuity in df /dt arises, because
we have assumed a zero crossover range in Eqs. (2.4)
and (2.5) to obtain the best representation of experi-
mental data. It is interesting to note, that an ansatz
of the form

t/t× = 2−1/m[(f /f×)αm + (f /f×)βm]1/m,

(2.6)

with proper chosen exponents α = 0.4 and β = 2.0
gives a quite satisfactory representation of data for
high integers of m, see Fig. 2 [16]. The best repre-
sentation is found for m → ∞, which corresponds to
Eqs. (2.4) and (2.5).

In the following we propose relations between the
above mentioned exponents γ and δ and the kinetic ex-
ponents of an overall rate equation. The observed ex-
ponents will allow for some general statements about
the hydration mechanisms.

We note, that from Eq. (2.3) the trivial relations

xB(t) =

nB(t)
nA(t0)

=

f (t)
1 + f (t)

,

(2.8)

follow, where nA(t0) characterizes the absolute silica
mass scale. The overall rate equation for xA and xB
has to be ﬁrst order in time,

−

d
dt

xA =

d
dt

xB =

1
(1 + f )2

d
dt

f.

(2.9)

One particular observation from Eqs. (2.7), (2.8), and
(2.9) is that the global hydration rate can be repre-
sented as a product of powers of the mole fractions
xA and xB, if d
dt f follows a power-law in f . In such
case the reaction is of overall order two and f (t) fol-
lows a power-law in time, except for d
dt f ∼ f which
yields an exponential dependency in time. We have
already mentioned, considering the experimental re-
sults in Fig. 2, that f (t) follows indeed two power-
laws, Eqs. (2.4) and (2.5), seperated by a characteris-
tic time t×. Thus it is possible to extract two rate laws
from the measurements; one for ‘early’ times t < t×
and another one for ‘late’ times t > t×. Consider
f (t) = f× · (t/t×)ψ where for times t < t×, ψ = γ and
for times t > t×, ψ = δ, according to Eqs. (2.4) and
(2.5). The associated ﬁrst order diﬀerential equation
× f (ψ−1)/ψ.
is (d/dt)f = ψt
Inserting this into
Eq. (2.9) and resorting with respect to factors xB and
xA [Eqs. (2.8) and (2.7)] we obtain the explicit rate
equation in terms of mole fractions,

−1
× f 1/ψ

−

d
dt

xA =

d
dt

xB = ψt

−1
× f 1/ψ
× x

ψ−1
ψ

B x

ψ+1
ψ

A ,

(2.10)

with ψ = 2.5 for t < t× and ψ = 0.5 for t > t×.

Furthermore, by passing from mole fractions to con-
centrations, it is possible to determine the approxi-
mate eﬀective rate constant(s) from the experimen-
tally observed crossover point, the extracted expo-
nents, and the initial water to cement weight ratio. It
is convenient to consider ﬁrst the initial concentration
[A]|t0 = nA(t0)/V0 of cement in the overall specimen
volume V0 = VC3S(t0) + VH2O(t0) [17],

1
[A]|t0

= (1 +

ρC3S
ρH2O

·

w
c

)vC3S ≈ 0.18 liter mol−1,

(2.11)

with ρC3S/ρH2O = 3.21 and vC3S = 7.2 ·
10−2 liter mol−1 being the relative density and the
molecular volume of cement respectively. The con-
sidered water to cement weight ratio is w/c = 0.5.
We ﬁnd for the ‘accelerated’ period (t < t×),

−

d
dt

[A] =

d
dt

[B] = kt<t× · [B]0.6[A]1.4,

(2.12)

kt<t×

7 ·
2.5[A]|
with
10−6 liter mol−1 s−1, and for the ‘deaccelerated’ pe-
riod (t > t×)

≈

=

−1
t0 t

−1
× f 0.4
×

−

d
dt

[A] =

d
dt

[B] = kt>t× · [B]−1.0[A]3.0,

(2.13)

xA(t) =

nA(t)
nA(t0)

=

1
1 + f (t)

,

(2.7)

with
kt>t×
10−7 liter mol−1 s−1.

=

0.5[A]|

−1
t0 t

−1
× f 2.0
×

≈

6 ·

3

III. INTERPRETATION

Before we are going to present a possible expla-
nation for the hydration kinetics as manifested in
Eqs. (2.12) and (2.13) we would like to give a brief
account on another representation of the hydration
kinetics being more widespread in cement literature,
i.e., the degree of hydration α(t). The degree of hydra-
tion is usually referred as the relative amount (mole
fraction) of hydrated cement [18], α(t) ≡ xB(t) =
1 − xA(t). Therefore Eq. (2.8) gives the relation-
ship between α(t) and f (t) as deﬁned in Eq. (2.3).
Typical experimental curves for the degree of hydra-
tion exhibit sigmoidal shapes in linear representations.
The observed inﬂection points, however, do in general
not posses any particular signiﬁcance for a change in
chemical mechanism. This can be seen for example by
assuming in Eq. (2.10) Ψ > 1 for all times. The de-
gree of hydration will show an inﬂection point though
there is only a single chemical mechanism (rate law)
operative. Therefore it is not reliable to read oﬀ char-
acteristic times from α(t) diagrams. While α(t) ap-
proximates f (t) well if f ≪ 1 (early hydration) the
discrepancy becomes very large for f ≫ 1 (late hy-
dration).

The foregoing remark has hopefully illustrated why
we have avoided degree of hydration diagrams in our
considerations. As another motivation for our ap-
proach we present in Fig. 3 a so-called ‘Avrami–
Plot’ for the hydrated silica amount, i.e., a test on
the stretched exponential relationship xB = 1 −
exp(−(t/τ )k). Such empirical relationships are fre-
quently found for overall transformations [1]. It can
be clearly seen from Fig. 3 that the hydration data
cannot be described by such a relation.

The kinetic equations Eqs. (2.12) and (2.13) al-
low to make somewhat more substantial statements
about the global cement hydration mechanism(s).
During the acceleration period already existing hy-
drates catalyse the precipitation of new hydrates (pos-
itive kinetic exponent for the products in Eq. (2.12)).
The growth of connected hydrate structures appears
thus to be thermodynamically more favorable than an
uncorrelated ‘through solution’ precipitation mecha-
nism.

On the other hand in the deacceleration period
(t > t×) the ‘hydrate layers’ surrounding the cement
grains increasingly separate reacting anhydrous ce-
ment and water and thus hinder/block further C3S
dissolution. The hydrates are acting in the deaccel-
erated period as inhibitors (negative exponent for the
products in Eq. (2.13). The inversed role of hydration
products during the accelerated and deaccelerated pe-
riods appears to be experimentally evident from the
foregoing considerations.

A widespread assertion in cement literature is that
‘early’ hydration is controlled by chemical kinetics
whilst ‘late’ stage kinetics is being diﬀusion controlled.
We agree with the later assumption that ion diﬀu-
sion most probably represents the rate controlling
step within the deacceleration period. This is in fact
strongly indicated by the very low hydration rate at
large times, see Fig. 2.

However, there is no direct indication that the ac-

celeration kinetics is chemically limited. Obviously
Eq. (2.12) cannot describe initial nucleation (approxi-
mately within the ﬁrst 15 min) because there exist no
products at this times at all ([B]|t0 = 0). On the other
hand the early nucleation period is not accessible em-
ploying the here considered experimental techniques,
so there is no conﬂict in interpretation. One just has
to keep in mind that all experimental data points as
well as the thereof extracted power–laws are beyond
the nucleation period.

After the ﬁrst few minutes of bringing cement and
water into contact, the ions in solution rise their con-
centrations far beyond the equilibrium solubilities,
without precipitating at all. This can be understood
by viewing the process of heterogeneous nucleation as
overcoming a thermodynamical barrier (supersolubil-
ity [7]). Being supersaturated the hydrate nucleation
happens on the cement grain surfaces [19,18]. At this
instant a more or less signiﬁcant part of the solution
is strongly oversaturated with respect to the equilib-
rium solubility. The further precipitation (growth) of
the hydrates can thus be regarded to happen approx-
imately within a spatial uniform oversaturated solu-
tion (oversaturated interface layer). This is in so far
of concern as the uniformity of ‘initial conditions’ is
crucial to predict kinetic exponents for diﬀusion con-
trolled reactions. It also supposes that the nucleation
rate tends rapidly to zero as the hydrate microstruc-
ture further develops.

The hydrate microstructure has been experimen-
tally classiﬁed for a water to cement ratio w/c = 0.47.
Within the ﬁrst 4 hours foil–like microstructure pre-
cipitation is reported to happen radially away from
the cement grains (typical dimensions < 0.5 µm
and xB < 10−2). Thereafter (< 24 hours) the
formation of a gelatinous layer sourrouding the ce-
ment grains have been observed (thickness ≈ 0.5 µm
and xB(24 h) ≈ 0.3). Also needle-like precipitates
have been found. Finally after several days crum-
pled interlocking foils are observed (comp. Fig. 1).
It has been also reported that the precipitated mi-
crostructure morphologies are strongly inﬂuenced by
the available interparticle spacings [19]. There is
presently no straightforward way to predict/calculate
microstructural morphologies for such complex sys-
recently developed heterogeneous
tems, however,
reaction-diﬀusion models have received considerable
interest in this context [20].

The growth of a precipitate is kinematically very
complex. The precipitated geometry (microstructure)
cannot be predescribed in general beyond the initial
conditions but is rather a result of the associated inter-
face dynamics. The most simplest case is governed by
the growth of spherical precipitates of radius R from
an initially supersaturated solution of concentration
¯c. Let c = c(r) denote the particle concentration in
the solvent, csℓ the particle concentration within the
precipitate at the interface, cℓs(R) the particle con-
centration within the solvent at the interface and D
the diﬀusion coeﬃcient of particles in the solvent. One
has from continuity of mass,

d R
d t

=

D
csℓ − cℓs(R)

· (cid:16)

d c
d r (cid:17)r=R

.

(3.1)

4

This is the equation of motion for the interface (in
spherical co–ordinates). It establishes the direct pro-
portionality between local growth rate and particle
current density at the interface.
In general cℓs de-
pends, as a consequence of interfacial tension, on the
(local) interface curvature.
If the precipitate is not
too small one often assumes the zero curvature limit,
i.e., cℓs(R) ≈ cℓs(∞). The most interesting point in
Eq. (3.1) is that the gradient of c contains ‘global in-
formation’ about the interface because c(r) is the so-
lution of the (stationary) diﬀusion equation,

∆ c(r) = 0,

(3.2)

obtained under boundary conditions c(∞) = ¯c and
c(R) = cℓs(∞). The solution of Eqs. (3.1) and (3.2)
is the well known parabolic growth law [1],

R2 − R2

0 = 2D

¯c − cℓs(∞)
csℓ − cℓs(∞)

(t − t0).

(3.3)

Similarly a parabolic solution is also obtained for the
growth of a ﬂat interface. More generally does the lo-
cal growth rate dynamically depend on (at least) two
competitive mechanisms (a) ﬂattening of high curva-
ture regions due to interfacial tension and (b) sharpen-
ing of these regions due to preferential diﬀusive growth
at these ‘tips’. Numerical boundary integral methods
have been developed in order to study the associated
interface dynamics and instability, e. g. see Ref. [21].
For a pertubative treatment see for example Ref. [22].
Despite the complexity of involved microstructural
transformations the natural question arises whether
there exists at a given time a typical microstructure
and a typical mode of growth within the system.

Suppose the case of a vanishing nucleation rate dur-
ing precipitate growth. If the precipitating structure
grows geometrically in form of a plate (see the above
experimental classiﬁcation scheme) then the variation
in mole fraction of precipitated phase in time is pre-
dicted theoretically for xB ≪ 1 as xB ∼ (t/τ )5/2 [1]
with τ being a characteristic timescale for the growth
[23]. The plate’s rim grows at a constant rate while its
thickness grows parabolically in time, explaining the
exponent 5/2. For xB ≪ 1 one can replace the quan-
tity f (t) by xB(t) in all foregoing considerations. One
is lead to the conclusion that for early foil–like hydrate
growth γ = 5/2 and (ψ − 1)/ψ = 3/5 in Eqs. (2.4) and
(2.10) respectively. This is in agreement with the con-
sidered measurements, see Fig. 2.

What causes the observed slowing down of the hy-
If a single foil would precipitate
dration process?
in a spatially inﬁnite supersaturated solution there
would be no obvious reason for a slowing down of
the hydration process as there exists no characteristic
length scale. However, the here considered case of ce-
ment paste is an assembly of small anhydrous cement
grains immersed in water. The mean free distance be-
tween particles has to be considered as a typical length
scale for the transport and for the precipitation pro-
cess (xB ≪ 1). The size of the growing ﬂakes can-
not exceed this because of spatial hindrance. Hence
there must exist a typical time scale t× at which the
ﬂakes change their mode of growth into thickening
only. We interpret this typical time as the crossover

time t× ≈ 16 hours observed in Fig. 2. Growth of
ﬂakes in the thickening only mode is expected to hap-
pen parabolically in time for diﬀusion limited precip-
itation reactions [1]. Therefore we predict the expo-
nents of the deaccelerated period to be δ = 1/2 and
(ψ − 1)/ψ = −1 in Eqs. (2.5) and (2.10) respectively,
in agreement with the experimental data Fig. 2.

Apparently with the above assessments we have re-
lated the experimentally observed kinetic exponents
of the hydration products to microstructural informa-
tion. Certainly there is no unique mapping between
kinetics and geometry, but this constitutes a complex
question in terms of Eqs. (3.1) and (3.2) to be studied
in future on its own right.

So far we have restricted our considerations to the
case of a water to cement weight ratio w/c = 0.5. The
question arises whether the kinetic exponents are uni-
versal and how the observed typical crossover quanti-
ties t× and f× do depend on w/c. We show in Fig. 4
experimental (replotted) data for three diﬀerent w/c
ratios. The data do not collapse, which is not so sur-
prising because the typical interparticle spacing does
depend on w/c. Qualitatively higher w/c ratios cor-
respond to lower charateristic times t× and lower hy-
drate ‘amounts’ f×. For early times we observe ki-
netic exponents that do (apparently) depend on w/c.
Interestingly are the kinetic exponents δ for the deac-
celeration period in all cases close to 1/2. However, we
have not studied this in further detail because there
are less experimental data available than for the stan-
dard case w/c = 0.5, i.e., the hydration curves need
to be experimentally reproducible for given w/c.

IV. CONCLUSION

We have reconsiderd NMR measurements on the
overall hydration kinetics of tricalcium silicate pastes
(w/c = 0.5) In Sec. II B we brieﬂy discussed the con-
ditions for w/c to be fulﬁlled in order to allow a mean-
ingfull discussion in terms of a global net reaction and
its schematic counterpart.
In Sec. II C we demon-
strated that the time dependent ratio of hydrated and
unhydrated silica mole numbers can be well character-
ized by two power–laws in time, x/(1 − x) ∼ (t/t×)ψ.
For early times t < t× we found an ‘accelerated’ hy-
dration (ψ = 5/2) and for later times t > t× a ‘deac-
celerated’ behavior (ψ = 1/2). The crossover time
has been estimated as t× ≈ 16 hours. We inter-
preted these results in terms of a global second order
rate equation indicating that (a) hydrates do catal-
yse the hydration process for t < t×, (b) they do in-
hibit hydration for t > t× and (c) the value of the
associated second order rate constant is of magnitude
6 · 10−7 − 7 · 10−6 liter mol−1 s−1. We have argued
in Sec. III, by considering the hydration process actu-
ally being furnished as a diﬀusion limited precipitation
that the exponents ψ = 5/2 and ψ = 1/2 directly in-
dicate a preferentially ‘leaf’ like hydrate microstruc-
ture. This argument was supported by experimen-
tal observations of cellular hydrate microstructures for
this class of materials.

5

ACKNOWLEDGMENTS

F. T. would like to acknowledge ﬁnancial support
from CEC under grant number ERBFMBICT 950009.

[1] , V. Raghavan and M. Cohen in Treatise on Solid
State Chemistry, Vol. 5 Changes of State, ed. by N.B.
Hannay (Plenum Press, London, 1975) pp. 67–127.

[2] G. Sauthoﬀ, J. de Physique IV 6, 87-97 (1996).
[3] E.H. Oelkers and P.A. Bjorkum, American Journal of

Science 296, 420-52 (1996).

[4] M.D. Cohen and R.D. Cohen, J. Mat. Sci. 23, 3816-

20, (1988).

[5] P. Barret and D. Bertrandie, Journal de Chimie

Physique 83, 11/12, 765-75, (1986).

[6] This is an approximation. A particularity of the ce-
ment hydration problem is that the appearing cement
hydrate exhibits a variable stoichiometry in course
of its formation (‘solid solution’). The selected stoi-
chiometries in Eq. (2.1) correspond to the ‘late stage’
proportions in cement hydration [5].

[7] D. Damidot and A. Nonat, Advances in Cement Re-

search 6 (21), 27-35, (1994).

[8] S. Tsumura, Zement Kalk Gips 11, 511-8 (1966).
[9] I. Odler and H. Doerr, Cement and Concrete Research

9, (2), 239-48 (1979).

[10] M. Tarrida, M. Madon, B. Le Rolland and P. Colom-

bet, Advn. Cem. Bas. Mat. 2, 15-20 (1995).

[11] C.M. Dobson, D.G.C. Goberdhan, J.D.F. Ramsay
and S.A. Rodger, J. Mat. Sci. 23, 4108-14 (1988).
[12] A.R. Brough, C.M. Dobson, I.G. Richardson and
G.W. Groves, J. Mat. Sci. 29, 3926-40 (1994).
[13] J. Hjorth, J. Skibsted and H.J. Jakobsen, Cement and

Concrete Research 18, 789-98 (1988).

[14] S.U. Al-Dulaijan, G. Parry-Jones, A.-H. J. Al-Tayyib
and A. I. Al-Mana, J. Am. Ceram. Soc. 73, (3), 736-
39 (1990); H. Justnes, I. Meland, O.J. Bjoergum and
J. Krane, Adv. Cem. Res. 3, (11), 111-16 (1990).
[15] J.G. Engelhardt and D. Michel, High-Resolution solid
state NMR of silicates and zerlites (J. Wiley Editions
1987).

[16] Note that f (t) cannot be expressed as the sum of two
powers in time because γ > δ, compare Eqs. (2.4) and
(2.5). However, the time can be expressed as a sum of
two powers of f (t).

[17] We assume here a constant and characteristic refer-
ence volume V0. This is an approximation in that
the hydrating system Eq. (2.1) undergoes a chem-
ical shrinkage in course of the hydration (nominal
≈ 10 V ol %, however, in practice less).

[18] H.F.W. Taylor, Cement Chemistry, (Academic Press,

London, 1990).

[19] H. M. Jennings, B. J. Dalgleish and P. L. Pratt, J.

Am. Ceram. Soc. 64, (10), 567–72 (1981).

[20] F. Tzschichholz, H. J. Herrmann and H. Zanni, Phys.

Rev. E 53, (3), 2629-37 (1996).

[21] D. A. Kessler, J. Koplik and H. Levine, Adv. Phys.

37, 255-336 (1988).

[22] R. Lovett, P. Ortoleva and J. Ross, J. Chem. Phys.

69, (3), 947 (1978).

[23] The timescale τ arises from such quantities as ini-
tial oversaturation, diﬀusion coeﬃcients, and water–
hydrate interface properties.

6

FIG. 1. SEM micrograph of hydrated tricalcium silicate cement after 40 hours hydration time. The initial water to

cement ratio was 0.5. Note the leaf–like hydrate microstructure (with courtesy of Institute Francais du Petrole).

7

100

10

)
t
(
f

1

0.1

0.01

1

10

100
t (hours)

1000

10000

FIG. 2. Double logarithmic plot of the measured mole ratio between hydrated and unhydrated silica f (t) = xB/(1−xB)
as a function of hydration time t employing NMR and TGA (Thermogravimetry). All measurements correspond to a
water to cement weight ratio w/c = 0.5 conducted under room temperature and normal pressure. The data are well
represented by two power-laws: for t < t× by Eq. (2.4) (γ = 2.5) and for t > t× by Eq. (2.5) (δ = 0.5). The dashed line
shows the corresponding numerical ﬁt according to Eq. (2.6) employing t× = 16 hours, f (t×) = 0.6, and m = 20. Data
from (⋄) Ref. 11 (NMR), (×) Ref. 12 (NMR), (✷) Ref. 13 (NMR) and (+) Ref. 11 (TGA).

8

)

A
_
x
(
g
o
l

-

10

1

0.1

0.01

1

10

100
t (hours)

1000

10000

FIG. 3. ‘Avrami’–Plot for the amount of hydrated silica (double logarithmic plot of the negative logarithm of unhy-
drated silica amount − log(xA) versus time t). If the hydration kinetics would follow a generalized Avarami–Johnson–Mehl
law, i.e., xA = 1 − xB = exp(−(t/τ )k), the data should lay on a single straight line of slope k. It can been seen that this
is not the case. The data were taken from Ref. 12 (NMR).

9

 
)
t
(
f

100

10

1

0.1

0.01

0.001

1

10

100
t (hours)

1000

10000

FIG. 4. Same representation as in Fig. 2 but for various water cement ratios employing XDR (x-ray diﬀraction)
and Raman spectroscopy. The measurements were conducted at room temperature and normal pressure. The dashed
line shows again the powerlaw ﬁt corresponding to Fig. 2 for comparison purposes. Data from (✷) Ref. 10 (Raman,
w/c = 0.4), (⋄) Ref. 8 (XDR, w/c = 0.45) and (+) Ref. 9 (XDR, w/c = 0.7). Note that the data do not collapse,
however, for large times they yield similar slopes ≈ 1/2 compared to Fig. 2.

10"
"The Effect of Structural Distortions on the Electronic Structure of
  Carbon Nanotubes","  We calculated the effects of structural distortions on the electronic
structure of carbon nanotubes. The key modification of the electronic structure
brought about by bending a nanotube involves an increased mixing of $\sigma$
and $\pi$-states. This mixing leads to an enhanced density-of-states in the
valence band near the Fermi energy region. While in a straight tube the states
accessible for electrical conduction are essentially pure C($2p_{\pi}$)-states,
they acquire significant C($2sp_{\sigma}$) character upon bending. Bending also
leads to a charge polarization of the C-C bonds in the deformed region
reminiscent of interface dipole formation. Scattering of conduction electrons
at the distorted regions may lead to electron localization at low temperatures.
",http://arxiv.org/pdf/cond-mat/9808269v2,3,"The Eﬀect of Structural Distortions on the Electronic Structure

of Carbon Nanotubes

Alain Rochefort∗,† Dennis R. Salahub† ,†,‡ and Phaedon Avouris‡,§

† Centre de Recherche en Calcul Appliqu´e (CERCA), 5160 boul. D´ecarie,

bureau 400, Montr´eal, (Qu´ebec) Canada H3X 2H9

‡ D´epartement de Chimie, Universit´e de Montr´eal, C.P. 6128,

Succ. Centre-Ville, Montr´eal, (Qu´e) Canada H3C 3J7

§ IBM Research Division, T.J. Watson Research Center, P.O. Box 218,

Yorktown Heights, NY 10598, USA

Abstract

We calculated the eﬀects of structural distortions on the electronic structure of carbon

nanotubes. The main eﬀect of nanotube bending is an increased mixing of σ and π-states.

This mixing leads to an enhanced density-of-states in the valence band near the Fermi energy.

While in a straight tube the states accessible for electrical conduction are essentially pure

C(2pπ)-states, they acquire signiﬁcant C(2spσ) character upon bending. Bending also leads

to a charge polarization of the C-C bonds in the deformed region reminiscent of interface

dipole formation. Scattering of conduction electrons at the distorted regions may lead to

electron localization.

I. INTRODUCTION

Carbon nanotubes are an interesting class of nanostructures which can be thought of

as arising from the folding of a graphene sheet. Depending on the width of the graphene

8
9
9
1

v
o
N
6
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
9
6
2
8
0
8
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

∗e-mail: rochefor@cerca.umontreal.ca

†e-mail: Dennis.Salahub@umontreal.ca

‡e-mail: avouris@us.ibm.com

 
 
 
 
 
 
The Eﬀect of Structural Distortions . . . by Rochefort et al.

2

sheet and the way it is folded a variety of diﬀerent nanotube structures are formed. The

nanotubes are usually described using the chiral vector: Ch = n~a1 + m~a2, where ~a1 and

~a2 are unit vectors of the hexagonal honeycomb lattice and n, m are integers, and a chi-

ral angle θ which is the angle of the chiral vector with respect to the zigzag direction of

the graphene sheet1,2. The one-dimensional electronic structure of a nanotube with indices

(n, m) can be predicted on the basis of the two-dimensional electronic structure of graphite.

Armchair (n, n) nanotubes have a band degeneracy between the highest π-valence band and

the lowest π∗-conduction band at k =

(2/3)(π/a0), where these bands meet the Fermi

±

level, and should show metallic behavior. Among the other (n, m) nanotubes, the ones with

−

n

m = 3i (where i is an integer) should also be metallic, while the rest should have a

band-gap and, therefore, be semiconductors.1,2 Recent STM spectroscopy experiments ver-

iﬁed these predictions3,4. Their electrical properties coupled with the superb mechanical

strength of the nanotubes5,6 makes these materials promising candidates for use as ideal

one-dimensional (1-D) conductors, if ballistic transport can be achieved or, in the case of

semiconducting tubes, as key building elements of novel nanoelectronic devices7,8.

The above discussion of the properties of carbon nanotubes is based on the assumption

that they have the perfect symmetry expected for a free nanotube. Nanotubes, however, are

usually studied and utilized while being supported on a solid substrate. Studies of supported

nanotubes using atomic force microsopy9 and molecular mechanics calculations10 show that

supported nanotubes can undergo signiﬁcant axial and radial distortions. The nanotubes

tend to bend so as to conform to the morphology of the substrate and thus optimize the van

der Waals adhesion forces. Similarly, the side of the nanotube in contact with the surface

may ﬂatten so as to optimize the contact area. The extent of the above distortions depends

on the balance between the increased adhesion and the rise in strain energy produced by

the distortions. These structural distortions can, in turn, modify the nanotube’s electronic

structure and electrical transport properties. For example, a reduction in symmetry may

result in the lifting of degeneracies. An increased curvature can enhance σ-π mixing and

The Eﬀect of Structural Distortions . . . by Rochefort et al.

3

rehybridization, while bond strain can modify the band-gap of semiconducting tubes. These

eﬀects may produce local barriers at the distortion regions and aﬀect electrical transport.

Previous theoretical work on this problem11 focused only on the π-electrons, ignoring the

σ-electrons and the possibility of π-σ mixing, and concluded that the eﬀects of bending dis-

tortions on electronic structure are insigniﬁcant. Experimentally, bends in quantum wires

produced by patterning of two-dimensional electron-gas systems have been shown to aﬀect

transport and lead to interesting interference phenomena12,13. It is thus likely that similar

eﬀects may be induced by bends in nanotubes and be observable in low temperature trans-

port experiments.

Here we explore the eﬀects of structural distortions on the electronic structure of nan-

otubes by performing Extended H¨uckel calculations on straight and bent armchair (6, 6)

single-wall nanotubes. Important changes in the local density of states (LDOS) of σ and

π-electrons and increased π-σ mixing are observed to develop as the nanotube is distorted.

These changes become stronger with increasing bending angle. In addition, a charge po-

larization of the C-C bonds in the distorted regions is observed. The electronic structure

changes are expected to have important implications for the low temperature electrical trans-

port properties of the nanotubes, and should also aﬀect locally their chemical reactivity.

II. COMPUTATIONAL DETAILS

Electronic structure calculations were performed on a 972 atom cluster model (948 C and

24 H that saturate the dangling bonds at the ends) of a (6, 6) nanotube using the extended

H¨uckel method14. The parameters used for carbon and hydrogen were: C2s (Hii = -21.4 eV,

ζ = 1.625), C2p (Hii = -11.4 eV, ζ = 1.625), and H1s (Hii = -13.6 eV, ζ = 1.3), where Hii

and ζ are the orbital energy and Slater exponents, respectively.

In the undistorted nanotube, the C-C and C-H bond lengths were ﬁxed at the values

obtained for bulk graphite15 that are 1.42 and 1.09 ˚A, respectively. We have built models

The Eﬀect of Structural Distortions . . . by Rochefort et al.

4

with bending angles of 30, 45 and 60◦ using a constant length segment in the middle of the

tube to introduce the distortion. Prior to the electronic structure calculations, the geometry

of the bent nanotubes was optimized with the molecular mechanics program TINKER16

employing the MM3 force ﬁeld17.

In the structural relaxation and optimization process,

the ﬁrst 5 sections (a section is deﬁned as a single circular plane of carbon atoms that are

packed along the length of the nanotube) at the two ends of the nanotube were kept ﬁxed

in order to maintain the bending angle. In the molecular mechanics calculations, we used

the MM3 alkene parameters except for the bond length parameter which we modiﬁed from

that of an alkene (1.33 ˚A) to that of bulk graphite (1.42 ˚A). Density of states (DOS) plots

were generated by convoluting the computed electronic structure with a 50:50 combination

of Gaussian and Lorentzian functions. In order to analyze the origin of the band states, we

performed a series of projections of the DOS where each molecular orbital was weighted by

the contribution obtained from a Mulliken analysis of speciﬁc carbon atoms.

III. RESULTS AND DISCUSSION

Figure 1 shows the computed electronic structure of a perfect (6, 6) armchair nanotube

model. This model contains 948 carbon atoms distributed in 79 circular sections. The over-

all DOS spectrum shows high binding energy (BE) states extending from -22 to -12 eV that

are mainly σ-bond states involving C(2s) orbitals. The σ-bond states associated with C(2p)

orbitals lie at lower BE between -12 and 0 eV with respect to the Fermi energy (EF ). The

ﬁne structure visible in the high BE region involves van Hove singularities characteristic of

one-dimensional systems18. Each of these peaks is characterized by a speciﬁc number of

nodes in the wavefunction along the circumference of a single nanotube section, while the

1/√E tail reﬂects the free electron character along the tube axis. The more intense DOS

bands between -6 and 0 eV are due to overlapping π- and σ-bond states, with the π-states

centered at a slightly lower binding energy. The set of DOS bands between 0 and 8 eV

are essentially π∗-states. The σ∗-states (not shown) extend above 10 eV. The valence and

conduction band states near the “gap” edges have π-character; electric transport involves π

The Eﬀect of Structural Distortions . . . by Rochefort et al.

5

electrons. A more detailed view of the DOS in the region around the Fermi level is shown

in the inset of Figure 1.

The local density of states (LDOS) proﬁles presented in Figure 1 where the projection is

summed over the contribution of the twelve carbon atoms contained in a particular section of

the tube shows that the electronic structure along the tube is quite uniform. The similarity

of the LDOS proﬁles indicates that the wavefunction of this ﬁnite size tube is delocalized

over its entire length.

Figure 2 shows the model structures used to evaluate the eﬀects of bending on the elec-

tronic properties of carbon nanotubes. The following approach is used to generate the 30◦,

45◦ and 60◦ bend models: a section of constant length in the middle of the tube is bent

and the atomic structure of the nanotube is then optimized with molecular mechanics. As

the bending angle increases, the deformation of the atomic structure of the tube increases,

particularly in the central region of the tube. The 30◦ bend induces a compression of the

C-C bonds in the inner side of the tube while the bonds on the outer side are stretched. The

general tubular shape, however, remains essentially intact in both straight and bent regions.

After a 45◦ bend, the increased compression of C-C bonds in the center of the nanotube

leads to a ﬂattening of its cross-section. Further bending increases this ﬂattening to the

point where the force between opposite nanotube walls becomes high enough to induce the

formation of a kink as in the 60◦ model of Figure 2. The front views of the central sections

of the bent tube models clearly show the drastic structural deformations that occur as the

bending angle is increased from 45◦ to 60◦.

The changes in the electronic structure (from -25 to 10 eV) induced by the bending of

the armchair (6, 6) nanotube appear weakly in the total density of states spectrum. This

is because the deformed region is relatively small compared to the total length of the nan-

otube. On the other hand, the LDOS along the nanotube length. i.e. the LDOS generated

The Eﬀect of Structural Distortions . . . by Rochefort et al.

6

by adding the contributions of the twelve carbon atoms contained in a particular section of

the nanotube, provides a much clearer view of the changes brought about by bending. As

already discussed, in a straight (0◦) nanotube there is no obvious variation of the LDOS

along its length (Figure 1). Upon bending, the most obvious change is a broadening of the

ﬁne structure of the overlapping σ

−

π states near EF , which becomes particularly large in

the 60◦ bent example. Far from the distorted region, the LDOS proﬁles are very similar

(in terms of band position and structure) in all bent nanotube models.

In the distorted

segment of the the tube (i.e. near the central section), the ﬁne structure of the σ

π band

−

disappears. The σ-bond states at higher binding energy arising from a combination of C(2s)

orbitals are similarly altered. In general, σ-bonds in the bent region appear to be the most

perturbed by the deformation, while π-bonds are aﬀected to a lesser extent.

Another interesting result of the deformation involves the distribution of net charge along

the length of the nanotube shown in Figure 3. Upon increasing the bending angle from 0◦ to

60◦, the net charge ﬂuctuation rises. Furthermore, the position in the bent region where the

largest ﬂuctuations are observed changes with bending angle. A smooth 30◦ bending leads to

a broad distribution of small charges among all carbon atoms in the bent region. A bending

of 45◦ gives a larger charge ﬂuctuation in the innermost deformed region. Finally, the kink

in the 60◦ bent nanotube has a particularly dramatic eﬀect on both the magnitude and the

spatial extent of the net charge distribution leading to large charge ﬂuctuations displaced

toward the central edges of the kinked region. In general, the largest ﬂuctuations are found

where the changes in the nanotube geometry (RC−C) are most pronounced. This localiza-

tion of charge ﬂuctuations is directly related to the changes observed in the σ-wavefunction

discussed above; the larger ﬂuctuations arise from an enhanced σ-orbital contribution or, in

other words, from an increased sp2

sp3 rehybridization.

−

To investigate how the electrical transport properties of the nanotube may be aﬀected by

bending, we focus on the π-states near EF . The upper part of Figure 4 shows an expanded

The Eﬀect of Structural Distortions . . . by Rochefort et al.

7

view of the DOS in this energy range. Bending is found to induce an increased DOS near

EF (at about -1 eV BE). Furthermore, the DOS at EF remains ﬁnite in all bent nanotubes

studied. More informative are LDOS curves along the nanotube length. In the case of a

straight tube, the lack of change in LDOS along the tube indicates that π and π∗ states near

EF are not conﬁned in a speciﬁc area but are delocalized along its length. Upon bending,

small changes in the electronic structure are observed at the tube boundaries. These changes

result from the relaxation of the atomic structure of the entire nanotube upon bending. The

largest changes are found, however, at the centers of the nanotubes (section 40), in partic-

ular in the kinked tube (60◦ angle). Figure 4 shows an overall increase in the LDOS near

EF in the distorted regions of the nanotubes. Analysis of the wavefunction indicates that

the induced density contains an increased contribution of C(2spσ) states. The shift of the

valence band edge to higher energy and the increased C(2spσ) contribution can both be

explained by a bending-induced π-σ hybridization. Such a rehybridization already exists to

some extent in the straight tube due to its curvature19, but becomes enhanced by further

bending.

In conclusion, we have shown that the local electronic structure of carbon nanotubes

is modiﬁed as a result of structural distortions. Such distortions can be the result of the

interaction of the nanotubes with the topography of the substrate they are placed on10, with

the metal electrodes used to monitor their electrical properties20, or as a result of controlled

manipulation9. Two types of perturbations of the electronic structure as a result of bending

are predicted by our calculations: First, a modiﬁcation of the LDOS in the deformed region

of the nanotube leading to an increased DOS near EF and a shift of the valence band edge to

a lower binding energy. These eﬀects are due to increased π-σ hybridization. Discussion of

electrical transport in distorted tubes must take into account this hybridization. Secondly,

we observe a charge polarization of the C-C bonds in the deformed region. The magnitude

of this polarization increases with the bending angle and is particularly severe upon kink

formation. The above changes in the local electronic structure are expected to scatter the

The Eﬀect of Structural Distortions . . . by Rochefort et al.

8

conduction electrons at the deformed regions leading to carrier localization, especially at low

temperatures. Truly ballistic transport in nanotubes may require perfectly straight tubes21.

This conclusion is supported by recent experiments by Bezryadin et al.20 who examined the

electrical behavior of a chiral single-wall nanotube draped over a set of several Pt electrodes.

Their studies indicated that electrically the nanotube was broken into a series of isolated

islands as a result of barriers generated by the bending of the tube over the raised electrodes.

Acknowledgements

We would like to thank T. Hertel for many helpful discussions.

The Eﬀect of Structural Distortions . . . by Rochefort et al.

9

REFERENCES

1 R. Saito, M. Fujita, G. Dresselhaus and M.S. Dresselhaus, Appl. Phys. Lett. 60 (1992)

2204.

2 M.S. Dresselhaus, G. Dresselhaus and P.C. Eklund, Science of Fullerenes and Carbon

Nanotubes (Academic Press, San Diego, 1996).

3 J.W.G. Wild¨oer, L.C. Venema, A.G. Rinzler, R.E. Smalley and C. Dekker, Nature 391

(1998) 59.

4 T.W. Odom, J.-L. Huang, P. Kim and C.M. Lieber, Nature 391 (1998) 62.

5 M.M. Treacy, T. W. Ebessen and J. M. Gibson, Nature 381 (1996) 678.

6 E. W. Wong, P.E. Sheehan and C. M. Lieber, Science 277 (1997) 1971.

7 S.J. Tans, R.M. Verschueren and C. Dekker, Nature 393 (1998) 49.

8 R. Martel, Ph. Avouris, T. Hertel, T. Schmidt and H. Shea, to be published.

9 T. Hertel, R. Martel and Ph. Avouris, J. Phys. Chem. B 102 (1998) 910.

10 T. Hertel, R. Walkup and Ph. Avouris, Phys. Rev. B 15, Nov.1998.

11 C.L. Kane and E.J. Mele, Phys. Rev. Lett. 78 (1997) 1932.

12 J.C. Wu and M.N. Wybourne, Appl. Phys. Lett. 59 (1991) 102.

13 A. Weisshaar, J. Lary and S.M. Goodnick, Appl. Phys. Lett. 55 (1989) 2114.

14 G. Landrum, YAeHMOP (Yet Another Extended H¨uckel Molecular Orbital Package, Cor-

nell University, Ithaca, NY, 1995).

15 Gmelin Handbuch der Anorganishen Chemie, Vol.14B/2 (8th ed., Verlag Chemie, Wein-

heim, 1968) p.413.

16 Y. Kong and J.W. Ponder, J. Chem. Phys. 107 (1997) 481.

The Eﬀect of Structural Distortions . . . by Rochefort et al.

10

17 N.L. Allinger, Y.H. Yuh and J.-H. Lii, J. Am. Chem. Soc. 111 (1989) 8551.

18 N.W. Ashcroft and N.D. Mermin, Solid States Physics (Saunders College Publishing,

Philadelphia, 1976).

19 X. Blase, L.X. Benedict, E.L. Shirley and S.G. Louie, Phys. Rev. Lett. 72 (1994) 1878.

20 A. Bezryadin, A.R.M. Verschueren, S.J. Tans and C. Dekker, Phys. Rev. Letters 80 (1998)

4036.

21 S. Frank, P. Poncharal, Z.L. Wang and W.A. de Heer, Science 280 (1998) 1744.

The Eﬀect of Structural Distortions . . . by Rochefort et al.

11

FIGURES

FIG. 1. Total (DOS) and local density of states (LDOS) diagrams of a straight armchair (6, 6)

nanotube (resolution = 0.2 eV). The indices in the LDOS diagram give the relative position of

the carbon atoms in the nanotube structure (1: boundary, 40: middle of the nanotube) The inset

gives an expanded view of the DOS near the Fermi level (E=0 eV). The zero of the DOS scale is

indicated by the horizontal line, and the energy resolution is 0.05 eV.

FIG. 2. Structures of bent (6,6) nanotubes optimized using molecular mechanics. The bending

angles are (from left) 0◦, 30◦, 45◦ and 60◦. A front view of the most central sections of bent models

is also shown.

FIG. 3. Variation of the net charge distribution along the length of bent nanotubes. Atom

indices give the relative position of the carbon atoms in the nanotube structure (a total of 948

carbon atoms distributed in 79 sections of 12 carbon atoms were used)

FIG. 4. Variation of DOS and LDOS near the Fermi level for several bent (6, 6) armchair

nanotubes. (resolution = 0.05 eV). Indices give the relative position of the section in the nanotube

structure (1: boundary, 40: middle of the nanotube)

Figure 1. Rochefort, Salahub and Avouris

o

o
 0             30           45        60

o

o

Front View

o

o
    0      30    45      60

o

o

s
i
r
u
o
v
A
d
n
a

b
u
h
a
l
a
S

,
t
r
o
f
e
h
c
o
R

.
2

e
r
u
g
i
F

Figure 3. Rochefort, Salahub and Avouris

Figure 4. Rochefort, Salahub and Avouris"
Elastic Properties of Single-Wall Nanotubes,"  We report results of theoretical studies on the elastic properties of
single-wall nanotubes of the following compositions: C, BN, ${BC}_3$,
${BC}_2{N}$ and ${C}_3{N}_4$. These studies have been carried out using a total
energy, non-orthogonal tight-binding parametrisation which is shown to provide
results in good agreement both with calculations using higher levels of theory
and the available experimental data. Our results predict that of all types of
nanotubes considered, carbon nanotubes have the highest Young's modulus. We
have considered tubes of different diameters, ranging from 0.5 to 2~nm, and
find that in the limit of large diameters the mechanical properties of
nanotubes approach those of the corresponding flat graphene-like sheets.
",http://arxiv.org/pdf/cond-mat/9811257v1,3,"8
9
9
1

v
o
N
7
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
7
5
2
1
1
8
9
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Elastic Properties of Single-Wall Nanotubes

E. Hern´andez1∗, C. Goze2, P. Bernier2 and A. Rubio1
1 Departamento de F´ısica Te´orica, Universidad de Valladolid, Valladolid 47011, Spain
2 Groupe de Dynamique des Phases Condens´ees, Universit´e Montpellier II, 34090 Montpellier, France

We report results of theoretical studies on the elastic properties of single-wall nanotubes of the
following compositions: C, BN, BC3, BC2N and C3N4. These studies have been carried out using a
total energy, non-orthogonal tight-binding parametrisation which is shown to provide results in good
agreement both with calculations using higher levels of theory and the available experimental data.
Our results predict that of all types of nanotubes considered, carbon nanotubes have the highest
Young’s modulus. We have considered tubes of diﬀerent diameters, ranging from 0.5 to 2 nm, and
ﬁnd that in the limit of large diameters the mechanical properties of nanotubes approach those of
the corresponding ﬂat graphene-like sheets.

The discovery of C60 and fullerenes [1] in the mid 80’s
was soon followed by the observation of nanotubes [2],
ﬁrst reported by Iijima [3] in 1991. Since then nanotubes
have been the focus of attention of a growing scientiﬁc
community, attracted to them by their many interesting
properties, such as their structure, electrical conductiv-
ity and mechanical properties, as well as by their large
potential for practical applications. Two types of nan-
otubes exist: those originally observed by Iijima [3] were
multi-wall nanotubes (MWNT’s), formed by concentric
shells of apparently seamless cylinders of graphene, hav-
ing a separation between them similar to that in graphite.
More recently, single-wall nanotubes (SWNT’s) have also
been synthesized. As their name indicates, these consist
of a single seamless cylinder of graphene [2].

Soon after the discovery of carbon nanotubes it was
proposed that other compounds forming graphite-like
structures, such as BN [4], BC3 [5], BC2N [6], and
CN [7], could also form nanotubular structures. Indeed
BN [8–10], BC3 and BC2N [11] have now been synthe-
sized, though the actual structure of BC2N tubes seems
to correspond to concentric shells of C and BN in a ’sand-
wich’ structure [12]. Other tubular structures formed by
heavier element compounds have been predicted, such as
GaSe [13], and synthesized, like WS2 and MoS2 [14].

In this paper we focus our attention on the structural,
energetic and mechanical properties of single-wall car-
bon and composite nanotubes. We perform a systematic
study of these systems using Tight-Binding total energy
methods [15], as well as ﬁrst-principles [16] calculations.
Some of the results reported here have already appeared
in published form [17], but we also provide previously
unpublished results for the C3N4 nanotubes.

The structure of this paper is as follows. In Sec. I we
review the available experimental data on the mechanical
properties of nanotubes, while Sec. II is devoted to dis-
cussing previous theoretical work. In Sec. III we describe
the models used in our work and the calculations carried
out in order to address the issues discussed here. Then,
in Sec. IV we discuss our results and conclusions.

I. REVIEW OF EXPERIMENTAL RESULTS

There is a growing body of experimental evidence
indicating that carbon nanotubes (both MWNT’s and
SWNT’s) have extraordinary mechanical properties.
There are many direct observations of the large bending
ﬂexibility [18–20] of nanotubes, which provide evidence of
their capability to sustain large strains without evidence
of collapse or failure. However, the technical diﬃculties
involved in the manipulation of these nano-scale struc-
tures makes the direct determination of their mechanical
properties a rather challenging task. In spite of these dif-
ﬁculties, a number of experimental measurements of the
Young’s modulus of nanotubes have been reported. The
ﬁrst such study was that of Treacy et al. [21], who corre-
lated the amplitude of the thermal vibrations of the free
ends of anchored nanotubes as a function of temperature
with the Young’s modulus. Regarding a MWNT as a hol-
low cylinder with a given wall thickness, one can obtain
a relation between the amplitude of the tip oscillations in
the limit of small deﬂections, and the Young’s modulus.
Having quantiﬁed the amplitude of those oscillations by
means of careful TEM observations of a number of nan-
otubes, Treacy et al. were able to obtain an average value
of 1.8 TPa for the Young’s modulus, though there was
signiﬁcant scatter in the data (from 0.4 to 4.15 TPa for
individual tubes). Thus this number is subject to large
error bars, but it is nevertheless indicative of the excep-
tional axial stiﬀness of these materials.

More recently Krishnan et al. [22] have reported stud-
ies on SWNT’s using the same technique. A larger sam-
ple of nanotubes was used, and a somewhat smaller av-
erage value was obtained, Y = 1.25 TPa, closer to the
expected value for graphite along the basal plane.

This technique has also been used by Chopra and
Zettl [23] to estimate Y for BN nanotubes. Their results
indicate that these composite tubes are also exception-
ally stiﬀ, having a value of Y around 1.22 TPa, very close
to the value obtained for carbon nanotubes.

Another way to probe the mechanical properties of

1

 
 
 
 
 
 
nanotubes has been described by Wong et al. [24], who
have used the tip of an Atomic Force Microscope (AFM)
to bend anchored MWNT’s while simultaneously record-
ing the force exerted by the tube as a function of the
displacement from its equilibrium position, information
from which the Young’s modulus of the nanotube can be
extracted. Wong et al. have reported a mean value of
1.28 TPa, which is in good agreement with the previous
experimental results. Also Salvetat and coworkers [25]
have used a similar idea, which consists of depositing
MWNT’s on an ultra-ﬁltration membrane. Many tubes
are then found to lie across the holes present in the mem-
brane, with a fraction of their length suspended. The tip
of an AFM is then used to exert a load on the suspended
length of the nanotube, measuring at the same time the
nanotube deﬂection. The mean value of the Young’s
modulus obtained by Salvetat et al. was 0.81 TPa. A
similar procedure has also been used by Muster et al. [26],
who used an AFM to record the proﬁle of a MWNT ly-
ing across an electrode array. By assuming a simple Van
der Waals interaction law between the tube and the sub-
strate, and regarding the nanotube as an elastic beam,
the measured proﬁle was found to be consistent with a
Young’s modulus of approximately 1 TPa.

Other experiments, which as yet have not aimed at the
mechanical characterization of nanotubes, nevertheless
hint at other possible ways in which this characterization
could be carried out. Among these we could cite the
embedding of nanotubes in resins [27], or measuring the
bending of anchored nanotubes in controlled magnetic
ﬁelds [28].

All these experiments have contributed to conﬁrming
that nanotubes, both SW and MW, have indeed excep-
tional mechanical properties, but there are still ques-
tions that remain unresolved. The work of Chopra and
Zettl [23] indicates that BN nanotubes are close in stiﬀ-
ness to carbon nanotubes, but the experimental error
bars are too large to state categorically that one type
of tube is stiﬀer than the other. The results of Salve-
tat et al. [25] clearly indicate that MWNT’s synthesized
by the arc-discharge method [29] are much stiﬀer than
those produced by the catalytic decomposition of hydro-
carbons [30], which have a Young’s modulus in the range
of 10-50 TPa. This large diﬀerence is presumably a reﬂec-
tion of the inﬂuence of the high density of defects present
in the structure of the latter tubes, but a detailed quan-
tiﬁcation of the inﬂuence of defects on the mechanical
properties of nanotubes is as yet missing.

II. PREVIOUS THEORETICAL WORK

The mechanical properties of nanotubes have been ad-
dressed also by means of theoretical calculations in a
number of publications [18,31–37]. Most of these stud-
ies have been carried out using empirical potentials, al-

though tight-binding based models have also been oc-
casionally used [33]. Though well-tested empirical po-
tential models exist for carbon-based systems [38–40], to
our knowledge no such model exists for the composite
systems, and therefore these materials have been mostly
studied using ﬁrst-principles methodologies [4,5]. How-
ever, these latter studies have concentrated largely on
electronic, structural and vibrational properties of the
composite systems, without addressing the issue of their
mechanical properties.

Lu [37] has reported an extensive study of the Young’s
modulus, Poisson ratio and elastic constants of car-
bon nanotubes (both SW and MW, as well as ropes of
SWNT’s) using an empirical pair potential. Yakobson et
al. [34] and Nardelli et al. [35] have studied the behaviour
of nanotubes subject to large axial strains.

III. MODEL AND CALCULATIONS

For the majority of the calculations reported here we
have used a non-orthogonal Tight-Binding scheme due to
Porezag and coworkers [41]. Tight-Binding (TB) meth-
ods [15] lie in the centre region of the spectrum of simu-
lation methods in both computational cost and reliabil-
ity. Empirical potentials [38] are much cheaper to use,
but their accuracy and reliability is often questionable.
First-principles methods [16] on the other hand are more
reliable, but their computational demands are orders of
magnitude larger than for TB calculations, and often this
makes their use impractical.

The TB model of Porezag et al. [41] contains two con-
tributions to the total energy: a so-called band-structure
energy term, and a repulsive pair-potential. The band-
structure energy is calculated as the sum of the eigenval-
ues of the occupied states of a TB Hamiltonian. A matrix
representation of this Hamiltonian is constructed using a
minimal basis set consisting of a single atomic-like or-
bital per atomic valence state. The matrix elements are
evaluated in the framework of Density Functional The-
ory (DFT) (normally in the Local Density Approxima-
tion, LDA), but retaining only two-centre contributions
to the integrals. This means that each matrix element
of the Hamiltonian depends only on the relative distance
of the two atoms on which the corresponding basis func-
tions are centred and the direction cosines of the internu-
clear vector [42,15]. Since the basis set is not orthogonal,
the calculation of the band structure energy requires the
solution of a generalized eigenvalue problem [43]. The
repulsive pair potential is then constructed in such a way
that the total TB energy of a reference system (usually
the dimer) matches that of the full DFT calculation with
the same basis set. For more details on the construction
of the model the reader should consult the original ref-
erences [41], but an important point worth emphasizing

2

R − Req
Req

= −σǫ,

(3)

where R is the radius of the tube at strain ǫ, and Req is
the equilibrium (zero strain) tube radius. The Poisson
ration measures how much the tube contracts (expands)
radially when subject to a positive (negative) axial strain
ǫ.

We have performed a series of calculations using
the Tight Binding model discussed above aimed at de-
termining Ys and σ of both carbon and composite
SWNT’s,including BN, BC3 BC2N and C3N4 nanotubes.
Two diﬀerent graphite-like BC2N structures are possible,
but in our studies we have only considered the structure
known as II, since this is the one reported to be most
stable [46].

The calculations consist of taking a section of a nan-
otube using periodic boundary conditions to simulate an
inﬁnite tube, and subject it to both negative and pos-
itive strains along the axial direction. At each strain
the positions of all atoms in the repeat-cell are fully re-
laxed without constraints, using the Conjugate Gradients
minimisation technique [43]. A given calculation was as-
sumed to have converged once the total energy varied
less than 10−5 Hartree between two successive iterations.
From these calculations we obtained the total energy and
atomic positions as a function of the axial strain imposed
on the nanotube, from which we could calculate Young’s
modulus and the Poisson ratio, as well as the equilibrium
structures of each nanotube considered.

IV. RESULTS AND DISCUSSION

Let us ﬁrst consider the diﬀerence of energy between
a nanotube structure and the corresponding inﬁnite ﬂat
graphene sheet. This energy diﬀerence is known as the
strain energy Es, and we have plotted it in Fig. 1 for
C, BN and BC3 (n,n) nanotubes, as a function of the
tube diameter. It can be seen from Fig. 1 that the strain
energy varies as D−2, where D is the tube diameter; we
have performed ﬁts of functions of the form aD−b to the
data, and the values for the parameters a and b are given
in Table I.

here is the fact that no information concerning the me-
chanical properties of the system under study are used
in the construction of the TB parametrisation.

Even thought the TB model used here is not ﬁtted to
any empirical data, it is nevertheless approximate and
less accurate than conventional ﬁrst-principles methods.
For this reason we have also carried out plane-wave (PW)
pseudopotential DFT calculations for the (6,6) C and BN
nanotubes, in order to have the possibility of compar-
ing our TB results with fully ab initio calculations. The
PW calculations were performed using Troullier-Martins
pseudopotentials [44] with a PW cutoﬀ of 40 Ry for the
basis set, and 10 reciprocal space points generated ac-
cording to the Monkhorst-Pack scheme [45] to sample
the one-dimensional Brillouin zone. The TB calculations
used Γ-point sampling only, but the periodic cells were
chosen large enough as to ensure the same degree of con-
vergence in total energy diﬀerences as were achieved in
the PW calculations.

As we have seen in Sec. I, the central property charac-
terizing the stiﬀness of nanotubes, to which the experi-
ments have access, is the Young’s modulus. In bulk 3-D
systems Y is given by the following expression:

Y =

1
V0 (cid:18)

∂2E
∂ǫ2 (cid:19)ǫ=0

,

(1)

where E is the total energy, ǫ is the strain and Vo is
the equilibrium volume. The second derivative measures
how rapidly the energy grows as the system is distorted
out of its equilibrium conﬁguration. Usually Y is given
−1
in units of pressure, and this is why the factor of V
0
appears in this formula. However, Eq. (1) presents an
ambiguity in the case of SWNT’s, which stems from the
deﬁnition of V0. To deﬁne V0 for a SWNT one needs to
specify the wall thickness, and there is no clear way to
deﬁne the thickness of a wall one-atom thick. In previous
publications diﬀerent authors have used diﬀerent values
for the tube wall thickness, thought the most common
convention has been to adopt the value of the interlayer
spacing in graphite. Nevertheless the value of Y depends
on the inverse of the wall thickness δR, and is therefore
rather sensitive to the chosen value. In a recent publica-
tion [17] we proposed a way to bypass this problem by
using an alternative deﬁnition of the Young’s modulus,
more appropriate to the case of SWNT’s:

Ys =

1
S0 (cid:18)

∂2E
∂ǫ2 (cid:19)ǫ=0

.

(2)

Here S0 is the surface area deﬁned by the nanotube at
zero strain, which is a well deﬁned quantity. Given that
V0 = S0δR, one can recover the usual deﬁnition by simply
dividing by δR: Y = Ys/δR, if one wishes to adopt a
particular convention.

Another mechanical property of interest is the Poisson

ratio, σ, which is deﬁned by

3

(n,m) Deq (nm)
(10,0)
(6,6)

BxCyNz
C

BN

BC3

BC2N II

C3N4

(10,5)
(10,7)
(10,10)
(20,0)
(15,15)
(10,0)
(6,6)

(15,0)
(10,10)
(20,0)
(15,15)
(5,0)
(3,3)
(10,0)
(6,6)
(7,0)
(5,5)
(6,0)
(8,0)
(6,6)
(8,8)

σ
0.275
0.247

0.265
0.266
0.256
0.270
0.256
0.232
0.268

0.246
0.263
0.254
0.263
0.301
0.289
0.282
0.279
0.289
0.287
0.280
0.238
0.177
0.132

Ys (TPa · nm) Y (TPa)

0.416
0.415
(0.371)
0.426
0.422
0.423
0.430
0.425
0.284
0.296
(0.267)
0.298
0.306
0.301
0.310
0.308
0.311
0.313
0.315
0.336
0.343
0.192
0.207
0.228
0.233

1.22
1.22
(1.09)
1.25
1.24
1.24
1.26
1.25
0.837
0.870
(0.784)
0.876
0.901
0.884
0.912
0.906
0.914
0.922
0.925
0.988
1.008
0.565
0.610
0.670
0.684

0.791
0.820
(0.817)
1.034
1.165
1.360
1.571
2.034
0.811
0.838
(0.823)
1.206
1.390
1.604
2.081
0.818
0.850
1.630
1.694
1.111
1.370
0.913
1.210
1.558
2.075

TABLE II. Structural and elastic properties of selected
nanotubes obtained from the tight-binding calculations re-
ported here. Young’s modulus values given in parenthesis
were obtained from ﬁrst-principles calculations. Also the
value of Y with the convention δR = 0.34 nm is given for
comparison.

C (n,n)
BN (n,n)
BC3 (n,n)

)

m
o
t
a
/
V
e
(
y
g
r
e
n
E
n

i
a
r
t
S

0.20

0.10

0.00

0.3

0.8

1.3
Tube Diameter (nm)

1.8

2.3

FIG. 1. Curvature strain energy as a function of the equi-
librium tube diameter, as obtained from the tight-binding cal-
culations, for C, BN and BC3 nanotubes.

That the strain energy should decay as D−2 was
predicted by Tibbetts [47] (see also Mintmire and
White [48]) on the basis of continuum elasticity theory,
according to which the strain energy per atom is given
by

Es
N

=

Y a3
6

Ω
D2 ,

(4)

where Y is the Young’s modulus of the tube, a is a con-
stant of the order of the inter-layer spacing in graphite
and Ω is the area per atom. Note that from Eq. (4) and
the numerical ﬁts to the strain energy data of Fig. 1 given
in Table I, one can predict that the Young’s modulus of
SWNT’s of BN and BC3 of a given diameter should be
approximately 0.68 and 0.71 respectively that of a carbon
nanotube of the same diameter. As we shall see below,
direct calculations of Young’s modulus for these tubes
obey approximately this relation.

BxCyNz
C

BN

BC3

(n,m)
(n,n)
(n,0)
(n,n)
(n,0)
(n,n)
(n,0)

a × 102 (eV nm2/atom)
8.1
8.7
5.5
5.6
5.8
5.6

b
2.083
1.996
1.984
1.980
1.984
2.048

TABLE I. Parameters obtained from ﬁtting the strain en-
ergy curves of Fig. 1 to a function of the form aD−b. Note
that the value of b is very close to 2 in all cases.

4

 
 
A ﬁrst indication that the TB model used in this work
is a reliable one stems from the good agreement obtained
in the strain energy as calculated here and that calcu-
lated from ﬁrst-principles methods and reported else-
where [4,5]. Another indication comes from the fact that
a certain buckling on the surface of the BN nanotubes
is predicted to occur, also in agreement with preliminary
ﬁrst-principles calculations [4]. This buckling, which re-
sults from the B atoms displacing inwards towards the
tube axis, while the N atoms displace in the opposite
direction, is a consequence of the slightly diﬀerent hy-
bridizations of B and N on the curved surface of the nan-
otube. The amount of buckling is dependent on the tube
diameter, but it is otherwise independent of the tube
structure for arm-chair and zig-zag nanotubes.

In Table II we give the obtained values of structural
and mechanical properties for a set of nanotubes obtained
from our calculations. For comparison we also give re-
sults for the (6,6) C and BN nanotubes calculated with
PW pseudopotential DFT calculations. As can be seen,
the agreement between the TB and ﬁrst-principles cal-
culations in both structural and mechanical properties is
rather good. Notice also that the values of Ys (and in
fact those of Y also) for C, BN and BC3 nanotubes of
similar diameters are approximately in the same ratio as
predicted from Eq. (4).

)

m
n
a
P
T

(

s

Y

0.40

0.30

0.20

C (n,n)
C (n,0)
BN (n,n)
BN (n,0)
BC3 (n,n)
BC3 (n,0)
BC2N II (n,n)
BC2N II (n,0)
C3N4 (n,n)
C3N4 (n,0)

0.10

0.0

0.5

2.0
1.5
1.0
Tube Diameter (nm)

2.5

3.0

FIG. 2. Young’s modulus as a function of the tube diam-
eter for C, BN, BC3, BC2N (structure II only) and C3N4,
as calculated from the tight-binding simulations. Results ob-
tained for (n,n) nanotubes (ﬁlled symbols), (n,0) nanotubes
(empty symbols) and also for C (10,5) (+) and (10,7) (×) are
shown.

FIG. 3. Relaxed structure for the C3N4 (8,0) nanotube, as
obtained from the TB calculations. The dark shaded atoms
are Nitrogen atoms, while the lighter ones are Carbon atoms.

In Fig. 2 the values Ys have been plotted as a function
of the tube diameter for the diﬀerent types of tubes con-
sidered in this work. The ﬁrst observation that can be
extracted from Table II and Fig. 2 is the fact that car-
bon nanotubes are predicted to have the highest Young’s
modulus of all the diﬀerent types of tubes considered. BN
and BC3 tubes have very similar values of Ys, though the
latter have slightly larger values. The BC2N nanotubes
are predicted to be slightly stiﬀer than the BN and BC3
tubes, while C3N4 nanotubes lie well below the rest in
stiﬀness. The value of Ys we obtain for the wider C nan-
otubes, 0.43 TPa nm, corresponds to a Young’s modulus
of 1.26 TPa in the conventional deﬁnition of Eq. (1), if
we take δR = 0.34 nm, i.e.
the inter-layer spacing in
graphite. This value is in very good agreement with the
experimental value recently obtained by Krishnan and
coworkers [22] for SWNT’s (1.25 TPa). It is also in rather
good agreement with the value of 1.28 TPa reported by

5

 
 
Wong et al. [24], though this later value was obtained for
MWNT’s. However, it is expected that the Young’s mod-
ulus be mostly determined by the intra-wall C-C bonds,
and it is therefore not surprising that the values look so
similar for both MW and SWNT’s. For composite nan-
otubes, the only experimental data on mechanical prop-
erties currently available to our knowledge are the re-
sults of Chopra and Zettl [23], who have measured Y for
BN MWNT’s. They quote a value of 1.22 TPa, which
is somewhat larger than the result we obtain for these
tubes, but nevertheless the agreement is close. Tough it
may seem that the choice δR = 0.34 nm is somewhat
arbitrary, it should be pointed out that the experimen-
tal results are not free of this arbitrariness either, given
that to obtain a value of the Young’s modulus according
to Eq. (1), it is necessary to interpret the experimen-
tal observations on the basis of some mechanical model,
usually a hollow cylinder with a certain wall thickness.
Clearly, in the case of SWNT’s the question of how to
choose δR = 0.34 nm applies to experiments as well as
to theoretical calculations.

FIG. 4. Relaxed structure for the C3N4 (5,5) nanotube.

The reason why C3N4 nanotubes are predicted to be
so much softer than all other types of nanotubes consid-
ered in this work is the fact that for a given amount of
tube surface, tubes of this composition have a smaller
density of chemical bonds. Indeed, these tubes present
a more hollow structure when compared to the other,
perfectly hexagonal nanotubes (see Figs. 3 and 4).
It
is also interesting to note that, while C, BN, BC3 and
BC2N nanotubes do not show noticeable diﬀerences for
the structural or mechanical properties as the chiral an-
gle is varied, sizeable diﬀerences are observed in the case
of C3N4 nanotubes. It can be seen in Table II that the
(n,n) C3N4 tubes have a higher Young’s modulus than
the (n,0), though both seem to converge towards the
same number in the limit of large diameters. This dif-
ference is also reﬂected in the structure, as can be seen
in Figs. 3 and 4. Notice how the the hexagons are at an
angle with the surface of the tube which is diﬀerent in
(n,n) and (n,0) tubes.

As for comparison with other theoretical predictions,
the results quoted by Lu [37] are somewhat smaller than
ours. The results in ref. [37] are 0.97 TPa for all tubes.
This diﬀerence is most likely due to the diﬀerent ap-
proaches (empirical potentials and TB) used in that work
and ours. We also observe in our results for Ys a slight de-
pendence on the tube diameter. As the diameter becomes
larger, Ys approaches a plateau value which corresponds
to the value calculated for the ﬂat graphene-like sheet of
each nanotube composition. Interestingly, the approach
to the limit value is from below, as can be expected if
one considers that bending a ﬂat graphene sheet weakens
the bonds. Given that it is the strength of the chemical
bonds which determines the actual value of the Young’s
modulus, it is natural that small-diameter (high curva-
ture) tubes have smaller Young’s moduli, and in the limit
of large diameters, the mechanical properties essentially
correspond to those of the ﬂat graphene sheet. In con-
trast, the results of Lu [37] are largely insensitive to the
tube diameter. This is due to the fact that pair-potential
models, such as the one used by Lu, do not reﬂect the
changing nature of the chemical bonding as the curvature
is changed. To reproduce this eﬀect, a model sensitive to
the changing environment (i.e. a many-body model) is
required.

To summarize, we have used a non-orthogonal TB
model parametrised for C, B and N based systems to
perform a systematic study of the energetic, structural
and mechanical properties of single-wall nanotubes of
diﬀerent chemical composition. We have checked the
accuracy of our predictions against some ﬁrst-principles
calculations, and the agreement obtained is good. Fur-
thermore, we obtain good agreement with the available
experimental data. We obtain strain energy vs. diame-
ter curves which obey very closely the expected D−2 be-

6

haviour. Our results show that carbon nanotubes are ex-
pected to be stiﬀer than any of the composite nanotubes
considered, having a Young’s modulus of approximately
1.3 TPa, which corresponds to that of a ﬂat graphene
sheet within the same theoretical model. The C3N4 nan-
otubes, which present a more hollow structure than the
other tubes, are predicted to have a Young’s modulus
nearly half that of the carbon nanotubes.

We are grateful to G. Seifert and T. Heine for providing
the TB parametrisations used in this work. J.A. Alonso,
M.J. L´opez and M. Galtier are gratefully acknowledged
for helpful discussions. This work was carried out
within the framework of the EU Transfer and Mobil-
ity of Researchers Namitech project under contract No.
ERBFMRX-CT96-0067 (DG12-MITH) and Grant No.
DGIS-PB95-0202 of the Spanish Ministry of Education.
The use of computer facilities at C4 (Centre de Com-
putaci´o i Comunicacions de Catalunya) and CNUSC
(Montpellier) is also acknowledged.

[1] H.W. Kroto, J.R. Heath, S.C. O’Brien, R.F. Curl and

R.E. Smalley, Nature 318 162 (1985).

[2] See e.g. P.M. Ajayan and T.W. Ebbesen, Rep. Prog.
Phys. 60 1025 (1997); M.S. Dresselhaus, G. Dresselhaus
and P.C. Eklund, Science of Fullerenes and Carbon Nan-
otubes (Academic Press, New York 1996); T.W. Ebbe-
sen (Ed.), Carbon Nanotubes, Preparation and Properties
(CRC Press, Boca Raton 1997).

[3] S. Iijima, Nature 354 56 (1991); S. Iijima and T. Ichi-

hashi, Nature 363 603 (1993).

[4] A. Rubio, J.L. Corkill and M.L. Cohen, Phys. Rev. B
49 5081 (1994); X. Blase et al. Europhys. Lett. 28 335
(1994); Phys. Rev. B 51 6868 (1995).

[5] Y. Miyamoto, A. Rubio, S.G. Louie and M.L. Cohen,

Phys. Rev. B 50 18360 (1994).

[6] Y. Miyamoto, A. Rubio, M.L. Cohen and S.G. Louie,

Phys. Rev. B 50 4976 (1994).

[7] Y. Miyamoto, M.L. Cohen and S.G. Louie, Solid State

Comm. 102 605 (1997).

[8] N.G. Chopra, R.J. Luyken, K. Cherrey, V.H. Crespi,
M.L. Cohen, S.G. Louie and A. Zettl, Science 269 966
(1995).

[9] A. Loiseau, F. Willaime, N. Demoncy, G. Hug and

H. Pascard, Phys. Rev. Lett. 76 4737 (1996).

[10] M. Terrones, W.K. Hsu, H. Terrones, J.P. Zhang,
J.P. Hare, R. Castillo, K. Prasides,
S. Ramos,
A.K. Cheetham, H.W. Kroto and D.R.M. Walton, Chem.
Phys. Lett. 259 568 (1996); M. Terrones, A.M. Benito,
C. Manteca-Diego, W.K. Hsu, O.I. Osman, J.P. Hare,
D.G. Reid, H. Terrones, A.K. Cheetham, K. Prasides,
H.W. Kroto and D.R.M. Walton, Chem. Phys. Lett. 257
576 (1996).

[11] Z. Weng-Sieh, K. Cherrey, N.G. Chopra, X. Blase,
Y. Miyamoto, A. Rubio, M.L. Cohen, S.G. Louie,

A. Zettl and R. Gronsky, Phys. Rev. B, 51 11229 (1995).
[12] K. Suenaga, C. Colliex, N. Demoncy, A. Loiseau, H. Pas-

card and F. Willaime, Science 278 653 (1997).

[13] M. Cˆot´e, M.L. Cohen and D.J. Chadi, Phys. Rev. B 58,

4277 (1998).

[14] R. Tenne, L. Margulis, M. Genut and G. Hodes, Nature

360 444 (1992).

[15] For a review on tight-binding see C.M. Goringe,
D.R. Bowler and E. Hern´andez, Rep. Prog. Phys. 60 1447
(1997).

[16] See e.g. M.C. Payne,, M.P. Teter, D.C. Allan, T.A. Arias
and J.D. Joannopoulos, Rev. Mod. Phys. 64 1045 (1992).
[17] E. Hern´andez, C. Goze, P. Bernier and A. Rubio, Phys.

Rev. Lett. 80, 4502 (1998).

[18] S. Iijima, C. Brabec, A. Maiti and J. Bernholc, J. Chem.

Phys. 104 2089 (1996).

[19] M.R. Falvo, G.J. Clary, R.M. Taylor, V. Chi,
F.P. Brooks, S. Washburn and R. Superﬁne, Nature 389,
582 (1997).

[20] T. Hertel, R. Martel and P. Avouris, J. Phys. Chem. B

102, 910 (1998).

[21] M.M.J. Treacy, T.W. Ebbesen and J.M. Gibson, Nature

381 678 (1996).

[22] A. Krishnan, E. Dujardin, T.W. Ebbesen, P.N. Yanilos

and M.M.J. Treacy, Phys. Rev. B (in press).

[23] N.G. Chopra and A. Zettl, Solid State Comm. 105 297

(1998).

[24] E.W. Wong, P.E. Sheehan and C.M. Lieber, Science 277

1971 (1997).

[25] J.P. Salvetat, A.J. Kulik, G.A.D. Briggs, J.M. Bonard,
T.St¯ockli, K. M´et´enier,
S. Bonnamy, F. B´euin,
N.A. Burnham and L. Forr´o, submitted for publication.
[26] J. Muster, M. Burghard, S. Roth, G.S. D¨usberg,
E. Hern´andez and A. Rubio, J. Vac. Sci. Tech. 16, 2796
(1998).

[27] P.M. Ajayan, O. Stephan, P. Redlich and C. Colliex, Na-

ture 375, 564 (1995).

[28] W.H. Knechtel, G.S. D¨usberg, W.J. Blau, E. Hern´andez
and A. Rubio, Appl. Phys. Lett. 73, 1961 (1998).
[29] T.W. Ebbesen and P.M. Ajayan, Nature 358, 220 (1992).
[30] M.J. Yacam´an, M. Miki-Yoshida, L. Rend´on and
J.G. Santiesteban, Appl Phys. Lett. 62, 657 (1993).
[31] D.H. Robertson, D.W. Brenner and J.W. Wintmire,

Phys. Rev. B 45 12592 (1992).

[32] R.S. Ruoﬀ and D.C. Lorents, Carbon 33 925 (1995).
[33] J.M. Molina, S.S. Savinsky and N.V. Khokhriakov, J.

Chem. Phys. 104 4652 (1996).

[34] B.I. Yakobson, C.J. Brabec and J. Bernholc, Phys. Rev.

Lett. 76 2411 (1996).

[35] M.B. Nardelli, B.I. Yakobson and J. Bernholc, Phys. Rev.

[36] C.F. Cornwell and L.T. Wille, Solid State Comm. 101

B 57, 4277 (1998).

555 (1997).

[37] J.P. Lu, Phys. Rev. Lett. 79 1297 (1997).
[38] J. Tersoﬀ, Phys. Rev. Lett. 61 2879 (1988).
[39] D.W. Brenner, Phys. Rev. B 42 9458 (1990).
[40] K. Nordlund, J. Keinonen and T. Mattila, Phys. Rev.

Lett. 77, 699 (1996).

[41] D. Porezag, T. Frauenheim, T. K¨ohler, G. Seifert and
R. Kashner, Phys. Rev. B 51 12947 (1995); J. Widany,
T. Frauenheim, T. K¨ohler, M. Sternberg, D. Porezag,

7

G. Jungnickel and G. Seifert, Phys. Rev. B 53 4443
(1996); F. Weich, J. Widany, T. Frauenheim and
G. Seifert (private communication).

[42] J.C. Slater and G.F. Koster, Phys. Rev. 94, 1498 (1954).
[43] W.H. Press, S.A. Teukolsky, W.T. Vetterling and
B.P. Flannery, Numerical Recipes, the Art of Scientiﬁc
Computing 2nd Edition (Cambridge University Press
1992).

[44] N. Troullier and J.L. Martins, Phys. Rev. B 43 1993

(1991).

[45] H.J. Monkhorst and J.D. Pack, Phys. Rev. B 13 5188

(1976).

[46] A.Y. Liu, R.M. Wentzcovitch and M.L. Cohen, Phys.

Rev. B 39 1760 (1989).

[47] G.G. Tibbetts, J. Cryst. Grwoth, 66, 632 (1983).
[48] J.W. Mintmire and C.T. White, in Carbon Nanotubes,
Preparation and Properties, T.W. Ebbesen (Ed.) (CRC
Press, Boca Raton 1997).

8"
"Tight Binding Molecular Dynamics Studies of Boron Assisted Nanotube
  Growth","  In this paper we report a theoretical study of the effects of the presence of
boron in growing carbon nanotubes. We employ a well established Tight Binding
model to describe the interactions responsible for the energetics of these
systems, combined with the Molecular Dynamics simulation technique and
Structural Relaxation calculations. We find, in agreement with the previous
theoretical/experimental work of Blase {\em et al.} [{\em Phys. Rev. Lett.}
{\bf 83}, 5078 (1999)], that boron favors (n,0) (zig-zag) tubular structures
over (n,n) (arm-chair) ones by stabilizing the zig-zag edge. Furthermore, it is
shown that boron has the effect of delaying the tube closure process, a fact
which could explain the improved aspect ratio experimentally observed in
nanotubes synthesized in the presence of boron. Our dynamical simulations lead
us to propose a mechanism through which this extension of the closure time can
be explained.
",http://arxiv.org/pdf/cond-mat/0006230v1,3,"0
0
0
2

n
u
J

4
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
0
3
2
6
0
0
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Tight Binding Molecular Dynamics Studies of Boron Assisted Nanotube Growth

E. Hern´andez ∗ and P. Ordej´on
Institut de Ci`encia de Materials de Barcelona - CSIC, Campus de la Universitat Aut`onoma de Barcelona, 08193 Bellaterra,
Barcelona, Spain

I. Boustani
Bergische Universit¨at - Gesamthochschule Wuppertal, FB 9 - Theoretische Chemie, Gaußstraße 20, D-42097 Wuppertal,
Germany

A. Rubio and J.A. Alonso
Departamento de F´ısica Te´orica, Universidad de Valladolid, 47011 Valladolid, Spain
(October 26, 2018)

In this paper we report a theoretical study of the eﬀects of the presence of boron in growing car-
bon nanotubes. We employ a well established Tight Binding model to describe the interactions
responsible for the energetics of these systems, combined with the Molecular Dynamics simulation
technique and Structural Relaxation calculations. We ﬁnd, in agreement with the previous theoret-
ical/experimental work of Blase et al. [Phys. Rev. Lett. 83, 5078 (1999)], that boron favors (n,0)
(zig-zag) tubular structures over (n,n) (arm-chair) ones by stabilizing the zig-zag edge. Further-
more, it is shown that boron has the eﬀect of delaying the tube closure process, a fact which could
explain the improved aspect ratio experimentally observed in nanotubes synthesized in the presence
of boron. Our dynamical simulations lead us to propose a mechanism through which this extension
of the closure time can be explained.

I. INTRODUCTION

The discovery of carbon nanotubes by Iijima in 19911
has marked the starting point of a scientiﬁc revolution2–6.
This discovery has opened a whole new perspective in the
nanoscopic regime of Materials Science and Engineering.
Their mechanical7–14, electrical15,16 and magnetic17–19
properties provide ample opportunity for the fabrication
of nano-scale devices. Indeed some such devices have al-
ready been reported in the literature20–23. Since Iijima’s,
discovery nanotubes of other chemical composition have
also been synthesized, such as BxCyNz composite nan-
otubes24–28, the so-called inorganic nanotubes consisting
29–31, or NiCl2 nanotubes32.
of layers of MoS2 or WS2
All these compounds have phases which consist of lay-
ered structures, and this has lead to the prediction that
other materials also capable of crystallizing in layered
structures can in principle produce nanotubes. Indeed,
theoretical arguments have been presented in the litera-
35, BC2N36, GaN37,
ture for the viability of BN33,34, BC3
B38, GaSe39 and P40 nanotubes. Interestingly, nanotubu-
lar structures can also be constructed from biochemical
compounts, such as peptides, as demonstrated experi-
mentally by Ghadiri et al.41 and theoretically by Carloni
et al.42.

The tubes ﬁrst detected by Iijima1 were multi-wall
nanotubes (MWCNT’s), i.e. concentric shells of cylin-
drical shape, in which each shell is separated from the
next by approximately the same distance as the inter-
layer spacing in graphite. Each shell can be character-
ized by a pair of indices, (n,m), which determine how the
folding of the graphene sheet must be carried out in or-

der to obtain the shell. The shells are usually classiﬁed
into three diﬀerent types: (n,0) or zig-zag shells, (n,n)
or arm-chair shells, and chiral shells, of indices (n,m)
where n > m > 0. Zig-zag and arm-chair shells are said
to be achiral (they can be superimposed onto their mirror
images). The ordering of the shells in a MWCNT is usu-
ally turbostratic, i.e. the pattern of atomic arrangement
may vary (and in general does vary) from one shell to
the next, or in other words, diﬀerent shells usually have
diﬀerent chiralities4.

After the discovery of MWCNT’s, a procedure for syn-
thesizing single-wall nanotubes (SWCNT’s) was found43.
These tubes are found to aggregate into bundles or ropes,
and their diameter distribution peaks at around 1.4 nm,
although more recently this distribution has been found
to vary according to the synthesis conditions44. The pro-
duction of SWNT’s has allowed the experimental corrob-
oration16 of a theoretical prediction made by Hamada
and coworkers15 soon after the discovery of MWCNT’s,
that the electrical conductivity properties of SWCNT’s
are dependent on the (n,m) indices. This prediction
stated that SWCNT’s can be either metallic or semi-
conducting; if the indices (n,m) of a nanotube obey the
relation n − m = 3q (q = 0, 1, 2, 3, . . . ), then the tube
is metallic, otherwise the tube is semi-conducting. This
dependence of the electric characteristics of SWCNT’s
upon their structure has raised an interest in the possi-
bility of devising new synthetic methods that allowed a
structural selection of nanotubes, not only according to
their diameter, but also to their chirality. A ﬁrst step in
this direction was achieved by Redlich et al.45, Carroll et
al.46, and by Terrones et al.47, who, by adding a certain

1

 
 
 
 
 
 
amount of boron during the synthesis, obtained boron
doped MWCNT’s which, interestingly, have an improved
crystallinity and a larger aspect ratio (quotient of length
to diameter) with respect to tubes obtained in the ab-
sence of boron. It was shown that boron appears mostly
in the form of clusters associated with the tips of the nan-
otubes. But most importantly, a recent combined exper-
imental and theoretical study by Blase and coworkers48
has demonstrated that the MWCNT’s thus obtained con-
sist mostly of zig-zag shells. This study also sheds some
light on the role played by boron in favoring the zig-zag
structure over others, and tries to explain the larger as-
pect ratio observed in boron assisted synthesis. This lat-
ter issue, though, was addressed by First-Principles (FP)
Density Functional Theory (DFT) Molecular Dynamics
simulations, and the large computational costs of this
technique prevented Blase and coworkers from pursuing
a detailed enough study which clariﬁed completely this
question.

In this paper we address the problem of boron assisted
nanotube growth using a Tight Binding model49. Tight
Binding (TB) is an approximate method which never-
theless is capable of providing extremely accurate results
in favorable systems. Its main advantage with respect to
FP methodologies is its comparatively low computational
cost, which often allows a more extensive study than is
practical or even possible with higher levels of theory.
In this work we have used the Density-Functional Tight
Binding (DFTB) model due to Porezag et al 50, about
which we give more details in Section II. This model has
proved to be very accurate for carbon based systems. We
have used DFTB to perform a series of static and dynam-
ical simulations of SWCNT’s, with and without boron
present, with the aim of understanding the eﬀects of the
presence of boron on the structural properties of the re-
sulting NT’s. The structure of this paper is as follows:
in Section II we describe brieﬂy the DFTB model, and
provide previous examples of its successes in order to jus-
tify its use here. We also describe the calculations which
are reported in the remaining of the paper. Section III is
devoted to a discussion of our simulation results, and we
summarize our conclusions in Section IV.

II. COMPUTATIONAL DETAILS

A. Model

DFTB is is a non-orthogonal Tight Binding scheme
in which a parametrisation is constructed directly from
DFT calculations using atomic-like orbitals in the ba-
sis set, and adopting a two-center approximation for
the Hamiltonian matrix elements. For more details on
the parametrisation used here the reader should consult
references50,51. The DFTB scheme has proved to be ex-
tremely successful in the modeling of carbon-based sys-
tems, in particular carbon clusters and nanostructures.

2

Fowler et al.52 have used it to analyze the energetic or-
dering of all 426 cage structures containing 5, 6 and
7-membered rings in C40. Ayuela et al .53 have found,
using DFTB and other ﬁve semi-empirical methods, a
heptagon-containing isomer of C62 which was predicted
to be more stable than any of the other 2385 classi-
cal fullerene isomers (i.e.
isomers containing only pen-
tagons and hexagons). DFTB has also been used to de-
termine the mechanical properties of single-wall C, BN
and some BxCyNz nanotubes11, providing results which
are in excellent agreement with the available experimen-
tal data. More recently DFTB has also been used to
study the structural, mechanical and electronic prop-
erties of a novel family of laminar carbon structures
known as Haeckelites, as well as those of their tubu-
lar counterparts54. Haeckelites consist of pentagons and
heptagons in equal number, with an arbitrary number
of hexagons. The suitability of DFTB for performing
Molecular Dynamics simulations in carbon-based sys-
tems has been most recently demonstrated by Fugaciu
et al.55, who have used it to study the conversion of di-
amond nanoparticles to concentric shell fullerenes. The
many examples of the use of DFTB in the context of
carbon based systems and the accuracy of the results
reported give us conﬁdence in the reliability of this the-
oretical model.

Like in other Tight Binding models49, in DFTB the to-
tal energy is calculated as the sum of two contributions:
the band structure contribution, which is mostly attrac-
tive, and the repulsive pair-potential contribution, which
accounts for the core-core repulsion and the double-
counting of the electron-electron interaction which is im-
plicit in the band structure term. The band structure en-
ergy is calculated by straight forward diagonalisation of
the Hamiltonian, summing the eigen-values of the occu-
pied states weighted according to their occupation num-
bers, i.e

Ebs = 2 X
n

fnǫn,

(1)

where fn is the population of state n (which in our case
is equal to 1 for occupied states, and to zero for unoccu-
pied, i.e. we have assumed 0 K electronic temperature),
and ǫn is the eigen-value of state n. The factor of two
accounts for the degeneracy of spin. The band structure
contribution to the atomic force Fi is then calculated
from the Hellmann-Feynman theorem:

∇i ǫn = 2fnC†

n (∇i H − ǫn∇i S) Cn,

(2)

where Cn is the vector representation of eigen-state n,
H is the Hamiltonian matrix, and S is the overlap. The
repulsive pair potential energy and force contributions
are trivially added to equations 1 and 2, respectively.

B. Calculations

A. Carbon nanotubes in the absence of boron

We have performed two types of calculations: a) struc-
tural relaxation calculations, in which, using the Conju-
gate Gradients (CG) technique56, the positions of the
atoms in a system are displaced until a minimum in the
potential energy hyper-surface is found; and b) molecu-
lar dynamics (MD) simulations, which we have employed
to study the time evolution of the systems considered
here at a range of temperatures. More speciﬁcally we
have performed canonical ensemble molecular dynamics
calculations, in which the conserved quantities are the
number of atoms, the volume and the average temper-
ature (NVT-MD). We have implemented the NVT-MD
algorithm of Nos´e as modiﬁed by Hoover57,58.
In this
algorithm the physical system of interest is extended by
the addition of an extra degree of freedom, playing the
role of a thermostat, which interacts with the physical
system in such a way as to ﬁx the average temperature.
In this algorithm the mass associated with the thermo-
stat is somewhat arbitrary, as it does not aﬀect the value
of the average temperature, only the size of the instan-
taneous temperature ﬂuctuations. We have chosen this
mass to be equal to the total mass of the physical system.
We have used the implementation of the Nos´e-Hoover
algorithm described by Frenkel and Smit59. Although
the total energy is not conserved in NVT-MD, there is a
conserved quantity which can be monitored to ensure the
correctness of the implementation. This magnitude plays
the role of total energy of the extended system. In our
simulations we have used a time-step of 1 fs, which has
proved to be suﬃciently small to maintain the conserved
quantity oscillations smaller than 1 part in 10000 during
the length of the simulations, with no appreciable drift.
Our studies have covered a range of temperatures,
namely 1000, 2000, 2500 and 3000 K. At each tempera-
ture the dynamics of the system were monitored during
at least 10 ps. The simulations were carried out sequen-
tially, using the coordinates and velocities at the end of
a run at a given temperature as a seed for the simulation
at the next higher temperature. The transition from one
temperature to another was made by gradually increas-
ing the temperature of the thermostat at a rate of 0.5
K/fs. To use a lower heating rate would be prohibitive, in
view of the computational costs involved. Nevertheless,
once the thermostat reached the desired temperature, the
system was allowed to reach equilibrium at the new tem-
perature during 1 ps, in order to minimize as much as
possible the eﬀects of such a high heating rate, before
performing the simulation at the new temperature.

III. SIMULATION RESULTS

Before addressing the eﬀect of boron on the structure
and growth mechanism of nanotubes, it is necessary to
study the dynamics of carbon nanotubes in the absence of
boron. In so doing we can also assess the quality and ap-
propriateness of the model. In order to study the dynam-
ics of the open ended tubes, we ﬁrst considered the sys-
tems illustrated in Figure 1. These systems are a (10,0)
nanotube, with one end saturated by ten H atoms, and
a (5,5) nanotube, also with one end saturated by ten H
atoms. Both tubes consist of 120 C atoms, plus the 10
H atoms. Figure 1 shows the structures obtained after
a CG relaxation, which were then used as starting con-
ﬁgurations for the NVT-MD simulations. To facilitate
the analysis of the MD simulations, the 10 H atoms were
kept ﬁxed throughout the dynamical simulations. While
this is an approximation, we have chosen a tube section
as large as was practical in order to minimise the possible
eﬀects of having the H atoms frozen on the dynamics at
the other end of the tube.

(a)

(b)

FIG. 1. The relaxed structures of a (10,0) nanotube (a)
and a (5,5) nanotube (b), used as starting conﬁgurations for
the Molecular Dynamics simulations described in the text.

We ﬁrst discuss the case of the (10,0) nanotube. At the
lowest temperature considered (1000 K) the structure of
the nanotube remains unaltered except for the normal
thermal oscillations around the equilibrium atomic posi-
tions. All the hexagonal rings present in the initial struc-
ture (Figure 1) retain their identity, as can be seen in
Figure 2(a), which illustrates the conﬁguration attained
after 10 ps of MD run at this temperature. In view of the
fact that the simulation of the open nanotube end at 1000
K failed to produce any structural reordering within this
time scale, we proceeded to heat the system up to 2000 K.
At this temperature, structural changes begin to appear
in the open edges of the nanotube, as can be seen in Fig-
ure 2(b). Indeed, some hexagonal rings at the edge have
been broken, resulting in chains of carbon atoms, while
others have fused into pentagon-heptagon (5/7) pairs.
After 10 ps at 2000 K, two pentagonal rings can be seen,
as well as one heptagon. These non-hexagonal rings are
produced by the fusing of two hexagons, to give a pen-

3

tagon and a heptagon. However, we ﬁnd that heptagons
appear to be less stable, and break more easily into car-
bon chains that remain attached to the nanotube edge,
while the pentagons remain stable. The presence of these
pentagons induces curvature in the structure, so the edge
of the nanotube bends inwards.

(a)

(b)

(a)

(b)

(c)

(d)

FIG. 2. (a) Final structure of the (10,0) nanotube obtained
after 10 ps of dynamics at 1000 K. (b) Final structure of the
(10,0) nanotube obtained after 10 ps of dynamics at 2000 K.

Clearly, a tendency to form a fullerene-like cap is ob-
served, a situation that is after all energetically more
stable than the open edge. Therefore, we continued the
simulation at a temperature of 2500 K. Like before, the
temperature of the thermostat was increased at a rate
of 0.5 K/fs, and once the desired thermostat tempera-
ture was achieved the combined system of nanotube and
thermostat was allowed to equilibrate during 1 ps. The
dynamics of the system were then monitored during a
further 20 ps. Figure 3 illustrates six representative con-
ﬁgurations of the system at this temperature. As can be
seen, the process of tube closure initiated at 2000 K is
further facilitated at 2500 K. The chains of carbon atoms
which were seen already at 2000 K can now form links
bridging across the open edge. This, combined with the
presence of the pentagonal rings at or close to the edge,
has the overall eﬀect of bending inwards the nanotube
walls. As the simulation proceeds, the number of freely
oscillating chains is reduced, due to their tendency to
bond into the dome-like structure being formed. Eventu-
ally the tube closure is completed, and all carbon atoms
are three-coordinated in an sp2 hybridisation fashion. Al-
though the resulting closed structure is highly strained,
due to the presence of some small rings (a tetragon can be
seen) and to the adjacency of pentagons, this is certainly
a deep local minimum of the potential energy hyper-
surface, as the structure, once closed, remains unaltered
(except for thermal oscillations), even after heating up
the system to 3000 K and following the dynamics at this
temperature for a further 10 ps. Obviously, the time-scale
for structural re-orderings once the nanotube has closed
is much larger than the time-scale for the closure itself.
This is because structural changes now must happen via
the Stone-Wales60 mechanism, which has a high activa-
tion barrier, and therefore occurs very infrequently61.

4

closure occurs within a few tens of ps. This ﬁnding is
in agreement with previous ﬁrst-principles results62. At
temperatures between 1000 and 2000 K the time scale
for closure (which remains beyond the scope of the sim-
ulation times covered here) could be in the order of hun-
dreds of ps or even in the ns range, but even so this
seems to us to be too short a time scale for permitting
nanotube growth, and this is presumably why single-wall
nanotubes cannot be obtained without using transition
metal nano-particles which act as catalysts. However,
the microscopic details of this catalytic growth process
are as yet far from being understood63.

In order to gain some insight into the experimental ob-
servation that boron doping can result in the production
of longer and more crystalline multi-wall nanotubes, and
in particular how it favors the zig-zag type tubes over the
arm-chair or chiral ones, we have performed a number of
static and dynamical simulations in the (10,0) nanotube
system with diﬀerent degrees of boron substitution.

B. Boron doped nanotubes

We ﬁrst address the question as to why boron tends
to accumulate at the ends of the nanotubes, as has been
experimentally observed48. To investigate this site pref-
erence, we have performed a series of relaxation calcula-
tions in which we compare the energy of nanotube and
ﬂat edge structures with a boron atom substituting a car-
bon atom at diﬀerent sites. We have considered two dif-
ferent nanotube structures, one a zig-zag nanotube with
indices (10,0) (the same as illustrated in Figure 1), and a
(6,6) arm-chair nanotube. For each of the two structures
we have taken into account ﬁve possible boron substi-
tutional sites, namely: the boron atom substitutes at an
edge carbon site (site α), the boron is located at a site one
bond away from the edge site (site β), two bonds away
(site γ), three (site δ) and six bonds away from the edge
(site ǫ). These positions are illustrated schematically in
Figure 4.

(e)

(f)

FIG. 3. Diﬀerent stages of the closure of the (10,0) nan-
otube at 2500 K. These structures were observed at approx-
imately (a) 2 ps, (b) 5 ps, (c) 8 ps, (d) 11 ps, (e) 15 ps and
(f) 18 ps.

We now discuss the results obtained from the simu-
lation of the (5,5) nanotube. During the ﬁrst 10 ps of
dynamics, in which the average temperature was ﬁxed
at 1000 K, one of the edges of a hexagon at the end of
the nanotube is broken, and as a result a carbon chain is
formed which oscillates under the inﬂuence of the thermal
motion, but no (5/7) complexes are observed at this tem-
perature. When the temperature is increased to 2000 K
two more hexagons break, but still no (5/7) pairs are
formed. At 2500 K nearly all edge hexagons have broken,
and consequently there is an abundance of carbon chains.
Among these the ﬁrst two pentagons can be observed, but
there are still no signs of heptagons. This is probably be-
cause the mechanism of pentagon formation in this case
is somewhat diﬀerent than in the (10,0) nanotube.
In
the latter, pentagons and heptagons occur in pairs, re-
sulting from the fusion of two edge hexagons. Here the
pentagons appear from the re-bonding of chains result-
ing from the breaking of edge hexagons. The presence
of these pentagons induces curvature in the structure,
which will eventually cause the tube closure. At 3000 K
a total of three pentagons are seen, and the structure is
rapidly evolving towards complete closure, but this only
happens beyond 10 ps of dynamics at this temperature.
Our results show unambiguously that the open edges
of nanotubes are unstable, and at suﬃciently high tem-
peratures close spontaneously by forming half-fullerene
caps. The time scales we ﬁnd for the nanotube closure
are only orientative, as they may vary slightly for dif-
ferent initial conditions, and certainly they are sensitive
to the temperature, but we can say that above 2000 K,

5

a double bond cannot form, and the conﬁguration that
results is thus less stable than conﬁguration β. The same
trends are evident from the calculations involving the ﬂat
graphene edges, indicating that the curvature of the nan-
otubes does not play any signiﬁcant part in determining
the energetics of the boron-substituted structures.

TABLE I. Energies of boron-substituted structures for
zig-zag and arm-chair nanotube and graphene edges. The
energies are given in eV relative to the most stable structure
in each case.

bonds
from edge
0
1
2
3
6

(10,0)
nanotube
0.00
1.39
0.57
1.30
1.41

zig-zag
edge
0.00
0.99
0.67
1.42
1.35

(6,6)
nanotube
0.58
0.00
0.60
0.83
0.88

arm-chair
edge
0.48
0.00
0.66
0.75
0.88

(a)

(b)

α

δ

β

γ

ε

β

δ

α

γ

ε

FIG. 4. (a) Schematic view of the boron substitutional sites
considered in the (10,0) nanotube and the zig-zag graphene
edge; (b) the substitutional sites in the (6,6) nanotube and
arm-chair graphene edge.

Our results, given in Table I, show that in both types of
nanotubes the most favorable position for boron to sub-
stitute at is in the vicinity of the edge . However, there
are marked diﬀerences between both types of edges. In
the zig-zag case, the energy of the structure with boron
substituted in site β is 1.4 eV higher than the structure
with boron substituted at the α site, almost the same
as for substitution of boron far (site ǫ) from the edge
(1.41 eV). So, in the case of the zig-zag edge it is much
more favorable for boron to substitute at the edge than
elsewhere in the nanotube. In the arm-chair edge, how-
ever, it turns out that the most stable structure is that in
which the boron atom is placed at a site one bond away
from the edge, i.e. site β in Figure 4(b), which turns out
to be 0.58 eV more stable than the structure obtained by
placing the boron atom directly at the edge (site α). Nev-
ertheless, boron will still preferentially locate itself close
to the edge rather than far away from it, as the energy
diﬀerence between the most stable conﬁguration and that
with boron placed in site ǫ is 0.88 eV. These ﬁndings can
be easily rationalized: in the zig-zag case it is more fa-
vorable for boron to be at the edge than elsewhere in the
tube because in this way the number of carbon dangling
bonds at the nanotube edge is reduced, given that boron
has one electron less than carbon. In the arm-chair case,
however, the same argument does not apply, because the
carbon atoms at the edge are able to pair up forming a
stable double bond. By placing a boron atom at the edge

6

These static calculations illustrate how boron could
play a role in favoring zig-zag structures over arm-chair
ones, as has been found experimentally. Our ﬁndings
are in very good agreement with the DFT plane-wave
pseudo-potential results reported by Blase and cowork-
ers48. However, these results do not give any explanation
for the increased length of the nanotubes synthesized in
the presence of boron. Thus, in order to gain some in-
sight into how boron can assist the production of longer
nanotubes, we have performed a series of MD simula-
tions of a (10,0) nanotube with varying degrees of boron
substitution at the edge. We have employed the same
structure as illustrated in Figure 1, but placing four, six,
eight and ten boron atoms at the tube edge, substitut-
ing as many carbon atoms in each case. Starting from
such conﬁgurations, we have performed MD simulations
following the same pattern described above for the un-
doped carbon nanotubes. Let us comment brieﬂy on the
details of the dynamics in each case. In all instances, at
the lowest temperature considered (1000 K), the struc-
tures remain unaltered during the time spanned at this
temperature (10 ps); all hexagonal rings present initially
maintain their identity during this time, and it is not
until the system is run at a temperature of 2000 K that
structural changes begin to appear.

When only four boron atoms are present, after 10 ps
of dynamics at 2000 K two (5/7) pairs are formed at the
tube edge. The structure of these (5/7) pairs is such
that the common edge between both rings always incor-
porates a boron atom [see Figure 5(a)]. This is a struc-
tural feature that repeats itself frequently in the other
cases considered, as will be seen below. At this temper-
ature, a transient C4 ring, and a B2C6 octagonal ring
are also seen. When the temperature is raised further to
2500 K, the boron containing pentagons still survive, but
the heptagonal rings break, and carbon chains linked to
the pentagons are formed. These chains, of length equal
to two or three bonds, oscillate widely, eventually linking
with similar chains or unsaturated bonds along the open
edge, thus initiating the tube closure. The tube is closed
after approximately 8.5 ps at this temperature. Given
the low concentration of boron at the tip, the dynamics
observed here is rather similar to that already described
for the pure carbon case.

(a)

(b)

α

β

γ

α

(c)
α’

β

γ

FIG. 5. Schematic view of (a) the (5/7) edge complex ob-
served during the MD runs of the (10,0) nanotube (the circle
indicates the position where boron is found in the boron doped
cases); (b) one of the the possible edge reconstructions involv-
ing pentagons and heptagons in the arm-chair type tubes, the
(7/5/7) complex, and (c) the (5/7) arm-chair edge complex.
The circles indicate the substitutional sites considered in the
relaxation calculations (see text).

When the number of boron atoms is increased to 6,
at the temperature of 2000 K two (5/7) complexes like
those observed in the four-boron atom case are formed,
but the structure is otherwise unaltered. These boron-
containing (5/7) pairs are remarkably stable; they remain
intact even after 10 ps at 2500 K. In this particular case,
it is necessary to rise the temperature further, to 3000 K,
for the tube closure to occur. This happens only after

7

8 ps of dynamics at this temperature, which is indicative
of a higher stability of the open edge when compared to
the tube with only four boron atoms. In the case of the
nanotube doped with eight boron atoms, the structure
develops two (5/7) pairs within 10 ps at 2000 K, much like
in the previous cases. However, once the temperature is
elevated to 2500 K, the structure closes completely within
7.5 ps. This result appears to contradict the thesis that
increasing the amount of boron at the tube edge delays
the closure process, but in fact this is not necessarily so,
as will be argued below.

Finally, let us consider the case of the tube with ten
boron atoms. Like in all the cases analyzed earlier,
structural changes at the open edge begin to appear at
a temperature of 2000 K, at which a boron-containing
(5/7) pair is formed. Three such complexes can be seen
after 10 ps at 2500 K, but the structure is otherwise un-
changed. It is necessary to reach a temperature of 3000 K
and monitor the dynamics of the system for 11 ps at
this temperature before the tube can be said to be com-
pletely closed. We note that Blase and coworkers48, who
have also performed MD simulations of this particular
system using DFT with a basis set of plane-waves and
the pseudo-potential approximation up to temperatures
of 2500 K for 10 ps, failed to observe the closure. The
results reported here indicate that, at such a tempera-
ture, it is most likely that the closure would not occur
below 10 ps, as it required 11 ps at 3000 K to observe
the closure in the simulations that we have performed.

(a)

(b)

(c)

(d)

FIG. 6. The dome structures of the closed boron doped
nanotubes arrived at during the MD simulations: (a) nan-
otube with four boron atoms, (b) nanotube with six boron
atoms, (c) nanotube with eight boron atoms and (d) with ten
boron atoms.

8

Figure 6 illustrates the structures obtained at the end
of the MD simulations described above. As can be seen,
regardless of the amount of boron present initially at the
tube edge, the ﬁnal structures are invariably closed, but
as seen in the discussion, there are notable diﬀerences
observed during the dynamics in each case. That the
nanotubes evolve in such a way as to achieve a closed
structure is, after all, not so surprising, given that the
closed structures, with all atoms connected in an sp2
network are always more stable than the corresponding
open structures. For example, the structure illustrated
in Figure 6(d), once relaxed at 0 K, is 13.7 eV more sta-
ble than the corresponding open structure (a ﬁgure to be
compared with an energy diﬀerence of 17 eV, obtained
for the pure carbon case using the same two structures).
Nevertheless, as can be seen from the discussion above,
the details of the closure process vary according to the
amount of boron present at the edge.

Our MD results seem to indicate that a delay of the
tube closure occurs when boron is present in the sys-
tem. However, it is diﬃcult to establish this beyond
doubt purely on the basis of a small number of MD tra-
jectories, because at each temperature and boron com-
position there will be a distribution of possible closure
times (depending on the initial conditions) for a given
type of nanotube. To get a clear picture of how the clo-
sure time distribution changes as the amount of boron is
increased would require a very large sample of MD simu-
lations, much larger than would be practical to carry out
given the computational costs involved. Our simulations
are clearly insuﬃcient in number to reveal unambigu-
ously the changing trends in closure times with increasing
boron content, which could explain the apparently con-
tradicting result obtained for the tube with eight boron
atoms, which closes faster and at a lower temperature
than the tube with only six boron atoms. Nevertheless,
these simulations are suﬃcient to clarify the role played
by boron when present at the open edge of a nanotube,
and are thus extremely revealing. They indicate that be-
fore the tube closure can begin to occur, (5/7) complexes
form at the edge. This is true of both the pure carbon
and the boron doped tubes. Under the eﬀect of the rapid
thermal motion the heptagons seem to be more prone to
breaking, and the chains of atoms thus formed initiate or
can participate in the tube closure. Interestingly, when
boron is present, it seems to be always associated with
these structures once they are formed, in the manner de-
picted in Figure 5(a).

These observations have lead us to perform a new set
of static structural relaxation calculations, in which we
investigate the stability of these edge (5/7) complexes in
both (n,0) and (n,n) nanotubes. We have compared the
energy of a normal zig-zag edge structure, such as that
shown in Figure 1 with that of a zig-zag edge containing
a (5/7) pair, both in the pure carbon case and in the
case in which the (5/7) pair contains a boron atom sit-
uated between the pentagon and heptagon at the edge
It turns out that a (5/7) pair placed at
[Figure 5(a)].

the edge of a pure (10,0) tube lowers the total energy by
about 0.56 eV. When boron is present between the pen-
tagon and heptagon, the energy gain is slightly larger,
0.67 eV, according to our calculations. This seems to in-
dicate that the formation of such boron containing edge
complexes stabilizes the open edge, and consequently de-
lays its closure.

A (5/7) complex is also possible at an arm-chair nan-
otube edge, where it is also possible to construct a more
complicated edge structure, involving a pentagon and two
heptagons, which we call a (7/5/7) edge complex; both
structures are illustrated schematically in Figure 5(b)
and 5(c). Structure 5(b) is reminiscent of the ring-defect
structure discussed by Crespi et al.64. We have investi-
gated the stability of these, both in the pure carbon case
and when boron is present in the diﬀerent possible sub-
stitutional sites. The results from these calculations are
listed in Table II. It turns out that the only reconstructed
arm-chair edge which is more stable than the structure β
shown in Figure 4(b) is that illustrated in Figure 5(b),
with the boron atom placed between the two heptagonal
rings, but not forming part of the pentagon (i.e. site β).
Even so, the energy diﬀerence is only small (0.33 eV),
certainly smaller than the energy gain obtained by the
reconstruction in the zig-zag edge.

TABLE II. Energies of boron-substituted reconstructed
edges for the (6,6) nanotube. The labeling of the edges corre-
sponds to that of Figure 5 (b) and (c). The energies are given
in eV relative to the most stable unreconstructed substituted
arm-chair edge structure.

Position
α
β
γ
α′

Structure (b)
1.10
-0.33
0.46
–

Structure (c)
3.40
3.17
2.67
2.64

The results obtained from these structural relaxation
calculations provide a possible mechanism for explaining
both the observed preference for the zig-zag structure and
the improved aspect ratio of nanotubes synthesized in the
presence of boron. The reconstruction of a zig-zag edge
in which boron is present from the saw-tooth structure
illustrated in Figure 1 to one containing a (5/7) pair is
exothermic, resulting in a signiﬁcant stabilization of the
nanotube. In the case of an undoped nanotube edge, this
reconstruction also lowers the energy, but by a smaller
amount. Note also that, while similar reconstructions
are possible in the case of a boron doped arm-chair nan-
otube, only one such reconstructions lowers the energy
with respect to the unreconstructed edge, and only by a
small amount. Boron, thus, is seen to signiﬁcantly sta-
bilize zig-zag edges compared to arm-chair ones and we
expect the former tubes to grow better; furthermore the
edge (5/7) relaxation mechanism we have found is only
eﬀective in zig-zag edges, a fact that contributes to favor
this type of tube even further.

IV. CONCLUSIONS

We have performed an extensive theoretical study of
the eﬀects of the presence of varying amounts of boron in
the edge of growing nanotubes using TB MD and struc-
tural relaxation calculations. In spite of the approximate
nature of the TB model used here, it gives results that
compare quite well with the available FP data from the
work of Blase et al.48.

We have shown that both carbon and boron-doped
nanotubes spontaneously close in a time scale of a few
(≤ 20) ps in a temperature range of 2500-3000 K. In the
case of boron-doped tubes the MD simulations reveal a
pattern of longer closure times as the amount of boron
at the tip of the nanotube is increased. The presence of
boron in the proximity of the tube edge has a stabilizing
eﬀect, but this eﬀect is larger in the case of zig-zag nan-
otubes than in the case of arm-chair ones. Furthermore,
we have shown that in (n,0) edges a reconstruction of
the edge involving (5/7) pairs stabilizes further the open
edge. Although similar reconstructions are topologically
possible in the case of (n,n) edges they do not result in
any signiﬁcant stabilization of this type of edge.

These results contribute to a better understanding of
the experimental observations45,47,48 that boron accumu-
lates at the nanotube tips, that it favors zig-zag nan-
otubes over other structures, and that the nanotubes
synthesized in the presence of boron have a larger aspect
ratio than other nanotubes.

* to whom correspondence should be addressed; emai:

ehe@icmab.es

9

ACKNOWLEDGMENTS

20 H. Dai, J.H. Hafner, A.G. Rinzler, D.T. Colbert and

E.H. wishes

to thank X. Blase, M. Terrones,
N. Grobert, W.K. Hsu, H. Terrones and M.J. L´opez for
enlightening discussions. E.H. and P.O. thank the EU
for ﬁnancial support under project SATURN (IST-1999-
10593). A.R and J.A.A ackowledge support by the DGES
(Grant: PB98-0345), JCyL (Grant: VA28/99), and
EU TMR NAMITECH project (ERBFMRX-CT96-0067
(DG12-MITH)). I.B. acknowledges support by the DGES
(SAB 1995-0670P) of Spain during the sabbatical stay
at the University of Valladolid, by the DFG (Deutsche
Forschungsgemeinschaft Project SPP-Polyeder), and ﬁ-
nally by the Fonds der Chemischen Industrie. We ac-
knowledge the C4 (Centre de Computaci´o i Comunica-
cions de Catalunya) and CEPBA (European Centre for
Parallelism of Barcelona) for the use of their computer
facilities.

1 S. Iijima, Nature (London) 354, 56 (1991).
2 M.S. Dresselhaus, G. Dresselhaus and P.C. Eklund, Science
of Fullerenes and Carbon Nanotubes (Academic Press, New
York 1996).

3 T.W. Ebbesen (Ed.), Carbon Nanotubes, Preparation and

Properties (CRC Press, Boca Raton 1997).

4 P.M. Ajayan and T.W. Ebbesen, Rep. Prog. Phys. 60, 1025

(1997).

5 P.M. Ajayan, Chem. Rev. 99, 1787 (1999).
6 M. Terrones, W.K. Hsu, H.W. Kroto and D.R.M. Walton,

Topics in Current Chemistry 199, 189 (1999).

7 M.M.J. Treacy, T.W. Ebbesen and J.M. Gibson, Nature

(London) 381, 678 (1996).

8 N.G. Chopra and A. Zettl, Solid State Comm. 105, 297

(1998).

9 A. Krishnan, E. Dujardin, T.W. Ebbesen, P.N. Yanilos and

M.M.J. Treacy, Phys. Rev. B 58, 14013 (1998).

10 E.W. Wong, P.E. Sheehan and C.M. Lieber, Science 277,

1971 (1997).

11 E. Hern´andez, C. Goze, P. Bernier and A. Rubio, Phys.

Rev. Lett. 80, 4502 (1998).

12 J.P. Lu, Phys. Rev. Lett. 79, 1297 (1997).
13 B.I. Yakobson, C.J. Brabec and J. Bernholc, Phys. Rev.

Lett. 76, 2411 (1996).

14 M. Buongiorno Nardelli, B.I. Yakobson and J. Bernholc,

Phys. Rev. B 57, R4277 (1998).

15 N. Hamada, S. Sawada and A. Oshiyama, Phys. Rev. Lett.

68, 1579 (1992).

16 J.W.G. Wild¨oer, L.C. Venema, A.G. Rinzler, R.E. Smalley

and C. Dekker, Nature (London) 391, 59 (1998).

17 J.P. Lu, Phys. Rev. Lett. 74, 1123 (1995).
18 W.H. Knechtel, G.S. D¨usberg, W.J. Blau, E. Hern´andez

and A. Rubio, Appl. Phys. Lett. 73, 1961 (1998).

19 P. Poncharal, Z.L. Wang, D. Ugarte and W.A. de Heer,

Science 283, 1513 (1999).

10

R.E. Smalley, Nature (London) 384, 147 (1996).

21 W.A. de Heer, A. Chatelain and D. Ugarte, Science 270,
1179 (1995); A.G. Rinzler, J.H. Hafner, P. Nikolaev,
L. Lou, S.G. Kim, D. Tom´anek, P. Norlander, D.T. Colbert
and R.E. Smalley, Science 269, 1550 (1995).

22 P.G. Collins, A. Zettl, H. Bando, A. Thess and R.E. Smal-

ley, Science 278, 100 (1997).

23 S.J. Tans, A.R.M. Verschueren and C. Dekker, Nature

(London), 393, 49 (1998)

24 N.G. Chopra, R.J. Luyken, K. Cherrey, V.H. Crespi,
M.L. Cohen, S.G. Louie and A.Zettl, Science 269, 966
(1995).

25 A. Loiseau, F. Willaime, N. Demoncy, G. Hug and H. Pas-

card, Phys. Rev. Lett. 76, 4737 (1996).

26 M. Terrones, W.K. Hsu, H. Terrones, J.P. Zhang,
J.P. Hare, R. Castillo, K. Prasides,
S. Ramos,
A.K. Cheetham, H.W. Kroto and D.R.M. Walton, Chem.
Phys. Lett. 259, 568 (1996).

27 M. Terrones, A.M. Benito, C. Manteca-Diego, W.K. Hsu,
J.P. Hare, D.G. Reid, H. Terrones,
O.I. Osman,
A.K. Cheetham, K. Prasides, H.W. Kroto and D.R.M. Wal-
ton, Chem. Phys. Lett. 257, 576 (1996).

28 K. Suenaga, C. Colliex, N. Demoncy, A. Loiseau, H. Pas-

card and F. Willaime, Science 278, 653 (1997).

29 L. Rapoport, Y. Bilik, Y. Feldman, M. Homyonfer,
S.R. Cohen and R. Tenne, Nature (London) 387, 791
(1997).

30 Y. Feldman, E. Wasserman, D.J. Srolovitz and R. Tenne,

Science 267, 222 (1995).

31 R. Tenne, L. Margulis, M. Genut and G. Hodes, Nature

(London) 360, 444 (1992).

32 Y.R. Hacohen, E. Grunbaum, R. Tenne, J. Sloan and

J.L. Hutchinson, Nature (London) 395, 336 (1998).

33 A. Rubio, J.L. Corkill and M.L. Cohen, Phys. Rev. B 49,

5081 (1994).

34 X. Blase, A. Rubio, S.G. Louie and M.L. Cohen, Europhys.

Lett. 28, 335 (1994).

35 Y. Miyamoto, A. Rubio, S.G. Louie, and M.L. Cohen,

Phys. Rev. B 50 18360 (1994).

36 Y. Miyamoto, A. Rubio, S.G. Louie, and M.L. Cohen,

Phys. Rev. B 50, 4976 (1994).

37 S.M. Lee, Y.H. Lee, Y.G. Hwang, J. Elsner, D. Porezag

and Th. Frauenheim, Phys. Rev. B 60, 7788 (1999).

38 I. Boustani, A. Quandt, E. Hern´andez and A. Rubio, J.

Chem. Phys. 110, 3176 (1999).

39 M. Cote, M.L. Cohen and D.J. Chadi, Phys. Rev. B 58,

4277 (1998).

40 G. Seifert and E. Hern´andez, Chem. Phys. Lett. 318, 355

(2000).

41 M.R. Ghadiri, J.R. Granja, R.A. Milligan, D.E. McRee and

N. Khazanovich, Nature (London) 366, 324 (1993).

42 P. Carloni, W. Andreoni and M. Parrinello, Phys. Rev.

Lett. 79, 761 (1997).

43 A. Thess, R. Lee, P. Nikolaev, H. Dai, P. Petit, J. Robert,
C. Xu, Y.H. Lee, S.G. Kim, A.G. Rinzler, D.T. Colbert,
G.E. Scuseria, D. Tom´anek, J.E. Fischer and R.E. Smalley,
Science 273, 483 (1996).

44 S. Bandow, S. Asaka, Y. Saito, A.M. Rao, L. Grigorian,
E. Richter and P.C. Eklund, Phys. Rev. Lett. 80, 3779

(1998).

45 P. Redlich, J. Loeﬀer, P.M. Ajayan, J. Bill, F. Aldinger and

M. Ruhle, Chem. Phys. Lett. 260, 465 (1996).

46 D.L. Carroll, P. Redlich, P.M. Ajayan, S. Curran, S. Roth

and M. Ruhle, Carbon 36, 753 (1998).

47 M. Terrones, W.K. Hsu, A. Schilder, H. Terrones,
N. Grobert, J.P. Hare, Y.Q. Zhu, M. Schwoerer, K. Pras-
sides, H.W. Kroto and D.R.M. Walton, Appl. Phys. A 66,
307 (1998).

48 X. Blase, J.-C. Charlier, A. de Vita, R. Car, P. Redlich,
M. Terrones, W.K. Hsu, H. Terrones, D.L. Carroll and
P.M. Ajayan, Phys. Rev. Lett. 83, 5078 (1999).

49 For a review on tight-binding see C.M. Goringe,
D.R. Bowler and E. Hern´andez, Rep. Prog. Phys. 60, 1447
(1997).

50 D. Porezag, T. Frauenheim, T. K¨ohler, G. Seifert and

R. Kashner, Phys. Rev. B 51, 12947 (1995).

51 J. Widany, T. Frauenheim, T. K¨ohler, M. Sternberg,
D. Porezag, G. Jungnickel and G. Seifert, Phys. Rev. B
53, 4443 (1996).

52 P.W. Fowler, T. Heine, D. Mitchell, G. Orlandi,
R. Schmidt, G. Seifert and F. Zerbetto, J. Chem. Soc.,
Faraday Trans. 92, 2203 (1996).

53 A. Ayuela, P.W. Fowler, D. Mitchell, R. Schmidt, G. Seifert

and F. Zerbetto, J. Phys. Chem. 100, 15634 (1996).

54 H. Terrones, M. Terrones, E. Hern´andez, N. Grobert, J.-
C. Charlier and P.M. Ajayan, Phys. Rev. Lett 84, 1716
(2000).

55 F. Fugaciu, H. Hermann and G. Seifert, Phys. Rev. B 60,

10711 (1999).

56 W.H. Press, S.A. Teukolsky, W.T. Vetterling and
B.P. Flannery, Numerical Recipes,
the Art of Scien-
tiﬁc Computing 2nd Edition (Cambridge University Press
1992).

57 S. Nos´e, J. Chem. Phys. 81, 511 (1984).
58 W.G. Hoover, Phys. Rev. A 31, 1695 (1985).
59 D. Frenkel and B. Smit, Understanding Molecular Simula-

tion, Academic Press, San Diego (1996).

60 A.J. Stone and D.J. Wales, Chem. Phys. Lett. 128, 501

(1986).

61 T.R. Welsh and D.J. Wales, J. Chem. Phys. 109, 6691

(1998).

62 J.-C. Charlier, A. De Vita, X. Blase, and R. Car, Science

275, 646 (1997).

63 H. Kanzow and A. Ding, Phys. Rev. B 60, 11180 (1999).
64 V.H. Crespi, M.L. Cohen and A. Rubio, Phys. Rev. Lett.

79, 2093 (1997).

11"
"Ab initio calculations for bromine adlayers on the Ag(100) and Au(100)
  surfaces: the c(2x2) structure","  Ab initio total-energy density-functional methods with supercell models have
been employed to calculate the c(2x2) structure of the Br-adsorbed Ag(100) and
  Au(100) surfaces. The atomic geometries of the surfaces and the preferred
bonding sites of the bromine have been determined. The bonding character of
bromine with the substrates has also been studied by analyzing the electronic
density of states and the charge transfer. The calculations show that while the
four-fold hollow-site configuration is more stable than the two-fold
bridge-site topology on the Ag(100) surface, bromine prefers the bridge site on
the Au(100) surface. The one-fold on-top configuration is the least stable
configuration on both surfaces. It is also observed that the second layer of
the Ag substrate undergoes a small buckling as a consequence of the adsorption
of Br. Our results provide a theoretical explanation for the experimental
observations that the adsorption of bromine on the Ag(100) and Au(100) surfaces
results in different bonding configurations.
",http://arxiv.org/pdf/cond-mat/0104040v2,3,"Ab initio calculations for bromine adlayers on the Ag(100) and Au(100) surfaces:

the c(2

2) structure

×

2
0
0
2

b
e
F
5

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
0
4
0
4
0
1
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Sanwu Wang1 and Per Arne Rikvold1,2
1School of Computational Science and Information Technology,
and Center for Materials Research and Technology,
Florida State University, Tallahassee, Florida 32306-4120
2Department of Physics, Florida State University, Tallahassee, Florida 32306-4350

Ab initio total-energy density-functional methods with supercell models have been employed to
calculate the c(2 × 2) structure of the Br-adsorbed Ag(100) and Au(100) surfaces. The atomic
geometries of the surfaces and the preferred bonding sites of the bromine have been determined.
The bonding character of bromine with the substrates has also been studied by analyzing the
electronic density of states and the charge transfer. The calculations show that while the four-
fold hollow-site conﬁguration is more stable than the two-fold bridge-site topology on the Ag(100)
surface, bromine prefers the bridge site on the Au(100) surface. The one-fold on-top conﬁguration
is the least stable conﬁguration on both surfaces. It is also observed that the second layer of the Ag
substrate undergoes a small buckling as a consequence of the adsorption of Br. Our results provide
a theoretical explanation for the experimental observations that the adsorption of bromine on the
Ag(100) and Au(100) surfaces results in diﬀerent bonding conﬁgurations.

PACS numbers: 68.43.Bc, 68.43.Fg, 68.47.-b, 82.45.-h

I. INTRODUCTION

Anion adsorption on metals can strongly modify sur-
face morphology and electronic structure and chemical
reactivity. It is therefore of great scientiﬁc and techno-
In particular, the halide-adsorbed
logical importance.
noble-metal systems play a signiﬁcant role in electro-
chemistry. From the fundamental point of view, halide-
adsorbed noble-metal surfaces are important model sys-
tems for adsorption on metal surfaces with formation of
ordered two-dimensional adsorbate structures. It is thus
not surprising that the adsorption of halides on noble
metals has been extensively investigated.

The systems we selected to study are the Br-
chemisorbed Ag(100) and Au(100) surfaces. The adsorp-
tion of bromine on the Ag(100) and Au(100) surfaces
both in vacuum and in solution have been widely studied
by experiments1–12 and by classical simulations.13–16 Ex-
perimentally, bromine has been found to form diﬀerent
bonding structures on the Ag(100) and Au(100) surfaces.
While bromine chemisorbed on the Ag(100) surface occu-
pies the four-fold hollow site (hereafter referred to as H4),
the most stable chemisorption structure on Au(100) is
the conﬁguration with bromine at the two-fold bridge site
(hereafter referred to as B2). These diﬀerent chemisorp-
tion structures have been veriﬁed by various experimental
measurements.1–4,6–12 However, theoretical studies have
not yet reproduced these diﬀerent adsorption behaviors.
Kleinherbers et al. performed angle-resolved photoe-
mission, low-energy electron diﬀraction (LEED), and X-
ray photoemission measurements for the interaction of
halides with Ag surfaces.1 They found that the adsorp-
tion of Cl, Br, and I on the Ag(100) surface in vacuum all
resulted in the formation of a c(2
2) overlayer with the
adsorbates in the H4 sites. Using in situ surface X-ray

×

1

×

×

×

scattering, Ocko et al. studied the adsorption of bromide
on an Ag(100) electrode. They observed a disordered
phase at lower coverages and an ordered c(2
2) phase at
a coverage of half a monolayer.2 The Br was determined
to bond at the H4 site in both the c(2
2) and disor-
dered phases. The atomic geometry of the Br/Ag(100)-
2) surface was further investigated by Endo et al.
c(2
with the in situ X-ray absorption ﬁne structure (XAFS)
method.4 The H4 site was conﬁrmed to be the bonding
site of bromine. The disordered phase of the Br/Ag(100)
surface at lower bromine coverages was also recently fur-
ther investigated experimentally.3 In that study, it was
suggested that while most of the bromide ions occupy
the H4 sites, there are additional bromide ions adsorbed
slightly oﬀ the H4 sites.

2), (√2

The LEED data reported by Bertel et al.6,7 have shown
that the chemisorption of Br on the Au(100) surface in
vacuum results in the rearrangement of the top-layer Au
20)
atoms of the original clean reconstructed Au(100)-(5
surface and the formation of an unreconstructed (1
1)
substrate structure. Several ordered structures of the
4√2)R45◦, and
Br adlayer, including c(2
2)R45◦, were obtained after bromine exposure on
c(4
Au(100) surfaces, with the former two structures being
metastable. It was concluded from the experimental data
that Br adsorbed at the B2 site on the Au(100) surface in
all the observed phases. This is in contrast to the case of
the Br-adsorbed Ag(100) surface. Under electrochemical
in situ conditions, surface X-ray scattering and scanning
tunneling microscopy (STM) experiments showed that
bromide adsorbed on the unreconstructed Au(100)-(1
1)
2√2)R45◦ struc-
surface forms a commensurate c(√2
2√2,
ture and an incommensurate c(√2
depending on the applied potential).8,9,11,12 In this case,
too, the bromide ions were determined to reside at the

×
2p)R45◦ (p

×
×

≤

×

×

×

×

×

 
 
 
 
 
 
B2 sites.

In contrast to the considerable progress of the exper-
imental measurements, theoretical studies employing ab
initio methods to these systems are still at an early stage.
Several groups have performed ab initio Hartree-Fock
(HF) and density-functional-theory (DFT) calculations
for the Br/Ag(100) and Br/Au(100) interfaces using clus-
ter models.17–20 While these investigations have provided
useful information about the interaction between Br and
the surfaces, as we discuss below, many of the results are
not yet suﬃciently accurate. For example, the preferred
bonding site of Br on the Au(100) surface was incor-
rectly predicted by ab initio DFT cluster calculations,
which showed that Br would prefer to bond at the H4
site on both the Ag(100) and Au(100) surfaces.18 Simi-
larly, ab initio HF studies with small clusters predicted
the bridge site as the preferred adsorption site for Br on
Ag(100).19 Given that these calculations with small clus-
ters cannot reproduce such a fundamental property as
the binding site, all other results (e.g., energy barriers)
obtained from such calculations for both the Br/Ag(100)
and Br/Au(100) systems are questionable.

Here we present results of total-energy DFT calcula-
tions in which we used supercell models for the Ag(100)
and Au(100) surfaces. The detailed atomic structures
and electronic properties of the chemisorbed surfaces
and the preferred bonding site of the adsorbate have
been determined. Our theoretical approach has repro-
duced the diﬀerent behavior of Br on the Ag(100) and
Au(100) surfaces. The most stable adsorption sites for
Br chemisorbed on the Ag(100) and Au(100) surfaces are
determined by our calculations to be the H4 and the B2
sites, respectively. Our results are in excellent agreement
with the experimental data. The obtained results for the
electronic properties also enable us to analyze the nature
of the bonding between Br and the substrates and un-
derstand the diﬀerent adsorption behavior of Br on the
Ag(100) and Au(100) surfaces.

The remainder of this paper is organized as follows.
In Sec. II we outline in detail the computational method
and the supercell models that we used.
In Sec. III we
present and discuss the results for bulk, clean surfaces
(Sec. III A), and adsorbed surfaces (Sec. III B). The ad-
sorption geometries and atomic relaxations are discussed
in Sec. III B1, and the electronic properties and bonding
character in Sec. III B2. We also give comparisons of our
results with previous calculations and experimental data.
Finally, in Sec. IV, we summarize the main results of our
calculations.

II. METHOD AND MODEL

On the Ag(100) and Au(100) surfaces, there are three
diﬀerent symmetric adsorption sites, known as H4, B2,
and T1 (on-top) sites. These three sites are shown in
2) structure in which Br
Fig. 1. We have studied a c(2

×

2

(a)

(b)

(c)

FIG. 1. Schematics of an adatom at (a) the four-fold hol-
low (H4) site, (b) the two-fold bridge (B2) site, and (c) the
on-top (T1) site on the unreconstructed Ag(100) and Au(100)
surfaces.

forms an adlayer with a coverage of 1
surface for each of the three bonding conﬁgurations.

2 monolayer on the

The metal surface is modeled by repeated slabs with
ﬁve, seven, and nine metal layers separated by a vac-
uum region equivalent to ﬁve or seven metal layers. Each
metal layer in the supercell contains two metal atoms. Br
is adsorbed symmetrically on both sides of the slab. All
the metal atoms were initially located at their bulk po-
sitions, with the equilibrium lattice constant of the bulk
determined by our calculations.

theory, using the pseudopotential

The calculations were performed within density-
functional
(PP)
method and a plane-wave basis set. The results re-
ported in this paper were obtained using the Vi-
enna ab-initio simulation package (VASP).21–23 The
exchange-correlation eﬀects were treated with the gener-
alized gradient-corrected exchange-correlation function-
als (GGA) given by Perdew and Wang.24,25 We adopted
the scalar-relativistic Vanderbilt ultrasoft pseudopoten-
tials supplied by Kresse and Hafner26,27. A plane-wave
energy cutoﬀ of 20 Ry and 56 special k points in the ir-
reducible part of the two-dimensional Brillouin zone of
the c(2
2) surface were used for calculating both the
Br/Ag(100) and Br/Au(100) surfaces. Optimization of
the atomic structure was performed for each supercell
via a conjugate-gradient technique using the total energy
and the Hellmann-Feynman forces on the atoms.28 All
the structures were fully relaxed until the change in total
energy was smaller than 1 meV between two ionic steps.
The convergence of the total energies was checked with

×

diﬀerent values of the plane-wave cutoﬀ and diﬀerent
numbers of special k points. A series of test calculations
with diﬀerent slab thicknesses (from ﬁve to nine metal
layers) and vacuum-gap widths (equivalent to ﬁve and
seven metal layers) were also carried out to check con-
vergence. The calculations on which this paper is based
represent approximately 300 CPU hours on an IBM SP2
computer.

III. RESULTS AND DISCUSSION

A. Bulk and clean surface

We ﬁrst present the calculated properties for bulk sil-
ver and bulk gold, and the relaxed but unreconstructed
clean Ag(100) and Au(100) surfaces.

Calculations for bulk Ag and Au were conducted with
408 special k points and cutoﬀ energies ranging from 20
Ry to 40 Ry. The total energy convergence with respect
to the cutoﬀ energy was shown to be within a few tenths
of 1 meV. We obtained lattice constants of 4.17 ˚A and
4.18 ˚A for bulk Ag and Au, about 2.0% and 2.5% larger
than the corresponding experimental values29 at room
temperature, respectively. Previous total-energy DFT
calculations at the GGA level found lattice constants be-
tween 4.13 ˚A and 4.19 ˚A for bulk Ag,30–37 and between
4.19 ˚A [Ref. 38] and 4.20 ˚A [Ref. 37] for bulk Au. Our
results are in good agreement with these calculations.

The properties of the clean Ag(100) and Au(100) sur-
faces were calculated using supercells containing a 7-layer
metal slab and a vacuum gap equivalent to 7 bulk-metal
1 surface cell was used with 66 special
layers. A 1
k points in the surface Brillouin zone. The kinetic en-
ergy cutoﬀ for the calculations was 20 Ry. All the layers
except for the central one were relaxed. Surface recon-
struction was not considered.

×

The surface energies for the Ag(100) and Au(100) sur-
faces obtained from our calculations are 0.43 eV/atom
and 0.47 eV/atom, respectively. Both results are in
good agreement with recent pseudopotential GGA cal-
culations by Yu and Scheﬄer, who reported the corre-
sponding values of 0.48 and 0.45 eV/atom.31,38 A re-
cent calculation with linear-muﬃn-tin-orbital (LMTO)-
GGA methods, however, obtained much larger values of
0.65 and 0.90 eV/atom for the unrelaxed Ag(100) and
Au(100) surfaces, respectively.37 The reason for the large
discrepancy from the other GGA results is not clear.
Pseudopotential local-density approximation (LDA),31,38
LMTO-LDA,39–41 and linearized augmented-plane-wave
LDA42–44 calculations have provided values of 0.59–0.7
eV/atom, and 0.69–0.72 eV/atom for the surface ener-
gies of the Ag(100) and Au(100) surfaces, respectively.
These DFT-LDA values for the surface energy are gen-
erally larger than those calculated with the DFT-GGA
calculations reported in this paper and Refs. 31 and 38.
This is consistent with the previous observation24 that

LDA surface energies are normally larger than the cor-
responding GGA values due to the diﬀerent treatment
of the exchange-correlation functional. The calculated
values for the surface energies are thus seen to be quite
sensitive to the computational method and the form of
the exchange-correlation functional.

Table I shows the results of the surface relaxation.
While no signiﬁcant structural relaxation is found for ei-
ther surface, the Ag(100) surface shows a slightly more
relaxed geometry than the Au(100) surface. Both sur-
faces show an inward relaxation of the top layer and
slight outward relaxation of the second and third lay-
ers. LEED measurements46 showed insigniﬁcant relax-
ation of the Ag(100) surface with ∆d12/d0 = 0
1.5%
and ∆d23/d0 = 0
1.5%, where ∆d12 and ∆d23 are the
changes in spacing between the top and the second layer
and between the second and the third layer, and d0 is
the bulk interlayer distance. Our results are thus in good
agreement with the experimental data, and basically con-
sistent with other ab initio calculations, the results of
which are also listed in Table I for comparison.

±

±

B. Br-adsorbed Ag(100) and Au(100) surfaces

1. Relaxations and energetics

×

2) and the Br/Au(100)-c(2

The results of our calculations for the Br/Ag(100)-
2) surfaces are shown
c(2
in Tables II and III. If not otherwise indicated, the re-
sults reported in this section (and in Tables II and III)
were calculated with a cutoﬀ energy of 20 Ry, 56 special
k points, and supercells containing a 9-layer metal slab
with a vacuum region equivalent to seven metal layers.

×

TABLE I. Relaxation of the clean Ag(100) and Au(100)
surfaces. ∆dij is the change of the interlayer distance, and d0
is the corresponding distance in the bulk.

∆d12/d0 (%) ∆d23/d0 (%) ∆d34/d0 (%)

−1.8
−1.4
−2.2
−1.3
−1.9
0 ± 1.5

−1.3
−1.2
−1.0

0.7

0.4
1.0

0 ± 1.5

0.3
0.4

0.2

0.8

0.2

Ag(100)
This work
PP-GGAa
PP-LDAa
PP-LDAb
LMTO-LDAc
Experimentd
Au(100)
This work
PP-LDAe
LMTO-LDAf

aRef. 31.
bRef. 45.
cRefs. 39–41.
dRef. 46.
eRef. 38.
f Refs. 40,41.

3

In-plane relaxations of the top-layer metal atoms were
found to result in changes of the distance between Br
and its nearest-neighbor metal atoms and of the total-
energy diﬀerence between two diﬀerent conﬁgurations
within only 0.01 ˚A and a few meV, respectively. The ef-
fects of in-plane relaxations are thus negligible, and such
relaxations were not considered in the calculations for the
Br-adsorbed surfaces.

Table II shows total-energy diﬀerences between diﬀer-
ent bonding conﬁgurations of both surfaces. Each struc-
ture was optimized. We found that while the total energy
of the H4 conﬁguration is lower by 213 meV than the B2
conﬁguration for the Br/Ag(100) surface, it is higher by
58 meV for the Br/Au(100) surface. The T1 conﬁgura-
tion for both surfaces is found to be higher in total energy
than both the corresponding H4 and B2 conﬁgurations.
Thus, we conclude that while Br adsorbed on the Ag(100)
surface prefers the H4 site, it is adsorbed at the B2 site
on the Au(100) surface. This conclusion is in agreement
with experimental observations.1–4,6–12

It is interesting to note that the magnitude of the total-
energy diﬀerence between the H4 and B2 structures for
Br/Ag(100) is signiﬁcantly larger than the correspond-
ing value for the Br/Au(100) surface. This suggests that
diﬀusion of Br on the Au(100) surface may occur much
more easily than on the Ag(100) surface since the total-
energy diﬀerence between the most stable conﬁguration
(the global minimum) and the less favorable conﬁgura-
tion (probably a saddle point) is directly relevant to ad-
sorbate diﬀusion.

Previous theoretical studies employing cluster mod-
els also determined the preferred bonding sites of Br
on the Ag(100) and Au(100) surfaces, as mentioned in
Sec. I. Ab initio HF calculations showed that Br would
prefer to bond at the B2 site on the Ag(100) surface
(by 370 meV/adatom over the H4 site, and by 570
meV/adatom over the T1 site).19 This is inconsistent with
both our DFT-supercell calculations and the experimen-
tal data.1–4 DFT cluster calculations predicted that the
binding energy of Br at the H4 site on both the Ag(100)
and Au(100) surfaces was larger than at the B2 and T1
sites by 120 meV for Ag(100) [89 meV for Au(100)] and

TABLE II. Total energy diﬀerences (in eV per unit cell)
between diﬀerent conﬁgurations of the Br/Ag(100)-c(2 × 2)
and Br/Au(100)-c(2 × 2) surfaces, obtained from calculations
with supercells containing a 9-layer slab and a 7-layer vacuum
region, a cutoﬀ energy of 20 Ry, and 56 special k-points.
EH4 − EB2 (Br/Ag(100))
EH4 − ET1 (Br/Ag(100))
EB2 − ET1 (Br/Ag(100))
EH4 − EB2 (Br/Au(100))
EH4 − ET1 (Br/Au(100))
EB2 − ET1 (Br/Au(100))

−0.213
−0.557
−0.344
+0.058
−0.244
−0.302

202 meV for Ag(100) [202 prefers to bond at the H4 site
on the Au(100) surface is in disagreement with exper-
imental measurements,6–12 as well as with our results.
We believe that the main problem is that these previ-
ous calculations were limited to small clusters, contain-
ing only up to 13 metal atoms. It is well known that a
small metal cluster has a very diﬀerent electronic struc-
ture than an extended metal surface, yielding very sig-
niﬁcant diﬀerences in adsorbate binding energies and re-
action pathways.47–50 Large clusters or extended surface
models (e.g., supercell models) are therefore needed to
simulate real metal surfaces accurately.

The structural parameters of the optimized geometries
for the H4, B2, and T1 conﬁgurations of the Br/Ag(100)
and Br/Au(100) surfaces are presented in Table III. The
vertical distances (dz) between the Br centers and the
plane of the centers of the top-layer atoms were calcu-
lated to be 1.91 ˚A on the Ag(100) surface and 2.01 ˚A
on the Au(100) surface for the H4 structure, 2.16 ˚A on
Ag(100) and 2.18 ˚A on Au(100) for the B2 conﬁguration,
and 2.48 ˚A on Ag(100) and 2.46 ˚A on Au(100) for the
T1 structure. While the values of dz for the B2 and T1
conﬁgurations of the Br/Ag(100) surface are very close
to the corresponding values for the Br/Au(100) surface,
the distance between Br and the surface in the H4 conﬁg-
uration is observed to be signiﬁcantly longer (by 0.1 ˚A)
on Br/Au(100) than on Br/Ag(100). Accurate in-situ
XAFS measurements for Br/Ag(100) in NaBr solution
by Endo et al. showed that the bond length between Br
and its four nearest-neighbor Ag atoms in the H4 con-
0.05 ˚A, and the distance between the
ﬁguration is 2.82
0.07 ˚A.4 Our results (2.82 ˚A
Br and the surface is 1.94
±
and 1.91 ˚A, respectively) are thus in excellent agreement
with the experimental data, provided that the solution
has only a minor inﬂuence on the bond lengths between
the adsorbate and the surface.

±

The bond lengths between Br and Ag and Au clusters
of varying size have been obtained with both HF and
DFT calculations. Illas et al., using the HF method with
a cluster of 5 Ag atoms simulating the H4 conﬁguration
of the Ag(100) surface, obtained a value of 3.43 ˚A for
the length of the Br-Ag bond.20 Paccioni, also using the
HF method with slightly larger clusters, found that the
bond lengths between a Br ion and the surface Ag atom
were 3.24 ˚A, 2.97 ˚A, and 2.94 ˚A in clusters of Br−-Ag13
(modeling the H4 structure), Br−-Ag8 (simulating the
B2 geometry), and Br−-Ag13 (representing the T1 con-
ﬁguration), respectively. Ignaczak and Gomes performed
DFT calculations with clusters containing a Br ion and
12 metal atoms and determined the bond lengths to be
3.2 ˚A, 3.0 ˚A, and 2.9 ˚A for the H4, B2, and T1 conﬁgu-
rations of Br−-Ag12 and Br−-Au12 clusters, respectively.
All of these values are much larger that those obtained
from our supercell calculations and the XAFS measure-
ments, suggesting that small clusters do not represent
the metal surfaces properly.

The B2 conﬁguration of the Br/Ag(100) surface shows
a very similar relaxation of the surface metal layers as

4

that of the same conﬁguration for the Br/Au(100) sur-
face. Both undergo an inward relaxation of the top layer
and slight outward relaxations of the second and third
layers. Similar relaxed structures are also found for the
clean Ag(100) and Au(100) surfaces (see Table I).

Our calculations show that the second metal layer un-
dergoes a small buckling with the adsorption of Br in the
H4 conﬁgurations. The atoms in the second layer that
are immediately below the H4 sites are observed to shift
slightly up towards the surface, while the other atoms in
that layer shift up by only on the order of 0.001 ˚A and
hence essentially keep their bulk positions. The spacing
between these two sub-layers is found to be 0.02 ˚A and
0.04 ˚A for the Br/Ag(100) and Br/Au(100) surfaces. The
distance between Br and the second-layer metal atom
just below it is still far larger than the bond length be-
tween Br and its nearest-neighbor metal atoms in the
top layer. Thus a pseudo-ﬁve-fold coordination, which
has been observed in c(2
2) overlayer structures on bcc
metal surfaces,51,52 does not exist for the Br/Ag(100) and
Br/Au(100) surfaces. This buckling may give rise to an
eﬀective Br-Br interaction, mediated through the surface
strain ﬁeld. The top metal layer in the H4 conﬁgurations
still shows a slight inward relaxation, similar to the cases
of the clean surfaces and the B2 conﬁgurations.

×

The top metal layer of the T1 conﬁguration of the
Br/Au(100) surface also shows a small buckling. The
Au atoms in the top layer that are bonded to Br are
observed to undergo a larger inward relaxation than the
other half of the Au atoms in the top metal layer. The
corresponding buckling is, however, very large for the T1
conﬁguration of the Br/Ag(100) surface. The distance
between the two sublayers formed from the top Ag layer
is 0.75 ˚A, indicating a zigzag surface reconstruction.

Finally, in Table IV we show results of convergence
checks for the total-energy diﬀerences. Such checks are
particularly important for the Br/Au(100) surface due to
the small value of the total-energy diﬀerence between the
H4 and B2 conﬁgurations. Calculations with a higher
cutoﬀ energy (30 Ry) obtained total-energy diﬀerences
within 1 meV of those from calculations with a cutoﬀ
Increasing the number of special k
energy of 20 Ry.
points from 36 to 56, increasing the slab thickness from
7 to 9 metal layers, and increasing the vacuum region
in the supercell from 5 to 7 layers, all changed the re-
sults by only a few meV. Supercells with 5 metal layers
are seen to cause errors in the total-energy diﬀerences of
10 meV for Br/Au(100).
∼
The use of 20 special k points also causes an error of
10 meV. Therefore, it is necessary to employ supercells
∼
with at least 7 metal layers and 36 special k points for
obtaining the total-energy diﬀerences with errors smaller
than 10 meV. The distances between Br and its nearest-
neighbor metal atoms were also checked. We found that
the changes of these distances were smaller than 0.01 ˚A
over the ranges of cut-oﬀ energies between 20 and 30 Ry,
numbers of k points between 20 and 56, and numbers of
metal layers between 5 and 9 in the supercells, indicating

30 meV for Br/Ag(100) and

∼

that the bond lengths are not very sensitive to the choice
of computational parameters.

2. Electronic properties and bonding character

In order to better understand the diﬀerences between
the bonding of bromine on the Ag(100) and Au(100) sur-
faces, we calculated the total electronic density of states
(DOS), the DOS projected onto individual atoms and
speciﬁc atomic states, and the charge transfer between
bromine and the substrate.

Figure 2 shows the total DOS for the Br-adsorbed
Ag(100) and Au(100) surfaces. For comparison, the total
DOS for the clean relaxed Ag(100) and Au(100) surfaces
are also shown. The peaks of the DOS curves for the
clean surfaces represent the main features of the s and
d states of the substrates and remain essentially at the
same positions when bromine atoms are adsorbed. New
15
states are, however, found to be located at between
eV and
13 eV relative to the Fermi level in the DOS
curves of the Br-adsorbed Ag(100) and Au(100) surfaces.
These states are predominantly the bromine 3s states
with small contributions from the s and d states of the
substrate, as seen from the curves for the DOS projected
onto the speciﬁc atomic states of the adsorbate and the
substrate (shown in Fig. 3). Signiﬁcant changes of the
total DOS in the higher energy range close to the Fermi
1.5 eV for the Br/Ag(100) and
level (above
the Br/Au(100) surfaces, respectively) are also observed

2.5 eV and

−

−

−

−

)
s
t
i
n
u

.

b
r
a
(

s
e
t
a
t
S
f
o

y
t
i
s
n
e
D

40

0

40

0

40

0

40

0

Clean Ag(100)

Clean Au(100)

Br/Ag(100)−H4

Br/Au(100)−H4

Br/Ag(100)−B2

Br/Au(100)−B2

Br/Ag(100)−T1

Br/Au(100)−T1

−15

−10

−5

0

−15

−10

−5

0

Energy (eV)

FIG. 2. Total density of states for the clean relaxed and
the Br-adsorbed Ag(100) and Au(100) surfaces. The Fermi
level is at 0 eV. In this ﬁgure, as well as in Figs. 3 and
4, the curves are obtained from calculations with supercells
containing a 7-layer slab and a 7-layer vacuum region, a cutoﬀ
energy of 20 Ry, and 36 special k-points.

5

 
 
 
 
)
s
t
i
n
u

.

b
r
a
(

s
e
t
a
t
S
f
o

y
t
i
s
n
e
D
d
e
t
c
e
j
o
r
P

8

4

8

4

8

4

8

4

8

4

8

4

0

Br/Ag(100)−H4
Br 3s
Br 3p
Ag 5s
Ag 4d

Br/Ag(100)−B2
Br 3s
Br 3p
Ag 5s
Ag 4d

Br/Ag(100)−T1
Br 3s
Br 3p
Ag 5s
Ag 4d

Br/Au(100)−H4
Br 3s
Br 3p
Au 6s
Au 5d

Br/Au(100)−B2
Br 3s
Br 3p
Au 6s
Au 5d

Br/Au(100)−T1
Br 3s
Br 3p
Au 6s
Au 5d

−15

−10

−5
Energy (eV)

0

FIG. 3. The density of states projected onto the Br 3s,
Br 3p, Ag 5s, Ag 4d, Au 6s, and Au 5d states for the H4,
B2, and T1 conﬁgurations of the Br-adsorbed Ag(100) and
Au(100) surfaces.

when the DOS curves for the clean surfaces are compared
with those for the H4, B2, and T1 conﬁgurations of the
Br-adsorbed surfaces (see Fig. 2). The electronic states
in the higher energy range are composed mostly of the
bromine 3p states and the Ag 4d (or Au 5d) states, with
some contributions coming from the Ag 5s (or Au 6s)
states (see Fig. 3).

In Fig. 4, we show the DOS projected onto bromine for
the systems before and after adsorption. The results for
the systems before adsorption were calculated by employ-
ing the supercell of a 7-layer slab and a 7-layer vacuum
region. A bromine layer with a c(2
2) periodicity was
kept ﬁxed in the middle of the vacuum region (located
7 ˚A above the surface) so that there was essen-
at
tially no interaction between Br and the substrate. The
peaks located in the lower and higher energy ranges in
the projected DOS before adsorption are due to the Br

∼

×

3s and 3p states, respectively. The slight broadening of
the 3p states reﬂects the weak 3p-3p interaction between
neighboring bromine atoms. When bromine is adsorbed,
both the 3s and 3p states shift down in energy due to the
bonding between bromine and the substrate. A broad-
ening of the Br 3p states is also observed and can be
attributed to the hybridization of the bromine 3p states
with the s- and d-bands of the substrates (see Fig. 3).
The Br 3s states are also seen to mix slightly with the
s and d states of the substrate (see also Fig. 3). The
hybridization of the Br 3s and 3p states with the elec-
tronic states of the substrate suggests covalent bonding
between bromine and the Ag(100) and Au(100) surfaces.
The bonding of Br with the Ag(100) and Au(100) sur-
faces is also found to be associated with a charge transfer
from the substrate to Br. To obtain a rough estimate
of the charge transfer, we calculated the change of the
charge for a bromine atom upon adsorption by integrat-
ing the diﬀerence of the corresponding charge densities
over a sphere with a radius of 1.28 ˚A around the atom.53
We found that 0.15 and 0.14 electrons were transfered
from the Ag(100) and Au(100) surfaces, respectively, to
the bromine atom. The amount of the charge transfer
was found to be basically the same for the H4, B2, and T1
conﬁgurations. These results are consistent with the data
for the DOS projected onto the Br atom. By integrating
the 3p contributions up to the Fermi level, we observe
that more 3p states are occupied in the Br-adsorbed sur-
faces than in the systems before adsorption (see Fig. 4).
A recent periodic GGA calculation with a local basis
set for the adsorption of chlorine on the Ag(111) sur-
face also found that a slight charge (
0.2 electrons) was
transferred from the Ag(111) substrate to the chlorine
atom.54 Experimental measurements of the electrosorp-
tion valency of Br adsorbed on Ag(100) report values
0.75,5,13,15,16 corresponding
of approximately
−
to a residual charge of 0.25 to 0.30 electrons on the ad-
sorbed Br. These values are considerably larger than our
calculated charge of 0.15 electrons. The discrepancy may
be due to the fact that our calculations were performed
for systems in vacuum.
In an electrochemical environ-
ment, the net charge associated with the adsorbate might
be very diﬀerent from that in vacuum, due to solvation.
However, the discrepancy might also be attributed to in-
accuracies in the theoretical and experimental methods
used to estimate the charge.

0.70 to

∼

−

The diﬀerence in the bonding strength of the bromine
with the substrate between the diﬀerent conﬁgurations
directly aﬀects their relative stability. Based on our DOS
data, we provide a qualitative explanation of the diﬀer-
ence in bonding strength between the H4 and B2 conﬁg-
urations. The Br 3s and 3p states in the Br/Ag(100)-H4
conﬁguration are signiﬁcantly lower in energy than in the
Br/Ag(100)-B2 conﬁguration (see Fig. 4).
In addition,
the intensity of the lower part of the 3p states (below ap-
proximately
3 eV) is larger for Br/Ag(100)-H4 than for
Br/Ag(100)-B2. Both facts suggest a stronger bonding
for the H4 conﬁguration on Ag(100). This is expected

−

6

 
 
 
 
 
since there are more direct bonding neighbors for the
bromine atom at the H4 site. On the other hand, the Br

Before adsorption

(a)

)
s
t
i
n
u

.

b
r
a
(

s
e
t
a
t
S
f
o

y
t
i
s
n
e
D
d
e
t
c
e
j
o
r
P

4

0

4

0

4

0

2

0

2

)
s
t
i
n
u

.

b
r
a
(

s
e
t
a
t
S
f
o
y
t
i
s
n
e
D
d
e
t
c
e
j
o
r
P

Br/Ag(100)−H4
Br/Ag(100)−B2
Br/Ag(100)−T1

Br/Au(100)−H4
Br/Au(100)−B2
Br/Au(100)−T1

0

(b)

−15

−10

−5
Energy (eV)

Br/Ag(100)−H4
Br/Ag(100)−B2
Br/Ag(100)−T1

Br/Au(100)−H4
Br/Au(100)−B2
Br/Au(100)−T1

0

−8

−6

−2
−4
Energy (eV)

0

2

FIG. 4. The density of states projected onto Br for the H4,
B2, and T1 conﬁgurations of the Br-adsorbed Ag(100) and
Au(100) surfaces (a) over a larger energy range (−16 eV to
2 eV) in which both the 3s and 3p states are shown, and (b)
over a smaller energy range (−8 eV to 2 eV) where only the 3p
states are presented. Also shown in (a) is the DOS projected
onto Br without adsorption.

7

∼ −
∼ −

3s states in the Br/Au(100)-H4 conﬁguration are only
slightly lower in energy than in the Br/Au(100)-B2 con-
ﬁguration. While the Br 3p states extend over almost
the same range in energy for the Br/Au(100)-H4 and -
B2 conﬁgurations, they have slightly larger intensity in
2 eV) and smaller intensity in
the lower part (below
2 eV) for the Br/Au(100)-H4
the higher part (above
conﬁguration than for the Br/Au(100)-B2 conﬁguration.
While the H4 conﬁguration thus has a stronger covalent
bonding for both the Br-adsorbed Ag(100) and Au(100)
surfaces, the diﬀerence in bonding strength between the
H4 and the corresponding B2 conﬁgurations is smaller for
the Au(100) surface than for the Ag(100) surface. This is
probably due to the fact that the Au 6s and 5d electrons
are more delocalized than the Ag 5s and 4d electrons,
and the bonding strength is expected to be less sensitive
to the bonding sites for substrates with more delocalized
electrons. In addition to the stronger covalent bonding,
the Coulomb attraction resulting from the charge transfer
in the H4 conﬁguration is also stronger than the corre-
sponding B2 conﬁguration for both the Br/Ag(100) and
Br/Au(100) systems, due to the shorter distance between
bromine and the surface in the H4 conﬁguration (see Ta-
ble III).

It is clear that there is a delicate competition between
the attractive and repulsive interactions in each conﬁg-
uration.
In particular, the core-core repulsion between
bromine and the substrate, which is irrelevant to the elec-
tronic DOS but makes a contribution to the total energy
of the system, in the H4 conﬁguration is stronger than
in the B2 conﬁguration. The core-core repulsive energy
is calculated as an Ewald sum28,55 (see the third col-
umn of Table V). The total energy, as determined in our
DFT calculations, contains as separate parts the elec-
tronic and the core-core Coulomb contributions. Diﬀer-
ences of the electronic and the core-core contributions to
the total energy between the H4 and the B2 conﬁgura-
tion are presented in Table V. We note that considera-
tion of the electronic contributions alone does not prop-
erly address the opposite order of the total-energy dif-
ference (ie, the binding-energy diﬀerence) between the
H4 and B2 conﬁgurations for the the Br/Ag(100) and
Br/Au(100) surfaces. The core-core interactions need to
be included. For both the Br/Ag(100) and Br/Au(100)
surfaces, the electronic contribution favors the H4 con-
ﬁguration, while the core-core contribution favors the B2
conﬁguration. In the Ag(100) case, the core-core energy,
which is higher for H4 than for B2, is more than compen-
sated by the lower electronic energy for the H4 conﬁgu-
ration, resulting in H4 being the preferred bonding site
for Br on Ag(100). For the Br/Au(100) system, how-
ever, the lower electronic energy for the H4 conﬁguration
only partially compensates the higher core-core energy
for Br/Au(100)-H4. As a result, the B2 conﬁguration is
lower in total energy than the H4 conﬁguration for the
Br-adsorbed Au(100) surface. The small magnitudes of
the total-energy diﬀerences, compared to the individual
electronic and core-core contributions, strongly empha-

 
 
 
 
 
 
 
 
 
 
size the need for very accurate energy calculations and
careful convergence checks.

IV. CONCLUSIONS

The theoretical approach of supercell models combined
with ﬁrst-principles total-energy DFT pseudopotential
methods has reproduced experimental measurements of
preferred adsorption sites for Br-chemisorbed Ag(100)
and Au(100) surfaces.

We have shown that while the hollow-site conﬁgu-
ration is more stable on the Br/Ag(100) surface (by
210 meV/adatom over the bridge-site structure), the
bridge-site conﬁguration is more stable than the corre-
sponding hollow-site structure by 60 meV/adatom on
the Br/Au(100) surface. The calculations also predict
that the one-fold on-top conﬁguration is the least sta-
ble structure on both surfaces (560 meV and 300 meV
higher than the corresponding most stable structure for
the Br/Ag(100) and Br/Au(100) surfaces, respectively).
Other aspects of the geometries of the Br/Ag(100) and
Br/Au(100) systems have also been determined and are
shown to be in excellent agreement with the available
experimental data.

The bond between Br and the substrate is found to be
covalent with a slight polarization due to a small charge
transfer from the substrate to the bromine. The chemi-
cal bonding between Br and the substrate is shown to be
stronger in the H4 conﬁguration than in the B2 conﬁgu-
ration. Compared with the Br/Ag(100) surface, however,
the Br/Au(100) surface exhibits a reduced diﬀerence in
the bonding strength between the H4 and B2 conﬁgu-
rations. The core-core Coulomb interaction is found to
be higher for the H4 conﬁguration than for the B2 con-
ﬁguration. The detailed balance between the electronic
and the core-core contributions to the total energy de-
termines H4 and B2 as the the preferred bonding site on
the Ag(100) and Au(100) surfaces, respectively.

Our work demonstrates that the use of extended sur-
face models and careful convergence checks are critical
for obtaining reliable information on the Br/Ag(100) and
Br/Au(100) systems from ab initio calculations.

ACKNOWLEDGMENTS

We thank S. J. Mitchell and L. G. Wang for helpful
discussions. We also thank S. P. Lewis, M. A. Novotny
and G. Brown for comments on the manuscript. This
work was supported by the National Science Foundation
under grant No. DMR-9981815 and by Florida State
University through the Center for Materials Research and
Technology and the School of Computational Science and
Technology.

1 K. K. Kleinherbers, E. Janssen, A. Goldmann, and H.

Saalfeld, Surf. Sci. 215, 394 (1989).

2 B. M. Ocko, J. X. Wang, and Th. Wandlowski, Phys. Rev.

Lett. 79, 1511 (1997).

3 C. Hanewinkel, A. Otto, and Th. Wandlowski, Surf. Sci.

429, 255 (1999).

4 O. Endo, M. Kiguchi, T. Yokoyama, M. Ito, and T. Ohta,

J. Electroanal. Chem. 473, 19 (1999).

5 Th. Wandlowski, J. X. Wang, and B. M. Ocko, J. Elec-

troanal. Chem. 500, 418 (2001).

6 E. Bertel and F. P. Netzer, Surf. Sci. 97, 409 (1980).
7 F. P. Netzer, E. Bertel, and J. A. D. Matthew, Solid State

Commun. 33, 519 (1980).

8 B. M. Ocko, O. M. Magnussen, J. X. Wang, and Th. Wand-

lowski, Phys. Rev. B 53, R7654 (1996).

9 Th. Wandlowski, J. X. Wang, O. M. Magnussen, and B. M.

Ocko, J. Phys. Chem. 100, 10277 (1996).

10 T. Pajkossy, T. Wandlowski, and D. M. Kolb, J. Elec-

troanal. Chem. 414, 209 (1996).

11 B. M. Ocko, O. M. Magnussen, J. X. Wang, R. R. Adzic,

and Th. Wandlowski, Physica B 221, 238 (1996).
12 A. Cuesta and D. M. Kolb, Surf. Sci. 465, 310 (2000).
13 M. T. M. Koper, J. Electroanal. Chem. 450, 189 (1998).
14 M. T. M. Koper, Electrochim. Acta 44, 1207 (1998).
15 S. J. Mitchell, G. Brown, and P. A. Rikvold, J. Electroanal.

Chem. 493, 68 (2000).

16 S. J. Mitchell, G. Brown, and P. A. Rikvold, Surf. Sci. 471,

125 (2001).

17 J. A. N. F. Gomes and A. Ignaczak, J. Mol. Struc.

(Theochem.) 463, 113 (1999).

18 A. Ignaczak and J. A. N. F. Gomes, J. Electroanal. Chem.

420, 71 (1997).

19 G. Pacchioni, Electrochim. Acta 41, 2285 (1996).
20 F. Illas, J. Rubio, J. M. Ricart, and J. A. Garrido, J. Elec-

troanal. Chem. 200, 47 (1986).

21 G. Kresse and J. Hafner, Phys. Rev. B 47, 558 (1993).
22 G. Kresse and J. Furthm¨uller, Comput. Mat. Sci. 6, 15

(1996).

23 G. Kresse and J. Furthm¨uller, Phys. Rev. B 54, 11169

(1996).

24 J. P. Perdew, J. A. Chevary, S. H. Vosko, K. A. Jackson,
M. R. Pederson, D. J. Singh, and C. Fiolhais, Phys. Rev.
B 46, 6671 (1992).

25 J. P. Perdew and Y. Wang, Phys. Rev. B 45, 13244 (1992).
26 D. Vanderbilt, Phys. Rev. B 41, 7892 (1990).
27 G. Kresse and J. Hafner, J. Phys.: Condens. Matter 6,

8245 (1994).

28 M. C. Payne, M. P. Teter, D. C. Allan, T. A. Arias, and
J. D. Joannopoulos, Rev. Mod. Phys. 64, 1045 (1992).
29 CRC, CRC Handbook of Chemistry and Physics, 77th edn.

(CRC press, Boca Raton, 1996).

30 A. Khein, D. J. Singh, and C. J. Umrigar, Phys. Rev. B

51, 4105 (1995).

31 B. D. Yu and M. Scheﬄer, Phys. Rev. Lett. 77, 1095

(1996); Phys. Rev. B 55, 13916 (1997).

32 C. Ratsch, A. P. Seitsonen, and M. Scheﬄer, Phys. Rev. B

55, 6750 (1997).

33 P. A. Gravil, D. M. Bird, and J. A. White, Phys. Rev. Lett.

77, 3933 (1996).

34 P. A. Gravil, J. A. White, and D. M. Bird, Surf. Sci. 352,

8

248 (1996).

35 A. Eichler, G. Kresse, and J. Hafner, Surf. Sci. 397, 116

(1998).

36 M. Asato, A. Settels, T. Hoshino, T. Asada, S. Bl¨ugel, R.
Zeller, and P. H. Dederichs Phys. Rev. B 60, 5202 (1999).
37 L. Vitos, A. V. Ruban, H. L. Skriver, and J. Koll´ar, Surf.

Sci. 411, 186 (1998).

38 B. D. Yu and M. Scheﬄer, Phys. Rev. B 56, R15569 (1997).
39 M. Methfessel, D. Hennig, and M. Scheﬄer, Phys. Rev. B

46, 4816 (1992).

40 G. Boisvert, L. J. Lewis, M. J. Puska, R. M. Nieminen,

Phys. Rev. B 52, 9078 (1995).

41 V. Fiorentini, M. Methfessel, and M. Scheﬄer, Phys. Rev.

Lett. 71, 1051 (1993).

42 M. Weinert, R. E. Watson, J. W. Davenport, and G. W.

Fernando, Phys. Rev. B 39, 12585 (1989).

43 H. Erschbaumer, A. J. Freeman, C. L. Fu, and R. Pod-

loucky, Surf. Sci. 243, 317 (1991).

44 R. Eibler, H. Erschbaumer, C. Temnitschka, R. Podloucky,

and A. J. Freeman, Surf. Sci. 280, 398 (1993).

45 K. P. Bohnen and K. M. Ho, Vacuum 41, 416 (1990).
46 H. Li, J. Quinn, Y. S. Li, D. Tian, F. Jona, and P. M.

Marcus, Phys. Rev. B 43, 7305 (1991).

47 J. L. Whitten and H. Yang, Surf. Sci. Rep. 24, 55 (1996).
48 I. Panas, P. E. M. Siegbahn, and U. Wahlgren, Chem. Phys.

112, 325 (1987).

49 R. L. Whetten, D. M. Cox, D. J. Trevor, and A. Kaldor,

Phys. Rev. Lett. 54, 1494 (1985).

50 M. D. Mores, M. E. Gensic, J. R. Heath, and R. E. Smalley,

J. Chem. Phys. 83, 2293 (1985).

51 K. Griﬃths, D. A. King, G. C. Aers, and J. B. Pendry, J.

Phys. C 15, 4921 (1985).

52 M. P. Bessent, P. Hu, A. Wander, and D. A. King, Surf.

Sci. 325, 272 (1995).

53 The value of 1.28 ˚A was chosen to be intermediate between
the atomic (1.14 ˚A) and ionic (1.95 ˚A) radii of bromine,
but closer to the atomic radius.

54 K. Doll and N. M. Harrison, Phys. Rev. B 63, 165410

(2001).

55 J. Ihm, A. Zunger, and M. L. Cohen, J. Phys. C: Solid

State Phys. 12, 4409 (1979).

9

TABLE III. Relaxation of the H4, B2, and T1 conﬁgurations of the Br/Ag(100)-c(2 × 2) and Br/Au(100)-c(2 × 2) surfaces.
Also shown are the vertical distance (dz, in units of ˚A) between Br and the plane of the centers of the top-layer atoms on the
surface, and the distance (d, in units of ˚A) between Br and its nearest-neighbor metal atom(s). The change in spacing between
′
layers i and j is denoted by ∆dij. When sub-layers are present, the changes are denoted by ∆dij and ∆d
ij, with ∆dij being
the larger in magnitude. d0 is the same as in Table I. The computational details are the same as in Table II.

Br/Ag(100)-H4
Br/Ag(100)-B2
Br/Ag(100)-T1
Br/Au(100)-H4
Br/Au(100)-B2
Br/Au(100)-T1

dz
1.91
2.16
2.48
2.01
2.18
2.46

d
2.82
2.61
2.48
2.89
2.62
2.46

∆d12/d0 (%)
−0.6
−0.9
10.4
−1.6
−0.9
−1.2

∆d

′
12/d0 (%)

0.1

−7.7
0.2

−0.5

∆d23/d0 (%)
0.8
0.5
0.2
1.4
0.4
0.5

∆d

′
23/d0 (%)

0.1

−0.3

∆d34/d0 (%)
−0.0
0.2
−0.1
0.4
0.3
0.4

TABLE IV. Convergence checks for the total energy diﬀerences (in units of eV per unit cell)
between diﬀerent conﬁgurations with respect to the cutoﬀ energy (Ecut, in units of Ry), the number
of metal layers (Nm) in the supercell, the thickness of the vacuum region (Nv, in units of number
of bulk metal layers), and the number of k points in the surface Brillouin zone (Nk).

Ecut

Nm

Nv

Nk

20
20
20
30
20
20
20

5
7
7
7
7
7
9

7
7
7
7
5
7
7

20
20
36
36
36
56
56

EH4 − EB2
Br/Ag(100)
−0.191
−0.222
−0.211
−0.212
−0.210
−0.210
−0.213

EH4 − ET1
Br/Ag(100)
−0.526
−0.556
−0.552
−0.552
−0.550
−0.551
−0.557

EH4 − EB2
Br/Au(100)
+0.061
+0.048
+0.056
+0.057
+0.057
+0.059
+0.058

EB2 − ET1
Br/Au(100)
−0.282
−0.285
−0.291
−0.291
−0.289
−0.294
−0.302

TABLE V. Diﬀerences (in eV per unit cell) of two energy
contributions to the total energy between the H4 and B2
conﬁgurations. Ee and Ecc are the electronic and core-core
Coulomb contributions, respectively. Also shown is the to-
− Etot
tal-energy diﬀerence (Etot
B2 ). The results are obtained
H4
from calculations with supercells containing a 7-layer slab and
a 7-layer vacuum region, a cutoﬀ energy of 20 Ry, and 36 spe-
cial k-points.

Br/Ag(100)
Br/Au(100)

− Ee
Ee
B2
H4
−429.230
−371.156

− Ecc
Ecc
B2
H4
+429.018
+371.213

− Etot
B2

Etot
H4
−0.212
+0.057

10"
Ten-nanometer surface intrusions in room temperature silicon,"  Defects ~10 nm in size, with number densities ~10^{10} cm^{-2}, form
spontaneously beneath ion-milled, etched, or HF-dipped silicon surfaces
examined in our Ti-ion getter-pumped transmission electron microscope (TEM)
after exposure to air. They appear as weakly-strained non-crystalline
intrusions into silicon bulk, that show up best in the TEM under conditions of
strong edge or bend contrast. If ambient air exposure is <10 minutes, defect
nucleation and growth can be monitored {\em in situ}. Possible mechanisms of
formation are discussed.
",http://arxiv.org/pdf/cond-mat/0110393v1,3,"1
0
0
2

t
c
O
9
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
3
9
3
0
1
1
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Ten-nanometer surface intrusions in room temperature silicon

Shuhan Lin, Iris Mack, Noom Pongkrapan, and P. Fraundorf∗
Physics & Astronomy and Center for Molecular Electronics,
U. Missouri-StL (63121)
St. Louis, MO, USA
(Dated: October 25, 2018)
Defects ∼ 10nm in size, with number densities ∼ 1010cm−2, form spontaneously beneath ion-
milled, etched, or HF-dipped silicon surfaces examined in our Ti-ion getter-pumped transmission
electron microscope (TEM) after exposure to air. They appear as weakly-strained non-crystalline
intrusions into silicon bulk, that show up best in the TEM under conditions of strong edge or bend
contrast. If ambient air exposure is < 10 minutes, defect nucleation and growth can be monitored
in situ. Possible mechanisms of formation are discussed.

PACS numbers: 61.72.Ff, 68.37.Lp, 81.05.Cy, 85.40.-e

I.

INTRODUCTION

As gigascale integrated circuit devices approach
nanometer dimensions, the bulk and surface structure of
single crystal silicon is attracting ﬁner scrutiny. In this
context, recent searches for bulk defects 10 nm in size re-
quired that we consider more carefully some ubiquitous
but weakly-strained specimen preparation artifacts that
for studies of larger bulk defects we had ignored.

TEM observations show that these imperfections,
which form in variously-oriented silicon surfaces after ex-
posure to air, are strikingly similar after thinning with
physically diﬀerent methods. Moreover, the process of
their formation can be slowed to laboratory time scales
at room temperature if air exposure is suﬃciently short.
This allows in situ study of nucleation and growth, of-
fering a view of dynamic processes in silicon which take
place on laboratory time scales at room temperature, in-
cluding the movement of self-interstitials and surface dif-
fusion barrier formation. Both of these are subjects of
widespread fundamental and applied interest [1, 2, 3, 4].

II. EXPERIMENTAL SETUP

This study was begun on 200mm p-type boron-doped
wafers, although the results have been checked on archive
specimens with a wide range of ingot diameters (down
to 100mm), growth conditions, impurity concentrations,
and thermal histories. The silicon was cut into 3 mm
diameter disks, mechanically thinned, and dimpled to
about 20 micron thickness in the center. Final thinning
to perforation involved one of three methods: (a) ion-
milling, in which the thinned disk was bombarded with
1 keV or 4 keV Ar ions at an incidence angle of 70 to 85
degrees, until perforation; (b) chemical etching, in which
the thinned disk was put into a solution of concentrated
HN O3 : HF = 3 : 1 until perforation, followed by a

∗pfraundorf@umsl.edu

water wash; and (c) “HF dip”, in which a chemically
etched specimen is dipped for 30 seconds in concentrated
50-55% HF before the wash, so as to passivate surface
silicon atoms with hydrogen to reduce the rate of surface
oxidation.

Specimens were examined in a 300 kV Philips
EM430ST TEM with point resolution near 0.2nm. A
10µm diameter objective aperture was used to increase
diﬀraction contrast, as an aid in locating otherwise nearly
invisible defects. Choice of regions and orientations
where strong thickness fringe and/or bend contour con-
trast was available [5] also aided visualization. This
sometimes involved enlarging the perforation to increase
”wedge angles” at the perforation edge, since contrast
in the neigborhood of thickness fringes [6] was the most
reliable way to count number densities over large areas.

III. OBSERVATIONS OF DEFECT STRUCTURE
AND ABUNDANCE

Figures 1, 2, and 3 show defects in specimens prepared
with the above three methods. All defects measured 5 to
15 nm in diameter, and had weak strain ﬁelds when, for
example, compared with ”bulk” oxygen precipitates of
comparable size. The defect density and the morphology
of defects so detected are comparable in all specimens
examined so far. These include (100) specimens prepared
by each of the methods mentioned above, plus ion milled
specimens with (111) and (110) surface orientations.

The defects are most easily seen under two-beam con-
ditions in specimens with large wedge angles (Fig. 2).
Here their contrast suggests that they’re associated with
“beam-direction columns” in the specimen containing
less silicon than found in adjacent columns, as expected
for voids or amorphous precipitates. The thickness of
missing silicon (determined from the phase lag in contrast
given the extinction distance for the active reﬂection) is
comparable to the lateral size of the defects, suggesting
that they are nearly as deep as they are wide. Plots of de-
fect number density of defects versus specimen thickness
in several such images did not show the increase in pro-

 
 
 
 
 
 
2

FIG. 2: Defects seen with help from thickness fringe contrast
under (220) 2-beam near-Bragg conditions in (001) silicon af-
ter a 3:1 nitric:HF acid etch. Defect density and specimen
◦
thickness are not proportional. The wedge half-angle is ∼ 12
.

FIG. 3: Images taken 1 and 45 hours after a 5 minute air
exposure of (100) silicon etched in 3:1 nitric:HF and then
dipped in concentrated HF to retard the rate of oxidation. We
have detailed chronology on the formation time of all defects
in the “after” image, except for those circled. These were
formed in an interval between the 31 hour and the 45 hour
mark, when no intervening observations were made.

FIG. 1: Defects which formed spontaneously when a (111)
silicon specimen was given less than 5 minutes of air expo-
sure after being thinned by Argon ion milling. The greyvalue
histogram of the image has been equalized to improve defect
visibility.

jected density expected for defects distributed through-
out the volume of the wafer. The surface-correlated na-
ture of these defects received further support from ion-
milling experiments. Removal of 10 to 30 nm of silicon
(by 10 seconds of Argon ion milling) from a previously-
examined surface created a new set of defects not corre-
lated with those present before milling.

A high resolution TEM image of one defect is shown in
Fig. 4. The defects show increased electron transmission
on lateral size scales large compared to the transverse
coherence width of the electrons [7] used in the exper-
iment (< 2nm). They also show (220) fringe contrast
[8] consistent with thinner silicon under the defect than
adjacent to it. On h100i surfaces, the defects sometimes
show faceting along (011), reminescent of (much larger)
platelet oxygen precipitates in silicon [9].

Studies of formation kinetics have been attempted for
(100) specimens prepared by each of the specimen prepa-
ration protocols mentioned above. Air exposure was min-
imized to between 1 and 10 minutes, following surface
preparation by milling or wet chemistry, by rapidly in-
serting the specimen into the Ti getter-pump vacuum of
the microscope. Following a nitric-HF etch, this precau-
tion resulted in no obvious decrease in the number of de-
fects. However, for ion-milled and HF-dipped specimens
the number density of defects observed following inser-
tion in the microscope was lower, by more than a factor
of 10, than the density otherwise routinely observed (e.g.
with post-preparation air exposures of half day or more).
More importantly, on those specimens with reduced

3

conditions, to be limited by rate of nucleation and not
by rate of growth. The initial rate of nucleation, in turn,
may be limited by the surface concentration of a molec-
ular species available through exposure to air (like oxy-
gen). Time-lapse series, and video tapes, over shorter
time intervals should allow a look at the growth process
itself. Given the apparent insensitivity of the process to
electron examination, such series may also allow lattice-
scale ”pre-nucleation” imaging of sites at which defects
are destined to develop at a later time.

IV. DISCUSSION

The classic empirical test for artifacts of TEM spec-
imen preparation is simple: Thin the specimen by two
physically diﬀerent techniques, e.g. by both Ar ion-
milling and by chemical etching. Only defects that are
not a result of specimen preparation are likely to be com-
mon in both cases. This test was the inspiration for work
on etched specimens, after we began characterizing more
carefully the defects in Ar ion-milled silicon mentioned
above. Even though the literature [10] argued against
Argon bubbles as a possible source, given our high inci-
dence angles and relatively large defect sizes, we wanted
experimental conﬁrmation.

The defects pass the classical test, in that they are
ubiquitous in etched and ion-milled surfaces of many
orientations and vintage (some stored in air for > 2
decades). Work here, however, shows that they do
form after specimen preparation. In that sense, litera-
ture studies of bulk defects have appropriately ignored
them. The presence of comparable defect number densi-
ties, sizes, and in the case of ion milled and HF-dipped
specimens comparable formation dynamics, after phys-
ically diverse thinning processes thus argues that they
result from the interaction between fresh silicon surfaces
and air or the microscope vacuum, independent of the
way in which the surfaces are created.

Observed parameters are as follows: (i) Final defect
number densities, after extended air exposure at standard
temperature and pressure are ∼ 1010 defects/cm2. (ii)
Initial e-folding times for nucleation, independent of air
exposure, are in the 10 to 30 hour range. (iii) Final size
of defects is ∼ 10nm, sometimes trailing to smaller and
less visible sizes. (iv) Time elapsed between nucleation,
and growth to full size, is much less than an hour.

Why these values? Note that 1010 defects/cm2 cor-
responds to an average half-distance between defects of
around 50 nm. This is comparable to the distance for
strain ﬁeld relaxation in silicon [11]. The defects might
thus support a process of silicon surface “hardening” on
air exposure, in which a compressional strain ﬁeld (still
mild compared to that of oxygen precipitates in a wafer
interior) is built up around an array of defects due to oxi-
dation. Oxidation of silicon surfaces occurs at room tem-
perature by indiﬀusion that can leave atomic steps on the
surface statistically intact. Hence signiﬁcant expansion

FIG. 4: A HREM image of spontaneously-forming defects in
an HF:nitric etched (100) silicon specimen. Faceting parallel
to the 0.192 nm (022) fringes is atypically strong in this defect.

defect density, new defects began to appear in the micro-
scope during “time-lapse observation” of the specimens
at 1 hour intervals over periods of days (Fig. 3). A pre-
liminary quantitative look at the early stages of this pro-
cess suggests e-folding times of approximately a day for
our ion-milled specimen, and more like a half day for the
etched surface after an HF-dip. Re-exposure to air for a
couple of hours, after a day or two in the microscope, re-
sults in a temporary increase in formation rate when the
specimen is put back into the microscope. However, the
process of defect formation in the microscope seems to
be “already completed” if the surfaces have instead been
exposed to air for signiﬁcantly longer periods of time (e.g.
a day or more) before examination.

We have been unable to “induce formation” of these
defects by exposure to the electron beam, even at beam
intensities orders of magnitude higher than those used for
routine observation. High resolution studies of these de-
fects during the time series on HF-dipped specimens con-
ﬁrm our impression, from conventional TEM images, that
the defects reach nearly their ﬁnal size by ﬁrst glance, i.e.
on time scales short compared to an hour.

Hence the formation of the defects seems, under these

4

sequences. Even buried beneath the native oxide, they
will scatter light diﬀusely. Harada et al ([12]) report SPM
observation of hillocks on (100) Si that assist early stage
oxidation, with lateral sizes and number densities com-
parable to the defects reported here. Silicon’s volume
increase on oxidation may thus result in associated sur-
face hillocks. This is supported so far by preliminary
work in our lab at creating such defects on extremely
ﬂat (as evidenced by 0.13 nm steps after native oxida-
tion) epitaxial silicon. We now think that previously re-
ported crystalline defects in TEM specimens of “bulk”
silicon (Fig. 5) with comparable number densities and a
2% lattice misﬁt [13] may also have formed at specimen
surfaces after thinning. Recent HREM work on simi-
larities between the above crystalline defects and Cu3Si
colony defects [14] in bulk silicon, and the similarity of
intrusions reported here to S-pit “intrusions” associated
with nickel contamination [15] in Si, suggest that hetero-
geneous nucleation may play a role in determining the
number density of these defects as well.

Acknowledgments

Thanks to Lu Fei, Jeﬀ Libbert, Lucio Mulestagno, and
Blake Rowe at MEMC Electronic Materials for insight
and diverse specimens, and to MEMC, Monsanto, and
Boeing for regional facility support.

FIG. 5: Image of crystalline defects with comparably weak
strain ﬁelds, small sizes, and high number densities likely
formed after thinning (100) silicon.

likely takes place at the buried oxide/silicon interface.
The resulting strain ﬁeld, much like the reaction “skin”
on a pot of soup allowed to sit, could in turn limit further
defect formation and defect size. One consequence of this
mechanism would be an expected decrease in size of in-
trusions nearby one another, something not demonstated
so far.

The presence of such subsurface defects will have con-

[1] M. J. Aziz, Appl. Phys. Lett. 70, 2810 (1997).
[2] R. C. Newman, J. Phys.: Condensed Matter 12, R335

(2000).

(1973).

[9] T. Y. Tan and W. K. Tice, Phil. Mag. 34(4), 615 (1976).
[10] U. Bangert, P. J. Goodhew, C. Jeynes, and I. H. Wilson,

[3] S. M. Myers, M. Seibt, and W. Schroter, J. Appl. Phys.

J. Phys. D: Appl. Phys. 19, 589 (1986).

88(7), 3795 (2000).

[4] S. K. Estreicher, M. Gharaibeh, P. A. Fedders, and P. Or-

[11] M. F. Ashby and L. M. Brown, Phil. Mag. 8, 1083 (1963).
[12] Y. Harada, M. Niwa, T. Nagatomi, and R. Shimizu, Jpn.

dejon, Phys. Rev. Lett. 86(7), 1247 (2001).

J. Appl. Phys. 39(2A), 560 (2000).

[5] P. Hirsch, A. Howie, R. B. Nicholson, D. W. Pashley,
and M. J. Whelan, Electron Microscopy of Thin Crys-
tals (Robert E. Krieger Publishing Company, Malabar,
Florida, 1965/1977), 2nd ed.

[6] M. F. Ashby and L. M. Brown, Phil. Mag. 8, 1649 (1963).
[7] J. C. H. Spence, Experimental High-Resolution Elec-
tron Microscopy (Oxford University Press, New York,
1980/1988), 2nd ed.

[8] J. G. Allpress and J. V. Sanders, J. Appl. Cryst. 6, 165

[13] P. Fraundorf and G. K. Fraundorf, in Proc. 47th Annual
Electron Microscope Society of America Meeting, edited
by G. W. Bailey (San Francisco Press, 1989), pp. 122–
123.

[14] J. K. Solberg, Acta Cryst. A 34, 684 (1978).
[15] G. Keefe and R. A. Craven, in Extended Abstracts (The
Electrochemical Society, Pennington NJ, 1983), vol. 83-1
of ECS Spring Meeting, pp. 480–487."
"Dynamic Structure Factor of Liquid and Amorphous Ge From Ab Initio
  Simulations","  We calculate the dynamic structure factor S(k,omega) of liquid Ge (l-Ge) at
temperature T = 1250 K, and of amorphous Ge (a-Ge) at T = 300 K, using ab
initio molecular dynamics. The electronic energy is computed using
density-functional theory, primarily in the generalized gradient approximation,
together with a plane wave representation of the wave functions and ultra-soft
pseudopotentials. We use a 64-atom cell with periodic boundary conditions, and
calculate averages over runs of up to 16 ps. The calculated liquid S(k,omega)
agrees qualitatively with that obtained by Hosokawa et al, using inelastic
X-ray scattering. In a-Ge, we find that the calculated S(k,omega) is in
qualitative agreement with that obtained experimentally by Maley et al. Our
results suggest that the ab initio approach is sufficient to allow approximate
calculations of S(k,omega) in both liquid and amorphous materials.
",http://arxiv.org/pdf/cond-mat/0206470v3,3,"3
0
0
2

n
a
J

0
3

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

3
v
0
7
4
6
0
2
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Dynamic Structure Factor of Liquid and Amorphous Ge From Ab

Initio Simulations

Jeng-Da Chai∗ and D. Stroud†

Department of Physics, The Ohio State University, Columbus, Ohio 43210

J. Hafner and G. Kresse

Institut f¨ur Materialphysik and Center for Computational Materials Science, Technische

Universit¨at Wien, Sensengasse 8/12, A-1090 Wien, Austria

(November 7, 2018)

Abstract

We calculate the dynamic structure factor S(k, ω) of liquid Ge (ℓ-Ge) at

temperature T = 1250 K, and of amorphous Ge (a-Ge) at T = 300 K, us-

ing ab initio molecular dynamics. The electronic energy is computed using

density-functional theory, primarily in the generalized gradient approxima-

tion, together with a plane wave representation of the wave functions and

ultra-soft pseudopotentials. We use a 64-atom cell with periodic boundary

conditions, and calculate averages over runs of up to about 16 ps. The cal-

culated liquid S(k, ω) agrees qualitatively with that obtained by Hosokawa

et al, using inelastic X-ray scattering. In a-Ge, we ﬁnd that the calculated

S(k, ω) is in qualitative agreement with that obtained experimentally by Ma-

∗Present address: Institute for Physical Science and Technology, University of Maryland, College

Park, Maryland 20742; email jdchai@wam.umd.edu

†Corresponding author: tel. (614)292-8140; fax (614)292-7557; email stroud@mps.ohio-state.edu

1

 
 
 
 
 
 
ley et al. Our results suggest that the ab initio approach is suﬃcient to allow

approximate calculations of S(k, ω) in both liquid and amorphous materials.

PACS numbers: 61.20.Gy, 61.20.Lc, 61.20.Ja, 61.25.Mv, 61.43.Dq

Typeset using REVTEX

2

I. INTRODUCTION

Ge is a well-known semiconductor in its solid phase, but becomes metallic in its liquid

phase. Liquid Ge (ℓ-Ge) has, near its melting point, an electrical conductivity characteristic

of a reasonably good metal (

1.6

×

∼

10−4Ω−1cm−1 [1]), but it retains some residual structural

features of the solid semiconductor. For example, the static structure factor S(k), has a

shoulder on the high-k side of its ﬁrst (principal) peak, which is believed to be due to a

residual tetrahedral short-range order. This shoulder is absent in more conventional liquid

metals such as Na or Al, which have a more close-packed structure in the liquid state and a

shoulderless ﬁrst peak in the structure factor. Similarly, the bond-angle distribution function

just above melting is believed to have peaks at two angles, one near 60o and characteristic

of close packing, and one near 108o, indicative of tetrahedral short range order. This latter

peak rapidly disappears with increasing temperature in the liquid state.

These striking properties of ℓ-Ge have been studied theoretically by several groups. Their

methods fall into two broad classes: empirical and ﬁrst-principles. A typical empirical cal-

culation is that of Yu et al [2], who calculate the structural properties of ℓ-Ge assuming

that the interatomic potentials in ℓ-Ge are a sum of two-body and three-body potentials

of the form proposed by Stillinger and Weber [3]. These authors ﬁnd, in agreement with

experiment, that there is a high-k shoulder on the ﬁrst peak of S(k) just above melting,

which fades away with increasing temperature. However, since in this model all the poten-

tial energy is described by a sum of two-body and three-body interactions, the interatomic

forces are probably stronger, and the ionic diﬀusion coeﬃcient is correspondingly smaller,

than their actual values.

In the second approach, the electronic degrees of freedom are taken explicitly into ac-

count. If the electron-ion interaction is suﬃciently weak, it can be treated by linear response

theory [4]. In linear response, the total energy in a given ionic conﬁguration is a term which

is independent of the ionic arrangement, plus a sum of two-body ion-ion eﬀective interac-

tions. These interactions typically do not give the bond-angle-dependent forces which are

3

present in the experiments, unless the calculations are carried to third order in the electron-

ion pseudopotential [4]. Such interactions are, however, included in the so-called ab initio

approach, in which the forces on the ions are calculated from ﬁrst principles, using the

Hellman-Feynman theorem together with density-functional theory [5] to treat the energy

of the inhomogeneous electron gas. This approach not only correctly gives the bond-angle-

dependent ion-ion interactions, but also, when combined with standard molecular dynamics

techniques, provides a good account of the electronic properties and such dynamical ionic

properties as the ionic self-diﬀusion coeﬃcients.

This combined approach, usually known as ab initio molecular dynamics, was pioneered

by Car and Parrinello [6], and, in somewhat diﬀerent form, has been applied to a wide range

of liquid metals and alloys, including ℓ-Ge [7–9], ℓ-GaxGe1−x [10], stoichiometric III-V ma-

terials such as ℓ-GaAs, ℓ-GaP, and ℓ-InP [11,12], nonstoichiometric ℓ-GaxAs1−x [13], ℓ-CdTe

[14], and ℓ-ZnTe [15], among other materials which are semiconducting in their solid phases.

It has been employed to calculate a wide range of properties of these materials, including

the static structure factor, bond-angle distribution function, single-particle electronic den-

sity of states, d. c. and a. c. electrical conductivity, and ionic self-diﬀusion coeﬃcient. The

calculations generally agree quite well with available experiment.

A similar ab initio approach has also been applied extensively to a variety of amorphous

semiconductors, usually obtained by quenching an equilibrated liquid state from the melt.

For example, Car, Parrinello and their collaborators have used their own ab initio approach

(based on treating the Fourier components of the electronic wave functions as ﬁctitious

classical variables) to obtain many structural and electronic properties of amorphous Si

[16,17]. A similar approach has been used by Lee and Chang [18]. Kresse and Hafner [7]

obtained both S(k) and g(r), as well as many electronic properties, of a-Ge, using an ab

initio approach similar to that used here, in which the forces are obtained directly from the

Hellmann-Feynman theorem and no use is made of ﬁctitious dynamical variables for the

electrons, as in the Car-Parrinello approach. A similar calculation for a-Si has been carried

out by Cooper et al [19], also making use of a plane wave basis and treating the electron

4

density functional in the generalized gradient approximation (GGA) [20]. More recently, a

number of calculations for a-Si and other amorphous semiconductors have been carried out

by Sankey et al [21], and by Drabold and collaborators [22]. These calculations use ab initio

molecular dynamics and electronic density functional theory, but in a localized basis. A

recent study, in which S(k) and g(r) were computed for several ab initio structural models

of a-Si, has been carried out by Alvarez et al [23].

Finally, we mention a third approach,

intermediate between empirical and ab initio

molecular dynamics, and generally known as tight-binding molecular dynamics.

In this

approach, the electronic part of the total energy is described using a general tight-binding

Hamiltonian for the band electrons. The hopping matrix elements depend on separation

between the ions, and additional terms are included to account for the various Coulomb

energies in a consistent way. The parameters can be ﬁtted to ab initio calculations, and

forces on the ions can be derived from the separation-dependence of the hopping matrix

elements. This approach has been used, e. g., to treat ℓ-Si [24], a-Si [25], and liquid

compound semiconductors such as ℓ-GaAs and ℓ-GaSb [26]. Results are in quite good

agreement with experiment.

In this paper, we extend the method of ab initio molecular dynamics to another dy-

namical property of the ions: the dynamical structure factor, denoted S(k, ω). While no

fundamentally new theory is required to calculate S(k, ω), this quantity provides additional

information about the time-dependent ionic response beyond what can be extracted from

other quantities. The present work appears to be the ﬁrst to calculate S(k, ω) using ab initio

molecular dynamics. Here, we will calculate S(k, ω) for ℓ-Ge, where some recent experiments

[27] provide data for comparison, and also for amorphous Ge (a-Ge). In the latter case, us-

ing a series of approximations described below, we are able to infer the vibrational density

of states of as-quenched a-Ge near temperature T = 300K in reasonable agreement with

experiment. The calculated S(k, ω) for the liquid also agrees quite well with experiment,

especially considering the computational uncertainties inherent in an ab initio simulation

with its necessarily small number of atoms and limited time intervals.

5

The remainder of this paper is organized as follows. A brief review of the calculational

method is given in Section II. The results are presented in Section III, followed by a discussion

and a summary of our conclusions in Section IV.

II. METHOD

Our method is similar to that described in several previous papers [9,10,13], but uses

the Vienna Ab Initio Simulation Package (VASP), whose workings have been extensively

described in the literature [28]. Brieﬂy, the calculation involves two parts. First, for a given

ionic conﬁguration, the total electronic energy is calculated, using an approximate form of

the Kohn-Sham free energy density functional, and the force on each ion is also calculated,

using the Hellmann-Feynman theorem. Second, Newton’s equations of motion are integrated

numerically for the ions, using a suitable time step. The process is repeated for as many time

steps as are needed to calculate the desired quantity. To hold the temperature constant, we

use the canonical ensemble with the velocity rescaled at each time step. Further details of

this approach are given in Ref. [9].

The VASP code uses ultrasoft Vanderbilt pseudopotentials [29], a plane wave basis for

the wave functions, with the original Monkhorst-Pack (3

3

×

×

3) k-space meshes [30] and a

total of 21,952 plane waves, corresponding to an energy cut-oﬀ of 104.4eV. We use a ﬁnite-

temperature version of the Kohn-Sham theory [31] in which the electron gas Helmholtz

free energy is calculated on each time step. This version also broadens the one-electron

energy levels to make the k-space sums converge more rapidly. Most of our calculations are

done using the generalized gradient approximation (GGA) [20] for the exchange-correlation

energy (we use the particular form of the GGA developed by Perdew and Wang [20]), but

some are also carried out using the local-density approximation (LDA).

In our iteration of Newton’s Laws in liquid Ge (ℓ-Ge), we typically start from the diamond

structure (at the experimental liquid state density for the temperature of interest), then

iterate for 901 time steps, each of 10 fs, using the LDA. To obtain S(k) within the GGA,

6

we start from the LDA conﬁguration after 601 time steps, then iterate using the GGA for

an additional 1641 10-fs time steps, or 16.41 ps. We calculate the GGA S(k) by averaging

over an interval of 13.41 ps within this 16.41 time interval, starting a time t2 after the start

of the GGA simulation. We average over all t2’s from 1.0 to 3.0 ps.

For comparison, we have also calculated S(k) within the LDA. This S(k) is obtained by

averaging over 601 time steps of the 901 time-step LDA simulation. This 601-step interval

is chosen to start a time t1 after the start of this simulation; the calculated LDA S(k) is also

averaged over all t1’s from 1ps to 3ps.

To calculate quantities for amorphous Ge (a-Ge), we start with Ge in the diamond

structure at T = 1600K and at the experimental density for that temperature, as quoted

in Ref. [9]. Next, we quench this sample to 300 K, cooling at a uniform rate over, so as to

reach 300 K in about 3.25 ps (in 10-fs time steps). Finally, starting from T = 300 K, we

iterate for a further 897 time steps, each of 10 fs, or 8.97 ps, using the LDA. The LDA S(k)

is then obtained by averaging over 5.97 of those 8.97 ps, starting a time t1 after the system

is reached 300K; we also average this S(k) over all t1’s from 1.0 to 3.0 ps. To obtain S(k)

within the GGA, we start the GGA after 5.7 ps of the LDA simulation, and then iterate

using the GGA for an additional 18.11 ps in 10-fs time steps. The GGA S(k) is obtained

by averaging over a 15.11 ps time interval of this 18.11 ps run, starting a time t2 after the

start of the GGA simulation; we also average over all values of t2 from 1.0 to 3.0 ps.

The reader may be concerned that the 3.25 ps quench time is very short, very unrepre-

sentative of a realistic quench, and very likely to produce numerous defects in the quenched

structure, which are not typical of the a-Ge studied in experiments. In defense, we note that

some of these defects may be annealed out in the subsequent relaxation at low temperatures,

which is carried out before the averages are taken. In addition, the static structure factor

we obtain agrees well with experiment, and the dynamic structure factor is also consistent

with experiment, as discussed below. Thus, the quench procedure appears to produce a

material rather similar to some of those studied experimentally. Finally, we note that exper-

iments on a-Ge themselves show some variation, depending on the exact method of sample

7

preparation.

We have used the procedure outlined above to calculate various properties of ℓ-Ge and a-

Ge. Most of these calculated properties have been described in previous papers, using slightly

diﬀerent methods, and therefore will be discussed here only very brieﬂy [32]. However, our

results for the dynamic structure factor S(k, ω) as a function of wave vector k and frequency

ω are new, and will be described in detail. We also present our calculated static structure

factor S(k), which is needed in order to understand the dynamical results.

S(k) is deﬁned by the relation

S(k) =

1
N h

Xi,j

exp[ik

(ri(t)

·

−

rj(t))]

it0 −

Nδk,0,

(1)

where ri is the position of the ith ion at time t, N is the number of ions in the sample, and the

triangular brackets denote an average over the sampling time. In all our calculations, we have

used a cubic cell with N = 64 and periodic boundary conditions in all three directions. This

choice of particle number and cell shape is compatible with any possible diamond-structure

Ge within the computational cell.

S(k, ω) is deﬁned by the relation (for k

= 0, ω

= 0)

S(k, ω) =

1
2πN Z

∞

−∞

exp(iωt)

ρ(k, t)ρ(

k, 0)

−

dt,

i

h

where the Fourier component ρ(k, t) of the number density is deﬁned by

ρ(k, t) =

N

Xi=1

exp(

ik

−

·

ri(t)).

In our calculations, the average

is computed as

...

i

h

ρ(k, t)ρ(

k, 0)

−

=

i

h

∆t1

1
∆t1 Z

0

ρ(k, t1 + t)ρ(

k, t1)dt1

−

(2)

(3)

(4)

over a suitable range of initial times t1. Because of the expected isotropy of the liquid or

amorphous phase, which should hold in the limit of large N, S(k, ω) should be a function

only of the magnitude k rather than the vector k, as should the structure factor S(k).

Our calculations are carried out over relatively short times. To reduce statistical errors,

we therefore ﬁrst calculate

8

6
6
S(k, ω, t1, t2) =

t2

1
πN Z

t1

dtρ(k, t1 + t)ρ(

k, t1) exp(iωt).

−

(5)

For large enough t2, S(k, ω, t1, t2) should become independent of t2 but will still retain some

dependence on t1. Therefore, in the liquid, we obtain our calculated dynamic structure

factor, Scalc(k, ω), by averaging over a suitable range of t1 from 0 to ∆t1:

Scalc(k, ω) =

∆t1

1
∆t1 Z

0

dt1S(k, ω, t1, t2).

(6)

We choose our initial time in the t1 integral to be 1 ps after the start of the GGA calculation,

and (in the liquid) ∆t1 = 7 ps. We choose the ﬁnal MD time t2 = 16.41ps. For a-Ge, we

use the same procedure but t2 = 18.11ps in our simulations. For our ﬁnite simulational

sample, the calculated S(k) and S(k, ω) will, in fact, depend on the direction as well as

the magnitude of k. To suppress this ﬁnite-size eﬀect, we average the calculated S(k) and

S(k, ω) over all k values of the same length. This averaging considerably reduces statistical

error in both S(k, ω) and S(k).

Finally, we have also incorporated the experimental resolution functions into our plotted

values of S(k, ω). Speciﬁcally, we generally plot Sav(k, ω)/S(k), where Sav(k, ω) is obtained

from the (already orientationally averaged) S(k, ω) using the formula

Sav(k, ω) =

∞

−∞

Z

R(ω

−

ω′)S(k, ω′)dω′,

where the resolution function R(ω) (normalized so that

∞
−∞ R(ω)dω = 1) is
R
ω2/ω2
0).

R(ω) =

1
√πω0

exp(

−

(7)

(8)

In an isotropic liquid, we must have S(k,

ω) = S(k, ω), since our ions are assumed

−

to move classically under the calculated ﬁrst-principles force. Our orientational averaging

procedure guarantees that this will be satisﬁed identically in our calculations, since for every

k, we always include

k in the same average. We will nonetheless show results for negative

−

ω for clarity, but they do not provide any additional information.

9

III. RESULTS

A. S(k) for ℓ-Ge and a-Ge

In Fig. 1, we show the calculated S(k) for ℓ-Ge at T = 1250 K, as obtained using

the procedure described in Section II. The two calculated curves are obtained using the

GGA and the LDA for the electronic energy-density functional; they lead to nearly identical

results. The calculated S(k) shows the well-known characteristics already found in previous

simulations [7,9]. Most notably, there is a shoulder on the high-k side of the principal peak,

which is believed to arise from residual short-range tetrahedral order persisting into the

liquid phase just above melting. We also show the experimental results of Waseda et al

[33]; agreement between simulation and experiment is good, and in particular the shoulder

seen in experiment is also present in both calculated curves (as observed also in previous

simulations).

We have also calculated S(k) for a model of amorphous Ge (a-Ge) at 300K. Our sample of

a-Ge is prepared as follows. First, we create an equilibrated sample of ℓ-Ge at a temperature

of 1600K and the experimental density corresponding to that temperature (as quoted in

Ref. [9]). Next, we quench this sample of ℓ-Ge to 300K, by cooling at a uniform rate over

a time interval of about 3.25ps. Finally, starting from T = 300K, we evaluate the structure

factor by averaging over 800 time steps of 10 fs each, or 8 ps, after ﬁrst discarding 100 time

steps at T = 300K. We also average S(k) over diﬀerent k vectors of the same length, as for

ℓ-Ge. We use the measured number density of 0.04370˚A−3 for a-Ge at T = 300K [34].

In Fig. 2, we show the calculated S(k) for a-Ge at T = 300, again using both the GGA

and the LDA. The sample is prepared and the averages obtained as described in Section II.

In contrast to ℓ-Ge, but consistent with previous simulations [7,23], the principal peak in

S(k) is strikingly split. The calculations are in excellent agreement with experiments carried

out on as-quenched a-Ge at T = 300 K [34]; in particular, the split principal peak seen in

experiment is accurately reproduced by the simulations.

10

We have also calculated a number of other quantities for both ℓ-Ge and a-Ge, including

pair distribution function g(r), and the electronic density of states n(E).

For ℓ-Ge, we calculated n(E) using the Monkhorst-Pack mesh with gamma point shifting

(one of the meshes recommended in the VASP package). The resulting n(E) is generally

similar to that found in previous calculations [7,9], provided that an average is taken over

at least 5-10 liquid state conﬁgurations. Our n(E) for a-Ge [calculated using a shorter

averaging time than that used below for S(k, ω)] is also similar to that found previously [7].

Our calculated g(r)’s for both ℓ-Ge and a-Ge, as given by the VASP program, are similar

to those found in Refs. [7] and [9]. The calculated number of nearest neighbors in the ﬁrst

shell is 4.18 for a-Ge measured to the ﬁrst minimum after the principal peak in g(r). For

ℓ-Ge, if we count as “nearest neighbors” all those atoms within 3.4˚Aof the central atom (one

of the cutoﬀs used in Ref. [7]) we ﬁnd approximately 6.1 nearest neighbors, very close to

the value of 5.9 obtained in Ref. [7] for that cutoﬀ. Finally, we have recalculated the self-

diﬀusion coeﬃcient D(T ) for ℓ-Ge at T = 1250 K, from the time derivative of the calculated

mean-square ionic displacement; we obtain a result very close to that of Ref. [9].

B. S(k, ω) for ℓ-Ge and a-Ge

1. ℓ-Ge

Fig. 3 shows the calculated ratio S(k, ω)/S(k) for ℓ-Ge at T = 1250 K, as obtained using

the averaging procedure described in Section II. We include a resolution function [eqs. (7)

and (8)] of width ¯hω = 2.5 meV, the same as the quoted experimental width [27]. In Fig. 4,

we show the same ratio, but without the resolution function (i. e., with ω0 = 0). Obviously,

there is much more statistical noise in this latter case, though the overall features can still

be distinguished.

To interpret these results, we ﬁrst compare the calculated S(k, ω) in ℓ-Ge with hydro-

dynamic predictions, which should be appropriate at small k and ω. The This prediction

11

takes the form (see, for example, Ref. [35]):
2DT k2
ω2 + (DT k2)2
Γk2
(ω + csk)2 + (Γk2)2 +

S(k, ω)
S(k)

1
−
γ  

1
γ  

2π

=

+

+

!

γ

Γk2

csk)2 + (Γk2)2

!

(ω

−

.

(9)

Here γ = cP /cV is the ratio of speciﬁc heats and constant pressure and constant volume, DT

is the thermal diﬀusivity, cs is the adiabatic sound velocity, and Γ is the sound attenuation

constant. DT and Γ can in turn be expressed in terms of other quantities. For example,

DT = κT /(ρcP ), where κT is the thermal conductivity and ρ is the atomic number density.
Similarly, Γ = 1

1)/γ + b], where a = κT /(ρcV ) and b is the kinematic longitudinal

2 [a(γ

−

viscosity (see, for example, Ref. [35], pp. 264-66).

Eq. (9) indicates that S(k, ω) in the hydrodynamic regime should have two propagating

peaks centered at ω =

csk, and a diﬀusive peak centered at ω = 0 and of width determined

±

by DT . The calculated S(k, ω)/S(k) for the three smallest values of k in Fig. 3, does show the

propagating peaks. We estimate peak values of ¯hω

10 meV for k = 5.60 nm−1, ¯hω

11

∼

∼

meV for k = 7.92 nm−1, and (somewhat less clearly) ¯hω

13 meV for k = 9.70 nm−1. The

∼
105 cm/sec. (The largest of these

value of cs estimated from the lowest k value is cs ∼
three k values may already be outside the hydrodynamic, linear-dispersion regime.)

2.7

×

These predictions agree reasonably well with the measured S(k, ω) obtained by Hosokawa

et al [27], using inelastic X-ray scattering. For example, the measured sound-wave peaks

for k =

6 nm−1 occur near 10 meV, while those k =

±

12 nm−1 occur at ¯hω = 17.2 meV,

±

Furthermore, the integrated relative strength of our calculated sound-wave peaks, compared

to that of the central diﬀusion peak, decreases between k = 7.92 nm−1 and 12.5 nm−1,

consistent with both eq. (9) and the change in experimental behavior [27] between k = 6

nm−1 and 12 nm−1.

Because S(k, ω) in Fig. 3 already includes a signiﬁcant Gaussian smoothing function, a

quantitatively accurate half-width for the central peak, and hence a reliable predicted value

for DT , cannot be extracted. A rough estimate can be made as follows. For the smallest k

value of 5.6 nm−1, the full width of the central peak at half-maximum is around 7.5 meV. If

12

the only broadening were due to this Gaussian smoothing, the full width would be around

2¯hω0 = 5.5 meV. Thus, a rough estimate of the intrinsic full width is

√7.52

−

≈

5.52 = 5

meV

≈

2¯hDT k2. This estimate seems reasonable from the raw data for S(k, ω) shown in

Fig. 4. Using this estimate, one obtains DT ≈

1.3

×

10−3 cm2/sec.

The hydrodynamic expression for S(k, ω)/S(k) was originally obtained without consid-

eration of the electronic degrees of freedom. Since ℓ-Ge is a reasonably good metal, one

might ask if the various coeﬃcients appearing eq. (9) should be the full coeﬃcients, or just

the ionic contribution to those coeﬃcients. For example, should the value of DT which de-

termines the central peak width be obtained from the full cP , cV , and κT , or from only the

ionic contributions to these quantities? For ℓ-Ge, the question is most relevant for κT , since

the dominant contribution to cP and cV should be the ionic parts, even in a liquid metal [4].

However, the principal contribution to κT is expected to be the electronic contribution.

We have made an order-of-magnitude estimate of DT using the experimental liquid num-

ber density and the value CP = (5/3)kB per ion, and obtaining the electronic contribution

to κT from the Wiedemann-Franz law [36] together with previously calculated estimates of

the electronic contribution [9]. This procedure yields DT ∼
of magnitude greater than that extracted from Fig. 3, and well outside the possible errors

0.1 cm2/sec, about two orders

in that estimate. We conclude that the DT which should be used in eq. (9) for ℓ-Ge (and

by inference other liquid metals) is the ionic contribution only.

In support of this interpretation, we consider what one expects for S(k, ω) in a simple

metal such as Na. In such a metal, ionic motions are quite accurately determined by eﬀective

pairwise screened ion-ion interactions [4]. Since the ionic motion is determined by such an

interaction, the S(k, ω) resulting from that motion should not involve the contribution of

the electron gas to the thermal conductivity. Although ℓ-Ge is not a simple metal, it seems

plausible that its S(k, ω) should be governed by similar eﬀects, at least in the hydrodynamic

regime. This plausibility argument is supported by our numerical results.

For k beyond around 12 nm−1, the hydrodynamic model should start to break down,

since the dimensionless parameter ωτ (where τ is the Maxwell viscoelastic relaxation time)

13

becomes comparable to unity. At these larger k’s, both our calculated and the measured [27]

curves of S(k, ω)/S(k) continue to exhibit similarities. Most notable is the existence of a

single, rather narrow peak for k near the principal peak of S(k), followed by a reduction in

height and broadening of this central peak as k is further increased. This narrowing was ﬁrst

predicted by de Gennes [37]. In our calculations, it shows up in the plot for k = 20.9 nm−1,

for which the half width of S(k, ω)/S(k) is quite narrow, while at k = 28.5 and 30.7 nm−1,

the corresponding plots are somewhat broader and lower. By comparison, the measured

central peak in S(k, ω)/S(k) is narrow at k = 20 nm−1 and especially at k = 24 nm−1, while

it is broader and lower at k = 28 nm−1 [27].

The likely physics behind the de Gennes narrowing is straightforward. The half-width of

S(k, ω) is inversely proportional to the lifetime of a density ﬂuctuation of wave number k.

If that k coincides with the principal peak in the structure factor, a density ﬂuctuation will

be in phase with the natural wavelength of the liquid structure, and should decay slowly,

in comparison to density ﬂuctuations at other wavelengths. This is indeed the behavior

observed both in our simulations and in experiment.

In further support of this picture, we may attempt to describe these ﬂuctuations by a

very oversimpliﬁed Langevin model. We suppose that the Fourier component ρ(k, t) [eq.

(3)] is governed by a Langevin equation

˙ρ(k, t) =

ξρ(k, t) + η(t).

−

(10)

Here the dot is a time derivative, ξ is a constant, and η(t) is a random time-dependent “force”

which has ensemble average

η

h

i

= 0 and correlation function

η(t)η∗(t′)

h

= Aδ(t

i

−

t′). Eq.

(10) can be solved by standard methods (see, e. g., Ref. [35] for a related example), with

the result (for suﬃciently large t)

ρ(k, t)ρ∗(k, t + τ )

h

πA
ξ

=

i

exp(

ξ).

τ

|

−|

(11)

According to eq. (2), S(k, ω) is, to within a constant factor, the frequency Fourier transform

of this expression, i. e.

14

S(k, ω)

∞

∝ Z

−∞

(πA/ξ) exp(iωτ ) exp(

ξ)dτ,

τ

|

−|

or, on carrying out the integral,

S(k, ω)

πA
ω2 + ξ2 .

∝

(12)

(13)

This is a Gaussian function centered at ω = 0 and of half-width ξ. On the other hand, the

static structure factor

S(k)

∝

Limτ →0

h

ρ(k, t)ρ∗(k, t + τ )

πA
ξ

.

=

i

(14)

Thus, if the constant A is independent of k, the half-width ξ of the function S(k, ω) at wave

number k is inversely proportional to the static structure S(k). This prediction is consistent

with the “de Gennes narrowing” seen in our simulations and in experiment [27].

To summarize, there is overall a striking similarity in the shapes of the experimental and

calculated curves for S(k, ω)/S(k) both in the hydrodynamic regime and at larger values of

k.

2. a-Ge

We have also calculated the dynamic structure for our sample of a-Ge at T = 300K.

The results for the ratio S(k, ω)/S(k) are shown in Figs. 5 and 6 for a range of k values,

and, over a broader range of ω, in Fig. 7. Once again, both S(k, ω) and S(k) are averaged

over diﬀerent values of k of the same length, as described above. We have incorporated a

resolution function of width ¯hω0 = 2 meV into S(k, ω). This width is a rough estimate for

the experimental resolution function in the measurements of Maley et al [38]; we assume

it to be smaller than the liquid case because the measured width of the central peak in

S(k, ω)/S(k) for a-Ge is quite small.

Ideally, our calculated S(k, ω) should be compared to the measured one. However, the

published measured quantity is not S(k, ω) but is, instead, based on a modiﬁed dynamical

structure factor, denoted G(k, ω), and related to S(k, ω) by [38]

15

G(k, ω) =

C
k2

(cid:18)

(cid:19)  

¯hω
n(ω, T ) + 1 !

S(k, ω).

Here C is a k- and ω-independent constant, and n(ω, T ) = 1/[e¯hω/kB T

(15)

1] is the phonon

−

occupation number for phonons of energy E = ¯hω at temperature T . The quantity plotted

by Maley et al [38] is an average of G(k, ω) over a range of k values from 40 to 70 nm−1.

These workers assume that this average is proportional to the vibrational density of states

nvib(ω). The measured nvib(ω) as obtained in this way [38] is shown in Fig. 8 for two

diﬀerent amorphous structures, corresponding to two diﬀerent methods of preparation and

having diﬀering degrees of disorder.

In order to compare our calculated S(k, ω) to experiment, we use eq. (15) to infer G(k, ω),

then average over a suitable range of k. However, in using eq. (15), we use the classical form

of the occupation factor, n(¯hω) + 1

≈

kBT /¯hω, This choice is justiﬁed because we have

calculated S(k, ω) using classical equations of motion for the ions. We thus obtain for the

calculated vibrational density of states

nvib(ω)

2
C¯h
kBT !  

ω2
k2

!

≈  

S(k, ω).

(16)

In Fig. 8 we show two such calculated plots of nvib(ω), as obtained by averaging eq. (16)

over two separate groups of k’s, as indicated in the caption [39]. For comparison, we also

show nvib(ω) for a-Ge as calculated in Ref. [7] directly from the Fourier transform of the

velocity-velocity autocorrelation function.

The calculated plots for nvib(ω) in Fig. 8 have some distinct structure, which arises from

some corresponding high frequency structure in S(k, ω). The plot of nvib(ω) for the group

of smaller k’s has two distinct peaks, near 8 meV and 29 meV, separated by a broad dip

with a minimum near 18 meV. The plot corresponding to the group of larger k’s has similar

structure and width, but the dip is less pronounced. The two experimental plots also have

two peaks separated by a clear dip. The two maxima are found around 10 and 35 meV, while

the principal dip occurs near 16 meV. In addition, the overall width of the two densities of

states is quite similar.

16

The reasonable agreement between the calculated and measured nvib(ω) suggests that our

ab initio calculation of S(k, ω) for a-Ge is reasonably accurate. The noticeable diﬀerences

probably arise from several factors. First, there are several approximations involved in going

from the calculated and measured S(k, ω)’s to the corresponding nvib(ω)’s, and these may

be responsible for some of the discrepancies. Secondly, there may actually be diﬀerences

between the particular amorphous structures studied in the experiments, and the quenched,

then relaxed structure considered in the present calculations.

(However, the similarities

in the static structure factors suggest that these diﬀerences are not vast.) Finally, our

calculations are carried out over relatively short times, using relatively few atoms; thus,

ﬁnite-size and ﬁnite-time eﬀects are likely to produce some additional errors. Considering

all these factors, agreement between calculation and experiment is quite reasonable.

Previous ab initio calculations for a-Ge [7] have also obtained a vibrational density of

states, but this is computed directly from the ionic velocity-velocity autocorrelation function

rather than from the procedure described here. The calculations in Ref. [7] do not require

computing S(k, ω). In the present work, by contrast, we start from S(k, ω) (which is calcu-

lated here for the ﬁrst time in an ab initio calculation for a-Ge), and we work backwards to

get nvib(ω). In principle, our S(k, ω) includes all anharmonic eﬀects on the vibrational spec-

trum of a-Ge, though in extracting nvib(ω) we assume that the lattice vibrates harmonically

about the metastable atomic positions. In Fig. 8, we also show the results of Ref. [7] for

nvib(ω) as obtained from this correlation function. They are quite similar to those obtained

in the present work, but have a somewhat deeper minimum between the two principal peaks.

The quantity nvib(ω) could, of course, also be calculated directly from the force constant

matrix, obtained by assuming that the quenched conﬁguration is a local energy minimum

and calculating the potential energy for small positional deviations from that minimum using

ab initio molecular dynamics. This procedure has been followed for a-GeSe2, for example, by

Cappelletti et al [40]. These workers have then obtained S(q, ω) versus q from their nvib(ω)

at selected values of ω, within a one-phonon approximation. However, as noted above, the

present work produces the full S(k, ω) and thus has, in principle, more information than

17

nvib(ω).

IV. DISCUSSION AND CONCLUSIONS

The present results show that ab initio molecular dynamics can be used to calculate the

dynamic structure factor S(k, ω) for both liquid and amorphous semiconductors. Although

the accuracy of the calculated S(k, ω) is lower than that attained for static quantities, such

as S(k), nonetheless it is suﬃcient for comparison to most experimental features. This is

true even though our calculations are limited to 64-atom samples and fewer than 20 ps of

elapsed real time.

We have presented evidence that the calculated S(k, ω)/S(k) in ℓ-Ge agrees qualitatively

with measured by inelastic X-ray scattering [27], and that the one calculated for a-Ge leads

to a vibrational density of states qualitatively similar to the quoted experimental one [38].

Since such calculations are thus shown to be feasible, our work should spur further numer-

ical studies, with longer runs on larger samples, to obtain even more detailed information.

Furthermore, we can use these dynamical simulations to probe the underlying processes at

the atomic scale which give rise to speciﬁc features in the measured and calculated S(k, ω).

V. ACKNOWLEDGEMENTS

This work has been supported by NASA, Division of Microgravity Sciences, through grant

NCC8-152, and by NSF grants DMR01-04987 (DS) and CHE 01-11104 (JDC). Calculations

were carried out using the Beowulf Cluster at the Ohio Supercomputer Center, with the

help of a grant of time. We are very grateful to Prof. David H. Matthiesen for his continual

support and encouragement through the course of this work, and to Sergey Barabash for

many valuable conversations. Jeng-Da Chai wishes to thank Lan Bi for her endless support.

18

REFERENCES

[1] V. M. Glazov, S. N. Chizhevskaya, and N. N. Glagoleva, Liquid Semiconductors

(Plenum, New York, 1969).

[2] W. B. Yu, Z. Q. Wang, and D. Stroud, Phys. Rev. B54, 13946 (1996).

[3] F. H. Stillinger and Weber, Phys. Rev. B31, 5262 (1985).

[4] For a review, see, e. g., N. W. Ashcroft and D. Stroud, Solid State Physics 33, pp. 1ﬀ

(1978).

[5] W. Kohn and L. J. Sham, Phys. Rev. 140, A1133 (1965).

[6] R. Car and M. Parrinello, Phys. Rev. Lett. 35, 2471 (1985).

[7] G. Kresse and J. Hafner, Phys. Rev. B49, 14251 (1994).

[8] N. Takeuchi and I. L. Garz´on, Phys. Rev. B50, 8342 (1995).

[9] R. V. Kulkarni, W. G. Aulbur, and D. Stroud, Phys. Rev. B55, 6896 (1997).

[10] R. V. Kulkarni and D. Stroud, Phys. Rev. B57, 10476 (1998).

[11] Q. Zhang, G. Chiarotti, A. Selloni, R. Car, and M. Parrinello, Phys. Rev. B42, 5071.

[12] L. Lewis, A. De Vita, and R. Car, Phys. Rev. B57, 1594 (1998).

[13] R. V. Kulkarni and D. Stroud, Phys. Rev. B62, 4991 (2000).

[14] V. Godlevsky, J. Derby, and J. Chelikowsky, Phys. Rev. Lett. 81, 4959 (1998); V.

Godlevsky, M. Jain, J. Derby, and J. Chelikowsky, Phys. Rev. B60, 8640 (1999);

[15] M. Jain, V. V. Godlevsky, J. J. Derby, and J. R. Chelikowsky, Phys. Rev. B65, 035212

(2001).

[16] R. Car and M. Parrinello, Phys. Rev. Lett. 63, 204 (1988)

[17] I Stich, R. Car, and M. Parrinello, Phys. Rev. Lett. 63, 2240 (1989); Phys. Rev. B44,

19

4261 (1991); Phys. Rev. B44, 11092 (1991).

[18] I. Lee and K. J. Chang, Phys. Rev. B50, 18083 (1994).

[19] N. C. Cooper, C. M. Goringe, and D. R. McKenzie, Comput. Mater. Sci. 17, 1 (2000)

[20] See, e. g., J. P. Perdew, in Electronic Structure of Solids, edited by P. Ziesche and H.

Eschrig (Akademic Verlag, Berlin, 1991).

[21] O. Sankey and D. J. Niklewsky, Phys. Rev. B40, 3979 (1989)

[22] D. A. Drabold, P. A. Fedders, O. F. Sankey, and J. D. Dow, Phys. Rev. B42, 5135

(1990)

[23] F. Alvarez, C. C. D´iaz, A. A. Valladares, and R. M. Valladares, Phys. Rev. B65, 113108

(2002).

[24] C. Z. Wang, C. T. Chan, and K. M. Ho, Phys. Rev. B45, 12227 (1992); I. Kwon, R.

Biswas, C. Z. Wang, K. M. Ho, and C. M. Soukoulis, Phys. Rev. B49, 7242 (1994).

[25] G. Servalli and L. Colombo, Europhys. Lett. 22, 107 (1993).

[26] C. Molteni, L. Colombo, and Miglio, J. Phys.: Cond. Matt. 6, 5255 (1994).

[27] S. Hosokawa, Y. Kawakita, W.-C. Pilgrim, and H. Sinn, Phys. Rev. B63, 134205 (2001).

[28] G. Kresse and J. Hafner, Phys. Rev. B47, 558 (1993); G. Kresse, Thesis, Technische

Universit¨at Wien (1993); G. Kresse and J. Furthm¨uller, Comput. Mat. Sci. 6, pp. 15-50

(1996); G. Kresse and J. Furthm¨uller, Phys. Rev. B54, 11169 (1996).

[29] D. Vanderbilt, Phys. Rev. B32, 8412 (1985).

[30] H. J. Monkhorst and J. D. Pack, Phys. Rev. B13, 5188 (1976).

[31] N. D. Mermin, Phys. Rev. 137, A1141 (1965).

[32] Our method is very similar to that used in Ref. [7] to treat ℓ-Ge and a-Ge, but with

20

the following diﬀerences: (i) we use both the GGA and the LDA, while Ref. [7] uses

only the LDA; (ii) we include slightly more bands (161 as compared to 138); and (iii)

most of our calculations are carried out using a 10 fs time step, rather than the 3 fs

step used in Ref. [7]. Our a-Ge structure may also diﬀer slightly from that of Ref. [7],

since we use a somewhat faster quench rate (

3

×

∼

1014 K/sec rather than 1.7

1014

×

K/sec). Both codes use the conjugate gradient method to ﬁnd energy minima and the

same Vanderbilt ultrasoft pseudopotentials.

[33] Y. Waseda, The Structure of Noncrystalline Materials: Liquids and Amorphous Solids

(McGraw-Hill, 1980).

[34] G. Etherington, A. C. Wright, J. T. Wenzel, J. T. Dore, J. H. Clarke, and R. N. Sinclair,

J. Non-Cryst. Solids 48, 265 (1982).

[35] See, for example, J.-P. Hansen and I. R. McDonald, Theory of Simple Liquids, 2nd

edition (Academic Press, London, 1986), pp. 222-228.

[36] See, for example, N. W. Ashcroft and N. D. Mermin, Solid State Physics (Harcourt-

Brace, Fort Worth, 1976), ch. 2.

[37] P. G. de Gennes, Physics 25, 825 (1959); Physics 3, 37 (1967).

[38] N. Maley, J. S. Lannin, and D. L. Price, Phys. Rev. Lett. 56, 1720 (1986).

[39] Two recent groups [V. Mart´in-Mayor, M. M´ezard, G. Parisi, and P. Verrocchio, J.

Chem. Phys. 114, 8068 (2001), and T. S. Grigera, V. Mart´in-Mayor, G. Parisi, and P.

Verrocchio, Phys. Rev. Lett. 87, 085502 (2001)] have derived approximate expressions

connecting S(k, ω) to nvib(ω) in an amorphous solid, which closely resemble eq. (16).

In fact, their expressions can be shown to become equivalent to eq. (16) at suﬃciently

large k.

[40] R. L. Cappelletti, M. Cobb, D. A. Drabold, and W. A. Kamitakahara, Phys. Rev. B52,

9133 (1995).

21

Figure Captions

1. Static structure factor S(k) for ℓ-Ge at T = 1250K, just above the experimental

melting temperature. Full curve: present work, as calculated using the generalized

gradient approximation (GGA; see text). Dashed curve: present work, but using

the local density approximation (LDA; see text). Open circles: measured S(k) near

T = 1250 K, as given in Ref. [33].

2. Full curve: Calculated S(k) for a-Ge at T = 300K, as obtained using the GGA.

Structure is prepared as described in the text. Open circles: measured S(k) for a-Ge

at T = 300K, as given in Ref. [34].

3. Calculated ratio of dynamic structure factor S(k, ω) to static structure factor S(k) for

ℓ-Ge at T = 1250K for several values of k, plotted as a function of ω, calculated using

ab initio molecular dynamics with a MD time step of 10 fs. For clarity, each curve

has been vertically displaced by 0.05 units from the curve below. In each case, the

plotted curve is obtained by averaging both the calculated S(k, ω) and the calculated

S(k) over all values of k of the same length. We also incorporate a Gaussian resolution

function of half-width ¯hω0 = 2.5 meV, as in eqs. (7) and (8). This value of ω0 is chosen

to equal the quoted experimental resolution [27].

4. Same as in Fig. 3, but without the resolution function.

5. Calculated S(k, ω)/S(k) for a-Ge at T = 300 K at k

35 nn−1, plotted as a function

≤

of ω Again, each curve has been vertically displaced by appropriate amounts from

the one below it, as evident from the Figure, and both S(k, ω) and S(k) have been

plotted after an average over all k’s of the same length. We also incorporate a Gaussian

resolution function of half-width ¯hω0 = 2 meV. This value is chosen to give the best

results for nvib(ω) as measured by Ref. [38]. The time step here is 10 fs.

6. Same as Fig. 5, but at k

35 nm−1.

≥

22

7. Calculated S(k, ω)/S(k) as in Figs. 5 and 6 but including higher frequencies ω. The

vertical displacements are the same as in Figs. 5 and 6. At ¯hω = 60 meV, the curves

are arranged vertically in order of increasing frequency.

8. Full curve: calculated vibrational density of states nvib(ω), in units of 10−3 states/meV.

nvib(ω) is obtained from the resolution-broadened S(k, ω) and S(k) of the previous

Figure, using the formula nvib(ω) =

Gcalc(k, ω)

i

h

, where Gcalc(k, ω) is given by eq.

(16), and the averaging is carried out over the three magnitudes of k near 40 nm−1 for

which we have computed S(k, ω). Dashed curve: same as full curve, but calculated

by averaging over the six magnitudes of k near 90 nm−1 for which we have computed

S(k, ω). The open circles and open stars denote the measured nvib(ω), as reported in

Ref. [38] for two forms of a-Ge. Finally, the open diamonds denote nvib(ω) as calculated

in Ref. [7] from the ionic velocity-velocity autocorrelation function (dot-dashed curves).

In all plots except that of Ref. [7], nvib(ω) is normalized so that

ωmax
0

n(ω)d(¯hω) = 1.

ωmax is the frequency at which nvib(ω)

→

R
0, and is estimated from this Figure by

extrapolating the right hand parts of the solid and dashed curves linearly to zero.

23

1.6

1.4

1.2

1

)
k
(
S

0.8

0.6

0.4

0.2

0

0

FIGURES

GGA
LDA
Expt.

1

2

3

4

5
k (10 nm−1)

6

7

8

9

10

FIG. 1.

24

GGA
LDA
Expt.

2.5

2

1.5

1

0.5

)
k
(
S

0

0

1

2

3

4

5
k (10 nm−1)

6

7

8

9

10

FIG. 2.

25

)
k
(
S
/
)

,

ω
k
(
S

0.5

0.45

0.4

0.35

0.3

0.25

0.2

0.15

0.1

0.05

0

30.7 nm−1

28.5

25.7

20.9

12.5

11.2

9.70

7.92

5.60

−30

−20

−10

0
ω (meV) 

10

20

30

FIG. 3.

26

)
k
(
S
/
)

,

ω
k
(
S

0.9

0.8

0.7

0.6

0.5

0.4

0.3

0.2

0.1

0

30.7 nm−1

28.5

25.7

20.9

12.5

11.2

9.70

7.92

5.60

−30

−20

−10

0
ω (meV) 

10

20

30

FIG. 4.

27

)
k
(
S
/
)

,

ω
k
(
S

2

1.5

1

0.5

0
−30

−20

−10

34.1 nm−1

30.3

28.2

25.4

20.7

12.4

11.1

9.58

7.82

5.53

10

20

30

0
ω (meV) 

FIG. 5.

28

)
k
(
S
/
)

,

ω
k
(
S

1.8

1.6

1.4

1.2

1

0.8

0.6

0.4

0.2

0
−30

−20

−10

93.4 nm−1

90.9

90.2

87.7

86.6

84.6

48.6

43.2

39.1

0
ω (meV) 

10

20

30

FIG. 6.

29

)
k
(
S
/
)

,

ω
k
(
S

0.035

0.03

0.025

0.02

0.015

0.01

0.005

0

39.1 nm−1
43.2
48.6
84.6
86.6
87.7
90.2
90.9
93.4

5

10

15

20

25

30
ω (meV) 

35

40

45

50

55

60

FIG. 7.

30

55

50

45

40

35

30

25

3k near 40 nm−1
6k near 90 nm−1
Expt. (disordered)
Expt. (ordered)
Ab Initio (Kresse)

)

1
−
V
e
m

3
−

0
1
(

)

ω

(

b
i
v

n

20

15

10

5

0

0

5

10

15

20

25
ω (meV) 

30

35

40

45

50

FIG. 8.

31"
"Electrosorption of Br and Cl on Ag(100): Experiments and Computer
  Simulations","  We present chronocoulometry experiments and equilibrium Monte Carlo
simulations for the electrosorption of Br and Cl on Ag(100) single-crystal
electrode surfaces. Two different methods are used to calculate the long-range
part of the adsorbate-adsorbate interactions. The first method is a
truncated-sum approach, while the second is a mean-field-enhanced truncated-sum
approach. To compare the two methods, the resulting isotherms are fit to
experimental adsorption isotherms, assuming both a constant electrosorption
valency &gamma and also a coverage-dependent &gamma. While a constant &gamma
fits the Br/Ag(100) well, a coverage-dependent or potential-dependent &gamma is
needed for Cl/Ag(100).
",http://arxiv.org/pdf/cond-mat/0211169v2,3,"2
0
0
2
c
e
D
6
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
9
6
1
1
1
2
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Electrosorption of Br and Cl on Ag(100):

Experiments and Computer Simulations∗

I. Abou Hamad1,2, Th. Wandlowski3, G. Brown2,4, and P.A. Rikvold1,2,5

1Center for Materials Research and Technology and Department of Physics, Florida State University, Tallahassee, FL 32306-4350, USA

2School of Computational Science and Information Technology, Florida State University, Tallahassee, Florida 32306-4120, USA

3Institute for Thin Films and Interfaces, ISG 3, J¨ulich GmbH, D-52425 J¨ulich, Germany

4Center for Computational Sciences, Oak Ridge National Laboratory, Oak Ridge, TN 37831, USA

5Center for Stochastic Processes in Science and Engineering, Department of Physics,

Virginia Polytechnic Institute and State University, Blacksburg, VA 24061-0435, USA

October 29, 2018

Abstract

We present chronocoulometry experiments and equilibrium Monte Carlo simula-

tions for the electrosorption of Br and Cl on Ag(100) single-crystal electrode surfaces.

Two diﬀerent methods are used to calculate the long-range part of the adsorbate-

adsorbate interactions. The ﬁrst method is a truncated-sum approach, while the second

∗We dedicate this paper to the memory of Michael J. Weaver. Mike’s breadth, depth, and productivity,

as well as his engaging personality made him an outstanding member of our community. We will miss him

deeply.

1

 
 
 
 
 
 
is a mean-ﬁeld-enhanced truncated-sum approach. To compare the two methods, the

resulting isotherms are ﬁt to experimental adsorption isotherms, assuming both a

constant electrosorption valency γ and also a coverage-dependent γ. While a constant

γ ﬁts the Br/Ag(100) well, a coverage-dependent or potential-dependent γ is needed

for Cl/Ag(100).

Keywords: Bromine electrosorption; Chlorine electrosorption; Continuous phase transition;

Chronocoulometry; Lattice-gas model; Monte Carlo simulation.

1

Introduction

Speciﬁcally adsorbed anions strongly inﬂuence the structure and dynamics of adsorbed layers

on electrode surfaces [1, 2]. Among these systems, halides electrosorbed on single-crystal

metal surfaces have been extensively studied both experimentally and theoretically over

the last decade. Examples of these studies include the electrosorption of Cl, Br, I, and

F on low-index surfaces of Ag [3, 4, 5] employing classical electrochemical techniques [3,

5, 6, 7], (see also literature cited in ref. [5]), and structure sensitive techniques such as

electroreﬂectance [8], in-situ scanning tunneling microscopy (STM) [9, 10], surface X-ray

scattering (SXS) [4, 5, 11], and X-ray absorption ﬁne structure (XAFS) [12].

Ocko, Wang, and Wandlowski

[4] showed that the sharp peak observed in cyclic

voltamograms of Br electrosorption on Ag(100) corresponds to a continuous phase transition

in the layer of adsorbed Br. This transition separates a low-coverage disordered phase at

more negative electrode potentials from a c(2

2) ordered phase at more positive potentials.

×

Moreover,

in recent static and dynamic studies, Mitchell, Brown, and Rikvold [13, 14]

have numerically investigated the phase ordering and disordering mechanisms in cyclic-

voltammetry (CV) and sudden potential-step experiments. Using Monte Carlo simulations

2

of a lattice-gas model ﬁrst used by Koper [15, 16], they also produced theoretical adsorption

isotherms for this system that were ﬁt to experimental adsorption isotherms. From these ﬁts,

parameters such as the electrosorption valency, γ, and the next-nearest neighbor interaction

parameter, φnnn, were estimated.

Less attention has been given to Cl electrosorption on Ag(100), perhaps because previous

studies [3] have assumed that this system is similar to Br/Ag(100). In the present paper we

compare Monte Carlo simulation results with experimental equilibrium isotherms obtained

by chronocoulometry for both Cl and Br, using a lattice-gas model and two diﬀerent methods

for calculating the long-range part of the conﬁguration energies.

The remainder of this paper is organized as follows. The experimental procedures and

results are discussed in Sec. 2. The lattice-gas model is presented in Sec. 3. Equilibrium

simulations using the two diﬀerent methods of calculation are discussed in Sec. 4, and the

ﬁtting procedures and resulting parameter estimates for each system are discussed in Sec. 5.

Finally, a summary and conclusions are presented in Sec. 6.

2 Experimental

The electrochemical measurements were performed with Ag(100) single-crystal electrodes

(4 mm diameter and 4 mm thickness) using the so-called hanging meniscus technique. The

silver electrodes were chemically etched in cyanide solution before each experiment until

the surface appeared shiny [17] and, after careful rinsing in Milli-Q water, annealed in a

hydrogen ﬂame for about 30 s. After cooling in a stream of argon the electrode was quickly

transferred into the electrochemical cell. Contact with the electrolyte was established under

strict potential control, usually at values close to the potential of zero charge of 0.05 M

KClO4 (Epzc ≈ −

0.900 V) [18]. The counter electrode was a platinum wire, and a saturated

3

calomel electrode (SCE) in a side compartment served as reference. All potentials are quoted

with respect to the SCE. The temperature was (20

1)◦C.

±

The set-up and procedures for the electrochemical experiments (cyclic voltammetry,

capacitance measurements, chronocoulometry) were described previously [5, 19]. We focus

here only on some additional details of the chronocoulometric experiments [20]: The potential

was initially held at a value Ei between

1.375 V and

−

0.300 V (25 mV interval length),

−

up to 300 s for the lowest chloride concentrations, and then stepped to the ﬁnal potential

Ef =

1.400 V, where chloride is completely desorbed from the electrode surface. The

−

waiting time at Ei was chosen (in control experiments) to be always suﬃcient to establish

adsorption equilibrium. A comprehensive account of the setup and detailed results of the

SXS experiments for Ag(100)/Cl will be given elsewhere [20].

Results of the electrochemical experiments

Figures 1(A) and 1(B) show voltammograms (CV) and capacitance (CE) curves (5 mV peak-

to-peak amplitude, 18 Hz ac-frequency) for the Ag(100) electrode in 0.05 M KClO4 and

0.02 M KCl + 0.03 M KClO4 as obtained after continuous cycling of the potential between

1.40 V and

0.10 V. The capacitance curves merge at E <

1.20 V, indicating complete

−
desorption of chloride. The onset of chloride adsorption is characterized by broad peaks in

−

−

the CV and CE curves, which are la belled P1 in Fig. 1. In-situ SXS experiments revealed

that chloride adsorbs in this potential region as a lattice gas corresponding to randomly

adsorbed species on fourfold hollow sites [20]. The sharp peak P2 in Figs. 1(A) and 1(B)

represents the continuous transformation of the lattice gas into an ordered c(2

2) chloride

×

adlayer [20]. This phase is stable until rather complex AgClx-surface compounds are being

formed at more positive potentials [E >

0.20 V for the system shown in Fig. 1(A)] [7, 20].

−

4

Equilibrium data on the adsorption of chloride ions at Ag(100) electrodes were obtained

from chronocoulometric measurements in a gently stirred solution. Figure 1(A) shows

selected charge density curves for KCl in (0.05

x) M KClO4 + x M KCl. Adsorption

−

of chloride causes a positive charge to ﬂow to the metal side of the interface. This is

accompanied by a negative shift of the potential of zero charge. Phenomenologically, the

charge density vs. potential curves as measured in the presence of chloride concentrations

CCl > 10−3 M are composed of two segments. The region of low charge densities corresponds

to the potential range of the broad features in the CV and CE curves. The second one

appears at a potential just positive of the adlayer phase transition at P2, corresponding

to charge densities between 35 and 40 µC cm−2. It is characterized by an initial increase

of δqM/δE. Subsequently the slope decreases and seems to become less dependent on the

chloride concentration for CCl > 10−3 M at the most positive potentials studied.

The corresponding Gibbs surface excess has been calculated at constant potential (see

Fig. 2) and constant charge (not shown, c.f. [20]), using the approach of Stolberg and

Lipkowski [5, 20, 21]. The surface excess increases in the potential region of disordered

chloride and at constant concentration monotonously with potential. At CCl > 10−3 M

one observes in the potential region of the sharp volumetric peak P2 a distinct increase in

slope (Γ

6

×

∼

10−10 mol cm−2). At the most positive potentials experimentally accessible,

the surface excess levels oﬀ and approaches a chloride-concentration independent limit of

Γm = 10.2

×

10−10 mol cm−2. This chronocoulometric result is close to 9.94

10−10 mol cm−2

×

expected for a complete c (2

×

2) chloride adlayer, and is well supported by in-situ SXS

experiments employing the so-called interference scattering technique [20].

The electrosorption valency, as determined from a plot of the charge density vs. surface

excess at constant potential for the Ag(100)/Cl system is shown as an inset in Fig. 2. Using

this method, the electrosorption valency is found to be potential dependent, decreases with

5

increasing potential, and approaches -0.45 at -0.40 V. This value is larger than the result for

Ag(100)/Br (γ

0.80) [5, 13] (see also discussion in Sec. 5), indicating the stronger ionic

∼ −

character of adsorbed chloride, in comparison to bromide on silver.

3 Lattice-gas Model

The model used for both the Br and Cl systems is a lattice-gas model similar to that used

by Koper [15, 16] and Mitchell et al. [13, 14]. In this model the Br or Cl ions adsorb at the

four-fold hollow sites of the Ag(100) surface, as shown in Fig. 3. The model is deﬁned by

the grand-canonical eﬀective Hamiltonian

=

H

− Xi<j

φijcicj −

µ

L2

Xi=1

ci

(1)

where

i<j is a sum over all pairs of sites, φij are the lateral interaction energies between

P

particles on the ith and jth sites measured in meV/pair, and µ is the electrochemical

potential measured in meV/atom. Here the local occupation variables ci can take the values

0 or 1, depending on whether site i is occupied by an ion (1) or solvated (0).

The simulations were performed on an L

×

L square lattice, using periodic boundary

conditions to reduce ﬁnite-size eﬀects. The interaction constants φij between ions on sites i

and j a distance rij apart (measured in Ag(100) lattice spacing units, a = 2.889 ˚A [4]) are

given by

φij = 


−∞
23/2φnnn
r3
ij

rij = 1

√2

rij ≥

(2)



where the inﬁnite value for rij = 1 indicates nearest-neighbor exclusion, the interaction

for large rij

is most likely a combination of dipole-dipole and surface-mediated elastic

interactions, and negative values of φij denote repulsion. The previous studies by Koper [15,

16] have shown that large but ﬁnite nearest-neighbor repulsion has only minor eﬀects on the

6

coverage isotherms. Consequently, we have chosen a simpliﬁed model with nearest-neighbor

exclusion.

In the weak-solution approximation, the electrochemical potential µ is related to the bulk

ionic concentration C and the electrode potential E (measured in mV) as

µ = µ0 + kBT ln

C
C0 −

eγE

(3)

where µ0 is an arbitrary constant, C0 is a reference concentration (here taken to be 1 mM),

e is the elementary charge unit, γ is the electrosorption valency [22], and µ has the sign

convention that µ > 0 favors adsorption.

The anion coverage is deﬁned as

θ = N −1

N

Xi=1

ci ,

(4)

where N = L2 is the total number of lattice sites. The coverage can be experimentally

obtained by standard electrochemical methods as well as from the integer-order peaks in

surface X-ray scattering (SXS) data [4, 20].

To compute the isotherms θ(µ) or θ(E), the change in energy must be calculated before

each attempted Monte Carlo move. This requires evaluation of the interaction sum in Eq. (1),

which is computationally intensive even for modest system sizes.

In the next section we

compare a direct summation approach with a more eﬃcient truncated summation combined

with a mean-ﬁeld approximation for the inﬂuence of adparticle pairs at large separations.

4 Monte Carlo Methods

The Monte Carlo simulation proceeds as follows. On a square lattice with L = 64 and

periodic boundary conditions we randomly select a lattice site, i, and attempt to change

the occupation variable (ci = 1

ci = 0 or ci = 0

→

→

ci = 1). The energy diﬀerence,

7

, between the intial state of the system and the proposed state is then calculated using

∆

H

Eq. (1). We use the Metropolis acceptance probability [23]

= min

1, exp

(cid:20)

R

∆
H
kBT (cid:19)(cid:21)

(cid:18)−

(5)

for accepting the new trial conﬁguration as the next conﬁguration in the Monte Carlo

sequence.

Since the value of ∆

H

determines

R

in Eq. (5), the approximations made to calculate

the large-rij contributions to the pair sum in Eq. (1) are important. In our computations,

we used two diﬀerent methods to calculate ∆

H

. The ﬁrst was a direct-summation-plus-

truncation method previously used by Mitchell et al. [13, 14]. In the second method, which

we introduce here, we include the exact contribution of fewer sites on the surface, using a

mean-ﬁeld approximation to calculate the contribution from all the sites at larger distances.

4.1 Direct summation

The ﬁrst method involves calculating the contribution of the sites that are less than or equal

to ﬁve lattice spacings away from the site of interest. Since nearest-neighbor adsorption is

prohibited, the acceptance probability vanishes for any move that would bring two particles

into nearest-neighbor positions. In addition to the four nearest-neighbor sites, there are a

total of 76 sites such that 1 < rij ≤
classes as shown in Fig. 4. This summation provides approximately 87% of the total energy

5. These are divided between 12 diﬀerent distance

due to the long-range interactions [14].

This method of approximation proved to be acceptable for simulating Br adsorption on

Ag(100) [13, 14] as it produced values for the electrosorption valency γ that are in good

agreement with experimental data. On the other hand, because of its computationally

8

intensive nature, this method of calculating ∆

H

made it harder for dynamic simulations to

achieve CV scan rates within the experimental range [14].

4.2 Mean-ﬁeld-enhanced method

The method of calculating ∆

H

can be modiﬁed from the previous one so that, without

reducing the accuracy of the calculation, the cutoﬀ radius is reduced from ﬁve to three

lattice constants. This decreases the number of sites beyond nearest neighbors that are

included in the summation from 76 to 24, as shown in Fig. 4.

This modiﬁcation includes a mean-ﬁeld approximation to estimate the interaction energy

contribution from those particles that are farther than three lattice constants from the site

in question. Consequently, the change in energy associated with desorbing from the surface

a particle at lattice site i is

Hi = 23/2φnnn 
∆



X1<rij ≤3

cj
r3
ij

+ θ 

Σ∞



− X1≤rij ≤3

1
r3
ij









(6)

which is both more eﬃcient and more accurate than calculating the exact energy contribu-

tions out to rij = 5. Here Σ∞ =

∞
r=1 1/r3 is a Zucker sum over the sites of a square lattice

P

of unit lattice constant [15], and the quantity in the parenthesis is a constant, independent of

the adsorbate conﬁguration. It can easily be calculated to arbitrary numerical precision. The

energy change upon adsorption at a previously empty site i with four empty nearest-neighbor

sites is the negative of the result in Eq. (6).

This modiﬁcation of the calculation of the energy changes for the Monte Carlo steps

makes the program run more than twice as fast as when using the method described in

Sec. 4.1 and used in Refs. [13, 14]. It is consequently better suited for dynamical simulations

[24].

9

The results of the calculations performed with this method are similar to those using

exact summation for r

≤

5. At higher coverages, the numerical eﬀect of introducing the

mean-ﬁeld approximation is more pronounced, as expected. We note that this method is

successful because the interactions in our model are repulsive, which ensures that the spatial

distribution of adparticles is approximately uniform on large length scales. For systems with

attractive interactions more sophisticated methods to calculate the contributions from the

long-range interactions, such as the Fast Fourier Transform or Fast Multipole Method [25],

would be needed.

4.3 Comparison

A comparison of the calculated coverage as a function of the electrochemical potential,

obtained with both mean-ﬁeld and non-mean-ﬁeld methods for diﬀerent cutoﬀ radii,

is

shown in Fig. 5. The mean-ﬁeld enhancement makes a signiﬁcant contribution to the

adsorption isotherms for both cutoﬀ lengths. However, when the mean-ﬁeld enhancement

is used, increasing the cutoﬀ radius beyond three does not signiﬁcantly improve the results.

Tests with even smaller cutoﬀ radii revealed that three is an optimal choice to increase the

computational speed with only a minimal loss of accuracy.

5 Parameter Estimation

To estimate the parameters in the lattice-gas model, φnnn and γ, we performed standard

equilibrium MC simulations [23] with ∆

H

calculated by the mean-ﬁeld-enhanced method

at room temperature (kBT = 25 meV or T

290 K) to obtain θ(µ) for diﬀerent

≈

parameter values. These simulated isotherms were then compared with the experimental

chronocoulometry data using two ﬁtting procedures. The ﬁrst procedure assumed a constant

10

electrosorption valency γ, while the second assumed a coverage-dependent γ(θ). The

experimental coverage data for Br/Ag(100) [5], which were also used in Refs. [13, 14], were

provided to the authors of those papers by J.X. Wang.

5.1 Constant γ

To extract the values of γ and φnnn that would best ﬁt the experimental data, we used a

least-squares ﬁtting procedure that minimizes χ2 with respect to three ﬁtting parameters for

Cl and Br electrosorbed on Ag(100) [14],

Nconc

lmax(k)

χ2(φnnn, γ, µ0) =

[θsim(Ek

l ; µ0, γ, φnnn; Ck)

θexp(Ek

l ; Ck)]2

−

(7)

Xk=1

Xl=1

where θsim and θexp are the simulated and experimental coverage values respectively, k is the

concentration index, Nconc is the number of diﬀerent concentrations used in a ﬁt, and l is

the point index of the experimental data points.

This ﬁtting procedure, which provides good ﬁts for Br/Ag(100) in Refs. [13, 14] (see

also Table 1) does not give satisfactory ﬁts for Cl/Ag(100). The assumption that the

electrosorption valency γ is independent of the coverage is consistent with the Br results,

but appears to be invalid for the Cl system.

5.2

θ dependent γ

Since a coverage independent γ does not appear to be a valid assumption for Cl/Ag(100),

we assume that γ depends linearly on the coverage as

γ(θ) = γ0 + γ1θ

(8)

This adds to the model a fourth parameter, γ1, that must be determined by comparison to

the experimental results. The θ-dependent γ is allowed to vary in the interval [

1, 0], which

−

11

limits the values that γ0 and γ1 can assume according to Eq. (8). The range of variation for

γ0 is [

1, 0], while it is [

−

2, 0] for γ1 since the latter is multiplied by θ, which can assume a

−

maximum value of 0.5. As determined by χ2 [Eq. (7)], the inclusion of a coverage-dependent

electrosorption valency improves the ﬁts to the adsorption isotherms, shown in Fig. 6. It also

gives reasonable values for γ and φnnn. The resulting parameter values, based on ﬁtting Cl

and Br simulations to the experimental isotherms, are shown in Tables 1 and 2, respectively.

The tables include values for the ﬁtting parameters, γc for the constant γ ﬁts and γ0 and

γ1 for the coverage-dependent ﬁts. Moreover they include values for φnnn and χ2 per degree

of freedom, ˆχ2, for all the ﬁts. Fitting to the experimental data was performed both for the

truncated-sum Monte Carlo isotherms and for the mean-ﬁeld-enhanced isotherms. For each

of these simulated isotherms we performed three kinds of ﬁts. First, the numerical isotherms

were ﬁt to a single set of experimental data with a certain halide ion concentration (columns

3-8 in Tables 1 and 2, labeled 1-ﬁt). Second, each numerical isotherm was simultaneously

ﬁt to two experimental isotherms with ionic concentrations of 10 mM and 20 mM for Cl or

1 mM and 10 mM for Br (columns 9 and 10, labeled 2-ﬁt). Third, numerical isotherms were

ﬁt to three experimental isotherms simultaneously with the concentrations 6, 10 and 20 mM

for Cl and 0.1, 1.0, and 10.0 mM for Br (columns 11 and 12, labeled 3-ﬁt).

In ﬁtting two or more isotherms simultaneously, several conclusions may be drawn from

the tables shown. With one exception, the values of γ1 in Table 1 for Br/Ag(100) are zero

(i.e.,

γ1|

|

< 0.01) or nearly zero for all of the ﬁts. This supports the conclusion that a

constant γ is a good approximation for that system. Moreover, the quality of the ﬁts is

enhanced by using two or more concentrations simultaneously because this utilizes a greater

number of experimental data points in one ﬁt and constrains γ more directly through the

ln(C/C0) term of Eq. (3). For constant γ the 2-ﬁt and 3-ﬁt values for φnnn and γ for

the mean-ﬁeld-enhanced method are consistent with those obtained by the non-mean-ﬁeld

12

method. However, smaller values of ˆχ2 are found for the mean-ﬁeld-enhanced method than

for the non-mean-ﬁeld method, indicating that the mean-ﬁeld-enhanced isotherms ﬁt slightly

better to the experimental data than the non-mean-ﬁeld ones. Comparing the values found

using the 2-ﬁt and 3-ﬁt methods for mean-ﬁeld-enhanced isotherms, suggests φnnn =

21

−

2

±

meV and γc =

0.71

−

±

0.01 as reasonable estimates. These results are consistent with those

obtained in Refs. [5, 13, 14].

The results for the ﬁts to the Cl/Ag(100) experiments are given in Table 2, whose layout

is the same as for Table 1. Notice that γ1 assumes non-zero values for most of the ﬁts, and

that – except for the ﬁt to the 6 mM isotherm – the values of ˆχ2 obtained with variable γ are

less than those obtained with the constant-γ ﬁts. This supports the conclusion that, for the

Cl system, a coverage-dependent γ should be adopted. The exception can be attributed to

the fact that the 6 mM experimental data points do not cover the whole θ range, especially in

the important region near the phase transition. Consequently, we hereafter ignore the 6 mM

data in estimating parameters for the Cl/Ag(100) system. This leaves the 2-ﬁt parameter

values for a θ-dependent γ. The mean-ﬁeld and non-mean-ﬁeld parameters are similar and,

as determined by ˆχ2, provide equally valid descriptions of the experiment. From this we

conclude that, for Cl/Ag(100), φnnn =

14

−

±

2 meV and γ = (

0.66

−

±

0.01)+(

0.68

−

±

0.01)θ.

While these results for γ0 and γ1 are more negative than those obtained from the charge-

density curves in Sec. 2, the trends of a stronger dependence on coverage or electrode

potential and a higher (less negative) overall value than for Br/Ag(100) are the same. The

reasons for the quantitative diﬀerence between the estimates based on the two methods to

determine the electrosorption valency are left for future study.

13

6 Conclusions

In this paper we have presented a new method for implementing the lattice-gas model for

the electrosorption of halide ions on a Ag(100) surface by introducing a mean-ﬁeld-enhanced

method to calculate the contributions to the conﬁguration energy of widely separated

adparticle pairs. We ﬁt adsorption isotherms obtained by Monte Carlo simulation to the

experimental adsorption isotherms based on chronocoulometric data after comparing them

to the results obtained using the non-mean ﬁeld method.

The isotherms from both methods were ﬁt to experimental data for both Cl and Br.

It was shown that it was safe to assume a coverage-independent or potential-dependent

electrosorption valency for Br on Ag(100) while a coverage-dependent electrosorption valency

had to be implemented for the Cl on Ag(100).

Acknowledgments

We thank S.J. Mitchell, J.X. Wang, and B.M. Ocko for useful discussions. P.A.R. thanks

the Physics Department of Virginia Polytechnic Institute and State University for hospitality

during the ﬁnal stages of this work.

Supported by US National Science Foundation Grant No. DMR-9981815 and by Florida

State University through the Center for Materials Research and Technology and the School

of Computational Science and Information Technology.

References

[1] O.M. Magnussen, Chem. Rev. 102 (2002) 679.

14

[2] Th. Wandlowski, in Encyclopedia of Electrochemistry, Vol. 1, M. Urbakh and E. Gileadi

(Eds.), VCH-Wiley, Weinheim, 2002, p. 383.

[3] G. Valette, A. Hamelin, R. Parsons, Zeitschrift f¨ur Physikalische Chemie, Neue Folge

113 (1978) 71.

[4] B.M. Ocko, J.X. Wang, Th. Wandlowski, Phys. Rev. Lett. 79 (1997) 1511.

[5] Th. Wandlowski, J.X. Wang, B.M. Ocko, J. Electroanal. Chem. 500 (2001) 418.

[6] A. Hamelin, in Modern Aspects of Electrochemistry, Vol.16, B.E. Conway, R.E. White,

J.O.M. Bockris (Eds.). Plenum Press, New York, 1987, p. 1.

[7] B.M. Jovic, V.D. Jovic, D.M. Drazic, J. Electroanal. Chem. 399 (1995) 197.

[8] C. Franke, G. Piazza, D.M. Kolb, Electrochim. Acta 34 (1989) 67.

[9] G. Aloisi, A.M. Funtikov, T. Will, J. Electroanal. Chem. 370 (1994) 297.

[10] T. Yamata, K. Ogaki, S. Okubo, Surf. Sci. 369 (1996) 321.

[11] B.M. Ocko, O.M. Magnussen, J.X. Wang, R.R. Adzic, Th. Wandlowski, Physica B 221

(1996) 238.

[12] O. Endo, M. Kiguchi, T. Yokoyama, M. Ito, T. Ohta, J. Electroanal. Chem. 473 (1999)

19.

[13] S.J. Mitchell, G. Brown, P.A. Rikvold, J. Electroanal. Chem. 493 (2000) 68.

[14] S.J. Mitchell, G. Brown, P.A. Rikvold, Surf. Sci. 471 (2001) 125.

[15] M.T.M. Koper, J. Electroanal. Chem. 450 (1998) 189.

[16] M.T.M. Koper, Electrochim. Acta 44 (1998) 1207.

15

[17] A. Bewick, B. Thomas, J. Electroanal. Chem. 65 (1975) 911.

[18] M.L. Foresti, M. Innocenti, R. Guidelli, J. Electroanal. Chem. 376 (1994) 8.

[19] T. Pajkossy, Th. Wandlowski, D.M. Kolb, J. Electroanal. Chem. 414 (1996) 209.

[20] Th. Wandlowski, B.M. Ocko, J.X. Wang, in preparation

[21] L. Stolberg, J. Lipkowski, in Adsorption of Organic Molecules, J. Lipkowski, P.N. Ross

(Eds.). VCH, New York, 1993.

[22] K.J. Vetter, J.W. Schultze, Ber. Bunrenges. Phys. Chem. 76 (1972) 920; ibid 76 (1972)

927.

[23] D.P. Landau, K. Binder, A Guide to Monte Carlo Simulations in Statistical Physics.

Cambridge Univ. Press., Cambridge, 2000.

[24] I. Abou Hamad, et al., in preparation.

[25] L.F. Greengard, The Rapid Evaluation of Potential Fields in Particle Systems. MIT

Press, Cambridge, MA, 1988.

16

Table 1: Fitting parameters for Br adsorption on a Ag(100) single-crystal surface, using isotherms computed with a cutoﬀ

distance of three lattice constants, and with and without mean-ﬁeld interactions included. The quantity ˆχ2 is the χ2 per degree

of freedom of the ﬁt. Here, “1-ﬁt” means individual ﬁts for each of the three diﬀerent bulk concentrations given; “2-ﬁt” means

a single, simultaneous ﬁt for the two bulk concentrations given; and “3-ﬁt” means a single, simultaneous ﬁt for the three bulk

concentrations given.

1
7

mean-ﬁeld

no mean-ﬁeld

mean-ﬁeld

no mean-ﬁeld mean-ﬁeld

no mean-ﬁeld

1-ﬁt; 0.1 mM, 1 mM, 10 mM

2-ﬁt; 1 mM, 10 mM

3-ﬁt; 0.1mM, 1 mM 10, mM

γc

γ = Const.

φnnn (meV)

ˆχ2

105

×
γ0

γ1

γ = γ0 + γ1θ

φnnn(meV)

ˆχ2

×

105

0.51

−

9

−
0.564803

0.49

−

10

−

0.46

−

10

−

2.14327

7.34073

0.47

−

8

−
0.680078

0.46

−

10

−

2.56305

0.54

0.01

−

−

10

−
0.54580

0.49

−
0.00

10

−

0.46

−
0.00

10

−

0.53

−
0.02

11

−

0.46

−
0.00

10

−

2.20281

7.54464

0.69541

2.63425

0.45

−

11

−
8.09803

0.45

−
0.00

11

−
8.32297

0.70

−

22

−

0.67

−

23

−

0.73

−

22

−

6.89425

9.46991

7.31550

0.70

−
0.00

22

−

0.66

−
0.04

21

−

0.72

0.01

−

−

21

−

6.98496

9.53128

7.36551

0.70

−

23

−
9.76821

0.68

0.19

−

−

16

−
8.68241

Table 2: Fitting parameters for Cl adsorption on a Ag(100) single-crystal surface, using isotherms computed with a cutoﬀ

distance of three lattice constants, and with and without mean-ﬁeld interactions included. The quantities shown and the

organization of the table are the same as in Table 1.

1-ﬁt; 6 mM, 10 mM, 20 mM

2-ﬁt; 10 mM, 20 mM

3-ﬁt; 6 mM, 10 mM, 20 mM

mean-ﬁeld

no mean-ﬁeld

mean-ﬁeld

no mean-ﬁeld mean-ﬁeld

no mean-ﬁeld

1
8

γc

γ = Const.

φnnn (meV)

ˆχ2

105

×
γ0

γ1

γ = γ0 + γ1θ

φnnn (meV)

ˆχ2

×

105

0.29

−

4

−
4.06844

0.35

−

6

−
5.05880

0.29

0.00

−

−

0.46

0.36

−

−

4

−
4.17015

7

−
3.35255

0.40

−

8

−
11.2260

0.66

0.68

−

−

12

−

5.61327

0.28

−

4

−
4.11751

0.35

−

7

−
4.63378

0.46

−

14

−
10.3544

0.28

0.00

−

−

0.47

0.36

−

−

0.65

0.67

−

−

4

−
4.22045

9

−
2.74380

14

−
4.28522

0.57

−

19

−

0.54

−

20

−

0.44

−

12

−

0.44

−

14

−

11.8302

11.7546

13.2892

13.1223

0.67

0.66

−

−

14

−

0.65

0.70

−

−

14

−

0.43

−
0.02

11

−

0.42

−
0.04

12

−

5.93654

5.41895

13.2942

13.1225

20

10

0

-10

-20

400

300

200

100

0

60

40

20

0

-20

P2

P1

P2

A

B

C

P1

0
1.0 10-5
1.0 10-4
1.0 10-3
6.0 10-3
1.0 10-2
2.0 10-2

2

m-
c
A
m

/
i

2

m-
c
F
m
C

/

2
-

m
c
C
m
/
M
q

-1.4

-1.2

-1.0

-0.8

-0.6

-0.4

E/V vs SCE

Figure 1: (A) Cyclic voltamogram (50 mV s−1) for Ag(100)/(0.05

x) M KClO4 + x M KCl,

−

x=0 (dotted curve) and x=0.02 M (solid curve).

(B) Capacitance vs. potential curves

for the system of Fig. 1(A), 10 mV s−1.

(C) Charge density vs. potential curves for

Ag(100)/(0.05

x) M KClO4 + x M KCl (x in M), as indicated in the ﬁgure.
19

−

2
-

m
c
o
m

l

0
1
-
0
1
/
G

1.0 10-5
1.0 10-4
1.0 10-3
6.0 10-3
1.0 10-2
2.0 10-2

-0.50

-0.45

-0.40

-0.35

-0.30

-0.25

-1.0
.

-0.8

-0.6
E/V vs SCE

-0.4

l

y
c
n
e
a
v
n
o
i
t
p
r
o
s
o
r
t
c
e
e

l

10

8

6

4

2

0

-1.4

-1.2

-0.8

-1.0
E/V vs SCE

-0.6

-0.4

Figure 2: Plots for surface excess for Ag(100)/(0.05

x) M KClO4 + x M KCl (x in M),

−

employing the electrode potential as the independent electrical variable for selected chloride

concentrations. The inset shows the potential-dependent electrosorption valency.

20

 
Figure 3: Br or Cl (bigger spheres) adsorbed at the 4-fold hollow sites of the (100) surface

of Ag (smaller spheres). The squares of the grid frame correspond to the adsorption sites.

21

13

12

10

13

11

12

10

13

9

10

12

8

7

6

7

8

13

11

8

5

4

3

4

5

8

7

4

2

1

2

4

7

13

12

10

13

9

6

3

1

0

1

3

6

9

13

10

12

7

4

2

1

2

4

7

8

5

4

3

4

5

8

13

11

8

7

6

7

8

11

10

12

13

13

12

10

9

10

12

13

13

Figure 4: Sites included in the energy calculation. The dashed lines surround the 76 sites

included in the direct summation for 1 < r

included in the direct sumation for 1 < r

≤

5. The heavy solid lines enclose the 24 sites

≤
3, which is used with the mean-ﬁeld-enhanced

method.

22

φ

nnn = −26 meV

R=3 without mean field
R=5 without mean field
R=3 with mean field
R=5 with mean field

0.5

0.4

0.3

0.2

0.1

θ

0
−500

0

µ   (meV)

500

1000

Figure 5: Simulated coverage isotherms vs. electrochemical potential, computed with

diﬀerent methods. Here R is the cutoﬀ radius up to which exact summation was performed.

The simulations were performed at T

27◦C with φnnn =

≈

26 meV. The line segments

−

connecting the data points are included as a guide to the eye.

23

 
 
0.5

0.4

0.3

0.2

0.1

θ

0
−1.2

0.5

0.4

0.3

0.2

0.1

0
−1.2

θ

φ
nnn=−19
γ
c=−0.57
^
χ2=11.83 x 10−5

(a)

sim 20 mM
sim 10 mM
exp 20 mM
exp 10 mM

−0.8

−0.4

0.0

E vs SCE (V)

γ

φ
nnn=−14
0=−0.67
γ
1=−0.66
^
χ2=5.94 x 10−5

(b)

sim 20 mM
sim 10 mM
exp 20 mM
exp 10 mM

−0.8

−0.4

0.0

E vs SCE (V)

Figure 6: One simulated Cl/Ag(100) isotherm ﬁt to two experimental

isotherms with

diﬀerent bulk concentrations. The simulated isotherms were obtained using the mean-

ﬁeld-enhanced method described in Sec. 4.2. (a) Using coverage independent γ. (b) Using

coverage-dependent γ(θ) = γ0 + γ1θ.

24"
Multiscale Algorithms for Eigenvalue Problems,"  Iterative multiscale methods for electronic structure calculations offer
several advantages for large-scale problems. Here we examine a nonlinear full
approximation scheme (FAS) multigrid method for solving fixed potential and
self-consistent eigenvalue problems. In principle, the expensive
orthogonalization and Ritz projection operations can be moved to coarse levels,
thus substantially reducing the overall computational expense. Results of the
nonlinear multiscale approach are presented for simple fixed potential problems
and for self-consistent pseudopotential calculations on large molecules. It is
shown that, while excellent efficiencies can be obtained for problems with
small numbers of states or well-defined eigenvalue cluster structure, the
algorithm in its original form stalls for large-molecule problems with tens of
occupied levels. Work is in progress to attempt to alleviate those
difficulties.
",http://arxiv.org/pdf/cond-mat/0304374v1,3,"3
0
0
2

r
p
A
6
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
4
7
3
4
0
3
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Multiscale Algorithms for Eigenvalue Problems

Nimal Wijesekera1, Guogang Feng2, Thomas L. Beck2∗
1Department of Physics
2Department of Chemistry
University of Cincinnati
Cincinnati, OH 45221-0172
thomas.beck@uc.edu
*corresponding author
February 7, 2020

Abstract

Iterative multiscale methods for electronic structure calculations oﬀer several advantages
for large-scale problems. Here we examine a nonlinear full approximation scheme (FAS)
multigrid method for solving ﬁxed potential and self-consistent eigenvalue problems.
In
principle, the expensive orthogonalization and Ritz projection operations can be moved to
coarse levels, thus substantially reducing the overall computational expense. Results of
the nonlinear multiscale approach are presented for simple ﬁxed potential problems and
for self-consistent pseudopotential calculations on large molecules. It is shown that, while
excellent eﬃciencies can be obtained for problems with small numbers of states or well-
deﬁned eigenvalue cluster structure, the algorithm in its original form stalls for large-molecule
problems with tens of occupied levels. Work is in progress to attempt to alleviate those
diﬃculties.

Introduction

Electronic structure methods for large-scale problems can be divided into three general
categories: plane-wave [1], traditional basis set [2, 3], and real-space methods [4]. Real-space
methods result in a banded Hamiltonian, through ﬁnite diﬀerence [5, 6, 7, 8, 9, 10, 11, 12,
13, 14, 15, 16, 17], ﬁnite element [18, 19, 20], or wavelet [21] representations of the Laplacian
operator. Gaussian basis sets lead to a smaller total matrix size of the Hamiltonian (relative
to real-space methods), but the matrix is less banded. The plane-wave basis set, on the
other hand, is completely delocalized in real space. The bandedness of the Hamiltonian in
real-space methods is advantageous in several respects. First, it leads to ease of developing
parallel codes. Second, methods developed recently which scale linearly with the system size
generally rely on localization of the orbitals and real-space methods ‘mesh’ well with those
algorithms [22]. Third, eﬃcient multiscale methods accelerate convergence by decimating
errors over a wide range of length scales. Fourth, ﬁnite clusters or periodic systems can
be treated with equal eﬀort. Finally, local mesh reﬁnements can be incorporated without

1

 
 
 
 
 
 
degrading the eﬃciency of the solver [16, 23]. Several groups have developed real-space
solvers for the Kohn-Sham equations of density functional theory (DFT) in the last decade
[4]. Multigrid (MG) methods have been employed extensively to accelerate the convergence
rate [6, 9, 11, 12, 13, 14, 15, 16, 17].

A central feature of the Kohn-Sham problem is its nonlinearity. It is nonlinear in two
respects. First, the eigenvalue problem itself is nonlinear since one solves for both the
eigenvalues and eigenfunctions. Second, the self-consistent potential depends nonlinearly on
the charge density obtained from the squares of the eigenstates. Therefore, it can be expected
that nonlinear multigrid methods will lead to increased eﬃciencies. This has indeed been
observed previously in studies which compare a full approximation scheme (FAS) nonlinear
approach to linearized MG methods [9, 12].

The most costly operation in the nonlinear eigenvalue approach of Brandt et al. [9, 24]
is the Ritz projection (preceeded by Gram-Schmidt orthogonalization) on the ﬁne level. If q
orbitals span the whole physical domain, with N h
g grid points on the ﬁne level (labelled by h),
this step of the algorithm scales as q2N h
g . In the present paper, we carry the nonlinear FAS
scheme further by implementing an extension of the Brandt et al. algorithm proposed by
Costiner and Ta’asan [25, 26]. In their approach, the orthogonalization and Ritz projection
are moved to coarse levels within the FAS strategy. This results in an 8-fold decrease in
computational cost for the Gram-Schmidt/Ritz operation for each coarser level in three
dimensions. We discuss relevant details of their method, and then present numerical results
on ﬁxed potential and self-consistent eigenvalue problems related to atomic and molecular
structure.

Algorithms

Multigrid methods accelerate the convergence rate of iterative relaxation solvers for par-
tial diﬀerential equations by decimating errors on a wide range of length scales [27]; it is the
long wavelength modes of the error which degrade single-level relaxation eﬃciency. Non-
linear multigrid methods incorporate a full representation of the problem on coarse levels.
Modiﬁcations of the ﬁne grid matrix equation are necessary on the coarse grids to obtain
zero correction at convergence. These modiﬁcations are termed defect corrections. In this
paper, we examine the FAS multigrid method of Costiner and Ta’asan [25, 26]. They pre-
sented a detailed account of the algorithm in two papers: the ﬁrst concerns ﬁxed potential
problems and the second addresses self-consistency. A brief summary will be given here. We
will follow the notation from their work.

FAS Eigenvalue Method

Suppose we wish to solve an eigenvalue problem represented in real space with ﬁnite

diﬀerences. This leads to the matrix equation

2

AU = UΛ.

(1)

The matrix A is the N h
vectors, and Λ is the diagonal q × q matrix of eigenvalues.

g (banded) Hamiltonian, U is the q × N h

g × N h

g matrix of the eigen-

In the FAS approach, we express the coarse grid (level i) problem as

Here FiUi = AiUi − UiΛi and Ti is the defect correction. On the ﬁnest grid Ti = 0. On grids
j coarser than i,

FiUi = Ti.

(2)

Tj = I j

i (Ti − FiUi) + FjI j

i Ui,

(3)

where the operator I j
i is the restriction operator. We use full weighting restriction through-
out, which just involves a local trapezoid-rule integration of the function values from the
ﬁne grid. In the above equations, if the exact numerical ﬁne grid solution is inserted into
the coarse grid equations, identities are obtained. This is equivalent to the zero correction
at convergence condition.

An initial approximation is ﬁrst obtained on the ﬁne grid. We obtain this approximation
by implementing a full multigrid (FMG) cycle [9], beginning on the coarsest level, interpo-
lating to the next ﬁner grid, performing MG cycles there, and so on until the ﬁnest grid is
reached. In this way, a good initial approximation is obtained for very little numerical eﬀort.
Following relaxation (typically 2-5 Gauss-Seidel or successive over-relaxation/SOR steps),
the ﬁne grid approximation is passed to the coarse level by restricting the eigenfunctions,
the potential, and the defect correction from the ﬁner grid. Relaxations (and generalized
Ritz projections, see below) are performed on the current coarse grid, and the problem is
then passed again to the next coarser level. This process is repeated until the coarsest grid
is reached. We typically utilize three grid levels when the ﬁnest grid is a 653 mesh. Once
relaxation is done on the coarsest level, a correction step for the next ﬁner level is performed:

i = U old
U new

i + I i

j(Uj − I j

i U old
i

).

(4)

I i
j is the interpolation operator. Linear interpolation by lines is used throughout except
during the FMG process when passing to the next ﬁner level, where cubic interpolation
by lines is used (to obtain a better initial guess on the ﬁne grid). The correction steps are
continued until the ﬁnest grid functions are corrected followed by relaxation steps there. The
full cycle through all the levels is termed a V-cycle. One may then repeat the MG V-cycles
until a desired convergence is obtained.

Generalized Ritz Projection, GRP

Consider a new eigenvalue relation, in which the matrix V results from a linear combi-

nation of the current approximation U:

3

AV = V Λ,

(5)

where V = UE and E is a q×q matrix of normalized vectors, the columns of which determine
the coeﬃcients for the linear combination of old vectors from U. Then on the ﬁne grid we
have the relation

When this problem is passed to the coarser levels, the proper FAS transfer is

AUE = UEΛ.

AUE = UEΛ + T E.

(6)

(7)

If we multiply on the left by U T , we obtain the following generalized (nonsymmetric) eigen-
value problem on the coarse grid:

U T (AU − T )E = (U T U)EΛ.

(8)

Notice that the eigenfunctions are no longer orthonormal when passed to the coarse grid.
Also, it is easy to show that, at convergence, the eigenvalues are the same on all grid
levels; in principle, there is no need to compute them on the ﬁnest grid. We solve this
q × q eigenproblem with standard linear algebra packages. Once solved, we obtain new
eigenvalues, eigenfunctions (linear combinations of the current approximation), and defect
corrections (also linear combinations of the old defect corrections). On the ﬁnest grid, where
the defect correction T is zero, the GRP reduces to the usual Ritz projection employed in
the Brandt et al. algorithm [24].

Backrotation, BR

A subtle aspect of the correction scheme outlined above is that the coarse-grid eigenfunc-
tions must properly match their ﬁne-grid counterparts for the correction step. Therefore,
Costiner and Ta’asan [25] introduced a process called backrotation in their solver. This op-
eration is designed to prevent rotations in degenerate or near-degenerate subspaces, and to
prevent sign changes, rescalings, and permutations of the eigenvectors. In the backrotation,
the E matrix is modiﬁed towards the ends listed above. If this step is not employed in the
algorithm of Ref. [25], the solver typically does not fully converge. As a simple example,
imagine that the sign of one of the eigenfunctions changes during GRP on a coarse level. If
the correction is then interpolated to the ﬁne grid, the corrected function will be severely
distorted. At convergence, the E matrix should approach the unit matrix. During processing
(prior to backrotation), it tends to have block diagonal form, where the blocks correspond
to degenerate or near-degenerate subspaces. The dimensions of the blocks determine the
eigenvalue cluster sizes. An extensive discussion of the backrotation is given in the original
paper.

Relaxation

4

A major feature of MG methods is that relatively simple relaxation strategies can be
employed so long as they decimate errors with wavelengths comparable to the grid spacing on
a given level [27]. Gauss-Seidel is the most common one utilized. We have investigated several
relaxation strategies for smoothing on each level. Originally, we used the Gauss-Seidel with
shift form given in Ref. [24]. Recently, we have extended this relaxation method to an SOR
form, and ﬁnd improved convergence. On the coarsest level, we have employed Gauss-Seidel
directly, Gauss-Seidel with constraints designed to maintain eigenfunction orthonormality
on the ﬁne grid [24], and Kaczmarz [28] relaxation. Kaczmarz relaxation is guaranteed to
converge, but it exhibits slower convergence relative to Gauss-Seidel or SOR (this is not a
signiﬁcant issue on coarse levels). It will be speciﬁed below which method was used for each
application. Further details of relaxation methods will be presented in an extensive account
of our algorithm [29].

Self-Consistent Problems

Some of the applications presented below concern self-consistent solution of the Kohn-
Sham equations. In the work presented here, we update the eigenfunctions and self-consistent
potential sequentially. That is, given an initial approximation to the eﬀective potential, an
MG V-cycle is performed to update the eigenfunctions. From the new eigenfunctions, a new
charge density is computed, from which a new eﬀective potential is obtained. The main
computational step for updating the eﬀective potential is solution of a Poisson problem.
This equation is also solved with MG V-cycles. The total time to solve the Poisson equation
is less than that for updating a single eigenfunction, and this operation scales linearly with
system size. We are currently exploring approaches to update the eﬀective potential on
coarse levels simultaneously with the eigenfunctions [26]. This can be expected to accelerate
the self-consistent convergence rate. We note that in our calculations so far, we have found
no need for potential or charge density mixing of old and new solutions; we believe this is
due to long-wavelength stabilization of the charge density during the FMG preconditioning
process.

Pseudopotentials

For our calculations on atoms and molecules, we have incorporated the separable dual-
space Gaussian pseudopotentials developed by Goedecker et al. [30, 31]. These pseudopo-
tentials have analytic forms with only several parameters per atom, and they exhibit optimal
decay properties in both real and reciprocal space. We have implemented the real-space rela-
tivistic version of these pseudopotentials for the present calculations. For calculations on the
coarse grids, we simply compute the function values just as we do on the ﬁne level. Of course
fewer grid points are necessary to sample the pseudopotential on coarse grids due to the de-
cay properties of the projectors. It has been shown that application of pseudopotentials in
real space is more eﬃcient than in reciprocal space [32].

5

Numerical Results

Fixed Potential Problems

We ﬁrst present results of the FAS algorithm on ﬁxed potential problems. As a bench-
mark, we utilized the original algorithm of Ref. [24] and solved the same two dimensional
eigenvalue problem addressed in that paper. Their kinetic energy operator is scaled by a
factor of two. A second order ﬁnite diﬀerence approximation was assumed for the Laplacian.
Half of their potential is

v = 5y sin(3πx).

(9)

The total domain size was taken as one, and four grid levels were utilized in the FAS
process. Gauss-Seidel relaxation (with a shift parameter of zero) was employed on all four
levels. One relaxation step was performed on the coarsest level while enforcing constraints
designed to maintain eigenfunction orthonormality on the ﬁnest level. On all other levels,
In total, 7 FAS V-cycles were implemented on the
two relaxation steps were performed.
ﬁnest level. The computed eigenvalues and residuals are shown in Table 1. The residual for
each eigenfunction is deﬁned as

r = v
u
u
t

P

2
|Hψ − Eψ|
N h
g

,

(10)

where the sum is over all the ﬁne grid points and N h
g is the total number of grid points.
The algorithm with Ritz projection performed on the ﬁnest level converges nicely to the
numerically exact eigenfunction/eigenvalue pairs.

We next compare the convergence rates of three FAS algorithms: 1) Ritz on ﬁne grid (Ref.
[24], 2) generalized Ritz with backrotation (GRBR) on coarse grids with no orthonormal-
ization on the ﬁne level [25], and 3) GRBR on coarse grids with periodic (every 5 V-cycles)
Gram-Schmidt orthonormalization on the ﬁne grid. These approaches were tested on simple
ﬁxed potential problems, namely the three-dimensional harmonic oscillator and the hydro-
gen atom. Both of these physical problems have degenerate subspaces leading to eigenvalue
clusters which must be handled in the backrotation step. For these problems, Gauss-Seidel
relaxation was employed on all levels, except Kaczmarz relaxation was utilized for the coars-
est grid relaxation for the hydrogen atom problem (this led to increased eﬃciency).

The convergence results are presented in Figs. 1 and 2. For the harmonic oscillator
problem, we solved for ten states and used a 12th-order ﬁnite diﬀerence representation for
the Laplacian. The total domain size is ten, and the ﬁne grid is a 653 mesh; three grid
levels were utilized. Atomic units are used throughout. A shift parameter equal to the
current eigenvalue was employed in the Gauss-Seidel relaxations (5 steps per level). The

6

GRBR step was performed on the coarsest level. A total of 15 V-cycles were conducted.
The compute times per V-cycle for the three algorithms listed above were 50.9, 34.6, and
36.6 sec., respectively, on an 800 MHz machine. The q values are small enough that the
orthogonalization and Ritz projections do not yet dominate the compute time. For the
hydrogen atom case, we generated the ﬁxed potential by numerical solution of the Poisson
equation for a ﬁxed central unit charge. Again, 12th-order ﬁnite diﬀerences were employed,
and we solved for 14 states on a domain with a total side length of 28. The ﬁne grid
is a 653 mesh. For this case, it was found that a shift parameter equal to the potential
was more eﬃcient. A total of 20 V-cycles were conducted. For both cases, the fastest
(lowest eigenvalue) and slowest (highest eigenvalue) converging cases are shown. The GRBR
(without orthonormalization) operation was conducted on the middle grid level, while for
the third algorithm with periodic Gram-Schmidt operations on the ﬁne grid, the GRBR step
was implemented on the coarsest level. The compute times per V-cycle were 81.5, 59.7, and
52.8 sec. for the three algorithms.

For both physical problems, performing the orthonormalization and Ritz projection on
the ﬁne level leads to the most eﬃcient convergence. The harmonic oscillator potential is
smooth, and the GRBR algorithm exhibits good convergence behavior. However, the conver-
gence rate is slightly slower than when orthonormalization and Ritz projection are performed
on the ﬁnest level. The GRBR convergence rate is the same whether or not orthonormal-
ization is periodically done on the ﬁnest level, indicating good separation can be obtained
without processes on the ﬁne level. For the hydrogen atom case, the overall convergence
rate is reduced relative to the harmonic oscillator, presumably due to the singular nature
of the potential. Also, periodic Gram-Schmidt operations on the ﬁnest level increase the
convergence rate slightly.

As part of the backrotation step, the degenerate subspaces (eigenvalue clusters) must
be identiﬁed so as to prevent rotations within those clusters. Both the harmonic oscillator
and the hydrogen atom problems possess clear eigenvalue structure which can be directly
incorporated or determined during the solution process. This ensures healthy convergence
of the GRBR algorithm, behavior which was also observed in the original work of Costiner
and Ta’asan [25]. We will see below that, for large self-consistent molecular cases without
such well-deﬁned eigenvalue cluster structure, the algorithm may stall due to mixing during
the backrotation step.

Self-Consistent Pseudopotential Calculations

Computational results for self-consistent pseudopotential Schr¨odinger-Poisson eigenvalue
problems are presented. Just as for the ﬁxed potential problems presented above, the al-
gorithms used were Ritz projection on the ﬁne level coupled with Gram-Schmidt orthog-
onalisation and the GRBR algorithm without and with periodic ﬁne grid Gram-Schmidt
operations. In both GRBR algorithms, the eigenfunctions were normalized on the ﬁne level
to ensure charge conservation. Three examples, Ne, CO, and the benzene dithiol molecule
were used in the study. All three cases are three dimensional and were treated with 12th

7

order ﬁnite diﬀerence representations. Three grid levels were utilized comprising 173, 333
and 653 total points . The ﬁrst example, the Ne atom, possesses 4 occupied states. Similarly
5 and 21 eigenvectors were required for the CO and benzene dithiol molecules, respectively.
The Ne and CO examples possess well-deﬁned eigenvalue cluster structure (triply degenerate
p states for Ne and a doubly degenerate π bonding orbital for CO). Convergence results are
presented in Figs. 3-5.

Choosing the optimal parameters for the relaxation scheme was important. The shift
parameter for Gauss-Seidel relaxation was taken as λ + v, where λ is the eigenvalue and v
is symbolically the eﬀective potential (nonlocal in the case of the pseudopotential). Gauss-
Seidel relaxation (ω = 1, where ω is the overrelaxation parameter) was used on all levels
except on the ﬁnest grid where SOR relaxation was employed (ω = 1.7). These near-
optimal relaxation parameters were determined by numerical experiments. In the ﬁnal V-
cycle involving the three grid levels, three relaxation steps were done on each level.

All three algorithms converged for the Ne and CO cases. The ﬁne grid Ritz plus Gram-
Schmidt and coarse-grid GRBR with periodic ﬁne level Gram-Schmidt algorithms both ex-
hibited excellent convergence rates. Implementing GRBR with no ﬁne grid separation (or-
thogonalization) led to slower convergence; the total energy convergence slows after a few
self-consistency iterations. In the GRP, the ﬁne level separation of wavefunctions comes as
a result of GRBR done on the middle level. But complete separation may not always be
achieved on the ﬁne level (Table 2). Performing only a few ﬁne grid Gram-Schmidt opera-
tions during the entire solution process restores the convergence rate and leads to acceptable
ﬁne grid eigenfunction orthogonality at the end. Clearly the form of the potential (self-
consistent pseudopotential in this case) and resulting eigenvalue structure have impacts on
the convergence behavior of the GRBR algorithm.

In the case of benzene dithiol, the ﬁne grid separation algorithm converged nicely as for
the smaller molecules. However, neither variant of the GRBR algorithm converged properly;
the solver stalled with only modest energy convergence. To probe for the reason for this lack
of convergence, we ﬁrst converged the system using ﬁne-grid separation for 15 V-cycles, and
then used the resulting potential in a ﬁxed potential calculation. We observed that the E
matrix determined from GRBR gradually begins to destablize rather than to converge to the
unit matrix as expected. This suggests again that the form of the potential and the resulting
eigenvalue cluster structure aﬀect the convergence of the GRBR algorithms. Benzene dithiol
is a relatively large molecule with 14 atoms (C,O,S and H) and 21 valence eigenstates.
We believe that the diﬃculties arise from the ambiguous cluster structure of the eigenvalues
which leads to mixing during the backrotation operation. Similar calculations were performed
on the benzene molecule, which possesses clear symmetry and cluster structure, and the
algorithm converged. Since determination of the cluster structure is crucial for convergence,
and this must be performed automatically in the algorithm in order to treat general systems,
this issue must be addressed for the GRBR approach to provide a generally convergent
scheme. Work is in progress investigating these diﬃculties. One possible solution is suggested
below.

8

Discussion

The objective of this paper has been to provide a test of the nonlinear FAS multigrid
eigenvalue method of Refs. [25, 26] for solving the Kohn-Sham equations. This method is
promising because it removes the expensive orthogonalization and Ritz projection operations
to coarse levels (with a corresponding 8-fold reduction in cost per level in three dimensions).
The necessary ﬁne grid work only involves relaxation, normalization of the eigenfunctions,
and perhaps orthogonalization within degenerate clusters. The model problems treated in
Refs. [25, 26] possess relatively smooth potentials and well-deﬁned eigenvalue cluster struc-
ture. Similar to the results of Costiner and Ta’asan, we ﬁnd good convergence of the GRBR
approach for ﬁxed potential and self-consistent eigenvalue problems with well-deﬁned eigen-
value clusters. However, we found that for a larger molecular case with complicated eigen-
value structure, the GRBR approach did not converge properly. We linked these diﬃculties
to the backrotation step which appears to be highly sensitive to the determination of the
clusters. Since determination of the clusters must be done numerically during the course of
the solution process, this issue must be addressed to develop a generally convergent solver
for large systems.

We have recently begun investigating one possible approach to deal with these diﬃculties.
Notice that the E matrix of Eqs. 6 and 7 is formally the same on all levels at convergence
(just as are the eigenvalues).
In the algorithm of Ref. [25], the backrotation involves a
modiﬁcation of the E matrix designed to prevent rotations in degenerate or near-degenerate
subspaces, sign changes, rescalings, and permutations of eigenvectors. Utilizing the fact that
the E matrix is the same on the coarse and ﬁne levels (at convergence), we can circumvent
the backrotation by ﬁrst applying the E matrix to the current ﬁne-grid approximation to the
eigenfunctions prior to the correction step. This approach is in a sense a hybrid of the ﬁne
and coarse grid Ritz projections; we use the coarse grid to generate the new eigenvalues and
the E matrix, but we use that E matrix to alter the ﬁne-grid occupied subspace. Thus the
expensive step of constructing the Ritz matrix has been moved to the coarser level. The use
of the E matrix to update the ﬁne-grid function is a relatively cheap operation. Formally, it
does scale as q2N h
g , but the E matrix is of block diagonal form, with the blocks of dimension
of the corresponding degenerate cluster. These clusters are generally very small. Therefore
realistically the update operation scales as qN h
g if the eigenfunctions span the whole domain.
Some discussion along these lines was already given in Ref. [24]. We are currently exploring
the use of this idea in our nonlinear FAS multigrid solver. In preliminary results, we have
found it to converge properly for all of the physical problems examined in this paper.

Acknowledgments

We gratefully acknowledge the support of the National Science Foundation (CHE-0112322)
for this research. We also thank Achi Brandt and Shlomo Ta’asan for many helpful discus-
sions.

9

References

[1] M. Payne, M. Teter, D. Allan, T. Arias, and J. Joannopoulos, Rev. Mod. Phys. 64,

1045 (1992).

[2] M. Challacombe, Comput. Phys. Commun. 128, 93 (2000).

[3] D. P. S´anchez-Portal, P. Ordej´on, E. Artacho, and J. M. Soler, Intl. J. Quantum Chem.

65, 453 (1997).

[4] T. L. Beck, Rev. Mod. Phys. 72, 1041 (2000).

[5] J. R. Chelikowsky, N. Troullier, K. Wu, and Y. Saad, Phys. Rev. B 50, 11355 (1994).

[6] E. L. Briggs, D. J. Sullivan, and J. Bernholc, Phys. Rev. B 54, 14362 (1996).

[7] J. Bernholc, E. L. Briggs, D. J. Sullivan, C. J. Brabec, M. Buongiorno Nardelli, K.

Rapcewicz, C. Roland, and M. Wensell, Intl. J. Quantum Chem. 65, 531 (1997).

[8] K. Iyer, M. P. Merrick, and T. L. Beck, J. Chem. Phys. 103, 227 (1995).

[9] J. Wang and T. L. Beck, J. Chem. Phys. 112, 9223 (2000).

[10] T. L. Beck, in Multiscale Computational Methods in Chemistry and Physics, ed. A.

Brandt, J. Bernholc, and K. Binder (IOS Press, Amsterdam, 2001).

[11] M. Heiskanen, T. Torsti, M. J. Puska, and R. M. Nieminen, Phys. Rev. B 63, 245106

(2001).

[12] F. Ancilotto, P. Blandin, and F. Toigo, Phys. Rev. B 59, 7868 (1999).

[13] T. Hoshi and T. Fujiwara, J. Phys. Soc. Jpn. 66, 3710 (1997).

[14] I.-H. Lee, Y.-H. Kim, and R. M. Martin, Phys. Rev. B 61, 4397 (2000).

[15] N. A. Modine, G. Zumbach, and E. Kaxiras, Phys. Rev. B 55, 10289 (1997).

[16] J.-L. Fattebert, J. Comput. Phys. 149, 75 (1999).

[17] J.-L. Fattebert and J. Bernholc, Phys. Rev. B 62, 1713 (2000).

[18] E. Tsuchida and M. Tsukada, J. Phys. Soc. Jpn. 67, 3844 (1998).

[19] C. M. Goringe, E. Hern´andez, M. J. Gillan, and I. J. Bush, Comput. Phys. Commun.

102, 1 (1997).

[20] J. E. Pask, B. M. Klein, C. Y. Fong, and P. A. Sterne, Phys. Rev. B 59, 12352 (1999).

[21] T. A. Arias, Rev. Mod. Phys. 71, 267 (1999).

10

[22] S. Goedecker, Rev. Mod. Phys. 71, 1085 (1999).

[23] T. L. Beck, J. Comput. Chem. 20, 1731 (1999).

[24] A. Brandt, S. F. McCormick, and J. Ruge, SIAM J. Sci. Stat. Comput. 4, 244 (1983).

[25] S. Costiner and S. Ta’asan, Phys. Rev. E 51, 3704 (1995).

[26] S. Costiner and S. Ta’asan, Phys. Rev. E 52, 1181 (1995).

[27] A. Brandt, Math. Comput. 31, 333 (1977).

[28] W. Hackbusch, Multigrid Methods and Applications (Springer-Verlag, New York, 1985).

[29] N. Wijesekera, G. Feng, and T. L. Beck (in preparation).

[30] S. Goedecker, M. Teter, and J. Hutter, Phys. Rev. B 54, 1703 (1996).

[31] C. Hartwigsen, S. Goedecker, and J. Hutter, Phys. Rev. B 58, 3641 (1998).

[32] R. D. King-Smith, M. C. Payne, and J. S. Lin, Phys. Rev. B 44, 13063 (1991).

11

2λ

T able 1 Ritz result
No.
r
1 18.71847149 3.3E − 11
2 48.18927363 4.1E − 09
3 51.56004355 5.0E − 12
4 81.07201016 2.8E − 11
5 97.00117915 9.6E − 09
6 99.57484220 1.2E − 08
7 129.1084354 1.7E − 06
8 129.8996943 2.5E − 07

Ref. [24]
λ

18.71847149
48.18927363
51.56004355
81.07201016
97.00117915
99.57484220
129.1084354
129.8996943

Table 1: Comparison of eigenvalues to results of Ref. [24].

12

Wfs
(wf0*wf0)
(wf0*wf2)
(wf0*wf3)
(wf1*wf2)
(wf1*wf3)
(wf2*wf3)
(wf0*wf4)
(wf1*wf4)
(wf2*wf4)
(wf3*wf4)

CO
GS
1.0e+00
-1.4e-17
-6.2e-18
-1.7e-17
3.0e-17
9.5e-17
-1.9e-18
-2.4e-18
-1.3e-19
-5.1e-19

GRBR GRBR+GS
1.0e+00
-7.3e-07
3.9e-07
1.7e-06
-5.0e-07
-5.9e-04
2.9e-08
2.1e-08
-1.4e-07
4.4e-08

1.0e+00
-5.6e-08
-1.9e-08
-6.9e-09
9.3e-08
1.2e-06
2.9e-09
3.4e-08
4.0e-07
3.8e-09

Ne
GS
1.0e+00
-3.4e-17
5.0e-18
1.3e-16
-1.8e-18
7.4e-18
-
-
-
-

GRBR GRBR+GS
1.0e+00
-1.2e-07
-4.6e-07
2.0e-05
-2.7e-04
-2.8e-05
-
-
-
-

1.0e+00
9.3e-16
2.2e-12
-6.0e-11
7.8e-10
6.9e-11
-
-
-
-

Table 2: A sample of dot products of wavefunctions of CO and Ne are shown. Column GS
includes products when the Gram-Schmidt orthogonalization was performed and it serves
only as a reference. The column GRBR includes the products as a result of GRBR only and
the wavefunctions are not fully separated. The column GRBR+GS includes the products
when Gram-Schmidt orthogonalization was perfomed at a regular interval (5,10,15 V-cycles
only). The separation of wavefunctions is improved. The total number of V-cycles perfomed
was 20.

13

−2

−4

−6

−8

)

|

t
c
a
x
e

i

E
−
E

i

|

(
g
L

−10

0

Ritz
GRBR+GS
GRBR

5
Number of Vcycle

10

15

Figure 1: Convergence rates for diﬀerent methods in a ﬁxed harmonic oscillator potential.
Long dashed lines are the results of the Ritz method on the ﬁne grid, the solid lines are
results of the GRBR method on the coarsest level, and the dotted lines with diamonds are
results of the GRBR method on the coarsest level with additional periodic Gram-Schmidt
orthogonalization on the ﬁne grid.

14

 
 
 
 
 
 
0

−2

−4

−6

−8

−10

0

)

|

t
c
a
x
e

i

E
−
E

i

|

(
g
L

Ritz
GRBR+GS
GRBR

5
Number of Vcycle

10

15

Figure 2: Convergence rates for diﬀerent methods in a ﬁxed hydrogen atom potential. Long
dashed lines are the results of the Ritz method on the ﬁne grid, the solid lines are the results
of the GRBR method on the 333 grid, and the dotted lines with diamonds are results of the
GRBR method on the 173 grid with additional periodic Gram-Schmidt orthogonalization on
the ﬁne grid.

15

 
 
 
 
 
0

−2

−4

−6

−8

−10

0

)

|

t
c
a
x
e

T
E
−
T
E

|

(
g
L

Ritz
GRBR+GS
GRBR

5

10
Number of Vcycle

15

20

Figure 3: Convergence rate for Ne. The logarithm (base 10) of the diﬀerence between
the current and fully converged total energies is plotted against the number of V-cycles
(self-consistency steps). Ritz and GRBR stand for ﬁne-grid Ritz projection and coarse-grid
generalised Ritz projection, respectively. GRBR-GS is for GRBR with ﬁne-grid Gram-
Schmidt orthogonalization performed at 3 V-cycles (5,10,15). The ﬁne grid spacing used
was h=0.178437.

16

 
 
 
 
 
0

−2

−4

−6

−8

−10

0

)

|

t
c
a
x
e

T
E
−
T
E

|

(
g
L

Ritz
GRBR+GS
GRBR

5

10
Number of Vcycle

15

20

Figure 4: Convergence rate for CO. The logarithm (base 10) of the diﬀerence between
the current and fully converged total energies is plotted against the number of V-cycles
(self-consistency iterations). Ritz and GRBR stand for ﬁne grid Ritz projection and coarse-
grid generalized Ritz projection with backrotation, respectively. GRBR-GS is for coarse-
grid GRBR with Gram-Schmidt orthogonalization performed on the ﬁne grid at 3 V-cycles
(5,10,15). The ﬁne grid spacing used was h=0.178437.

17

 
 
 
 
 
0

−2

−4

−6

−8

−10

0

)

|

t
c
a
x
e

T
E
−
T
E

|

(
g
L

Ritz

5

10
Number of Vcycle

15

20

Figure 5: Convergence rate for benzene dithiol. The logarithm (base 10) of the diﬀerence
between the current total energy and the fully converged value is plotted against the number
of V-cycles (self-consistency iterations). Only the ﬁne grid Ritz projection case is shown.
The ﬁne grid spacing used was h=0.3.

18"
Synthesis and Laser Processing of ZnO Nanocrystalline Thin Films,"  We present the results of experiments on synthesis of ZnO nanoclusters by
reactive pulsed laser deposition (PLD). The nanoclusters were formed and
crystallized in the gas phase and deposited on SiO2 substrates. The
nanostructured films were characterized by conventional photoluminescence (PL).
The PL spectra consist of a narrow UV excitonic band and a broad visible band
related to defects in the film. The film preparation conditions such as the
substrate temperature, ambient gas nature and pressure, were optimized in order
to increase the intensity of excitonic emission and prevent the formation of
defects. A post-growth annealing by UV laser radiation improved the optical
quality of the deposited films. The photoluminescence intensity was found to be
dependent significantly on the laser fluence and on the number of shots per
site. The nature of the defects responsible for the observed luminescence in a
visible range is discussed.
",http://arxiv.org/pdf/cond-mat/0311315v1,3,"TH.B 9.45 O 

Synthesis and Laser Processing of ZnO Nanocrystalline Thin Films 

I. Ozerov1, D. Nelson2, A.V. Bulgakov3, W. Marine*1, and M. Sentis4 

1 GPEC, UMR 6631 CNRS, 13288 Marseille, France. 

2 A.F. Ioffe Physico-Technical Institute, St.-Petersburg, Russia. 

3 Institute of Thermophysics, Novosibirsk, Russia. 

4LP3, FRE 2165 CNRS, Marseille, France. 

*Tel : +33 4 91 82 91 73, Fax : +33 4 91 82 91 76, E-mail : marine@gpec.univ-mrs.fr 

Abstract 

We present the  results of  experiments on  synthesis of ZnO nanoclus ters by reactive 

pulsed laser deposition (PLD). The nanoclusters were formed and crystallized in the gas phase 

and deposited on 

SiO2  substrates.  The nanostructured films were characterized by 

conventional photoluminescence (PL). The PL spectra consist of a narrow UV excitonic band 

and a broad visible band related to defects  in the film .  The film preparation conditions such  

as  the  substrate temperature, ambient gas  nature  and   pressure,  were optimized  i n order to 

increase the intensity of excitonic emission and prevent the formation of defects

.    A  post-

growth annealing by UV laser  radiation improved the optical quality of the  deposited films. 

The photoluminescence intensity was found to be  dependent significantly on the laser fluence 

and  on the   number of shots   per site . The nature of the defects 

responsible for the observed 

luminescence in a visible range is discussed. 

PACS : 

81.15.Fg; 81.05.Ys; 78.55.Et; 61.80.Ba 

Keywords: Zinc oxide, nanoclusters, laser ablation, photoluminescence, laser annealing 

1 

 
 
 
Introduction 

New applications   in optoelectronics stimulate d the research on materials for short 

wavelength emitting  devices. ZnO is a semiconductor with  a wide direct band gap (3.37 eV) 

and large exciton binding energy (60 meV). Exciton lasing from ZnO films at room 

temperature was reported recently [1]. Moreover,  the efficient mirrorless laser emission with 

the optical feedback created by multiple light scattering (random lasing)  was observed in zinc 

oxide microparticles [2].  To synthesize a lasing  material for a random laser it is necessary to 

produce defect free films with strong excitonic emission, large coef ficient of amplification of 

spontaneous emission, and strong multiple scattering [2]. The nanocrystalline ZnO films 

potentially possess all these features. 

Recently, we showed that 

pulsed laser ablation  and the following cluster assisted 

deposition  is an efficient method 

for formation 

of nanocluster s and  synthesis 

of 

nanocrystalline films. By varying the experimental conditions it is possible to control the film 

thickness, cluster sizes and their composition 

[3]. The main features of pulsed laser 

deposition are the chemical purity, low substrate temperatures,  and a  possibility to improve 

the stoichiometry by introducing a reactive atmosphere. 

In this paper we present the optical properties of laser deposited 

ZnO  films and 

characterize the films by conventional photoluminescence (PL). The PL spectra co nsist of a 

narrow exitonic band and a large defect

-related band.  We have optimized the preparation 

conditions and annealed the films by UV laser in order  t

o increase the intensity of the 

excitonic band and decrease the defect

-related emission . The visible luminescence band 

resulted  from the transitions between 

the  deep levels corresponding to 

the  different local 

configurations of oxygen in the films [4, 5]. 

2 

 
 
 
Experimental 

The si ntered pure ZnO target was placed on a rotating holder inside a stainless steel 

vacuum chamber evacuated by a turbomolecular pump.

 A continuous flux of oxygen  mixed 

with helium at variable ratios  was introduced into the  chamber as an ambient  after pumping 

the chamber down to about 2 · 10-7 mbar. The substrate was placed in front of the target on a 

holder equipped with a heater, allowing variation of substrate temperature in the range of 20 –  

500 °C. The ablation was performed by a pulsed ArF

 laser (l =193 nm, pulse duration 15 ns, 

FWHM) at a fluence level  of 3.5 J/cm 2. The laser beam was focused onto the target with an 

incident angle of 45

. The  PL  of deposited films was excited by a Hg lamp with 

the 

wavelength of 254 nm and 

detected by a cooled photomultiplier

 linked to 

a grating 

monochromator. 

We  have ut ilized the same pulsed laser  for laser annealing  as for the film deposition. 

The laser beam was shaped by  apertures and focused on the film surface  at normal incidence 

into a rectangular spot of 18 mm2. 

Results and discussion 

The  nanocluster  size distributions  were studied  by  using Atomic Force Microscopy 

(AFM) in  a tapping mode. The quantity of clusters inferior to one monolayer was deposited 

on an atomically plane surface of highly ordered p yrolytic graphite (HOPG).  We concluded 

from  high resolution transmission electron microscopy observation

s  that most of the 

nanoparticles have  a  near spherical shape .  The nanoparticle 

lateral  size could not be 

determined from the AFM measurements due to the convolution of an object and the AFM tip 

shapes. Contrarily, the height of  the object gives the correct size if  a flat surface  is used as  a 

reference. Fig. 1  s hows the size histogram of ZnO particles prepared on cleaved HOPG 

surface. We have  presented the size statistics of about 150 nanoclusters deposited on an area 

3 

 
*
o
 
of about 10  m m². The size distribution is narrow and can be described by Gaussian f unction 

with a maximum at 10 nm and a half width of 3 nm.  

The sample quality has been characterized by the absolute luminescence intensity and 

by the ratio of excitonic to defects band intensities.  The substrate temperature and the oxygen 

pressure were fi rst optimized in order to prepare the films of the best quality . The quality of 

samples was found to be improved with the increase of the substrate temperature. However, to 

prevent the  coalescence of clusters and their recrystallisation on the substrate surface, the 

temperature of 385 °C has  appeared to be  optimal. The films prepared in 4 mbars of oxygen 

show the best quality . If the pre ssure is lower, the oxygen amount is insufficient to improve 

the films stoichiometry. Higher pressures strongly reduce the deposition rate and 

affect 

considerably the cluster growth process that leads to the formation of defects. 

In Fig. 2 we present PL spectra of ZnO nanocrystalline films prepared on 

SiO2 

substrates heated up to 385°C. Helium partial pressure was the only variable parameter in this 

series of experiments. Fi g. 2a shows  a spectrum of the film prepared in pure oxygen without 

adding helium. This spectrum consists of two principal bands: a narrow UV peak of ZnO free 

excitons centered at photon energy of 3.28 eV with 0.1 eV FWHM , and a large visible b and 

with maximum intensity at 2.0 - 2.4 eV related to deep defect levels. 

Adding 1 mbar of He during the film preparation  led to significant decrease of intensity 

of the defect -related band (Fig. 2b).  We could also  notice the increas e of the  excitonic to 

defect bands  ratio of intensit y, i.e.  an improvement of the film optical quality. The position 

and the width of the excitonic peak remain the same as for  the films prepared in pure oxygen. 

The best optical quality (strong exciton luminescence  combined with a negligible defect band 

intensity) was achieved in a gas mixture with the partial helium pressure of 1.5 mbar (Fig. 2c). 

We believe that the observed  PL behavior is due to  a more efficient cooling of the  gas phase 

nanoclusters through collisions with He molecules. Further augmentation of the He pressure 

4 

 
up to 2 mbars led to decrease of absolute luminescence intensity (Fig. 2d). This  was probably 

related to the fact that the total pressure in the preparation chamber  was fairly high and  thus 

less amount of clusters reached the substrate. 

The obtained optimal ablation conditions ( the fluence 3.5 J/cm², the gas mixture 4 mbar 

O2, 1.5 mbar He) were used to produce films without heating the substrate. Typical PL spectra 

are presented in Fig. 3. For 

the  as-deposed film, the exciton band 

is  very weak and only 

defect-related band with  a  maximum at about 2 eV 

is  observed (Fig. 3a). To improve the 

quality of the films we have performed annealing by the excimer laser. The PL spectra 

obtained  after annealing  the films   by 30 laser shots  with  various  fluences are presented in 

Figs. 3b-d. 

It can be seen that annealing  led to the increase of the exciton band intensity but  did not 

affect neither its spectral position nor its shape. Contrarily, the position of the defect

-related 

band shifted to the blue side of the spectrum.  

Various mechanisms have been proposed for  the orange and  the green luminescence of 

ZnO. The orange band centered at 2 eV was observed in ZnO films with local excess of 

oxygen [5], and the green  band at 2.4 eV is  a well-known in ZnO and associated  with oxygen 

vacancies [4, 5]. It should be noted that the maxim

um  used  fluence  of 140 mJ/cm ², 

corresponds to  melting of ZnO surface .  The annealing with fluences above the melting 

threshold changed the film morphology radically and resulted in coalescence of nanoclusters 

to a size of 40 -60 nm [6].  The results presented in Fig. 3b and 3c correspond to annealing in 

the solid phase  at sub -threshold fluences. Even for relatively low fluences, the augmentation 

of the number of laser shots  reduced the intensity of the orange band and  increased the green 

one. The excess of oxygen incorporated on the surface of clusters during  film preparation can 

be easily removed by laser. It explains the decrease in intensity of the orange band. At the 

same time, the photons of 6.4 eV energy can break chemical bonds and create 

oxygen 

5 

 
vacancies. This leads to increase in intensity of the  green band.  Once the green luminescent 

band obt ained, it  remained  very stable. The increase in 

the  number of shots or  in  the  laser 

fluence did not affect the spectral position but only increased the intensity of this band. 

Conclusion 

We have developed the cluster -assisted pulsed laser deposition method  in a mixed O 2-

He background gas atmosphere  to form the nanocrystalline ZnO films.  The nanoclusters are 

formed in the gas phase and have a narrow size distribution. The films prepared with 

the 

optimized substrate temperature and gas 

partial  pressures  have  an  intense UV excitonic 

luminescence and  a weak defect-related band.  We have demonstrated that the  optical quality 

of films prepared with reduced substrate temperature  can be improved by UV laser annealing. 

We  have  shown possible ways to control the defect

-related luminescence  by changing  the 

local amount of oxygen in the films. 

6 

 
 
References 

1. Z.K. Tang, G.K.L. Wong, P. Yu, M. Kawasaki, A. Ohtomo, H. Koinuma, and Y. Segawa, 

Appl. Phys. Lett., 72, 3270 (1998). 

2. H. Cao, Y.G. Zhao, H.C. Ong, S.T. Ho, J.Y. Dai, J.Y. Wu, and R.P.H. Chang, Appl. Phys. 

Lett., 73, 3656 (1998). 

3. W. Marine, L. Patrone, B. Luk’yanchuk, M. Sentis, Appl. Surf. Sci., 154– 155, 345 (2000). 

4. K. Vanheusden, W. L. Warren, C. H. Seager, D. R. Tallant, J. A. Voigt, and B. E. Gnade, J. 

Appl. Phys. 79, 7983 (1996). 

5. S. A. Studenikin, N. Golego, and M. Cocivera, J. Appl. Phys. 84, 2287 (1998) 

6. I. Ozerov, D. Nelson, W. Marine, To be published elsewhere. 

7 

 
 
 
 
 
 
 
 
Figure captions: 

Fig 1. Size histogram of ZnO particles prepared on HOPG surface. 

The laser  fluence 

was 3.5 J/cm ²;    the  gas  mixture  was  4 mbar  O 2 and 1.5 mbar He.  A solid  line is  a  fit with   

Gaussian distribution with the mean cluster size of 10 nm and dispersion of 3 nm. 

Fig 2. The photoluminescence spectra of ZnO nanocrystalline films prepared on SiO 2 

substrate at temper ature of 385 °C. The laser  fluence was 3.5 J/cm ². The oxygen  and helium 

partial pressures were 4 mbar and: a) 0 mbar; b) 1 mbar; c) 1.5 mbar; and d) 2 mbar, 

respectively. 

Fig 3. The photoluminescence spectra of ZnO nanocrystalline films prepar

ed on SiO 2 

substrate at room temperature.  The laser  fluence was 3.5 mJ/cm ².  The oxygen  and helium 

partial pressures were 4 mbar and 1.5 mbar respectively ; a) as-prepared film; b)  annealed by 

30 shots of ArF laser with  the fluence F = 0.075 J/cm² ; c) F = 0.094 J/cm ²; d) F = 0.14 J/cm². 

The spectra were shifted vertically for sake of clearness. 

8 

 
 
 
 
)
.

.

u
a
(

s
r
e
t
s
u
c

l

f
o
r
e
b
m
u
N

20

15

10

5

0

Mean Size: (10 ±  3) nm

5

10
Cluster Size (nm)

15

Fig 1. 

9 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
)
.
u
.
a
(

y
t
i
s
n
e
t
n
I
L
P

P

He

 = 0 mbar

P

He

 = 1 mbar

P

He

 = 1.5 mbar

P

He

 = 2 mbar

(a)

(b)

(c)

(d)

2.0

2.5

3.0

3.5

Photon Energy (eV)

Fig 2. 

10 

 
 
 
 
 
 
 
 
 
)
.
u
a
(

.

y
t
i
s
n
e
t
n
I

L
P

1.5

1.0

0.5

0.0

TSubstrate=20oC
 = 4 mbar
PO
 = 1.5 mbar
P

2

He

(d)
(c)
(b)

(a)

2.5

2.0
3.5
Photon Energy (eV)

3.0

Fig 3. 

11"
"Electronic mechanism of ion expulsion under UV nanosecond laser
  excitation of silicon: Experiment and modeling","  We present experimental and modeling studies of UV nanosecond pulsed laser
desorption and ablation of (111) bulk silicon. The results involve a new
approach to the analysis of plume formation dynamics under high-energy photon
irradiation of the semiconductor surface. Non-thermal, photo-induced desorption
has been observed at low laser fluence, well below the melting threshold. Under
ablation conditions, the non-thermal ions have also a high concentration. The
origin of these ions is discussed on the basis of electronic excitation of Si
surface states associated with the Coulomb explosion mechanism. We present a
model describing dynamics of silicon target excitation, heating and
harge-carrier transport.
",http://arxiv.org/pdf/cond-mat/0403330v2,3,"4
0
0
2

r
a

M
4
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
0
3
3
3
0
4
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Applied Physics A (2004) accepted

Electronic mechanism of ion expulsion
under UV nanosecond laser excitation of silicon:
Experiment and modeling

Wladimir Marine,1, ∗ Nadezhda M. Bulgakova,2, † Lionel Patrone,1 and Igor Ozerov1, ‡
1Groupe de Physique des ´Etats Condens´es (GPEC),
UMRS 6631 CNRS, Universit´e de la M´editerran´ee, Case 901,
163 Avenue de Luminy, 13288 Marseille Cedex 9, France
2Institute of Thermophysics, Prospect Lavrentyev 1, 630090 Novosibirsk, Russia
(Dated: November 10, 2018)

We present experimental and modeling studies of UV nanosecond pulsed laser desorption and
ablation of (111) bulk silicon. The results involve a new approach to the analysis of plume formation
dynamics under high-energy photon irradiation of the semiconductor surface. Non-thermal, photo-
induced desorption has been observed at low laser ﬂuence, well below the melting threshold. Under
ablation conditions, the non-thermal ions have also a high concentration. The origin of these ions
is discussed on the basis of electronic excitation of Si surface states associated with the Coulomb
explosion mechanism. We present a model describing dynamics of silicon target excitation, heating
and charge-carrier transport.

PACS numbers: 52.38.Mf, 68.34.Tj, 68.35.Rh, 79.20.Ds
Keywords: Silicon; Surface; Charge; Ablation; Desorption; Non-thermal ions; Coulomb explosion

I.

INTRODUCTION

(the Coulomb explosion mechanism).

Laser ablation technique has been widely used for thin
ﬁlm deposition and nanoparticles synthesis. For these ap-
plications, understanding of dynamics and mechanisms
of particle desorption and ablation from the irradiated
surfaces is of crucial importance. For nanosecond laser
pulses, it is generally accepted that the ablation mech-
anism of normal vaporization gives way to phase explo-
sion with increasing laser ﬂuence [1]. At low laser ﬂu-
ences near ablation threshold, electronic mechanism of
high-energy ion emission has been proven to play a role
in initiating the ablation process, mainly for dielectrics
and semiconductors [2, 3]. For ultrashort laser pulses,
the electronic mechanisms of desorption [4] and ablation
[5, 6] for both dielectric and semiconductor targets are
studied extensively, whereas for nanosecond pulses there
is a lack of both the experimental and theoretical analy-
ses.

In this paper, we present the results of the experi-
mental and theoretical studies of ion ejection from the
Si targets induced by UV nanosecond laser pulses in a
wide range of laser ﬂuences in the regimes from those
well below melting threshold up to developed ablation.
Non-thermal ions have been detected at very low laser
ﬂuence. The theoretical study of ion ejection involves
an analytical analysis and numerical modeling of charge
transport in the laser-irradiated target. We attribute the
high-energy ion emission to the generation of a strong
electric ﬁeld due to the electron photoemission process

∗Electronic address: marine@crmcn.univ-mrs.fr
†Electronic address: nbul@itp.nsc.ru
‡Electronic address: ozerov@crmcn.univ-mrs.fr

II. EXPERIMENTAL

Clean (111) Si surface was passivated by hydrogen in a
usual chemical way [7]. Ablation was carried out in a high
vacuum chamber (pressure < 10−8 Torr) at an incidence
angle of 45˚ using an ArF excimer laser (hν = 6.4 eV,
15 ns pulse duration at FWHM). The set of masks was
used to select the homogeneous part of the laser beam.
The laser spot size on the target and laser ﬂuence (F0)
were 0.5 mm2 and 0.01 − 1 J/cm 2, respectively. The
target was rotated/translated during measurements to
avoid cratering. The expansion dynamics and origin of
the desorbed particles were analyzed by reﬂectron time-
of-ﬂight (TOF) mass spectrometer.

The most abundant desorbed species, Si+, are ob-
served already at F0 ∼ 0.2 J/cm2, well below melt-
ing threshold determined by time-resolved reﬂectivity
measurements to be ∼ 0.4 J/cm2 (see [8] and refer-
ences therein) that is consistent with the other studies
[9, 10]. Neutral monatomic Si particles are detected
only at F0 > 0.8 J/cm2. Attempts to detect charged
or neutral clusters, excepting silicon ions dimmer [11],
have been unsuccessful. Figure 1 shows the typical TOF
spectra of Si+ at diﬀerent ﬂuences. At low laser ﬂuence
(0.26 J/cm2on the Fig. 1, the TOF spectrum consists
of an only population of Si+ ions. The spatial distri-
bution of this kind of ions is narrow, strongly peaked
relatively to the target normal and, up to the melting
threshold, the kinetic energy (∼ 4.8 − 5 eV) is a weak
function of laser ﬂuence that is typical for non-thermal
desorption/ablation [3, 12].

Increasing laser ﬂuence above the melting threshold
leads to broadening of Si+ TOF distribution (see Fig. 1,

 
 
 
 
 
 
)
.
u

.

a
(

y
t
i
s
n
e
n

t

I

l

a
n
g
S

i

i

S

+

50

40

30

20

10

0

)
e
s
u
p

l

/

s
n
o
r
t
c
e
e
(

l

e
g
r
a
h
C

t

e
g
r
a
T

1E13

1E12

1E11

0.01

0.1

1

 Laser Fluence (J/cm

)

2

X100

0

50

100

150

Time-of-Flight ((cid:181)s)

FIG. 1: Time-of-ﬂight spectra of Si+ ions for diﬀerent laser
ﬂuences:
open circles – 0.26 J/cm2 intensity (multiplied by 100);
dark triangles – 0.42 J/cm2;
open triangles – 1.02 J/cm2.
The target - mass spectrometer distance was 126 mm.
Inset shows charge of silicon target versus laser ﬂuence.

I ~ F0

0.97

]
.
n
u
.
b
r
a
[
d
e
y
n
o
I

i

l

1000

100

10

1

0.1

I ~ F0

10.4

Laser fluence [J/cm2]

1

FIG. 2: Experimental data on Si+ yield vs.
laser ﬂuence.
0.2 J/cm2 corresponds to the ion desorption threshold. Up
to ∼0.4 J/cm2 that is around melting threshold, ion yield be-
haves as F 10.4
whereas at higher ﬂuence dependence changes
to F 0.97
. Solid curve corresponds to Eq. (6) with F0th = 0.2
0
J/cm2.

0

2

0

ﬂuence 0.42 J/cm2) and to formation (from 0.7 − 0.8
J/cm2) of a well-pronounced low-energy distribution [13].
The appearance of the low-energy Si+ concurs with the
development of Si surface melting. The intensity of this
population rapidly increases with ﬂuence and becomes
dominant at F0 > 1 J/cm2. The abundance of Si+
species versus laser ﬂuence (Fig. 2, experimental points)
shows an abrupt change in the behavior of the exper-
imental data that can be treated as the change of the
ejection regime. The ﬁrst regime, corresponding to the
generation of the fast population, exhibits a very strong
non-linear dependence on ﬂuence, F 10.4
, that is a typi-
cal feature of the multi-particle ejection process [3]. The
second regime, starting after melting, shows near-linear
Si+ abundance variation with ﬂuence.

The expulsion of the non-thermal Si+ ions is attributed
to accumulation of a positive charge on the silicon sur-
face as a result of electron photoemission. This charge
has been evaluated by measuring a compensating current
variation between the Si target and ground [14] during
laser pulse. The positive charge is accumulated already
at ∼ 0.001 J/cm2 (see inset on Fig. 1), increasing near
linearly up to a saturation level of (1−2)·1013 elementary
charges per pulse at ∼ 0.15 − 0.2 J/cm2. Exactly at these
ﬂuences we detect the ﬁrst non-thermal ions. Both the
target charge saturation and ions ejection clearly indicate
that Si surface reaches the critical, threshold, conditions
corresponding to dynamical equilibrium between primary
particles ejection (photoelectrons) and desorption of the
secondary species (positively charged ions).

An assumption for the electron photoemission under
the UV laser irradiation, when photon energy exceeds
work function, reads as

P E =

1
2

αab

I(x, t)
hv

exp

−

(cid:18)

x
lP E (cid:19)

(1)

where I(x,t) is the laser power of a Gaussian temporal
shape:

I(x, t) = (1 − R)

2F0
τ r

ln 2
π

exp

−4 ln 2

t
τ

(cid:18)

(cid:19)

2

e−αabx,

!

(2)
τ is laser pulse duration (FWHM), αab and R are the
absorption and reﬂection coeﬃcients, lP E is the electron
escape depth, x is the distance from the target surface to-
ward the bulk depth, hv is the energy of laser light quan-
tum. The expression (1) implies that the laser-generated
electrons whose momentum component normal to and in
the direction of the surface are immediately photoemit-
ted from the surface and below surface region with an
exponential decreasing within the bulk [5].

A.(F0-0.2)

III. MODELING

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3

An estimate of the number of electrons photoemitted through a unit surface area (NP E) is obtained by integrating

the photoemission term over time and space that gives:

NP E =

αab(1 − R)F0
2hν(αab + l−1
P E)

(3)

Under the assumption that the target is unearthed and there is no electron supply from the radiation-free sides of
the target, the electric ﬁeld generated on the target surface can be estimated by using the Gauss law (the net positive
charge of the target is equal to the charge of the photoemitted electrons):

E|x=0 =

1
2εε0

L

Z0

q(x)dx =

eNP E
2εε0

=

eαab(1 − R)F0
4εε0hν(αab + l−1
P E)

,

(4)

where L is the target width and ε is dielectric permittivity of bulk silicon.

The threshold electric ﬁeld necessary to be exceeded in order to break the atomic bonds in crystalline silicon can
be estimated through the energy density of the electric ﬁeld, w = εε0E2/2. The value Wat = εε0E2/2n falls at an
atom in the crystal, where n−1 is a volume occupied by atom. The binding energy of an atom on the target surface
estimated from the latent heat of sublimation, Λsub = 16115 J/g [7], is ≈ 4.67 eV. Thus, the threshold electric ﬁeld
2Λatn/εε0 or Eth ≈ 2.65·1010 V/m for crystalline silicon. Laser ﬂuence above which the
is of order Eth|x=0 =
non-thermal ions can be observed is:

p

F0th =

4εε0hνEth

αab + l−1
P E

eαab(1 − R)
(cid:0)

.

(cid:1)

(5)

With lP E ∼ 10 ˚A it gives ∼ 0.13 J/cm2 that is in good agreement with the experimental observations. The excess
of positive charge in the target for generation of the threshold electric ﬁeld is eNIth = 2 εε0SREth|x=0 or ∼ 1.8 · 1013
electrons escaped from the irradiation spot size SR of 0.5 mm2 that is in excellent agreement with the measured
electric residue.

A strongly charged target tends to take oﬀ the electrostatic stress, decreasing the electric ﬁeld below its threshold
value through ion expulsion. The number of ions thrown out from the target by the electrostatic force can be evaluated
as

Nexp|SR = NI − NIth =

αab(1 − R)(F0 − F0th)SR
2hν(αab + l−1
P E)

(6)

or 1.4·1014(F0 − F0th) for our irradiation conditions (laser ﬂuence is taken in J/cm2). This dependence follows the
general tendency observed experimentally (Fig. 2, solid line). Thus, a seeming change in the ablation regime from
laser ﬂuence can be roughly described by a shifted
the strong non-linear to near-linear dependence of ion yield vs.
linear dependence [Eq. (6)].

More sophisticated description can be reached by modeling the electron dynamics in the laser-irradiated semicon-
ductor targets. Here we shall consider only the target charging eﬀect without concerning the ion ejection process, both
electrostatic and thermal. Our model is based on the continuity equations for electron and hole generation, including
one-photon ionization, Auger recombination and the photoemission process according to Eq. (1), and we incorporate
the electric current Jy(y = e, h) = |e| nyµE − eD∇ny written in the drift-diﬀusion approach into the equations:

∂ne
∂t

− µene

e
εε0

(nh − ne) − µeE

∂ne
∂x

−

∂
∂x

De

∂ne
∂x

= αab

I(x, t)
~ω

− γn2

enh − P E,

∂nh
∂t

+ µhnh

e
εε0

(nh − ne) + µhE

∂nh
∂x

−

∂
∂x

Dh

∂nh
∂x

= αab

I(x, t)
~ω

− γn2

enh.

(7)

(8)

Here n, µ, D, γ are the density, mobility and the diﬀusion and Auger recombination coeﬃcients, respectively; indices
e and h refer to the electrons and holes. The diﬀusion coeﬃcients are calculated as De = kBTeµe/e and Dh = kBTeµh/e

with the carrier temperature Te. The photoemission and diﬀusion lead to charge separation in the target that results
in the electric ﬁeld generation described by the Poisson equation with the boundary condition according to the Gauss
law. The energy equations for the electron and lattice subsystems [15] degenerate into an only equation at fairly long
laser pulses of ns time scale [16, 17]

4

cpρ

∂T
∂t

(cid:18)

− u(t)

∂T
∂x

(cid:19)

=

∂
∂x

λ

∂T
∂x

+ αab(1 − R)I0(t) exp(−αabx).

(9)

The vaporization rate u(t) is deﬁned under the assump-
tion that the ﬂow of vaporized material from the surface
follows the Hertz-Knudsen equation and the vapor pres-
sure above the vaporized surface can be estimated with
the Clausius-Clapeyron equation:

u(t) = (1 − β)

pb
ρ

1/2

m
2πkTs (cid:19)

(cid:18)

exp

L
k

(cid:20)

(cid:18)

1
Tb

−

1
Ts (cid:19)(cid:21)

,

(10)
Thermodynamic and optical properties of silicon (spe-
ciﬁc heat cp, thermal conductivity λ, latent heat of vapor-
ization L, boiling temperature Tb, absorption coeﬃcient
αab, and reﬂection coeﬃcient R) were taken from Ref.
[9]. The initial and boundary conditions are

3
-

]

m
c
[

n

,

n

e

i

22

10

21

10

20

10

19

10

18

10

17

10

16

10

15

10

14

10

13

10

1

10

100

Distance [nm]

T (0, x) = T0, T (t, 0) = Ts(t), λ

∂T
∂x

= Lu(t) (11)

x=0

FIG. 3: Calculated spatial proﬁles of the electron (dashed
line) and ion densities (solid line) in the Si target irradiated
with 0.2 J/cm2.

(cid:12)
(cid:12)
(cid:12)
(cid:12)

with T0 being the initial temperature uniform across the
target. The target was divided into an irregular grid,
dense in the absorption region (cells of 5 ˚A) and rarefying
toward the target depth. We used an explicit scheme for
solving the described system of equations. The time step
was selected empirically to satisfy the numerical scheme
stability and the approximation of the original equations.

IV. RESULTS AND DISCUSSION

The modeling results are presented in Figs. 3, 4. To
the end of the laser pulse, the surface charge reaches al-
most 60%, an unexpected value for silicon irradiated by
low laser ﬂuence. The densities of the electrons and holes
are presented in Fig. 3. Considerable charging takes
place in a surface zone of order of 2 nm wide (∼ 5 − 6
atomic monolayers). It is generally agreed that, because
of eﬃcient Auger recombination, a silicon target can not
be ionized to a high ionization degree at moderate laser
ﬂuences. That is a major argument against the Coulomb
explosion mechanism. Our modeling shows that a thin
surface layer of the target reaches a high ionization de-
gree, but therewith this layer occurs to be strongly de-
pleted of electrons. Extremely high density of positive
charge is gained in a few monolayers, implying the strong
repulsion force between the ions. First of all, adatoms,
which have lower binding with surface, have to be ejected
from the surface, giving way to the generation of new
adatoms. The process of ion expulsion will take place till

all the layer of high positive charge is exploded or till the
macroscopic electric ﬁeld is reduced below the threshold
value. Figure 4 illustrates that, at 0.2 J/cm2, the macro-
scopic electric ﬁeld exceeds the threshold value, as it was
predicted analytically. The values of charging and the
electric ﬁeld in two external monolayers are so high, that
their electrostatic explosion is inevitable.

Let us consider the origin of high surface charging of
a silicon target in detail. What is happening when a
target subjected to laser irradiation loses the electrons
due to photoemission? The dielectric breakdown takes
place within a skin layer with an exponential decay to-
ward the target depth. Because of photoemission, the
target quasi-neutrality is broken. According to the Gauss
law, the target, which starts to behave as a metal, aspires
to accumulate the excess positive charge in its surface.
The electric ﬁeld in this thin surface layer is “negative”
(directed to vacuum) that means that the non-emitted
electrons are dragged toward the target depth to a re-
gion with a lower ﬁeld. Thus, the following scenario of
the electrostatic mechanism for both ion desorption and
ablation from the semiconductor targets (that may be a
case also for dielectrics) can be proposed step by step:
(i) target material breakdown and photoemission under
laser irradiation; (ii) generation of the electric ﬁeld which
drags the electrons away from the surface layer; (iii) con-
tinuing surface ionization together with suppression of
Auger recombination; (iv) as a result, ionization degree

 
0.5

0.0

Surface

0
1

]

m
V

/

0
1

[

E

-0.5

-1.0

-1.5

-2.0

-2.5

-3.0

-3.5

5

is that, in the charged outer layer, one-photon ionization
is continuing during the laser pulse, whereas the Auger
recombination is strongly suppressed because of lack of
electrons.

Critical electric field

V. CONCLUSIONS

0.0

0.5

1.0

1.5

2.0

Distance [nm]

FIG. 4:
target (F0 = 0.2 J/cm2).

Spatial distribution of the electric ﬁeld in the Si

up to 100% in a thin surface layer; (v) electrostatic disin-
tegration of this layer. The most important consequence

[1] A. Miotello, R. Kelly: Appl. Phys. A 69, S67 (1999).
[2] R. Kelly, A. Miotello: Nucl. Instr. Meth. B 122, 374

(1997).

[3] J.T. Dickinson, S.C. Langford, J-J. Shin, D.L. Doering:

Phys.Rev. Lett. 73, 2630 (1994)

[4] J. Kanasaki, K. Tanimura: Phys. Rev. B 66, 125320

(2002).

[5] R. Stoian, A. Rosenfeld, D. Ashkenasi, I.V. Hertel,
N.M. Bulgakova, E.E.B. Campbell: Phys. Rev. Lett. 88,
0976031 (2002).

[6] M. Henik, F. Costache, J. Reif: Appl. Surf. Sci. 186, 381

(2002).

[7] G.S. Higashi, Y.J. Chabal, G.W. Trucks, K.

Raghavachari: Appl. Phys. Lett. 56, 656 (1990).

[8] G.E. Jellison, D.H. Lowndes, D.N. Mashburn, R.F.

Wood: Phys. Rev. B 34, 2407 (1986).

[9] S. De Unamuno, E. Fogarassy: Appl. Surf. Sci. 36, 1

Mechanisms of desorption and ablation of silicon un-
der irradiation by the nanosecond laser pulses in a wide
range of laser ﬂuences have been studied both experimen-
tally and theoretically. At low laser ﬂuence the desorp-
tion ﬂux is mostly composed of high-energy ions with a
narrow energy distribution that points to a non-thermal
mechanism of their generation. Theoretical analysis has
attributed the high-energetic ions to a strong electric
ﬁeld generated in an exterior target layer due to pho-
toemission that causes Coulomb explosion. More sophis-
ticated two-temperature modeling, which takes into ac-
count electronic ion emission and the aspects of thermal
vaporization, is under the progress.

(1989).

[10] L. Chen, V. Liberman, J.A. O’Neil, Z.Wu, R.M. Osgood

Jr. : J. Vac. Sci. Technol. A 6, 1426 (1988).

[11] A.V. Bulgakov, W. Marine, O.F. Bobrenok, I. Ozerov, to

be published.

[12] F. Stietz, M. Stuke, J. Viereck, T. Wenzel, F. Tr¨ager:

Appl. Surf. Sci, 129, 64 (1998).

[13] Full set and more extended analysis of the TOF spectra

will be given in a separate paper.

[14] W. Marine, M. Gerry, P. Thomsen-Schmidt, J.M. Scotti

d’Aniello: Appl. Surf. Sci. 69,290 (1993).
[15] H.M. van Driel: Phys. Rev. B 35, 8166 (1987).
[16] V.N. Tokarev, J.G. Lunney, W. Marine, M. Sentis: J.

Appl. Phys. 78, 1241 (1995).

[17] A.V. Bulgakov, N.M. Bulgakova: Quantum Electronics

29, 433 (1999)."
"Simple model for the spherically- and system-averaged pair density:
  Results for two-electron atoms","  As shown by Overhauser and others, accurate pair densities for the uniform
electron gas may be found by solving a two-electron scattering problem with an
effective screened electron-electron repulsion. In this work we explore the
extension of this approach to nonuniform systems, and we discuss its potential
for density functional theory. For the spherically- and system-averaged pair
density of two-electron atoms we obtain very accurate short-range properties,
including, for nuclear charge $Z\ge 2$, ``on-top'' values (zero
electron-electron distance) essentially indistinguishable from those coming
from precise variational wavefunctions. By means of a nonlinear adiabatic
connection that separates long- and short-range effects, we also obtain
Kohn-Sham correlation energies whose error is less than 4 mHartree, again for
$Z\ge 2$, and short-range-only correlation energies whose accuracy is one order
of magnitude better.
",http://arxiv.org/pdf/cond-mat/0411179v2,3,"5
0
0
2

b
e
F
8

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
9
7
1
1
1
4
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Simple model for the spherically- and system-averaged pair density:
Results for two-electron atoms

Paola Gori-Giorgi and Andreas Savin
Laboratoire de Chimie Th´eorique, CNRS, Universit´e Pierre et Marie Curie, 4 Place Jussieu, F-75252 Paris, France
(Dated: November 19, 2018)

As shown by Overhauser and others, accurate pair densities for the uniform electron gas may
be found by solving a two-electron scattering problem with an eﬀective screened electron-electron
repulsion. In this work we explore the extension of this approach to nonuniform systems, and we
discuss its potential for density functional theory. For the spherically- and system-averaged pair
density of two-electron atoms we obtain very accurate short-range properties, including, for nuclear
charge Z ≥ 2, “on-top” values (zero electron-electron distance) essentially indistinguishable from
those coming from precise variational wavefunctions. By means of a nonlinear adiabatic connection
that separates long- and short-range eﬀects, we also obtain Kohn-Sham correlation energies whose
error is less than 4 mHartree, again for Z ≥ 2, and short-range-only correlation energies whose
accuracy is one order of magnitude better.

I.

INTRODUCTION AND SUMMARY OF

tential method (OEP) [12].

RESULTS

Density Functional Theory (DFT) [1, 2, 3] is nowa-
days the most widely used method for electronic struc-
ture calculations, in both condensed matter physics and
quantum chemistry, thanks to a combination of low com-
putational cost and reasonable accuracy.

In the application of this theory within the Kohn-Sham
(KS) formalism [4], one deals with a model system (the
KS system) of N noninteracting electrons in a local po-
tential vKS(r) that forces them to yield the same density
n(r) of the physical system. The energy of the physi-
cal system is then obtained from that of the KS system
via a functional of the density, whose only term not ex-
plicitly known is the exchange-correlation energy Exc[n].
Correspondingly, in the local potential vKS(r) there is an
unknown term, vxc(r) = δExc[n]/δn(r).

The success of KS DFT is mostly due to the fact that
even simple physical approximations of Exc[n], like the
local density approximation (LDA) [4], already give ac-
ceptable results for many purposes. This spurred fun-
damental research in the ﬁeld, and led to a wealth of
more and more sophisticated exchange-correlation func-
tionals [2, 3, 5], and to the development of diﬀerent ap-
proaches to DFT [6, 7].

Recently,

in the search for accurate Exc[n], the fo-
cus of a large part of the DFT community has shifted
from seeking explicit functionals of the density like the
generalized gradient approximations (GGA) [8], to im-
plicit functionals, tipically using the Kohn-Sham orbital
kinetic energy density [9] or the Kohn-Sham orbitals
(see, e.g., [3, 10, 11]). The so-called “third generation”
of exchange-correlation functionals is based on the ex-
act exchange of the noninteracting (KS) system, sim-
ply obtained by putting in the formal expression for the
Hartee-Fock exchange the Kohn-Sham orbitals ϕiσ(r).
Such expression corresponds to an implicit functional
of the density, Ex[n] = Ex[
]. The local poten-
{
tial vx(r) = δEx[n]/δn(r) that generates the orbitals
ϕiσ(r)[n] can be obtained via the optimized eﬀective po-

ϕiσ[n]

}

In this broad context, sketchily summarized here, we
propose a simpliﬁed method to build the “bridge” be-
tween the physical and the KS system, or, more gener-
ally, with a reference model system of partially interact-
ing electrons. We focus on a quantity which is known to
play a crucial role in DFT and has an intuitive physical
meaning, the spherically and system-averaged electronic
pair density f (r12) (also known in chemistry as spherical
average of the intracule density, see e.g. [13, 14, 15, 16],
and especially [17, 18]). Given the spin-resolved diagonal
of the two-body reduced density matrix,

σ1σ2 (r1, r2) =
γ(2)

Ψ(r1σ1, ..., rN σN )
|

Z |

2dr3...drN ,

Xσ3...σN

we deﬁne the spin-summed pair density n2(r1, r2),

n2(r1, r2) =

N (N

1)
−
2 Xσ1σ2

σ1σ2 (r1, r2),
γ(2)

(1)

(2)

r1|
and we integrate it over all variables but r12 =
by switching, e.g., to center-of-mass coordinates, R =
2 (r1 + r2), r12 = r2 −
1

r2 −

r1,

|

f (r12) =

dR dΩr12
4π

Z

n2

R

(cid:16)

−

r12
2

, R +

r12
2 (cid:17)

.

(3)

The function f (r12) times the volume element 4πr2
12 dr12
is proportional to the probability density for the particle-
particle distance in a system of N electrons in the state
Ψ, and is normalized to the number of electron pairs,
N (N
1)/2 . This quantity fully determines the ex-
pectation value of the electronic Coulomb repulsion (in
Hartree atomic units used throughout),

−

Ψ
Veei ≡ h
h

Vee|

|

Ψ

i

=

Z
0

∞

4π r2
12

f (r12)
r12

dr12,

(4)

and is a measurable quantity, being essentially the
Fourier transform of the electronic static structure fac-
tor [19]. By construction, the one-electron density n(r) is

 
 
 
 
 
 
2

)

2
1

r
(
f

 0.16

 0.12

 0.08

 0.04

’exact’

He

Kohn-Sham

this work

H-

Kohn-Sham

’exact’

this work

 0

 1

 2

 3
r12

 0.014

 0.012

 0.01

 0.008

 0.006

 0.004

 0.002

 0

)

2
1

r
(
f

)

2
1

r
(
f

 4

 5

 6

 0

 0.5

 1

 1.5

 2

 2.5

 0.8

 0.6

 0.4

 0.2

 0

Kohn-Sham

’exact’

Li+

this work

 0  0.2  0.4  0.6  0.8  1  1.2
r12

)

2
1

r
(
f

 2

 1.5

 1

 0.5

 0

r12

Kohn-Sham

Be2+

’exact’

this work

 0

 0.2

 0.4

 0.6

 0.8

 1

r12

FIG. 1: Spherically and system-averaged pair densities for two-electron atoms: ’exact’ results [40] are compared with the values
obtained for the Kohn-Sham system and with the present approach, which is designed to get realistic f (r12) starting from the
Kohn-Sham ones.

the same in the KS and in the physical system, whereas
f (r12) will be diﬀerent in the two cases, as shown, e.g., in
Fig. 1 for some two-electron atoms. In the physical sys-
tem f (r12) has a much lower “on-top” value f (r12 = 0)
than in the KS system, and it has a cusp [20], as expected
from the fact that the electrons repel each other via the
Coulomb interaction. Roughly speaking, in the classic
DFT approach to correlation, the diﬀerence in energy
arising when we evaluate the r.h.s. of Eq. (4) with the
two f (r12), the physical and the KS, is what one tries to
describe with a universal functional of the density [21].
Here we follow a diﬀerent approach: we try to build re-
alistic f (r12) from a set of simple radial equations, to be
solved for each system, and eventually coupled to a DFT
calculation.

Our approach is inspired by the seminal work of Over-
hauser [22] and its subsequent extension [23], in which the
function f (r12) for the uniform electron gas is obtained
from a set of geminals, solutions of a radial Schr¨odinger
equation with an eﬀective electron-electron (e-e) poten-
tial. Simple approximations for such eﬀective e-e po-
tential give indeed accurate results at all relevant densi-
ties [23, 24, 25]. Here we try to generalize this approach
to systems of nonuniform density to get accurate f (r12).
The main goal of the present work is understanding
whether the method is promising, and whether it is worth
developing and reﬁning it. To this purpose, we deﬁne the

formalism (Sec. II), we give a physically-motivated pre-
scription for the eﬀective e-e potential (Sec. III), and we
test it on the simple but not trivial case of two-electron
atoms (Sec. IV). The prescription for the eﬀective e-e
potential used here is not very sophisticated. Improve-
ments along the lines of what has been done for the uni-
form electron gas [23, 24, 25] will be the subject of future
work. Yet, even at this simple ﬁrst stage of the theory
we already obtain rather accurate results, especially for
the short-range part of f (r12) (see Fig. 1 and Table I).
In Sec. V we show that with the present approach we can
also recover the diﬀerence in kinetic energy between the
physical and the KS system. Finally, Sec. VI is devoted
to conclusions, perspectives and open questions.

II. FORMALISM

In addition to the work on the “Overhauser model” [22,
23, 24], the approach described here takes advantage of
inspiring papers on the possibility of constructing a pair-
density functional theory [26, 27, 28, 29], and a local-
density-of-states functional theory [30].

Our starting point is a constrained search over 1

−
1) “eﬀective” orthonormal geminals ψi(r12) that mini-
mize the electron-electron relative kinetic energy T12 =
2
r12 (the reduced mass for the relative motion is 1/2)
−∇

2 N (N

and yield the exact f ,

P

ψi(r12)
i |
|
ψi| − ∇
h

min
ψi
}→

{

f Xi

2 = f (r12),

2
r12|

,
ψii

(5)

thus leading to a set of radial equations formally similar
to the KS ones,

[

2
r12 + veﬀ (r12)]ψi(r12) = ǫi ψi(r12)
−∇
1)/2
N (N
−

ψi(r12)
|

2 = f (r12).

Xi=1

|

(6)

(7)

These equations imply that an expansion in spherical
harmonics of f (r12) has been done, so that the kinetic
energy operator also contains the usual ℓ(ℓ + 1)/r2 term.
To fully deﬁne these equations we need a rule for the oc-
cupancy of the eﬀective geminals. In analogy with what
has been done for the uniform electron gas [23, 24], we
can assign spin degeneracy 1 to even-angular-momentum
states (singlet) and spin degeneracy 3 to odd-angular-
momentum states (triplet), up to N (N
1)/2 occupied
states. More generally, for open shell systems it could
be better to develop the formalism for the spin-resolved
quantities, starting from Eq. (1). This will be investi-
gated in future work.

−

The eﬀective electron-electron potential veﬀ (r12) of
Eq. (6) is the Lagrange parameter for f (r12), and is a
functional of f itself and of the electron-nucleus external
potential Vne (or, equivalently, of the density n(r)). To
see this, we can rewrite our Eqs. (6)-(7) in terms of a
minimization of the total energy in two steps, using the
constrained search formalism [31, 32] for the ground state
T + Vee + Vne|
Ψ
energy E = minΨh

,
i

Ψ

|

E = min

f

min
ψi
}→

min
Ψ
→

{

f n
T + Vne|

+

Ψ
h

|

f Xi

ψi| − ∇
h

2
r12 |

ψii

+

Z

f
r12

dr12

Ψ

i −

{

min
ψi
}→

f Xi

ψi| − ∇
h

2
r12|

.(8)

ψiio

Deﬁning the kinetic and external-potential functional as

Ψ

min
fh
Ψ
→

T + Vne|

|

Ψ

i −

min
ψi
}→

f Xi

{

we can rewrite

FKE[f ; Vne] =
2
,
ψii
ψi| − ∇
r12 |
h

(9)

E = min

f n

min
ψi
}→

f Xi

{

ψi| − ∇
h

2
r12 |

ψii

+

Z

f
r12

dr12

3

|

Ψ

Ψ
h

Thus, in principle we could recover the whole ground-
state energy via the (unknown) system-dependent func-
tional FKE[f ; Vne]. In practice, it seems much more fea-
sible to combine Eqs. (6)-(7) with a DFT calculation,
that yields the complementary information (the density,
and thus
). The steps of Eqs. (8)-(11) can be
Vne|
i
repeated for arbitrary electron-electron interaction and
external one-body potential.
In particular, we can set
V λ
ee = λVee and Vne = V λ, where V λ is an external po-
tential that keeps the density equal to the one of the
physical system. One could thus obtain f λ at each cou-
pling strength λ between 0 and 1 from Eqs. (6)-(7) with
a suitable vλ
eﬀ . The correlation energy of KS theory is
then simply given by [6, 33, 34]

Ec[n] =

1

dλ

Z

Z
0

f λ(r12)

dr12

f λ=0(r12)

−
r12

.

(12)

Alternatively, this procedure (usually called adiabatic
connection [34]) can be performed along a nonlinear path,
e.g., by setting [6, 35, 36, 37] vλ
ee = erf(λr)/r, where
erf(x) is the error function (see Sec. V). Eventually, the
two sets of equations, KS and (6)-(7) plus (12), could
be solved together self-consistently. This last issue is dis-
cussed in Sec. VI. Notice that if we combine Eqs. (6), (7)
and (12) with a DFT calculation, we only need to approx-
imate the potential vλ
eﬀ(r12) and not the whole functional
FKE since the remaining information is provided by DFT.
It is also worth to stress at this point that there is no
wavefunction behind our Eqs. (6)-(7): the eﬀective gem-
inals ψi are deﬁned via Eq. (5), and by specifying their
occupancy (e.g., triplet and singlet). A bosonic version
of the theory, in which only one geminal (proportional
to
f (r12)) is occupied can also be considered [29, 38].
In this work we only focus on two-electron systems for
which the two choices are equivalent. A careful com-
parison of performances of the “fermion-like” and of the
“boson-like” occupancy in the uniform electron gas is the
subject of current investigations [39].

p

As for KS DFT, the formalism just described can be
useful only if simple approximations for veﬀ (r12) yield ac-
curate results. This is what we start to check in the rest
of this paper. First, we construct a physically-motivated
veﬀ for two-electron atoms for the fully-interacting sys-
tem, and we compare our results with “exact” ones [40].
Then, we generalize our construction to build veﬀ along
the adiabatic connection, and we calculate the KS corre-
lation energy.

+FKE[f ; Vne]

.
o

(10)

III. EFFECTIVE ELECTRON-ELECTRON
POTENTIAL: THE OVERHAUSER MODEL

Searching this minimum by directly varying the ψi (with
given, ﬁxed, Vne) leads to Eqs. (6)-(7) with the identiﬁ-
cation

veﬀ (r12) =

1
r12

+

δFKE[f ; Vne]
δf (r12)

.

(11)

For the interacting electron gas of uniform density n,
Overhauser [22] proposed a simple and reasonable eﬀec-
1
tive potential veﬀ (r12): he took the sphere of volume n−
around a given electron as the boundary within which
the other electrons are excluded, due to exchange and

4

correlation eﬀects. In the standard uniform-electron-gas
model, a rigid positively-charged background maintains
the electrical neutrality. Thus the exclusion region (or
“hole”) around a given electron, modeled with a sphere
1/3, uncovers the background of
of radius rs = (4πn/3)−
positive charge, leading to an eﬀective screened Coulomb
potential with screening length rs,

vOv
eﬀ (r12; rs) =

1
r12 − Z
|

r

|≤

rs

n
r12|

−

r

|

dr,

(13)

equal to

rs

f (0)
“exact”
LDA

rmax
12
“exact”

f (rmax
12 )
“exact”

−

H
2.1

He
0.86

Li+
0.54

Be2+ Ne8+
0.15
0.39

0.0021 0.104 0.528 1.526 32.6
0.0027 0.106 0.534 1.523 32.7
0.0047 0.119 0.563 1.587 33.0

0.835 0.193 0.083 0.0465 0.0074
0.927 0.194 0.083 0.0465 0.0074

0.0031 0.114 0.55
0.0040 0.117 0.56

1.56
1.56

32.74
32.74

vOv
eﬀ (r12; rs) = 1
vOv
eﬀ (r12; rs) =

2
r12 + r
12
2r3

3
2rs

rs

r12 ≤
r12 > rs. (14)

s −
0

Equations (6)-(7), combined with the Overhauser eﬀec-
tive potential of Eq. (14) gave extremely accurate results
rs) of the function f (r12)
for the short-range part (r12 ≤
in the uniform electron gas at all relevant densities [23].
A more sophisticated eﬀective potential, based on a self-
consistent Hartree approximation, extended such accu-
racy to the long-range part of f (r12) at metallic den-
sities [24]. Other approximate veﬀ (r12) for the uniform
electron gas have also been proposed [25], and exact prop-
erties have been derived [41].

To produce realistic f (r12) for nonuniform systems
from Eqs. (6)-(7), here we generalize the original idea
of Overhauser [22, 23] to two-electron atoms, and show
that it gives rather accurate results, especially for the
short-range part of f (r12). We start from the eﬀective po-
tential v(0)
eﬀ (r12) that generates fKS(r12), the spherically-
and system averaged pair density of the Kohn-Sham sys-
tem.
In the special case of a spin-compensated two-
electron system, the KS wavefunction is simply equal to
n(r2). Because, at this ﬁrst stage, we are in-
1
2
terested in testing our method as a “bridge” between
the KS and the real system, here we use the “exact”
Kohn-Sham system. We thus take accurate one-electron
densities [40], and construct fKS(r12),

n(r1)

p

p

hVeei − hVeeiKS -0.12
-0.07
“exact”

-0.097 -0.10 -0.10
-0.10
-0.078 -0.082 -0.089 -0.09

TABLE I: Our results for the function f (r12) for two-electron
atoms (ﬁrst line for each property) compared with the corre-
sponding “exact” quantities [40]. In the ﬁrst line of the table
we report the average rs as deﬁned by Eqs. (17) and (19). For
the “on-top” value f (0) we also show the LDA result (with
f (0) for the uniform electron gas from Ref. [23]). All values
are in Hartree atomic units.

potential. When the interaction is turned on, the aver-
age distance between the two electrons increases, with
the constraint that n(r) is kept ﬁxed. We can thus imag-
ine that, with respect to the Kohn-Sham system, in the
physical system the Coulomb repulsion between the elec-
trons creates, on average, a screening “hole” around the
1, where n is an average
reference electron of volume (n)−
density (i.e., n(r) integrated over the wavefunction),

n =

1
N Z

dr n(r)2.

(17)

An approximate veﬀ (r12) could thus be simply con-
structed as

veﬀ (r12)

≈

v(0)
eﬀ (r12) + vOv

eﬀ (r12; rs)

(18)

with an average rs in vOv

eﬀ of Eq. (14),

fKS(r12) =

1
4 Z

R

n

(cid:16)

−

r12
2 (cid:17)

n

R +
(cid:16)

r12
2 (cid:17)

dR dΩr12
4π

,

and the corresponding “exact” potential v(0)
can be calculated by inverting Eqs. (6)-(7),

(15)
eﬀ (r12), that

v(0)
eﬀ = ∇

2√fKS
√fKS

+ const.

(16)

For systems with more than two electrons, the poten-
tial v(0)
eﬀ could be calculated, e.g., with the methods of
Refs. [42, 43]. In practice, it would be much more eﬃcient
to build approximations also for v(0)
eﬀ (see Sec. VI). Ex-
amples of functions fKS for nuclear charges Z = 1, 2, 3, 4
are given in Fig. 1: they have a maximum at r12 = 0,
as expected in a system of two non-interacting electrons
with antiparallel spins in a conﬁning one-body external

rs =

4π
3 n

(cid:0)

−
(cid:1)

1/3

.

(19)

The Overhauser-like potential vOv
eﬀ (r12; rs) is thus a cor-
relation potential to be added to the one that generates
fKS. It describes the correlation between pairs of elec-
trons due to Coulomb interaction, and keeps the informa-
tion on the one-electron density in an approximate way,
via the average n of Eq. (17). Of course, for more com-
plicated systems we expect to need a more sophisticated
construction for rs.

IV. RESULTS

We have inserted the potential of Eq. (18) into Eqs. (6)-
(7), and solved them for several two-electron atoms. Our
results are shown in Fig. 1 and summarized in Table I.

≥

We see that the simple eﬀective potential of Eq. (18) gives
already reasonable results for Z = 1 and 2, and that the
accuracy of the results increases with Z (as the system
becomes less and less correlated). The “on-top” value
f (0) is essentially exact for Z
2, and is much better
than the LDA estimate (normally regarded as accurate)
for all Z. This feature is appealing, since the on-top value
plays an important role in DFT [44], and accurate f (0)
are not easy to obtain from ab initio methods (see, e.g.,
Ref. [45] and references therein). The term 1/r12 in the
eﬀective potential ensures that the calculated f (r12) sat-
isﬁes the exact cusp condition f ′(0) = f (0). Table I also
shows that the position rmax
12 ) of
the maximum of f is very well predicted by the present
approach. The presence of this maximum is essentially
due to the combined eﬀect of the Coulomb repulsion be-
tween the electrons and the conﬁning external potential.
In Fig. 2 we consider He and Ne8+, and we compare
the correlated part of our f , fc = f
fKS, with the
“exact” result [40] and with the corresponding quantity
calculated within LDA, i.e.,

and the height f (rmax

−

12

f LDA
c

(r12) =

1
2 Z

n(r)2 gc(r12; n(r)) dr,

(20)

where gc is the pair-correlation function of the uni-
form electron gas at full coupling strength, taken from
Ref. [46]. (For an extended system of uniform density n,
we have gc = 2fc/nN .) Figure 3 shows the same quanti-
ties multiplied by 4πr12, i.e. the integrand of Eq. (4) for
Veei
: the area under each curve
the correlation part of
h
VeeiKS. In the last line of Table I we report
gives
Veei−h
h
VeeiKS. This quantity is
Veei − h
quantitative results for
h
less accurate than the short-range properties, but it is
still encouraging. Moreover, it saturates for large Z as in
the exact case.

5

 0

-0.02

-0.04

-0.06

-0.08

 0.5
 0
-0.5
-1
-1.5
-2
-2.5
-3
-3.5
-4

He

’exact’
this work
LDA

 0

 0.5

 1

 1.5

 2

 2.5

r12

Ne8+

’exact’
this work
LDA

)

2
1

r
(

c

f

)

2
1

r
(

c

f

 0

 0.1

 0.2

 0.3

 0.4

 0.5

r12

FIG. 2: The correlated part of the spherically- and system-
averaged pair density, fc(r12) = f (r12)−fKS(r12). Our results
for He and Ne8+ are compared with the “exact” ones and with
the LDA result (the hole for the uniform electron gas is taken
from Ref. [46]).

resulting Ec from Eq. (21) is independent of the choice
of vλ
ee. However, when approximations are made some
“paths” can give much better results than others [6]. As
we shall see, this is the case with the present approach.
We build an Overhauser-like potential for interaction
ee (to be added to v(0)
vλ

eﬀ ) as

V. ADIABATIC CONNECTION AND
CORRELATION ENERGY

vOv, λ
eﬀ

(r12; rs) = vλ

ee(r12)

−Z

n vλ

ee(
|

r
−

r12|

) dr. (22)

r

|≤

|

rs

Veei − h
h

For the calculation of the energy of the physical sys-
VeeiKS, one needs to
tem, in addition to Vc[n] =
know the kinetic-energy diﬀerence, Tc[n] =
iKS,
T
h
that can be obtained via the adiabatic connection for-
malism [6, 33, 34]. By varying a parameter λ, the in-
teraction vλ
ee(r12) between the electrons is switched on
continuously from zero to 1/r12, while the density is
kept ﬁxed by an external one-body potential V λ.
If
vλ=0
ee = 0 and vλ=a
ee = 1/r12, the KS correlation energy
Ec[n] = Tc[n] + Vc[n] is given by [6, 34]

i − h

T

That is, the average density n of Eq. (17) (and thus
the average rs) is kept ﬁxed to mimic the fact that the
one-electron density does not change along the adiabatic
connection. The modiﬁed interaction vλ
ee is screened by
a sphere of radius rs and of positive uniform charge of
density n that attracts the electrons with the same mod-
iﬁed interaction. This attractive background approxi-
mates the eﬀect of the external potential V λ on f .

A. Linear adiabatic connection

Ec[n] =

a

dλ

∞

Z

0

Z
0

dr12 4π r2

12 f λ

c (r12)

∂vλ

ee(r12)
∂λ

,

(21)

where f λ

c = f λ

fKS.

−
linear “path” [11, 33], by setting vλ
to Eq. (12). If one is able to compute the exact f λ

Usually, the adiabatic connection is performed along a
ee = λ/r12, which leads
c , the

If we choose vλ

(r12; rs) = λ vOv

vOv, λ
eﬀ
given by Eq. (14).
The results for

ee = λ/r12 we simply obtain
eﬀ (r12; rs) is

eﬀ (r12; rs), where vOv

VeeiKS for He and Ne8+ are
shown in Fig. 4, and are compared with the “exact”
[42]. The correlation energy Ec can be
ones of Ref.

V λ
eei − h
h

 0.004

 0

-0.004

-0.008

-0.012

-0.016

 0.02

 0

-0.02

-0.04

-0.06

-0.08

-0.1

-0.12

He

’exact’
this work
LDA

 0

 0.5

 1

 1.5

 2

 2.5

r12

Ne8+

’exact’
this work
LDA

6

’exact’
this work

He

 0

 0.2

 0.4

 0.6

 0.8

 1

λ

’exact’
this work

Ne8+

S
K

〉

e
e
V

〈

−

〉

e
λ e
V

〈

S
K

〉

e
e
V

〈

−

〉

e
λ e
V

〈

 0

-0.02

-0.04

-0.06

-0.08

-0.1

 0

-0.02

-0.04

-0.06

-0.08

-0.1

-0.12

2
1

r

)

2
1

r
(

c

f

π

4

2
1

r

)

2
1

r
(

c

f

π

4

 0

 0.1  0.2  0.3  0.4  0.5  0.6

 0

 0.2

 0.4

 0.6

 0.8

 1

r12

λ

FIG. 3: The real space analysis of the correlation part of
the expectation value of Vee: the area under each curve gives
hVeei − hVeeiKS (see also Eq. (4) and Fig. 2). Our results for
He and Ne8+ are compared with the “exact” ones and with
the LDA result (the hole for the uniform electron gas is taken
from Ref. [46]).

FIG. 4: Correlation part of hV λ
eei along the linear adiabatic
connection for He and Ne8+. Our results are compared with
the “exact” ones of Ref. [42]. The area under each curve gives
the correlation energy Ec of standard Kohn-Sham theory.

calculated as the area under each curve. We obtain
0.053 Hartree
Ec =
for Ne8+, to be compared with the corresponding ’exact’
results, -0.042 and -0.045, respectively.

0.052 Hartree for He and Ec =

−

−

B. A nonlinear adiabatic connection

As shown by Figs. 1–3 and Table I, the Overhauser-like
potential gives accurate results for the short-range part of
fc(r12). We can thus expect to obtain better correlation
energies from the adiabatic connection formalism if we
choose a modiﬁed interaction vλ
ee that is able to separate
long-range and short-range contributions, like the “erf”
interaction [6, 35, 36, 37]

vλ
ee(r12) =

erf(λ r12)
r12

.

(23)

→

0, not only is f λ

interaction, and thus f λ
c , become small, so that the con-
tribution to Ec coming from λ-values for which the long-
range part of f λ
c is not quenched is moderate. Moreover,
the function f λ
c is correctly normalized to zero so that for
λ
c small, but also the integral itself
vanishes. In the linear adiabatic connection of Eq. (12),
instead, the long-range part of f λ
c plays an important
role in the energy integrand at all λ. Indeed, with this
nonlinear adiabatic connection we obtain Ec =
0.0405
0.0413 for Ne8+, much closer
Hartree for He and Ec =
to the “exact” values with respect to the results from the
linear adiabatic connection.

−

−

eﬀ

The technical details of this calculation are as fol-
lows. The potential vOv, λ
(r12; rs) of Eq. (22) can
be computed analytically, and is reported in Ap-
pendix A. We thus obtained, via Eqs. (6)-(7), dEλ
c /dλ =
2
12 for 23 values of λ between 0 and
R
20 for He, and between 0 and 100 for Ne8+. We then ﬁt-
ted our results with the derivative of the following func-
tional form

c (r12) 2

dr12f λ

√π e−

2
λ

r

With this choice, Eq. (21) becomes

Ec[n] =

∞

dλ

∞

Z
0

Z

0

dr12 4π r2

12 f λ

c (r12) 2

√π e−

For large λ, when we are approaching the physical sys-
2
λ
12 in Eq. (24) quenches the
tem, the gaussian factor e−
long-range contribution of f λ
c to the energy integrand. At
0, the
the KS end of the adiabatic connection, when λ

r

2

→

2
λ

r

2
12 . (24)

Eλ

c =

a1 x6 + a2 x8 + a3 x10
(1 + b2 x2)5

,

−

x =

λ
Z

,

(25)

that has exact asymptotic behaviors for small and large
(We have numerical evidence that our results
λ [37].
fulﬁll such exact behaviors.)
In Fig. 5 we report our
numerical values for dEλ
c /dλ, together with the derivative
of the ﬁtting function of Eq. (25). The parameters and

 
 
 
 
 
 
 
 
 
 
a1

a3
1.2047 2.3253 2.7788 1.5263 4·10

r.m.s.
−5

a2

b

He

He

Ne8+ 0.3983 0.4711 0.4026 1.2557 9·10

−6

7

 0

-0.002

-0.004

-0.006

-0.008

-0.01

-0.012

-0.014

λ
d

/

λ c
E
d

λ
d

/

λ c
E
d

 0

 5

fit
results

 10
λ

 15

 20

 0

-0.0005

-0.001

-0.0015

-0.002

-0.0025

Ne8+

fit
results

 0

 20

 40

 60

 80  100

λ

FIG. 5: The derivative dEλ
c /dλ along the nonlinear adiabatic
connection deﬁned by Eqs. (23)–(24) for He and Ne8+. Our
results are compared with the derivative of the ﬁtting function
of Eq. (25). The area under each curve from zero to ∞ gives
the correlation energy Ec of standard Kohn-Sham theory.

the r.m.s of residuals are reported in Table II. The KS
correlation energy Ec[n] is then given by a3/b10.

The accuracy of our results with the “erf” adiabatic
connection is of particular interest for the method of
Refs. [6, 35, 36, 37], which combines multideterminantal
wavefunctions (conﬁguration interaction, CI) with den-
sity functional theory (“CI+DFT”). In such approach,
instead of the KS system, one choses a reference system
of partially interacting particles, usually with the poten-
tial of Eq. (23). This model system is treated with a
multideterminantal wavefunction, in a CI fashion, that
allows to treat near-degeneracy eﬀects. The remaining
part of the energy is calculated via a density functional,
that needs to be approximated. The larger λ, the larger
is the energy fraction treated with the CI calculation,
and thus the larger is the computational cost. The corre-
lation energy functional that needs to be approximated
is [6, 35, 36, 37]

E

λ
c [n]

≡
and can be rewritten as

Ec[n]

−

Eλ

c [n],

(26)

E

λ
c [n] =

Z

λ

∞

dλ′

Z

0

∞

dr12 4π r2

12 f λ

c (r12) 2

√π e−

′

′2

λ

r

2
12 .

(27)
Thus, only the short-range part of f λ
c contributes to the
λ
functional E
c [n], and we expect to get accurate results
with the present approach. Indeed, this is the case, as

TABLE II: Optimal ﬁt parameters and r.m.s of the residuals
for the derivative of Eq. (25), that parametrizes our results
for dEλ
c /dλ along the nonlinear adiabatic connection deﬁned
by Eqs. (23)–(24). See also Fig. 5.

cλ
E
−

c
E

cλ
E
−

c
E

 0

-0.01

-0.02

-0.03

-0.04

-0.05

 0

-0.01

-0.02

-0.03

-0.04

-0.05

He

’exact’
this work

 0

 2

 4

 6

 8

 10

λ

Ne8+

’exact’
this work

 0  10  20  30  40  50  60  70  80
λ

FIG. 6: A nonlinear adiabatic connection that separates long-
and short-range eﬀects: diﬀerence between the correlation en-
ergy Ec of the physical system (with full interaction 1/r) and
the correlation energy Eλ
c of the system with partial interac-
tion erf(λ r)/r, for He and Ne8+. Our results are compared
with the “exact” ones of Ref. [36].

shown in Fig. 6, where we compare our results as a func-
tion of λ with the “exact” ones of Ref. [36]. The error
is less than 0.5 mHartree for λ & 1/rs, that is a very
reasonable choice for the value of λ to be used in the
CI+DFT method of Refs. [6, 35, 36, 37].

VI. CONCLUSIONS AND PERSPECTIVES

In this work we have started to explore the possibil-
ity of solving simple radial equations to generate realistic
spherically- and system-averaged electronic pair densities
f (r12) for nonuniform systems. With a simple approxi-
mation for the unknown eﬀective electron-electron inter-
action that appears in our formalism, we have obtained,
for two-electron atoms, results that are in fair agreement
with those coming from accurate variational wavefunc-

 
 
 
 
 
 
 
 
tions (Figs. 1–3 and Table I). We have then extended
our approach along a nonlinear adiabatic connection and
obtained Kohn-Sham correlation energies whose error is
less than 4 mHartrees, and short-range-only correlation
energies whose accuracy is one order of magnitude better
(Fig. 6).

In Sec. II, we have introduced a general formalism for
many-electron systems that will be further tested in fu-
ture work. So far we can say that this formalism, com-
bined with simple physical approximations, works very
well for two completely diﬀerent systems: the uniform
electron gas [23, 24, 25] and the He series. We think that
this fact makes the method promising.

To fully develop the approach described in this paper,
many steps have to be performed. First of all, the KS
part of the eﬀective e-e potential, v(0)
eﬀ (r12) of Eq. (18),
should be also approximated, to make the extension to
many-electron systems practical. The correlation part of
the eﬀective e-e potential can be improved, in analogy
with the recent developments for the uniform electron-
gas case [24, 25]. It should then be possible to construct
a self-consistent scheme (OEP-like) that combines the
Kohn-Sham equations with the correlation energy func-
tional arising from our approach [Eqs. (6)-(7) at diﬀerent
coupling strengths λ, plus Eq. (12) or Eq. (24)]. With
respect to traditional DFT calculations, this combined
scheme would have the advantage of yielding not only
the ground-state one-electron density n(r) and energy E,
but also the spherically- and system-averaged pair den-
sity f (r12), thus allowing to calculate expectation values

8

of two-body operators that only depend on the electron-
electron distance. The combination of our approach with
the CI+DFT method of Refs. [6, 35, 36, 37] could be also
implemented and, in view of the results of Fig. 6, it is
even more promising. We are presently working in all of
these main directions.

Acknowledgments

We thank C. Umrigar for

the wavefunctions of
Ref. [40], J. Toulouse for the results of Ref. [36], E.K.U.
Gross, W. Kohn, M. Polini, G. Vignale and P. Ziesche
for encouraging discussions, V. Sahni for useful hints,
and J.K. Percus for helpful suggestions. This research
was supported by a Marie Curie Intra-European Fellow-
ships within the 6th European Community Framework
Programme (contract number MEIF-CT-2003-500026).

APPENDIX A: OVERHAUSER-LIKE
POTENTIAL FOR THE ERF INTERACTION

The evaluation of Eq. (22) with the interaction vλ

ee =

erf(λ r12)/r12 gives

(r12; rs) =
where s = r12/rs, µ = λ rs, and

vOv, λ
eﬀ

u(s, µ)
rs

,

(A1)

u(s, µ) =

erf(µ s)
s

1
2
8 √π s µ3 (cid:26)

−

√π µ

3 s + 2 (1
h

−

s)2 (2 + s) µ2

i

2 + s + s2

µ2 + e−

2
4 s µ

1 +
h

−
(cid:0)
erf [µ (1

(cid:1)
s)] + √π µ

−

3 s + 2 (2

−

h−

1 +

(
−

s2

−

2 + s
(cid:1)
(cid:0)
s) (1 + s)2 µ2

µ2)
i

e−

(1

−

2

s)

2
µ

−

erf [µ (1 + s)]

(cid:27)

.

(A2)

i

[1] W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).
[2] A.E. Mattsson, Science 298, 759 (2002).
[3] C. Fiolhais, F. Nogueira, and M. Marques (eds.), A
Primer in Density Functional Theory (Springer-Verlag,
Berlin, 2003).

[4] W. Kohn and L.J. Sham, Phys. Rev. 140, A1133 (1965).
[5] J.P. Perdew and K. Schmidt, in Density Functional The-
ory and Its Applications to Materials, edited by V. Van-
Doren et al. (AIP, NY, 2001), and references therein.
[6] A. Savin, F. Colonna, and R. Pollet, Int. J. Quantum

Chem. 93, 166 (2003), and references therein.

Phys. Rev. A 38, 3098 (1988); J. Chem. Phys. 84, 4524
(1986); C. Lee, W. Yang, and R.G. Parr, Phys. Rev. B
37, 785 (1988); J.P. Perdew, J.A. Chevary, S.H. Vosko,
K.A. Jackson, M.R. Pederson, D.J. Singh, and C. Fiol-
hais, Phys. Rev. B. 46, 6671 (1992); ibid. 48, 4978 (1993).
[9] J. Tao, J.P. Perdew, V.N. Staroverov, and G.E. Scuseria,

Phys. Rev. Lett. 91, 146401 (2003).

[10] J.P. Perdew, A. Ruzsinszky, J. Tao, V.N. Staroverov,
G.E. Scuseria, and G.I. Csonka, J. Chem. Phys., to ap-
pear.

[11] M. Seidl, J.P. Perdew, and S. Kurth, Phys. Rev. Lett.

[7] V. Sahni, Quantal Density Functional Theory (Springer-

84, 5070 (2000).

Verlag, Berlin, 2004).

[8] J.P. Perdew, K. Burke, and M. Ernzerhof, Phys. Rev.
Lett. 77, 3865 (1996); ibid. 78, 1396 (1997); A.D. Becke,

[12] see, e.g., S. K¨ummel and J.P. Perdew, Phys. Rev. B 68,
035103 (2003); W. Yang and Q. Wu, Phys. Rev. Lett. 89,
143002 (2002); R. J. Magyar, A. Fleszar, and E. K. U.

9

Gross, Phys. Rev. B 69, 045111 (2004); M. Gr¨uning, O.
V. Gritsenko, and E. J. Baerends, J. Chem. Phys. 118,
7183 (2003).

[13] C.A. Coulson and A.H. Neilson, Proc. Phys. Soc. London

78, 831 (1961).

[14] J. Cioslowski, B.B. Stefanov, A. Tan, and C.J. Umrigar,

J. Chem. Phys. 103, 6093 (1995).

[15] J. Cioslowski and G. Liu, J. Chem. Phys. 109, 8225

(1998).

[16] E. Valderrama, J.M. Ugalde, and R.J. Boyd, in Many-
electron densities and reduced density matrices, edited
by J. Cioslowski (Kluwer Academic/Plenum Publishers,
New York, 2000).

Langreth and J.P. Perdew, Solid State Commun. 17,
1425 (1975); O. Gunnarsson and B.I. Lundqvist, Phys.
Rev. B 13, 4274 (1976).

[34] W. Yang, J. Chem. Phys. 109, 10107 (1998).
[35] A. Savin, in Recent Developments and Applications of
Modern Density Functional Theory, edited by J.M. Sem-
inario (Elsevier, Amsterdam, 1996); T. Leininger, H.
Stoll, H.-J. Werner, and A. Savin, Chem. Phys. Lett.
275, 151 (1997); R. Pollet, A. Savin, T. Leininger, and
H. Stoll, J. Chem. Phys. 116, 1250 (2002).

[36] R. Pollet, F. Colonna, T. Leininger, H. Stoll, H.-J.
Werner, and A. Savin, Int. J. Quantum Chem. 91, 84
(2003); J. Toulouse, private communication.

[17] E.R. Davidson, Reduced Density Matrices in Quantum

[37] J. Toulouse, F. Colonna, and A. Savin, Phys. Rev. A 70,

Chemistry (Academic Press, New York, 1976).

062505 (2004).

[18] A.J. Coleman and V.I. Yukalov, Reduced Density Ma-
trices: Coulson’s Challenge (Springer-Verlag, New York,
2000).

[19] see, e.g., G. Mazzone, F. Sacchetti, and V. Contini, Phys.
Rev. B 28, 1772 (1983); C. Petrillo and F. Sacchetti, ibid.
51, 4755 (1995).

[20] A. K. Rajagopal, J. C. Kimball, and M. Banerjee, Phys.
Rev. B 18, 2339 (1978); X.-Y. Pan and V. Sahni, J.
Chem. Phys. 119, 7083 (2003).

[21] The diﬀerence in kinetic energy can be obtained from
the adiabatic connection formula that can be viewed as
a generalization of the above argument, and is treated in
Sec. V.

[22] A.W. Overhauser, Can. J. Phys. 73, 683 (1995).
[23] P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 64, 155102

(2001).

[24] B. Davoudi, M. Polini, R. Asgari, and M.P. Tosi, Phys.

Rev. B 66, 075110 (2002).

[25] M. Corona, P. Gori-Giorgi, and J.P. Perdew, Phys. Rev.
B 69, 045108 (2004); I. Nagy, R. Diez Mui˜no, J.I. Juar-
isti, and P.M. Echenique, Phys. Rev. B 69, 233105
(2004).

[26] P. Ziesche, Phys. Lett. A 195, 213 (1994); M. Levy and

P. Ziesche, J. Chem. Phys. 115, 9110 (2001).

[27] A. Gonis, T.G. Schulthess, J. van Ek, and P.E.A. Turchi,
Phys. Rev. Lett. 77, 2981 (1996); A. Gonis, T.G.
Schulthess, P.E.A. Turchi, and J. van Ek, Phys. Rev.
B 56, 9335 (1997).

[28] A. Nagy, Phys. Rev. A 66, 022505 (2002).
[29] F. Furche, Phys. Rev. A 70, 022514 (2004).
[30] J.M. Soler, Phys. Rev. B 69, 195101 (2004).
[31] M. Levy, Proc. Natl. Acad. Sci. U.S.A. 76, 6062 (1979).
[32] E. Lieb, Int. J. Quantum Chem. 24, 243 (1983).
[33] J. Harris and R. Jones, J. Phys. F 4, 1170 (1974); D.C.

[38] B. Davoudi, R. Asgari, M. Polini, and M.P. Tosi, Phys.
Rev. B 68, 155112 (2003); R. Asgari, B. Davoudi, and
M.P. Tosi, Solid State Comm. 131, 301 (2004).
[39] R. Asgari, B. Davoudi, M. Polini, and M.P. Tosi,

in

preparation.

[40] D.E. Freund, B.D. Huxtable, and J.D. Morgan III, Phys.
Rev. A 29, 980 (1984). We used an improved version
(provided to us by C. Umrigar) of the accurate varia-
tional wavefunctions described in this work to obtain one-
electron densities n(r) and functions f (r12). See also C.J.
Umrigar and X. Gonze, Phys. Rev. A 50, 3827 (1994),
and Ref. [14].

[41] P. Ziesche, Phys. Rev. B 67, 233102 (2003); P. Ziesche,
K. Pernal, and F. Tasn´adi, Phys. Status Solidi B 239, 185
(2003). In these papers interesting exact properties of the
“Overhauser geminals” are derived, using the interacting
momentum distribution to deﬁne the geminal occupancy.
Notice however that the uniform-electron gas equivalent
of our Eqs. (6)-(7) employ the non-interacting momen-
tum distribution, as it has been done in Refs. [23, 24, 25].
[42] F. Colonna and A. Savin, J. Chem. Phys. 110, 2828

(1999).

[43] Q. Zhao, R. C. Morrison, and R. G. Parr, Phys. Rev.
A 50, 2138 (1994); R. van Leeuwen and E. J. Baerends
Phys. Rev. A 49, 2421 (1994).

[44] J.P. Perdew, A. Savin, and K. Burke, Phys. Rev. A, 51,
4531 (1995); K. Burke, J.P. Perdew, and M. Ernzerhof, J.
Chem. Phys. 109, 3760 (1998); E. Valderrama and J.M.
Ugalde, Int. J. Quantum Chem. 86, 40 (2002).

[45] X. Fradera, M. Duran, E. Valderrama, and J.M. Ugalde,

Phys. Rev. A 62, 034502 (2000).

[46] P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 66, 165118

(2002)."
"Cl electrosorption on Ag(100): Lateral interactions and electrosorption
  valency from comparison of Monte Carlo simulations with chronocoulometry
  experiments","  We present Monte Carlo Simulations using an equilibrium lattice-gas model for
the electrosorption of Cl on Ag(100) single-crystal surfaces. Fitting the
simulated isotherms to chronocoulometry experiments, we extract parameters such
as the electrosorption valency gamma and the next-nearest-neighbor lateral
interaction energy phi_nnn. Both coverage-dependent and coverage independent
gamma were previously studied assuming a constant phi_nnn [I. Abou Hamad, Th.
Wandlowski, G. Brown, P.A. Rikvold, J. Electroanal. Chem. 554-555 (2003) 211].
Here, a self-consistent, entirely electrostatic picture of the lateral
interactions with a coverage-dependent phi_nnn is developed, and a relationship
between phi_nnn and gamma is investigated for Cl on Ag(100).
",http://arxiv.org/pdf/cond-mat/0502407v2,3,"5
0
0
2

r
a

M
4
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
7
0
4
2
0
5
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Cl electrosorption on Ag(100): Lateral
interactions and electrosorption valency from
comparison of Monte Carlo simulations with
chronocoulometry experiments

I. Abou Hamad1,2, S.J. Mitchell3,4, Th. Wandlowski5, P.A. Rikvold1,2, and G. Brown2,6
1Center for Materials Research and Technology and Department of Physics, Florida State University, Tallahassee, FL 32306-4350, USA

2School of Computational Science, Florida State University, Tallahassee, FL 32306-4120, USA

3Schuit Institute for Catalysis and Department of Chemical Engineering, Eindhoven University of Technology, 5600 MB Eindhoven, The Netherlands

4The Center for Simulational Physics and The Department of Physics and Astronomy, The University of Georgia, Athens, GA 30602-2451

5Institute for Thin Films and Interfaces, ISG 3, and Center of Nanoelectronic Systems, cni, Research Centre J¨ulich, 52425 J¨ulich, Germany

6Center for Computational Sciences, Oak Ridge National Laboratory, Oak Ridge, TN 37831, USA

November 18, 2018

Abstract

We present Monte Carlo Simulations using an equilibrium lattice-
gas model for the electrosorption of Cl on Ag(100) single-crystal sur-
faces. Fitting the simulated isotherms to chronocoulometry experi-
ments, we extract parameters such as the electrosorption valency γ
and the next-nearest-neighbor lateral interaction energy φnnn. Both
coverage-dependent and coverage independent γ were previously stud-
ied, assuming a constant φnnn [I. Abou Hamad, Th. Wandlowski,
G. Brown, P.A. Rikvold, J. Electroanal. Chem. 554-555 (2003) 211].
Here, a self-consistent, entirely electrostatic picture of the lateral in-
teractions with a coverage-dependent φnnn is developed, and a rela-
tionship between φnnn and γ is investigated for Cl on Ag(100).

Keywords: Chlorine electrosorption; Lateral interactions; Electrosorp-
tion valency; Chronocoulometry; Continuous phase transition; Lattice-gas
model; Monte Carlo simulation.

1

 
 
 
 
 
 
1

Introduction

Studies of lateral interactions between adsorbed particles are motivated by
the need to understand the origin of the wide variety of ordered overlayers and
phase transitions at fractional adsorbate coverage on metal surfaces. These
interactions have contributions ranging from short-range and van der Waals
to long-range dipole-dipole, and lattice-mediated interactions [1]. Hard-
square short-range interactions and dipole-dipole long-range interactions are
the major contributions to the lateral interactions for bromine adsorption on
Ag(100) [2]. In this paper, we explore the validity and applicability of such
a model for adsorption of chlorine on Ag(100).

Halide electrosorption on single-crystal metal electrode surfaces is a good
model system for studying the properties of the electrode-electrolyte interface
in an electrochemical cell. Due to its relative simplicity, it can be used to dis-
tinguish between the various contributions of diﬀerent parameters according
to the eﬀect of their inclusion on the overall behavior of the system. A mean-
ﬁeld approach is not suﬃcient, even for the description of one of the simplest
halide-electrosorption systems Br/Ag(100). However, a simple lattice-gas
model with constant parameters is suﬃcient to describe its equilibrium [2, 3],
and dynamic [4] properties. While the electrosorption of Br on single-crystal
Ag(100) from aqueous solution has been extensively studied as an example
of adlayer formation in an electrochemical system [2, 5, 6, 7, 8], less attention
has been given to the electrosorption of Cl [3, 9, 10] on Ag(100). A lattice-
gas model with constant parameters is not suﬃcient to describe Cl/Ag(100),
therefore this system can be used to further investigate the nature and char-
acteristics of the lateral interactions between the adsorbed halide atoms. In
particular, we here develop a self-consistent picture of variable lattice-gas
parameters based on the resident charge on the adatoms being coverage de-
pendent or electrode-potential dependent (through the coverage).

The rest of this paper is organized as follows. In Section 2 we describe an
electrostatic model of the adlayer that is used in the simulations, the lateral
interaction energies, and the Monte Carlo methods used. A brief description
of the experimental procedure is given in Section 3. The results of ﬁtting the
simulations to experimental data are detailed in Section 4, followed by a brief
comparison with Br/Ag(100) in Section 5. Our conclusions are summarized
in Section 6.

2

2 Self-consistent electrostatic adlayer model

2.1 Lattice-gas model

The adsorption of Cl ions occurs at the fourfold hollow sites of the Ag(100)
surface [11], which form a square lattice as shown in Fig. 1. To approximate
the equilibrium behavior of this system, we use a lattice-gas model, in which
the lattice sites correspond to the adsorption sites. Mitchell et al. [12] used an
oﬀ-lattice model for the Br/Ag(100) system to show that the Br adsorbates
spend most of the time near the four-fold hollow sites of the Ag(100) surface,
thus justifying the lattice-gas treatment of halide adsorption. To describe
the energy associated with a conﬁguration of adsorbates on the surface, a
grand-canonical eﬀective Hamiltonian [2, 6, 13, 14] is used,

=

H

−

Xi<j

φijcicj −

µ

ci ,

N

Xi=1

(1)

P

i<j is a sum over all pairs of sites, φij are the lateral interaction ener-
where
gies between particles on the ith and jth lattice sites, measured in meV/pair,
µ is the electrochemical potential, measured in meV/particle, and N = L2 is
the total number of lattice sites. The local occupation variable ci is 1 if site
i is occupied and 0 otherwise.

The long-range interactions, φij, depend on the distance, rij, between
ions i and j (measured in Ag(100) lattice spacing units, a = 2.889 ˚A [7]) as

φij =

−∞
23/2φnnn
r3
ij




rij = 1
√2
rij ≥

,

(2)

where the inﬁnite value for rij = 1 indicates nearest-neighbor exclusion, and
negative values of φij denote long-range repulsion. The coverage isotherms
were simulated using a square L
L lattice with periodic boundary conditions
to reduce ﬁnite-size eﬀects.

×



The electrochemical potential µ is related to the bulk ionic concentration
C and the electrode potential E (measured in mV). In the dilute-solution
approximation, the relationship is

µ = µ0 + kBT ln

C
C0 (cid:19) −

e

(cid:18)

E

E0

Z

γ(E′)dE′ ,

(3)

3

where µ0 is an arbitrary constant, C0 is a reference concentration (here taken
to be 1 mM), and e is the elementary charge unit [15]. The reference potential
E0 is chosen suﬃciently negative such that the coverage vanishes at E0 for all
values of C used, and µ has the sign convention that µ > 0 favors adsorption.
The relationship between µ, C, and E is discussed further in the Appendix.

2.2 Lateral interaction energies

When Cl ions adsorb on the surface, a fraction of their charge is transfered
through the external circuit. This fraction, γe, is negative and is directly
(1 + γ)e [16]. This
related to the average resident charge per ion, q =
relationship is an approximation and is more valid as the potential at the
adsorbate approaches the value of the potential in the solution. For the
current system’s ionic strength, this condition is only approximately satisﬁed
and may be considered as a source of error.

−

We have previously shown [3] that for Cl/Ag(100), the electrosorption

valency γ depends on the coverage θ, which is deﬁned as

θ = N −1

ci .

N

Xi=1

(4)

In order to investigate such a dependence more thoroughly, we here propose
a model with a coverage-dependent next-nearest-neighbor lateral interaction
energy φnnn, as well. This is motivated by two assumptions: that γ is coverage
dependent and that the major contribution to φnnn is due to electrostatic
dipole-dipole interactions. A simple electrostatic picture of the adlayer, in
which an adsorbate’s resident charge and its image charge form a dipole,
suggests a relationship between the electrosorption valency and the dipole
moment. If γ is coverage dependent (γ = γ(θ)), then the resident charge is
also coverage dependent (q = q(θ)), and hence φnnn, which is proportional to
q2, is coverage dependent as well (φnnn = φnnn(θ)).

Assuming for simplicity that γ depends linearly on θ,

the resident charge q becomes

γ = γ0 + γ1θ ,

q =

(1 + γ0 + γ1θ)e ,

−

4

(5)

(6)

and φnnn takes the form:

φnnn = A(1 + γ0 + γ1θ)2 ,

(7)

where A is a prefactor proportional to the square of a “dipole distance”. This
eﬀect is known as depolarization, and may under extreme conditions lead to
the possibilty of a ﬁrst-order phase transition [17, 18]1.
If γ is coverage
independent (i.e., γ1 = 0), then φnnn becomes coverage independent, as well.

2.3 Monte Carlo method

Equilibrium Monte Carlo (MC) simulations were used to measure the equi-
librium coverage as a function of µ, which was then converted to E using
Eq. (3). At each MC step a lattice site, i, was chosen randomly, and a change
in its occupation variable ci was attempted with a Metropolis acceptance
probability [19]:

= min

R

1, exp
(cid:20)

(cid:18)−

∆
H
kBT (cid:19)(cid:21)

,

(8)

where ∆
is the energy diﬀerence between the initial state and the proposed
state. The value of φnnn was updated in the simulations at each MC step,
corresponding to the new proposed coverage.

H

H

The energy diﬀerence ∆

was calculated from Eq. (1) using two methods,
a truncated sum of the contributions of neighboring occupied sites up to ﬁve
lattice spacings away [2, 3, 6], and a mean-ﬁeld-enhanced truncated sum
up to three lattice spacings [3]. In the latter method, energy contributions
from adparticles more than three lattice spacings away are calculated using
a mean-ﬁeld estimate as detailed in Ref. [3].

3 Experimental

A detailed description of the experimental procedure is given in Ref. [3, 8],
and only a brief summary follows here. The Ag(100) single-crystal electrodes
were chemically etched in cyanide solution, rinsed in Milli-Q water, and care-
fully annealed in a hydrogen ﬂame. They were then quickly transfered into
1For our model of Cl adsorption on Ag(100) with the ﬁtting parameters obtained in
this paper, the ﬁrst-order phase transition is not observed in the simultions, even for
temperatures as unrealistically low as 1 K. The model does produce a ﬁrst-order transition
at room temperature for some parameters that do not ﬁt the experimental data.

5

the electrochemical cell after cooling in a stream of Argon. Using the hang-
ing meniscus technique, a platinum wire counter electrode, and a saturated
calomel electrode as reference electrode, the electrochemical measurements
were carried out at a temperature of (20

1)◦C.

For the chronocoulometric experiments, the potential was set at initial
0.300 V vs SCE until adsorption equilibrium
1.400 V, where

values between
−
was established, and then stepped to the ﬁnal potential of
the chloride is completely desorbed from the surface.

1.375 and

−

−

±

4 Results

−

100 meV in steps of 5 meV, while γ0 and γ1 were varied from 0 to

The equilibrium MC simulations were performed at a temperature of 17◦C
for various values of A, γ0, and γ1. The value of A was varied from 0 to
0.9
−
in steps of 0.1, resulting in 2000 diﬀerent simulations. The resulting sim-
ulated isotherms were ﬁtted to experimental data. This large number of
simulations necessitated the choice of the relatively small system size with
L = 32. The system displays a second-order phase transition from a disor-
dered, low-density phase to an ordered c(2
2) phase [2] at an intermediate
value of the electrochemical potential. For the steepest part of the isotherm
(Fig. 2), where critical slowing down due to the phase transition is impor-
tant, the system was allowed to relax for a longer time to reach equilibrium
than for the points further away from the phase transition. We checked for
ﬁnite-size eﬀects, and no signiﬁcant diﬀerence was observed when comparing
the resulting isotherms with isotherms simulated using larger system sizes
of L = 64, 128, and 256. A small value of L can be used because θ is not
the order parameter corresponding to the c(2
2) phase, and so its ﬂuctu-
ations, which are proportional to dθ/dµ, only diverge logarithmically with
L [2, 20, 21]. In addition, better statistics were collected close to the phase
transition, using longer runs and more sampling than for points far from the
phase transition, where the ﬂuctuations are smaller.

×

×

Using Eq. (3), the simulated isotherms were converted from the µ scale
to the E scale and then ﬁt to the experimental isotherms. The ﬁtting was
done by varying the value of µ0 to minimize ˆχ2 for each set of values for A,

6

γ0, and γ1. Here,

(θexp

−

θsim)2

ˆχ2 = Xexp points

degrees of freedom

(9)

is the least-squares sum per degree of freedom, and θexp and θsim are the ex-
perimental and simulated coverages, respectively, corresponding to the same
value of E. Linear interpolation was used between the simulated data points
to calculate θsim for all values of E.

−

−

0.3, γ1 =

From ﬁts to 10 mM and 20 mM experiments, a grid of of values of ˆχ2,
was collected. Three diﬀerent models were studied. (i) A constant γ (i.e.,
also constant φnnn) model for which we only considered the simulations with
γ1 = 0. (ii) A model in which only the line with γ0 =
0.3
was considered. These values for γ0 and γ1 were estimated from values of γ
obtained from the experimental data in Ref. [3] using the method in Ref. [22].
(iii) The third model studied was the coverage dependent model with φnnn =
φnnn(γ(θ)), where no constraints on the values of any of the parameters were
imposed, and the whole parameter space was searched for a global minimum.
A three-dimensional plot of the parameter space is shown in Fig. 3(a),
where the diameters of the symbols are proportional to 1/ ˆχ2 for ﬁts to
20 mM (circles) and 10 mM (squares) of the mean-ﬁeld-enhanced simulations.
The parameter space for the non-mean-ﬁeld-enhanced method (not shown) is
similar. Figure 3(a) shows the existence of several local minima and a good
overlap between the minima for both concentrations. The position of the
accepted global minimum is indicated by the arrows. Figure 3(b) is a pro-
jection onto the γ0, γ1 plane, which shows that the minima are concentrated
within one region close to the γ1 = 0 plane, suggesting a relatively weak de-
pendence of γ on the coverage. Moreover, the ˆχ2 values in the γ1 = 0 plane
0.3 (model (ii)) are signiﬁcantly larger than
(model (i)) and for γ0 = γ1 =
the ˆχ2 values for the accepted global minimum (model (iii)). Figures 3(c)
and 3(d) show that while the magnitude of γ0 decreases monotonically with
increasing A, there is no general trend for γ1 as a function of A.

−

Due to the existence of several shallow minima of ˆχ2, and due to the
limited resolution of the grid in parameter space, we list in Table 1 the best-
ﬁt parameter values for each model, along with all ﬁts that have ˆχ2 within
10% of the best-ﬁt value. One can see in Table 1 that there are two possible
sets of parameters that ﬁt to the 10 mM data for model (iii) with mean-
ﬁeld-enhanced simulations. To discriminate between these possible ﬁts to the
10 mM data we check if they are also possible ﬁts to the 20 mM experimental

7

−

−

−

−

0.4, γ1 =

55 meV, γ0 =

data. The ﬁrst set (A =
90 meV) is the overall best ﬁt for 10 mM. However,
−
it ﬁts only slightly better than the second set (A =
55 meV), and it is not
a possible ﬁt to the 20 mM experimental data. The only parameter set
0.2) that is a possible ﬁt to both the
(A =
10 mM and 20 mM experimental data, is the accepted best ﬁt for model (iii).
Using the same approach for the non-mean-ﬁeld-enhanced method, models
(i) and (ii), and concentration, results in a unique set of parameter values
for each model, simulation method, and concentration. These accepted ﬁts
are summarized in Table 2. Notice in Table 2 that for the accepted global
minimum of model (iii), and for both mean-ﬁeld-enhanced and non-mean-
ﬁeld-enhanced methods, the values of γ0 and γ1 are reasonably close to the
ones calculated from the experimental data [3] using the method of Ref. [22].
Also note that the ﬁts for 10 mM are consistently better than the ﬁts to the
20 mM experiments. This might be due to violation of the dilute-solution
limit at the higher concentration. This may also be the reason that the
values of µ0, which are expected to be the same for both concentrations
when ﬁt to a single simulation, diﬀer consistently by about 12
7 meV
between the concentrations. The values of A are consistently less negative
for the longer-ranged lateral interactions of the mean-ﬁeld-enhanced than for
the non-mean-ﬁeld method. This is not surprising.

±

The quality of the ﬁts is better for model (iii), as can be seen from the
plots corresponding to each of the models (Figs. 2, 4, and 5). Models (ii) and
(i) ﬁt worse at either the lower-coverage part of the isotherm (model (ii)),
see Fig. 4, or at the upper part of the isotherm (model (i)), see Fig. 5. In
contrast, the best-ﬁt simulations in Fig. 2 ﬁt the experiments well over the
whole range of coverages. The plots for the non-mean-ﬁeld-enhanced ﬁts (not
shown) are similar. A plot of γ vs E is shown is Fig. 6(a) for the best-ﬁt
values of γ0 and γ1 corresponding to the 10 mM experimental data for each
of the three models considered. Also shown are the values of γ obtained in
Ref. [3] by the method of Ref. [22]. While model (ii) is expected to ﬁt the
Ref. [3, 22] values of γ, model (iii) also predicts a mean value of γ close to,
but slightly more negative than, the mean of the values of γ from Ref. [3, 22].
The φnnn values corresponding to the best ﬁts of the three models are shown
in Fig. 6(b).

Since the ﬁts are sometimes better for the mean-ﬁeld-enhanced method,
and sometimes worse, the mean of the sets of parameters obtained by includ-
ing and excluding the mean-ﬁeld enhancement are reported here as our ﬁnal
results: A =
325 meV. In the

60 meV, γ0 =

0.4, γ1 =

0.2, and µ0 =

−

−

−

−

8

far-ﬁeld approximation used here, the lateral interaction energy between two
parallel dipoles separated by a distance a√2 is given by

φnnn =

1
4πǫ0

p2
(a√2)3

= A(1 + γ0 + γ1θ)2 = A

2

q
e (cid:19)

(cid:18)

,

(10)

q

where p =
d is the dipole moment, d is an eﬀective “dipolar distance,” and
the second and third equalities result from Eqs. (7) and (6), respectively.
Consequently,

|

|

p =

|

q
|
e ! q

4πǫ0(a√2)3A.

(11)

≈

For the A =
60 meV ﬁnal result, the dipole moment ranges between
−
p = 0.32 e˚A for θ = 0 and p = 0.26 e˚A for θ = 0.5, and the “dipolar
0.53 ˚A. Density Functional Theory calculations of a model
distance” d
without water [23] suggest a dipole moment of 0.46 e˚A, which is only about
40% higher than the ﬁtted value at low coverage. From na¨ıve physical intu-
ition, the dipolar distance might be expected to be of the order of the ionic
diameter of Cl, about 3˚A. The value of d obtained here involves several as-
sumptions. One main assumption used is that the dipole is a classical point
dipole, which should be quite reasonable as the distance between neighbor-
ing dipoles is about an order of magnitude larger than the obtained value
for d. Moreover, we have assumed that the interaction is a classical electro-
static dipole interaction, while there could be quantum eﬀects at the shortest
length scales. On the other hand, when viewed as a charge distribution, the
dipole is expected to have a much smaller “dipolar distance” than na¨ıvely
expected [24]. Using the relationship between the dipole moment and the
Helmholtz capacitance CH [16],

p =

d =

q

|

|

eǫ0
CH

(1 + γ),

(12)

and our values for the dipole moment and γ, we obtain a CH that is in the
range of 26 to 32 µF/cm2. This range is comparable to the reported value of
100 µF/cm2 [24], which would
CH for Ag(110) in chloride ion solution, CH
0.1 ˚A. This value of d is of the same order of magnitude
yield d = ǫ0/CH
as our value.

≈

≈

Finally, although models (i) and (ii) are still possible, a self-consistent
(φnnn(γ(θ))) entirely electrostatic model not only ﬁts better to the experi-
mental data but also, with no constraints imposed, predicts values of γ that

9

 
are reasonably compatible with those obtained from the experimental data
using the method of Ref. [22].

5 Comparison to Br/Ag(100)

±

−

21

Br electrosorption on the same substrate Ag(100) displays diﬀerent char-
acteristics. The electrosorption valency and the next-nearest-neighbor lat-
eral interaction energy are not only more negative, γ =
0.01 and
φnnn =
2 meV, but also independent of the coverage [3]. In other words,
while mutual depolarization [18] is present for Cl/Ag(100), this eﬀect is not
signiﬁcant for Br/Ag(100). Simulations of Br/Ag(100) using γ = γ0 + γ1θ,
when ﬁt to three experimental data sets, yielded γ1
0 [3]. Moreover, the
value obtained for γ (
0.71), is consistent with previous results from both
simulations and experimental analysis [2]. Since Cl is more electronegative
than Br, it is expected to have a less negative γ or a more negative resident
charge, consistent with our results.

0.71

−

−

≈

±

6 Conclusion

A discrepancy between the values of the electrosorption valency γ obtained
from ﬁtting simulations to experiments, and the value obtained from the
analysis [22] of experimental data was reported in a previous study by Abou
Hamad et al. [3]. This discrepancy suggested that the long-range interactions
are dominated by electrostatic dipole/dipole eﬀects for Cl electrosorption on
the Ag(100) single crystal surface.

In this work, a large set of MC simulations (2000 simulations) over a grid
in parameter space was ﬁtted to two sets of chronocoulometry experimental
data for diﬀerent concentrations. The existence of local minima of ˆχ2 in pa-
rameter space suggests alternative models. To within the resolution of our
grid and the accuracy of the experimental data, we have shown that while
other, simpler, models are still possible, a purely electrostatic model can be
used to describe the Cl/Ag(100) system. It also predicts an electrosorption
valency that is compatible with the value obtained through direct experimen-
tal data analysis by the method of Ref. [22]. Additional sets of experimental
data, with diﬀerent concentrations around 10 and 20 mM of the adsorbate
ion, along with a ﬁner grid in parameter space would enable a more decisive

10

determination of the most appropriate model and its parameter values.

Acknowledgments

We thank M.T.M. Koper and S. Frank for useful discussions and helpful
comments. We also thank M.T.M. Koper for bringing Refs. [17, 18] to our
attention. This work was supported in part by NSF grant No. DMR-0240078,
and by Florida State University through the School of Computational Science
and the Center for Materials Research and Technology, the Research Centre
J¨ulich, and the Netherlands Organization for Scientiﬁc Research (NWO).

Appendix

In this appendix we discuss the relationship between the electrochemical
potential µ and the electrode potential E for a coverage or ﬁeld dependent
electrosorption valency γ.

We deﬁne the electrosorption valency as [16]

γ =

∂σM
∂θ !E

,

−  

(13)

where σM is the charge on the metal, θ is the coverage, and µ is the chemical
potential of the solution (here taken as the dilute-solution approximation,
µ = kBT ln( C
C0 )). Considering an auxiliary thermodynamic potential X re-
lated to the surface tension α as

and using the Lippman equation,

X = α + θµ ,

dX = µdθ

σMdE ,

−

we have

∂X
∂E !θ
Consequently, one obtains the Maxwell relation, [16]

∂X
∂θ !σM

σM and

−

=

= µ .

γ =

∂σM
∂θ !E

=

∂X
∂E∂θ

=

∂µ
∂E !θ

.

−  

11

(14)

(15)

(16)

(17)

 
 
 
The relation, γ =

, gives the electrosorption valency as the change
in µ necessary to keep θ constant under a change in E. But to keep θ
constant, the electrochemical potential µ must remain constant, so that

θ
(cid:17)

(cid:16)

∂µ
∂E

γ =

∂µ
∂E !θ ≡  

∂µ
∂E !µ

.

It is easy to show that Eq. (3) satisﬁes this requirement for γ. If

then

µ = µ0 + kBT ln

C
C0 (cid:19) −

e

(cid:18)

E

E0

Z

γ(E′)dE′ ,

µ = µ + e

E

E0

Z

γ(E′)dE′ + const. ,

and

∂µ
∂E !θ
Generalization to multiple adsorbates is straightforward.

∂µ
∂E !µ

= γ(E) .

=

(18)

(19)

(20)

References

[1] T.L. Einstein, in: W.N. Unertl (Ed.), Handbook of Surface Science, vol.

1, Elsevier Science B.V., Amsterdam, 1996, p. 577-650.

[2] S.J. Mitchell, G. Brown, P.A. Rikvold, Surf. Sci. 471 (2001) 125.

[3] I. Abou Hamad, Th. Wandlowski, G. Brown, P.A. Rikvold, J. Elec-

troanal. Chem. 554-555 (2003) 211.

[4] I. Abou Hamad, P.A. Rikvold, G. Brown, Surf. Sci. 572 (2004) L355.

[5] O. Endo, M. Kiguchi, T. Yokoyama, M. Ito, and T. Ohta. J. Electroanal.

Chem., 473 (1999) 19.

[6] S.J. Mitchell, G. Brown, P.A. Rikvold, J. Electroanal. Chem. 493 (2000)

68.

[7] B.M. Ocko, J.X. Wang, Th. Wandlowski, Phys. Rev. Lett. 79 (1997)

1511.

12

 
 
 
[8] Th. Wandlowski, J.X. Wang, B.M. Ocko, J. Electroanal. Chem. 500

(2001) 418.

[9] O.M. Magnussen, Chem. Rev. 102 (2002) 679.

[10] G. Valette, A. Hamelin, R. Parsons, Z. Phys. Chem. Neue Fol. 113 (1978)

71.

[11] Th. Wandlowski, B.M. Ocko, J.X. Wang, in preparation (2005).

[12] S.J. Mitchell, S.W. Wang, P.A. Rikvold, Faraday Disc. 121 (2002) 53.

[13] M.T.M. Koper, J. Electroanal. Chem. 450 (1998) 189.

[14] M.T.M. Koper, Electrochim. Acta 44 (1998) 1207.

[15] K.J. Vetter, J.W. Schultze, Ber. Bunsenges. Phys. Chem. 76 (1972) 920;

ibid 76 (1972) 927.

[16] W. Schmickler, Interfacial Electrochemistry, Oxford Univ. Press, New

York Oxford, 1996, Chapter 18.

[17] L.D. Roelofs, D.B. Fromowitz, Surf. Sci. 388 (1997) 92.

[18] M.T.M. Koper, Surf. Sci. 395 (1998) L196.

[19] D.P. Landau, K. Binder, A Guide to Monte Carlo Simulations in Sta-

tistical Physics, Cambridge Univ. Press, Cambridge, 2000.

[20] K. Binder, Ann. Rev. Phys. Chem. 43 (1992) 33.

[21] P.A. Rikvold, Phys. Rev. B 32 (1985) 4756; Erratum: Phys. Rev. B 33

(1986) 6523.

[22] J. Lipkowski, J. Stolberg, in: J. Lipkowski, P.N. Ross, (Eds.), Adsorp-
tion of Molecules at Metal Electrodes, VCH Publishers, New York, 1992,
pp. 171-238.

[23] I. Abou Hamad, S.J. Mitchell, M.T.M. Koper, unpublished.

[24] W. Schmickler, J. Electroanal. Chem. 249 (1988) 25.

13

Figure 1: Cl (larger, dark gray, spheres) adsorbed at the 4-fold hollow sites of
the (100) surface of Ag (smaller, lighter gray, spheres). The grid frame corre-
sponds to the lattice of adsorption sites. The ﬁgure is drawn approximately
to scale.

14

θ

0.5

0.4

0.3

0.2

0.1

0
-1.25

Sim 10 mM: A= -55 meV, γ
-5
χ2
^
Sim 20 mM: A= -55 meV, γ
-5
χ2
^

= 2.0 x 10

= 3.3 x 10

0= -0.4, γ

1= -0.2

0= -0.4, γ

1= -0.2

Exp 10 mM

Exp 20 mM

-1

-0.75
E / V vs SCE

-0.5

-0.25

Figure 2: Best ﬁt of mean-ﬁeld-enhanced simulation to experimental 10 mM
and 20 mM coverage isotherms: A =
0.2
(model (iii)). L = 32.

55 meV, γ0 =

0.4, and γ1 =

−

−

−

15

Accepted

Global Minimium

1
6

Figure 3: A plot of 1/ ˆχ2 in the three-dimensional parameter space, obtained from ﬁts of mean-ﬁeld-enhanced
simulations to the 10 mM experimental data (squares) and the 20 mM experimental data (circles). The
diameters of the symbols are proportional to 1/ ˆχ2. (a) is a three dimensional view, (b) is a projection onto
the γ0, γ1 plane, and (c) and (d) are projections onto the γ0, A plane and the γ1, A, plane respectively. The
parameter space for the non-mean-ﬁeld-enhanced method (not shown) is similar.

θ

0.5

0.4

0.3

0.2

0.1

0
-1.25

Sim 10 mM: A= -30, meV γ
-5
χ2
^
Sim 20 mM: A= -25, meV γ
-5
χ2
^

= 6.1 x 10

= 8.0 x 10

0= -0.3, γ

1= -0.3

0= -0.3, γ

1= -0.3

Exp 10 mM

Exp 20 mM

-1

-0.75
E / V vs SCE

-0.5

-0.25

0.3 and
0.3 (model (ii)) for the 10 and 20 mM experimental data. Mean-ﬁeld-

Figure 4: Simulated constrained best ﬁt with the values of γ0 =
γ1 =
enhanced simulations are shown here. L = 32.

−

−

17

θ

0.5

0.4

0.3

0.2

0.1

0
-1.25

Sim 10 mM: A= -25 meV, γ
χ2
-5
^
Sim 20 mM: A= -25 meV, γ
-4
χ2
^

= 5.7 x 10

= 1.2 x 10

0= -0.4, γ

1= 0

0= -0.4, γ

1= 0

Exp 10 mM

Exp 20 mM

-1

-0.75
E / V vs SCE

-0.5

-0.25

Figure 5: Simulated constrained best ﬁt with a constant γ (model (i)) for
the 10 and 20 mM experimental data. Mean-ﬁeld-enhanced simulations are
shown here. L = 32.

18

γ

-0.5

-0.45

-0.4

-0.35

-0.3

-0.25

-1.25

-10

-12

-14

V
e
m

/

n
n
n

φ

-16

-18

-20

-1.25

(a)

0= -0.4, γ
γ
γ
0= -0.3, γ
0= -0.4, γ
γ
Ref. [3,19] γ

1= -0.2, model (iii)
1= -0.3, model (ii)
1= 0, model (i)

-1

-0.75
E / V vs SCE

-0.5

-0.25

A= -55, γ
A= -30, γ
A= -25, γ

0= -0.4, γ
0= -0.3, γ
0= -0.4, γ

1= -0.2, model (iii)
1= -0.3, model (ii)
1= 0, model (i)

(b)

-1

-0.75
E / V vs SCE

-0.5

-0.25

Figure 6: (a) The electrosorption valency γ vs E for the values of γ0 and
γ1 obtained from the best ﬁts for models (i), (ii), and (iii) to the 10 mM
experimental data. The values of γ obtained in Ref. [3] by the method of
Ref. [22] are also shown. (b) Corresponding plots of φnnn vs E for the three
models.

19

 
 
Table 1: Fitting parameters for Cl adsorption on a Ag(100) single-crystal
surface, for models (i), (ii), and (iii), with and without mean-ﬁeld interac-
tions. Possible ﬁts to within 10% of the best ˆχ2 for each model are also
shown. A and µ0 are in units of meV.

Mean-ﬁeld enhanced

Model

(i) Const. γ

(ii) Ref. [3, 22] γ
(iii) φnnn(γ(θ))

(i) Const. γ

A
25
5

−
−

30
90
55

−
−
−

30

−

γ0
0.4
0.3

−
−

10 mM
γ1
0
0

−
−

µ0
330
281

ˆχ2

105

×
5.664
5.769

0.3
0.5
0.4

0.3
0.1
0.2

−
−
−

0.4

0

−
−
−

−

−
−
−

−

266
371
318

6.068
1.815
1.976

330

5.369

(ii) Ref. [3, 22] γ
(iii) φnnn(γ(θ))

35
45
65

−
−
−

0.3
0.4
0.4

−
−
−

0.3
0.1
0.2

−
−
−

268
325
320

−
−
−

6.086
2.310
2.311

A
60
55
25
20
25
55

−
−
−
−
−
−

γ0
0.5
0.5
0.4
0.4
0.3
0.4

−
−
−
−
−
−

20 mM
γ1
0
0
0
0
0.3
0.2

−
−
−
−
−
−

µ0
390
396
340
349
285
328

−
−

105
ˆχ2
×
11.927
11.942
12.079
12.514
8.037
3.340

70
30
65
25
30
65

−
−
−
−
−
−

0.5
0.4
0.5
0.4
0.3
0.4

−
−
−
−
−
−

0
0
0
0
0.3
0.2

−
−

393
341
398
348
286
330

−
−
−
−
−
−

11.246
11.330
11.350
11.606
7.462
3.112

No mean-ﬁeld enhancement

Table 2: The best-ﬁt parameters for Cl adsorption on a Ag(100) single-
crystal surface, for models (i), (ii), and (iii), with and without mean-ﬁeld
interactions. A and µ0 are in units of meV.

Mean-ﬁeld enhanced

Model

(i) Const. γ
(ii) Ref. [3, 22] γ
(iii) φnnn(γ(θ))

(i) Const. γ
(ii) Ref. [3, 22] γ
(iii) φnnn(γ(θ))

A
25
30
55

−
−
−

30
35
65

−
−
−

γ0
0.4
0.3
0.4

−
−
−

0.4
0.3
0.4

−
−
−

10 mM
γ1
0
0.3
0.2

−
−
−

−
−

µ0
330
266
318

ˆχ2

105

×
5.664
6.068
1.976

A
25
25
55

−
−
−

γ0
0.4
0.3
0.4

−
−
−

No mean-ﬁeld enhancement

20 mM
γ1
0
0.3
0.2

−
−
−

−
−

µ0
340
285
328

ˆχ2
105
×
12.079
8.037
3.340

0
0.3
0.2

−
−

330
268
325

−
−
−

5.369
6.086
2.310

30
30
65

−
−
−

0.4
0.3
0.4

−
−
−

0
0.3
0.2

−
−

341
286
330

−
−
−

11.330
7.462
3.112

20"
Coordinate scaling in time-dependent current density functional theory,"  The coupling constant dependence is derived in time-dependent {\em current}
density functional theory. The scaling relation can be used to check
approximate functionals and in conjunction with the adiabatic connection
formula to obtain the ground-state energy from the exchange-correlation kernel.
The result for the uniform gas using the Vignale-Kohn approximation is deduced.
",http://arxiv.org/pdf/cond-mat/0502590v3,3,"5
0
0
2

n
u
J

2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

3
v
0
9
5
2
0
5
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Coordinate scaling in time-dependent current density functional theory

Maxime Dion and Kieron Burke
Department of Chemistry and Chemical Biology,
Rutgers University, 610 Taylor Rd., Piscataway, NJ 08854, USA
(Dated: November 6, 2018)

The coupling constant dependence is derived in time-dependent current density functional theory.
The scaling relation can be used to check approximate functionals and in conjunction with the
adiabatic connection formula to obtain the ground-state energy from the exchange-correlation kernel.
The result for the uniform gas using the Vignale-Kohn approximation is deduced.

PACS numbers: 31.15.Ew, 71.65.Gm

Time-dependent functional density functional theory
(TDDFT) [1] is developing rapidly as a tool for predicting
electronic response to laser ﬁelds, both weak and strong
[2]. For weak ﬁelds, linear response applies, and perhaps
the most popular present application of TDDFT is in
calculating optical response of molecules, including tran-
sition frequencies [3]. For strong ﬁelds, TDDFT allows
prediction of many properties in response to intense laser
pulses, such as high harmonic generation [4].
It seems
likely that TDDFT will play a key role in the emerging
ﬁeld of electron quantum control [2].

The time-dependent scheme can also be used for
strictly ground-state properties by using the adiabatic
connection formula to compute the static exchange-
correlation energy [5, 6, 7]. Although using TDDFT
to calculate ground-state properties might seem an
unwarranted complication, the approximate exchange-
correlation energy functional within this scheme has
many useful properties. For example, it correctly de-
scribes the static correlation for bond dissociation [8] and
can be used to calculate accurately van der Waals disper-
sion energies [9, 10, 11, 12].

To use TDDFT in the adiabatic connection formula,
one must generalize the response functions to arbitrary
coupling constant λ.
In DFT, this has a very precise
meaning, as the density is held ﬁxed while the Coulomb
repulsion between electrons is multiplied by λ [5, 6].
Coordinate-scaling is used to derive the λ-dependence
of quantities in DFT [13], or current DFT [14]. It leads
to many useful results, such as the virial theorem for the
exchange-correlation energy [13], and exact conditions on
that energy [15]. It can be used to check that approxi-
mate functionals have the right scaling behavior [16].

Time-dependent current density functional theory
(TDCDFT) is a more general scheme where the cur-
rent density is the basic variational parameter instead
of the density and it can include arbitrary magnetic
ﬁelds. Unlike TDDFT, TDCDFT can be approximated
with local or semi-local functionals without any con-
ceptual diﬃculty [17] and is now being used to calcu-
late excitations of quantum wells [18, 19], atoms [20],
molecules [21, 22, 23, 24] and single molecule trans-
port [25, 26]. Five years ago, the connection between
coordinate-scaling and the coupling constant was derived
for TDDFT [27]. The present paper generates analogous

results within the more general framework of TDCDFT.
TDCDFT [28, 29] starts from the Schr¨odinger equation

for N electrons in a vector potential aext:

1
2

(

N

i=1
X

(ˆpi + aext(ˆri, t))

2

+ ˆVext + ˆVee

Ψ = i

)

∂
∂t

Ψ (1)

P

the

denotes

one-body

ˆVext
where
potential,
ˆVee = 1
i,j=1 |ˆri − ˆrj|−1 and ˆpi = −i ˆ∇i. We use
N
2
atomic units throughout (e2 = me = ~ = 1), and there
included in
is an implicit speed of light constant, c,
i.e., B = c∇ × A, where B is
the vector potential,
the usual magnetic ﬁeld. The physical results from
the Schr¨odinger equation above are invariant under the
gauge transformation

¯vext(r, t) = vext(r, t) −

∂Λ(r, t)
∂t

¯aext(r, t) = aext(r, t) + ∇Λ(r, t),

(2)

(3)

where Λ is an arbitrary function. The gauge freedom can
be used, for example, to remove of the scalar potential
by choosing ∂Λ(r, t)/∂t = vext(r, t).

As the density is the conjugate variable to the scalar
potential vext(r, t), the conjugate variable to the vector
potential is the current density

ˆ(r, t) =

1
2

N

i=1
X

{ˆvi(t)δ(r − ri) + δ(r − ri)ˆvi(t)} ,

(4)

where ˆvi(t) = ˆpi + aext(ˆri, t). The basic theorem of TD-
CDFT [28, 29] states that, for a given initial wavefunc-
tion, a given j(r, t) is generated by at most one aext(r, t),
up to a gauge transformation. The density and the cur-
rent are related through the continuity equation

dn(r, t)
dt

+ ∇ · j(r, t) = 0

(5)

To derive the coupling constant dependence, we
i, λ2t′) in

ﬁrst transform the coordinates to (ri, t) = (λr′
Eq. (1):

1
2

(

ˆp′
i
λ

N

i=1 (cid:18)
X

′
+ aext(λˆr
i, λ

2

′

t

)

+ ˆV

′
ext,λ +

2

(cid:19)

′
ˆV
ee
λ )

′
λ =

Ψ

i
λ2

′
λ.

∂
∂t′ Ψ
(6)

 
 
 
 
 
 
ext,λ =

where the prime means that the quantity is evaluated at
i, λ2t′), and the scaled nor-
N
(r′, t′), ˆV ′
i=1 vext(λˆr′
N , λ2t′).
λ = λ3N/2 Ψ(λr′
malized wavefunction is Ψ′
Consistent with Ref.
[27], we deﬁne the scaled density
by nλ(r, t) = λ3 n(λr, λ2t). Now we also deﬁne the scaled
current density

1...λr′

P

jλ(r, t) = λ

2
4 j(λr, λ

t).

(7)

Continuity (Eq. (5)) remains satisﬁed for all λ. Multi-
plying Eq. (6) by λ2 and omitting the primes,

N

2

2

(cid:0)

t)

(

1
2

+ λ

i=1
X

ˆpi + λ aext(λˆri, λ

2 ˆVext,λ + λ ˆVee

∂
∂t
(8)
We deﬁne alext[j, Ψ0] as the vector potential for a sys-
tem with modiﬁed coupling constant λ, which gives rise
to current j starting from wavefunction Ψ0. Thus we
identify

Ψλ = i

)

(cid:1)

Ψλ.

aextl[jλ, Ψ0,λ](r, t) = λ aext[j, Ψ0](λr, λ2t).

(9)

Although the λ-dependence of the external potentials
in Eq.
(8) is generally complicated, by virtue of the
one-to-one correspondence between current and poten-
tials [28, 29], the vector potential appearing in Eq. (8)
is that unique potential producing current density j(r, t)
from the initial wavefunction Ψ0, with electron-electron
interaction λ ˆVee.

Next we apply the same argument to the Kohn-
Sham system, where the electrons are non-interacting
( ˆVee = 0) and aext(r, t) is replaced by an eﬀective vec-
tor potential, as(r, t), deﬁned to reproduce the same
current as the interacting system. Since our previous
argument does not depend on the interaction, aλ
s (r, t)
(9). And the Hartree vector poten-
also satisﬁes Eq.
t dt′
dr′ e2 n(r′, t′)/|r − r′|, satisﬁes
tial, aH(r, t) = ~∇
the same scaling. From the deﬁnition of the exchange-
correlation potential, as = aext + aH + aXC, we see that
it must obey the same scaling as the other vector poten-
tials:

R

R

aXCl[j; Ψ0, Φ0](r, t) = λ aXC[j1/λ; Ψ0,1/λ, Φ0,1/λ](λr, λ2t),
(10)
where there is also a functional dependence on the initial
Kohn-Sham wavefunction Φ0, from as(r, t). This is the
central result of this work.

When the vector potential is irrotational, i.e. can be
gauge-transformed to a scalar potential, the TDDFT
λ-dependence of Ref.
[27] can be derived from these
more general results. From the gauge transformation,
Eqs. (2,3), one can see that an irrotational vector poten-
tial is transformed to a scalar potential through ∂a/∂t =
∇v. Inserting Eq. (10), we ﬁnd

∇vλ

2
XC(r, t) = λ ∂aXC(λr, λ

t),
(11)
where ∇λ = ∂/∂(λr). Requiring the potential to vanish
XC(r, t) = λ2vXC(λr, λ2t)
far from the system we recover vλ

2
∇λvXC(λr, λ

3
t)/∂t = λ

from Ref.
[27]. This relation can also be derived directly
from Eq. (8) by the same arguments used for the vector
potential.

2

R

While Eq.

(9) represents the most general form,
applicable to all TDCDFT applications, we next look
at the special case of the linear response of an elec-
tronic system. The susceptibility, χ, is usually deﬁned
dr′dt′ χ(r, t; r′, t′) δv(r′, t′), where δn is a
by δn(r, t) =
small change in density due to a small perturbation in the
potential, δv. We sometimes represent the previous equa-
tion as δn = χ∗δv. Since we now have a vector potential,
we can generalize the linear response to δj = ←→χ ∗ δa. We
restrict ourselves to applying (time-dependent) pertur-
bations on systems for which the external potentials are
static. The response can then be considered as a func-
tional of the ground-state density only, not the current.
The scaling relation for the linear response exchange-
correlation kernel in TDDFT is given in Ref.
In
←→
fXC = δaXC/δj
TDCDFT the tensor analog is deﬁned as
and we can ﬁnd the scaling relation with the functional
diﬀerentiation

[30].

aXCl[n + δn](r, t) − aXCl[n](r, t) =
λ(aXC[n1/λ + δn1/λ](λr, λ
′ ←→

2

2

′
fXC[n1/λ](λr, r

, λ

′
dr

dt

λ

t) − aXC[n1/λ](λr, λ

2

t)) =

t − t

′

′
) δj1/λ(r

, t

′

) =

λ

Z

Z

3

(λ

d¯r)(λ

2

d¯t)

←→
fXC[n1/λ](λr, λ¯r, λ

2

(t − ¯t))

δj(¯r, ¯t)
λ4

Eq. (10) implies
←−→
′
f lXC[n0](r, r

, t − t

′

) = λ

2 ←→

′
fXC[n0,1/λ](λr, λr

2

′

(t − t

, λ

)),(12)

or, in frequency space,

←−→
′
f lXC[n0](r, r

, ω) =

←→
′
fXC[n0,1/λ](λr, λr

, ω/λ

2

).

(13)

These results are needed to implement the TDCDFT ver-
sion of the adiabatic connection formula as shown below.

In the special case of a uniform electron gas

←−→
f lXC[n0](q, ω) =

←→
fXC[n0,1/λ]

1
λ3

q
λ

,

ω
λ2

.

(14)

(cid:16)

(cid:17)

The above relation implies that, for a uniform gas, know-
ing the exchange-correlation kernel as a functional of the
density is the same as knowing the coupling constant de-
pendence; this was used for the equivalent TDDFT case
[30, 31].

There have been various approximations proposed for
←→
fXC [32, 33, 34, 35] and
fXC [36, 37] since they are such
important quantities. The main TDCDFT approximate
functional currently in use is the Vignale-Kohn (VK)
functional [17]. This is the gradient expansion in the
current density, and uses as input the q → 0 limit of
both the longitudinal exchange-correlation kernel, f L
XC(ω)
(which is precisely the scalar fXC(ω) of TDDFT), and the
transverse kernel, f T
XC(ω) of the uniform gas. We have
checked that the VK functional respects the above scal-
ing relation, Eq. (13), provided that f {L,T}
(ω) used in
constructing the functional also respect the appropriate

XC

scaling. The most recent approximation for these ker-
nel components is that of Qian and Vignale [37]. We
veriﬁed that it satisﬁes Eq. (14), assuming the Landau
parameters are invariant under simultaneous scaling of
the density and the coupling constant.

Just as for the exchange-correlation potential, the scal-
ing relation for the exchange-correlation can be derived
from TDCDFT. When the vector potential
is irrota-
←→
tional, the scaling relation of
fXC reduces to that of the
scalar kernel fXC [30], via

~∇~∇′f λ

XC[n0](r, r′, ω) = ω

2←−→
f lXC[n0](r, r′, ω)
2←→
2
fXC[n0,1/λ](λr, λr′, ω/λ
4 ~∇λ ~∇′

)

2
λfXC[n0,1/λ](λr, λr′, ω/λ
(15)
),

= ω

= λ

Then, since fXC → 0 as r → ∞ for any ﬁnite sys-
tem,
integration implies than the scaling of the cur-
rent kernel reduces to the scaling of the scalar ker-
XC[n0](r, r′, ω) = λ2fXC[n0,1/λ](λr, λr′, ω/λ2), as in
nel, f λ
[30].
Ref.

Similarly to the adiabatic connection formula used
in ground-state DFT [5, 6, 7, 38], which relates the
exchange-correlation energy to the susceptibility, we in-
troduce the adiabatic connection for the ground-state of
a system with a static scalar potential using current DFT
susceptibility

1

∞

0

∗

−∞

Tr

dλ

the

(16)

Z
is

←→
T

←→
χl − n0(r) 1

Z
trace

EXC = − 1
2

dω
2πi
(cid:16)h
Tr (←→a ) =
and
←→
T = −~∇Vee ~∇/ω2. The symbol 1 stands for δ(r − r′) δij.
The tensor susceptibility is related to the exchange-
correlation kernel through [39]
←→
χl =

i
i aii(r, r)

←→
T +

←−→
f lXC

←→
χs +

←→
χl ,

←→
χs

(17)

P

dr

λ

(cid:17)

R

(cid:16)
where ←→χs is the tensor susceptibility for the Kohn-Sham
system

(cid:17)

′
χs,ij(r, r

, ω) = n0(r) 1 +

(fα − fβ)

φ

Xα,β

∗

∗

α(r)~∇iφβ(r)φ

)~∇′
ω − (ǫβ − ǫα) + iη

β(r′

jφα(r′

)
(18)

where f is the occupation number, i.e. 1 for an occupied
state, 0 for an unoccupied one, and η is inﬁnitesimal.
The Kohn-Sham wavefunctions and energies are denoted
by φ and ǫ.

In the special case of a homogeneous gas, the longitu-
dinal and transverse responses decouple, and reordering

[1] E. Runge and E.K.U. Gross, Phys. Rev. Lett. 52, 997

(1984).

[2] J. Werschnik,

appear

to
http://xxx.lanl.gov/abs/cond-mat/0410362.

in

J.

E.K.U. Gross,
Chem.

and K. Burke,
(2005),

Phys.

3

the terms within the trace of Eq. (16) shows that only
the longitudinal components contribute to EXC, i.e., it
reduces to the usual scalar case. Lein et al [30] tested a
variety of approximations to the scalar fXC for the uni-
form gas, to see how well they reproduced the known
correlation energy. To perform the same test for the VK
functional, we ﬁrst note that, although VK is a gradient
expansion in the current, yielding terms of order q2, these
terms are actually zero-order in q when transformed back
to the equivalent scalar kernel via Eq. (15). So we ﬁnd
that VK, inserted in the current adiabatic connection
formula, reduces to inserting f L
XC (q → 0, ω)
in the usual scalar adiabatic connection formula. This
approximation was already tested by Lein et al, and is
labelled ‘local RA’ in their work. (Although they used a
diﬀerent parametrization [35] from QV [37], the results
are unlikely to depend strongly on such details.) They
found about a factor of 2 reduction in error relative to the
adiabatic local density approximation (ALDA). We have
thus demonstrated that, for the special case of the uni-
form gas, the VK approximation, inserted in the current
adiabatic connection formula, improves over ALDA.

XC(ω) = f unif

Carrying out a calculation of Eq.

(16) on molecules
or solids is much more computationally demanding than
the usual ground-state calculations with approximate
exchange-correlation energy functionals, but is probably
not much more expensive than the scalar case. Such cal-
culations are presently being performed [38, 40] because
the use of the adiabatic connection formula correctly de-
scribes the dissociation of molecules [8] and dispersion
energies [9, 10, 11, 12]. The exchange-correlation kernel
of TDCDFT being better suited to local or semi-local ap-
proximations than the pure density theory [17], we would
expect that it would supersede TDDFT when used within
the adiabatic connection formula.

To summarize, we have used coordinate scaling to de-
rive the coupling-constant dependence of the exchange-
correlation potential in TDCDFT. We have derived the
adiabatic connection formula for TDCDFT, and shown
how the VK approximation performs for a uniform gas.
We have also given explicit formulas relating both po-
tentials and kernels in TDCDFT to their couterparts in
TDDFT. Given both the recent use of TDDFT exchange-
correlation kernels in the adiabatic connection formula,
for calculating bond dissociation curves, and the use and
tests of TDCDFT for excitations in which TDDFT has
shown limitations, it is clear that an important appli-
cation of this work is likely to be realized in the near
future.

Work supported by NSF grant CHE-0355405.

[3] F. Furche and K. Burke, in Annual reports in computa-
tional chemistry, ed. D. C. Spellmeyer (Elsevier, Amster-
dam, 2005).

[4] M.A.L. Marques and E.K.U. Gross, Annu. Rev. Phys.

Chem. 55, 427 (2004).

[5] D.C. Langreth and J.P. Perdew, Solid State Commun.

[23] M. van Faassen and P.L. de Boeij, J. Chem. Phys. 120,

17, 1425 (1975).

8353 (2004).

[6] O. Gunnarsson and B.I. Lundqvist, Phys. Rev. B 13,

[24] M. van Faassen and P.L. de Boeij, J. Chem. Phys. 121,

4274 (1976).

10707 (2004); (e) ibid. 121, 7035 (2004).

[7] D.C. Langreth and J.P. Perdew, Phys. Rev. B 15, 2884

[25] K. Burke, Roberto Car, and Ralph Gebauer, Phys. Rev.

4

(1977).

[8] M. Fuchs, Y.-M. Niquet, X. Gonze,

Burke,
http://dft.rutgers.edu/pubs/publist.html, no. 87.

J. Chem. Phys.

094116

122,

and K.
(2005).

[9] V.P. Osinga, S.J.A. van Gisbergen, J.G. Snijders, and

E.J. Baerends, J. Chem. Phys. 106, 5091 (1997).

Lett. 94, 146803 (2005).

[26] K. Burke, M. Koentropp, and F. Evers, submitted,

Spring 05, http://xxx.lanl.gov/abs/cond-mat/0502385.

[27] P. Hessler, J. Park, and K. Burke, Phys. Rev. Lett. 82,
378 (1999); Phys. Rev. Lett. 83, 5184 (1999) (E).
[28] S.K. Ghosh and A.K. Dhara, Phys. Rev. A 38, 1149

[10] W. Kohn, Y. Meir, and D.E. Makarov, Phys. Rev. Lett.,

(1988).

80, 4153 (1998).

[11] A.J. Misquitta, B. Jeziorski, and K. Szalewicz, Phys.

[29] G. Vignale, Phys. Rev. B 70, 201102(R) (2004).
[30] M. Lein, E.K.U. Gross, and J.P. Perdew, Phys. Rev. B

Rev. Lett. 91, 033201 (2003).

61, 13431 (2000).

[12] M. Dion, H. Rydberg, E. Schr¨oder, D.C. Langreth, and
B.I. Lundqvist, Phys. Rev. Lett. 92, 246401 (2004).
[13] M. Levy and J.P. Perdew, Phys. Rev. A 32, 2010 (1985).
[14] S. Erhard and E.K.U. Gross, Phys. Rev. A 53, R5 (1996).
[15] M. Levy, Phys. Rev. A 43, 4637 (1991).
[16] M. Levy, in Density Functional Theory, eds. R. Dreizler
and E. K. U. Gross, NATO ASI Series (Plenum, New
York, 1995).

[31] R. Asgari, M. Polini, B. Davoudi and M.P. Tosi, Phys.

Rev. B 68, 235116 (2003).

[32] E.K.U. Gross and W. Kohn, Phys. Rev. Lett. 55, 2850

(1985); 57, 923 (1986) (E).

[33] E.K.U. Gross and W. Kohn, Phys. Rev. Lett. 57, 923

(1986).

[34] M. Petersilka, U.J. Gossmann, and E.K.U. Gross, Phys.

Rev. Lett. 76, 1212 (1996).

[17] G. Vignale and W. Kohn, Phys. Rev. Lett. 77, 2037

[35] C.F. Richardson and N.W. Ashcroft, Phys. Rev. B 50,

(1996).

[18] C. A. Ullrich, G. Vignale, Phys. Rev. B, 58, 7141 (1998).
[19] C.A. Ullrich and G. Vignale, Phys. Rev. Lett. 87, 037402

(2001).

[20] C.A. Ullrich and K. Burke, J. Chem. Phys. 121, 28

(2004).

[21] M. van Faassen, P.L. de Boeij, R. van Leeuwen, J.A.
Berger, and J.G. Snijders, Phys. Rev. Lett. 88, 186401
(2002).

[22] M. van Faassen, P.L. de Boeij, R. van Leeuwen, J.A.
Berger, and J.G. Snijders, J. Chem. Phys. 118, 1044
(2003).

8170 (1994).

[36] R. Nifosi, S. Conti, and M. P. Tosi, Phys. Rev. B, 58,

12758 (1998).

[37] Z. Qian and G. Vignale, Phys. Rev. B 65 235121 (2002)
[38] F. Furche and T. Van Voorhis, J. Chem. Phys. 122,

164106 (2005).

[39] G. Vignale and W. Kohn, in Electronic Density Func-
tional Theory: Recent Progress and New Directions, eds.
J.F. Dobson, G. Vignale, and M.P. Das (Plenum, NY,
1998), pg. 199.

[40] M. Fuchs and X. Gonze, Phys. Rev. B 65, 235109 (2002)."
"System-adapted correlation energy density functionals from effective
  pair interactions","  We present and discuss some ideas concerning an ``average-pair-density
functional theory'', in which the ground-state energy of a many-electron system
is rewritten as a functional of the spherically and system-averaged pair
density. These ideas are further clarified with simple physical examples. We
then show that the proposed formalism can be combined with density functional
theory to build system-adapted correlation energy functionals. A simple
approximation for the unknown effective electron-electron interaction that
enters in this combined approach is described, and results for the He series
and for the uniform electron gas are briefly reviewed.
",http://arxiv.org/pdf/cond-mat/0503071v2,3,"5
0
0
2

y
a
M
8
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
1
7
0
3
0
5
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

System-adapted correlation energy density functionals from eﬀective pair interactions

Paola Gori-Giorgi and Andreas Savin
Laboratoire de Chimie Th´eorique, CNRS, Universit´e Pierre et Marie Curie, 4 Place Jussieu, F-75252 Paris, France
(Dated: November 8, 2018)

We present and discuss some ideas concerning an “average-pair-density functional theory”, in
which the ground-state energy of a many-electron system is rewritten as a functional of the spheri-
cally and system-averaged pair density f (r12). These ideas are further clariﬁed with simple physical
examples. We then show that the proposed formalism can be combined with density functional
theory to build system-adapted correlation energy functionals. A simple approximation for the un-
known eﬀective electron-electron interaction that enters in this combined approach is described, and
results for the He series and for the uniform electron gas are brieﬂy reviewed.

I.

INTRODUCTION

sions and perspectives.

Density Functional Theory (DFT) is nowadays the
most widely used method for the calculation of electronic
structure in both solid-state physics and quantum chem-
istry [1, 2, 3]. The accuracy of the results coming from
a DFT calculation is limited by the approximate nature
of the exchange and correlation energy Exc[n] and the
associated potential, its functional derivative. While, at
present, many algorithms for a very accurate or even ex-
act exchange potential vx(r) and energy Ex[n] are avail-
able [3, 4], better approximations for calculating accurate
correlation energies Ec[n] are still needed.

In a recent paper [5], we proposed an alternative ap-
proach to build the DFT correlation energy Ec[n]. The
method consists in solving simple radial equations to gen-
erate the spherically and system-averaged pair density
f (r12) along the so-called adiabatic connection. Besides
its practical use for DFT, we realized that this method
has many aspects that deserve to be better investigated,
including the possibility for an alternative theory com-
pletely based on f (r12). In this work, we sketch the basic
ideas for this alternative theory, we further discuss them
with simple physical examples, and we deal with some of
the aspects that went overlooked in Ref. [5]. The scope
of this paper is to lay the rigorous foundations for an
approach that will be further developed towards the con-
struction of a self-consistent scheme combining the radial
equations for f (r12) with the Kohn-Sham equations.

The paper is organized as follows. After deﬁning the
notation, we develop in Sec. III the formalism corre-
sponding to a theory based on the spherically and system
averaged pair density, reviewing at the same time the cor-
responding concepts for DFT. We hope that this parallel
treatment will make it easier for the reader to familiar-
ize with the new concepts. We then give, in Sec. IV,
some simple physical examples. Section V is devoted to
explain how the ideas of Sec. III can be used to build
correlation energy functionals for DFT. A simple, physi-
cally motivated, approximation for the unknown eﬀective
eletron-electron interaction that appears in our formal-
ism is discussed in Sec. VI, where applications to two-
electron atoms and to the uniform electron gas are also
brieﬂy reviewed. The last section is devoted to conclu-

II. DEFINITIONS

We start from the standard N -electron hamiltonian
(in Hartree atomic units, ~ = m = a0 = e = 1, used
throughout)

H = T + Vee + Vne,

T =

Vee =

Vne =

N

1
2

Xi=1
N

Xi6=j

|

−

1
2

2
i ,
∇

1
ri −

,

rj|

N

Xi=1

vne(ri),

(1)

(2)

(3)

(4)

where vne is the external potential due to nuclei. Given
Ψ, the ground-state wavefunction of H, we consider two
reduced quantities that fully determine, respectively, the
expectation values
i.e., the
Ψ
Vne|
usual one-electron density

Vee|

Ψ
h

Ψ
h

and

,
i

Ψ

i

|

|

n(r) = N

Xσ1...σN

Ψ(r, r2, ..., rN )
|

Z |

2dr2...drN ,

(5)

and the spherically and system-averaged pair density
2 over all
(APD), which is obtained as an integral of
r1 −
variables but r12 =

r2|

Ψ

,

|

|

|

N (N

f (r12) =

1)
−
2 Xσ1...σN
dRdr3...drN ,

×

(6)

Ψ(r12, R, r3, ..., rN )
|

Z |

2 dΩr12
4π

2 (r1 + r2). The func-
r2, and R = 1
where r12 = r1 −
tion f (r12) is also known in chemistry as intracule den-
sity [6, 7, 8, 9, 10, 11, 12], and, when multiplied by the
volume element 4πr2
12dr12, is proportional to the proba-
bility distribution for the electron-electron distance. We

 
 
 
 
 
 
then have

B. APDFT – The system-dependent functional

2

Ψ
h

Vee|

|

Ψ

i

=

Z

f (r12)
r12

Ψ

=

i
∞

|

Ψ
h

Vne|
dr12 =

Z
0

Z
f (r12)
r12

n(r)vne(r)dr (7)

4πr2

12dr12. (8)

In the following text we will also deal with modiﬁed sys-
tems in which the external potential and/or the electron-
electron interaction is changed. Thus, the notation Vee
and Vne will be used to characterize the physical system,
while the modiﬁed systems will be deﬁned by W and V ,
with

W =

1
2

N

Xi6=j

N

w(
|

ri −

rj |

),

V =

v(ri),

Xi=1

(9)

(10)

where the pairwise interaction w always depends only on
ri −

rj |

.

|

III. FORMALISM

In this section we present a “APD-functional theory”
(APDFT) based on the function f (r12) highlighting, step
by step, the analogies in reasoning with the derivation of
standard DFT.

A. DFT – The universal functional

In standard DFT one deﬁnes a universal functional of
the one-electron density n as resulting from a constrained
search over all the antisymmetric wavefunctions Ψ that
yield n [13]

˜F [n; Vee, T ] = min
Ψ→nh

Ψ

T + Vee|

|

Ψ

,
i

(11)

or, more completely, as a Legendre transform [14]

F [n; Vee, T ] = sup

v n

Ψ

min
Ψ h

|

T + Vee + V

Ψ

|

i

− Z

n(r)v(r)dr

.

o

(12)

In both Eqs. (11) and (12), the dependence on the
electron-electron interaction (and on the kinetic energy
operator T ) has been explictly shown in the functional.
The universality of the functional F stems exactly from
the fact that the e-e interaction is always 1/r (and that
T is always the same).

The ground-state energy E0 of the system can then be

obtained by minimizing the energy with respect to n,

E0 = min

F [n; Vee, T ] +

n (cid:26)

n(r)vne(r)dr

(cid:27)

Z

.

(13)

Similarly, we can deﬁne a system-dependent functional
(i.e., a functional depending on the external potential
Vne, and thus on the speciﬁc system) of the APD f (r12)
as

˜G[f ; Vne, T ] = min
Ψ→fh

Ψ

T + Vne|

|

Ψ

,
i

(14)

or better as

G[f ; Vne, T ] = sup

w n

Ψ

min
Ψ h

T + W + Vne|

|

Ψ

i

− Z

f (r12)w(r12)dr12

.
o

(15)

The ground-state energy can be obtained by a minimiza-
tion with respect to f

E0 = min

G[f ; Vne, T ] +

f (cid:26)

f (r12)
r12

dr12(cid:27)

.

Z

(16)

Evidently, with respect to DFT, the functional G has the
disadvantage of being not universal: in DFT, an approx-
imation for F should be in principle valid for all systems.
However, the crucial point for applications is understand-
ing how diﬃcult is to build a reasonable approximation
for G[f ; Vne, T ], given a certain Vne.
In the particular
combination of DFT and APDFT that we propose in
Sec. V the lack of universality of G is not an issue.

Another issue concerns the N -representability condi-
tions on f (r12), i.e., which contraints must a given f
satisfy to guarantee that it comes from the contrac-
tion of a N -electron wavefunction Ψ. This is a prob-
lem shared with other generalizations of DFT, like the
pair-density functional theory [15, 16, 17, 18, 19]. The
N -representability conditions on f (r12) are evidently re-
lated to those on the pair density, and we thus might ex-
pect that they are not a trivial matter [19]. The deﬁnition
of the functional G of Eq. (15) formally overcomes this
problem by giving a divergent (+
) answer for any non
N -representable f (when f is not N -representable the
right-hand side of Eq. (15) is not bounded from above),
but this is not a practical solution when coming to appli-
cations. As we shall see, in the particular use of APDFT
presented in Sec. V, this issue is not particularly crucial
from a practical point of view, since we use APDFT to
build correlation functionals for DFT

∞

C. DFT – Adiabatic connection

In density functional theory, one usually deﬁnes a set
of hamiltonians depending on a parameter λ [20, 21, 22],

H λ = T + W λ + V λ,

(17)

having all the same one-electron density, equal to the one
of the physical system

nλ(r) = n(r)

λ.

∀

(18)

If W λ=0 = 0 and W λphys = Vee, one switches continu-
ously from a noninteracting system to the physical sys-
tem, while keeping the density ﬁxed by means of a suit-
able external potential V λ. Obviously, the APD f (r12)
changes with λ. By the Hellmann-Feynmann theorem,

=

∂Eλ
0
Ψλ
∂λ
h
∂wλ(r12)
∂λ

∂W λ
∂λ

|

+

∂V λ
∂λ |

Ψλ

i
∂vλ(r)
∂λ

=

dr,

(19)

f λ(r12)

=

Z

dr12 +

n(r)

Z

so that by directly integrating Eq. (19), and by combining
it with Eq. (13), one obtains

F [n; Vee, T ] = Ts[n] +

λphys

dr12f λ(r12)

dλ

Z

∂wλ(r12)
∂λ

,

Z
0

(20)
where Ts[n] is the kinetic energy of a noninteracting sys-
tem of N electrons with density n(r).

More generally, one can be interested in using as a
starting point a system of partially interacting electrons,
corresponding to a particular value of the coupling λ (say,
λ = µ) between 0 and λphys. In this case, if Ψµ is the
wavefunction of the system with partial interaction W µ
(and external potential V µ) we have

3

so that

G[f ; Vne, T ] = Tf [f ] +

ξphys

dr nξ(r)

dξ

Z

∂vξ(r)
∂ξ

Z
0

, (25)

where Tf [f ] is the kinetic energy of a system of N free
fermions (zero external potential) having the same f (r12)
of the physical system. A simple example of such adi-
abatic connection is given in Sec. IV A. As we shall
see, given a conﬁned physical system, the correspond-
ing wξ=0(r12) must be partially attractive (in order to
create a bound cluster of fermions). This could in princi-
ple lead to “exotic” ground states for some of the systems
corresponding to ξ < ξphys. This issue is not considered
in this paper, and will be investigated in future work.

Similarly to the DFT case, it could be convenient to
choose as starting point a system with an external po-
tential corresponding to some coupling constant ξ (say,
ξ = α) between 0 and ξphys. If Ψα is the ground-state
wavefunction of the system with external potential V α
(and e-e interaction W α) we have

G[f ; Vne, T ] =

Ψα
h

T + V α
|
ξphys

|

Ψα

+

i

+

Z

α

dξ

Z

dr nξ(r)

∂vξ(r)
∂ξ

. (26)

F [n; Vee, T ] =

Ψµ
h

T + W µ
|
λphys

|

Ψµ

+

i
dr12f λ(r12)

+

Z
µ

dλ

Z

∂wλ(r12)
∂λ

.(21)

E. DFT – Kohn-Sham equations

Usually, the adiabatic connection is performed along a
linear path by setting W λ = λVee (thus λphys = 1),
but some nonlinear choices can be more convenient when
dealing with approximations.

One-particle equations in DFT can be obtained by
deﬁning a set of orthogonal orbitals ϕi(r) with occupa-
and
tion number νi that minimize
2 =
yield the density of the physical system,
n(r). This gives

1
2
ϕii
2 ∇
|
ϕi(r)
i νi|
|

ϕi| −

i νih

P

P

D. APDFT – Adiabatic connection

−
(cid:2)

We can also deﬁne a set of hamiltonians

H ξ = T + W ξ + V ξ,

(22)

in which the function f (r12) is kept ﬁxed, equal to the
one of the physical system,

f ξ(r12) = f (r12)

ξ,

∀

(23)

If V ξ=0 = 0 and V ξphys = Vne, we are switching con-
tinuously from a system of N free electrons interacting
with a modiﬁed potential wξ=0(r12), to the physical sys-
tem. That is, f (r12) is kept ﬁxed as ξ varies by means
of a suitable electron-electron interaction W ξ while the
one-electron density n(r) changes with ξ. Again, by the
Hellmann-Feynmann theorem, we ﬁnd

=

∂Eξ
0
∂ξ
∂wξ(r12)
∂ξ

=

Z

f (r12)

Ψξ
h

|

∂W ξ
∂ξ

+

dr12 +

Z

nξ(r)

Ψξ

∂V ξ
∂ξ |
i
∂vξ(r)
∂ξ

=

dr,

(24)

1
2 ∇

2 + v1(r)
(cid:3)
ϕi(r)
νi|
|

ϕi(r) = ǫi ϕi(r)
2 = n(r),

Xi

(27)

where the potential v1(r) is the Lagrange parameter for
the density. To fully specify these equations one needs
a rule for the occupation νi of the orbitals. The Kohn-
Sham choice corresponds to occupy the orbitals in the
same way as for a Slater determinant. This determinant
is the wavefunction of a system of N non-interacting elec-
trons constrained to have the same one-electron density
of the physical system, and leads to the identiﬁcation

Ts[n] = min

{ϕi}→n Xi

ϕi| −
h

1
2
2 ∇

,
ϕii

|

(28)

with the same Ts[n] of Eq. (20). The ground-state energy
of the physical system is then obtained via the Hartree-
exchange-correlation functional EHxc[n], deﬁned as the
Ts[n]. This also implies that, in
diﬀerence F [n; Vee, T ]
Eqs. (27), v1(r) = vKS(r) = vne(r) + δEHxc[n]/δn(r).

−

Usually, the Kohn-Sham equations are derived starting
from the noninteracting system with density n(r), rather

ϕi| −
than from a constrained minimization of
1
2
. This diﬀerent way of proceeding allows us to
2 ∇
keep the analogy with what we will do in the next sub-
section for APDFT.

i νih

ϕii

P

|

F. APDFT – eﬀective equations

Since the e-e interaction is spherically symmetric, the
relevant APD that determines
is a unidimen-
sional quantity. To obtain simple “two-particle” equa-
tions for f (r12) we start from the kinetic energy operator
for the scalar relative coordinate r12 =

Vee|

Ψ
h

Ψ

i

,

|

T12 =

2
r12 =
−∇

−

1
r12

d2
dr2
12

r12 +

r1|

|

r2 −
ℓ(ℓ + 1)
r2
12

,

(29)

ψii
and we perform a minimization of
with respect to some orthogonal “eﬀective” geminals
ψi(r12) constrained to yield f of the physical system,

ψi| − ∇

i ϑih

P

2
r12 |

2 = f , leading to

i ϑi|

ψi|

P

4

the kinetic and external-potential functional deﬁned in
Ref. [5], FKE[f ; Vne] = G[f ; Vne, T ]
Tg[f ]. This also
in Eqs (30), weﬀ (r12) =
leads to the identiﬁcation,
1/r12 + δFKE[f ; Vne]/δf (r12).

−

An important issue to be addressed concerning the ef-
fective equations (30) is whether a given physical (and
thus N -representable) f (r12) is also representable by the
simple “eﬀective-geminal” decomposition of Eqs. (30).
This question is similar to the one arising in DFT: is
a physical density always non-interacting representable?
In view of the more complex nature of f (r12) with re-
spect to n(r) we might expect that this problem is much
more diﬃcult to face in APDFT than in DFT. It seems
reasonable that at least the short-range part of a physical
f (r12) is representable by Eqs. (30), while the long-range
tail of f of an extended system could be problematic [26].

IV. SIMPLE PHYSICAL EXAMPLES:
TWO-ELECTRON SYSTEMS

[

2
r12 + weﬀ (r12)]ψi(r12) = ǫi ψi(r12)
−∇
ϑi|

2 = f (r12).

ψi(r12)
|

Xi

In this section we give some examples for two-electron
systems, in order to gain physical insight with some of
the ideas just introduced.

(30)

The interaction weﬀ (r12) is the Lagrange parameter for
f . Again, to fully specify these equations we need a rule
for the occupancy ϑi of the eﬀective geminals. For spin
compensated systems, we can choose to apply a rule that
resembles to a Slater determinant: occupancy 1 for even
ℓ (singlet symmetry), occupancy 3 for odd ℓ (triplet sym-
metry), up to N (N
1)/2 occupied geminals. This rule
has been applied to solve the eﬀective equations (30)
in the uniform electron gas, with rather accurate re-
sults [23, 24, 25]. It is however important to point out
that when we apply this occupancy rule to Eqs. (30)

−

1. there is no Slater determinant that can be asso-
ciated with our eﬀective geminals: the ψi are con-
strained to give the exact f that cannot be obtained
from a noninteracting wavefunction (for example,
any Slater determinant violates the cusp condition
satisﬁed by the exact f );

2. more generally, there is no wavefunction (and so no
physical system) that can be built from our eﬀective
geminals.

A. A picture from harmonic forces

A very simple picture of the whole adiabatic connection
path in both DFT and APDFT can be gained by looking
at an analytic-solvable model, i.e., a two-electron hamil-
tonian with only harmonic forces (harmonic electron-
nucleus attraction, and harmonic e-e repulsion too) [11],

−

2 K r2

H(K, k) =

2
1
1 −
2 ∇

2
2 + 1
1
2 ∇

r2|
2,
(33)
where K > 0 (attractive nucleus-electron potential),
k > 0 (repulsive e-e interaction), and K > 2k, to have a
bound system. For this hamiltonian,

2 K r2

r1 −

1 + 1

1
2 k

2 −

|

n(r) =

f (r12) =

2β3/2
π3/2 e−β r2
γ3/2
π3/2 e−γ r2

12,

,

β =

K (K

2k)
−
2k + √K

(34)

γ =

2k.

(35)

2
p
√K
1
2

−
√K

−

This last point implies that, if we deﬁne

1. DFT

Tg[f ] = min

{ψi}→f Xi

ψi| − ∇
h

2
r12 |

ψii

(31)

(with the determinant-like occupancy), we have in gen-
eral

Tg[f ]

= Tf [f ],

(32)

where Tf [f ] was deﬁned in Eq. (25). The total en-
ergy of the physical system can then be recovered via

If our “physical” system corresponds to some K = Kne
and k = kee, and we want to switch oﬀ the e-e interaction
(by setting, e.g., k = λkee) while keeping the density
ﬁxed, we will simply have to change Kne into K(λ) such
that β in Eq. (34) does not change. The function K(λ) is
shown in the upper panel of Fig. 1 for the case Kne = 3,
kee = 1. We see that, as λ
0, K(λ) decreases, because
→
a smaller attraction is needed to keep the electrons in
the density when there is no e-e repulsion. Of course,

6
.

(37)

 0

 0.5

 1

 2

 2.5

 3

 1.5
r12

f (r12) changes with λ, as shown in in the lower panel of
Fig. 1: as λ decreases, the “on-top” value f λ(r12 = 0)
gets larger. This reﬂects the fact that when there is no
e-e repulsion, it is more likely to ﬁnd the two electrons
close to each other.

2. APDFT

If, instead, we switch oﬀ the external potential, (e.g.,
by setting K = ξKne) while keeping f (r12) ﬁxed, we will
have to change the e-e interaction in order to keep γ of
Eq. (35) constant,

k(ξ) = 1

2 (ξ

1)Kne + kee.

−
The one-electron density along this adiabatic connection
is

(36)

nξ(r) =

β(ξ) =

,

e−β(ξ) r2

2β(ξ)3/2
π3/2
ξKne (Kne −

2
p
√Kne −

2kee)
2kee + √ξKne

→

Thus nξ(r) is a gaussian that, as ξ
0, becomes more
and more spread, as shown in the lower panel of Fig. 2.
When the external potential goes to zero, the system
becomes translationally invariant and the wavefunction
for the center-of-mass degree of freedom is simply a plane
wave. Correspondingly, the electron-electron interaction
changes with Eq. (36): we see from the upper panel of
Fig. 2 that, as ξ gets smaller, k(ξ) becomes smaller (less
repulsive), and then it changes sign at some 0 < ξ <
1, becoming an attractive interaction. For a conﬁned
system, when the external potential approaches zero, an
attractive e-e interaction is needed in order to keep f (r12)
ﬁxed. Moreover, in the very special case of harmonic
forces there is a value ξ∗ = 1
(0, 1) for which
the e-e eﬀective interaction is zero everywhere, wξ
= 0.
Of course, when the e-e physical interaction is the
Coulomb potential 1/r12 this cannot happen: a system
with the same f (r12) of the physical system cannot have
w = 0 everywhere. This can be simply understood by
thinking that there is no external potential that can force
the system to have the correct cusp [27] at r12 = 0. In
fact, along any adiabatic connection that keeps f (r12)
ﬁxed, equal to the one of a system with Coulombic e-e
interaction, wξ(r12) will always behave as 1/r12 in the
limit of small r12.

2kee/Kne ∈

−

∗

B. He atom

5

 3

 2.5

 2

 1.5

 1

 0.5

 0

K(λ)

λkee

 0

 0.2

 0.4

 0.6

 0.8

 1

λ

λ = 0

λ = 0.3

λ = 0.7

 0.1

 0.08

 0.06

)

2
1

r
(

λ

f

 0.04

λ = 1

 0.02

 0

FIG. 1: Adiabatic connection in DFT for the simple harmonic
hamiltonian of Eq. (33). The e-e interaction is multiplied by
a parameter λ, and the density is kept ﬁxed by a suitable
external potential (upper panel). The APD f (r12) changes
with λ as shown in the lower panel.

 3

 2.5

 2

 1.5

 1

 0.5

 0

-0.5

ξKne

k(ξ)

 0

 0.2

 0.4

 0.6

 0.8

 1

ξ

ξ = 1

ξ = 0.5

ξ = 0.1

ξ = 0.01

)
r
(

ξ

n

 0.6

 0.5

 0.4

 0.3

 0.2

 0.1

 0

 0

 0.5

 1

 1.5

 2

 2.5

 3

r

Consider now the two electrons of a He atom. They
2/r, and they repel
feel the attraction of the nucleus,
each other with potential 1/r12. Given the exact (or a
very accurate [28]) ground-state wavefunction Ψ, we can
calculate the “exact” density n(r) and the “exact” f (r12).

−

FIG. 2: Adiabatic connection in APDFT for the simple har-
monic hamiltonian of Eq. (33). The external potential is mul-
tiplied by a parameter ξ, and the function f (r12) is kept ﬁxed
by a suitable electron-electron interaction (upper panel). The
density n(r) changes with ξ as shown in the lower panel, and
as ξ → 0 becomes completely delocalized.

Now, we can consider the case in which W = 0 and n(r)
is kept ﬁxed (the KS system in DFT, Sec. III C), and the
one in which V = 0 and f (r12) is kept ﬁxed (APDFT,
Sec. III D):

)

2
1

r
(

1. DFT

λ

f

6

’exact’ (λ = λ

phys)

He

Kohn-Sham (λ = 0)

 0.16

 0.12

 0.08

 0.04

−

We construct a system which has the same density n(r)
of the physical one and no electron-electron interaction.
This is the KS system, in which the two electrons do not
interact (w = 0) and feel an external potential v(r) less
attractive than
2/r, as in the case of the harmonic po-
tential of Fig. 1. The APD f λ=0(r12) of this system will
be diﬀerent from the physical one, as shown in Fig. 3. We
see that the change in the function f when we switch from
the physical system to the KS one is qualititatively simi-
lar to the one of Fig. 1, i.e., at λ = 0 the “on-top” value is
higher than the physical one. In the case of Coulomb e-e
interaction the physical f (r12) has a cusp, f ′(0) = f (0),
due to the short-range divergence of 1/r12 [27].

2. APDFT

In APDFT, we can construct a system which has the
same f (r12) of the physical one, and zero external poten-
tial (V = 0). This is a system of two bounded fermions
interacting with the eﬀective potential wξ=0(r12) of Fig. 4
(calculated from an accurate [5, 28] f ). As in the case of
harmonic forces, the density of this system is completely
delocalized, because the wavefunction for the center-of-
mass degree of freedom is a plane wave. We can imag-
ine that along the linear adiabatic connection, vξ(r) =
2ξ/r, the corresponding wξ(r12) changes smoothly be-
−
tween 1/r12 (at ξ = ξphys = 1) and the potential
wξ=0(r12) of Fig. 4. As anticipated, we se that at ξ = 0
the eﬀective e-e interaction has an attractive part, which
is necessary to have the same f of a physical conﬁned sys-
tem. However, as already pointed out, for small r12, the
e-e interaction must always behave as 1/r12, to produce
the exact cusp in f (r12) [27].

V. FROM APDFT TO CORRELATION
ENERGY FUNCTIONALS FOR DFT

|

Ψ

Ψ
h

Vee|

In Sec. III we have underlined the similarity of the roles
played by n(r) and f (r12) from a mathematical point of
view: the former completely determines
, and
i
the latter
. However, while the KS system is a
i
substantial simpliﬁcation of the many-electron problem
(yielding to single particle equations), the auxiliary sys-
tem of Sec. III D (with zero external potential) is still a
complicated many-body object, consisting of N fermions
interacting with a partially attractive potential. The ra-
dial equations of Sec. III F are a great simpliﬁcation of

Vne|

Ψ
h

Ψ

|

 0

 0.5

 1

 1.5

 2

 2.5

r12

FIG. 3: The function f λ(r12) at the two ends of the adiabatic
connection in DFT for the He atom. For λ = 0, we have a
system of two noninteracting (W = 0) electrons constrained
by an external potential to yield the same density of the phys-
ical system. For λ = λphys we have the physical system with
full interaction 1/r12 and external potential −2/r (from the
wavefunction of Ref. [28]; see also Ref. [5]).

)

2
1

r
(

ξ

w

 6

 4

 2

 0

-2

-4

-6

He

1/r12 (ξ = ξ

phys)

ξ = 0

 0

 1

 2

 3

 4

 5

r12

FIG. 4: The electron-electron interaction wξ(r12) at the two
ends of the adiabatic connection in APDFT for the He atom.
For ξ = 0 we have a system of two free fermions (zero ex-
ternal potential) interacting with wξ=0(r12). This system has
the same f (r12) of the physical system, but a completely de-
localized one-electron density. For ξ = ξphys we have the
physical system, with e-e interaction 1/r12 and external po-
tential −2/r. (The potential w at ξ = 0 has been calculated
from the accurate wavefunction of Ref. [28]; see Ref. [5] for
more details.)

the problem, but we might expect that building approx-
imations for the whole functional FKE[f ; Vne] could be
not easy.

Our basic idea, instead, is to use APDFT to build what
is missing in DFT, i.e., to build f λ(r12) along the adia-
batic connection in DFT. As said in the Introduction, we
insert our approach in the framework of exact-exchange
DFT [3, 4, 29, 30] in which only the correlation energy
functional needs to be approximated. The ground-state
energy of the physical system is given by

E0 = Ts[n] +

n(r)vne(r)dr + EH[n] + Ex[n] + Ec[n],
(38)
where EH[n] is the usual Hartree term, Ex[n] is the ex-

Z

change energy, obtained by putting the Kohn-Sham or-
bitals in the Hartree-Fock expression for exchange, and
the correlation energy, Ec[n], is unkown. Equation (38)
can be also rewritten as

E0 =

ΦKSi

+ Ec[n],

ΦKS|
h

T + Vee + Vne|
where ΦKS is the Slater determinant of Kohn-Sham or-
bitals, i.e., the wavefunction of N noninteracting elec-
trons constrained to yield the same n(r) of the physical
system. Combining Eq. (20) with Eq. (39), we see that
the wanted correlation energy is given by

(39)

λphys

∞

Ec[n] =

Z
0

dλ

Z

0

where

dr12 4π r2

12 f λ

c (r12)

∂wλ(r12)
∂λ

,

(40)

−

−

f λ
c (r12) = f λ(r12)

f λ=0(r12) = f λ(r12)

fKS(r12).

(41)
Thus, in order to get the KS correlation energy, we should
compute f λ(r12) for each hamiltonian H λ of Sec. III C.
Our approach consists in solving the simple radial equa-
tions of Sec. III F for each H λ along the adiabatic con-
nection in DFT. This is not particularly expensive: we
are dealing with unidimensional equations, and, if the de-
pendence of wλ on λ is smooth, we will only need few λ
values (
30) between 0 and λphys. With this partic-
ular combination of APDFT and DFT, we do not need
to approximate the whole functional FKE along the DFT
adiabatic connection, but only its functional derivative,
i.e., the eﬀective interaction weﬀ (r12) which appears in
Eqs. (30), since the remaining information is provided
by DFT. As we shall see, simple physical arguments can
be used to build reasonable approximations for weﬀ (r12)
at each coupling strength λ.

∼

−

5

Since the eﬀective equations yielding f λ

c (r12) must be
solved for each system, we speak of system-adapted cor-
relation energy density functionals.

VI. BUILDING APPROXIMATIONS

In Ref. [5], we proposed and successfully tested a sim-
ple approximation for building weﬀ (r12) along the DFT
adiabatic connection for two-electron atoms. This ap-
proximation starts from w(0)
eﬀ (r12), the eﬀective e-e inter-
action that gives fKS(r12) when inserted in Eqs. (30). In
the special case of two-electron systems, w(0)
eﬀ (r12) is di-
rectly available in a KS calculation. For systems with
more than two electrons, w(0)
eﬀ (r12) could be calculated,
e.g., with the methods of Refs. [31, 32]. Then, the idea
is to build an approximation for a correlation potential,
to be added to w(0)
eﬀ (r12), which describes the change in
f when the e-e interaction is turned on, from zero to
wλ(r12). To do this, we deﬁned an average density n,

n =

1
N Z

dr n(r)2,

(42)

7

He

1/r12

c   approx.

weff

(0)
weff

c   ’exact’

weff

 0

 0.5

 1
r12

 1.5

 2

 8
 6
 4
 2
 0
-2
-4
-6
-8

FIG. 5: Construction of an approximation for the eﬀective
potential that generates the APD f (r12) of the He atom: w(0)
eﬀ
is the part of the potential that generates the APD of the
Kohn-Sham system. The “exact” [5, 28] correlation potential
wc
eﬀ and our approximation of Eq. (45) are shown, together
with the Coulomb repulsion 1/r12.

and, correspondingly, an average radius rs,

rs =

4π
3 n

−1/3

.

(43)

We then built a correlation potential wc,λ

eﬀ (r12), as

(cid:0)

(cid:1)

wc,λ

eﬀ (r12) = wλ(r12)

− Z|r|≤rs

r

n wλ(
|

r12|

−

) dr.

(44)

The idea behind Eq. (44) is the following: the e-e in-
teraction wλ is screened by a sphere of radius rs and
of positive uniform charge of density n that attracts the
electrons with the same interaction wλ. The average den-
sity n of Eq. (42) (and thus the average rs) is kept ﬁxed
to mimic the fact that the one-electron density does not
change along the adiabatic connection.

In order to gain insight with our construction, let us
consider the case of the physical system, wλ=λphys =
1/r12, for which Eq. (44) corresponds to

wc

eﬀ (r12) =

1
r12

(cid:18)

+

r2
12
2 r3
s −

3
2 rs (cid:19)

θ (rs −

r12) ,

(45)

where θ(x) is the Heaviside step function. In Fig. 5 we
reported, for the He atom, the potential w(0)
eﬀ which gen-
erates fKS, together with the “exact” correlation poten-
tial wc
eﬀ , and the approximation of Eq. (45). We see that
the potential w(0)
eﬀ is a conﬁning potential for the vari-
able r12: our idea is to include in this term, available
from DFT, the contribution to f (r12) coming from the
particular external potential of the system and from the
fermionic structure of the wavefunction. The remaining
part to be approximated, the correlation potential wc
eﬀ ,
must include the eﬀect of the e-e repulsion while keeping
the density ﬁxed, i.e., it must be essentially a screened
Coulomb interaction. We see from Fig. 5 that the simple
approximation of Eq. (45) is reasonable, i.e., the screen-
ing length is well approximated by rs of Eqs. (42)-(43).

eﬀ .

For comparison, the full Coulomb repulsion 1/r12 is also
shown. Notice that in the special case of two-electron sys-
tems we have Tg[f ] = Tf [f ], so that the potential wξ=0
of Fig. 4 corresponds, in Fig. 5, to the sum of w(0)
eﬀ and
the “exact” wc
[5], we inserted the potential w(0)
eﬀ (r12) +
In Ref.
wc,λ
eﬀ (r12) into Eqs. (30), and solved them for several two-
electron atoms. Our results can be summarized as fol-
lows: (i) at λ = λphys (i.e., for wλ(r12) = 1/r12) we ob-
tained APD f (r12) in close agreement with those coming
from accurate variational wavefunctions [28], especially
at small r12; (ii) by setting wλ(r12) = erf(λr12)/r12 (the
“erf” adiabatic connection), the KS correlation energies
from Eq. (40) have an error which is less than 4 mH for
2; (iii) again with the “erf” adia-
nuclear charges Z
batic connection, we found that when the reference sys-
tem corresponds to some λ = µ between zero and λphys
[as in Eq. (21)] our correlation energies are one order of
magnitude better for µ & 1/rs.

≥

The correlation potential of Eq. (45), originally pro-
posed by Overhauser [33], has been also used to solve the
eﬀective Eqs. (30) for the uniform electron gas (UEG),
yielding to a very accurate description of the short-range
part of f (r12) at all densities [23]. A more sophisticated
eﬀective potential, based on a self-consistent Hartree ap-
proximation, extended such accuracy to the long-range
part of the UEG f (r12) at metallic densities [24]. Other
simple approximations for weﬀ (r12) in the UEG have also
been proposed and tested [25].

8

sity f (r12), and we have suggested to combine it with
DFT to obtain system-adapted correlation energy func-
tionals. So far, the method has been tested for the He
series [5] and for the uniform electron gas [23, 24, 25],
yielding promising results.

In order to completely develop the approach presented
here, many steps are still to be performed and many is-
sues are to be addressed. Among them, the most rele-
vant ones concern the construction of better approxima-
tions for the eﬀective electron-electron interaction that
enters the formalism, and the implementation of a self-
consistent scheme to combine the Kohn-Sham equations
with the correlation energy functional arising from our
approach. Last but not least, with the approximations
tested so far our approach works very well for the short-
range part of f (r12), so that the combination with mul-
tideterminantal DFT [21, 34] (in which only the short-
range correlations are treated within DFT) is also very
promising and deserves further investigation.

Acknowledgments

VII. CONCLUSIONS AND PERSPECTIVES

We have presented the ideas concerning a theory
based on the spherically and system-averaged pair den-

We thank C. Umrigar for

the wavefunctions of
Ref.
[28]. This research was supported by a Marie
Curie Intra-European Fellowships within the 6th Euro-
pean Community Framework Programme (contract num-
ber MEIF-CT-2003-500026).

[1] W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).
[2] A.E. Mattsson, Science 298, 759 (2002).
[3] C. Fiolhais, F. Nogueira, and M. Marques (eds.), A
Primer in Density Functional Theory (Springer-Verlag,
Berlin, 2003).

[4] see, e.g., S. K¨ummel and J.P. Perdew, Phys. Rev. B 68,
035103 (2003); W. Yang and Q. Wu, Phys. Rev. Lett. 89,
143002 (2002); R. J. Magyar, A. Fleszar, and E. K. U.
Gross, Phys. Rev. B 69, 045111 (2004); M. Gr¨uning, O.
V. Gritsenko, and E. J. Baerends, J. Chem. Phys. 118,
7183 (2003).

[5] P. Gori-Giorgi and A. Savin, Phys. Rev. A 71, 032513

(2005).

[6] A.J. Thakkar, A.N. Tripathi, and V.H. Smith, Jr., Int. J.
Quantum Chem. 26, 157 (1984), and references therein.
[7] C.A. Coulson and A.H. Neilson, Proc. Phys. Soc. London

78, 831 (1961).

[8] J. Cioslowski, B.B. Stefanov, A. Tan, and C.J. Umrigar,

J. Chem. Phys. 103, 6093 (1995).

[9] J. Cioslowski and G. Liu, J. Chem. Phys. 109, 8225

(1998).

[10] E. Valderrama, J.M. Ugalde, and R.J. Boyd, in Many-
electron densities and reduced density matrices, edited
by J. Cioslowski (Kluwer Academic/Plenum Publishers,
New York, 2000).

[11] E.R. Davidson, Reduced Density Matrices in Quantum

Chemistry (Academic Press, New York, 1976).

[12] A.J. Coleman and V.I. Yukalov, Reduced Density Ma-
trices: Coulson’s Challenge (Springer-Verlag, New York,
2000).

[13] M. Levy, Proc. Natl. Acad. Sci. U.S.A. 76, 6062 (1979).
[14] E. Lieb, Int. J. Quantum Chem. 24, 243 (1983).
[15] P. Ziesche, Phys. Lett. A 195, 213 (1994); M. Levy and

P. Ziesche, J. Chem. Phys. 115, 9110 (2001).

[16] A. Gonis, T.G. Schulthess, J. van Ek, and P.E.A. Turchi,
Phys. Rev. Lett. 77, 2981 (1996); A. Gonis, T.G.
Schulthess, P.E.A. Turchi, and J. van Ek, Phys. Rev.
B 56, 9335 (1997).

[17] A. Nagy, Phys. Rev. A 66, 022505 (2002).
[18] F. Furche, Phys. Rev. A 70, 022514 (2004).

9

[19] P.W. Ayers, submitted to J. Math. Phys.
[20] W. Yang, J. Chem. Phys. 109, 10107 (1998).
[21] A. Savin, F. Colonna, and R. Pollet, Int. J. Quantum

Chem. 93, 166 (2003), and references therein.

[22] J. Harris and R. Jones, J. Phys. F 4, 1170 (1974); D.C.
Langreth and J.P. Perdew, Solid State Commun. 17,
1425 (1975); O. Gunnarsson and B.I. Lundqvist, Phys.
Rev. B 13, 4274 (1976).

[23] P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 64, 155102

(2001).

tional wavefunctions described in this work to obtain one-
electron densities n(r) and functions f (r12). See also C.J.
Umrigar and X. Gonze, Phys. Rev. A 50, 3827 (1994),
and Ref. [8].

[29] M. Seidl, J.P. Perdew, and S. Kurth, Phys. Rev. Lett.

84, 5070 (2000).

[30] J.P. Perdew, A. Ruzsinszky, J. Tao, V.N. Staroverov,
G.E. Scuseria, and G.I. Csonka, J. Chem. Phys., to ap-
pear.

[31] F. Colonna and A. Savin, J. Chem. Phys. 110, 2828

[24] B. Davoudi, M. Polini, R. Asgari, and M.P. Tosi, Phys.

(1999).

Rev. B 66, 075110 (2002).

[25] M. Corona, P. Gori-Giorgi, and J.P. Perdew, Phys. Rev.
B 69, 045108 (2004); I. Nagy, R. Diez Mui˜no, J.I. Juar-
isti, and P.M. Echenique, Phys. Rev. B 69, 233105
(2004).

[26] P. Ziesche, to appear in Phys. Status Solidi B.
[27] A. K. Rajagopal, J. C. Kimball, and M. Banerjee, Phys.
Rev. B 18, 2339 (1978); X.-Y. Pan and V. Sahni, J.
Chem. Phys. 119, 7083 (2003).

[28] D.E. Freund, B.D. Huxtable, and J.D. Morgan III, Phys.
Rev. A 29, 980 (1984). We used an improved version
(provided to us by C. Umrigar) of the accurate varia-

[32] Q. Zhao, R. C. Morrison, and R. G. Parr, Phys. Rev.
A 50, 2138 (1994); R. van Leeuwen and E. J. Baerends
Phys. Rev. A 49, 2421 (1994).

[33] A.W. Overhauser, Can. J. Phys. 73, 683 (1995).
[34] A. Savin, in Recent Developments and Applications of
Modern Density Functional Theory, edited by J.M. Sem-
inario (Elsevier, Amsterdam, 1996); T. Leininger, H.
Stoll, H.-J. Werner, and A. Savin, Chem. Phys. Lett.
275, 151 (1997); R. Pollet, A. Savin, T. Leininger, and
H. Stoll, J. Chem. Phys. 116, 1250 (2002); J. Toulouse, F.
Colonna, and A. Savin, Phys. Rev. A 70, 062505 (2004)."
"Construction of model dielectric constants for two and three dimensional
  electron liquids from density functionals","  The Thomas-Fermi (TF) approximation for the static dielectric constant of a
three-dimensional electron liquid can be derived from minimizing the TF
local-density approximation for the kinetic-energy functional. Here we show
that this connection between energy functionals and model dielectric constants
is not an artifact of three-dimensionality or of the kinetic-energy functional,
but a general paradigm that can be exploited to build specific physical
phenomena into model dielectric constants by deriving them from suitable energy
functionals. Four examples are worked out in detail, by calculating the
dielectric constants that follow, respectively, from (i) exchange corrections
to TF theory in three dimensions, i.e., TF-Dirac theory, (ii) further
correlation corrections to TF-Dirac theory in three dimensions, (iii) TF theory
in two dimensions, and (iv) exchange corrections to TF theory in two
dimensions. Each of these cases has certain interesting features that are
discussed in some detail. As a byproduct of these investigations we also find
that a common textbook statement about the long-wavelength ($k\to0$) limit of
the random-phase approximation is not fully correct.
",http://arxiv.org/pdf/cond-mat/0509159v2,3,"5
0
0
2
c
e
D
2
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
9
5
1
9
0
5
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Construction of model dielectric functions for two and three dimensional electron
liquids from density functionals

A. P. F´avaro,1 Jo˜ao V´ıtor Batista Ferreira,2 and K. Capelle1,
1Departamento de F´ısica e Inform´atica, Instituto de F´ısica de S˜ao Carlos,
Universidade de S˜ao Paulo, Caixa Postal 369, 13560-970 S˜ao Carlos, SP, Brazil
2Departamento de F´ısica, CCET, Universidade Federal de Mato Grosso do Sul, Campo Grande, MS, Brazil
(Dated: June 20, 2018)

∗

The Thomas-Fermi (TF) approximation for the static dielectric function of a three-dimensional
(3d) electron liquid can be derived by minimizing the TF local-density approximation for the kinetic-
energy functional. Here we show that this connection between energy functionals and model dielec-
tric functions is not an artifact, but a general paradigm. Four examples are worked out in detail,
by calculating the model dielectric functions that follow, respectively, from (i) exchange corrections
to TF theory in 3d, i.e., TF-Dirac theory, (ii) further correlation corrections to TF-Dirac theory in
3d, (iii) TF theory in 2d, and (iv) exchange corrections to TF theory in 2d. Each of these cases has
certain interesting features, revealing connections between independent many-body methods, that
are discussed in some detail. As a byproduct of these investigations we also ﬁnd that a common
textbook statement about the long-wavelength (k → 0) limit of the random-phase approximation is
not fully correct.

PACS numbers: 71.45.Gm, 71.10.Ca, 71.15.Mb

I.

INTRODUCTION

Screening is one of the most important manifesta-
tions of many-body eﬀects in metals, semiconductors and
plasmas.1,2 In the Thomas-Fermi (TF) approximation,3
static screening in three-dimensional (3-d) electron liq-
uids is described by means of a wave-vector-dependent
dielectric function,4–6

ǫT F (k) = 1 +

k2
T F
k2 ,

(1)

p

4kF /πa0.
where the TF screening wave vector is kT F =
Here kF = (3π2n0)1/3 and a0 = ¯h2/me2 denote the Fermi
wave vector and the Bohr radius, respectively, and n0 is
the charge density of the unperturbed electron liquid.
This model dielectric function is sometimes used in its
own right as an approximation for screening in metals,
plasmas and doped semiconductors; more frequently, it
appears as starting point for, or limiting case of, more
sophisticated many-body treatments of screening.4–8 We
stress from the outset that our aim in the present work is
not the construction of high-precision or material-speciﬁc
expressions for the dielectric function, but to explore con-
nections between diﬀerent many-body methods that be-
come visible through the expressions they yield for the
dielectric functions.

The Thomas-Fermi approximation to the kinetic en-

ergy of a 3-d electron liquid is9,10

TT F [n] =

3¯h2(3π2)2/3
10m

Z

d3r n(r)5/3 = C

d3r n(r)5/3.

Z

(2)
While both ǫT F (k) and TT F [n] are widely known and
employed concepts, it is worthwhile stressing that the
two uses of the label ‘Thomas-Fermi’ are not equivalent:

the 3-d TF dielectric function can be obtained from the
TF energy functional by one additional approximation,
a linearization of the Euler equation resulting from min-
imizing TT F [n].7,11 To make our paper self-contained we
start, in Sec. II, by brieﬂy recalling this derivation.

The inclusion of many-body eﬀects beyond the TF
approximation is in general highly nontrivial, and typ-
ically accomplished by either constructing local-ﬁeld cor-
rections to the random-phase approximation (RPA),7 or
by ﬁrst-principles density-functional calculations of the
dielectric functions of realistic materials.12 In Sec. III we
show that certain important many-body eﬀects can be
incorporated into the TF dielectric function in a much
simpler way, by employing the Dirac-Slater local-density
approximation (LDA) for the exchange energy,8–10

ELDA
x

[n] =

3e2
4 (cid:18)

−

1/3

3
π (cid:19)

Z

d3r n(r)4/3

=

D

−

Z

d3r n(r)4/3.

(3)

(4)

to

this
the TF energy functional
Addition of
leads
so-called Thomas-Fermi-Dirac (TFD)
to the
approximation.8–10 Further correlation corrections can
be described by the local-density approximation9

ELDA
xc

[n] = ELDA

x

[n] +

Z

d3r ec(n)

n(r),

|n

→

(5)

is

where ec(n)
the per-volume correlation energy
of the uniform electron liquid13 underlying common
parametrizations of the LDA.9 In Sec. V we derive the
dielectric function arising from ELDA
. Secs. VI and VII
extend these calculations to two-dimensional electron liq-
uids, within TF and TFD theory, respectively. As a
byproduct of this investigation we also revisit, in Sec. IV,

xc

 
 
 
 
 
 
the long wavelength limit of the three-dimensional dielec-
tric function found in the RPA, which has as nontrivial
correction similar to the one found here within TFD the-
ory.

II. TF DIELECTRIC FUNCTION IN
THREE-DIMENSIONAL ELECTRON LIQUIDS

This derivation, although elementary, will be presented
in some detail, because it serves as a model for the more
complicated cases treated afterwards. The 3-d TF total-
energy functional is

ET F [n] = TT F [n] +

|

r

Z

Z

+

−

(6)

d3r

d3r′

e2
2 Z

d3r n(r)vext(r),

n(r)n(r′)
r′|
where the second term on the right-hand-side (rhs) is the
electrostatic (Hartree) energy of the charge distribution
n(r) with itself, and the third term describes the poten-
tial energy of this charge distribution in the external po-
tential vext(r), composed of a smeared-out background of
positive charge with constant density nbg and potential
vbg and an additional test charge ntest(r) with potential
vtest(r). It is the screening of this test charge, which is
normally taken to be a point charge, that the theory aims
to describe. Equilibrium is characterized by the condi-
µN )/δn(r) = 0, where the total particle
tion δ(ET F [n]
d3r n(r) and the chemical potential µ at
number N =
zero temperature is the Fermi energy ǫF . This minimiza-
tion leads to the Euler equation

−

R

5
3

Cn(r)2/3 + vext(r) + vH (r)

µ = 0,

(7)

−

where the Hartree potential
e2
r

d3r′ n(r′)/

r′

is vH = δEH [n]/δn =

. Solving Eq. (7) for n(r) we ﬁnd

R

|

−

|

2

Stability of the unperturbed electron liquid (with vtest =
0) requires n0 =
so that the background-
contribution to vext is cancelled precisely by the ﬁrst term
arising from the integral. Hence,

nbg,

−

vs(r) = vtest(r) + e2

d3r′

.

(11)

Z

nind(r′)
r′|
r

−
Upon Fourier transformation this becomes

|

vs(k) = vtest(k) + e2

[nind(r)]

F

F

[1/r],

(12)

stands for the 3-d Fourier transform opera-
where
F
tor.
In the second term we have used the convolu-
tion theorem to decompose the Fourier transform of the
Hartree potential into a product of two Fourier trans-
g0vs in this equation,
forms. By substituting nind =
using

[1/r] = 4π/k2, and solving for vs, we obtain

−

F

vs(k) =

vtest(k)
1 + e2g0F

[1/r]

=

vtest(k)
1 + 4kF
a0πk2

=

vtest(k)
ǫT F (k)

,

(13)

in agreement with the deﬁnitions following Eq. (1). For
the screening of a point charge with vtest(k) = 4πe2/k2
this becomes

vs(k) =

4πe2
k2 + k2

T F

.

(14)

Minimization of the TF kinetic-energy functional fol-
lowed by a minimization of the resulting Euler equation
thus reproduces the TF dielectric function

ǫT F (k) = 1 +

4kF
a0π

1
k2 .

(15)

In the following sections we explore whether this con-
nection between energy functionals and model dielectric
functions remains valid in more complex situations, char-
acterized by additional exchange and correlation terms in
the functional, and in two dimensions.

n(r) =

3/2

3
5C (cid:19)

(cid:18)

(µ

−

vs(r))3/2,

(8)

III. TFD DIELECTRIC FUNCTION IN
THREE-DIMENSIONAL ELECTRON LIQUIDS

where we have introduced the eﬀective, or screened, po-
tential vs = vH + vext.
If this potential is weak, i.e.,
vs/µ

1, Eq. (8) can be linearized to give

≪

n(r) =

3/2

3µ
5C (cid:19)

(cid:18)

1

(cid:18)

−

3
2

vs(r)

µ (cid:19)

.

(9)

F /3π2 (where ¯h2k2

By introducing the charge density of the unperturbed
system, n0 = k3
F /2m = µ), and the
corresponding 3-d density of states, g0 = mkF /¯h2π2, we
g0vs(r) =: n0 + nind. The
can write this as n(r) = n0 −
screened potential becomes

The fact that dielectric functions can be derived from
energy functionals opens up the possibility to incorporate
additional physics into a model dielectric function by us-
ing a more complete energy functional. To illustrate this
we now deduce an expression that incorporates exchange
eﬀects into the TF dielectric function. Starting point is
the 3-d TFD energy functional

ET F D[n] = ET F [n] + ELDA

x

[n],

(16)

where the functionals on the rhs are deﬁned in Eq. (6)
and (4), respectively. The Euler equation corresponding
to this functional is

vs(r) = vext(r) + e2

d3r′

Z

n0(r′) + nind(r′)

r

|

r′|

−

.

(10)

5
3

Cn(r)2/3 + vext(r) + vH (r)

4
3

−

Dn(r)1/3

−

µ = 0. (17)

In accordance with common practice
in density-
functional theory9,10 we regard the exchange term on the
rhs as a contribution to the eﬀective potential, now de-
ﬁned as

vs = vext + vH + vx = vext + vH −

(4D/3)n1/3.

(18)

The induced density change is deﬁned in terms of this
g0vs(r) =: n0 +
potential as before, via n(r) = n0 −
nind(r), and the counterpart to Eq. (12) becomes

vs(k) = vtest(k)+e2

[nind(r)]

F

1
r (cid:21)−

4D
3 F

F (cid:20)

[n1/3]. (19)

To evaluate this expression in closed form we linearize
n0, i.e., the
again, assuming consistently that nind ≪
self-consistent modiﬁcation of the density distribution
due to the test charge is small compared to the density of
the original unperturbed system. This allows us to write
n1/3
(1 + nind/3n0), and the preceding equation
becomes

n1/3
0

≈

vs(k) = vtest(k) + e2

[nind(r)]

F

1
r (cid:21)

F (cid:20)

4D
3 F

−

[n1/3
0

]

4D
9n2/3
0

F

−

[nind].

(20)

The last term can be handled as before, by using nind =
g0vsc. Since n0 is spatially constant, the Fourier trans-
−
form of the second-to-last term contributes only at k = 0.
Solving the preceding equation for vs we ﬁnd

vtest(k)
1 + kF

4D
1
r

[n1/3
]/3
0
1
πa0kF

,

F

vs(k) =

−
π2a0 F
where we have substituted the explicit expressions for
g0, n0 and D in terms of universal functions and the
Fermi wave vector. To identify the dielectric function
we consider again the screening of a point charge, with
vtest = 4πe2/k2. After a little algebra we ﬁnd

(21)

−

(cid:3)

(cid:2)

ǫT F D(k) = 1 +

4kF
πa0k2 −

1
πa0kF

= ǫT F (k)

αrs
π

−

, (22)

where in the last step we have introduced the usual elec-
tron gas parameters rs = 1/a0kF α and α = (4/9π)1/3.
Eq. (22) illustrates how exchange-corrections modify the
TF dielectric function, and also illustrates how by start-
ing from suitable energy functionals additional physics
can be built into models for ǫ(k).

Interestingly, the resulting additive exchange correc-
αrs/π, turns out to
tion to the TF dielectric function,
be the same already known to appear as the multiplica-
tive Hartree-Fock correction to the sound velocity (s),
compressibility (κ) and spin susceptibility (χ) of the 3-d
electron gas:1,2

−

ǫT F D(k)

−

ǫT F (k) = 1

s2
s2
0

−

= 1

κ2
0
κ2 = 1

−

χ0
χ

−

=

−

.

αrs
π
(23)

3

12

11

10

9
ε

8

7

6

5

0.6

0.61

0.62

0.63

0.64

0.65

0.66

0.67

0.68

0.69

0.7

k/k

F

FIG. 1: Three-dimensional Thomas-Fermi (dashed curves)
and Thomas-Fermi-Dirac (continuous curves) dielectric func-
tion vs. wave vector k/kF , for rs = 6 (upper curves) and
rs = 3 (lower curves). For comparison purposes we also in-
clude the k → 0 limit of the static RPA dielectric function
(dotted curves), as given in Eq. (26). For the density depen-
dence of the TF and TFD dielectric functions see Fig. 3.

The behaviour of ǫT F D(k) for two diﬀerent densities is
illustrated in Fig. 1. Exchange is seen to reduce screening
(i.e., to lead to a dielectric function closer to ǫ = 1 for all
k). This behaviour is easily understood because exchange
tends to keep particles apart, thereby making screening
less eﬀective. The limits of validity of Eq. (22) are similar
to that of ordinary TF theory, restricting the use of (22)
0).
to high and slowly varying densities (small rs and k

→

IV. LONG WAVELENGTH LIMIT OF THE
RANDOM-PHASE APPROXIMATION

In the random-phase approximation the static dielec-

tric function is given by1,2,4–7

1 + x
x (cid:12)
1
(cid:12)
(cid:12)
(cid:12)

k2
T F
2k2 (cid:20)

1 +

1
2x

(1

x2) ln

, (24)

ǫRP A(k) = 1 +

(cid:21)

−

−

(cid:12)
(cid:12)
(cid:12)
(cid:12)
In textbooks1,2,5,6,11,14 it is usually
where x = k/2kF .
0 the term in square brackets
argued that in the limit x
2x,
tends to 1, because, to linear order in x, ln
(cid:12)
so that the RPA dielectric function for long wavelength
(cid:12)
(cid:12)
0) = ǫT F (k) and
density oscillations becomes ǫRP A(k
(See, e.g., Eq. (5.65) of
thus recovers the TF result.
Ref. 1, p. 105 of Ref. 11, p. 140 of Ref. 6, Eq. (5.35) of
Ref. 2, or Eq. (28.9) of Ref. 14.)

1+x
1
x

→

→

→

(cid:12)
(cid:12)
(cid:12)

−

This statement, however, is not fully correct. More
precisely, it is not consistent in orders of k. To the order
in k to which TF theory provides an approximation to
ǫ(k), i.e., constant plus 1/k2, it is not enough to expand
the logarithm in Eq. (24) to linear order in x. Instead,
the expansion must be carried to cubic order, which after

multiplication by the prefactor 1
x2) also contributes
a constant term to ǫRP A(k). The RPA dielectric function
thus has the k

0 expansion

2x (1

−

→

ǫRP A(k

0) =

→

4kF
a0π

k−

2 +

1
(cid:18)

−

1
3

= ǫT F (k)

αrs
π (cid:19)
1
3

αrs
π

−

k0 + O(k2)(25)

+ O(k2).(26)

→

In the extreme k
0 limit all constants can be neglected
compared to 1/k2, and RPA and TF theory do indeed
predict the same divergence. However, already at the
level of constant corrections to this limit, RPA and TF
diﬀer, and the TF dielectric function in the form 1 +
k2
T F /k2 is never obtained as a long wavelength limit from
the RPA (except in the extreme case rs = 0).

Interestingly, the additional term

αrs/3π needed to
make the k
0 expansion of the static RPA consistent
in orders of k is, up to a factor 1/3 the same additional
term we found above as an exchange correction to the
TF dielectric function.

→

−

V. CORRELATION CORRECTIONS TO THE
THOMAS-FERMI DIELECTRIC FUNCTION

Further many-body eﬀects can be included by adding
the local-density approximation for correlation, Eq. (5) to
the TFD energy functional. We introduce the derivatives

and

vxc[n](r) =

δExc[n]
δn(r)

fxc[n](r, r′) =

δ2Exc[n]
δn(r)δn(r′)

.

(27)

(28)

4

30

25

20

15
ε

10

5

0
0.2

0.3

0.4

0.5

0.6

0.7

0.8

0.9

1

k/k

F

FIG. 2: Two-dimensional Thomas-Fermi (dashed curves) and
Thomas-Fermi-Dirac (continuous curves) dielectric function
vs. wave vector k/kF , for rs = 4 (upper curves) and rs = 1
(lower curves). Inclusion of exchange shifts the dielectric func-
tion to lower values, the shift being larger for lower densities
(larger rs), and for ﬁxed density larger in two than in three
dimensions. For the density dependence of the 2-d TF and
TFD dielectric functions see Fig. 3.

Interestingly, the inclusion of correlation, already on
the linearized LDA level, has introduced the exchange-
correlation kernel fxc in the corrected TF dielectric func-
tion, and thus lead to a dependence on local-ﬁeld correc-
tions that would ordinarily only be expected in sophis-
ticated beyond-RPA dielectric functions.1,2,7 The wave-
vector dependence of the local-ﬁeld correction, however,
is lost in the linearization.

and note that in the LDA, Eq. (5), the exchange-
correlation kernel fxc is

VI. TF DIELECTRIC FUNCTION IN
TWO-DIMENSIONAL ELECTRON LIQUIDS

f LDA
xc

[n](r, r′) =

∂2exc(n)
∂n2

|n
→
=: ¯f LDA
xc

n(r)δ(r

[n]δ(r

r′)

−

r′),

−

where the second equality deﬁnes the functional ¯f LDA
The Fourier transform of f LDA
xc
of the static local-ﬁeld factor

[n].
is simply related to that
(k) via9

xc

G

f LDA
xc

[n](k) =

e2

−

F (cid:20)

1
r (cid:21) G

(k),

(31)

[1/r] is the Fourier transfrom of the Coulomb

e2
where
F
interaction.

−

By going through the same steps as before we ﬁnd
for the dielectric function corresponding to correlation-
corrected TFD theory

ǫT F Dc(k) = 1 +

4kF
πa0k2 + g0 ¯f LDA
= ǫT F (k) + g0 ¯f LDA

xc

xc

[n0]

[n0].

(32)

(33)

(29)

(30)

Next, we extend the above analysis to two dimensions,
where our starting point is the 2-d local-density approx-
imation to the kinetic-energy functional,

TT F,2[n] =

π¯h2
2m Z

d2r n(r)2.

(34)

(Here and below 2-d energy functionals and dielectric
functions are distinguished from their 3-d counterparts
by a subscript 2. For all other quantities no confusion
can arise, and to avoid cluttering the formulas we use
the same symbol for them in 2-d as in 3-d.) By follow-
ing exactly the same steps as before we ﬁnd the Euler
equation

π¯h2
m

n(r) + vext(r) + vH (r)

µ = 0.

(35)

−

Unlike Eq. (8) in 3-d, this density-potential relation is
already linear, and no further approximation is needed to

write it in the form n(r) = n0 + nind(r). The 2-d Fermi
wave vector is related to the 2-d density via n0 = k2
F /2π,
and in terms of the 2-d density of states g0 = m/π¯h2
one immediately identiﬁes nind =
g0vs. All remaining
steps are the same as in 3-d, and from the 2-d Fourier
[1/r] = 2π/k one readily obtains
transform

−

F

vtest(k)
1 + e2g0F

[1/r]

=

vtest(k)
1
1 + 2
k
a0

=

vs(k) =
vtest(k)
ǫT F,2(k)

.

For screening of a point charge (36) becomes

vs(k) =

2πe2
k + kT F

,

(36)

(37)

where in 2-d kT F = 2/a0. The resulting density-
independent expression

ǫT F,2(k) = 1 +

2
a0

1
k

(38)

for the 2-d TF dielectric function is well known, e.g.,
in the context of 2-d electron liquids in semiconductor
heterostructures.15,18

Interestingly, the 2-d TF dielectric function follows
rigorously from the 2-d TF kinetic energy functional,
without an additional
in this
sense, (36) is a stronger result than its 3-d counterpart
(13).16 However, this stronger result is an artifact of two-
dimensionality, arising because the 2-d kinetic energy is
quadratic in n(r), and its density-derivative linear.

linearization. Hence,

On the other hand, the fact that ǫT F,2(k) is obtained
from TT F,2[n] in the same way ǫT F (k) is obtained from
TT F [n] shows that the relation between energy function-
als and dielectric functions in itself is not an artifact of
three-dimensionality.17

VII. TFD DIELECTRIC FUNCTION IN
TWO-DIMENSIONAL ELECTRON LIQUIDS

Finally, we work out the form of the exchange cor-
rections to the two-dimensional Thomas-Fermi dielectric
function. The per-particle exchange energy of a uniform
8√2/(3πrs)Ry.19,20
two-dimensional electron liquid is
where rs = 1/(a0√nπ) and Ry = e2/2a0. The local-
density approximation for Ex,2[n] is thus

−

ELDA
x,2

[n] =

4
3 r

2
π

e2

−

Z

d2r n3/2.

(39)

The 2-d TFD Euler equation can be cast in the same
form as before, n(r) = n0 + nind(r), where in 2-d n0 =
k2
g0,2vs, with vs = vext + vH + vx and
F /2π and nind =
2e2
2n/π. The Hartree potential arising from
vx =
the unperturbed density n0 and the potential energy in
the positive background (contained in vext) cancel again,

p

−

−

and by means of the convolution theorem the Fourier-
transformed screened potential becomes

5

2e2

F2 (cid:20)

1
r (cid:21) −

F2[nind(r)]

vs(k) = vext(k) + e2

2
π F2[√n].
(40)
The Fourier transforms in the second term on the rhs
g0,2vs(k) and
are easily evaluated by using nind =
F2[1/r] = 2π/k. To evaluate the Fourier transforms in
the third term we linearize in terms of nind/n0, as before,
and obtain

r

−

F2[√n0 + nind]

≈ F2[√n0]

−

1

2√n0 F2[nind].

(41)

for the 2-d screening of a point charge with

Hence,
vtest(r) = e2/r, we obtain

vs(k) =

2πe2
k

1
1
k −

,

√2
π rs

1 + 2
a0

(42)

where we have used rs = √2/a0kF for the 2-d density
parameter rs, and, as before, k δ(k)
0. As in the 3-
d case, the derivation from a kinetic-energy functional
allows us to build exchange eﬀects in a simple way into
the TF dielectric function.

≡

Interestingly, our ﬁnal expression

ǫT F D,2(k) = 1 +

2
a0

1
k −

√2
π

rs = ǫT F,2(k)

√2
π

−

rs (43)

has aquired a density dependence, through rs(n) =
1/a0√nπ.
Inclusion of exchange thus removes the un-
physical density-independence of ǫT F,2(k) obtained in the
2-d TF approximation (36). The behaviour of the 2-d
TF and TFD dielectric functions as a function of wave
vector and density is illustrated in Figs. 2 and 3. Cor-
relation corrections could be included in two dimensions
in the same way as in three dimensions. In the interest
of brevity we refrain from showing the straightforward
extension of the above expressions to this case.

On the other hand, we stress that in 2-d we obtain
the same chain of equalities as in 3-d, relating the addi-
tive corrrection to the dielectric function with multiplica-
tive renormalization of the sound velocity, compressibil-
ity and spin susceptibility of the 2-d electron gas:21,22

−

ǫT F D,2(k)

ǫT F,2(k) = 1

√2rs
π
(44)
Eq. (23) thus carries over to 2-d, with a modiﬁed density
dependence.

κ2
0
κ2 = 1

χ0
χ

s2
s2
0

= 1

−

=

−

−

−

.

VIII. SUMMARY AND ASSESSMENT

While the 2d and 3d TF dielectric functions ǫT F (k)
and ǫT F,2(k), given in Eqs. (15) and (38), are well known

22

20

18

16

14
ε

12

10

8

6

4

1

1.5

2

2.5

r
s

3

3.5

4

4.5

5

FIG. 3: Density dependence of the 3-d TF (dashed line),
3-d TFD (full
line), 2-d TF (dotted line) and 2-d TFD
(dash-dotted line) dielectric functions at ﬁxed wave vector
k = 1/3a0 (where λ = 2π/k = 6πa0 is the wave length of
the density variations in nind(r)). The change of the TF di-
electric function due to exchange corrections is a downshift
that is more pronounced at low densities (large rs). In 2-d
it is only because of the exchange corrections that a density-
dependence appears in the dielectric function.

(although not normally derived from density function-
als), their TFD counterparts ǫT F D(k) and ǫT F D,2(k),
Eqs. (22) and (43), and the correlation-corrected expres-
sion (33) are apparently derived for the ﬁrst time in this
work. We do not expect simple models of this type to
substitute the sophisticated models available from dia-
gramatic many-body physics,7 or the material-speciﬁc
dielectric functions that can be obtained from density-
functional theory.12 However, each of the four extensions
of the 3-d TF functional studied here displays interesting

6

features that were not obvious from the 3-d TF case, but
are revealed by deriving model dielectric constants from
density functionals.

Speciﬁcally in the 3-d TFD case, we found that the
exchange contribution to the TF dielectric function yields
a term of the same form as the long-wavelength expansion
of the RPA, if that expansion is carried out consistently
in orders of k. The standard way of identifying ǫT F (k)
as the k
0 limit of the static RPA is not consistent in
orders of k. Further correlation terms lead, already on
the linearized LDA level, to a simple dependence of the
dielectric function on local-ﬁeld factors.

→

Unlike the connection between the TF dielectric func-
tion and the Yukawa potential in real space, that be-
tween the TF dielectric function and energy functionals
carries over to two-dimensions, where ǫT F,2(k) turns out
to be a more robust expression than ǫT F (k) in 3-d, be-
cause it can be derived from the 2-d TF kinetic-energy
functional without any linearization. Upon including ex-
change (TFD), a density dependence reappears in the
2-d dielectric function, which is lost in the usual 2-d TF
dielectric function. In both 2d and 3d, the additive ex-
change contribution to the dielectric function turns out
to be the same as the multiplicative exchange renormal-
ization factor of other observables, such as the spin sus-
ceptibility.

The existence of a connection between a class of energy
functionals and a set of model dielectric functions opens
the question whether more detailed models for ǫ(k) can
be obtained from the more complex energy functionals
in use in modern density-functional theory. Models for
frequency-dependent dielectric functions may be accessi-
ble via time-dependent density-functional theory.23

Acknowledgments

This work was supported by FAPESP, CNPq and FUN-
DECT. We thank Lid´erio C. Ioriatti and Marco Polini
for useful discussions.

∗ Electronic address: capelle@if.sc.usp.br
1 P. Nozieres and D. Pines, The Theory of Quantum Liquids

(Addison Wesley, New York, revised printing 1989).

2 G. F. Giuliani and G. Vignale, Quantum Theory of the

Electron Liquid (Cambridge University Press, 2005).

3 L. Spruch, Rev. Mod. Phys. 63, 151 (1991).
4 N. W. Ashcroft and N. D. Mermin, Solid State Physics

(Saunders, Philadelphia, 1976).

5 J. M. Ziman, Principles of the Theory of Solids (Cambridge

University Press, London, 1972).

6 P. Phillips, Advanced Solid State Physics (Westview, Boul-

der, 2003).

7 G. D. Mahan, Many-Particle Physics, 2nd. ed., (Plenum,

New York, 1990).

8 N. H. March, Self-Consistent Fields in Atoms (Pergamon,

Oxford, 1975).

9 R. M. Dreizler and E. K. U. Gross, Density Functional

Theory (Springer, Berlin, 1990).

10 R. G. Parr and W. Yang, Density-Functional Theory of

Atoms and Molecules (Oxford University Press, Oxford,
1989).

11 W. Jones and N. H. March, Theoretical Solid State Physics

Vol. 1 (Wiley, London, 1973).

12 X. Cartoixa and L.-W. Wang, Phys. Rev. Lett. 94, 236804
(2005). E. Cockayne and B. P. Burton Phys. Rev. B 62,
3735 (2000). X. Blase, A. Rubio, S. G. Louie, and M. L.
Cohen, Phys. Rev. B 52, R2225 (1995). C. Lee and X.
Gonze, Phys. Rev. B 49, 14730 (1994). A. Dal Corso, S.
Baroni and R. Resta, Phys. Rev. B 49, 5323 (1994). M. S.
Hybertsen and S. G. Louie, Phys. Rev. B 35, 5585 (1987).
Z. H. Levine and S. G. Louie, Phys. Rev. B 25, 6310 (1982).
13 D. M. Ceperley and B. J. Alder, Phys. Rev. Lett. 45, 566

(1980).

14 E. Runge, E. K. U. Gross and O. Heinonen, Many-particle

theory (Adam Hilger, Bristol, 1991).

15 T. Ando, A. B. Fowler and F. Stern, Rev. Mod. Phys. 54,

437 (1982).

16 This is not immediately obvious from the alternative

derivation of ǫT F,2 via the usual textbook arguments re-
garding screening of slowly varying potentials.

17 To illustrate that this transfer from 3-d to 2-d is by no
means trivial, we remind the reader of the alternative
derivation of 3-d TF screening from a short-range Yukawa
−kT F r/r. Here screen-
potential in real space, vY (r) = e2e
ing is described by the exponential decay of the potential
away from the origin, where the point charge to be screened
is placed. The 3-d Fourier transform of this short-range po-
tential is

F[vY (r)] =

4π
k2

1
T F /k2 ,
1 + k2

(45)

which identical to (14). However, this identiﬁcation does
not carry over to 2-d: The 2-d Fourier transform of the
Yukawa potential is

F[vY (r)] =

2πe2
k2 + k2

T F

,

(46)

p
which is not identical to (37). Hence, the relation Yukawa-

7

potential—TF dielectric function is peculiar to 3-d sys-
tems, while the one between energy functionals and the
dielectric function carries over to 2-d.
18 F. Stern, Phys. Rev. Lett. 18, 546 (1967).
19 F. Stern, Phys. Rev. Lett. 30, 278 (1973).
20 A. Isihara, Electron Liquids, Springer Series in Solid-State

Sciences 96 (Springer, Berlin, 1998).

21 B. Davoudi, M. Polini, G. F. Giuliani and M. P. Tosi, Phys.

Rev. B 64, 153101 (2001).

22 B. Davoudi, M. Polini, G. F. Giuliani and M. P. Tosi, Phys.

Rev. B 64, 233110 (2001).

23 E. Runge and E. K. U. Gross, Phys. Rev. Lett. 52, 997
(1984). K. Burke and E. K. U. Gross in Density function-
als: Theory and applications, D. P. Joubert ed., Lecture
Notes in Physics, Vol. 500 (Springer-Verlag, Berlin, 1998).
E. K. U. Gross, J. F. Dobson, and M. Petersilka in Topics
in Current Chemistry 181, R. Nalewajski ed., (Springer,
Berlin, 1996)."
"Properties of short-range and long-range correlation energy density
  functionals from electron-electron coalescence","  The combination of density functional theory with other approaches to the
many-electron problem through the separation of the electron-electron
interaction into a short-range and a long-range contribution is a promising
method, which is raising more and more interest in recent years. In this work
some properties of the corresponding correlation energy functionals are derived
by studying the electron-electron coalescence condition for a modified
(long-range-only) interaction. A general relation for the on-top (zero
electron-electron distance) pair density is derived, and its usefulness is
discussed with some examples. For the special case of the uniform electron gas,
a simple parameterization of the on-top pair density for a long-range only
interaction is presented and supported by calculations within the ``extended
Overhauser model''. The results of this work can be used to build
self-interaction corrected short-range correlation energy functionals.
",http://arxiv.org/pdf/cond-mat/0511221v2,3,"6
0
0
2

b
e
F
0
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
1
2
2
1
1
5
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Properties of short-range and long-range correlation energy density functionals from
electron-electron coalescence

Paola Gori-Giorgi and Andreas Savin
Laboratoire de Chimie Th´eorique, CNRS, Universit´e Pierre et Marie Curie, 4 Place Jussieu, F-75252 Paris, France
(Dated: May 26, 2022)

The combination of density functional theory with other approaches to the many-electron prob-
lem through the separation of the electron-electron interaction into a short-range and a long-range
contribution is a promising method, which is raising more and more interest in recent years. In this
work some properties of the corresponding correlation energy functionals are derived by studying
the electron-electron coalescence condition for a modiﬁed (long-range-only) interaction. A general
relation for the on-top (zero electron-electron distance) pair density is derived, and its usefulness is
discussed with some examples. For the special case of the uniform electron gas, a simple param-
eterization of the on-top pair density for a long-range only interaction is presented and supported
by calculations within the “extended Overhauser model”. The results of this work can be used to
build self-interaction corrected short-range correlation energy functionals.

I.

INTRODUCTION

In recent years, there has been a growing interest in ap-
proaches that combine density functional theory [1, 2, 3]
(DFT) with other approximate methods to treat the
many-electron problem. In most cases, this combination
is achieved by splitting the Coulomb electron-electron in-
teraction 1/r12 into a short-range (SR) and a long-range
(LR) part (see, e.g., Refs 4, 5, 6, 7, 8, 9, 10, 11, 12).
The idea is to use diﬀerent, appropriate approximations
for the long-range and the short-range contributions to
the exchange and/or correlation energy density function-
als of the Kohn-Sham (KS) scheme, to treat, e.g., near-
degeneracy eﬀects or van der Waals forces. These ap-
proaches are often inspired by the observation that long-
range correlations are not well treated by local or semilo-
cal density functionals, but can be dealt with by other
techniques, like the standard wavefunction methods of
quantum chemistry. Conversely, correlation eﬀects due
to the short-range part of the electron-electron interac-
tion can be well described by local or semilocal function-
als (appropriately modiﬁed).

The error function and its complement (see Fig. 1),

1
r12

= vµ

SR(r12)+vµ

LR(r12) =

erfc(µr12)
r12

+

erf(µr12)
r12

, (1)

are often used [5, 6, 8, 10, 11] for the splitting of the
Coulomb interaction, since they yield analytic matrix el-
ements for both Gaussians and plane waves, i.e., the most
common basis functions in quantum chemistry and solid
state physics, respectively. The parameter µ controls the
range of the decomposition. Correspondingly, the uni-
versal Coulombic functional of the electron density n(r),
F [n], as deﬁned in the constrained search formalism [13],

 6

 5

 4

 3

 2

 1

 0

vSR = erfc(µr12)/r12

1/r12

vLR = erf(µr12)/r12

 0

 0.5

 1

 1.5

 2

 2.5

r12

FIG. 1: The splitting of the Coulomb interaction 1/r12 into
a short-range (SR) and a long-range (LR) part as deﬁned in
0 and
Eq. (1). Here µ = 1. When µ
→
vLR
1/r12 and
vLR

1/r12, and when µ
0.

→ ∞
0 we have vSR

we have vSR

→

→

→
→

tary short-range part, F [n] = F µ

LR[n] + F

µ
SR[n],

F µ

LR[n] = min
µ
SR[n] = F [n]

Ψµ→nh

F

Ψµ

T + V µ

Ψµ

i

LR|

|
F µ
LR[n],

−
or, alternatively, into a short-range part and a comple-
mentary long-range part

F µ

SR[n] = min

˜Ψµ→nh

˜Ψµ

T + V µ

˜Ψµ

i

SR|

F

µ
LR[n] = F [n]

|
F µ
SR[n].

−
These two decompositions lead to diﬀerent exchange-
correlation energy functionals that need to be approxi-
mated; they are compared in Ref. 14, where their advan-
tages and disadvantages are discussed.

(3)

(4)

F [n] = min

Ψ

Ψ→nh

T + Vee|

|

Ψ

i

(2)

can be divided into a long-range part and a complemen-

In the present work we focus on the properties of the
long-range and short-range correlation functionals that
come from the modiﬁcation of the electron-electron in-
teraction at short distances, i.e.
those properties that
are due to the change in the electron-electron coalescence

 
 
 
 
 
 
conditions. This means that we are only concerned with
the functionals of the decomposition of Eq. (3), which
involve a many-body wavefunction Ψµ of a system with
an electron-electron interaction that is softer than 1/r12
for small r12 (see Fig. 1). This decomposition is the one
used in the approaches of Refs. 5, 7, 8, 9, 10, 11.

→ ∞

The paper is organized as follows. In Sec. II we deﬁne
the long-range and short-range correlation energy func-
tionals that are the object of the present study. In Sec. III
we analyze the short-range properties of the pair den-
sity of a general many-electron system with interaction
erf(µr12)/r12 when µ gets larger and larger: we derive
an expansion for µ
of the on-top (zero electron-
electron distance) pair density, and, following (and partly
correcting) the work of Ref. 10, an expansion for µ
→ ∞
of the correlation energy functionals. Section IV is de-
voted to the special case of the uniform electron gas:
starting from the exact high-density limit, a simple pa-
rameterization of the on-top pair density as a function
of µ is proposed, and is favorably compared with the
results obtained from the “extended Overhauser model”
[15, 16] for the same quantity. The last Sec. V explains,
with some examples, how the results of this work can be
used to build self-interaction corrected approximations
for short-range correlation functionals.

Hartree atomic units are used throughout this work.

II. DEFINITIONS AND BASIC EQUATIONS

→

→ ∞

When the universal functional F [n] is decomposed as
in Eq. (3), we have a model system, whose wavefunc-
tion is denoted Ψµ, which has the same density n(r)
of the physical system and electron-electron interaction
erf(µr12)/r12. When µ
0 this model system becomes
the Kohn-Sham system, with no electron-electron inter-
the model system approaches
action, while when µ
the physical one, with interaction 1/r12. By deﬁnition,
the density is the same for all values of µ.
In the ap-
proach of Refs. 7, 8, 9, 10 the model system at a ﬁxed
µ is treated with a multideterminantal wavefunction. In
general, if µ is not too large, few determinants describe
Ψµ quite accurately (because of the smaller interaction,
and also because of the absence of the electron-electron
cusp); the larger is the chosen value of µ, the larger is the
needed conﬁguration space and thus the computational
cost. The remaining part of the energy is provided by
the complementary functional F
LR[n]
of Eq. (3), which can be divided into Hartree, exchange,
and correlation contributions in the usual way (for an
alternative separation of exchange and correlation, see
Ref. 17),

µ
SR[n] = F [n]

F µ

−

1
2

E

µ
H, SR[n] =

dr

Z
Z
µ
V µ
Φ
x, SR[n] =
Φ
SR|
|
h
µ
µ
SR[n]
c, SR[n] = F

E

E

dr′n(r)n(r′)vµ

SR(
|

r

r′

|

−

) (5)

E

µ
H, SR[n]
E

i −
µ
H, SR[n]
E

−

µ
x, SR[n],

(6)

(7)

−

2

µ

H, SR[n] and E

where Φ is the Kohn-Sham determinant. Notice that the
Hartree and the exchange functional are linear in the in-
µ
H, SR[n] = Eµ
teraction, so that E
x, SR[n] =
Eµ
H, SR[n] and Eµ
x, SR[n], where Eµ
x, SR[n] are the short-
range functionals of the decomposition of Eq. (4). The
correlation energy, instead, depends on the wavefunc-
= Eµ
tion Ψµ and we thus have E
c, SR[n]. The
µ
complementary correlation functional E
c, SR[n] is the dif-
ference between the usual Coulombic correlation energy
Ec[n], and the long-range correlation energy functional
Eµ

µ
c, SR[n]

c, LR[n],

Eµ
c, LR[n] =
|
µ
c, SR[n] = Ec[n]

Ψµ
h

E

T + V µ
Eµ

LR|
c, LR[n].

Ψµ

i − h

Φ

T + V µ

LR|

|

Φ

i

(8)

(9)

−

In what follows we study the short-range functional
µ
E
c, SR[n] or,
equivalently the long-range functional
Eµ
c, LR[n], in the limit of large µ, i.e., when the model
system described by Ψµ is approaching the physical sys-
tem.

Following Toulouse et al.

[10], we start from the

Helmann-Feynmann theorem which gives

∂
∂µ

E

µ
c, SR[n] =

2
√π

−

0
Z

∞

4πr2

12 f µ

c (r12) e−µ

2

r

2

12 dr12,

(10)
where the spherically and system-averaged pair density
(or intracule density) f µ(r12) is obtained by integrating
Ψµ
: we ﬁrst deﬁne
|
the spherical average of the pair density (with r = r1),

2 over all variables but r12 =

r2 −

r1|

|

|

˜P µ

2 (r, r12) =

N (N
2

−

1)

Ψµ(r, r12, r3, ..., rN )
|

|

2 dΩr12
4π

Z

×

σ1...σN
X
dr3...drN ,

and then integrate over all reference positions r,

f µ(r12) =

˜P µ

2 (r, r12) dr.

Z

(11)

(12)

The correlated part of f µ(r12) appearing in Eq. (10) is
f µ
c = f µ
fKS, where fKS(r12) is obtained by replacing
Ψµ with the Kohn-Sham determinant Φ in Eq. (11).

−

The correlated intracule f µ

c (r12) can be expanded in

its Taylor series around r12 = 0 up to some order M ,

f µ
c (r12) =

M−1

n=0
X

cn(µ) rn

12 + O(rM

12 ).

(13)

By inserting this expansion into Eq. (10) we ﬁnd [10]

∂
∂µ

E

µ
c, SR[n] =

−

M−1

4√π

cn(µ)
µn+3 Γ

n + 3
2

+O

1
µM+3

.

n=0
X

(cid:19)
(14)
This means that when µ
, i.e., when we are ap-
proaching the full interaction 1/r12, the correlation en-
µ
ergy functional E
c, SR[n] has an expansion in powers of

→ ∞

(cid:18)

(cid:19)

(cid:18)

6
µ−1 whose coeﬃcients are determined by the short-range
behavior of f µ
In order to determine as many coeﬃ-
c .
cients as possible in the expansion of Eq. (14) we thus
have to know how the cn(µ) behave in the limit of large
µ. In Ref. 10 the same expansion was considered, and
the ﬁrst two terms were obtained by simply inserting in
Eq. (14) the values of c0 and c1 for the physical system
(with Coulomb interaction). In the next Sec. III we study
the general problem of determining the short-range be-
havior of f µ(r12) in the limit µ
. We ﬁnd the same
→ ∞
µ−3) of Eq. (14),
result of Ref. 10 for the ﬁrst term (
∝
µ−4), and we
but a diﬀerent result for the second term (
explain why. Moreover, we obtain the ﬁrst-order (in µ−1)
term of the expansion for large µ of the on-top f µ(0).

∝

III. SHORT-RANGE BEHAVIOR OF A SYSTEM
WITH INTERACTION erf(µr12)/r12 WHEN µ

→ ∞

We start from the Schr¨odinger equation for the wave-

function Ψµ,

H µ Ψµ = Eµ Ψµ,

H µ =

N

−

i=1
X

2
i
∇
2

+

N

erf(µ

i>j=1
X

|

rj|

ri −
rj |

|
ri −

(15)

N

)

+

vµ(ri),

i=1
X

where the one-body potential vµ(r) keeps the density
equal to the one of the physical system for every µ.

When µ

r12| →

the interaction erf(µ r12)/r12 gets larger
→ ∞
1/µ). If we thus ﬁx a ﬁnite
and larger for small r12 (r12 ≪
but very large value of µ, we can use the same arguments
that lead to the derivation of the electron-electron cusp
condition for the Coulomb interaction [18, 19, 20, 21],
i.e., we can isolate two coalescing electrons (say, 1 and
2) in the hamiltonian of Eq. (15), and switch to vari-
r2 and R = (r1 + r2)/2. In the limit
ables r12 = r1 −
0 there must be a term in H µΨµ that
r12 =
|
compensates the divergence (or, more precisely, the very
large value) of erf(µ r12)/r12. As for the Coulombic sys-
tems, this compensation comes from the relative kinetic
energy term, and to determine the small r12 behavior of
2 we only need to look at
Ψµ
the spherical average of
|
the Schr¨odinger equation for the relative motion of two
electrons [18, 19, 20] approaching each other with rela-
tive angular momentum ℓ = 0. Higher ℓ, in fact, will
contribute to
12 in the limit of small r12.
Only in the case of a fully polarized system the case ℓ = 1
0 behavior
must be considered to determine the r12 →
2, since only odd ℓ are allowed [19] (triplet sym-
of
metry); this case is considered in Appendix B. The rare
case of unnatural parity singlet states [20] (which needs
ℓ = 2) is not considered in this work.

2 to orders r2ℓ

Ψµ

Ψµ

|

|

|

|

|

As it was done for the Coulomb electron-electron in-
teraction [18, 19, 20], we thus focus on the relative wave-
function ψµ(r12) for two electrons in the ℓ = 0 state.
By deﬁning x = r12 and uµ(x) = x ψµ(x), the relevant

(17)

(18)

Schr¨odinger-like equation reads

3

d2
dx2 +

erf(µx)
x

−

(cid:20)

(cid:21)

uµ(x) =

E

µ(x, R, r3, ..., rN )uµ(x),

E

(16)
µ is a complicated operator that does not aﬀect
where
and
the result as long as it remains bounded when µ
x
0, as it is reasonable to assume from the hamiltonian
of Eq. (15) [18, 19, 20]. We change variable y = µx, and
divide both members of Eq. (16) by µ2 to obtain

→ ∞

→

d2
dy2 +

1
µ

erf(y)
y

−

1
µ2 E

(cid:20)
We then expand uµ(y) for large µ,

(cid:21)

uµ(y) =

µ(y, R, r3, ..., rN )uµ(y).

uµ(y) = u(∞)(y) + 1

µ u(−1)(y) + O

1
µ2

,

insert this expansion into Eq. (17), and impose that the
left-hand-side be of order µ−2 as the right-hand side.
With the boundary condition that ψµ(x) is ﬁnite at
x = 0, we obtain

(cid:16)

(cid:17)

u(∞)(y) = ay

d2u(−1)(y)
dy2

= a erf(y),

(19)

(20)

and we ﬁnd that the ﬁnal solution for ψµ(x) from
Eqs. (19)-(20) is

ψµ(x) = a

1 + x p1(µx) +

(cid:20)

1
√πµ

+

A1
µ

+ ...

,

(21)

(cid:21)

where A1 is a constant coming from the integration of
Eq. (20) that is not determined by the condition that
ψµ(x) is ﬁnite in x = 0, and a determines the value ψ(0)
for the Coulombic system (µ =
). The function p1(y)
is given by

∞

p1(y) =

2

e−y
−
2√π y

2

+

1
2

+

1
4 y2

(cid:18)

(cid:19)

erf(y),

(22)

and has the following asymptotic behaviors

p1(y

→

0) =

p1(y

) =

→ ∞

y
3√π
1
2 −

+ O(y3)

1
√π y

+ O

1
y2

.

(cid:19)

(cid:18)

(23)

(24)

The spherically- and system-averaged pair-density of
Eq. (12) has thus, to leading orders in 1/µ for large µ,
the small-r12 expansion

f µ(r12) = f (0)

1 + 2 r12 p1(µr12) +
(cid:20)

(cid:21)
(25)
where f (0) is the on-top value corresponding to the full
interacting system [f (0) is proportional to a2, where a
determines u(∞)(y) in Eq. (19)]. Equation (24) tells us

2
√πµ

+

2A1
µ

,

∞

1,
that if in Eq. (25) we ﬁx r12 equal to a small value r0 ≪
and then let µ go to
we recover the Coulombic cusp,
f (r0) = f (0)(1 + r0 + ...). But for any ﬁnite large µ,
Eq. (23) shows that we always obtain a quadratic behav-
ior for small r12, f µ(r12) = f (0)(1 + 2r2
12µ/3√π + ...).
This is how the cuspless wavefunction corresponding
to the interaction erf(µr12)/r12 develops the Coulombic
cusp in the µ
limit. An alternative derivation
of Eq. (25), more similar to what one usually does for
the Coulombic cusp [18, 19, 20, 21], is reported in Ap-
pendix A.

→ ∞

To obtain the complementary short-range correlation
functional we can insert Eq. (25) into Eq. (14), which
gives

∂
∂µ

E

µ
c, SR[n] =

fc(0)

µ3 −

2π

−

4(√2π+A1π)

f (0)
µ4 +O

1
µ5

.

(cid:19)
(cid:18)
(26)
µ−4 in Eq. (26)
We see that to fully determine the term
we have to know the value of the constant A1. This
constant determines how the on-top f µ(0) approaches the
Coulombic value f (0) for large µ. In fact, from Eq. (25)
we have

∝

1
µ

2
√π

f µ(0) = f (0)

1 +

+ 2A1

+ O

.

(27)

(cid:20)
(cid:18)
In Ref. 10 the µ
limit of the long-range interaction
was formally rewritten as the Coulomb interaction 1/r12
plus a perturbation [10]

→ ∞

(cid:19)(cid:21)

(cid:19)

(cid:18)

1
µ2

erf(µr12)
r12

=

1
r12 −

π
µ2 δ(r12) + O

1
µ3

,

(cid:19)

(cid:18)

where δ(r) is the Dirac delta function. The fact that the
perturbation is of order µ−2 lead to the conclusion [10]
that the perturbation on Ψµ is also of order µ−2 with
respect to the Coulombic case, which would correspond
1/√π in Eq. (27). However, because of the
to A1 =
singular nature of the Dirac delta function, this argument
does not hold at r12 = 0.

−

→ ∞

To determine the correction to the on-top value when
µ
, here we take a large value of µ and a small value
1 (take, e.g. r0 = 1/µ1−q
r12 = r0 such that µ−1
r0 ≪
1
with 0 < q < 1). For such value of r0 we have µr0 ≫
so that from Eqs. (24) and (25) we obtain

≪

f µ(r0) = f (0)

1 + r0 +

(cid:18)

2A1
µ

(cid:19)

+ ...,

(29)

where the next leading terms are of order 1/µ2 and/or
r2
1/√π,
0. We then notice that A1 cannot be equal to
since any value of A1 < 0 would make f µ(r0) smaller
than the full interacting value f (r0), while, because for
small r12 the long-range interaction erf(µr12)/r12 is less
repulsive than 1/r12, for r0 small enough we expect that
f µ(r0)
0, and thus the correction to
the on-top value must be of order 1/µ. However, the
1/µ.
argument of Ref. 10 should be valid when r12 ≫

f (r0). So A1 ≥

−

≥

4

 1.12

 1.1

 1.08

 1.06

 1.04

 1.02

 1

 0.98

µ = 50

µ = 100

Coulomb cusp

 0

 0.02

 0.04

 0.06

 0.08

 0.1

r12

FIG. 2: The Coulombic cusp f (0)(1 + r12) (with f (0) = 1)
is compared to the expansion of f µ(r12) in the µ
limit,
f µ(r12) = f (0)(1 + 2r12p1(µr12) + 2/(√πµ) + 2A1/µ), with
A1 = 0. Any value A1 > 0 makes f µ(r12) diﬀer from the
1/µ.
Coulombic f (r12) of orders 1/µ also in the region r12

→ ∞

≫

That is, we still expect from Eq. (28) that the perturbed
Ψµ diﬀers from the Coulombic Ψ of an order higher than
1/µ. This is achieved only if A1 = 0, as
1/µ for r12 ≫
shown by Eq. (29). The result corresponding to A1 = 0
is illustrated in Fig. 2, where we compare the Coulomb
cusp f (0)(1+r12) to the short-range expansion of f µ(r12)
of Eq. (25), with A1 = 0. Any value of A1 larger than
zero makes the diﬀerence between the Coulombic f (r12)
and f µ(r12) of order 1/µ also in the region r12 ≫
1/µ,
while with A1 = 0 (as in Fig. 2) this diﬀerence is of higher
order, as expected from Eq. (28).

f µ(0) = f (0)

1 +

(cid:18)

2
√π µ

(cid:19)

+ O

1
µ2

.

(cid:19)

(cid:18)

(30)

This equation is also conﬁrmed in the next Sec. IV for the
case of the high-density electron gas that can be treated
exactly.

The ﬁnal expansion of the short-range functional
µ
c, SR[n] for large µ is then

E

E

µ
c, SR[n] = fc(0)

π
µ2 + f (0)

4√2π
3 µ3 + O

1
µ4

(cid:18)

(cid:19)

,

(31)

−

where f (0) and fc(0) are the on-top value and its corre-
lated part, fc = f
fKS, of the physical system. This
expansion diﬀers from the one of Ref. 10 by a factor √2
in the second term (see Appendix A for comments on
this discrepancy). The two expansions for the case of
the He atom are compared in Fig. 3 with the “exact”
results [9, 10] for E
c, LR[n]. The “exact”
c, SR[n] = Ec −
on-top value f (0) is taken from Ref. 22. We see that
the new expansion more accurately reproduce the “ex-
act” data for large µ, and that the µ-value for which it
breaks down (i.e., where the expansion has its minimum)
coincides with the minimum value of µ for which it still
gives accurate short-range correlation energies.

Eµ

µ

(28)

We thus conclude that

)
e
e
r
t
r
a
H

(

R
L

µ

,
c
E
−

c
E

 0

-0.01

-0.02

-0.03

-0.04

-0.05

this work

previous

He

’exact’

 0

 2

 4
 6
µ (a.u.)

 8

 10

µ
c, SR[n] = Ec

Eµ

FIG. 3: The “exact” values of E
c, LR[n] for
the He atom [9, 10] are compared with the large-µ expansion
of Eq. (31), and with the previous result for the same ex-
pansion given in Eq. (30) of Ref. 10. In both expansions the
“exact” on-top value is taken from Ref. 22.

−

In general the on-top value of the physical system,
f (0), is not accessible. A plausible approximation pro-
posed in Ref. 10 consists in replacing f (0) in Eq. (31)
with its local-density approximation (LDA) value,

fLDA(0) =

1
2

Z

n(r)2 g(r12 = 0; n(r)) dr,

(32)

where g(r12; n) is the pair distribution function [16, 23]
of the standard electron gas model (with Coulomb in-
teraction 1/r12) of uniform density n. The new Eq. (30)
allows to estimate the physical on-top value starting from
the one of the model system Ψµ. Potential applications
of this idea are discussed in Sec. V, together with simple
examples. Notice also that Eq. (30) is also valid locally,
i.e., we have

˜P µ
2 (r, r12 = 0) = ˜P2(r, r12 = 0)

1 +

2
√π µ

+ O

1
µ2

,

(cid:18)
(cid:19)
(33)
2 (r, r12) was deﬁned in Eq. (11), and ˜P2(r, r12)

where ˜P µ
is the pair density of the physical system (µ =

(cid:18)

(cid:19)

).

In Appendix B we also consider the case of a fully
polarized system, for which we ﬁnd that the short-range
correlation energy has the large-µ expansion

∞

E

µ
c, SR[n = n↑] = f ′′

c (0)

3π
8µ4 + f ′′(0)

3√2π
10 µ5 + O

1
µ6

,

(cid:18)

(cid:19)
(34)
where f ′′(0) and f ′′
c (0) are the second derivative at r12 =
0 and its correlated part of the physical, fully interacting,
system [24]. We also found that, again only in the case of
a fully polarized system, the second derivative of f µ(r12)
at r12 = 0 approaches the one of the Coulombic system
as

(f µ)′′(0) = f ′′(0)

1 +

(cid:18)

2
3√π µ

(cid:19)

+ O

1
µ2

.

(cid:19)

(cid:18)

(35)

5

IV. ON-TOP PAIR DENSITY OF A UNIFORM
SYSTEM WITH INTERACTION erf(µr12)/r12

Before coming to applications, we consider the special
case of the uniform electron gas, for which something
more than Eq. (30) can be done. We consider a uniform
system with long-range-only interaction,

H µ =

1
2

−

N

i=1
X

ri + V µ

LR + V µ

eb + V µ
bb,

2
∇

(36)

LR is the modiﬁed electron-electron interaction

where V µ

V µ
LR =

1
2

N

Xi6=j=1

erf(µ

ri −
rj|

|
ri −

|

rj|

)

,

(37)

V µ
eb is, accordingly, the interaction between the electrons
and a rigid, positive, uniform background of density n =
(4πr3

s /3)−1

V µ
eb =

n

−

N

i=1 Z
X

dx

erf(µ

ri −
x
|

|
ri −

|

)

x
|

,

(38)

bb is the corresponding background-background in-

and V µ
teraction

V µ
bb =

x

x′

n2
2

dx

dx′ erf(µ
x
|
H µ tends to the standard jellium hamil-
0 we recover the noninteracting

|
−

(39)

−
x′

Z

Z

)

|

|

.

When µ
→ ∞
tonian, while when µ
electron gas.

→

We focus on the µ-dependence of the on-top value of
the pair-distribution function [16, 23] g(r12 = 0, rs, µ),
which has its own interest to construct the LDA approx-
imation for the long-range and short-range functionals,
and for spin-density functional theory in the framework
of the alternative on-top interpretation [25]. The relation
between the function g and the function f of Eq. (12) is
g = 2f /nN .

A. High-density limit

As in the Coulomb gas, by switching to scaled units
si = ri/rs, we see that when rs →
0 the potential of
Eqs. (37)-(39) becomes a perturbation to the noninter-
acting gas. Deﬁning the correlation contribution to the
1
2 , and following
on-top value, gc(0, rs, µ) = g(0, rs, µ)
Kimball [26], the ﬁrst-order correction (with respect to
the interaction potential) to the on-top pair density is

−

gc(0, rs →

0, µ) = 6

∞

0
Z

∆SD(t, µ) t2 dt + ...,

(40)

where ∆SD(t, µ) is the direct second-order contribution
to the static structure factor [26],

∆SD(q, µ) =

k σ,k′ σ′ vee(q) nF(k)nF(k′

)[1−nF(k+q)][1−nF(k′

k2+k′2−(k+q)2−(k′−q)2

−q)]

,(41)

4
N

P

 
 
 
 
 
 
 
 
 
 
 
)
z
(
h

 0

-0.05

-0.1

-0.15

-0.2

-0.25

-0.3

-0.35

-0.4

 0

 5

 10
z

 15

 20

6

)
µ

,

s

r

,
0
(

c
g

 0
-0.05
-0.1
-0.15
-0.2
-0.25
-0.3
-0.35
-0.4
-0.45
-0.5

Overhauser model
interpolation formula
Coulomb (µ = ∞ )

µ = 0.3

µ = 0.5

µ = 1

µ = 3

µ = 15

 0

 2

 4

 6

 8

 10

rs

FIG. 4: The function h(z) that determines the high-density
limit of the on-top pair density of the “erf” gas [see Eq. (42)].
The numerical evaluation of Eq. (40) (points) is compared to
the ﬁtting function of Eq. (45) (solid line).

FIG. 5: The correlation on-top pair density of the electron
gas with interaction erf(µr12)/r12 for diﬀerent µ (in a.u.) as
a function of the dimensionless density parameter rs. The
results from the Overhauser model are compared with the
interpolation formula of Eq. (47). The dotted line corresponds
to the standard jellium model with interaction 1/r12.

nF is the usual Fermi occupation function [26] and vee(q)
is the Fourier transform of the electron-electron inter-
In Eq. (40) the scaled variable t = q/2kF
action.
[kF = (αrs)−1, α = ( 4
9π )1/3] has been used. The function
∆SD(t, µ) is thus equal to the one computed by Kim-
ball [26] and reported in his Eq. (11), except for a mul-
tiplying factor e−t
coming from the Fourier trans-
form of erf(µr12)/r12. From Eqs. (40) and (41) we ﬁnd

2
2
F /µ

k

2

gc(0, rs →

0, µ) = rs h(µ/kF ) + ...,

(42)

where the function h(z) has the following asymptotic be-
haviors

h(z

→

h(z

0) =

6α
π (1
−
) = aHD +

→ ∞

−

ln 2) z2 + O(z3)
α
√π z

+ O(z−2),

(43)

(44)

−

α(π2 + 6 ln 2

and aHD =
0.36583 is the
−
high-density limit of the standard jellium model. Notice
that Eq. (44) conﬁrms, for the high-density electron gas,
Eq. (30).

3)/5π

≈ −

For intermediate values of z we computed numerically
the function h(z), and we found that it can be accurately
ﬁtted by the Pad´e form

h(z) =

a1 z2 + a2 z3
1 + b1 z + b2 z2 + b3 z3 ,

(45)

6α
π (1

with a1 =
ln 2), b1 = 1.4919, b3 = 1.91528,
−
b3α/√π)/aHD. The numerical
a2 = aHD b3, b2 = (a1 −
results and the ﬁtting function of Eq. (45) are reported
in Fig. 4.

−

B.

Interpolation formula

The high-density limit of Eq. (42) and of Fig. 4 tells us
how (at least for small rs) gc(0, rs, µ) approaches the two

→ ∞

limits, the noninteracting gas (µ
gas (µ

).

0) and the Coulomb

→

A simple interpolation formula for all densities can be
built by assuming that the µ dependence of gc(0, rs, µ)
is roughly the same at each rs. We thus start from the
parameterization of the on-top pair density of the jellium
model given in Ref. 16,

1
2

−

(1

∞

) =

s + Er4

s + Dr3

g(0, rs, µ =

Brs + Cr2

s ) e−drs,
(46)
0.01277, E = 0.001859,
where C = 0.08193, D =
d, and we simply
d = 0.7524 and B =
rescale homogeneously all the coeﬃcients with the func-
tion h(z = µ/kF )/aHD,

−
2 aHD −

−

gc(0, rs, µ) =

1

e−d rs h(z)/aHD
2
h(z)3
a3
HD

h
r3
s + E

+D

B

−
h(z)4
a4
HD

h(z)
aHD

rs + C

1
2

.

r4
s

−

i

h(z)2
a2
HD

r2
s

(47)

This simple guess smoothly interpolates between the µ
0 and µ

limits, and is exact when rs →

→ ∞

0.

→

C. Results from the Overhauser model

To check the validity of the interpolation formula of
Eq. (47) we evaluated the on-top gc(0, rs, µ) within the
“extended Overhauser model” [15, 16], which gave good
results for the standard jellium model [16] and for two-
electron atoms [27]. Notice that the on-top value is not
known exactly. The diﬀerences between the jellium on-
top pair densities from diﬀerent approximate methods
(including the “extended Overhauser model”) are dis-
cussed in Refs. 28, 29, 30.

The scattering equations of the “extended Overhauser
model” are widely explained in Refs. 16, 31. Here we sim-

 
 
ply solved the same equations with the electron-electron
interaction erf(µr12)/r12 screened by a sphere of radius
rs of uniform positive charge density n and attracting the
electrons with the same modiﬁed interaction,

Veﬀ (r12, rs, µ) =

erf(µr12)

r12 −

n

r′

erf(µ
|
r′

|

−

−
r12|

r12|

)

dr′.

Z|r′|≤rs

(48)
This potential is reported in the Appendix of Ref. 27,
where it has been used for two-electron atoms with rather
accurate results for the corresponding short-range corre-
lation energy. Veﬀ (r12, rs, µ) is a screened potential that
tends to the “Overhauser potential”[15, 16] when µ
,
→ ∞
and which goes to zero when µ
0. As in the original
Overhauser model, the idea behind Eq. (48) is that the
radius of the screening “hole” is exactly equal to rs.

→

The results for the on-top gc(0, rs, µ) from the Over-
hauser model are reported in Fig. 5 as a function of rs
for diﬀerent values of µ. We see that the the simple in-
terpolation formula of Eq. (47) accurately captures the
µ and rs dependence of gc(0, rs, µ).

V. APPLICATIONS, PERSPECTIVES, AND
CONCLUSIONS

The main results of this work are (i) the corrected ex-
pansion of the short-range correlation energy functional,
Eq. (31), (ii) the expansion of the on-top pair density
of Eqs. (30) and (33), and (iii) the parameterization of
the µ- dependence of the on-top pair density of the uni-
form electron gas, Eq. (47). All these results (i-iii) can
be useful for the construction of approximate short-range
correlation energy functionals:

(i) In Ref. [10] the large-µ expansion of the correlation
energy functional has been already used to construct ap-
proximations: the idea is [10] to interpolate between a
given density functional approximation (DFA) of stan-
dard KS theory [32] at µ = 0, and the µ
expansion
µ
of E
c, SR[n]. In the spirit of the usual DFT approxima-
tions, this interpolation is done locally, i.e.,

→ ∞

E

µ
c, SR[n] =

dr n(r) ǫµ

c, SR(r),

(49)

where ǫµ

c, SR(r) is built, e.g., as [10]

Z

ǫµ
c, SR ≈

ǫDFA
c
1 + d1 µ + d2 µ2 .

(50)

c

µ
c, SR[n], and ǫDFA

The parameters d1 and d2 are ﬁxed by the condition
that Eq. (49) recovers the correct µ
expansion
can be, e.g., the PBE correla-
of E
tion functional [33] of standard Kohn-Sham theory or
any other available approximation. This correlation func-
tional can be combined with a similar interpolation for
exchange [10], or with the exchange functional of Heyd,
Scuseria, and Ernzerhof [6]. This way of constructing ap-
proximations should be improved by using the corrected

→ ∞

7

)
e
e
r
t
r
a
H

(

R
L

µ

,
c
E
−

c
E

 0
-0.01
-0.02
-0.03
-0.04
-0.05
-0.06
-0.07
-0.08
-0.09
-0.1

Be

this work

previous

 0

 5

 10
µ (a.u.)

exact

 15

 20

µ
c, SR[n] = Ec

Eµ

FIG. 6: The “exact” values of E
c, LR[n] for
the Be atom [9, 10] are compared with the large-µ expansion
of Eq. (31), and with the previous result for the same ex-
pansion given in Eq. (30) of Ref. 10. In both expansions the
“exact” on-top value is taken from Ref. 22.

−

expansion of Eq. (31), as suggested by Fig. 3. In Fig. 6
we also show similar data for the Be atom: again, the
corrected expansion is closer to the “exact” data [9, 10]
at large µ than the previous expansion used in Ref. 10.

∞

(ii) To impose the correct large-µ expansion in approx-
imations like the one of Eq. (50) we need an estimate of
) on-top pair density ˜P2(r, r12 = 0).
the physical (µ =
In Ref. 10 the LDA approximation [the integrand of the
right-hand side of Eq. (32)] was used. The new Eq. (33)
allows to use the on-top pair density of the partially
correlated wavefunction Ψµ to estimate ˜P2(r, r12 = 0).
In fact, once we have made a calculation at a given
(moderately large) µ (say, µ = µ0) we can estimate
˜P2(r, r12 = 0) as

˜P2(r, r12 = 0)

≈

˜P µ0

2 (r, r12 = 0)

1 +

(cid:18)

−1

2
√πµ0 (cid:19)

. (51)

There are cases in which this estimate could be much bet-
ter than the one obtained by using the LDA approxima-
tion for the physical on-top pair density. In fact, the use
of the partially correlated ˜P µ
2 (r, r12 = 0) would correct
the self-interaction error of LDA, becoming exactly equal
to zero for any one-electron density. Consider the exam-
ple of the stretched H2 molecule, for which the estimate
from Eq. (51) would be essentially exact (equal to zero
for any µ > 0), while LDA gives a spurious nonzero on-
top value, unless we consider the spin broken-symmetry
solution.

To show that Eq. (51) gives indeed a quantitative re-
liable estimate of the physical on-top pair density we
have considered the simple example of the He atom, and
we have inserted Eq. (51) directly in the expansion of
Eq. (31): the error on the estimated short-range correla-
tion energy at µ0 = 2.5 is 3 mH; if we choose µ0 = 2 the
µ0
error in E
c, SR[n] is 5 mH, and for µ0 = 1 is 11 mH. Of
course, when µ0 becomes too small, the large-µ expansion
of Eqs. (31) and (51) is no longer valid.

 
 
 
 
 
 
 
 
 
 
 
(iii) The on-top pair density of the uniform electron
gas with long-range- only interaction of Eq. (47) can be
used, in combination with the correlation energy of the
spin-polarized long-range electron gas [34], to implement
the local approximation for the on-top pair density inter-
pretation of spin density functional theory [25].

Another interesting application of Eq. (47) is con-
nected to point (ii): the construction of functionals that
explicitly depend on the on-top f µ(0) [or locally on
˜P µ
2 (r, r12 = 0)] of the partially correlated wavefunction
could use the µ dependence of the on-top LDA value to
go beyond Eq. (51),

fc(0)

≈

f µ0
c (0)

n(r)2 gc(0, rs(r), µ =

) dr

n(r)2 gc(0, rs(r), µ0) dr

∞

.

(52)

R

R

For example for the He atom Eq. (52) at µ0 = 2 gives
fc(0) =
0.090. The corre-
sponding “exact” value [22] is
0.085. Local versions of
Eq. (52) can be also considered, e.g.,

0.086, while Eq. (51) gives

−

−

−

fc(0)

≈

n(r)2 ˜P µ0

2,c(r, r12 = 0)

gc(0, rs(r), µ =

)
∞
gc(0, rs(r), µ0)

dr,

Z
(53)
where ˜P µ0
2,c(r, r12) is obtained by subtracting the Kohn-
Sham pair density from ˜P µ0
2 . Again, the advantage of
including in the construction of short-range functionals
the on-top ˜P µ
2,c(r, r12 = 0) is to locally remove the self-
interaction error.

In conclusions, we have presented a comprehensive
study of the short-range behavior of systems interact-
ing with the potential erf(µr12)/r12, in connection with
the properties of long- and short-range correlation en-
ergy density functionals. The same kind of analysis can
be of course repeated for other splittings of the Coulomb
electron-electron interaction [7, 35]. Future work will be
mainly oriented to the exploration of the promising ap-
proach of short-range functionals that explictly depend
on ˜P µ

2 (r, r12 = 0).

8

APPENDIX A: ALTERNATIVE DERIVATION OF
EQ. (25)

Start from Eq. (16), and consider the following series

expansions around x = 0

uµ(x) =

erf(µx)
x

=

bn =

∞

n=0
X
∞

n=0
X
2
√π

an(µ)xn+1,

(A1)

bnµ(µx)2n,

(
−

1)n
(2n + 1)n!

.

(A2)

This last series has an inﬁnite radius of convergence for
any ﬁnite µ.

E

The complicated operator

µ can be also expanded in
powers of x around x = 0. Its expansion will only contain
even powers of x because the hamiltonian of Eq. (15)
µ
is even in x = r12. As expected, the expansion of
does not play any role, so we do not consider its non-
spherical components (moreover, in the end we are only
interested in the spherically averaged pair density). The
µ remains bounded
only important requirement is that
when µ
0, as it happens for the Coulomb
and x
interaction [18, 19]. We thus write

→ ∞

→

E

E

µ =

E

∞

Xk=0

e2k(µ)x2k.

(A3)

By inserting Eqs. (A1), (A2) and (A3) into Eq. (16) we
ﬁnd that the an(µ) with odd n are zero (as expected
from the fact that erf(µx)/x is an even function of x),
2 diverge as µ
while the even n coeﬃcients with n
≥
increases, and, to leading order when µ
, they are
all proportional to a0(µ),

→ ∞

a2k+2(µ) = a0(µ)

""

bkµ2k+1
(2k + 2)(2k + 3)

+

µ2k
(2k + 2)(2k + 3)

k

×

i=1
X

bk−ibi−1
2i(2i + 1) #

+O(µ2k−1).

(A4)

This relation shows that ψµ(x) has the structure

ψµ(x) = a0(µ)[1 + x p1(µ x) + x2 p2(µ x) + ...]

(A5)

Acknowledgments

where

p1(y) =

p2(y) =

∞

Xk=0
∞

bky2k+1
(2k + 2)(2k + 3)

(A6)

y2k
(2k + 2)(2k + 3)

k

i=1
X

bk−ibi−1
2i(2i + 1) !

.(A7)

Xk=1  

We thank J. Toulouse for valuable discussions and for

the data of Ref. 9.

Equation (A6) gives exactly the same function p1(y) of
Eq. (22), and Eq. (A4) conﬁrms that all the terms beyond

the ones considered in Eq. (25) contribute to Eq. (26) to
orders µ−5 or higher.

We can now clearly see where the discrepancy with the
result of Ref. 10 comes from: the small-r12 expansion of
f µ(r12) only contains even powers of r12 for any ﬁnite µ.
It is thus incorrect to insert the odd coeﬃcient c1 of the
Coulombic system in Eq. (14), as it was done in Ref. 10.
What happens, instead, is that all the even coeﬃcients
of the small-r12 expansion of f µ(r12) diverge for large µ
µ−4 in Eq. (14).
and they all contribute to the term
Furthermore, in Ref. 10 it was assumed that the leading
order in the large-µ expansion of the on-top value f µ(0)
is 1/µ2, while we have shown that the correction to f µ(0)
with respect to the Coulombic case is of order 1/µ.

∝

APPENDIX B: THE CASE ℓ = 1

We insert the expansion of uµ(y) for large µ of Eq. (18)

into the equivalent of Eq. (17) for the case ℓ = 1,

d2
dy2 +

−

2
y2 +

1
µ

erf(y)
y

uµ(y) =

µuµ(y).

(B1)

1
µ2 E

(cid:20)

(cid:21)
The condition that the left-hand side be of order 1/µ2
yields

u(∞)(y) = b y2

u(−1)(y) = b y erf(y).

(B2)

(B3)

d2
dy2 −

2
y2

(cid:20)

(cid:21)

9

By solving Eq. (B3) we ﬁnd that the intracule f µ(r12)
has, for large µ, the small-r12 expansion

f µ(r12) =

f ′′(0)
2

r2
12

(cid:20)

1 + 2r12q1(µr12) +

2
3√πµ

+

,

B1
µ
(cid:21)
(B4)

where the function q1(y) is equal to

q1(y) =

e−y

2

(2y2
−
8√πy3

1)

1
3√π y

+

erf(y)(4y4 + 1)
16y4

,(B5)

−

and B1 is a constant of integration that is not determined
by the requirement that f µ vanishes at r12 = 0. The
function q1(y) has the asymptotic behaviors

q1(y

→

0) =

q1(y

) =

→ ∞

y
5√π
1
4 −

+ O(y3)

1
3√π y

+ O

1
y3

.

(cid:19)

(cid:18)

(B6)

(B7)

→ ∞

Again, we see that if we ﬁx r12 = r0 ≪
1, and then
we ﬁnd f µ(r0)
r2
0[1 + r0/2 + ...], which
let µ
is the parallel-spin cusp condition for the Coulomb in-
teraction [19]. But for any ﬁnite µ we have, for small
r12, f µ(r12)
122µ/5√π + ...]. The proof that
B1 = 0, and thus of Eqs. (34) and (35) is then completely
analogous to the one for the case ℓ = 0.

12[1 + r2
r2

∝

∝

[1] W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).
[2] A.E. Mattsson, Science 298, 759 (2002).
[3] C. Fiolhais, F. Nogueira, and M. Marques (eds.), A
Primer in Density Functional Theory (Springer-Verlag,
Berlin, 2003).

[4] W. Kohn, Y. Meir, and D. E. Makarov, Phys. Rev. Lett.

80, 4153 (1998).

[5] H. Ikura, T. Tsuneda, T. Yanai, and K. Hirao, J. Chem.
Phys. 115, 3540 (2001); M. Kamiya, T. Tsuneda, and K.
Hirao, ibid. 117, 6010 (2002); T.T.Y. Tawada, S. Yanag-
isawa, T. Yanai, and K. Hirao, ibid. 120, 8425 (2004).
[6] J. Heyd, G.E. Scuseria, and M. Ernzerhof, J. Chem.

Phys. 118, 8207 (2003).

[7] R. Baer and D. Neuhauser, Phys. Rev. Lett. 94, 043002

(2005).

[8] H. Stoll and A. Savin, in Density Functional Method in
Physics, edited by R. M. Dreizler and J. da Providencia
(Plenum, Amsterdam, 1985); A. Savin, in Recent Devel-
opments and Applications of Modern Density Functional
Theory, edited by J.M. Seminario (Elsevier, Amsterdam,
1996); T. Leininger, H. Stoll, H.-J. Werner, and A. Savin,
Chem. Phys. Lett. 275, 151 (1997); R. Pollet, A. Savin,
T. Leininger, and H. Stoll, J. Chem. Phys. 116, 1250
(2002); J. Toulouse, F. Colonna, and A. Savin, ibid. 122,
014110 (2005).

[9] R. Pollet, F. Colonna, T. Leininger, H. Stoll, H.-J.
Werner, and A. Savin, Int. J. Quantum Chem. 91, 84

(2003); J. Toulouse, private communication.

[10] J. Toulouse, F. Colonna, and A. Savin, Phys. Rev. A 70,

062505 (2004).

[11] J. G. ´Angy´an, I.C. Gerber, A. Savin, and J. Toulouse,
Phys. Rev. A 72, 012510 (2005); I. Gerber and J. G.
´Angy´an, Chem. Phys. Lett. 415, 100 (2005).

[12] S. Yamanaka, K. Kusakabe, K. Nakata, T. Takada, and

K. Yamaguchi , physics/0508121.

[13] M. Levy, Proc. Natl. Acad. Sci. U.S.A. 76, 6062 (1979).
[14] J. Toulouse and A. Savin, J. Mol. Struct. (Theochem),

to appear.

[15] A.W. Overhauser, Can. J. Phys. 73, 683 (1995).
[16] P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 64, 155102

(2001).

[17] J. Toulouse, P. Gori-Giorgi, and A. Savin, Theor. Chem.

Acc. 114, 305 (2005).

[18] T. Kato, Commun. Pure Appl. Math. 10, 151 (1957).
[19] R.T. Pack and B. Brown, J. Chem. Phys. 45, 556 (1966);
A. K. Rajagopal, J. C. Kimball, and M. Banerjee, Phys.
Rev. B 18, 2339 (1978).

[20] W. Kutzelnigg and J.D. Morgan III, J. Chem. Phys. 96,
4484 (1992); 97, 8821(E) (1992); J. D. Morgan III and
W. Kutzelnigg, J. Phys. Chem. 97, 2425 (1993).

[21] X.-Y. Pan and V. Sahni, J. Chem. Phys. 119, 7083
(2003);
I. Silanes, J.M. Ugalde, and R.J. Boyd, J.
Mol. Struct. (Theochem) 527, 27 (2000), and references
therein.

10

[22] J. Cioslowski, B.B. Stefanov, A. Tan, and C.J. Umrigar,

State Commun. 125 139 (2003).

J. Chem. Phys. 103, 6093 (1995).

[29] J. Cioslowski and P. Ziesche, Phys. Rev. B 71, 125105

[23] J.P. Perdew and Y. Wang, Phys. Rev. B 46, 12947
(1992); 56, 7018(E) (1997); P. Gori-Giorgi and J.P.
Perdew, Phys. Rev. B 66, 165118 (2002).

[24] For a calculation of the second derivative at r12 = of the
pair density in the special case of the uniform electron
gas, see Y. Ousaka, H. Suehiro, and H. Yasuhara, J. Phys.
C: Solid State Phys. 18, 4471 (1985), and Ref. 16.
[25] J.P. Perdew, A. Savin, and K. Burke, Phys. Rev. A, 51,
4531 (1995); A.D. Becke, A. Savin, and H. Stoll, Theor.
Chim. Acta, 91, 147 (1995).

(2005).

[30] Z. Qian, Phys. Rev. B 73, 035106 (2006).
[31] B. Davoudi, M. Polini, R. Asgari, and M.P. Tosi, Phys.

Rev. B 66, 075110 (2002).

[32] J.P. Perdew and K. Schmidt, in Density Functional The-
ory and Its Applications to Materials, edited by V. Van-
Doren et al. (AIP, NY, 2001), and references therein.
[33] J.P. Perdew, K. Burke, and M. Ernzerhof, Phys. Rev.

Lett. 77, 3865 (1996); ibid. 78, 1396 (1997)

[34] S. Paziani, S. Moroni, P. Gori-Giorgi, and G.B. Bachelet,

[26] J.C. Kimball, Phys. Rev. B 14, 2371 (1976). See also P.

cond-mat/0601343.

Ziesche and J. Cioslowski, Physica A 356, 598 (2005).

[27] P. Gori-Giorgi and A. Savin, Phys. Rev. A 71, 032513

(2005).

[28] R. Asgari, M. Polini, B. Davoudi and M.P. Tosi, Solid

[35] A. Savin and H.-J. Flad, Int. J. Quantum Chem. 56, 327
(1995); J. Toulouse, A. Savin, and H.-J. Flad, ibid. 100,
1047 (2004)."
"Local-spin-density functional for multideterminant density functional
  theory","  Based on exact limits and quantum Monte Carlo simulations, we obtain, at any
density and spin polarization, an accurate estimate for the energy of a
modified homogeneous electron gas where electrons repel each other only with a
long-range coulombic tail. This allows us to construct an analytic
local-spin-density exchange-correlation functional appropriate to new,
multideterminantal versions of the density functional theory, where quantum
chemistry and approximate exchange-correlation functionals are combined to
optimally describe both long- and short-range electron correlations.
",http://arxiv.org/pdf/cond-mat/0601343v2,3,"6
0
0
2

r
a

M
7

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
3
4
3
1
0
6
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Local-spin-density functional for multideterminant density functional theory

Simone Paziani,1 Saverio Moroni,2 Paola Gori-Giorgi,3 and Giovanni B. Bachelet1
1INFM Center for Statistical Mechanics and Complexity and Dipartimento di Fisica,
Universit`a di Roma “La Sapienza”, Piazzale A. Moro 2, I-00185 Roma, Italy
2INFM DEMOCRITOS National Simulation Center, via Beirut 2–4, I–34014 Trieste, Italy
3Laboratoire de Chimie Th´eorique, CNRS UMR7616,
Universit´e Pierre et Marie Curie, 4 Place Jussieu, F-75252 Paris, France
(Dated: August 18, 2018)

Based on exact limits and quantum Monte Carlo simulations, we obtain, at any density and spin
polarization, an accurate estimate for the energy of a modiﬁed homogeneous electron gas where elec-
trons repel each other only with a long-range coulombic tail. This allows us to construct an analytic
local-spin-density exchange-correlation functional appropriate to new, multideterminantal versions
of the density functional theory, where quantum chemistry and approximate exchange-correlation
functionals are combined to optimally describe both long- and short-range electron correlations.

I.

INTRODUCTION

Density functional theory1,2,3 (DFT) is by now the
most popular method for electronic structure calcula-
tions in condensed matter physics and quantum chem-
istry, because of its unique combination of low compu-
tational cost and high accuracy for many molecules and
solids. There are, however, exceptions to such an ac-
curacy. Even the best approximations of its key ingre-
dient, the exchange-correlation (XC) energy functional,
cannot describe strong electron correlations, like those
of the cuprates, and cannot exactly cancel the so-called
self-interaction, a property which the exact functional
should satisfy. On top of that, they fail to recover
long-range van der Waals interactions,4 are not com-
pletely safe for the description of the hydrogen bond,5
and have intrinsic problems with situations of near de-
generacy (when two sets of Kohn-Sham orbitals have very
close energies);6,7,8 more generally, the “chemical accu-
racy” has not yet been reached. To overcome the lat-
ter group of problems, there has been a growing inter-
est in “mixed schemes” which combine the DFT with
other approximate methods by splitting the coulom-
bic electron-electron interaction 1/r = vee(r) into a
short-range (SR) and a long-range (LR) part (see e.g.
Refs. 6,7,8,9,10,11,12,13,14,15,16,17,18). The idea is to
use diﬀerent approximations for the LR and the SR con-
tributions to the exchange and/or correlation energy den-
sity functionals of the Kohn-Sham (KS) scheme. It de-
scends from the observation that LR correlations, poorly
described by local or semi-local density functionals, can
be accurately dealt with by other techniques, like the
random-phase approximation (RPA) or standard wave-
function methods of quantum chemistry. Conversely,
correlation eﬀects due to the SR part of the electron-
electron interaction are in general well described by local
or semilocal functionals.19,20 The error function and its
complement

1
r

= vee(r) = vµ

SR(r) + vµ

LR(r) =

erfc(µr)
r

+

erf(µr)
r

(1)

where µ controls the range of the decomposition, are of-
ten used6,7,8,10,11,13,15,16,17 to split the Coulomb interac-
tion into a SR and a LR part, since they yield analytic
matrix elements for both Gaussians and plane waves, i.e.,
the most common basis functions in quantum chemistry
and solid state physics. Correspondingly, the universal
functional of the electron density n, as deﬁned in the
constrained-search formalism,21

F [n] = min
→

Ψ

nh

Ψ

T + Vee|

|

Ψ

.
i

(2)

can be divided into a short-range and a complementary
long-range part F [n] = F µ

SR[n] + F

µ
LR[n]

F µ

SR[n] = min
→
µ
LR[n] = F [n]

˜Ψµ

nh

F

˜Ψµ

T + V µ

SR|

|
F µ
SR[n].

−

˜Ψµ

i

(3)

or, alternatively, into a long-range and a complementary
short-range part F [n] = F µ

LR[n] + F

µ
SR[n]

F µ

LR[n] = min
→
µ
SR[n] = F [n]

Ψµ

nh

F

Ψµ

T + V µ

|
F µ
LR[n].

LR|

−

Ψµ

i

(4)

The two decompositions lead to diﬀerent strategies and
XC energy functionals, whose merits and drawbacks are
discussed in Ref. 22. In any event, for actual electronic-
structure calculations to be performed, these function-
als ultimately need approximations, in analogy with the
standard DFT. Regardless of the strategy adopted, the
potential superiority of “mixed schemes” comes into play
precisely at this stage: compared to the standard version,
a DFT which only deals with the SR part of the electron-
electron interaction should be much more accurately ap-
proximated, as mentioned, by local-density XC energy
functionals.15,19,20 While both decompositions [Eq. (3)
and Eq. (4)] are aimed at the exploitation of the DFT
scheme for the SR part of the interaction only, the cor-
responding approximate functionals require an accurate
description of the homogeneous electron gas (HEG) ei-
ther with SR [Eq. (3)] or LR interaction [Eq. (4)].

 
 
 
 
 
 
Up to now, the HEG exchange-correlation energies as
a function of the cutoﬀ parameter µ and of the elec-
tron density are available for the SR case from Quan-
tum Monte Carlo (QMC) simulations,23 and for the
LR case from coupled-cluster (CC) calculations.7,24 A
parametrization of the CC data for the XC energy of the
HEG with long-range-only interaction has been used in
Refs. 8 and 16 with very promising results for closed-shell
systems. Generalized-gradient-corrected density func-
tionals have also been designed and tested within this
framework,13,17 but all existing functionals are limited
to the spin-unpolarized case.

↓

↑

The purpose of this paper is to provide, based on novel
exact limits and quantum Monte Carlo simulations, an
accurate representation for the energy of the LR-only in-
teracting HEG not only as a function of the cutoﬀ pa-
rameter µ and of the total electron density, but also as
a function of the spin polarization [i.e., as a function
(r) separately]. Since
(r) and n
of the spin densities n
von Barth and Hedin25 showed, in 1972, that the task
of ﬁnding good approximations to exchange-correlation
density functionals is greatly simpliﬁed if the functional
is expressed in terms of the spin densities, and that this
is the simplest way to satisfy the requirement (Hund’s
rule) that a state with larger spin tends to be energet-
ically favored, the importance of including such a spin
dependence in approximate functionals was conﬁrmed
by countless calculations for molecules and solids.26,27 In
this context the decomposition of Eq. (4), based on the
constrained-search formalism,21 is generalized to spin-
DFT as follows:27

(5)

F µ

LR[n

, n

↓

↑

µ
SR[n

F

, n

Ψµ

] =

min
→
] = F [n

, n

n↑,n↓h

Ψµ

T + V µ

Ψµ

|
F µ
LR[n

LR|
].
, n

i

]

−

↑

↓

↑

↓

↓

↑
The spin-polarized LR-only gas, for which no previous re-
sults are to our knowledge available, is appropriate, via
Eq. (5), to a very promising “multideterminantal” ver-
sion of the spin-DFT. The ﬁnal outcome of this work
is thus a local-spin-density approximation of the corre-
sponding XC functional, given in analytic form, by which
electronic structure calculations of this new type will be
possible for unpolarized systems28 and, more important,
for spin-polarized systems, for which no such functional
is presently available. Such a functional also represents
the key ingredient for extending gradient-corrected SR
density functionals13,17 to spin-DFT.
The paper is organized as follows.

In Sec. II we de-
ﬁne the hamiltonian of the HEG with LR-only interac-
tion and we derive some exact limits of the correspond-
ing correlation energy, which is then computed (for val-
ues of the relevant parameters not accessible to analytic
methods) with QMC in Sec. III. The results of Secs. II
and III are then used in Sec. IV to construct an analytic
parametrization of the LR correlation energy. Sec. V
recalls, calculates and provides in analytic form an alter-
native deﬁnition of the LR correlation energy which in-
volves the use of pair-correlation functions (also obtained

2

from our QMC simulations) and may be of interest within
optimized-eﬀective-potential schemes.29

Hartree atomic units are used throughout this work.

II. DEFINITIONS, AND EXACT LIMITS

After decomposing the standard (Coulomb interac-
tion) spin-DFT functional according to Eq. (5), the re-
µ
sulting SR functional F
] can be further decom-
SR[n
posed, as usually, into a Hartree and an XC term

, n

↑

↓

E

µ
H[n] = Eµ

H[n] =

1
2

dr
Z

Z

dr′n(r) n(r′) vµ

SR(
|

r

r′

|

−

) (6)

µ
xc[n

E

, n

↓

↑

] = F

µ
SR[n

, n

]

↓

↑

−

µ
H[n].

E

(7)

The local-spin-density (LSD) approximation amounts to
replacing the exact, unknown functional of Eq. (7) with

µ
xc,LSD[n

, n

] =

↓

↑
dr n(r) [ǫxc(n

(r), n

(r))

↓

↑

dr n(r) [ǫxc(rs(r), ζ(r))

−

E

Z

Z

(8)

ǫLR
xc (n

(r), n

(r), µ)] =

↑

−
xc (rs(r), ζ(r), µ)],
ǫLR

↓

↑

↓

↑

↓

, n

, n

, n

xc (n

, and ǫLR

where ǫxc(n
) is the exchange-correlation energy per
particle of the standard jellium model30,31,32,33 with uni-
, µ) is the cor-
form spin densities n
responding quantity for a jellium model with LR-only in-
teraction vµ
LR(r), which forms the object of this paper. In
the third line of Eq. (8) we express the same quantity in
1
= (4πr3
s /3)−
terms of the electronic density n = n
)/n, thus introducing
and spin polarization ζ = (n
the notation used in what follows. To obtain ǫLR
xc (rs, ζ, µ)
we consider a uniform system with LR-only interaction

↑ −

+n

n

↑

↓

↑

↓

↓

H µ

LR =

1
2

−

N

i=1
X

ri + V µ

LR + V µ

eb + V µ
bb,

2
∇

(9)

where V µ

LR is the modiﬁed electron-electron interaction

V µ
LR =

1
2

N

erf(µ

ri −
rj|
|
rj|
ri −

=j=1
Xi

|

)

,

(10)

V µ
eb is the interaction between the electrons and a rigid,
positive, uniform background of density n

V µ
eb =

n

−

N

i=1 Z
X

dx erf(µ
|

ri −
|
x
ri −
|

)

x
|

,

(11)

and V µ
teraction

bb is the corresponding background-background in-

V µ
bb =

n2
2

dx

dx′

Z

Z

erf(µ
x

|

x

|
−

x′

−
x
′|

)

|

.

(12)

6
Our hamiltonian H µ
LR, and thus its ground-state energy
per electron ǫLR, depends on the density parameter rs,
on the spin-polarization ζ, and on the cutoﬀ parameter µ.
, we recover the standard jellium model; in
When µ
the opposite limit µ
0, we recover the noninteracting
In this Section we derive the asymptotic
electron gas.
of the correlation energy
behavior for µ
per electron, deﬁned as

0 and µ

→ ∞

→ ∞

→

→

ǫLR
c (rs, ζ, µ) =

(13)

ǫLR(rs, ζ, µ)

ts(rs, ζ)

−

−

ǫLR
x (rs, ζ, µ),

where ts(rs, ζ) = 3k2
of the noninteracting electron gas, with kF = (α rs)−
α = (4/9π)1/3, and

F φ5(ζ)/10 is the usual kinetic energy
1,

φn(ζ) =

1
2

(1+ζ)n/3 + (1
h

−

ζ)n/3

;

(14)

i

the exchange energy is given by7

(1+ζ)4/3fx

rs, µ(1+ζ)−

1/3

+

ǫLR
x (rs, ζ, µ) =

+

1
2
1
2

(1

−

(cid:16)

ζ)4/3fx

rs, µ(1

1/3

ζ)−

(cid:17)

,

(15)

−

(cid:16)
4y3) e−

2

1/4y

(cid:17)
3y + 4y3 +

−
µ α rs
2

y =

,

(16)

fx(rs, µ) =

µ
π

−

(cid:20)

(2y

+ √π erf

(cid:18)

−
1
2y

,

(cid:19)(cid:21)

and has the asymptotic behaviors

µ

ǫLR
x (rs, ζ, µ)
(cid:12)
(cid:12)
(cid:12)
µ

ǫLR
x (rs, ζ, µ)
(cid:12)
(cid:12)
(cid:12)

=

0

→

=
→∞

−

−
3kF
4π

µ
√π

+

φ4(ζ) +

3αrsµ2
2π
3 (1+ζ2)
16 r3

φ2(ζ) + O(µ3) (17)

s µ2 + O(µ−

4) (18)

A. Approaching the non-interacting gas

→

→

When µ

0 and/or rs →

0, we are approaching the
limit of the non-interacting Fermi gas. Toulouse et al.15
have studied the µ
0 limit of the long-range exchange
and correlation energy functionals for conﬁned systems
(atoms, molecules) using standard perturbation theory.
Their results cannot be applied to the case of an ex-
tended system like the uniform electron gas, because the
integrals of their Eqs. (17) and (20) would diverge. In-
0 limit) of
stead, the µ
the uniform electron gas can be studied with RPA,25,34
which becomes exact both for long-range correlations
(µ
0: in this limit the long-range coulombic tail shows
up only beyond larger and larger interelectronic distance
0). We
1/µ) and in the high-density limit (rs →
r
generalize to the LR-only interaction erf(µr)/r the stan-
dard RPA expression for the correlation energy (see Ap-
pendix A for details), and ﬁnd that, for small µ√rs (i.e.,

0 limit (as well as the rs →

→

→

∼

small-µ and/or rs →
scales as

0 limit), the correlation energy ǫLR

c

3

= [φ2(ζ)]3 Q(x),
0

→

µ,rs

x =

µ√rs
φ2(ζ)

,

(19)

ǫLR
c (rs, ζ, µ)
(cid:12)
(cid:12)
(cid:12)

where φ2(ζ) is given by Eq. (14), and the function Q(x)
has the following asymptotic behaviors

Q(x

→

0) =

Q(x

) =

→ ∞

3α
2π
−
2 ln(2)
π2

x2 + O(x3)

(20)

2

−

ln(x) + const.

(21)

The scaling of Eq. (19) for the long-range correlation en-
ergy was also expected from the fact that the long-range
part of the pair-correlation function of the standard jel-
lium model has a similar scaling.35,36,37 Notice also that,
in the small-µ expansion of ǫLR
[Eqs. (19) and (20)], the
c
term proportional to µ2 exactly cancels with the corre-
sponding term in the exchange energy ǫLR
[Eq. (17)], so
that the XC energy (exchange plus correlation) has no
µ2 term; in a conﬁned system, on the other hand, the µ2
terms are separately zero for exchange and correlation.15
We found that the function Q(x) (see Appendix A) is
accurately approximated by

x

Q(x) =

2 ln(2)
π2

2

−

ln

1 + a x + b x2 + c x3
1 + a x + d x2

(cid:18)

,

(22)

(cid:19)

−

4).

3πα/(4 ln(2)

with a = 5.84605, c = 3.91744, d = 3.44851, and b =
d

−
A ﬁnal remark on the scaling of Eq. (19) is that, al-
though it exactly holds only in the small-x regime, even
in the large-x regime of Eq. (21) (obtained e.g. with
small rs but very large µ), it represents an excellent ap-
proximation, because in this regime the ζ dependence of
ǫLR
c /Q is described by a function [Eq. (32) of Ref. 38]
which is very similar to [φ2(ζ)]3, and exactly equals it
for ζ = 0 and ζ = 1. All the densities corresponding to
rs & 0.1 are not aﬀected by this small diﬀerence in the ζ
dependence of Eq. (19), as discussed in Appendix A.

B. Approaching the coulombic gas

The large-µ behavior of the long-range correlation
functional appropriate to the decomposition of Eq. (5),
obtained in Refs. 15 and 39, is straigthforwardly extended
to the uniform electron gas. For ζ

= 1 we have39

ǫLR
c (rs, ζ, µ)
(cid:12)
(cid:12)
(cid:12)

µ

→∞

= ǫc(rs, ζ)

−
g(0, rs, ζ)
√2π r3
s µ3

−

3 gc(0, rs, ζ)
s µ2

8 r3

+ O(µ−

4)

(23)

where ǫc(rs, ζ) is the correlation energy of the standard
electron gas with Coulomb interaction, g(0, rs, ζ) its on-
top pair-distribution function,36,37,40 and gc(0, rs, ζ) =

6
1
g(0, rs, ζ)
2 (1
the terms proportional to µ−
expansion of ǫLR

ζ2). For the fully polarized gas (ζ = 1)
3 in the large-µ
2 and µ−
c vanish, and the next leading terms are39

−

−

ǫLR
c (rs, ζ = 1, µ)
µ
(cid:12)
(cid:12)
(cid:12)

→∞

= ǫc(rs, ζ = 1)

9 g′′c (0, rs, ζ = 1)

−

64 r3

s µ4

9 g′′(0, rs, ζ = 1)

−

40√2π r3

s µ5

+ O(µ−

6)(24)

C
M
V
E

where g′′(0, rs, ζ = 1) is the second derivative at r = 0 of
the pair-distribution function36,37,40 of the fully polarized
gas, and g′′c (0, rs, ζ = 1) = g′′(0, rs, ζ = 1)

25/3k2

F/5.

−

4

1.15

ζ=1

1.145

1.14

1.135

1.13

ζ=0

 0

 0.005

 0.01
1/N

 0.015

1.125

 0.02

 0.6

 0.595

 0.59

 0.585

 0.58

 0.575

III. DIFFUSION MONTE CARLO

.
→ ∞

The details of the simulations are similar to our previ-
ous calculation of a local density functional for a short-
range potential.23 Here we give a technical summary fo-
cusing on the main diﬀerences, which concern the size
extrapolation and the treatment of the long-range tails
of the interaction and of the pair pseudopotential in the
trial wave function. For the reader not keen on techni-
calities, it is enough to say that we provide a very tight
upper bound to the exact ground-state energy, choos-
ing a level of approximation which closely matches the
Ceperley–Alder30 (CA) result for µ

The ground-state energy of the Hamiltonian of Eq. (9)
is computed with the diﬀusion Monte Carlo (DMC)
method in the ﬁxed-node (FN) approximation,41 using a
standard Jastrow–Slater trial function with plane–wave
orbitals and RPA pseudopotentials.42 Several values of
the density (rs = 1, 2, 5, and 10), of the cutoﬀ parameter
(µrs = 0.5, 1, 2 and 4) and of the spin polarization (ζ = 0
and 1) are considered. The results are ﬁtted (see Sec. IV)
to a convenient analytical expression for the correlation
energy ǫc(rs, µ, ζ), which also embodies the exact limits
of Sec. II and is further constrained to recover the CA
result for the Coulomb potential.

This constraint sets the target precision of our simu-
lations, since there is no point in pushing the accuracy
much beyond the statistical uncertainty of the CA re-
sults. Correspondingly, we make sure that the biases
due to a ﬁnite time step and a ﬁnite number of walk-
ers are much smaller than the statistical uncertainties of
the CA results. Furthermore, as discussed in Ref. 23, a
smoother match to the CA results of the FN energy in
the µ
limit is expected using the nodal structure
given by Slater determinants of plane waves, instead of
the more accurate43 (and computationally more demand-
ing) backﬂow nodes.

→ ∞

We simulate N particles in a cubic box with “twist–
averaged boundary conditions”44 (TABC), which have
been shown to eliminate most of the ﬁnite–size eﬀect due
to the shell structure of the plane–wave determinants.
For each system considered, simulations are performed
for 35 points in the irreducible wedge of the ﬁrst Bril-
louin zone (BZ) of the simulation box, corresponding to

FIG. 1: The size dependence of the VMC energy for the
Coulomb potential at rs = 1. Empty symbols: VMC energy
EN ; ﬁlled symbols: EN +T∞
TN . The curves show the best–
−
ﬁt 1/N dependence of the latter, according to Eq. 25: circles
and solid line refer to ζ = 0 (left scale), triangles and dashed
line to ζ = 1 (right scale). The cross is the ζ = 0 result ob-
tained in the thermodynamic limit by Ref. 43, which appears
fully consistent with the present calculation. The statistical
errors on the data points are much smaller than the symbol
sizes. The χ2 is 11.8 for ζ = 0, and 0.4 for ζ = 1 (much poorer
values would be obtained by just ﬁtting EV M C , i.e., without
including the kinetic-energy size correction).

a 1000–point mesh in the whole BZ.

Both the interparticle potential and the RPA pair
pseudopotential are
computed using an optimized
breakup45 into a long–range part, to be treated in recip-
rocal space, and a short–range part, to be treated in real
space. The short–range part is expanded in locally piece-
wise quintic Hermite interpolants over 20 knots, and the
k–space summation includes 20 shells of reciprocal lat-
tice vectors. This choice of parameters ensures that, for
the Coulomb interaction, the potential energy calculated
for a simulation box containing 64 particles on a simple
cubic lattice reproduces the exact Madelung constant to
less than 1 part in 107.

All DMC simulations have been done with N = 54
for both the paramagnetic and the spin–polarized ﬂu-
ids (there is no need of choosing closed–shell determi-
nants with TABC). Following a common practice,30,43
the residual size eﬀect has been estimated assuming that
it is the same for DMC and Variational Monte Carlo
(VMC),41 which is somewhat less accurate but much
cheaper. Systems with up to 246 particles were simu-
lated with the VMC algorithm, and the size dependence
of the computed energies EN was modeled as

E

∞

= EN + T

∞ −

TN + β/N,

(25)

∞

where T
and TN are the kinetic energy in the thermody-
namic limit and in the N
particle system (with TABC),
and β are ﬁtting parameters. The
respectively, and E
χ2 value, less than 2 on average, is at worst about 10 for
rs = 1 and µ = 4, at ζ = 0. Figure 1 shows the size extrap-
olation procedure for the Coulomb potential at rs = 1.

−

∞

Since the dependence on spin polarization of the optimal
value of β is very weak (see Fig. 1), a systematic study
of the ﬁnite-size eﬀect was carried out only for ζ = 0: for
given µ and rs, the same value of β, determined from
the VMC energies of the paramagnetic ﬂuid at several
system sizes, was then used to estimate the ﬁnite-size
correction to the DMC energy for both ζ = 0 and ζ = 1.
For the unpolarized gas, we found that the discrepancies
on the correlation energy with the coupled-cluster data
of Refs. 7 and 24 are of the order of 5–8%.

IV. ANALYTIC REPRESENTATION OF THE
CORRELATION ENERGY

We construct an analytical representation of the cor-

relation energy as

ǫLR
c (rs, ζ, µ) =

[φ2(ζ)]3Q

µ√rs
φ2(ζ)

(cid:18)

(cid:19)

(26)

+ a1µ3 + a2µ4 + a3µ5 + a4µ6 + a5µ8

(1 + b2

0µ2)4

,

where the function Q is given by Eq. (22), the parameters
ai(rs, ζ) ensure the correct large-µ behavior of Eqs. (23)-
(24), and b0(rs) is ﬁxed by a best ﬁt to our DMC data.
Some more free parameters which are adjusted to ﬁt the
DMC data are also contained in the coeﬃcients ai(rs, ζ),
whose deﬁnition requires a detailed explanation. For the
limits of Eqs. (23)-(24) we use, for any spin-polarization
ζ, the approximation

ǫLR
c (rs, ζ, µ)
(cid:12)
(cid:12)
(cid:12)

µ

≈
→∞

−

−

ǫc(rs, ζ)

(1

ζ2)

−
9 c5(rs, ζ)
40√2πr3
s µ5
2

3(1

−

ζ2) gc(0, rs, ζ = 0)
s µ2

8 r3

−
g(0, rs, ζ = 0)

9 c4(rs, ζ)
64r3

sµ4

√2π r3

s µ3 −

+ O(µ−

6) , with

(27)

c4(rs, ζ) =

(cid:18)

(cid:18)

+

1+ζ
2

1

ζ

−
2

(cid:19)

2

(cid:19)

g′′

0, rs

g′′

0, rs

2
1+ζ

(cid:18)

2

1

ζ

+

1/3
,

ζ = 1

(cid:19)

1/3
,

ζ = 1

(cid:19)

!

!

+ (1

−

ζ2)D2(rs)

−

, and

(28)

(cid:18)
−
φ8(ζ)
5 α2 r2
s

c5(rs, ζ) =

1+ζ
2

(cid:18)

g′′

0, rs

2

(cid:19)

2

1

+

ζ

(cid:18)
+ (1

−

0, rs

g′′

−
2
ζ2)D3(rs).

(cid:19)

+

2
1+ζ

(cid:18)

2

1

(cid:18)

−

ζ

1/3
,

ζ = 1

(cid:19)

1/3
,

ζ = 1

(cid:19)

!

!

(29)

The function φ8 is deﬁned by Eq. (14); D2(rs) and D3(rs)
4 and
mimic the eﬀect of the
5 large-µ coeﬃcients, and are obtained by a best ﬁt
µ−

correlation on the µ−

↑↓

5

to the DMC data. For the parallel-spin g′′(0, rs, ζ) and
for the on-top g(0, rs, ζ) an exchange-like ζ dependence
was assumed, starting from the values at ζ = 1 and ζ = 0,
respectively. The on-top g(0, rs, ζ = 0) was taken from
Ref. 40, while g′′(0, rs, ζ = 1) was obtained as a best ﬁt
to our DMC data. The parameters ai(rs, ζ) of Eq. (26)
are then equal to

0 C5,
0 C4 + 6 b4

0ǫc,

a1 = 4 b6
a2 = 4 b6
a3 = b8
a4 = b8
a5 = b8

0 C3 + b8
0 C2 + b8
0 C3,
0 C2 + 4 b6
0 ǫc,

0 ǫc,

where ǫc(rs, ζ) is the parametrization of the CA correla-
tion energy as given by Perdew and Wang,33 and

C2 =

C3 =

C4 =

C5 =

3(1

−

−

ζ2) gc(0, rs, ζ = 0)

8 r3
s

ζ2)

(1

−

−

g(0, rs, ζ = 0)
√2π r3
s

9 c4(rs, ζ)
64r3
s
9 c5(rs, ζ)
40√2πr3
s

.

−

−

(30)

The functions b0, g′′, D2 and D3 are ﬁnally obtained from
a best ﬁt to the DMC data and read

b0(rs) = 0.784949 rs (31)

g′′(0, rs, ζ = 1) =

25/3
5 α2 r2
s

0.02267rs

1

−

(1 + 0.4319rs + 0.04r2
s)

(32)

D2(rs) =

0.547rs

e−

r2
s

D3(rs) =

e−

−
(cid:0)
0.31rs

0.388rs + 0.676r2
s

4.95rs + r2
s

r3
s

−
(cid:0)

(33)

(cid:1)
. (34)

(cid:1)

Notice that, by our construction, Eq. (32) satisﬁes the ex-
act high-density limit.46 Our data and the ﬁtting function
of Eq. (26) are shown in Fig. 2. The small discrepancy at
large µ, particularly visible for rs = 1 and ζ = 1 on the
scales of the ﬁgure, is due to the condition that our ﬁtting
function recovers in the Coulomb limit the Perdew-Wang
parametrization33 of the CA correlation energy, and it is
consistent with our FN results being an upper bound
to the data obtained30 by CA using a nominally exact
method.

V. PAIR-DISTRIBUTION FUNCTIONS AND
ALTERNATIVE SEPARATION OF EXCHANGE
AND CORRELATION

From our DMC runs we also extracted, in the usual
way,47 the pair-distribution functions gLR(r, rs, ζ, µ). A

 
 
 
 
 0

-0.01

-0.02

-0.03

-0.04

-0.05

-0.06

rs=10

rs=5

rs=2

rs=1

 0  0.5  1  1.5  2  2.5  3  3.5  4  4.5
µ rs

 0

-0.005

-0.01

-0.015

-0.02

-0.025

-0.03

-0.035

rs=10

rs=5

rs=2

rs=1

6

)
µ
,
ζ
,

s

r
,
r
(

R
L

g

)
µ
,
ζ
,

s

r
,
r
(

R
L

g

 1

 0.8

 0.6

 0.4

 0.2

 0

 1

 0.8

 0.6

 0.4

 0.2

 0

µ=0.25

µ=∞

rs=2
ζ=0

 0

 0.5

 1

 1.5

 2.5

 3

 3.5

 4

 2
r/rs

rs=10
ζ=1

µ=0.05

µ=∞

 0  0.5  1  1.5  2  2.5  3  3.5  4  4.5
µ rs

 0

 0.5

 1

 1.5

 2.5

 3

 3.5

 4

 2
r/rs

)
µ
,
0
=
ζ
,

s

r
(

R
L
ε

c

)
µ
,
1
=
ζ
,

s

r
(

R
L
ε

c

FIG. 2: Our DMC data for the correlation energy (
) of the
electron gas with long-range interaction erf(µr)/r are com-
pared with the ﬁtting function (lines) of Eq. (26) for the
unpolarized case (upper panel) and the fully polarized case
(lower panel). The statistical errors on the DMC data are
comparable with the symbol size.

•

sample of our results is shown in Fig. 3. These func-
tions are of interest in the framework of the approach
of Refs. 7,8,13,14,15,16,17. While a local- (or local-spin-
) density approximation for both exchange and correla-
tion has been, and to a large extent still is, the most
popular approach to Kohn-Sham calculations (possibly
with GGA improvements), there is a growing interest48
in optimized-eﬀective-potential schemes, where the ex-
change is treated exactly and the construction of ap-
proximations only concerns the correlation energy. The
latter is naturally deﬁned as whatever exceeds the exact-
exchange energy, obtained from a single Slater determi-
nant of Kohn-Sham orbitals. But once a multidetermi-
nantal, partially correlated wavefunction Ψµ [Eq. (5)] is
introduced, as in the modiﬁed schemes we are concerned
with here, an alternative, more eﬃcient choice, may be
to construct approximations only for that portion of the
correlation energy which is not already taken into ac-
count by Ψµ. In other words, one may prefer to deﬁne29
“exchange” and “correlation” energy functionals in the
following way:

E

E

µ
x,md[n
µ
c,md[n

, n

, n

↓

↓

↑

↑

] =

Ψµ
|
h
µ
xc[n
] = E

Vee −
, n

↑

↓

V µ
LR|
E

]

Ψµ
i −
µ
x,md[n

−

µ
H[n] (35)

E

, n

↓

↑

], (36)

FIG. 3: A sample of our DMC pair-distribution functions.
for rs = 2 and ζ = 0, gLR is shown for µ =
Upper panel:
). Lower panel:
0.25, 0.5, 1, 2, and for the Coulomb gas (µ =
for rs = 10 and ζ = 1, gLR is shown for µ = 0.05, 0.1, 0.2, 0.4,
and for the Coulomb gas (µ =

∞

).

∞

and then apply, e.g., the LSD approximation only to the
“correlation” energy functional of Eq. (36):29

E

µ
c,md[n

, n

↓

↑

] =

Z

Here

dr n(r) ǫc, md(rs(r), ζ(r), µ).

(37)

ǫc, md(rs, ζ, µ) = ǫc(rs, ζ)

−

ǫLR
c (rs, ζ, µ)+∆LR

−

SR(rs, ζ, µ),
(38)

the mixed term ∆LR

−

SR(rs, ζ, µ) is equal to

∆LR

−

SR(rs, ζ, µ) =

n
2

−

∞
4πr2dr gLR
0
Z

c

(r, rs, ζ, µ)

erfc(µr)
r

,

c

(39)
and gLR
is given by gLR minus the pair-distribution func-
tion of the noninteracting gas. Using the results of Ref. 39
it is easy to show that, for large µ, the mixed term
∆LR

SR behaves as

−

∆LR

−

SR

=
→∞

µ

−

(cid:12)
(cid:12)
(cid:12)

3 gc(0, rs, ζ)
s µ2

8 r3
−
g(0, rs, ζ)(2√2
s µ3
2√π r3

1)

−

+ O(µ−

4)

(40)

 
 
 
 
 
 
for ζ

= 1, and as

∆LR

−

SR

µ
(cid:12)
(cid:12)
(cid:12)

=
→∞

−

9 g′′c (0, rs, ζ = 1)

s µ4

64 r3

−
3 g′′(0, rs, ζ = 1)(3
s µ5

20√2π r3

−

√2)

+ O(µ−

6)(41)

for ζ = 1, with the same notations of Eqs.(23-24).

In this Section we present an accurate parametriza-
tion of ∆LR
SR. Exploiting our DMC pair-distribution
functions gLR(r, rs, ζ, µ), we solved Eq. (39) by numerical
integration, and parametrized our results as

−

∆LR

−

SR =

δ2 µ2 + δ3 µ3 + δ4 µ4 + δ5 µ5 + δ6 µ6

(1 + d2

0 µ2)4

,

(42)

where the functions δi(rs, ζ) with i = 3...6 guarantee the
correct large-µ behavior of Eqs. (40)-(41):

˜C5
˜C3 + d8
δ3 = 4 d6
0
0
0 C2 + d8
δ4 = 4 d6
0 C4
˜C3
δ5 = d8
0
δ6 = d8
0 C2 .

Here C2(rs, ζ) and C4(rs, ζ) are those of Eqs. (30);

˜C3 =

ζ2)

(1

−

−

g(0, rs, ζ = 0)(2√2

1)

,

−

˜C5 =

3 c5(rs, ζ)(3

−
20√2πr3
s

−

2√π r3
s
√2)

;

(43)
(44)

(45)
(46)

(47)

g(0, rs, ζ = 0) and c5(rs, ζ) are deﬁned in Sec. IV. The
remaining parameters δ2(rs) and d0(rs, ζ) are ﬁtted to
our DMC data and read

δ2(rs) = 0.073867 r3/2

s

d0(rs, ζ) = (0.70605 + 0.12927 ζ2) rs.

(48)
(49)

where

VI. CONCLUSIONS

with

7

that

A fortran subroutine

our LSD
corre-
exchange-correlation
to
sponding potentials
gori@lct.jussieu.fr,
can be downloaded at
or
http://www.lct.jussieu.fr/DFT/gori/elegas.html.

functional
is available upon request

evaluates
and

the

Acknowledgments

We thank A. Savin and J. Toulouse for useful discus-
sions, H. Stoll and J.G. ´Angy´an for suggesting and en-
couraging this work, and gratefully acknowledge ﬁnancial
support from the Italian Ministry of Education, Univer-
sity and Research (MIUR) through COFIN 2005-2006
and the allocation of computer resources from INFM In-
iziativa Calcolo Parallelo.

APPENDIX A: DETAILS OF EQ. (19)

We start from the RPA equations25 for the spin-
polarized electron gas, and we simply replace the
Coulomb interaction 1/r with the long-range interaction
erf(µr)/r. We then repeat the analysis done in Refs. 35
0
and 38 for the coulombic gas and ﬁnd that, in the rs →
limit, the correlation energy is given by

rs

ǫLR
c (rs, ζ, µ)
(cid:12)
(cid:12)
dy
(cid:12)
α2 y

12
π

−

∞

0
Z

=

0

→

∞

du

(

0
Z

α Rζ(u) e−

(cid:16)

y
αµ√rs

2

(cid:17)

y2 ln

−

1 +



α
y2 Rζ(u) e−

(cid:16)

y
αµ√rs



2

,

(cid:17)



)



Rζ(u) =

z1 R

1
2

(cid:20)

u
z1 (cid:19)

(cid:18)

+ z2 R

u
z2 (cid:19)(cid:21)

,

(cid:18)

(A1)

(A2)

We have presented a comprehensive numerical and an-
alytic study of the ground-state energy of a homogeneous
electron gas with modiﬁed,
long-range-only electron-
electron interaction erf(µr)/r, as a function of the cutoﬀ
parameter µ, of the electronic density, and of spin polar-
ization. The ﬁnal outcome of this work is the publica-
tion of a reliable local-spin-density functional which ﬁts
the results of our quantum Monte Carlo simulations and
automatically incorporates exact limits. Such a func-
tional (Sec. IV), or its variant implying the use of an
additional term also obtained in this work (Sec. V), are
the key ingredient for some recently proposed “multide-
terminantal” versions of the density functional theory,
where quantum chemistry and approximate exchange-
correlation functionals are combined to optimally de-
scribe both long- and short-range electron correlations.

R(u) =

1
π

1

−

u arctan(u−

1)

,

(A3)

(cid:2)

(cid:3)
ζ)1/3, and α = (4/9π)1/3.
z1 = (1 + ζ)1/3, z2 = (1
−
Equation (A1) already shows that the correlation energy
becomes a function of µ√rs in the rs →
To prove the small-x behavior of Eq. (20), take a value
of µ√rs = a
1. In this case all the contribution to the
integral of Eq. (A1) comes from small y, since, as soon as
a, the integrand goes to zero exponentially fast, as
y
0 . We thus integrate over y
a function of a, when a
Eq. (A1) between 0 and a value q1 such that a
1.
1, the integral reduces to
Since y

0 limit.

≫

→

≪

≪

≪

q1

≪

12
πα

−

q1

0
Z

dy y e−( y

α a )

2

du Rζ(u),

(A4)

∞

0
Z

6
R
L
ε

c

3
−

]
)
ζ
(

2

φ
[

 0

-0.02

-0.04

-0.06

-0.08

-0.1

-0.12

-0.14

-0.16

ζ = 0, 1

 0

 1

 2

 3

 4
x

ζ = 0.86

 5

 6

 7

 8

FIG. 4: The numerical evaluation of Eq. (A1), as a function of
−3. If the scaling of
x = µ√rs/φ2(ζ), and multiplied by [φ2(ζ)]
Eq. (19) were exact, all the values corresponding to diﬀerent
ζ would lie on the solid curve. The value ζ = 0.86 shown in
the ﬁgure corresponds to the maximum deviation from the
scaling of Eq. (A1).

which gives, to leading orders in a when a

0, Eqs. (19)-

→

1 W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).
2 A.E. Mattsson, Science 298, 759 (2002).
3 C. Fiolhais, F. Nogueira, and M. Marques (eds.), A Primer
in Density Functional Theory (Springer-Verlag, Berlin,
2003).

4 In this paper we deal with the separation of the long-range
and the short-range part of the electron-electron interac-
tion within DFT, a strategy which can eﬃciently describe
van der Waals interactions.9,16 For other, recent, promising
attempts to take into account dispersion forces within DFT
see, e.g., M. Dion, H. Rydberg, E. Schr¨oder, D. Langreth,
and B. Lundqvist, Phys. Rev. Lett. 92, 246401 (2004); J.
Dobson and J. Wang, B. Dinte, K. McLennan, and H. Le,
Int. J. Quantum Chem. 101, 579 (2005); E. Johnson and
A. Becke, J. Chem. Phys. 123 024101 (2005); A. Becke and
E. Johnson, ibid. 122, 154104 (2005); 123, 154101 (2005).
5 J. Ireta, J. Neugebauer, and M. Scheﬄer, On the accuracy
of DFT for describing hydrogen bonds: dependence on the
bond directionality, preprint.

6 H. Stoll and A. Savin, in Density Functional Method in
Physics, edited by R. M. Dreizler and J. da Providencia
(Plenum, Amsterdam, 1985);

7 A. Savin, in Recent Developments and Applications of Mod-
ern Density Functional Theory, edited by J.M. Seminario
(Elsevier, Amsterdam, 1996).

8 T. Leininger, H. Stoll, H.-J. Werner, and A. Savin, Chem.
Phys. Lett. 275, 151 (1997); R. Pollet, A. Savin, T.
Leininger, and H. Stoll, J. Chem. Phys. 116, 1250 (2002).
9 W. Kohn, Y. Meir, and D. E. Makarov, Phys. Rev. Lett.

80, 4153 (1998).

10 H. Ikura, T. Tsuneda, T. Yanai, and K. Hirao, J. Chem.
Phys. 115, 3540 (2001); M. Kamiya, T. Tsuneda, and K.
Hirao, ibid. 117, 6010 (2002); T.T.Y. Tawada, S. Yanagi-
sawa, T. Yanai, and K. Hirao, ibid. 120, 8425 (2004).

(20). The large x behavior of Eq. (21) follows by consid-
ering the µ
limit of Eq. (A1), which reduces to the
standard coulombic case studied in Ref. 38.

→ ∞

8

→

The ζ dependence of Eq. (19) is exact in the x

0
limit of Eq. (A4). For larger x, we evaluated Eq. (A1) nu-
merically, and in Fig. 4 we report our results multiplied
3, as a function of x = µ√rs/φ2(ζ): if the scal-
by [φ2(ζ)]−
ing of Eq. (19) were exact, all the values corresponding
to diﬀerent ζ would lie on the solid curve, corresponding
to ζ = 0 and 1. The value ζ = 0.86 reported in the ﬁgure
corresponds to the maximum deviation from the scaling
of Eq. (19), which is thus rather small. The function
Q(x) of Eq. (22) has been obtained by ﬁtting the RPA
data of the solid curve. On the scale of Fig. 4 the ﬁtting
error is invisible.

c

To conclude the discussion, we expect that the correla-
tion energy ǫLR
1
lies on the curve of Fig. 4 when µrs ≪
(high-density or really long-range-only interaction on the
scale rs). This means that at a given rs, the “exact”
ǫLR
lies on the curve of Fig. 4 for values of µ such that
c
µ√rs . 1/√rs, that is, only the densities rs . 0.1 would
be aﬀected by the small deviations from the scaling in ζ
of Eq. (19), which appear at x & 3.

11 J. Heyd, G.E. Scuseria, and M. Ernzerhof, J. Chem. Phys.

118, 8207 (2003).

12 R. Baer and D. Neuhauser, Phys. Rev. Lett. 94, 043002

(2005).

13 J. Toulouse, F. Colonna, and A. Savin, J. Chem. Phys.

122, 014110 (2005).

14 R. Pollet, F. Colonna, T. Leininger, H. Stoll, H.-J. Werner,
and A. Savin, Int. J. Quantum Chem. 91, 84 (2003).
15 J. Toulouse, F. Colonna, and A. Savin, Phys. Rev. A 70,

062505 (2004).

16 J. G. ´Angy´an, I.C. Gerber, A. Savin, and J. Toulouse,
Phys. Rev. A 72, 012510 (2005); I. Gerber and J. G.
´Angy´an, Chem. Phys. Lett. 415, 100 (2005).

17 E. Goll, H.-J. Werner and H. Stoll, Phys. Chem. Chem.

Phys. 7 , 3917 (2005).

18 S. Yamanaka, K. Kusakabe, K. Nakata, T. Takada, and K.

Yamaguchi , physics/0508121.

19 K. Burke, J. P. Perdew, and M. Ernzerhof, J. Chem. Phys.

109, 3760 (1998);

20 J.P. Perdew, A. Savin, and K. Burke, Phys. Rev. A, 51,

4531 (1995).

21 M. Levy, Proc. Natl. Acad. Sci. U.S.A. 76, 6062 (1979).
22 J. Toulouse and A. Savin, J. Mol. Struct. (Theochem), to

appear.

23 L. Zecca, P. Gori-Giorgi, S. Moroni, and G. B. Bachelet,

Phys. Rev. B 70, 205127 (2004).

24 A. Savin and H.-J. Flad, Int. J. Quantum Chem. 56, 327
(1995); J. Toulouse, A. Savin, and H.-J. Flad, ibid. 100,
1047 (2004).

25 U. von Barth and L. Hedin, J. Phys. C 5 1629 (1972).
26 R. O. Jones and O. Gunnarsson, Rev. Mod. Phys. 61, 689

(1989).

27 A. Nagy, Phys. Rep. 298, 1 (1998).
28 QMC provides the most accurate numerical values for sev-

 
eral physical properties of the HEG. See, e.g., G. Giuliani
and G. Vignale, Quantum Theory of the Electron Liquid
(Cambridge, 2005); D. M. Ceperley, in The electron liquid
paradigm in condensed matter physics, G. F. Giuliani and
G. Vignale eds. (IOS, Amsterdam, 2004).

29 J. Toulouse, P. Gori-Giorgi, and A. Savin, Theor. Chem.

Acc. 114, 305 (2005).

30 D.M. Ceperley and B.J. Alder, Phys. Rev. Lett. 45, 566

(1980).

31 S.H. Vosko, L. Wilk, and M. Nusair, Can. J. Phys. 58,

1200 (1980).

32 J.P. Perdew and A. Zunger, Phys. Rev. B 23, 5048 (1981).
33 J.P. Perdew and Y. Wang, Phys. Rev. B 45, 13244 (1992).
34 see, e.g., D. Pines and P. Nozi`eres, Theory of Quantum

Liquids (Benjamin, New York, 1966).

35 Y. Wang and J.P. Perdew, Phys. Rev. B 44, 13298 (1991).
36 J.P. Perdew and Y. Wang, Phys. Rev. B 46, 12947 (1992);

56, 7018(E) (1997).

37 P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 66, 165118

(2002).

38 Y. Wang and J.P. Perdew, Phys. Rev. B 43, 8911 (1991).
39 P. Gori-Giorgi and A. Savin, cond-mat/0511221, to appear

in Phys. Rev. A.

40 P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 64, 155102

9

(2001).

41 For a recent review on ﬁxed-node diﬀusion Monte Carlo
and further references, see M. Foulkes, L. Mitas, R. Needs,
and G. Rajagopal, Rev. Mod. Phys. 73, 33 (2001).

42 D. Ceperley, Phys. Rev. B 18, 3126 (1978).
43 Y. Kwon, D. M. Ceperley, and R. M. Martin, Phys. Rev.

B 58, 6800 (1998).

44 C. Lin, F. H. Zong, and D. M. Ceperley, Phys. Rev. E 64,

016702 (2001).

45 V. Natoli and D. M. Ceperley, J. Comput. Phys. 117, 171

(1995).

46 V. A. Rassolov, J. A. Pople, and M. A. Ratner Phys. Rev.

B 62, 2232 (2000).

47 see, e.g., G. Ortiz and P. Ballone, Phys. Rev. B 50, 1391

(1994); 56, 9970(E) (1997).

48 see, e.g., S. K¨ummel and J.P. Perdew, Phys. Rev. B 68,
035103 (2003); W. Yang and Q. Wu, Phys. Rev. Lett. 89,
143002 (2002); R. J. Magyar, A. Fleszar, and E. K. U.
Gross, Phys. Rev. B 69, 045111 (2004); M. Gr¨uning, O.
V. Gritsenko, and E. J. Baerends, J. Chem. Phys. 118,
7183 (2003). For a critical review, see also E.J. Baerends
and O.V. Gritsenko, J. Chem. Phys. 123, 062202 (2005)."
"Efficient quantum-chemical geometry optimization and the structure of
  large icosahedral fullerenes","  Geometry optimization is efficient using generalized Gaunt coefficients,
which significantly limit the amount of cross differentiation for multi-center
integrals of high-angular-momentum solid-harmonic basis sets. We parameterize
the fully analytic formulation of density functional theory (ADFT), called the
Slater-Roothaan method, developed in our group to give the exact geometry of
C60 fullerene. The parametrized ADFT is subsequently used to optimize
geometries of most stable C240, C540, C960, C1500 and C2160 icosahedral
fullerenes. The calculations are all electron, the orbital basis set includes d
functions and the exchange-correlation-potential basis set includes f
functions. The calculation of C2160 fullerene employed about 39000 basis
functions and is the largest calculation reported on any isolated molecule
to-date. The evolution of interatomic distance and atomization energy from C60
to graphite has been investigated.
",http://arxiv.org/pdf/cond-mat/0603225v2,3,"Efficient quantum-chemical geometry optimization and the structure of large 

icosahedral fullerenes 

Brett I. Dunlap 

Code 6189, Theoretical Chemistry Section 

US Naval Research Laboratory 

Washington, DC 20375-5342 

and 

 Rajendra Zope 

Department of Chemistry, 

 George Washington University,  

Washington DC, 20052 

Abstract 

Geometry optimization is efficient using generalized Gaunt coefficients, which 

significantly limit the amount of cross differentiation for multi-center integrals of high-

angular-momentum solid-harmonic basis sets.  The geometries of the most stable C240, 

C540, C960, C1500, and C2160 icosahedral fullerenes are optimized using analytic density-

functional theory (ADFT), which is parameterized to give the experimental geometry of 

C60.  The calculations are all electron, the orbital basis set includes d functions and the 

exchange-correlation-potential basis set includes f functions. The largest calculation on 

C2160 employed about 39000 basis functions. 

 
 
Key Words:  Analytic density-functional theory, geometry optimization, generalized 

Gaunt coefficients, giant fullerenes 

To our knowledge the geometry of C240 has not been optimized using excellent 

basis sets, despite continuing interest in the problem [1].  Based on the N3 scaling of the 

eigenvalue problem or the number of non-zero linear combination of atomic orbitals 

(LCAO) matrix elements involved, one would correctly estimate that accurate geometry 

optimization of C2160 requires slightly less than a thousand times the resources required to 

optimize C240.  Such calculations are not totally impossible, however. A practical 

approach is analytic density-functional theory (ADFT) [2-4].  Its variational parameters 

are 10’s of linear combination of atomic orbitals (LCAO) coefficients rather than 100’s 

of plane-wave coefficients or numerical values at 1000’s of points per atom per 

molecular orbital.  A second step forward is to compute the contribution of the local 

density-of-states to forces not by recursion [5], and xyz-factorization [6] but via the 

generalized Gaunt coefficients [7].  Due to the present limitations [8] on the functional 

forms that can be treated in ADFT, however, we need to parameterize it in order to get 

the correct geometry of the giant fullerenes. 

ADFT requires no numerical grid at all.  Therefore matrix elements and thus the 

total energy can be computed to machine precision [9,10].   Furthermore, exact matrix 

elements mean that degeneracy can be removed from the problem.  Both facts make 

accurate high-symmetry calculations much more practical than one might think.  In 

ADFT the degeneracy of multidimensional irreducible representations (irreps) is entirely 

removed except when invoking Pitzer’s theorem [11], which says that the sum of the 

2

 
 
 
magnitude squared of the basis functions for each irrep is invariant.  That theorem means 

that self-consistent-field (SCF) integrals [12] and now forces need only be evaluated for 

symmetry-distinct bra-ket atomic pairs of LCAO basis functions.   This efficiency 

enabled the largest ab initio SCF calculation on icosahedral C240 [13], which is much 

more stable than the icosahedral C60 cluster that can be made dominant among the 

fullerenes [14,15], for reasons that are still not completely understood. 

Efficient computation requires switching from the traditional Cartesian-Gaussian 

basis [5] to the solid-harmonic-Gaussian basis, which minimally contains all essential 

chemistry; the latter are eigenstates of angular momentum as are the atomic orbitals that 

collectively they approximate.   The matrix elements corresponding to higher angular 

momentum are computed by differentiating the s-type matrix elements with respect to the 

corresponding atomic center [9].  Angular momentum increases one unit with each 

appropriate differentiation.  The solid-harmonics of nabla [16] create angular momentum 

and are generated recursively by a two-term expression, 

(

L M
−

)[

L
]
∇ =
M

∂
z
∂

[
∇

1
L
−
]
M

(
+ −

∂
x
∂

+

i

∂
y
∂

)[

∇

−L
1
]
M +
1

,

(1) 

and its complex conjugate, using 

[
∇ = − ∇

( )

[

]

M

*
L
M

L
]
M−

,

 and 

∇ =   Differentiation of 
[

1.

0
]
0

solid-harmonics maximally lowers their angular momentum [17], and thus they are 

closed under differentiation.  The solid-harmonic addition theorem extends the product 

rule of differentiation to these differential operators [16].  Thus no amount of solid-

harmonic differentiation creates anything other than solid harmonics which are 

conveniently described as angular momentum about the various molecular centers.  The 

generalized Gaunt coefficients arise when an s-type function is operated upon by multiple 

solid-harmonic differential operators.  Angular momentum is lost when a differential 

3

 
 
operator acts upon a solid harmonic created by another operator.  The generalized Gaunt 

coefficients restricts that loss to zero total angular momentum.  Their use becomes more 

efficient as the angular momentum on each basis function is increased. 

In our normalization, Eq.1, the addition theorem is factorless [18], and thus 

independent of initial angular momentum, which means that the entire reduced density 

matrix for each symmetry-distinct pair of centers can be summed for each set of angular 

momentum lost by those two centers.  In our code this sum is repeated for each third 

center of the Kohn-Sham potential [19].  This approach tremendously speeds up analytic 

derivatives of three-center integrals via the 4-j generalized Gaunt coefficient [20].  This 

sum over geometric factors is still much work; it becomes 37% of the entire time it takes 

to optimize our largest fullerene.  Under its direct-SCF option, our code becomes much 

slower and this percentage drops accordingly.  The code is quite scalable as well as 

efficient when each processor reads its share of the three-center integrals from its own 

disk.   

For the single-element case of the fullerenes, our code is identical to the SCF code 

of Werpetinski and Cook [21].  This method requires a Gaussian basis, which we choose 

to be 6-311-G* [22], with highest angular momentum d-type, for analytically and 

variationally fitting the orbitals.  We also need auxiliary bases for analytically and 

variationally fitting the charge density, its cube root, and its cube root squared.  For the s-

type components of all three fitting bases we uncontract and appropriately scale the s-

type orbital exponents [2].  All higher angular momentum fitting functions are the 

uncontracted and unscaled density-fitting exponents from an optimization, the highest 

angular-momentum component of which is f-type [23].  There are 18 orbital basis 

4

 
functions per atom and at most 42 fitting functions (of three types) per symmetry 

inequivalent atom. 

The best standard method [24] can only converge the SCF calculations to the 

point where the maximum iteration-to-iteration occupied-virtual overlap matrix element 

is 10-10

.     The off-diagonal 1s-1s iteration-to-iteration overlaps in each symmetry block 

are up to three orders of magnitude larger. This instability, perhaps associated with our 

single-ζ treatment of the 1s cores, limits our SCF convergence, which we measure by 

largest change in a density-fitting coefficient.  We had to increase the allowed change to 

10-6 in the coefficient of a charge-density basis function with unit Coulomb self-

interaction.  With this limitation we are able to optimize the structure of the special 

fullerenes to the point where the root-mean-square gradient is less than 10-4 Hartree/Bohr.  

In the infinite limit a fullerene is a graphene sheet closed by 12 pentagons, which 

negligibly affects many properties including the binding energy and median nearest-

neighbor bond distance.  Total ab-initio energies, which can quite accurately be evaluated 

at empirical geometries due to the variational principle, as a function of fullerene size 

showed that band-structure calculations significantly underestimated the DFT binding 

energy of graphene and graphite [25] and lead to better band-structure calculations on 

graphite [26]. We can now just as rapidly compute fullerene geometries within ADFT for 

Xα exchange functionals.  The early appeal of the Xα method was that it is the unique 

quantum chemical method which allows molecules to dissociate correctly into atoms.  

This property leads to excellent total molecular energies [4].  Perhaps optimizing Slater’s 

exchange parameter, α [27], can be used to extrapolate other molecular properties. We 

used Perl scripts to determine the α value, 0.684667, that gives the experimental bond 

5

 
distances of C60.  The geometries using this α are given in Table I.  The coordinate axes 

are two-fold symmetry axes, thus an atom with a zero coordinate is one of sixty 

symmetry-equivalent atoms otherwise each tabulated atom generates 120 others.  The 

median nearest-neighbor bond distance for each fullerene is given in Table II.  The 

median bond distance might be going to that of graphite, which is 1.422 [26].  Certainly 

the mean bond distance for large fullerenes and graphene is less than 0.1% too long with 

this value of α in ADFT.   The standard deviation of the radius of each atom from the 

fullerene’s center is also given in Table II and compared with that of a tight-binding 

calculation [28].  Our structures are slightly more facetted.  As these are most likely the 

most accurate fullerene geometries available, their complete geometries can be 

constructed from the coordinates given in Table 1. 

With reliable structures, one can consider one-shot energy calculations with 

methods of higher accuracy, but for which geometry optimization is impractical at the 

moment.  Another alternative is to develop empirical methods for energy evaluation.  

More in line with the second approach we have determined the value α value, 0.64190, 

that gives the experimental atomization energy of C60, which we take as 7.14 eV, which 

corresponds to an enthalpy of formation of 0.43 eV/atom [29] relative to graphite’s 7.37 

eV/atom [30], ignoring zero-point energy differences.  To compute the total energy of our 

reference carbon atom we use C2v symmetry for which spin-polarized ADFT gives 

integral occupation numbers.  With this technology we estimate the atomization energy 

per carbon atom of these fullerenes in the final column of Table II.  This result is 

disappointing because already by C240 the atomization energy per atom is greater than 

that of graphite.  Clearly better ADFT energy functionals are needed, but those that we 

6

 
now have allow large basis-set calculations on some very large systems and can 

apparently give reliable geometries.  This work shows that standard convergence and 

optimization methods are sufficient for molecules as large as C2160. 

Acknowledgment 

 We thank Prof. Peter Pulay for discussions about convergence.  The Office of Naval 

Research, directly and through the Naval Research Laboratory, and the DoD's High 

Performance Computing Modernization Program, through the Common High 

Performance Computing Software Support Initiative, Project MBD-5, supported this 

research. 

Table I.  Coordinates in Angstroms of the symmetry-inequivalent carbon atoms in 

icosahedral fullerenes in a coordinate system in which the coordinate axes are two-fold 

symmetric.  Thus atoms in a coordinate axis plane are equivalent to 60 rather than 120 

other atoms. 

3.4785 

6.7860 
6.9303 
6.7985 

C60 
0.6991 
C240 
0.7115 
1.3919 
2.7763 
C540 

10.3325  3.5198 
10.2803  0.7073 
10.2436  4.9086 
10.1695  2.8338 
10.1779  1.4142 
6.9966 
5.1271 
C960 

0.0000 

1.2648 
0.0000 
0.0000 

0.0000 
0.0000 
0.0000 
1.2476 
1.2463 
5.3981 

3.5432 
4.9703 
2.8466 

5.8199  11.8037 
3.5496  12.7208 
4.7639  12.4593 

7

 
 
 
 
 
 
 
 
 
5.6793 
1.4252 
3.5573 
1.4201 
2.8364 
7.0406 
5.6502 

3.5512 
7.8104 
4.9511 
5.6653 
4.9761 
5.6878 
7.1003 
1.4247 
2.8479 
3.5577 
4.9666 
3.5497 
7.7814 
9.1725 
0.7093 

18.0082 
18.4625 
7.1054 
7.8192 
9.2300 
9.9418 
7.0731 
7.7955 
17.2983 
18.7696 
19.1851 
19.0625 
5.6898 
18.2145 
18.8481 
1.4202 
2.8390 
7.0968 
5.6803 
9.9124 

2.4027  13.1633 
4.8034  12.5708 
3.6032  12.8776 
0.0000  13.6515 
0.0000  13.6734 
0.0000  13.6930 
0.0000  13.7765 
C1500 
7.0518  15.0185 
2.4025  16.6105 
6.9501  14.7778 
5.8047  15.2231 
4.7588  15.8998 
3.6005  16.3197 
3.5465  16.1622 
5.9997  15.7080 
5.9672  15.6202 
4.8042  16.0266 
0.0000  17.1112 
0.0000  17.0721 
0.0000  17.2247 
0.0000  17.1423 
0.0000  17.0074 
C2160 
8.1894 
4.9622 
5.6791 
7.0479 
4.7521  19.3344 
3.6012  19.7701 
3.5423  19.6017 
2.4034  20.0606 
6.9341  18.1973 
5.8055  18.6713 
9.2173 
5.6441 
7.1695 
2.8471 
6.0083 
3.5591 
4.9781 
5.9624 
4.8044  19.4785 
3.5547 
8.2754 
7.1994 
1.4255 
0.0000  20.3958 
0.0000  20.4273 
0.0000  20.5677 
0.0000  20.4983 
0.0000  20.6708 

8

 
 
 
 
 
11.3039 

0.0000  20.5910 

Table II.  The median nearest-neighbor bond distance, average radius, radial standard 

deviation, all in Angstroms, for the fullerenes of this work computed using α = 0.684667.  

The average radii and radial standard deviations are slight larger than a published tight-

binding (TB) calculation [28].  The right-hand column gives the atomization energy, in 

electron volts, that we compute using α = 0.64190. 

Fullerene 

C60 
C240 
C540 
C960 
C1500 
C2160 

Median 
Bond 
Distance 
1.4244 
1.4306 
1.4264 
1.4249 
1.4244 
1.4241 

Average 
Radius 

TB Average 
Radius [28]

3.5481 
7.0728 
10.5528 
14.0342 
17.5225 
21.0137 

7.06 
10.53 
14.02 

20.95 

Radial 
Standard 
Deviation 
0.000 
0.165 
0.360 
0.526 
0.677 
0.822 

TB Radial 
Standard 
deviation [28] 

0.15 
0.35 
0.52 

0.82 

Atomization 
Energy/atom 
(α = 0.64190)
-7.140 
-7.373 
-7.431 
-7.459 
-7.474 
-7.484 

References: 

[1] G. E. Scuseria, Science 271, 942 (1996).  

[2] B. I. Dunlap, J. Phys. Chem. A 107, 10082 (2003).  

[3] R.R. Zope and B.I. Dunlap, Chem. Phys. Lett. 399, 417 (2004) 

[4]R.R. Zope and B.I. Dunlap, Phys. Rev. B 71, 193104 (2005) 

[5]  Y. Shao, C. A. White, and M. Head-Gordon, J. Chem. Phys. 114, 6572 (2001). 

[6]  D. Sundholm, J. Chem. Phys. 122, 194107 (2005). 

[7] B. I. Dunlap, Phys. Rev. A 66, 032502 (2002) 

[8] R. R. Zope and B. I. Dunlap, J. Chem. Phys.,  124, 044107 (2006).  

[9] S. F. Boys, Proc. Roy. Soc. 200, 542 (1950).  

9

 
 
 
 
 
 
 
 
 
 
 
 
[10] J. A. Pople, Angw. Chem. Int. Ed. 38, 1894 (1999).  

[11] R. M. Pitzer, J. Chem. Phys. 58, 3111 (1973).  

[12] B. I. Dunlap, Adv. Chem. Phys. 69, 287 (1987). 

[13] B.I. Dunlap, D.W. Brenner, J.W. Mintmire, R.C. Mowrey, and C.T. White, J. Phys. 

Chem. 95, 8737-8741 (1991) 

[14] H. W. Kroto, J. R. Heath, S. C. O’Brien, R. F. Curl, and R. E. Smalley, Nature 318, 

162 (1985). 

[15] W. Krätschmer, L. D. Lamb, K. Fostiropoulos, and D. R. Huffman, Nature, 347, 354 

(1990). 

[16] B. I. Dunlap, Phys. Rev. A 42, 1127 (1990). 

[17] E. J. Weniger, Collect. Czech. Chem. Comm. 70, 1225 (2005). 

[18] E. O. Steinborn and K. Ruedenberg, Adv. Quantum Chem. 7, 1 (1973). 

[19] B. I. Dunlap, Comp. Phys. Commun. 165, 18 (2005). 

[20] B. I. Dunlap, Int. J. Quantum. Chem. 81, 373 (2001). 

[21] K. S. Werpetinski and M. Cook, Phys. Rev. A 52, R3397 (1995); J. Chem. Phys. 

106, 7124 (1997).  

[22] R. Krishnan, J. S. Binkley, R. Seeger, and J. A. Pople, J. Chem. Phys. 72, 650 

(1980). 

[23] K. Eichkorn, O. Treutler, H. Öhm, M. Häser, R. Ahlrichs, Chem. Phys. Lett. 240, 

283 (1995). 

[24]  P. Pulay, J. Comp. Chem. 3, 556 (1982).  

[25] B.I. Dunlap and J.C. Boettger, J. Phys. B: At. Mol. Opt. Phys. 29, 4907 (1996). 

[26] J. C. Boettger, Phys. Rev. B 55, 11202 (1997). 

10

 
 
[27] J. C Slater, Quantum Theory of Molecules and Solids, Vol. IV (McGraw-Hill, New 

York, 1974). 

[28] S. Itoh, P. Ordejón, D. A. Drabold, and R. M. Martin, Phys. Rev. B 53, 2132 (1996).  

[29] H. P. Diogo, M. E. Mineas de Piedade, T. J. S. Dennis, J.P. Hare, H. W. Kroto, R. 

Taylor, and D. R. M. Watson, J. Chem. Soc.-Faraday Trans. 89, 3541 (1993). 

[30] C. Kittel, Introduction to Solid State Physics 5th Edn. (New York, Wiley, 1976) p. 

74. 

11"
Model hamiltonians in density functional theory,"  The formalism of Kohn and Sham uses a specific (model) hamiltonian which
highly simplifies the many-electron problem to that of noninteracting fermions.
The theorem of Hohenberg and Kohn tells us that, for a given ground state
density, this hamiltonian is unique. In principle, this density can be chosen
as that of the real, interacting system. To obtain the energy, or other
properties of the real system, approximations are needed. Working with non
interacting fermions is an important simplification, but it may be easier to
produce approximations with different choices of the model hamiltonian. The
feature that the exact density is (ideally) reproduced can be kept in the newly
defined fictitious systems. Using model hamiltonians having the same form as
the physical one, that is, being built of one- and two-body operators, allows
to approach the physical hamiltonian arbitrarily close, and thus a systematic
reduction of the approximations.
",http://arxiv.org/pdf/cond-mat/0605174v2,3,"6
0
0
2

l
u
J

6
2

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

2
v
4
7
1
5
0
6
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Model hamiltonians in density functional theory

Paola Gori-Giorgi, Julien Toulouse, and Andreas Savin

Abstract. The formalism of Kohn and Sham uses a speciﬁc (model) hamil-
tonian which highly simpliﬁes the many-electron problem to that of noninter-
acting fermions. The theorem of Hohenberg and Kohn tells us that, for a given
ground state density, this hamiltonian is unique. In principle, this density can
be chosen as that of the real, interacting system. To obtain the energy, or
other properties of the real system, approximations are needed. Working with
non interacting fermions is an important simpliﬁcation, but it may be easier to
produce approximations with diﬀerent choices of the model hamiltonian. The
feature that the exact density is (ideally) reproduced can be kept in the newly
deﬁned ﬁctitious systems. Using model hamiltonians having the same form as
the physical one, that is, being built of one- and two-body operators, allows
to approach the physical hamiltonian arbitrarily close, and thus a systematic
reduction of the approximations.

1. Introduction

1.1. General context. The knowledge from ﬁrst principles of the electronic
structure of atoms, molecules and solids is contained in the N -electron Schr¨odinger
equation that, within the Born-Oppenheimer approximation (i.e., at ﬁxed nuclei
positions Rα), reads

(1.1)

with

(1.2)

(1.3)

(1.4)

ˆH(r1, ..., rN ) Ψ(r1σ1, ..., rN σN ) = E Ψ(r1σ1, ..., rN σN ),

ˆH = ˆT + ˆWee + ˆVne,

ˆT =

ˆWee =

−

1
2

N

1
2

i=1
X
N

2
ri ,
∇

1
ri −

|

M

=j
Xi
N

1
2

N

=j
Xi

≡

rj |

wee(
|

ri −

rj|

),

N

(1.5)

ˆVne =

Zα
Rα −
where vne is the external potential due to the M nuclei of charges Zα at positions
Rα, and Hartree atomic units, ~ = 1 (reduced Planck’s constant) m = 1 (electron

ri| ! ≡

i=1  
X

vne(ri),

α=1
X

i=1
X

−

|

Key words and phrases. Schr¨odinger equation, density functional theory.

1

 
 
 
 
 
 
6
6
2

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

mass), a0 = 1 (Bohr radius), e = 1 (electron charge), have been used. Since elec-
trons obey the Fermi-Dirac statistics, Ψ must be antisymmetric under particle ex-
change, Ψ(r1σ1, ..., riσi, ..., rjσj, ..., rN σN ) =
Ψ(r1σ1, ..., rjσj, ..., riσi, ..., rN σN ),
where r denotes the three-dimensional electronic position and σ the spin degree of
freedom (
). In what follows we will be only concerned with the search for the
↑
ground-state energy, i.e., the lowest eigenvalue E0 of Eq. (1.1).

or

−

↓

The methods that both chemists and physicists have developed to ﬁnd approx-
imate solutions of Eq. (1.1) can be roughly divided in two large groups: wave-
function methods (traditional quantum chemistry methods [1], quantum Monte
Carlo [2]) and density methods (density functional theory [3], and density matrix
functional theory [4], that is somehow in between the two groups). Simplistically,
wave-function methods start from an approximation for the antisymmetric, nor-
malized, N -electron wave-function, Ψapprox, and take advantage of the variational
principle,

(1.6)

Eapprox

0

E0

≤

= min

Ψapproxh

Ψapprox

ˆH

|

|

Ψapprox

.
i

Since Ψapprox is a 3N dimensional object, wave-function methods are in general
computationally expensive when the number of particles increases.

Density Functional Theory (DFT) uses the electron density n(r) as a basic

variable,

(1.7)

n(r) = N

Ψ(rσ1, r2σ2, ..., rN σN )
|

|

2dr2...drN ,

σ1...σN Z
X

a much simpler quantity to handle, resulting in a low computational cost that allows
to reach system sizes much larger than those accessible to wave-function methods.
At given number of electrons N , the Hohenberg and Kohn theorem [5] tells us
that the ground-state density n(r) of Eq. (1.7) completely determines (except for
an additive constant) the external potential vne(r) of Eq. (1.5) (for the sake of
simplicity we only consider physical hamiltonians with a nondegenerate ground
state). Since the kinetic energy operator of Eq (1.3) and the electron-electron
interaction of Eq. (1.4) are the same for all systems, a universal functional F of the
density n(r) can be deﬁned as [6]

Ψ

Ψ

(1.8)

ˆT + ˆWee|

F [n; ˆWee, ˆT ] = min
nh
→
where, to keep the connection with what we will do in the next sections, we have
explictly shown the dependence of F on the electronic interaction ˆWee and on the
kinetic energy operator ˆT . The minimum search in Eq. (1.8) is performed over all
antisymmetric wave-functions Ψ that yield the density n(r) (by deﬁnition n(r) also
gives, by integration, the number of electrons N ). The universal functional F can
be also deﬁned as a Legendre transform [7]

,
i

Ψ

|

(1.9)

F [n; ˆWee, ˆT ] = sup

Ψ

min
Ψ h

ˆT + ˆWee + ˆV

|

Ψ

|

i −

v (cid:26)

n(r)v(r)dr

,

Z

(cid:27)

where, as in the rest of this paper, ˆV denotes a local one-body operator of the form
of Eq. (1.5) with vne(r) replaced by v(r). If the exact form of the functional F was
known, the variational principle would tell us that

(1.10)

E0 = min

n

(cid:26)

F [n; ˆWee, ˆT ] +

n(r) vne(r) dr

.

Z

(cid:27)

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

3

In practice, because we rely on approximations for F , the energy estimated by
carrying out the minimization in Eq. (1.10) can be lower than the exact E0.

1.2. Kohn-Sham density functional theory. The Kohn-Sham [8] approach

to DFT introduces another density functional Ts[n],

(1.11)

Ts[n]

≡

F [n; 0, ˆT ] = sup

Φ

min
Φ h

ˆT + ˆV

|

Φ

|

i −

Z

n(r)v(r)dr

,

(cid:27)

v (cid:26)

where, as in the rest of this work, Φ always denotes the wave-function of a spin-
1
2 fermionic system with zero electron-electron interaction, i.e., in the majority of
cases, a single Slater determinant (the fundamental idea of Kohn-Sham has been to
introduce the fermionic statistic in the construction of Ts[n]). Since dealing with
noninteracting particles is computationally simple, Kohn and Sham [8] proposed to
search for that particular noninteracting system which has the same ground-state
density of the physical one. This deﬁnes a model system which is usually called
Kohn-Sham (KS) system. The diﬀerence between F [n; ˆWee, ˆT ] and Ts[n] deﬁnes
the Hartree-exchange-correlation functional EHxc[n],

(1.12)

EHxc[n] = F [n; ˆWee, ˆT ]

Ts[n]

−

that needs to be approximated. The functional derivative, δEHxc[n]/δn(r) =
vHxc(r), determines the one-body KS potential vKS(r) = vne(r)+vHxc(r) that forces
the N noninteracting electrons to have the same density of the physical system. The
KS-DFT relies thus on the assumption that, given a physical ground-state density
n(r), it is possible to ﬁnd a noninteracting system which has the same ground-state
density.

From the functional EHxc[n] the classical electrostatic Hartree term is usually

extracted,

(1.13)

EH[n] =

Z
and the remaining, unknown, part is called exchange-correlation energy,

−

Z

|

1
2

dr

dr′

n(r)n(r′)
r′|

r

,

(1.14)

Exc[n] = F [n; ˆWee, ˆT ]

Ts[n]

−

−

EH[n].

The Hartree functional EH[n] describes the electrons as if they were classical charge
distributions. It is a simple functional of the density, and yields an important part
of the energy of a many-electron system, but is nonzero also for a one-electron
density. This “self-interaction part” of EH[n] is cancelled by the exact Exc[n], but
this does not occur for most of the current approximate functionals, which suﬀer
of the so called “self-interaction error”.

The success of KS-DFT is mostly due to the fact that simple approximations
(local-density approximation and generalized gradient corrections) for Exc[n] and
its functional derivative provide practical estimates of thermodynamical, structural
and spectroscopic properties of atoms, molecules and solids. However, with the
current approximations, KS-DFT is still lacking in several aspects, in particular
it fails to handle near-degeneracy correlation eﬀects (rearrangement of electrons
within partially ﬁlled shells) and to recover long-range van der Waals interaction
energies. The inaccuracy of KS-DFT stems from our lack of knowledge of Exc[n],
and much eﬀort is put nowadays in ﬁnding new approximations to this term [9]. A

4

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

trend in the current research is to construct implicit functionals of the density: in
particular, the exchange-correlation functional is divided into exact exchange

(1.15)

Ex[n] =

Φ
h

|

ˆWee|

Φ

i −

EH[n],

and the remaining correlation energy Ec[n] = Exc[n]
Ex[n]. The exact exchange
cancels the self-interaction error of EH[n], and is an implicit functional of n(r)
through the Slater determinant Φ. The corresponding Kohn-Sham potential must
be determined via the optimized eﬀective potential method (OEP) [10],

−

(1.16)

E0 = inf
v

ˆT + ˆWee + ˆVne|
where Φv is the ground state of the noninteracting hamiltonian, ˆT + ˆV . The con-
struction of a correlation energy functional Ec[n] to be used with exact exchange
in Eq. (1.16) is still an open problem.

Φv|
h
n

+ Ec[nΦv ]

Φvi

o

,

In this work, we review some basic ideas, results, and open questions of a
diﬀerent approach: instead of trying to approximate the KS Exc[n], we change the
model system deﬁned by Eq. (1.11).

1.3. Adiabatic connection formula. Before discussing the choice of diﬀer-
ent model hamiltonians, we report some equations that will be used in the next
sections. An exact formula for the functional EHxc[n] can be obtained via the adia-
batic connection formalism [11, 12]: by varying a real parameter λ, the interaction
wλ(r12) between the electrons (we have deﬁned r12 =
to denote pair-
wise interactions that only depend on the electron-electron distance) is switched
on continuously from zero to 1/r12, while the density is kept ﬁxed by an external
one-body potential ˆV λ. Each hamiltoninan ˆH λ along this adiabatic connection has
a ground-state wavefunction Ψλ that yields, by construction, the same density n(r)
for each λ. If wλ=0 = 0 and wλ=a = 1/r12, the KS Hartree-exchange-correlation
energy is given by [11, 12]

r2

r1

−

|

|

(1.17)

EHxc[n] =

a

0

dλ

Z

Z

dr12 4π r2

12f λ(r12)

∞

0

∂wλ(r12)
∂λ

,

where the spherically and system-averaged pair density (APD) f λ(r12) is obtained
by integrating

Ψλ

,

|

2 over all variables but r12 =
|
N (N
2

|
Ψλ(r12, R, r3, ..., rN )
|

r2

r1

1)

−

−

|

|

2 dΩr12
4π

dRdr3...drN .

(1.18) f λ(r12) =

where R = (r1 + r2)/2.

σ1...σN Z
X

2. Changing the model hamiltonian

2.1. General considerations. Equation (1.11) shows that the KS approach
to DFT introduces a model hamiltonian in which ˆWee is set equal to zero and the
one-body potential, vKS(r), is diﬀerent from vne(r) (and is obtained by imposing the
condition that the ground-state electron density of the model hamiltonian be the
same of the physical system). Solving the noninteracting KS hamiltonian instead of
the fully interacting hamiltonian of Eq. (1.1) is obviously very practical. The exact
ground-state energy of the physical system can, in principle, be obtained from the
KS Slater determinant Φ via the functional Exc[n]. However, there are cases in
which the restriction that the model system be noninteracting makes the search for
an approximate Exc[n] seem like a daunting task. Consider the simple example of

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

5

)

2
1

r
(
f

2
1

2

r

π
4

)

2
1

r
(
f

2
1

2

r

π
4

physical
KS

R = 1.4

 0

 1

 2

 3

 4

 5

r12

physical
KS

R = 20

 0.5
 0.45
 0.4
 0.35
 0.3
 0.25
 0.2
 0.15
 0.1
 0.05
 0

 0.35

 0.3

 0.25

 0.2

 0.15

 0.1

 0.05

 0

 0

 5

 10  15  20  25  30

r12

Figure 1. The spherically and system-averaged pair density
f λ(r12) of Eq. (1.18) for the H2 molecule in the KS system (λ = 0)
and in the physical system (Coulombic interaction). The inter-
nuclear equilibrium distance R = 1.4 and the extreme stretched
molecule at R = 20 are considered.

the H2 molecule (two electrons in the ﬁeld of two nuclei of unitary charge spaced by a
distance R). In Fig. 1 we report the quantity 4πr2
12f λ(r12) that enters in Eq. (1.17)
for the KS system and for the physical system (λ = 0 and λ = a, respectively)
at two internuclear distances R. As shown by Eq. (1.17), the change in the APD
f λ(r12) when we switch from the KS system to the physical (fully interacting)
system determines the functional EHxc[n].
If this change is not drastic, we can
expect that universal approximations for EHxc[n] can work relatively well. This is,
e.g., the case of the H2 molecule at the equilibrium distance R = 1.4 a.u., reported
in Fig. 1. But when we stretch the molecule (e.g., in the extreme case R = 20
considered in the same ﬁgure), we see that the two APD are completely diﬀerent,
which means that the term EHxc[n] becomes very important: it has to correct the
very diﬀerent nature of the KS wavefunction with respect to the physical one. This
eﬀect is completely system-dependent and it is thus very diﬃcult to include in a
universal functional of the density.

Cases like this appear when we have near-degenerate levels in the Kohn-Sham
system (in the case of the H2 molecule described above, the energies of the two KS
states σg and σu become closer and closer as R increases). The basic idea reviewed
in this paper is to remove the constraint that the model system be noninteracting

 
 
 
 
 
 
 
 
 
 
6

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

in order to keep a reasonable resemblance between the model wavefuntion and the
real one.

2.2. Using a modiﬁed electron-electron interaction. Obviously, the model

≥

0, smaller than the Coulomb interaction

system must still be less expensive to solve than the physical one. A possible ap-
proach is to deﬁne a density functional for a “partial” electron-electron interaction
w(r12)
1/r12, but diﬀer-
ent from zero (we restrict our choice to pairwise interactions that only depend on
the electron-electron distance). Following the idea of the adiabatic connection of
Sec. 1.3, we can make our partial interaction depend on a real parameter µ in such
a way that wµ(r12)
1/r12 when µ tends to some
positive value a, and deﬁne

0 and wµ(r12)

r12, w(r12)

0 when µ

→

→

→

≤

∀

(2.1)

F µ[n]

≡

F [n; ˆW µ, ˆT ] = sup

Ψ

min
Ψ h

ˆT + ˆW µ + ˆV

|

Ψ

|

i −

Z

n(r)v(r)dr

.

(cid:27)

v (cid:26)

With this deﬁnition, we see that the density functional F µ[n] switches from the
Kohn-Sham one of Eq. (1.11) to the physical one of Eq. (1.9),

(2.2)

(2.3)

F µ
F µ

→

→

0[n] = F [n; 0, ˆT ] = Ts[n],
a[n] = F [n; ˆWee, ˆT ].

In analogy with the KS approach, we can ask that the model system with inter-
action wµ(r12) have the same density of the physical one. This ﬁxes the external
one-body potential (that we call vµ(r)) in our model hamiltonian ˆH µ. The ground-
state wavefunction of our model system is denoted Ψµ: it is a multideterminantal
wavefunction that must be computed with one of the standard methods of quan-
tum chemistry (conﬁguration interaction, coupled cluster, multi-conﬁguration self-
consitent ﬁeld,...). In general, if µ is not too large (i.e., if wµ is still much smaller
than the full Coulomb interaction), few determinants describe Ψµ quite accurately,
[n] between the
so that the computational cost can be kept low. The diﬀerence F
physical functional F [n; ˆWee, ˆT ] and the partially-interacting F µ[n],

µ

(2.4)

µ

F

[n] = F [n; ˆWee, ˆT ]

F [n; ˆW µ, ˆT ],

−

−

is what we need to approximate, together with its functional derivative that deter-
mines vne(r)

vµ(r).

µ

How to choose wµ(r12)? Two points are important to determine the partial
interaction: (i) that we can design reasonable approximations for the correspond-
[n], and (ii) that we can solve adequately the hamiltonian ˆH µ of the model
ing F
system. A convenient choice seems to be a long-ranged interaction, i.e., a wµ(r12)
that behaves as 1/r12 for large r12, but that is softer than 1/r12 for small r12.
The reasons for this choice are (i) short-range correlation eﬀects seem to be more
transferable from one system to another [13], and they should thus be more easily
described in terms of an approximate universal density functional; (ii) the tradi-
tional wavefunction methods of quantum chemistry can reasonably describe Ψµ at a
lower cost than the fully interacting system, because of the smaller interaction and
because of the absence of the electron-electron cusp. For practical reasons (analytic
matrix elements for both Gaussians and plane-waves, i.e. the most commonly used
basis sets in quantum chemistry and solid-state physics, respectively), a common

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

7

choice is

(2.5)

wµ(r12) =

erf(µ r12)
r12

,

where erf(x) is the error function (and we thus have a =
). Other possibilities for
wµ(r12) have been also explored: they are all, like Eq. (2.5), arbitrary, and an open
question is wether there is a way to determine wµ(r12) according to some optimal
criteria. The approach resulting from the choice of Eq. (2.5) is the one that we
describe more in details in the next Sec. 3. Before doing that, for completness we
also brieﬂy introduce a diﬀerent choice of the model hamiltonian.

∞

2.3. Adding a nonlocal one-body operator. Another way to modify the
model system is by adding a nonlocal one-body operator, ˆONL, multiplied by a real,
positive constant g [14, 15],

(2.6)
By setting ˆONL equal to the projector (here reported for closed-shell systems) onto
the virtual Kohn-Sham orbitals φi(r) ,

F [n; ˆT + g ˆONL, ˆWee].

F g[n]

≡

(2.7)

ˆONL(r, r′) = δ(r

r′)

−

−

N/2

φi(r)φ∗i (r′),

i=1
X

the functional F g[n] of Eq. (2.6) switches from the physical one at g = 0 to the
0,
Kohn-Sham one of Eq. (1.11) in the limit g
as g
= 0, that
is, by occupying only the KS orbitals). This choice of the model system is not
further detailed here; the interested reader may ﬁnd additional information in the
literature [14, 16, 15].

|
the model system minimizes its energy by making

Ψ
|
i
ˆONL
|

ˆONL
Ψ
h

is always

(since

→ ∞

→ ∞

Ψ
h

≥

Ψ

i

|

3. Multideterminantal DFT from a long-range-only interaction

3.1. The functionals. Following the same steps of Sec. 1.3, we can write an
[n] of Eq. (2.4) in terms of the APD f µ(r12).
exact formula for the functional F
It is convenient to use for the adiabatic connection the same partial interaction
wµ(r12) of Eq. (2.5) chosen to determine the model system,
∂wµ

(r12)

∞

∞

µ

µ

′

′

(3.1)

F

[n] =

dµ′

dr12 4π r2

12f µ

(r12)

.

∂µ′

µ
Z

0
Z

This formula is identical to Eq. (2.4), except from the fact that the integration over
the coupling constant starts from the positive value µ instead than zero.
µ

As in KS-DFT, the functional F

[n] can be divided into an Hartree term,

(3.2)

µ
H[n] =

E

1
2

and an exchange-correlation term

Z

Z

dr

dr′n(r)n(r′)

1

r

(cid:20)

|

r′|

−

wµ(
|

r

−

−

r′

,

)
(cid:21)

|

µ

E

(3.3)

µ
xc[n] = F

µ
H[n]
µ
that needs to be approximated. The functional E
xc[n] can, in turn, be divided into
exchange and correlation in two diﬀerent ways. We can, in fact, deﬁne an exchange
functional by using the Kohn-Sham determinant Φ,
µ
x [n] =

µ
H[n],

(3.4)

ˆW µ

[n]

−

E

E

E

Φ

Φ
h

|

ˆWee −

|

i −

8

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

and then deﬁne the usual correlation energy functional E

µ
c [n],

(3.5)

E

µ
c [n] = E

µ
xc[n]

µ
x [n],

E

−

but we can also deﬁne a multideterminantal (md) exchange functional [17] by using
the wavefunction Ψµ,

(3.6)

ˆWee −
and then a corresponding correlation energy,

µ
x,md[n] =

Ψµ
h

E

|

ˆW µ

Ψµ

|

i −

µ
H[n],

E

(3.7)

E

µ
c,md[n] = E

µ
xc[n]

E

µ
x,md[n].

−

These two ways of splitting exchange and correlation play a role only if we imple-
ment an optimized eﬀective potential-like scheme, in analogy with what is usually
done for the exact-exchange KS-DFT [10] [see Eq. (1.16)]. In the case of the mul-
tideterminantal exchange of Eq. (3.6) the problem can be reformulated as [17]

(3.8)

E0 = inf
vµ

Ψµ
vµ
h

ˆT + ˆWee + ˆVne|

|

Ψµ
vµ

i

+ E

µ
c,md[nΨµ

vµ ]

,

n

o

where Ψµ
vµ is obtained by solving the Schr¨odinger equation corresponding to the
hamiltonian ˆH µ = ˆT + ˆW µ + ˆV µ. This equation is the generalization of Eq. (1.16)
to the case of the multideterminantal model system Ψµ.

3.2. Exact properties of the functionals. From Eq. (3.1) it is possible to
0 limit [18,

derive exact properties of the functionals of Eqs. (3.4)–(3.7) in the µ
19] and in the µ

limit [18, 20].

In the ﬁrst case, all the functionals E

µ
x,md,
µ
E
c,md [Eqs. (3.6) and (3.7)] tend to the KS functionals of Sec. 1.2. This limit
can be studied with perturbation theory: one ﬁnds that the way in which the
functionals approach the KS ones depends on wether the system is conﬁned [18]
(atoms, molecules) or extended [19].

µ
c [Eqs. (3.4) and (3.5)] and E

µ
x, E

→ ∞

→

The large-µ limit is the most interesting, since, as shown by Eq. (3.1), it always
lies in the range of µ-values for which we want to construct approximations. In
this limit, all the functionals of Eqs. (3.4)–(3.7) vanish and, since ∂wµ(r12)/∂µ =
2
√π e−
12 , Eq. (3.1) shows that their large-µ behavior is determined by the short-
range part (small r12) of the spherically and system-averaged pair density f µ(r12).
, the small-r12 part of f µ(r12) is
It is possible to show [20] that, when µ
dominated by

→ ∞

µ2r2

(3.9)

f µ(r12) = f (0)

1 + 2 r12 p1(µr12) +

(cid:20)

2
√πµ

,

(cid:21)

where f (0) is the “on-top value” (zero electron-electron distance) of the physical
(i.e., corresponding to the Coulomb interaction) f (r12), and the function p1(y) is
equal to [20]

(3.10)

p1(y) =

y2

e−

−
2√π y

2

+

1
2

+

1
4 y2

(cid:18)

(cid:19)

erf(y).

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

9

x [n], the KS f µ=0(r12), corresponding to
Inserting Eq. (3.9) (and, for the case of Eµ
the KS determinant Φ) into Eq. (3.1) we ﬁnd, for unpolarized systems [21, 18, 20]

(3.11)

E

µ
x

→∞

[n] =

π
4µ2

−

drn(r)2 + O

1
µ4

,

(cid:19)

(3.12)

E

µ
c

→∞

[n] =

(3.13)

E

µ
→∞x,md [n] =

π
µ2

π
µ2

(3.14)

E

µ
→∞c,md [n] =

f (0)

−

Z

f (0)

(cid:20)

f (0)

(cid:20)

1
4

−

Z

1
2

−
Z
4√π(√2
3 µ3

1)

−

+ O

(cid:18)

1
µ4

.

(cid:19)

(cid:18)
drn(r)2

drn(r)2

+ f (0)

+ f (0)

(cid:21)

(cid:21)

4√2π
3 µ3 + O
4√π(2√2
3 µ3

1
µ4

(cid:18)

1)

−

,

(cid:19)

+ O

1
µ4

,

(cid:19)

(cid:18)

These equations tell us that (i) if we use the deﬁnition of exchange with the KS
µ
determinant, the functional E
x[n] is, for large µ, exactly described by a local func-
tional of the density; (ii) all the other three functionals involve the physical “on-top”
f (0), which is usually not available (its knowledge would require a very accurate
calculation for the physical system!). However, it is possible to construct approx-
imations for f (0). For instance, for many systems the estimate of f (0) from the
local density approximation (i.e., by transfer from the uniform electron gas model)
is rather good [13]. Another possibility is to use Eq. (3.9) to estimate f (0) from
f µ(0). This estimate has the advantage of being without self-interaction error [20].

3.3. Building approximate functionals. Following the same historical path
of KS-DFT, the simplest approximation one can think of is the local density (LDA),

(3.15)

µ
xc[n] =

E

dr n(r) [ǫxc(n(r))

Z

ǫµ
xc(n(r))],

−

where ǫxc(n) and ǫµ
xc(n) are the exchange-correlation energy per particle of an elec-
tron gas of uniform density n with interaction 1/r12 [22] and wµ(r12) [23, 19],
respectively.

Generalized-gradient approximations (GGA) for E

µ
xc have been also constructed
[24, 25, 26, 27] along similar lines of KS-DFT [28]. In this context, we only men-
tion a conceptually simple approximation based on the exact properties of the
previous Sec. 3.2. It consists [24] in a rational interpolation between a given GGA
KS functional at µ = 0, and zero at µ
. The rational interpolation is con-
strained to recover the exact large-µ behavior of Eqs. (3.11)-(3.12), using the LDA
approximation for the physical on-top f (0).

→ ∞

All these ways of constructing approximate functionals are based on the as-
sumption of transferability of short-range exchange and correlation eﬀects from
one system (the uniform electron gas) to the others. Another strategy that came
out recently, and that seems very well suited to describe short-range correlation
eﬀects, consists in generating realistic APD f µ
(r12) along the adiabatic connection
µ, to be inserted in Eq. (3.1)] by solving simple “radial” (unidimensional)
[with µ′

′

≥

10

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

equations [29, 30] for a set of “eﬀective geminals” ψµ

i (r12),

−

(cid:20)

(3.16)

r12 +

1
r12
ϑi|

d2
dr2
12
′
ψµ
i (r12)
|

ℓ(ℓ + 1)
r2
12
′
2 = f µ

(r12).

′

+ wµ

eﬀ (r12)
(cid:21)

′

′

ψµ
i (r12) = ǫµ

i ψµ

i (r12)

′

′

′

′

′

in practice wµ

(r12) (i.e., corresponding to the wavefunction Ψµ

i
X
The eﬀective interaction wµ
eﬀ (r12) is (in principle) the Lagrange multiplier for the
exact f µ
along the adiabatic
In these equations the rule
connection;
for the occupancy ϑi of the eﬀective geminals is chosen, for spin compensated
systems, to be Slater-determinant-like: occupancy 1 for even ℓ (singlet symmetry),
occupancy 3 for odd ℓ (triplet symmetry), up to N (N
1)/2 occupied geminals.
This rule has been applied to solve the eﬀective equations (3.16) in the uniform
(Coulombic interaction), with rather accurate results [31, 32]
electron gas at µ =
when combined with simple approximations for the eﬀective interaction potential
weﬀ (r12).

eﬀ (r12) is approximated).

∞

−

′

3.4. The calculation of Ψµ: an illustrative example. As said in the
previous paragraphs, the model wavefunction Ψµ is, in most cases, computed with
one of the traditional wavefunction methods of quantum chemistry. We report here
an illustrative example of such calculation, and we then give in the next Sec. 4
an overview of recent results obtained using diﬀerent methods for computing Ψµ,
combined with diﬀerent approximations for the functionals.

Since the only purpose of this paragraph is to investigate the wavefunction
part of the multideterminantal DFT, we only consider two very small systems, the
He and the Be atoms, for which it has been possible to construct very accurate
potentials vµ [18].
In this way (i) we have essentially no approximation on the
functional part and we can focus our attention on the eﬀect of approximations on
the calculation of Ψµ, and (ii) we can produce accurate benchmark results to test
our calculations. Of course, this is not the general procedure in which we are ﬁnally
interested. The general procedure rather consists in using a given approximation
µ
(see Sec. 3.3) for the functional E
xc[n] and the corresponding potential, and com-
bining it with a wavefunction method to calculate Ψµ, to ﬁnally obtain the total
ground state energy of the physical hamiltonian. This procedure has been followed
with very promising results in the works reviewed in the next Sec. 4.

Here, in order to illustrate the eﬃciency of approximate wavefunction meth-
ods to treat Ψµ, we thus proceed as follows [18]. We ﬁrst construct, for each
µ, the model Hamiltonian ˆH µ using an accurate potential vµ [18] and compute
accurately its ground-state energy, Eµ =
Ψµ
, at the multi-reference con-
i
h
|
ﬁguration interaction with singles and doubles (MRCISD) level. We then compute
various approximate ground-state energies, Eµ
Ψµ
Ψµ
, by using approx-
Si
S|
|
h
imate conﬁguration inteaction (CI) type wave functions Ψµ
S expanded into linear
combinations of all the few Slater determinants generated from small orbital spaces
S. The orbitals used are the natural orbitals of the Coulombic system calculated
at the MRCISD level. The accuracy of the approximation for Ψµ
S can be assessed
by looking at the diﬀerence between Eµ

S =

ˆH µ

ˆH µ

Ψµ

|

S and Eµ

(3.17)

∆Eµ

S = Eµ

S −

Eµ.

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

11

0.04

0.03

DEΜ
Ha.u.L

0.02

0.01

1s

1s2s

1s2s2p

0

0

1

2

3
Μ Ha.u.L

4

5

6

|

Ψµ

ˆH µ

Ψµ
Figure 2. Ground-state energy diﬀerences ∆Eµ
Si−
where Ψµ is an accurate wave function and Ψµ
Ψµ
S are
h
approximate wave functions generated from small orbital spaces
S = 1s, S = 1s2s and S = 1s2s2p, as a function of µ for the He
atom.

Ψµ
S|
h

S =

ˆH µ

i

|

|

The diﬀerences ∆Eµ

S are plotted as a function of µ in Fig. 2 for the He atom
with the orbital spaces S = 1s, S = 1s2s and S = 1s2s2p. One sees that, in the
Coulombic limit, µ
, the reduction of the orbital space leads to important
errors in the energy. When µ is decreased, i.e. when the interaction is reduced, the
errors due to limited orbital spaces get smaller and smaller. For instance, at µ = 1,
using only the single-determinant wave function Ψµ
1s of less
than 0.005 Hartree.

1s, leads to an error ∆Eµ

→ ∞

The case of the Be atom with the orbital spaces S = 1s2s and S = 1s2s2p
is reported in Fig. 3. Because of the near-degeneracy of the 2s and 2p levels, the
inclusion of 2p conﬁgurations in the wave function is important, quite independently
of the electron-electron interaction. Indeed, the diﬀerence Eµ
1s2s2p remains
large for almost all µ’s. On the contrary, the error of the calculation where the 2p
orbitals are included, ∆Eµ
1s2s2p, quickly falls oﬀ when µ is decreased. Again, for
µ = 1 for instance, the error ∆Eµ
1s2s2p given by the few-determinant CI-type wave
function Ψµ

1s2s2p is less than 0.005 Hartree.

1s2s −

Eµ

Therefore, the modiﬁcation of the interaction enables to increase the accuracy
of CI-type wave function calculations, or equivalently for a ﬁxed target accuracy,
decrease the eﬀort of the calculation by reducing the orbital space. The crucial point
for this eﬀect to appear seems to be the reduction of the electron-electron interaction
compared to the Coulomb interaction rather than the long-range character of the
modiﬁed interaction.

4. Some recent results: a short overview

The idea of using the partially interacting model system of Eq. (2.1) has been
explored with diﬀerent techniques to compute the wavefunction Ψµ, and using
diﬀerent approximations for the functionals of Sec. 3.1. We review very brieﬂy
some of the corresponding results.

12

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

0.08

0.06

DEΜ
Ha.u.L

0.04

0.02

0

0

1s2s

1s2s2p

2

4
Μ Ha.u.L

6

8

3.
Ψµ

Ground-state
ˆH µ
Ψµ

Figure
=
Ψµ
ˆH µ
where Ψµ is an accurate wave
Si − h
S|
h
|
function and Ψµ
S are approximate wave functions generated from
small orbital spaces S = 1s2s and S = 1s2s2p, as a function of µ
for the Be atom.

diﬀerences ∆Eµ
S

energy

Ψµ

i

|

|

The LDA functional for E

µ
xc[n] has been combined with conﬁguration interac-
tion (CI) to handle the wavefunction Ψµ in Refs. [33, 34]; the method has been
applied to atoms and small molecules. Again using LDA for the short-range func-
tional, in Ref. [35] it has been shown that long-range van der Waals forces in rare
gas dimers can be well described by using second-order perturbation theory for Ψµ.
A short-range GGA functional has been combined with the coupled-cluster
(CC) method to describe Ψµ, with very good results for small molecules, both
for the closed and the open shell cases [26, 27]:
in particular, the results from
multideterminantal DFT for small and medium basis-set sizes are better of both
the pure DFT result and the pure CC result. In Ref. [36], a diﬀerent GGA func-
tional [25, 18] has been used, and Ψµ has been determined by multi-conﬁguration
self consitent ﬁeld (MCSCF). The corresponding application to systems in which
near-degeneracy eﬀects play a major role is promising, although self-interaction
errors in the functionals are still a problem in some cases [36].

Realistic f µ

(r12) from Eqs. (3.16) have been generated for two-electron atoms
in Ref. [29]: with a very simple approximation for wµ
eﬀ (r12) (inspired to the one
µ
xc[n] have been obtained.
used for the electron gas at µ =
This new strategy of producing functionals is still at a very early stage, and several
steps are needed for its development. In particular, we need better approximations
for wµ
eﬀ (r12), and the implementation of an eﬃcient algorithm to couple the radial
equations (3.16) with the method used to solve the model hamiltonian ˆH µ.

), extremely accurate E

∞

′

′

′

In conclusions, changing the model Hamiltonian in DFT calculations seems
to be a promising alternative to the construction of better exchange-correlation
functionals for standard Kohn-Sham DFT. Of course, the method has been under
development only in the last decade, and it still needs further improvement and
investigation in many aspects.

MODEL HAMILTONIANS IN DENSITY FUNCTIONAL THEORY

13

References

[1] see, e.g., J.A. Pople, Nobel Lecture: Quantum chemical models, Rev. Mod. Phys. (1999) 71,

1267–1274.

[2] see, e.g., W.M.C. Foulkes, L. Mitas, R.J. Needs, and G. Rajagopal, Quantum Monte Carlo

simulations of solids, Rev. Mod. Phys. (2001) 73, 33–83.

[3] see, e.g., W. Kohn, Nobel Lecture: Electronic structure of matter – wave functions and density

functionals, Rev. Mod. Phys. (1999) 71, 1253–1266.

[4] see, e.g., A.J. Coleman and V.I. Yukalov, Reduced density matrices : Coulson’s challenge,

Springer, Berlin, 2000.

[5] P. Hohenberg and W. Kohn, Inhomogeneous Electron Gas Phys. Rev. (1964) 136, B864-B871.
[6] M. Levy, Universal variational functionals of electron densities, 1st-order reduced density-
matrices, and natural spin-orbitals and solution of the v-representability problem, Proc. Natl.
Acad. Sci. U.S.A. (1979) 76, 6062-6065.

[7] E.H. Lieb, Int. J. Quantum Chem., Density functionals for Coulomb-systems (1983) 24, 243-

277.

[8] W. Kohn and L.J. Sham, Self-Consistent Equations Including Exchange and Correlation

Eﬀects, Phys. Rev. (1965) 140, A1133-A1138.

[9] see, e.g., A. E. Mattsson, In pursuit of the ”divine” functional, Science (2002), 298, 759-760.
[10] see, e.g., S. K¨ummel and J.P. Perdew, Optimized eﬀective potential made simple: Orbital
functionals, orbital shifts, and the exact Kohn-Sham exchange potential, Phys. Rev. B (2003)
68, 035103 1-15; W. Yang and Q. Wu, Direct Method for Optimized Eﬀective Potentials in
Density-Functional Theory, Phys. Rev. Lett. 89, 143002 1-4 (2002), and references therein.

[11] see, e.g., A. Savin, F. Colonna, R. Pollet, Adiabatic connection approach to density func-
tional theory of electronic systems, Int. J. Quantum Chem. (2003) 94, 166-190, and references
therein.

[12] W. Yang, Generalized adiabatic connection in density functional theory, J. Chem. Phys.

(1998), 109, 10107-10110.

[13] see, e.g., K. Burke, J. P. Perdew, and M. Ernzerhof, Why semilocal functionals work: Accu-
racy of the on-top pair density and importance of system averaging, J. Chem. Phys. (1998)
109, 3760-3771.

[14] J. Rey and A. Savin, Virtual space level shifting and correlation energies, Int. J. Quantum

Chem. (1998), 69, 581-590.

[15] C. Gutl´e, Espace orbitalaires et

th´eorie de la fonctionelle de la densit´e, PhD the-
sis, Universit´e Pierre et Marie Curie (Paris, France). Full text (in French) available at
http://www.lct.jussieu.fr/DFT/

[16] G.E. Engel, and W.E. Pickett, Investigation of density functionals to predict both ground-

state properties and band structures, Phys. Rev. B (1996) 54, 8420-8429.

[17] J. Toulouse, P. Gori-Giorgi and A. Savin, A short-range correlation energy density functional

with multi-determinantal reference, Theor. Chem. Acc. (2005), 114, 305-308.

[18] J. Toulouse, F. Colonna, A. Savin, Long-range/short-range separation of the electron-electron

interaction in density functional theory, Phys. Rev. A (2004) 70, 062505 1-16.

[19] S. Paziani, S. Moroni, P. Gori-Giorgi, and G.B. Bachelet, Local-spin-density functional for

multideterminant density functional theory, Phys. Rev. B (2006) 73, 155111 1-9.

[20] P. Gori-Giorgi and A. Savin, Properties of short-range and long-range correlation energy

density functionals from electron-electron coalescence, Phys. Rev. A (2006) 73, 032506 1-9.
[21] P.M.W. Gill and R.D. Adamson, A family of attenuated Coulomb operators, Chem. Phys.

Lett. (1996) 261, 105-110.

[22] D. M. Ceperley and B.J. Alder, Ground State of the Electron Gas by a Stochastic Method,

Phys. Rev. Lett. (1980) 45, 566-569.

[23] J. Toulouse, A. Savin, and H.-J. Flad, Short-range exchange-correlation energy of a uniform
electron gas with modiﬁed electron-electron interaction, Int. J. Quantum. Chem. (2004) 100,
1047.

[24] J. Toulouse, F. Colonna, and A. Savin, Short-range exchange and correlation energy density
functionals: beyond the local density approximation, J. Chem. Phys. (2005) 122, 014110 1-10.
[25] J. Heyd, G.E. Scuseria, and M. Ernzerhof Hybrid functionals based on a screened Coulomb

potential, J. Chem. Phys. (2003), 118 8207-8215.

14

PAOLA GORI-GIORGI, JULIEN TOULOUSE, AND ANDREAS SAVIN

[26] E. Goll, H.-J. Werner, and H. Stoll, A short-range gradient-corrected density functional in
long-range coupled-cluster calculations for rare gas dimers, Phys. Chem. Chem. Phys. (2005)
7, 3917-3923.

[27] E. Goll, H.-J. Werner, H. Stoll, T. Leininger, P. Gori-Giorgi, and A. Savin, A short-range
gradient-corrected spin density functional in combination with long-range coupled-cluster
methods: Application to alkali-metal rare-gas dimer, Chem. Phys., in press.

[28] J. P. Perdew, K. Burke, and M. Ernzerhof, Generalized Gradient Approximation Made Sim-

ple, Phys. Rev. Lett. (1996) 77, 3865-3868.

[29] P. Gori-Giorgi and A. Savin, Simple model for the spherically- and system-averaged pair

density: Results for two-electron atoms, Phys. Rev. A (2005) 71, 032513 1-9.

[30] P. Gori-Giorgi and A. Savin, System-adapted correlation energy density functionals from

eﬀective pair interactions, Phil. Mag. (2006) 86, 2643-2659.

[31] P. Gori-Giorgi and J.P. Perdew, Short-range correlation in the uniform electron gas: Ex-

tended Overhauser model, Phys. Rev. B (2001) 64, 155102 1-8.

[32] B. Davoudi, M. Polini, R. Asgari, and M. P. Tosi, Self-consistent Overhauser model for the
pair distribution function of an electron gas in dimensionalities D = 3 and D = 2, Phys.
Rev. B (2002) 66, 075110 1-8.

[33] T. Leininger, H. Stoll, H.-J. Werner, and A. Savin, Combining long-range conﬁguration in-
teraction with short-range density functionals, Chem. Phys. Lett. (1997) 275, 151-160.
[34] R. Pollet, A. Savin, T. Leininger, and H. Stoll, Combining multideterminantal wave functions
with density functionals to handle near-degeneracy in atoms and molecules, J. Chem. Phys.
(2002) 116, 1250-1258.

[35] J. G. Angyan, I. C. Gerber, A. Savin, and J. Toulouse, van der Waals forces in density
functional theory: perturbational long-range electron interaction corrections, Phys. Rev. A
(2005) 72, 012510 1-9.

[36] J. Toulouse, Extension multid´eterminantale de la m´ethode de Kohn-Sham en th´eorie de la
fonctionnelle de la densit´e par d´ecomposition de l’interaction ´electronique en contributions
de longue port´ee et de courte port´ee, PhD thesis, Universit´e Pierre et Marie Curie (Paris,
France). Full text (in French) available at http://www.lct.jussieu.fr/toulouse/.

Laboratoire de Chimie Th´eorique, CNRS, Universit´e Pierre et Marie Curie, 4 Place

Jussieu, F-75252 Paris, France

E-mail address: gori@lct.jussieu.fr

Cornell Theory Center, Frank H.T. Rhodes Hall, Cornell University, Ithaca, New

York, 14853-3801, USA.

E-mail address: toulouse@cornell.edu

Laboratoire de Chimie Th´eorique, CNRS, Universit´e Pierre et Marie Curie, 4 Place

Jussieu, F-75252 Paris, France

E-mail address: savin@lct.jussieu.fr"
"New Cyclic Voltammetry Method for Examining Phase Transitions: Simulated
  Results","  We propose a new experimental technique for cyclic voltammetry, based on the
first-order reversal curve (FORC) method for analysis of systems undergoing
hysteresis. The advantages of this electrochemical FORC (EC-FORC) technique are
demonstrated by applying it to dynamical models of electrochemical adsorption.
The method can not only differentiate between discontinuous and continuous
phase transitions, but can also quite accurately recover equilibrium behavior
from dynamic analysis of systems with a continuous phase transition.
Experimental data for EC-FORC analysis could easily be obtained by simple
reprogramming of a potentiostat designed for conventional cyclic-voltammetry
experiments.
",http://arxiv.org/pdf/cond-mat/0605601v3,3,"6
0
0
2

v
o
N
6
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

3
v
1
0
6
5
0
6
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

New Cyclic Voltammetry Method for
Examining Phase Transitions: Simulated
Results

I. Abou Hamad1,2,3, D.T. Robb3,∗, P.A. Rikvold2,3,4,†
1HPC2, Center for Computational Sciences, Mississippi State University, Mississippi, MS 39762-5167, USA

2Center for Materials Research and Technology and Department of Physics, Florida State University, Tallahassee, FL 32306-4350, USA

3School of Computational Science, Florida State University, Tallahassee, FL 32306-4120, USA

4National High Magnetic Field Laboratory, Tallahassee, FL 32310

November 2, 2018

Abstract

We propose a new experimental technique for cyclic voltammetry,
based on the ﬁrst-order reversal curve (FORC) method for analysis of
systems undergoing hysteresis. The advantages of this electrochemi-
cal FORC (EC-FORC) technique are demonstrated by applying it to
dynamical models of electrochemical adsorption. The method can not
only diﬀerentiate between discontinuous and continuous phase tran-
sitions, but can also quite accurately recover equilibrium behavior
from dynamic analysis of systems with a continuous phase transition.
Experimental data for EC-FORC analysis could easily be obtained
by simple reprogramming of a potentiostat designed for conventional
cyclic-voltammetry experiments.

Keywords: Cyclic-voltammetry experiments; First-order reversal curve;
Hysteresis; Continuous phase transition; Discontinuous phase transition; Lattice-
gas model; Kinetic Monte Carlo simulation.

∗Present address: Department of Physics, Box 5721, Clarkson University, Potsdam,

NY 13699, USA

†Corresponding author at: Department of Physics, Florida State University, Tallahas-

see, FL 32306-4350, USA E-mail address: rikvold@scs.fsu.edu

1

 
 
 
 
 
 
1

Introduction

Recent technological developments in electrochemical deposition have made
It is therefore
possible experimental studies of atomic-scale dynamics [1].
now both timely and important to develop new methods for computational
analysis of experimental adsorption dynamics. In this paper we apply one
such analysis technique, the ﬁrst-order reversal curve (FORC) method, to
analyze model electrosorption systems with continuous and discontinuous
phase transitions. We propose that this electrochemical FORC (EC-FORC)
method can be a useful new experimental tool in surface electrochemistry.

The EC-FORC method was originally conceived [2] in connection with
magnetic hysteresis. It has since been applied to a variety of magnetic sys-
tems, ranging from magnetic recording media and nanostructures to geo-
magnetic compounds, undergoing rate-independent (i.e., very slow) magne-
tization reversal [3]. Recently, there have also been several FORC studies
of rate-dependent reversal [4, 5, 6]. Here we introduce and apply the FORC
method in an electrochemical context.

The FORC analysis is applied to rate-dependent adsorption in two-dimensional

lattice-gas models of electrochemical deposition. We study the dynamics of
two speciﬁc models, using kinetic Monte Carlo (KMC) simulations. First,
we consider a lattice-gas model with attractive nearest-neighbor interactions
(a simple model of underpotential deposition, UPD), being driven across
its discontinuous phase transition by a time-varying electrochemical poten-
tial. Second, we study a lattice-gas model with repulsive lateral interactions
and nearest-neighbor exclusion (similar to the model of halide adsorption on
Ag(100), described in Refs. [7, 8, 9, 10]), being similarly driven through its
continuous phase transition. Some preliminary results of this work have been
submitted for publication elsewhere [11].

The rest of this paper is organized as follows. In Sec. 2 the FORC method
is explained. The lattice-gas model used both for systems with continuous
and discontinuous transitions is introduced in Sec. 3. In Sec. 4 the dynamics
of systems with a discontinuous phase transition are studied. The dynamics
of systems with a continuous phase transition are studied in Sec. 5. Finally, a
comparison between the two kinds of phase transitions is presented together
with our conclusions in Sec. 6.

2

θ(µ

r,µ
i)

(a)

i

i(µ

r,µ
i)

(b)

µ
r

µ
i

µ

µ
r

µ
i

µ

Figure 1: (a) Schematic diagram of two ﬁrst-order reversal curves (FORCs)
θ(¯µr, ¯µi), separated by the reversal-ﬁeld step size ∆¯µr (solid lines). The
(b) The corresponding
dotted lines represent the major hysteresis loop.
voltammetric currents, i(¯µr, ¯µi) ∝ ∂θ/∂ ¯µi.

2 The EC-FORC Method

For an electrochemical adsorption system, the FORC method consists of
saturating the adsorbate coverage θ in a strong positive electrochemical po-
tential ¯µ (proportional to the electrode potential, with the same sign for
anions and opposite sign for cations) and, in each case starting from satu-
ration, decreasing ¯µ at a constant scan rate Ω to a series of progressively
more negative “reversal potentials” ¯µr. (See Fig. 1). Subsequently, the po-
tential is increased back to the saturating value at the same rate Ω [3]. The
method is thus a simple generalization of the standard cyclic voltammetry
(CV) method, in which the negative return potential is decreased for each
cycle. This produces a family of FORCs, θ(¯µr, ¯µi), where θ is the adsorbate
coverage and ¯µi is the instantaneous potential during the increase back to-
ward saturation. Alternatively, as it is usually done in CV experiments, one
can record the family of voltammetric currents,

i(¯µr, ¯µi) = −γe

d¯µi
dt

∂θ
∂ ¯µi

,

(1)

where γ is the electrosorption valency [12, 13, 14] and e is the elementary
charge. Although we shall not discuss this further here, it is of course also
possible to ﬁx the negative limiting potential and change the positive return
potential from cycle to cycle.

3

Figure 2: A subset of the family of FORCs. The circled points are an example
of the ‘slanted’ 5 × 11 array of data points used to calculate ρ from θ(¯µr, ¯µi).
The ﬁlled squares represent a ‘square’ 5 × 5 array and the hollow squares
represent a ‘square’ 5 × 11 array. See discussion in the text.

The family of FORCs consists of N FORCs measured at values of ¯µr that
are evenly spaced by ∆¯µr. Each of these FORCs has data points measured
at the (in general diﬀerent) constant spacing ∆¯µi [3]. It is further useful to
calculate the FORC distribution,

ρ = −

1
2

∂2θ
∂ ¯µr ∂ ¯µi

=

1
2γe(d¯µi/dt)

∂i(¯µr, ¯µi)
∂ ¯µr

,

(2)

which measures the sensitivity of the dynamics to the progress of reversal
along the outermost hysteresis loop or major loop.1

The details of the calculation of ρ depend on whether the measured
quantity is the coverage θ(¯µr, ¯µi), which is the most convenient in simu-
lation studies, or the voltammetric current i(¯µr, ¯µi), which would be most
In the latter case, the calculation involves sim-
usual in CV experiments.
ple one-dimensional numerical diﬀerentiation with respect to ¯µr, e.g. ρ =
[2γe(d¯µi/dt)]−1[i(¯µr + ∆¯µr, ¯µi) − i(¯µr, ¯µi)]/∆¯µr. Geometrically it is propor-
tional to the vertical distance between the current traces. (See Fig. 1(b).)

1Note that to normalize the FORC distribution, the term 1

|¯µi→¯µ+
r
must be added to Eq. (2) [15]. Here we consider the distribution only away from the line
¯µi = ¯µr. The additional term could be found from the major loop.

2 δ(¯µi − ¯µr) ∂θ(¯µr,¯µi)

∂ ¯µi

4

In the case that θ(¯µr, ¯µi) is the measured quantity, as in the simulations
presented here, the calculation of ρ is somewhat more complicated. An array
of data points θ(¯µr, ¯µi) from consecutive FORCs is used to calculate ρ as
shown in Fig. 2. A polynomial surface is ﬁt to this array of data points to
provide a functional form of θ(¯µr, ¯µi), the mixed partial derivative of which is
proportional to ρ as given by Eq. (2). Away from the major hysteresis loop,
the array of data points used to calculate ρ can be taken to be ‘square’, i.e., to
start and end at the same value of ¯µi for each of the FORCs involved (squares
in Fig. 2). Close to the major loop, this is not geometrically possible. As
shown in Fig. 2, we therefore used a ‘slanted’ array of data points to calculate
ρ. To obtain the values of ρ at grid points other than the center point of
the grid (¯µi, closer to ¯µr) we used a third-order polynomial to ﬁt θ(¯µr, ¯µi).
This allows the evaluation of the mixed partial derivative ρ at all points
of the grid, while a second-order polynomial ﬁt only allows the evaluation
of ρ at the center point. For consistency and convenience, a third-order
polynomial was used with the three kinds of grids described above and at
all points close to and away from the major loop. The three kinds of grids
were compared for points away from the major hysteresis loop. While the
larger 5 ×11 grids (‘square’, and ‘slanted’) produced very similar and smooth
FORC diagrams, the FORC diagram produced by the 5 × 5 grid was more
noisy. Consequently, in the results shown in this paper, the 5 × 11 ‘slanted’
grid was used to calculate ρ from θ(¯µr, ¯µi) for all values of the arguments.

Another approach to calculating ρ near the major loop would be to use an
‘extended FORC diagram’ [15], for which a square grid of points can be used
even near the major loop, but where the delta function normalization term
(See Footnote 1) will automatically be included by the polynomial ﬁtting
procedure described above. The methods for calculating ρ that are described
here, are quite straightforward, but also rather slow. A faster method is
based on the Savitzky-Golay smoothing algorithm [16, 17]. It is described in
Ref. [18].

The FORC distribution is usually displayed as a contour plot called a
‘FORC diagram.’ A positive value of ρ indicates that the corresponding
FORCs are converging with increasing ¯µi, while a negative value indicates
divergence. The physical signiﬁcance of the sign of ρ will become clearer
when we apply the EC-FORC method to discontinuous and continuous phase
transitions in Secs. 4 and 5, respectively.

5

3 Model

KMC simulations of lattice-gas models, where a Monte Carlo step (MCS)
corresponds to one attempt to cross a free-energy barrier, have been used
to simulate the kinetics of electrochemical adsorption in systems with both
discontinuous [9, 10, 19, 20] and continuous [7, 21] phase transitions. The
energy associated with a lattice-gas conﬁguration is described by the grand-
canonical eﬀective Hamiltonian for an L × L square system of adsorption
sites,

L2

H = −

φijcicj − ¯µ

ci ,

Xi=1

Xi<j

(3)

P

i<j is a sum over all pairs of sites, φij are the lateral interaction
where
energies between particles on the ith and jth sites measured in meV/pair,
and ¯µ is the electrochemical potential measured in meV/atom. The local
occupation variables ci can take the values 1 or 0, depending on whether site
i is occupied by an ion (1) or solvated (0). The sign convention is chosen
such that ¯µ > 0 favors adsorption. Negative values of φij denote repulsion,
while positive values of φij denote attraction between adsorbate particles on
the surface. In addition to adsorption/desorption steps, we include diﬀusion
steps that have a free-energy barrier comparable to the adsorption/desorption
free-energy barrier [7].

The dynamics of the model are studied by a KMC simulation with the
computational time unit of one Monte Carlo Step per Site (1 MCSS = L2
MCS). For a discussion of the relation between this simulated time unit and
real, physical time, see Ref. [7]. In each MCS of the simulation, an adsorption
site is chosen at random and a move (adsorption, desorption, or diﬀusion) is
attempted. The transition rates from the present conﬁguration to the set of
new possible conﬁgurations are calculated. A weighted list of the probabilities
for accepting each of these moves during one MCS is constructed using Eq. (5)
below, and used to calculate the probabilities R(F|I) of the individual moves
between the initial state I and ﬁnal state F. The probability for the system to
remain in the initial conﬁguration at the end of the time step is consequently
R(I|I) = 1−ΣF6=IR(F|I) [7, 8].

Using a thermally activated, stochastic barrier-hopping picture, the en-
ergy of the transition state for a microscopic change from an initial state I
to a ﬁnal state F is approximated by the symmetric Butler-Volmer formula

6

[22, 23, 24]

UTλ =

+ ∆λ .

UI + UF
2
Here UI and UF are the energies of the initial and ﬁnal states as given by
Eq. (3), Tλ is the transition state for process λ, and ∆λ is a “bare” bar-
rier associated with process λ. This process can here be either nearest-
neighbor diﬀusion (∆nn), next-nearest-neighbor diﬀusion (∆nnn), or adsorp-
tion/desorption (∆a/d). The probability per unit time for a particle to make
a transition from state I to state F is approximated by the one-step Arrhenius
rate [22, 23, 24]

(4)

R(F|I) = ν exp

−

(cid:18)

UTλ − UI
kBT

(cid:19)

= ν exp

−

(cid:18)

∆λ
kBT (cid:19)

exp

−

(cid:18)

UF − UI

2kBT (cid:19)

,

(5)

where kB is Boltzmann’s constant and T is the absolute temperature. Here, ν
is the attempt frequency, which sets the overall timescale for the simulation.
We set ν equal to 1 MCSS−1, so that the transition probabilities in a single
time step (MCS) are given by R(F|I) = R(F|I)L−2 MCSS. The electrochem-
ical potential ¯µ is changed each MCSS, preventing the system from reaching
equilibrium at the instantaneous value of ¯µ.

Independent of the diﬀusional degree of freedom, attractive interactions
(φij > 0) produce a discontinuous phase transition between a low-coverage
phase at low ¯µ, and a high-coverage phase at high ¯µ. In contrast, repulsive
interactions (φij < 0) produce a continuous phase transition between a low-
coverage disordered phase for low ¯µ, and a high-coverage, ordered phase for
high ¯µ. Examples of systems with a discontinuous phase transition include
underpotential deposition [19, 20, 25], while the adsorption of halides on
Ag(100) [7, 8, 21, 26, 27] are examples of systems with a continuous phase
transition.

4 Discontinuous Phase Transition

A two-dimensional lattice gas with attractive adsorbate-adsorbate lateral in-
teractions that cause a discontinuous phase transition is a simple model of
electrochemical underpotential deposition [19, 20, 25, 28]. Using a lattice-
gas model with attractive interactions on an L × L lattice with L = 128,
a family of FORCs were simulated, averaging over ten realizations for each
FORC at room temperature. The lateral interaction energy (restricted to

7

nearest-neighbor) was taken to be φij = φnn = 55 meV, where the positive
value indicates nearest-neighbor attraction. For this value of φnn, room tem-
perature corresponds to T = 0.8Tc, where Tc is the critical temperature.
The barriers for adsorption/desorption and diﬀusion (nearest-neighbor only)
were ∆a/d = ∆nn = 150 meV, corresponding to relatively slow diﬀusion [20].
Simulation runs with faster diﬀusion (∆nn = 125 meV) and the same adsorp-
tion/desorption barrier were little diﬀerent from the results shown in Fig. 3.
The reversal electrochemical potentials ¯µr associated with the FORCs were
separated by ∆¯µr = 1 meV increments in the interval [−200 meV, 0 meV],
and the ﬁeld-sweep rate was constant at Ω = |∆¯µi/∆t| = 0.03 meV/MCSS.
The FORCs are shown in Fig. 3(a), with a vertical line indicating the position
of the coexistence value of the electrochemical potential, ¯µ0 = −110 meV,
and a ﬁlled circle showing the position of the minimum of each FORC. The
corresponding voltammetric currents are shown in Fig. 3(b).

In a simple Avrami’s-law analysis, the FORC minima all lie at ¯µi = ¯µ0
[6]. However, in the simulations the minima are displaced. For θ > 0.5, the
minima occur at ¯µi < ¯µ0, precisely at the points where the tendency to phase-
order, which drives local regions of the system toward the nearby metastable
state (θ ≈ 1), is momentarily balanced by the electrochemical potential,
which drives the system toward the distant stable state (θ ≈ 0). For θ < 0.5,
the stable and metastable states are θ ≈ 1 and θ ≈ 0, respectively, and the
same balancing eﬀect explains the FORC minima occurring at ¯µi > ¯µ0. The
net eﬀect is a ‘back-bending’ of the curve of minima, as seen in Fig. 3(a).

In Fig 3(c), the FORC diagram is plotted against the variables ¯µb =
(¯µr + ¯µi)/2 and ¯µc = (¯µr − ¯µi)/2. These variables are commonly used in
the literature for plotting FORC diagrams [3], as ¯µb denotes the midpoint
between ¯µr and ¯µi, and ¯µc is proportional to the distance between these two
values of ¯µ.2

The deﬁnition in Eq. (2) implies that the FORC distribution ρ should
be negative in the vicinity of the back-bending. This can be readily seen in
Fig 3(c). The negative values of ρ reﬂect a local divergence of the FORCs

2In magnetic applications, the variables Hb and Hc (corresponding to ¯µb and ¯µc, re-
spectively) have a clear physical meaning as the bias and coercive ﬁelds, respectively, in a
bistable magnetic system. While this physical meaning does not extend clearly to electro-
chemical systems, this choice of variables does produce FORC diagrams with less unused
space than the variables (¯µr, ¯µi), for which the region ¯µi < ¯µr is forbidden, and so we
have used it here. However, the analysis described in the following sections could also be
made with FORC diagrams plotted using the variables (¯µr, ¯µi).

8

(Color online.) (a) FORCs for a discontinuous phase transition,
Figure 3:
obtained with scan rate Ω = 0.03 meV/MCSS and interactions and barrier
heights as given in the text. The vertical line shows the coexistence value
of the electrochemical potential, ¯µ = ¯µ0. The minimum of each FORC is
also shown (ﬁlled circles). The thick curve corresponds to the FORC whose
minimum lies nearest the coexistence value, ¯µi = ¯µ0. (b) The corresponding
voltammetric currents, calculated by numerical diﬀerentiation of the FORCs.
See Eq. 1. (c) FORC diagram generated from the family of FORCs in (a).
The positions of the FORC minima are shown as ﬁlled circles. The thick,
straight line corresponds to the FORC marked as a thick curve in (a).

9

Figure 4: The dependence of the FORC minima on the sweep rate Ω. The
ﬁgure shows FORC minima for two families of FORCs with diﬀerent sweep
rates (Ω = 0.03 and 0.09 meV/MCSS, respectively). The curves are guides to
the eye, obtained by smoothing the data using a ﬁrst-order Savitzky-Golay
ﬁlter with a window of 5 points [16, 17].

10

away from each other as ¯µi (and time) increases. This can be considered
a dynamical instability, caused by the competition between the tendency
to phase-order and the eﬀect of the electrochemical potential. When the
potential sweep is stopped suddenly at a potential in this unstable region,
the subsequent time evolution of θ is non-monotonic: it ﬁrst approaches its
metastable value, but then reverses and relaxes reliably to its equilibrium
value at that potential. The only exception is the point (¯µ = ¯µ0, θ = 0.5)
It is also interesting
along the FORC indicated by bold lines in Fig. 3.
to note that the curve connecting the minima of the FORCs resembles the
van der Waals loop in the mean-ﬁeld isotherm of a ﬂuid system below its
critical temperature [29], but with an asymmetrical shape about the point
(¯µ = ¯µ0, θ = 0.5) and with a sweep-rate dependent shape as shown in Fig. 4.

5 Continuous Phase Transition

Using the same Hamiltonian, but with long-range repulsive interactions and
nearest-neighbor exclusion as appropriate for modeling halide electrosorption
on Ag(100) [7, 8, 9, 10], KMC simulations were used to produce the family
of FORCs for a continuous phase transition. The reversal potentials ¯µr were
separated by ∆¯µr = 10 meV increments in the interval [−200 meV, 400 meV].
As in Refs. [7, 9, 10], the repulsive 1/r3 interactions, with nearest-neighbor
exclusion and φnnn = −21 meV, are calculated with exact contributions for
rij ≤ 3, and using a mean-ﬁeld approximation for rij > 3. The barriers
for adsorption/desorption and nearest- and next-nearest-neighbor diﬀusion
were approximated on the basis of DFT calculations [21] as ∆a/d = 300 meV,
∆nn = 100 meV, and ∆nnn = 200 meV, respectively [7]. Larger values of
the diﬀusion barrier were also used to study the eﬀect of diﬀusion on the
dynamics. A continuous phase transition occurs between a disordered state
at low coverage and an ordered state at high coverage [26, 27]. The FORCs,
voltammetric currents, and FORC diagram are shown in Fig. 5.

Also indicated in Fig. 5(a) are the FORC minima and the equilibrium
isotherm, as calculated in independent equilibrium Monte Carlo simulations.
Note that the FORC minima in Fig. 5(a) lie directly on the equilibrium
isotherm. This is because such a system has one stable state for any given
value of the potential, as deﬁned by the continuous, single-valued equilibrium
isotherm. The corresponding voltammetric currents are shown in Fig. 5(b).
The uniformly positive value of the FORC diagram in Fig. 5(c) reﬂects the

11

(Color online.)

(a) FORCs for a continuous phase transition
Figure 5:
simulated at a slow scan rate, Ω = 0.0003 meV/MCSS. The thin black curve
near the middle of the major loop is the equilibrium isotherm. The inset is
a magniﬁcation of the critical region. The minimum of each FORC is also
shown (ﬁlled circles). The thick, black curve shows the ﬁrst FORC which dips
below the critical coverage, θc ≈ 0.36. (b) The corresponding voltammetric
currents, calculated by numerical diﬀerentiation of the FORCs. See Eq. 1.
(c) FORC diagram generated from the FORCs in (a). The positions of the
FORC minima are shown as ﬁlled circles. The thick, straight line corresponds
to the FORC marked as a thick curve in (a).

12

convergence of the family of FORCs with increasing ¯µi. This convergence
results from relaxation toward the equilibrium isotherm, at a rate which in-
creases with the distance from equilibrium.
It is interesting to note that,
while it is diﬃcult to see at this slow scan rate, the rate of approach to
equilibrium decreases greatly along the ﬁrst FORC that dips below the crit-
ical coverage θc ≈ 0.36 (shown in bold in Fig. 5(a)). The FORCs that lie
completely in the range θ > θc never enter into the disordered phase, and
thus their approach to equilibrium is not hindered by jamming. This is a
phenomenon that occurs when further adsorption in a disordered adlayer is
hindered by the nearest-neighbor exclusion. As a result, extra diﬀusion steps
are needed to make room for the new adsorbates, and the system follows
diﬀerent dynamics than a system with an ordered adlayer [30]. The FORCs
that dip below θc enter into the disordered phase, and thus their approach to
equilibrium is delayed by jamming. This is reﬂected in the FORC diagram
by the Florida-shaped “peninsula” centered around this FORC in Fig. 5(c).
The eﬀect of jamming is more pronounced at higher scan rates, or with
a higher diﬀusion barrier, where the rate of adsorption is much faster than
the rate of diﬀusion. The family of FORCs and FORC diagram at a higher
scan rate, Ω = 0.01 meV/MCSS, are shown in Fig. 6, and with a larger
diﬀusion barrier in Fig. 7. In Fig. 6, two distinct groups of FORCs undergoing
jammed and unjammed dynamics can be clearly seen. This is reﬂected in the
FORC diagram as a splitting of the “peninsula” into two “islands” of locally
maximal values of ρ. A similar eﬀect is seen in Fig. 7, since also there the
rate of adsorption is much faster than the rate of diﬀusion (larger diﬀusion
barrier). In addition, Fig. 7(a) shows a slight diﬀerence between the FORC
minima and the equilibrium curve around the critical coverage. Notice also
in Fig. 6(a) that even at a much higher scan rate than in Fig. 5 (nearly two
orders of magnitude), the FORC minima still follow the equilibrium curve
very accurately. Thus, the EC-FORC method should be useful to obtain the
equilibrium adsorption isotherm quite accurately in experimental systems
with slow equilibration rates.

6 Comparison and conclusions

Two observations can be made by comparing the FORCs, voltammetric cur-
rents, and FORC diagrams for systems with discontinuous and continuous
phase transitions. First, the FORC minima in systems with a continuous

13

(Color online.)

(a) FORCs for a continuous phase transition
Figure 6:
simulated at a high scan rate, Ω = 0.01 meV/MCSS, and the other model
parameters as given in the text. The diﬀerent curves and symbols have the
same meanings as in Fig. 5(a). The inset showing the region of large ¯µ and
θ emphasizes the jamming behavior. (b) FORC diagram generated from the
FORCs in (a). The diﬀerent lines and symbols have the same meanings as
in Fig. 5(b).

14

(Color online.)

(a) FORCs for a continuous phase transition
Figure 7:
simulated with Ω = 0.0003 meV/MCSS and a large diﬀusion barrier, ∆nn =
300 meV. The other model parameters are as given in the text. The diﬀerent
curves and symbols have the same meanings as in Figs. 5(a) and 6(a). The
inset showing the region of large ¯µ and θ emphasizes the jamming behavior.
(b) FORC diagram generated from the FORCs shown in (a). The diﬀerent
lines and symbols have the same meanings as in Figs. 5(b) and 6(b).

15

phase transition correspond closely to the equilibrium behavior, while they
do not for systems with a discontinuous phase transition. Thus, FORCs
can be used to recover the equilibrium behavior for systems with continu-
ous phase transitions that need a long time to equilibrate. This should be
useful in experiments. Second, due to the instability that exists in systems
with a discontinuous phase transition, the minima of the family of FORCs in
this case form a back-bending “van der Waals loop,” and the corresponding
FORC diagram contains negative regions that do not exist for systems with a
continuous phase transition. Since experimental implementation of the EC-
FORC method should only require simple reprogramming of a potentiostat
designed to carry out a standard CV experiment, we believe the method can
be of signiﬁcant use in obtaining additional dynamic as well as equilibrium
information from such experiments for systems that exhibit electrochemical
adsorption with related phase transitions.

Acknowledgments

We gratefully acknowledge useful comments from E. Borguet and two anony-
mous referees.

This research was supported by U.S. NSF Grant No. DMR-0240078, and
by Florida State University through the School of Computational Science,
the Center for Materials Research and Technology, and the National High
Magnetic Field Laboratory.

References

[1] T. Tansel, O.M. Magnussen, Phys. Rev. Lett. 96 (2006) 026101.

[2] I.D. Mayergoyz, IEEE Trans. Magn. MAG 22 (1986) 603.

[3] C.R. Pike, A.P. Roberts, K.L. Verosub, J. Appl. Phys. 85 (1999) 6660.

[4] C. Enachescu, R. Tanasa, A. Stancu, F. Varret, J. Linares, E. Codjovi,

Phys. Rev. B 72 (2005) 054413.

[5] M. Fecioru-Morariu, D. Ricinschi, P. Postolache, C.E. Ciomaga,

A. Stancu, J. Optoelectron. Adv. Mater. 6 (2004) 1059.

16

[6] D.T. Robb, M.A. Novotny, P.A. Rikvold, J. Appl. Phys. 97 (2005)

10E510.

[7] I. Abou Hamad, P.A. Rikvold, G. Brown, Surf. Sci. 572 (2004) L355.

[8] S.J. Mitchell, G. Brown, P.A. Rikvold, Surf. Sci. 471 (2001) 125.

[9] I. Abou Hamad, Th. Wandlowski, G. Brown, P.A. Rikvold, J. Elec-

troanal. Chem. 554-555 (2003) 211.

[10] I. Abou Hamad, S.J. Mitchell, Th. Wandlowski, P.A. Rikvold, Elec-

trochim. Acta 50 (2005) 5518.

[11] I. Abou Hamad, D.T. Robb, P.A. Rikvold, in: D.P. Landau, S.P. Lewis,
H.-B. Sch¨uttler (Eds.), Computer Simulation Studies in Condensed-
Matter Physics XIX, Springer-Verlag, Berlin, in press.

[12] K.J. Vetter, J.W. Schultze, Ber. Bunsenges. Phys. Chem. 72 (1972) 920.

[13] K.J. Vetter, J.W. Schultze, Ber. Bunsenges. Phys. Chem. 72 (1972) 927.

[14] P.A. Rikvold, Th. Wandlowski, I. Abou Hamad, S.J. Mitchell, G. Brown,

Electrochim. Acta (2006), doi:10.1016/j.electacta.2006.07.059

[15] C.R. Pike, Phys. Rev. B 68 (2003) 104424.

[16] A. Savitzky, M.J.E. Golay, Anal. Chem. 36 (1964) 1627.

[17] W.H. Press, A. Teukolsky, W.T. Vetterling, B.P. Flannery, Numerical
Recipes in C: The Art of Scientiﬁc Computing, Cambridge University
Press, Cambridge, 1997, Ch. 14.

[18] D. Heslop, A.R. Muxworthy, J. Magn. Magn. Mater. 288 (2005) 155.

[19] S. Frank, D.E. Roberts, P.A. Rikvold, J. Chem. Phys. 122 (2005) 064705.

[20] S. Frank, P.A. Rikvold, Surf. Sci. 600 (2006) 2470.

[21] S.J. Mitchell, S. Wang, P.A. Rikvold, Faraday Disc. 121 (2002) 53.

[22] G. Brown, P.A. Rikvold, S.J. Mitchell, M.A. Novotny, in: A. Wieckowski
(Ed.), Interfacial Electrochemistry: Theory, Experiment, and Applica-
tion, Marcel Dekker, New York, 1999, p. 47.

17

[23] H.C. Kang, W.H. Weinberg, J. Chem. Phys. 90 (1989) 2824.

[24] G.M. Buend´ıa, P.A. Rikvold, K. Park, M.A. Novotny, J. Chem. Phys.

121 (2004) 4193.

[25] G. Brown, P.A. Rikvold, M.A. Novotny, A. Wieckowski, J. Electrochem.

Soc. 146 (1999) 1035.

[26] B.M. Ocko, J.X. Wang, Th. Wandlowski, Phys. Rev. Lett. 79 (1997)

1511.

[27] Th. Wandlowski, J. X. Wang, and B. M. Ocko, J. Electroanal. Chem.

500 (2001) 418.

[28] R.A. Ramos, P.A. Rikvold, M.A. Novotny, Phys. Rev. B 59 (1999) 9053.

[29] G.W. Castellan, Physical Chemistry, Addison-Wesley, Reading, MA,

1964. Ch. 3.

[30] J.-S. Wand, P. Nielaba, V. Privman, Mod. Phys. Lett. B 7 (1993) 189.

18"
"Kohn-Sham calculations combined with an average pair-density functional
  theory","  A recently developed formalism in which Kohn-Sham calculations are combined
with an ``average pair density functional theory'' is reviewed, and some new
properties of the effective electron-electron interaction entering in this
formalism are derived. A preliminary construction of a fully self-consitent
scheme is also presented in this framework.
",http://arxiv.org/pdf/cond-mat/0611324v1,3,"Kohn-Sham calculations combined with an average pair-density

functional theory

Paola Gori-Giorgi∗ and Andreas Savin

Laboratoire de Chimie Th´eorique, CNRS UMR7616,

Universit´e Pierre et Marie Curie, 4 Place Jussieu, F-75252 Paris, France

∗E-mail: paola.gori-giorgi@lct.jussieu.fr

www.lct.jussieu.fr/pagesequipe/DFT/gori

Abstract

A recently developed formalism in which Kohn-Sham calculations are combined with an “average

pair density functional theory” is reviewed, and some new properties of the eﬀective electron-

electron interaction entering in this formalism are derived. A preliminary construction of a fully

self-consitent scheme is also presented in this framework.

6
0
0
2

v
o
N
3
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
4
2
3
1
1
6
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

1

 
 
 
 
 
 
I.

INTRODUCTION

Kohn-Sham (KS) Density Functional Theory1,2,3 (DFT) is nowadays one of the most pop-

ular methods for electronic structure calculations both in chemistry and solid-state physics,

thanks to its combination of low computational cost and reasonable performances. The ac-

curacy of a KS-DFT result is limited by the approximate nature of the exchange-correlation

energy density functional Exc[n]. Typical cases in which present-day DFT fails are strongly

correlated systems, the description of van der Waals forces, the handling of near degeneracy.

Much eﬀort is put nowadays in trying to improve the DFT performances via the construc-

tion of better approximations for the KS Exc[n] (for recent reviews, see, e.g., Refs. 2,3,4),

or via alternative routes, like, e.g., the use of non-KS options.5 A popular trend in the de-

velopment of new KS Exc[n] is the use of the exact exchange functional Ex[n] (in terms of

the KS orbitals), and thus the search for an approximate, compatible, correlation functional

Ec[n].

In this work we review the basis of a theoretical framework6,7 in which KS-DFT is com-

bined with an “average pair density functional theory” (APDFT) that provides an explicit

construction for Ec[n], transfering the work of ﬁnding an approximate functional to the

search of an eﬀective particle-particle interaction. A self-consitent scheme for this approach

is presented, and some new properties of the eﬀective interaction that enters in this combined

formalism are derived. Very preliminary applications are discussed.

II. DEFINITIONS

Our target problem is ﬁnding the ground-state energy of the standard N-electron hamilto-
nian in the Born-Oppenheimer approximation (in Hartree atomic units, ~ = m = a0 = e = 1,

2

used throughout),

H = T + Vee + Vne,

T = −

Vee =

N

∇2
i ,

1
2

Xi=1
N

1
|ri − rj|

,

1
2

Xi
=j
N

Vne =

vne(ri),

Xi=1

(1)

(2)

(3)

(4)

where vne is the external potential due to nuclei. Given Ψ, the exact ground-state wave-

function of H, we consider two reduced quantities that fully determine, respectively, the

expectation values hΨ|Vne|Ψi and hΨ|Vee|Ψi, i.e., the electronic density,

n(r) = N

Xσ1...σN

Z

|Ψ(rσ1, r2σ2, ..., rN σN )|2dr2...drN ,

(5)

and the spherically and system-averaged pair density f (r12) (APD), which is obtained by

ﬁrst considering the pair density P2(r1, r2),

P2(r1, r2) = N(N − 1)

Xσ1...σN

Z

|Ψ(r1σ1, r2σ2, r3σ3, ..., rN σN )|2dr3...drN ,

(6)

and then by integrating it over all variables except r12 = |r1 − r2|,

f (r12) =

1
2 Z

P2(r1, r2)

dΩr12
4π

dR,

(7)

where R = 1

2(r1 + r2), r12 = r2 − r1. The function f (r12) is also known in chemistry as
intracule density8,9,10,11,12,13,14, and, in the special case of a an electron liquid of uniform

density n, is related to the radial pair-distribution function g(r12) by g(r) = 2f (r)/(nN).

We thus have

hΨ|Vee|Ψi =

f (r12)
r12

Z

dr12 =

∞

Z

0

hΨ|Vne|Ψi =

n(r)vne(r)dr

Z
f (r12)
r12

4πr2

12dr12.

(8)

(9)

In the following text we will also deal with modiﬁed systems in which the external po-

tential and/or the electron-electron interaction is changed. Thus, the notation Vne and Vee

will be used to characterize the physical system, while the modiﬁed systems will be deﬁned

by V =

N

i=1 v(ri) and W = 1

2

depends only on |ri − rj|.

P

N
=j w(|ri − rj|), where the pairwise interaction w always
i
P

3

6
6
III. THE EXCHANGE-CORRELATION FUNCTIONAL OF KS-DFT

In standard DFT one deﬁnes a universal functional of the one-electron density n(r) as

resulting from a constrained search over all the antisymmetric wavefunctions Ψ that yield

n15

or, more completely, as a Legendre transform16

˜F [n; Vee] = min
n
→

Ψ

hΨ|T + Vee|Ψi,

F [n; Vee] = sup

v (cid:26)

min
Ψ

hΨ|T + Vee + V |Ψi −

n(r)v(r)dr

.

(cid:27)

Z

(10)

(11)

In both Eqs. (10) and (11), the dependence on the electron-electron interaction has been

explictly shown in the functional. The universality of the functional F stems exactly from

the fact that the e-e interaction is always 1/r12. The ground-state energy E0 of the system

can then be obtained by minimizing the energy with respect to n,

E0 = min

n (cid:26)

F [n; Vee] +

Z

n(r)vne(r)dr

.

(cid:27)

(12)

A possible way to derive the Kohn-Sham equations in DFT is to deﬁne a set of hamilto-

nians depending on a real parameter λ17,18,19,

H λ = T + W λ + V λ,

having all the same one-electron density, equal to the one of the physical system

nλ(r) = n(r)

∀λ.

(13)

(14)

If W λphys = Vee and W λ=0 = 0 (e.g., W λ = λVee), one can slowly switch oﬀ the electron-
electron interaction, while keeping the density ﬁxed via a suitable external potential V λ.

Obviously, the APD f (r12) changes with λ. By the Hellmann-Feynmann theorem,

∂Eλ
0
∂λ

= hΨλ|

∂W λ
∂λ

+

∂V λ
∂λ

|Ψλi =

Z

f λ(r12)

∂wλ(r12)
∂λ

dr12 +

Z

n(r)

∂vλ(r)
∂λ

dr,

(15)

so that by directly integrating Eq. (15), and by combining it with Eq. (12), one obtains

F [n; Vee] = Ts[n] +

λphys

Z
0

dλ

Z

dr12f λ(r12)

∂wλ(r12)
∂λ

,

(16)

where Ts[n] = F [n; 0] is the kinetic energy of a noninteracting system of N spin- 1

2 fermions
with density n(r). The adiabatic connection in DFT thus naturally deﬁnes the Kohn-Sham

4

non-interacting kinetic energy functional Ts[n]. The second term in the right-hand-side
of Eq. (16) is an exact expression, in terms of the APD f λ(r12), for the Hartree and the

exchange-correlation functional, EH[n] + Exc[n]. The one-body potential at λ = 0 is the
familiar Kohn-Sham potential, vλ=0(r) = vKS(r).

The traditional approach of DFT to construct approximations for Exc[n] is based on the

idea of universality. For example, the familiar local-density approximation (LDA) consists in

transfering, in each point of space, the pair density from the uniform electron gas to obtain
an approximation for f λ(r12) in Eq. (16). Our aim is to develop an alternative strategy
in which realistic APD f λ(r12) along the DFT adiabatic connection are constructed via a

formally exact theory that must be combined with the KS equations in a self-consitent way.

The formal justiﬁcation for this “average pair-density functional theory” (APDFT) is the

object of the next Sec. IV.

IV. AVERAGE PAIR DENSITY FUNCTIONAL THEORY

As shown by Eqs. (8) and (9), the APD f (r12) couples to the operator Vee in the same

way as the electronic density n(r) couples to Vne. In order to derive an “average pair density

functional theory” (APDFT) we thus simply repeat the steps of the previous Sec. III by

switching the roles of f and n, and of Vee and Vne.7

We thus deﬁne a system-dependent functional (i.e., a functional depending on the external

potential Vne, and thus on the speciﬁc system) of the APD f (r12) as

˜G[f ; Vne] = min
f
→

Ψ

hΨ|T + Vne|Ψi,

(17)

where, again the minimum is over all antisymmetric wavefunction Ψ that yield a given

f (r12). We can also deﬁne the system-dependent functional G as

G[f ; Vne] = sup

min
Ψ

hΨ|T + W + Vne|Ψi −

f (r12)w(r12)dr12(cid:27)

.

Z

w (cid:26)

The ground-state energy could then be obtained as

E0 = min
f

∈Nf (cid:26)

G[f ; Vne] +

f (r12)
r12

dr12(cid:27)

,

Z

(18)

(19)

where Nf is the space of all N-representable APD (i.e., coming from the contraction of

an N-particle antisymmetric wavefunction). The deﬁnition of the space Nf is evidently

5

related to the N-representability conditions for the pair density, for which recent interesting

progresses have been made20. In our case, however, we combine APDFT with DFT so that

the minimization of Eq. (19) is never directly carried on.

In order to ﬁnd the analog of the KS system for APDFT, we deﬁne an adiabatic connection

similar to the one of Eq. (13) in which, this time, we switch oﬀ the external potential. We

thus introduce a set of hamiltonians depending on a real parameter ξ,

H ξ = T + W ξ + V ξ,

in which the function f (r12) is kept ﬁxed, equal to the one of the physical system,

f ξ(r12) = f (r12)

∀ξ.

(20)

(21)

If V ξphys = Vne and V ξ=0 = 0 (e.g., V ξ = ξVne), we are switching continuously from the phys-
ical system, to a system of N free electrons interacting with a modiﬁed potential wξ=0(r12).

That is, f (r12) is kept ﬁxed as ξ varies by means of a suitable electron-electron interaction
W ξ while the one-electron density n(r) changes with ξ. Again, by the Hellmann-Feynmann

theorem, we ﬁnd

∂Eξ
0
∂ξ

= hΨξ|

∂W ξ
∂ξ

+

∂V ξ
∂ξ

|Ψξi =

Z

f (r12)

∂wξ(r12)
∂ξ

dr12 +

Z

nξ(r)

∂vξ(r)
∂ξ

dr,

so that

G[f ; Vne] = Tf[f ] +

ξphys

dr nξ(r)

dξ

Z

∂vξ(r)
∂ξ

,

Z

0

(22)

(23)

where Tf[f ] is the kinetic energy of a system of N free (zero external potential) interacting
spin- 1
2 fermions having the same f (r12) of the physical system. In the case of a conﬁned
system (atoms, molecules) the eﬀective interaction wξ=0(r12) must have an attractive tail:

the hamiltonian corresponding to ξ = 0 in Eq. (20) describes a cluster of fermions whose

center of mass is translationally invariant. The functional Tf[f ] is the internal kinetic energy

of this cluster.

To ﬁx the ideas, consider the simple case of two electrons, e.g. the He atom. When

ξ = 0, we have two fermions in a relative bound state (similar to the case of positronium,

but with a diﬀerent interaction). This relative bound state is such that the square of

the wavefunction for the relative coordinate r12 is equal to f (r12) of the starting physical
system. The corresponding eﬀective interaction wξ=0(r12), obtained7 by inversion from a
very accurate wavefunction,21 is shown in Fig. 1, for the case of the He atom.

6

)

2
1

r
(

w

ξ

 6

 4

 2

 0

-2

-4

-6

He

1/r12 (ξ = ξ

phys)

ξ = 0

 0

 1

 2

 3

 4

 5

r12

FIG. 1: The electron-electron interaction at the two ends of the APDFT adiabatic connection of

Eqs. (20)-(21) in the case of the He atom.

For more than two electrons, Tf[f ] is still a complicated many-body object. Moreover,
since the corresponding wξ=0(r12) can have an attractive tail (as in the case N = 2), we may

have an “exotic” true ground-state for the cluster, i.e., the cluster state with the same f (r12)

of the physical system can be an excited state. However, we have to keep in mind that our

aim is not to solve the many-electron problem by means of APDFT alone: we want to use

APDFT to produce realistic f (r12) along the DFT adiabatic connection of Eqs. (13)-(14).
To this end, we proposed6,7 an approximation for the functional Tf[f ] based on a geminal

decomposition,

Tg[f ] = min
}→

ψi
{

f Xi

ϑi hψi| − ∇2

r12|ψii,

(24)

where ψi(r12) are some eﬀective geminals (orbitals for two electrons, but only depending on

the relative distance r12), and ϑi some occupancy numbers to be chosen. For example, one

can always make a “bosonic” choice, by occupying only one geminal,22 equal to

f (r12).

The geminals ψi(r12) then satisfy the equations

with

[−∇2

r12 + weﬀ(r12)]ψi(r12) = ǫi ψi(r12)

i ϑi|ψi(r12)|2 = f (r12),

P






weﬀ(r12) =

1
r12

+

δG[f ]
δf (r12)

−

δTg[f ]
δf (r12)

.

7

p

(25)

(26)

The approximation of Eq. (24) is mainly motivated by the need of having simple equations

for f (r12) (the one-dimensional character of Eqs. (25) is of course very appealing). Notice

that only in the case N = 2 we have Tg[f ] = Tf[f ], and thus the eﬀective interaction weﬀ(r12)
of Eqs. (25) becomes equal to wξ=0(r12).

V. COMBINING DFT AND APDFT IN A SELF-CONSITENT WAY

As explained in the previous sections, to compute the expectation value of the physical

hamiltonian of Eq. (1) we only need f (r12) and n(r) for Vee and Vne, and the non-interacting
KS kinetic energy Ts[n] plus the APD f λ(r12) along the DFT adiabatic connection (13) for

the expectation value of T ; schematically:

hΨ|H|Ψi = hΨ|T |Ψi

+ hΨ|Vee|Ψi

+ hΨ|Vne|Ψi

.

(27)

|
Our aim is to obtain n(r) and Ts[n] via the KS equations, and f λ(r12) via Eqs. (25), which can

}

}

|

Ts[n]+f λ(r12)
| {z }

f (r12)
{z

n(r)
{z

be generalized to any hamiltonian along the DFT adiabatic connection, by simply replacing

the physical hamiltonian H with H λ of Eqs. (13)-(14) in the steps of Sec. IV.

A self-consitent scheme for this construction reads

(T + VKS) ΦKS = EKSΦKS

⇒

n(r), Ts[n]

[−∇2

r12 + wλ

eﬀ(r12; [n])]ψλ
i (r12)|2 = f λ(r12),

i ϑi|ψλ

i (r12) = ǫλ

i ψλ

i (r12)




⇒

f λ(r12)

(28)

(29)

P

E0 = min

vKS (cid:26)

λphys

Ts[n] +

Z

0

dλ

Z

dr12f λ(r12)

∂wλ(r12)
∂λ

+

Z

dr n(r)vne(r)

.

(cid:27)

(30)

The computation starts with a trial vKS(r) in the KS equations, schematically represented by

Eq. (28), where ΦKS is the Slater determinant of KS orbitals. From the KS equations we thus

get a ﬁrst approximation for the density n(r) and the non-interacting kinetic energy Ts[n].
Provided that we have a prescription to build an approximate wλ
eﬀ for a given density n(r)
(see next Sec. VI), we can obtain f λ(r12) along the DFT adiabatic connection from Eqs. (29).

In general, this step is not expensive: Eqs. (29) are unidimensional, and if the dependence
of wλ(r12) on λ is smooth, few λ values (5-20) are enough to provide a good estimate of

the coupling-constant average. The physical ground-state energy E0 is then evaluated via

Eq. (30). The procedure should then be repeated by optimizing the KS potential vKS, so that

8

E0 is minimum. The N-representability problem of the KS exchange-correlation functional
is clearly shifted to the N-representability problem for f λ(r12). In view of the new conditions
derived for the pair density,20 this seems to leave space for improvements.

VI. PROPERTIES OF THE EFFECTIVE ELECTRON-ELECTRON INTERAC-

TION

So far, we have only replaced the problem of ﬁnding an approximation for Exc[n] with

the problem of constructing wλ

eﬀ(r12; [n]). In order to proceed further, we study here the

properties of wλ

eﬀ(r12; [n]).

If we want our Eqs. (28)-(30) to be fully self-consitent, we should impose that for λ = 0

Eqs. (29) yield f λ=0(r12) = fKS(r12), i.e., the same APD we would obtain by inserting the

KS Slater determinant of Eq. (28) in Eqs. (6)-(7). This corresponds, in the usual DFT

language, to treat exchange exactly. The ﬁrst property we should thus impose to wλ

eﬀ(r12) is

wλ=0

eﬀ (r12) = wKS

eﬀ (r12).

(31)

If we use only one geminal to deﬁne Tg[f ] in Eq. (24), the property (31) corresponds to

wλ=0

eﬀ (r12) = ∇2

fKS(r12)/

fKS(r12). For more than one geminal we need more sophisti-

cated constructions, mathematically equivalent to those used to construct the KS potential

p

p

vKS(r) for a given spherical density n(r).23 Equation (31) also provides a very good starting
point to build wλ

eﬀ(r12): the KS system already takes into account the fermionic structure
and part of the eﬀect of the external potential in the physical problem. What is then left,

that needs to be approximated, is the eﬀect of turning on the electron-electron interaction

concerns the eigenvalue ǫλ

without changing the one-electron density n(r), and the diﬀerence between Tf [f ] and Tg[f ].
For conﬁned systems (atoms, molecules) another property to be imposed on wλ

eﬀ(r12)
max corresponding to the highest occupied geminal in Eqs. (29).
In fact, the asymptotic behavior of the pair density P2(r1, r2) of Eq. (6) for |r1| → ∞ (or
|r2| → ∞) is, in this case,24

lim
r1
|→∞

|

P2(r1, r2) = n(r1)nN

1(r2){ˆr1},

−

(32)

where nN

−

1(r) is one of the degenerate ground-state densities of the (N − 1)-electron system

(in the same external potential Vne), with the choice depending parametrically upon the

9

direction ˆr1 = r1/|r1|. A similar expansion holds for the KS pair density, obtained from the

KS Slater determinant of Eq. (28),

lim
r1
|→∞

|

P KS
2

(r1, r2) = n(r1)nKS
N
−

1(r2){ˆr1},

(33)

where we have used the fact that, by construction, the N-electron density is the same

for the physical system and for the KS one (while, of course, the corresponding (N − 1)-

electron densities are in general diﬀerent). For a given attractive (atomic, molecular) external

potential vanishing at large distances, the N-electron density is in general more diﬀuse

(decaying slower at large distances) than the (N −1)-electron density, so that the asymptotic

behavior of the APD f (r12) is, for large r12, dominated by the N-electron density decay at

large distances. We thus see, from Eqs. (32) and (33), that the corresponding APD’s, f (r12)
and fKS(r12), will have the same large-r12 decay, ∝ e√
2ǫmax r12, with a diﬀerent prefactor

−

(which can also include a polynomial function of r12), depending on the diﬀerence between

nN

1(r) and nKS
N
−

−

1(r). Since the same expansion holds for any P λ

2 (r1, r2) along the DFT

adiabatic connection,

lim
r1
|→∞

|

2 (r1, r2) = n(r1)nλ
P λ

N

1(r2){ˆr1},

−

(34)

the highest eigenvalue ǫλ

max in Eqs. (29) must be independent of λ and equal to the one for

the KS APD,

max = ǫλ=0
ǫλ

max = ǫKS

max.

(35)

In particular, if we choose only one geminal22 for the deﬁnition of Tg[f ], there is only one

eigenvalue, which must be the same for every λ.

For an extended system we have scattering states in Eqs. (29). For the special case of the

uniform electron gas, Eqs. (29) become equivalent to an approach that was ﬁrst proposed

by Overhauser,25 and further developed by other authors in the past ﬁve years.26,27,28 In

this approach, the geminal occupancy numbers ϑi are the same as the ones for a Slater

determinant: occupancy 1 for singlet states (even relative angular momentum ℓ), and occu-

Rather simple approximations for the eﬀective potential wλ

pancy 3 for triplet states (odd relative angular momentum ℓ), up to N(N − 1)/2 geminals.
eﬀ(r12) gave good results26,27,28
for the radial distribution function g(r12), when compared with quantum Monte Carlo data.

The long-range asymptotic behavior, in this case, corresponds to a phase-shift sum rule for
eﬀ(r12).29 The choice of one geminal for the uniform electron gas has been

the interaction wλ

10

explored, with remarkable success, in Ref. 30. In this case, the formal similarity with the

Fermi-hypernetted-chain approach31 (FHCN) was exploited to build a good approximation

for wλ

eﬀ(r12) (which was split into ↑↑ and ↑↓ contributions).
Finally, the small-r12 behavior of the eﬀective potential wλ

eﬀ(r12) is determined by the
choice of the adiabatic connection path. For instance, if we choose wλ(r12) = λ/r12 in
Eqs. (13)-(16), then the APD f λ(r12) displays the electron-electron cusp f λ(r12 → 0) =
f λ(0)(1 + λ r12 + ...), which implies, in turn, that also wλ
eﬀ(r12 → 0) = λ/r12 + .... In particular, for λ = λphys, we always have wλphys
wλ
1/r12 + ..., as shown, for the case of the He atom in Fig. 1. If we choose a cuspless nonlinear
path, like wλ(r12) = erf(λ r12)/r12, then the small r12 behavior of wλ
when we are approaching the physical interaction.32

eﬀ must behave, for small r12, as
(r12 → 0) =

eﬀ(r12) is known only

eﬀ

VII. PRELIMINARY APPLICATIONS

The construction of an approximate wλ

eﬀ(r12; [n]) can thus start with the decomposition

wλ

eﬀ(r12; [n]) = wKS

eﬀ (r12) + wλ(r12) + ∆wλ

eﬀ(r12; [n]),

(36)

where the term ∆wλ

eﬀ(r12; [n]) should take care of the fact that, when the electron-electron
interaction is turned on, the one-electron density n(r) and (for conﬁned systems) the highest

eigenvalue ǫλ

max do not change.

As a starting point, we applied the method of Eqs. (28)-(30) to the He isoelectronic

series. In this simple (yet not trivial) 2-electron case, we have the advantage that we can
treat Tf[f ] exactly. We developed an approximation6 for ∆wλ
eﬀ(r12; [n]) based on the one used
for the uniform electron gas.26 This approximation is designed to mimic the conservation

of n(r) along the DFT adiabatic connection, but does not take into account the eigenvalue

conservation. It works remarkably well when combined with a nonlinear adiabatic connection
path wλ(r12) = erf(λ r12)/r12 that separates short- and long-range correlation eﬀects, and

is reported in the Appendix of Ref. 6. Preliminary implementations of the self-consitent

procedure of Eqs. (28)-(30) yield ground-state energies within 1 mH with respect to full

conﬁguration interaction (CI) calculations in the same basis set. However, the way we carried

out these ﬁrst tests was simply based on a direct minimization of few variables parametrizing

vKS(r). This rather ineﬃcient way to implement Eqs. (28)-(30) needs further improvment.

11

Besides, the Kohn-Sham potentials we obtain in this way are very unstable (like the ones of

Ref. 33), although the corresponding total energies and electronic densities are stable, and

do not display the variational collapse of perturbation-theory-based approximate Ec[n].34

VIII. PERSPECTIVES

The generalization to many-electron systems of nonuniform density of the approximation

built in Ref. 6 for wλ

eﬀ(r12) is not straightforward. If we simply apply it to the Be atom
case (by using only one geminal), we obtain energy errors of 300 mH. Adding the eigenvalue

conservation can improve the results, but, of course, there is not a unique way to impose it.

So far, we found that the ﬁnal outcome strongly depends on how we impose the eigenvalue

conservation (i.e., if we use a functional form with one parameter adjusted to keep the

eigenvalue independent of λ, the results drastically depend on the chosen functional form). It

seems thus necessary to switch to more than one geminal, and/or to ﬁnd better constructions

for wλ

eﬀ(r12).

In particular, it may be promising to explore the possibility to construct approxima-

tions inspired to the FHNC,30,31,35 and to try to include some of the new results on N-

representability conditions for the pair density.20 Diﬀerent approximations with respect to

the one of Eq. (24) for the functional Tf[f ], and the use of Eq. (23) also deserve further

investigation.

Acknowledgments

We thank E.K.U. Gross for useful discussions and suggestions. One of the authors

(P.G.G.) gratefully aknowledges the 30th International Worksohop on Condensed Matter

Theory organizers for supporting her participiation to the meeting.

1 W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).

2 A.E. Mattsson, Science 298, 759 (2002).

3 C. Fiolhais, F. Nogueira, and M. Marques (eds.), A Primer in Density Functional Theory

(Springer-Verlag, Berlin, 2003).

12

4 J. P. Perdew, A. Ruzsinszky, J. Tao, V. N. Staroverov, G. E. Scuseria, and G. I. Csonka, J.

Chem. Phys. 123, 062201 (2005).

5 see, e.g., T. Leininger, H. Stoll, H.-J. Werner, and A. Savin, Chem. Phys. Lett. 275, 151 (1997);

R. Pollet, A. Savin, T. Leininger, and H. Stoll, J. Chem. Phys. 116, 1250 (2002); J. Toulouse, F.

Colonna, and A. Savin, Phys. Rev. A 70, 062505 (2004); J. Toulouse, F. Colonna, and A. Savin,

J. Chem. Phys. 122, 014110 (2005); J. G. ´Angy´an, I.C. Gerber, A. Savin, and J. Toulouse, Phys.

Rev. A 72, 012510 (2005); E. Goll, H.-J. Werner and H. Stoll, Phys. Chem. Chem. Phys. 7 ,

3917 (2005); E. Goll, H.-J. Werner, H. Stoll, T. Leininger, P. Gori-Giorgi, and A. Savin, Chem.

Phys. 329, 276 (2006).

6 P. Gori-Giorgi and A. Savin, Phys. Rev. A 71, 032513 (2005).

7 P. Gori-Giorgi and A. Savin, Philos. Mag. 86, 2643 (2006).

8 A.J. Thakkar, A.N. Tripathi, and V.H. Smith, Jr., Int. J. Quantum Chem. 26, 157 (1984), and

references therein.

9 C.A. Coulson and A.H. Neilson, Proc. Phys. Soc. London 78, 831 (1961).

10 J. Cioslowski, B.B. Stefanov, A. Tan, and C.J. Umrigar, J. Chem. Phys. 103, 6093 (1995).

11 J. Cioslowski and G. Liu, J. Chem. Phys. 109, 8225 (1998).

12 E. Valderrama, J.M. Ugalde, and R.J. Boyd, in Many-electron densities and reduced density

matrices, edited by J. Cioslowski (Kluwer Academic/Plenum Publishers, New York, 2000).

13 E.R. Davidson, Reduced Density Matrices in Quantum Chemistry (Academic Press, New York,

1976).

14 A.J. Coleman and V.I. Yukalov, Reduced Density Matrices: Coulson’s Challenge (Springer-

Verlag, New York, 2000).

15 M. Levy, Proc. Natl. Acad. Sci. U.S.A. 76, 6062 (1979).

16 E. Lieb, Int. J. Quantum Chem. 24, 243 (1983).

17 J. Harris and R. Jones, J. Phys. F 4, 1170 (1974); D.C. Langreth and J.P. Perdew, Solid State

Commun. 17, 1425 (1975); O. Gunnarsson and B.I. Lundqvist, Phys. Rev. B 13, 4274 (1976).

18 W. Yang, J. Chem. Phys. 109, 10107 (1998).

19 A. Savin, F. Colonna, and R. Pollet, Int. J. Quantum Chem. 93, 166 (2003).

20 P. W. Ayers and E. R. Davidson, Int. J. Quantum Chem. 106, 1487 (2006); P. W. Ayers, Phys.

Rev. A 74, 042502 (2006); P. W. Ayers and E. R. Davidson, Adv. Chem. Phys., in press.

21 D.E. Freund, B.D. Huxtable, and J.D. Morgan III, Phys. Rev. A 29, 980 (1984). We used

13

an improved version (provided to us by C. Umrigar) of the accurate variational wavefunctions

described in this work. See also C.J. Umrigar and X. Gonze, Phys. Rev. A 50, 3827 (1994), and

Ref. 10.

22 ´A. Nagy, J. Chem. Phys. 125, 184104 (2006).

23 F. Colonna and A. Savin, J. Chem. Phys. 110, 2828 (1999); Q. Zhao, R. C. Morrison, and R.

G. Parr, Phys. Rev. A 50, 2138 (1994); R. van Leeuwen and E. J. Baerends Phys. Rev. A 49,

2421 (1994).

24 M. Levy, J.P. Perdew, and V. Sahni, Phys. Rev. A 30, 2745 (1984); M. Ernzerhof, K. Burke,

and J.P. Perdew, J. Chem. Phys. 105, 2798 (1996).

25 A.W. Overhauser, Can. J. Phys. 73, 683 (1995).

26 P. Gori-Giorgi and J.P. Perdew, Phys. Rev. B 64, 155102 (2001).

27 B. Davoudi, M. Polini, R. Asgari, and M.P. Tosi, Phys. Rev. B 66, 075110 (2002).

28 M. Corona, P. Gori-Giorgi, and J.P. Perdew, Phys. Rev. B 69, 045108 (2004); I. Nagy, R. Diez

Mui˜no, J.I. Juaristi, and P.M. Echenique, Phys. Rev. B 69, 233105 (2004).

29 P. Ziesche, Phys. Rev. B 67, 233102 (2003); physica status solidi (b) 242, 2051 (2005).

30 B. Davoudi, R. Asgari, M. Polini, and M. P. Tosi Phys. Rev. B 68, 155112 (2003).

31 see, e.g., E. Krotscheck and M. Saarela, Phys. Rep. 232, 1 (1993).

32 P. Gori-Giorgi and A. Savin, Phys. Rev. A 73, 032506 (2006).

33 V. N. Staroverov, G. E. Scuseria, and E. R. Davidson, J. Chem. Phys. 124, 141103 (2006).

34 P. Mori-Snchez, Q. Wu, and W. Yang, J. Chem. Phys. 123, 062204 (2005); D. R. Rohr, O. V.

Gritsenko, and E. J. Baerends, Chem. Phys. Lett., in press.

35 E. Krotscheck, Phys. Lett. A 190, 201 (1994).

14"
Simple implementation of complex functionals: scaled selfconsistency,"  We explore and compare three approximate schemes allowing simple
implementation of complex density functionals by making use of selfconsistent
implementation of simpler functionals: (i) post-LDA evaluation of complex
functionals at the LDA densities (or those of other simple functionals); (ii)
application of a global scaling factor to the potential of the simple
functional; and (iii) application of a local scaling factor to that potential.
Option (i) is a common choice in density-functional calculations. Option (ii)
was recently proposed by Cafiero and Gonzalez. We here put their proposal on a
more rigorous basis, by deriving it, and explaining why it works, directly from
the theorems of density-functional theory. Option (iii) is proposed here for
the first time. We provide detailed comparisons of the three approaches among
each other and with fully selfconsistent implementations for Hartree,
local-density, generalized-gradient, self-interaction corrected, and
meta-generalized-gradient approximations, for atoms, ions, quantum wells and
model Hamiltonians. Scaled approaches turn out to be, on average, better than
post-approaches, and unlike these also provide corrections to eigenvalues and
orbitals. Scaled selfconsistency thus opens the possibility of efficient and
reliable implementation of density functionals of hitherto unprecedented
complexity.
",http://arxiv.org/pdf/cond-mat/0611482v1,3,"6
0
0
2

v
o
N
7
1

]
i
c
s
-
l
r
t

m

.
t
a
m
-
d
n
o
c
[

1
v
2
8
4
1
1
6
0
/
t
a
m
-
d
n
o
c
:
v
i
X
r
a

Simple implementation of complex functionals: scaled selfconsistency

Matheus P. Lima, Luana S. Pedroza, Antonio J. R. da Silva and A. Fazzio
Instituto de F´ısica, Universidade de S˜ao Paulo, S˜ao Paulo, Brazil

Daniel Vieira, Henrique J. P. Freire and K. Capelle∗
Departamento de F´ısica e Inform´atica, Instituto de F´ısica de S˜ao Carlos,
Universidade de S˜ao Paulo, Caixa Postal 369, 13560-970 S˜ao Carlos, SP, Brazil
(Dated: October 22, 2018)

We explore and compare three approximate schemes allowing simple implementation of com-
plex density functionals by making use of selfconsistent implementation of simpler functionals: (i)
post-LDA evaluation of complex functionals at the LDA densities (or those of other simple func-
tionals); (ii) application of a global scaling factor to the potential of the simple functional; and (iii)
application of a local scaling factor to that potential. Option (i) is a common choice in density-
functional calculations. Option (ii) was recently proposed by Caﬁero and Gonzalez. We here put
their proposal on a more rigorous basis, by deriving it, and explaining why it works, directly from
the theorems of density-functional theory. Option (iii) is proposed here for the ﬁrst time. We
provide detailed comparisons of the three approaches among each other and with fully selfconsis-
tent implementations for Hartree, local-density, generalized-gradient, self-interaction corrected, and
meta-generalized-gradient approximations, for atoms, ions, quantum wells and model Hamiltonians.
Scaled approaches turn out to be, on average, better than post-approaches, and unlike these also
provide corrections to eigenvalues and orbitals. Scaled selfconsistency thus opens the possibility of
eﬃcient and reliable implementation of density functionals of hitherto unprecedented complexity.

PACS numbers: 31.15.Ew, 31.25.Eb, 31.25.Jf, 71.15.Mb

I.

INTRODUCTION

tional is an implicit density functional.

Density-functional theory1,2,3 is the driving force be-
hind much of todays progress in electronic-structure cal-
culations. Progress in density-functional theory (DFT)
itself depends on the twin development of ever more pre-
cise density functionals and of ever more eﬃcient compu-
tational implementations of these functionals. The ﬁrst
line of development, functionals, has lead from the local-
density approximation (LDA) to generalized-gradient ap-
proximations (GGAs), hybrid functionals, and on to
meta-GGAs and other fully nonlocal approximations,
such as exact-exchange (EXX) and self-interaction cor-
rections (SICs).4,5

As functionals get more and more complex, the second
task, implementation, gets harder and harder.
Indeed,
very few truly selfconsistent implementations of beyond-
GGA functionals exist, and even GGAs are still some-
times implemented non-selfconsistently. At the heart of
the problem is not so much the actual coding (although
that can also be a formidable task, considering the com-
plexity of, e.g., meta-GGAs), but rather obtaining the
exchange-correlation (xc) potential vxc(r) corresponding
to a given approximation to the xc energy Exc[n]. Hy-
brid functionals, meta-GGAs, EXX and SICs are all or-
bital functionals, i.e., functionals of the general form
Eorb
xc [{ϕi[n]}], where our notation indicates an explicit
dependence on the set of Kohn-Sham (KS) orbitals ϕi(r).
This set may be restricted to the occupied orbitals, but
may also include unoccupied orbitals. Since by virtue of
the Hohenberg-Kohn (HK) theorem these orbitals them-
selves are density functionals, any explicit orbital func-

The HK theorem itself, however, does not provide any
clue how to obtain the xc potentials, i.e., how to calculate
the functional derivative

vxc[n](r) =

δEorb

xc [{ϕi}]
δn(r)

(1)

of a functional whose density dependence is not known
explicitly. Three diﬀerent solutions to this dilemma have
been advanced in the literature.

(i) The formally correct way to implement an implicit
density functional in DFT is the optimized-eﬀective po-
tential (OEP) algorithm5 [also known as the optimized
potential method (OPM)], which results in an integral
equation for the KS potential corresponding to the or-
bital functional. The ﬁrst step of the derivation of the
OEP is to write

vxc[n](r) =

δEorb

xc [{ϕi}]
δn(r)

(2)

d3r′

=

Z

δEorb

xc [{ϕi}]
δϕi(r′)

δϕi(r′)
δn(r)

+ c.c.

(3)

(cid:21)

(cid:20)

δEorb

Xi
xc [{ϕi}]
δϕi(r′)

δϕi(r′)
δvs(r′′)

δvs(r′′)
δn(r)

+ c.c.

.(4)

(cid:21)

d3r′d3r′′

=

Z

(cid:20)

Xi

Further evaluation of Eq. (4) gives rise to an integral
equation that determines the vxc[n] belonging to the
chosen orbital functional Eorb
xc [{ϕi[n]}]. This OEP in-
tegral equation must be solved at every step of the
selfconsistency cycle, which considerably increases de-
mands on memory and computing time. Often (in

 
 
 
 
 
 
particular for systems that do not have spherical sym-
metry) the integral equation is simpliﬁed by means of
the Krieger-Li-Iafrate (KLI) approximation,6 but even
within this approximation, or other recently proposed
simpliﬁcations,7,8 an OEP calculation is computationally
more expensive than a traditional KS calculation. A sep-
arate issue is the unexpected behaviour of the OEP in ﬁ-
nite basis sets, which was recently reported to cast doubt
on the reliability of the method.9 The OEP prescrip-
tion moreover assumes in the ﬁrst step that the orbital
derivative δEorb
xc [{ϕi}]/δϕi(r′) can be obtained, and even
that is not a trivial task for complex orbital-dependent
functionals such as meta-GGA and hyper-GGA. (For the
Fock term, on the other hand, this derivative is simple,
and the implementation of the Fock term by means of
the OEP is becoming popular under the name exact ex-
change [EXX]).

(ii) Instead of taking the variation of Exc[{ϕi[n]}] with
respect to n(r), as in the OEP, one often makes Exc
stationary with respect to the orbitals. When applied
to the Fock term, this is simply the Hartree-Fock (HF)
method, but similar procedures are commonly applied
within DFT to hybrid functionals, such as B3-LYP. Self-
consistent implementations of meta-GGA reported until
today are also selfconsistent with respect to the orbitals,
not the densities.10,11,12 For the Fock term, one ﬁnds em-
pirically that the occupied orbitals obtained from orbital
selfconsistency are quite similar to those obtained from
density selfconsistency, but such empirical ﬁnding is no
guarantee that the similarity will persist for all possible
functionals or systems — and in any case it does not ex-
tend to the unoccupied orbitals. Computationally, the
resulting nonlocal HF-like potential makes the solution
of the Kohn-Sham equation more complex than the local
potential resulting from the OEP (although the poten-
tial itself is obtained in a simpler way). Moreover, as
the OEP, this prescription also requires that the orbital
derivative δEorb
xc [{ϕi}]/δϕi(r′) can be obtained, which
need not be simple for complex functionals.

(iii) Less demanding than density-selfconsistency or
orbital-selfconsistency are post-selfconsistent implemen-
tations, in which a selfconsistent KS calculation is per-
formed with a simpler functional, and the resulting or-
bitals and densities are once substituted in the more com-
plex one. This strategy is sometimes used to implement
GGAs in a post-LDA way, and has been applied also to
meta-GGAs. It is much simpler than the other two pos-
sibilities, but does not lead to KS potentials, orbitals,
and single-particle energies associated with the complex
functional. It simply yields the total energy the complex
functional produces on the densities obtained from the
simpler functional.

As this brief summary shows, each of the three choices
has its own distinct set of advantages and disadvantages.
A method that is simple to implement, reliable, and pro-
vides access to total energies as well as single-particle
quantities would be a most useful addition to the arsenal
of computational DFT.

2

A method we consider to have the desired character-
istics was recently proposed by Caﬁero and Gonzalez,13
and consists in the application of a scaling factor to the
xc potential of a simple functional (which can be imple-
mented fully selfconsistently), such that it approximates
the potential expected to arise from a complex functional
(which need not be implemented selfconsistently). This
fourth possibility, which we call globally-scaled selfcon-
sistency (GSSC), is analysed in Sec.
II of the present
paper.

We believe the derivation presented by Caﬁero and
Gonzalez to lack rigour at a crucial step, and thus ded-
icate Sec. II A to an investigation of their procedure.
Our investigation leads to an alternative derivation of
the same approach, described in Sec. II B. Next, we pro-
vide, in Sec. II C, an analysis of the validity of the scaling
approximation, arriving at the counterintuitive (but nu-
merically conﬁrmed and explainable) conclusion that the
success of this approximation is not due to the small-
ness of the neglected term relative to the one kept. We
also suggest a modiﬁcation of the approach, which we
call locally-scaled selfconsistency (LSSC) and describe in
Sec. II D.

In Secs. III and IV we provide extensive numerical
tests of GSSC and LSSC, and also of the more com-
mon post-selfconsistent mode of implementation [here
denoted P-SC, option (iii) above]. Note that although
P-SC is quite commonly used, it has not been systemat-
ically tested in situations where the exact result or the
fully selfconsistent result is known. All three schemes
are applied to atoms and ions in Secs. III A and III B,
to one-dimensional Hubbard chains, in Sec. IV A, and to
semiconductor quantum wells, in Sec. IV B. We compare
Hartree, LDA, GGA, MGGA and SIC calculations, im-
plemented via P-SC, GSSC and LSSC, among each other,
and, where possible, with results obtained from fully self-
consistent implementations of the same functionals.

Our main conclusion is that scaled selfconsistency
works surprisingly well, for all diﬀerent combinations of
systems and functionals we tried. Scaled selfconsistency
yields better energies than post-selfconsistent implemen-
tations, and moreover provides access to orbitals and
eigenvalues. This conclusion opens the possibility of eﬃ-
cient and reliable implementation of density functionals
of hitherto unprecedented complexity.

II. SCALED SELFCONSISTENCY

In this section we ﬁrst brieﬂy review the approach sug-
gested by Caﬁero and Gonzalez (CG),13 and point out
where we believe their development to lack rigour. Next
we present an alternative derivation and suggest a mod-
iﬁcation.

A. The proposal of Caﬁero and Gonzalez

CG consider a complex functional, EB
tial vB
xc(r), and a simple functional, EA
vA
xc(r). They then deﬁne the energy ratio

xc[n] with poten-
xc[n] with potential

Fxc[n] =

EB
EA

xc[n]
xc[n]

(5)

and diﬀerentiate EB
the density n(r), obtaining, in their notation,

xc[n] = Fxc[n]EA

xc[n] with respect to

xc(r) = Fxc[n]vA
vB

xc(r) + EA

xc[n]

∂Fxc[n]
∂n(r)

.

(6)

xc[n∗] = EA

Next, CG argue that at the selfconsistent density, n∗,
EB
xc[n∗], so that Fxc[n∗] → 1. According to
CG, the last term in Eq. (6) is then equal to zero. Under
this ’constraint’13 they obtain

xc(r) = Fxc[n]vA
vB

xc(r)

(7)

which implies that an (approximate) selfconsistent im-
plementation of the complicated functional EB
xc[n] can
be achieved by means of a selfconsistent implementation
of the simple functional EA
xc[n], if at every step of the
selfconsistency cycle the potential corresponding to func-
tional A is multiplied by the ratio of the energies of B and
A. This procedure completely avoids the need to ever cal-
culate or implement the potential corresponding to B.
CG go on to test their proposal for a few functionals and
systems, and claim very good numerical agreement be-
tween approximate results obtained from (7) and fully
selfconsistent or post-selfconsistent implementations.

We were initially quite surprised by these good results,
as the preceding argument lacks rigour at a key step.
Apart from the use of partial derivatives instead of vari-
ational ones (which is probably just a question of nota-
tion), we do not see why at the selfconsistent density the
simple and the complex functional must approach the
same value, i.e., why F [n∗] should approach one. More-
over, whatever value F approaches, this value should not
be used to simplify the equation for the xc potential be-
cause the derivative must be carried out before substitut-
ing numerical values in the energy functional, not after-
wards.

B. An alternative derivation

In view of these troublesome features of the original
derivation we below present an alternative rationale for
the same approach. We start by writing the same identity
the CG approach is based on,

EB[n] =

EB[n]
EA[n]

EA[n] =: F [n]EA[n].

(8)

Note that we write this identity for an arbitrary energy
functional, as the approach is, in principle, not limited to

3

xc functionals. Indeed, below we will show one applica-
tion in which we deal with the entire interaction energy
(Hartree + xc). Next, we take the functional derivative
of the product F [n]EA[n],

vB(r) ≡

δEB[n]
δn(r)

=

δF [n]
δn(r)

EA[n] + F [n]

δEA[n]
δn(r)

(9)

=

δF [n]
δn(r)

EA + F [n]vA(r).

(10)

The functional derivative of the ratio F [n] is

δ
δn(r)

EB
EA =

EA[n]vB(r) − EB[n]vA(r)
EA[n]2

.

(11)

Substitution of this in the previous equation yields the
identity

vB(r) =

EA[n]vB(r) − EB[n]vA(r)
EA[n]

+ F [n]vA(r).

(12)

Neglecting the ﬁrst term leaves us with the simple ex-
pression

vB(r) ≈ vGSSC (r) := F [n]vA(r)

(13)

as an approximation to vB. In the following this approx-
imation is called globally scaled selfconsistency (GSSC).
Scaling here refers to the multiplication of the simple
potential vA(r) by the energy ratio F [n] in order to sim-
ulate the more complex potential vB(r), and the speciﬁer
globally is employed in anticipation of a local variant de-
veloped in Sec. II D.

C. Validity of scaled selfconsistency

The form of Eq.(12) suggests a simple explanation of
why scaled selfconsistency can lead to results close to
those obtained from a fully selfconsistent implementation
of functional B: Clearly, vGSSC (r) is a good approxima-
tion to vB(r) if the ﬁrst term in (12) can be neglected
compared to the second. Globally scaled selfconsistency
is thus guaranteed to be valid if the validity criterium

C1(r) :=

EA[n]vB(r) − EB[n]vA(r)
(cid:12)
|EB[n]vA(r)|
(cid:12)

(cid:12)
(cid:12)

<< 1

(14)

is satisﬁed at all points in space. Note that this is con-
ceptually a very diﬀerent requirement from F [n∗] → 1,
although it leads to the same ﬁnal result.

Interestingly, criterium (14) is a suﬃcient, but not at
all a necessary, criterium for applicability of the GSSC
approach.
In fact, in the applications reported below
we have frequently encountered situations in which the
ﬁrst term on the right-hand side in Eq. (12) is not much
smaller, but comparable to, or even larger than, the sec-
ond term. The empirical success of scaled selfconsistency,

claimed in Ref. 13 and conﬁrmed below for a wide vari-
ety of functionals and systems, must thus have another
explanation, rooted in systematic error cancellation.

One source of error cancellation is the fact that Eq.
(14) is a point-wise equation, which, in principle, must
be satisﬁed for every value of r. For the calculation of
integrated quantities (such as total energies) or quantities
determined by the values of vB(r) at all points in space
(such as KS eigenvalues) a violation of (14) at some point
in space can be compensated by that at some other point.
We have numerically veriﬁed that this indeed happens:
the sign of the term neglected in GSSC can be diﬀerent in
diﬀerent regions of space, reducing the integrated error.
The extent to which errors at diﬀerent points cancel in
the application of the scaling factor can be estimated by
replacing Eq. (14) by

C2 :=

d3r EA[n]vB(r) − EB[n]vA(r)
d3rEB[n]vA(r)

R

<< 1.

(15)

Representative values of C2 are also reported below.

R

In applications we have frequently obtained excellent
total energies even in situations in which this criterium
also fails. A second source of error cancellation is the
DFT total-energy expression

E0[n] =

ǫi −EH [n]−

Xi

Z

d3r n(r)vxc(r)+Exc[n], (16)

xc

where, ideally, vxc is the functional derivative of Exc[n].
Scaled selfconsistency is applied in situations in which
Exc[n] is known, but vxc is hard to obtain or to imple-
ment. Hence it replaces vxc by vGSSC
in the second-
to-last term, but the last term is evaluated using the
original Exc. The entire expression is evaluated on the
selfconsistent density arising from a Kohn-Sham calcu-
lation with potential vGSSC
. In situations in which all
terms in (16) can be obtained exactly, we have veriﬁed
numerically that the errors arising from diﬀerent terms
in the GSSC total energy make contributions of similar
size but opposite sign to the total error. Representative
analyses of this type are given below.

xc

Numerical comparison of the exact equation (12) and
its approximation (13) with results obtained from the
local (14) or the integrated (15) validity criterium, and
with the errors of each term in the total-energy expression
(16), permits us to identify the reason for the success of
GSSC. Anticipating results presented in detail in later
sections, we ﬁnd that the excellent approximations to
total energies obtained from the simple scaling approach
are to a large extent due to the error cancellation between
diﬀerent terms of the total energy, and depend only very
weakly on the smallness of the neglected term relative to
the one kept.

We end this discussion of validity and errors by point-
ing out that although frequently a violation of the criteria
(14) or (15) still provides good energies, we have never
observed the opposite situation, i.e., bad energies in sit-
uations in which (14) or (15) are satisﬁed.

4

D. Locally-scaled selfconsistency

As a result of the previous section, we have the expres-

sion

vB[n](r) ≈

vGSSC [n](r) =

EB[n]
EA[n]

vA[n](r) = F [n]vA[n](r)

(17)

for globally-scaled selfconsistency. Note that the scaling
factor depends on the density, i.e., is updated in every
iteration of the selfconsistency cycle, but does not depend
on the spatial coordinate r, i.e., is the same for all points
in space.

Clearly, such a global scaling factor cannot properly
account for the ﬁne point-by-point diﬀerences expected
between the potentials vA(r) and vB(r). In an attempt to
account for these diﬀerences, we introduce a local scaling
factor, based on the observation that many functionals
(in particular, LDA, GGA and MGGA) can be cast in
the form

E[n] =

Z

d3r e(n(r)),

(18)

where the energy density e(n) is deﬁned (up to a total
divergence) by the above expression, and the dependence
of e(n) on n(r) may be both explicit (as in LDA) or
implicit (as in meta-GGA). The energy density allows us
to introduce a local scaling factor f [n](r), according to

vB[n](r) ≈ vLSSC [n](r) =

vA[n](r) =: f [n](r)vA[n](r).

(19)

(20)

eB[n](r)
eA[n](r)

In the applications below we refer to vGSSC[n] as the
globally scaled potential (with upper-case scaling factor
F ), and to vLSSC as locally scaled potential (with lower-
case scaling factor f (r)).

We also explored a variety of alternative scaling
schemes, such as, e.g., application of scaling factors to the
full eﬀective potential instead of just its xc contribution,
or directly to the density. None of these consistently led
to better results than the GSSC and LSCC procedures,
and we refrain from presenting detailed results from al-
ternative schemes here.

III. TESTS AND APPLICATIONS TO ATOMS
AND IONS

In this section we compare post-selfconsistent imple-
mentations and globally and locally scaled implementa-
tions of diﬀerent density functionals for total energies and
Kohn-Sham eigenvalues of atoms and ions. We provide
comparisons of these modes of implementation among
each other and, where possible, with fully selfconsistent
applications. We also provide representative evaluations
of the validity criteria discussed in Sec. II C.

TABLE I: Ground-state energies of neutral atoms (in Ryd-
berg) obtained selfconsistently with LDA and with GGA, and
approximate GGA energies predicted by globally (F) and lo-
cally (f) scaled selfconsistency, starting from LDA, and by
post-LDA application (P) of GGA.

TABLE II: Ground-state energies of neutral atoms ob-
tained selfconsistently with GGA(PBE), compared to meta-
GGA(TPSS) energies predicted by globally (F) and locally (f)
scaled selfconsistency, starting from GGA, and by post-GGA
calculations (P).

5

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

GGA
f
LDA
-5.7859
-5.7838
-5.6686
-14.9244
-14.9206
-14.6853
-29.2599
-29.2561
-28.8924
-49.2108
-49.2057
-48.7037
-75.5874
-75.5813
-74.9315
-109.072
-109.065
-108.258
-150.002
-149.995
-149.042
-199.331
-199.325
-198.217
-257.733
-257.726
-256.455
-324.345
-324.338
-322.881
-399.910
-399.903
-398.265
-484.464
-484.456
-482.628
-578.464
-578.455
-576.429
-682.231
-682.222
-679.991
-795.892
-795.883
-793.471
-919.941
-919.932
-917.327
-1051.876 -1054.686 -1054.682 -1054.685 -1054.692

P
-5.7844
-14.9220
-29.2573
-49.2075
-75.5835
-109.067
-149.998
-199.327
-257.728
-324.340
-399.905
-484.458
-578.458
-682.224
-795.885
-919.934

F
-5.7854
-14.9235
-29.2589
-49.2089
-75.5846
-109.068
-149.998
-199.327
-257.729
-324.341
-399.906
-484.459
-578.458
-682.225
-795.886
-919.935

A. Total energy of atoms and ions: LDA, GGA,
Meta-GGA and SIC

Ground-state energies of neutral atoms from Z = 2
In Table I
to Z = 18 are shown in Tables I to III.
we compare selfconsistent LDA(PZ14) and GGA(PBE15)
energies with energies obtained by three approximate
schemes: post-LDA implementation of GGA and glob-
ally and locally scaled selfconsistency. For global scaling
we follow our above discussion and use

vGGA(GSSC)
xc

[n](r) =

EGGA
xc
ELDA
xc

[n]
[n]

vLDA
xc

[n](r)

(21)

xc

as xc potential, throughout the selfconsistency cycle. For
local scaling, the prefactor of vLDA
(r) is replaced by
the corresponding energy densities. Although GGAs are
nowadays often implemented fully selfconsistency, appli-
cation of approximate schemes to GGA is interesting pre-
cisely because fully selfconsistent data are available for
comparison. Table I clearly shows that both approxi-
mate schemes provide excellent approximations to the
fully selfconsistent values.

Next, we consider two alternative choices of energy
functionals, for which fully selfconsistent results are not
readily available: meta-GGA and self-interaction correc-
tions. In Table II we compare a GSCC implementation
of meta-GGA(TPSS)16,17 with results obtained from a
post-GGA(PBE) implementation of the same functional.
Fully selfconsistent implementation of meta-GGA would

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

GGA
-5.7859
-14.9244
-29.2599
-49.2108
-75.5874
-109.0715
-150.0019
-199.3313
-257.7329
-324.3454
-399.9103
-484.4641
-578.4640
-682.2314
-795.8921
-919.9413
-1054.6923

F
-5.8185
-14.9768
-29.3414
-49.3077
-75.7091
-109.2304
-150.1664
-199.5190
-257.9607
-324.5951
-400.1831
-484.7584
-578.7866
-682.5997
-796.2723
-920.3493
-1055.1359

f
-5.7625
-14.9111
-29.2654
-49.2061
-75.5768
-109.0610
-149.9781
-199.3022
-257.7085
-324.3452
-399.9298
-484.4871
-578.4969
-682.2784
-795.9499
-920.0101
-1054.7761

P
-5.8183
-14.9767
-29.3412
-49.3076
-75.7089
-109.2302
-150.1662
-199.5188
-257.9605
-324.5949
-400.1830
-484.7583
-578.7865
-682.5896
-796.2722
-920.3492
-1055.1359

require the OEP algorithm, and has not yet been re-
ported. However, previous tests of meta-GGA suggest
that orbital selfconsistency and post-GGA implementa-
tion of MGGA give rather similar results, and provide
signiﬁcant improvement on GGA.11,12 Consistently with
these observations, and also with those of Ref. 13 (which,
however, uses the now obsolete PKZB form of meta-
GGA), we ﬁnd, in Table II, very close agreement between
scaled and post-GGA implementations of TPSS meta-
GGA. Systematically, the LSSC energies are a little less
negative and the GSCC energies very slightly more neg-
ative than post-GGA energies.

A diﬀerent type of density functional is represented
by the self-interaction correction (SIC). Although several
distinct such corrections have been proposed, we here
focus on the best known suggestion, made by Perdew and
Zunger in 1981 (PZSIC).14 PZSIC provides an orbital-
dependent correction of the form

Eapprox
xc

[n↑, n↓] −

Xi,σ

Eapprox,SIC

xc
(EH [niσ] − Eapprox

xc

[n↑, n↓] =

[niσ, 0]) , (22)

xc

which can be applied to any approximate density func-
tional Eapprox
. Here we chose this functional to be the
LDA. The correction terms depend on the partial den-
sity of each occupied orbital, niσ(r), and not explicitly
on the total density. Hence, selfconsistent implementa-
tion should proceed via the OEP.18 Instead, common
implementations of PZSIC follow a suggestion made in

TABLE III: Ground-state energies of neutral atoms obtained
selfconsistently with LDA, and PZSIC energies predicted by
globally scaled selfconsistency, starting from LDA, and by
post-LDA implementation of PZSIC, all compared to ener-
gies obtained from a standard (i.e., orbitally selfconsistent)
implementation of LDA+PZSIC.

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

LDA
-5.6686
-14.6853
-28.8924
-48.7037
-74.9315
-108.258
-149.042
-198.217
-256.455
-322.881
-398.265
-482.628
-576.429
-679.991
-793.471
-917.327
-1051.876

F
-5.8366
-15.0075
-29.3863
-49.3992
-75.8573
-109.442
-150.505
-199.987
-258.561
-325.332
-401.060
-485.769
-579.922
-683.843
-797.689
-921.920
-1056.850

P
-5.8329
-15.0036
-29.3824
-49.3946
-75.8520
-109.436
-150.497
-199.979
-258.551
-325.324
-401.053
-485.762
-579.916
-683.836
-797.683
-921.914
-1056.850

LDA+PZSIC
-5.8386
-15.0091
-29.3877
-49.4007
-75.8592
-109.445
-150.508
-199.991
-258.565
-325.336
-401.064
-485.773
-579.926
-683.846
-797.692
-921.923
-1056.854

the original reference,14 and vary the energy functional
with respect to the orbitals. The resulting single-particle
equation is not the usual Kohn-Sham equation, but fea-
tures an eﬀective potential that is diﬀerent for each or-
bital.

In Table III we compare energies obtained from so-
lution of this equation with those obtained, in a much
simpler way, from applying GSCC to LDA+PZSIC. Very
good agreement is achieved. This is even more remark-
able as in usual implementations of PZSIC the potentials
are diﬀerent for each orbital, and the resulting orbitals
are not orthogonal, whereas in the GSSC implementa-
tion the local potential is the same for all orbitals, which
are automatically orthogonal. Formally, the GSSC im-
plementation is thus more satisfying than the standard
implementation.

The analysis of total energies of neutral atoms is sum-
marized in Figure 1, which displays the relative deviation

η =

(Eref − EGSSC )
Eref

(23)

of GSCC from selfconsistent data (GGA), post-GGA
data (meta-GGA) and orbitally selfconsistent data
(PZSIC).

Table IV presents a representative error analysis. Val-
ues of C2, deﬁned in Eq. (15), indicate that the term ne-
glected in the GSSC approach is smaller than the term
kept, but not by a suﬃcient margin to explain, on its
own, the very good approximation to total energies ob-

4.0 

3.0 

)

5
-

0
1
x
(
η

2.0 

1.0 

0

-1.0 
5

6

PZ-SIC
GGA
Meta-GGA

9

13

17

Z

FIG. 1: Relative deviation, as deﬁned in Eq. (23), of GSSC
GGA compared to selfconsistent GGA (full line), of GSSC
meta-GGA compared to post-GGA meta-GGA (dash-dotted
line) and of GSCC LDA+PZSIC compared to orbitally self-
consistent LDA+PZSIC. Note that only in the ﬁrst case this
relative deviation can be interpreted as a relative error of
GSSC relative to fully selfconsistent results, as in the other
two cases diﬀerent approximations are compared among each
other.

TABLE IV: Breakdown of errors of the diﬀerent contribu-
tions to the total energy in Eq. (16), comparing LDA-based
global-scaling predictions of GGA energies (GSSC GGA) with
selfconsistent GGA energies. The column labeled C2 contains
the integrated validity criterium of global scaling, as deﬁned
in Eq. (15). Note that we have not deﬁned an integrated
validity criterium for local scaling.

atom
He
C
O
Na
Si
Ar

C2
0.016
0.115
0.016
0.353
0.147
0.009

∆EKS ∆EH
0.0131
0.0974
-0.1670
0.2684
-0.318
0.333
-0.541
0.464
-0.691
0.689
-0.948
0.959

∆Vxc
0.0766
0.4504
0.679
1.041
1.416
1.950

∆Exc
-0.0081
0.0122
0.024
0.031
0.030
0.036

∆E0
-0.0004
-0.0028
-0.004
-0.004
-0.006
-0.007

tained from global scaling. The breakdown of the error
of the total energy into the contributions arising from
each term individually, shows that there is very substan-
tial error cancellation, mostly between the sum of the KS
eigenvalues and the potential energy in the xc potential.
As a consequence of this error cancellation, which is ul-
timately due to the variational principle, selfconsistent
total energies are predicted by scaling approaches with
much higher accuracy than the values of C2 suggest.

The performance of global and local scaling, as well as
that of post methods, for (positive) ions is essentially the
same obtained for neutral systems, as is illustrated for
selected ions in Table V.

From the data in Tables I to V we conclude that global
scaling yields slightly better ground-state energies than
local scaling and post methods. In addition, for orbital-
dependent functionals, such as PZ-SIC, it provides a com-

 
 
TABLE V: Ground-state energies of positive ions, obtained
from self-consistent LDA and GGA calculations, as well as
from locally and globally scaled LDA calculations.

GGA
LDA
atom
He+
-3.9875
-3.8838
Li+
-14.5135
-14.2831
Be+ -28.2278
-28.5986
B+
-48.5869
- 48.0742
C +
-74.7292
-74.0698
N+
-107.976
-107.159
O+
-148.997
-148.014
F+
-198.020
-196.886
Ne+ -254.823
-256.117
Na+ -322.487
-323.951
Mg+ -397.696
-399.351
Al+
-484.026
-482.188
Si+
-577.856
-575.823
P+
-681.456
-679.219
S+
-795.139
-792.690
Cl+
-918.981
-916.350
Ar+ -1050.703 -1053.524 -1053.520 -1053.523 -1053.530

P
-3.9864
-14.5116
-28.5960
-48.5840
-74.7258
-107.972
-148.992
-198.015
-256.112
-323.946
-399.346
-484.020
-577.850
-681.449
-795.132
-918.974

F
-3.9873
-14.5130
-28.5977
-48.5858
-74.7273
-107.973
-148.993
-198.016
-256.113
-323.947
-399.346
-484.021
-577.851
-681.450
-795.133
-918.975

f
-3.9853
-14.5105
-28.5945
-48.5827
-74.7238
-107.969
-148.990
-198.013
-256.110
-323.944
-399.344
-484.018
-577.848
-681.447
-795.129
-918.971

7

TABLE VI: Highest occupied KS eigenvalues of neutral
atoms, obtained selfconsistently from LDA and from GGA,
and LDA-based predictions of the GGA energies by means of
global and local scaling.

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

LDA
-1.1404
-0.2326
-0.4120
-0.2997
-0.4517
-0.6137
-0.5502
-0.7701
-0.9955
-0.2263
-0.3513
-0.2212
-0.3383
-0.4602
-0.4612
-0.6113
-0.7646

F
-1.2073
-0.2558
-0.4455
-0.3387
-0.5008
-0.6716
-0.5951
-0.8242
-1.0576
-0.2427
-0.3724
-0.2417
-0.3648
-0.4922
-0.4898
-0.6454
-0.8039

f
-1.2187
-0.2548
-0.4328
-0.3368
-0.5013
-0.6760
-0.6082
-0.8387
-1.0757
-0.2515
-0.3703
-0.2455
-0.3707
-0.5007
-0.4971
-0.6519
-0.8114

GGA
-1.1585
-0.2372
-0.4122
-0.2955
-0.4482
-0.6103
-0.5287
-0.7523
-0.9810
-0.2234
-0.3454
-0.2218
-0.3403
-0.4626
-0.4403
-0.5978
-0.7560

mon local potential and orthogonal orbitals at no extra
computational cost.

IV. TESTS AND APPLICATIONS TO MODELS
OF EXTENDED SYSTEMS

B. Kohn-Sham eigenvalues of atoms and ions:
LDA, GGA, Meta-GGA and SIC

In principle, a further advantage of scaled approaches,
as compared to post methods, is that the former also
provide corrections to the Kohn-Sham spectrum, which
cannot be obtained from the latter. Instead of consider-
ing the entire spectrum, we focus on the highest occupied
eigenvalue, as it is physically most signiﬁcant. Represen-
tative data for this eigenvalue are collected in Tables VI
to IX.

Unlike total energies, KS eigenvalues (single-particle
energies) are not protected by a variational principle,
and simple approximations, such as global or local scal-
ing, may work less well than for total energies. For the
transition from LDA to GGA, the data in Tables VI and
VII show indeed that not applying any scaling factor at
all, i.e., using the uncorrected LDA eigenvalues, produces
better approximations to the GGA eigenvalues than ei-
ther local or global scaling. For meta-GGA (Table VIII),
no fully selfconsistent eigenvalues are available for com-
parison (as explained in the introduction, this would re-
quire the OEP algorithm to be implemented for meta-
GGA). For PZ-SIC, on the other hand, Table IX shows
that substantial improvement on the LDA eigenvalues
is obtained by global scaling, although not by the same
margin observed for total energies.

The calculations in the preceding sections were re-
stricted to atoms and ions. Some results for molecules
were already reported in Ref. 13. We therefore next turn
to models for extended systems.

A. Hubbard model

First, we consider the Hubbard model, which is a much
studied model Hamiltonian of condensed-matter physics,
for which the basic theorems of density-functional theory
all hold.19,20,21 In the present context, this model consti-
tutes a most interesting test case for scaled selfconsis-
tency for three diﬀerent reasons: (i) It is maximally dif-
ferent from the atoms and ions considered in the previous
sections, and thus provides tests in an entirely diﬀerent
region of functional space.
(ii) For a small number of
lattice sites the exact diagonalization of the Hamiltonian
matrix in a complete basis (consisting of one orbital per
site) can be performed numerically, hence providing ex-
act data against which all approximate functionals and
implementations can be checked. (iii) In the thermody-
namic limit (inﬁnite number of sites) with equal occupa-
tion on each sites (homogeneous density distribution) the
exact many-body solution of the one-dimensional Hub-
bard model is known from the Bethe-Ansatz technique.22
This solution allows the construction of the exact local-
density approximation,19,21 which circumvents the need

TABLE VII: Highest occupied KS eigenvalues of positive ions,
obtained selfconsistently from LDA and from GGA, and LDA-
based predictions of the GGA energies by means of global and
local scaling.

atom
He+
Li+
Be+
B+
C+
N+
O+
F+
Ne+
Na+
Mg+
Al+
Si+
P+
S+
Cl+
Ar+

LDA
-3.0211
-4.3793
-1.0509
-1.4267
-1.3072
-1.6213
-1.9384
-1.9307
-2.3093
-2.6857
-0.8803
-1.0949
-0.8904
-1.1005
-1.3115
-1.3592
-1.5975

F
-3.1623
-4.5188
-1.0969
-1.4827
-1.3724
-1.6973
-2.0233
-1.9973
-2.3860
-2.7709
-0.9072
-1.1257
-0.9224
-1.1387
-1.3556
-1.3983
-1.6426

f
-3.1610
-4.5348
-1.0954
-1.4663
-1.3702
-1.6968
-2.0269
-2.0140
-2.4043
-2.7932
-0.9252
-1.1278
-0.9284
-1.1461
-1.3651
-1.4075
-1.6510

GGA
-3.0898
-4.4400
-1.0637
-1.4336
-1.3031
-1.6197
-1.9381
-1.9091
-2.2926
-2.6734
-0.8746
-1.0867
-0.8912
-1.1046
-1.3172
-1.3376
-1.5851

for analytical parametrizations of the underlying uni-
form reference data, required for the conventional LDA
of the ab initio Coulomb Hamiltonian. The simultaneous
disponibility of the exact solution and the exact LDA
makes this model an ideal test case for DFT approxima-
tions.

The one-dimensional Hubbard model is speciﬁed by

the second-quantized Hamiltonian

ˆH = −t

L

Xi,σ

(c†

iσci+1,σ + H.c.) + U

L

Xi

i↑ci↑c†
c†

i↓ci↓ (24)

deﬁned on a chain of L sites i, with one orbital per site.
Here U parametrizes the on-site interaction and t the
hopping between neighbouring sites. Below all energies
and values of U are given in multiples of t, as is common
practice in studies of the model (24).

The availability of an exact many-body solution for
small L, and of the exact LDA, permit us to eliminate
many of the uncertainties associated with more approxi-
mate calculations. To test the ideas of scaled selfconsis-
tency for the Hubbard model, we attempt to predict the
energies of a selfconsistent LDA calculation by starting
with a simple Hartree (mean-ﬁeld) calculation. Equa-
tion (13) cannot be directly applied to the xc potentials
because the xc potential of a pure Hartree calculation
is zero, but we can apply it to the entire interaction-
dependent contribution to the eﬀective potential, i.e., to
the sum of Hartree and xc terms. We thus approximate
the entire interaction potential by its Hartree contribu-
tion, and use scaled selfconsistency to predict the values

8

TABLE VIII: Highest occupied KS eigenvalues of neutral
atoms, obtained from GGA and predicted for TPSS meta-
GGA by global and local scaling.

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

GGA
-1.1585
-0.2372
-0.4122
-0.2955
-0.4482
-0.6103
-0.5287
-0.7523
-0.9810
-0.2234
-0.3454
-0.2218
-0.3403
-0.4626
-0.4403
-0.5978
-0.7560

F
-1.1767
-0.2420
-0.4192
-0.3023
-0.4566
-0.6208
-0.5356
-0.7606
-0.9912
-0.2259
-0.3486
-0.2249
-0.3443
-0.4675
-0.4444
-0.6028
-0.7618

f
-0.7159
-0.1055
-0.2249
-0.0968
-0.1763
-0.2656
-0.2585
-0.3881
-0.5245
-0.1000
-0.1841
-0.0731
-0.1364
-0.2065
-0.2202
-0.3154
-0.4140

of a Hartree+LDA calculation. In analogy to our previ-
ous equations we write this as

vGSSC(H+LDA)
int

(i) =

EH+LDA
int
EH
int[ni]

[ni]

vH (i).

(25)

Results obtained from this approximation can be com-
pared to a selfconsistent Hartree+LDA calculation, in
which

vint(i) = vH (i) + vLDA

xc

(i).

(26)

This comparison provides a severe test for the scaled
selfconsistency concept,
starting functional
as
(Hartree) is quite diﬀerent from the target functional
(Hartree+LDA).

the

The eﬀective potential vs(i) is, in principle, given by
adding vint(i) to the external potential vext(i), but here
we chose vext(i) ≡ 0, so that the interaction-dependent
contribution becomes identical to vs(i). This makes the
test even tougher, as there is no large external potential
dominating the total energy and the eigenvalues, and po-
tentially masking eﬀects of vLDA

xc
The system becomes inhomogeneous because of the ﬁ-
nite size of the chain. For L = 10 sites exact energies can
still be obtained, and are displayed, together with vari-
ous approximations to them, in Table X. For L = 100
sites obtaining exact energies is out of question, but all
DFT procedures are still easily applicable. Correspond-
ing results for total energies are also displayed in Table X.
Eigenvalues are recorded in Table XI.

(i).

From Tables X and XI we conclude that:

(i) For
ground-state energies the LDA typically deviates by

TABLE IX: Highest occupied KS eigenvalues of neutral
atoms, obtained selfconsistently from LDA and predicted for
LDA+PZSIC by means of global scaling, compared to an or-
bitally selfconsistent implementation of LDA+PZSIC.

atom
He
Li
Be
B
C
N
O
F
Ne
Na
Mg
Al
Si
P
S
Cl
Ar

LDA
-1.1404
-0.2326
-0.4120
-0.2997
-0.4517
-0.6137
-0.5502
-0.7701
-0.9955
-0.2263
-0.3513
-0.2212
-0.3383
-0.4602
-0.4612
-0.6113
-0.7646

F
-1.2370
-0.2642
-0.4575
-0.3538
-0.5219
-0.6990
-0.6195
-0.8570
-1.0991
-0.2544
-0.3875
-0.2571
-0.3844
-0.5159
-0.5116
-0.6718
-0.8348

LDA+PZSIC
-1.8957
-0.3927
-0.6554
-0.6125
-0.8512
-1.0960
-1.0627
-1.3732
-1.6838
-0.3782
-0.5502
-0.4081
-0.5717
-0.7376
-0.7696
-0.9632
-1.1586

TABLE X: Exact per-site ground-state energy (to six signiﬁ-
cant digits), selfconsistent LDA energy, selfconsistent Hartree
energy, and Hartree-based simulations of the LDA energy via
global scaling, local scaling and post-Hartree implementation.
All energies have been multiplied by −10/t. First set of three
rows: L = 10 sites with N = 2 electrons. Second set of three
rows: L = 10 sites with N = 8 electrons. Third set of three
rows: L = 100 sites with N = 96 electrons. All calculations
were done for open boundary conditions with vext = 0.

F

f

P

LDA

N U exact Hartree
2

2 3.69905 3.58412 3.68371 3.68457 3.68456 3.68472
4 3.65957 3.35102 3.62921 3.63175 3.63014 3.63239
6 3.64244 3.12796 3.60332 3.60710 3.60117 3.60815
2 8.87176 8.24130 8.81004 8.81062 8.81064 8.81067
4 7.30440 5.02351 7.13510 7.13573 7.13529 7.13574
6 6.37228 1.81375 6.11910 6.11850 6.11520 6.11918
8.02648 8.71172 8.71174 8.71174 8.71174
3.41821 6.19811 6.19806 6.19791 6.19962
-1.18994 4.74410 4.74411 4.74369 4.75018

-
-
-

8

96 2
4
6

about 1% from the exact values, while a Hartree calcula-
tion is about 10% oﬀ. (ii) Taking the selfconsistent LDA
data as standard, we ﬁnd that for ground-state energies
locally scaled selfconsistency comes closest, followed, in
this order, by post-Hartree data, globally scaled selfcon-
sistency and the original Hartree calculation.
(iii) For
eigenvalues the order changes: globally scaled selfcon-
sistency does better than locally scaled selfconsistency,

9

TABLE XI: Highest occupied Kohn-Sham eigenvalue ob-
tained from selfconsistent LDA calculations, selfconsistent
Hartree calculations, and Hartree-based simulations of the
LDA energy via global scaling (F) and local scaling (f). The
systems are the same as in Table X.

N
2

8

96

U
2
4
6
2
4
6
2
4
6

Hartree
-1.67177
-1.44839
-1.23452
-0.02259
0.77959
1.58054
0.80452
1.76435
2.72424

F
-1.76773
-1.71514
-1.69022
-0.16428
0.25307
0.50636
0.66180
1.18533
1.48818

f
-1.76999
-1.72036
-1.69737
-0.16486
0.25211
0.50562
0.66175
1.18531
1.48819

LDA
-1.74131
-1.66731
-1.63056
-0.09917
0.39835
0.68490
0.74151
1.25131
1.47135

whereas post-calculations naturally do not provide any
correction at all, and come a distant third.

We have performed similar comparisons also for other
systems (diﬀerent number of sites L, diﬀerent number of
electrons N , diﬀerent values of the on-site interaction pa-
rameter U ), but the general trend is the same, although
in isolated cases the relative quality of F, f and P-type
implementations can be diﬀerent.

In Table XII we analyse the satisfaction of the va-
lidity criteria of Sec. II C and the contribution of each
term in the ground-state-energy expression to the total
error. The values of C2 in Table XII show that the term
neglected in global scaling is always smaller than the
term kept, but in unfavorable cases, such as low density
and strong interactions, can be a sizeable fraction of it.
Hence, just as for atoms and ions, additional error can-
cellation, arising from the separate contributions to the
ground-state energy, is taking place in these situations.

These contributions to the ground-state energy can be

written as

E0 =

ǫi −

Z

Xi

d3r n(r)vint[n](r) + Eint[n]

(27)

=: EKS − Vint + Eint,

(28)

and their errors are recorded in Table XII.

The data in Table XII show that the total error is
much less than that of each contribution individually.
Global and local SSC thus beneﬁt from systematic and
extensive error compensation – mostly between the sum
of the KS eigenvalues and the interaction potential en-
ergy – which make it applicable even when the simplest
from of the validity criterium, Eq. (14), or its integrated
version, Eq. (15), are violated. Clearly, locally scaled
selfconsistence beneﬁts even more than globally scaled
selfconsistence.

TABLE XII: Validity criterium and error analysis for the sys-
tem of Tables X and XI. C2 is deﬁned in Eq. (15), and the
other columns report, for each term of the total energy ex-
pression (28), the diﬀerence between the fully selfconsistent
result and the result obtained by GSSC. The error in the to-
tal energy is given by ∆E0 = ∆EKS − ∆Vint + ∆Eint, and
always signiﬁcantly lower than each of the individual errors.
First set of nine lines: global scaling. Second set of nine lines:
local scaling. Recall that we have not deﬁned an integrated
validity criterium for local scaling.

TABLE XIII: Ground-state energies (in meV per particle)
and highest-occupied KS eigenvalue (in meV ) of a quantum
well of depth 200meV , width 10nm, embedded in a back-
ground semiconductor (charge reservoir) of width 50nm, areal
−2, eﬀective electron mass of 0.1m0
density of nA = 1012cm
and relative dielectric constant ε = 10. These parameters are
typical of semiconductor heterostructures.26,27 For the second
set of two lines we have added a central barrier of width 3nm
and hight 200meV , dividing the system in two weakly coupled
halves.

10

8

N U
2
2
4
6
2
4
6
2
4
6

96

2

8

96

2
4
6
2
4
6
2
4
6

C2
0.162
0.247
0.290
0.098
0.135
0.135
0.098
0.065
0.018

-
-
-
-
-
-
-
-
-

∆EKS
0.05285
0.09565
0.11933
0.52085
1.16243
1.42893
7.6541
6.4775
-0.7711

0.05737
0.10610
0.13363
0.52543
1.17013
1.43479
7.6551
6.4768
-0.7709

∆Vint
0.04794
0.08495
0.10522
0.51601
1.15674
1.42831
7.6531
6.4813
-0.7835

0.05526
0.10078
0.12627
0.52400
1.17090
1.44124
7.6548
6.4811
-0.7834

∆Eint
-0.00592
-0.01388
-0.01894
-0.00547
-0.00633
-0.00070
-0.0012
-0.0113
-0.0731

-0.00227
-0.00596
-0.00841
-0.00148
0.00075
0.00577
-0.0003
-0.0114
-0.0731

∆E0
-0.00101
-0.00318
-0.00483
-0.00063
-0.00064
-0.00008
-0.0002
-0.0151
-0.0608

-0.00016
-0.00064
-0.00105
-0.00005
-0.00002
-0.00068
0.0000
-0.0156
-0.0607

B. Quantum wells

Moving up from one dimension to three, we next con-
sider semiconductor heterostructures. To illustrate the
main features of scaled selfconsistency we consider a sim-
ple quantum well, in which the electrons are free to move
along the x and y direction, but conﬁned along the z di-
rection. The modelling of such quantum wells by means
of the eﬀective-mass approximation within DFT is de-
scribed in Ref. 23 and the particular approach we use is
that of Ref. 24, whose treatment we follow closely, and
to which we refer the reader for more details.

In Table XIII we display ground-state energies and
highest occupied KS eigenvalue obtained for represen-
tative quantum wells by means of a selfconsistent LDA
calculation (using the PW9225 parametrization for the
electron-liquid correlation energy), a selfconsistent GGA
calculation (using the PBE15 form of the GGA), post-
LDA GGA, and globally-scaled and locally-scaled simu-
lations of PBE by means of LDA.

Total energy diﬀerences between all three approximate
schemes are marginal, compared to the diﬀerence be-
tween a pure LDA calculation and a GGA calculation: all
three LDA-based schemes closely approximate the results

LDA(PW92)
78.0197
117.455
129.134
163.322

F
77.7135
117.060
128.435
162.420

f
77.7194
116.993
128.443
162.375

P
77.7136
117.455
128.436
163.322

GGA(PBE)
77.7122
117.183
128.426
162.706

E
ǫ
E
ǫ

of selfconsistent GGA calculations, with global scaling
slightly better than the other two. Interestingly, this is
the opposite trend observed in the Hubbard chain, where
local scaling was best. For eigenvalues, post-calculations
do not provide any improvement, whereas both global
and local scaling come close to the fully selfconsistent
results.

In Table XIV we show the values of C2, and the break-
down of the error of the ground-state energy in its com-
ponents, according to

E0[n] =

ǫi − EH [n] −

Xi

d3r n(r)vxc(r) + Exc[n](29)

Z

= EKS − EH [n] − Vxc + Exc[n].(30)

The GSSC validity criterium (15) is well satisﬁed. Val-
ues of C2 are an order of magnitude smaller than for the
Hubbard chain. This reduction expresses the fact that
simulating a GGA by starting from an LDA is a much
easier task than simulating an LDA by starting from a
Hartree calculation. Also understandable are the slightly
larger values of C2 and of the errors in the energy found
for the double well as compared to the single well, since
this structure has more pronounced density gradients,
enhancing the diﬀerence between LDA and GGA, and
complicating the task the scaling factor has to accom-
plish.

For the energy components, we observe the same type
of substantial error cancellation found also in the calcu-
lations for atoms, ions and the Hubbard model, resulting
in very good total energies. We note that this error can-
cellation is taking place mainly between the sum of the
KS eigenvalues and the potential energy in the xc po-
tential, whose errors are subtracted in forming E0. The
errors in the xc and the Hartree energies are orders of
magnitude smaller. This is the same observation previ-
ously made for the other systems, suggesting that this
pattern of error cancellation is a general trend.

TABLE XIV: Error analysis for the heterostructures of Ta-
ble XIII. First set of two lines: simple well. Second set of
two lines: well with barrier. The total error is obtained as
∆E0 = ∆EKS − ∆EH − ∆Vxc + ∆Exc. Very substantial error
cancellation between the sum of the KS eigenvalues and the
xc potential energy is taking place.

C2

GSSC 0.022
LSSC
GSSC 0.036
LSSC

-

-

∆EKS
-0.1232
-0.1904
-0.237
-0.289

∆EH
-0.0129
-0.0953
0.036
-0.032

∆Vxc
-0.1056
-0.0703
-0.248
-0.216

∆Exc
0.0061
0.0321
0.035
0.058

∆E0
0.0013
0.0072
0.010
0.017

V. CONCLUSIONS

Three diﬀerent possibilities for approximating the
results of selfconsistent calculations with a compli-
cated functional by means of selfconsistent calculations
with a simpler functional have been compared: Post-
selfconsistent implementation of the complicated func-
tional (P), global scaling of the potential of the simple
functional by the ratio of the energies (F), and local scal-
ing of the potential of the simple functional by the ratio
of the energy densities (f). While method P is a stan-
dard procedure of DFT, method F was proposed only
very recently (and without a solid derivation or a valid-
ity criterium, both of which we provide here). Method f
is proposed here for the ﬁrst time.

These three approaches were tested for atoms, ions,
Hubbard chains and quantum wells, and applied to
Hartree, LDA, GGA, meta-GGA and SIC type density
functionals. Our conclusions are summarized as follows.
(i) All three prescriptions provide signiﬁcant improve-
ments on the total ground-state energies obtained from
the simple functional (as measured by their proximity to
those obtained selfconsistently from the complex func-
tional). For these energies, on average, globally scaled
selfconsistency has a slight advantage compared to post-
selfconsistent implementations and local scaling, but the
relative performance of all three methods depends on ﬁne
details of the system parameters, on the quantity cal-
culated, and on the particular density functional used.
In general, neither local scaling nor alternative scaling
schemes (employing other scaling factors, or scaling other
contributions to the energy) provide consistent improve-

∗ Electronic address: capelle@ifsc.usp.br
1 W. Kohn, Rev. Mod. Phys. 71, 1253 (1999).
2 R. M. Dreizler and E. K. U. Gross, Density Functional

Theory (Springer, Berlin, 1990).

3 R. G. Parr and W. Yang, Density-Functional Theory of
Atoms and Molecules (Oxford University Press, Oxford,
1989).

4 J. P. Perdew, A. Ruzsinszky, J. Tao, V. N. Staroverov, G.

11

ments on global scaling, which for total energies is, on
average, the best of all methods tested here.

(ii) An additional advantage of scaled selfconsistency
is that it also provides approximations to the eigenvalues,
eigenfunctions and eﬀective potentials of the complicated
functional, which is by construction impossible for post-
methods. Indeed, for orbital-dependent potentials, such
as PZ-SIC, scaling provides a simple and eﬀective way
to produce a common local potential and orthogonal or-
bitals. For models of extended systems, scaling provides
signiﬁcant improvement on eigenvalues obtained from the
simple functional, although by a smaller margin than for
the total energy. For ﬁnite systems, similar improvement
was found in applications of PZ-SIC, but not in tests
trying to predict GGA eigenvalues from LDA.

(iii) The reason scaled selfconsistency works is due to
an interplay of three distinct mechanisms. First, when-
ever the term neglected in Eq. (12) is much smaller than
the term kept, its neglect is obviously a good approx-
imation. This is checked by the point-wise criterium
(14). Second, even when the neglected term is not much
smaller, quantities that depend on the potential at all
points in space, such as the total energies or the eigen-
values, beneﬁt from error cancellation arising from dif-
ferent points in space, as described by the integrated cri-
terium (15). Total energies — but not eigenvalues — also
beneﬁt from an additional error cancellation between the
diﬀerent contributions to the total energy expression of
DFT. Numerically, we found this third mechanism to be
dominant. The fact that this additional error cancella-
tion operates only for total energies explains why in all
our tests these are consistently better described by scaled
selfconsistency than eigenvalues.

Diﬀerent scaling schemes from the two employed here
may be investigated, and certainly additional informa-
tion from application to still other classes of systems
should be useful, but it seems safe to conclude from the
present analysis that scaled selfconsistency is a most use-
ful concept for density-functional theory, allowing the ef-
ﬁcient and reliable implementation of density functionals
of hitherto unprecedented complexity, without ever re-
quiring their variational derivative with respect to either
orbitals or densities.

Acknowledgments This work was supported by

FAPESP and CNPq.

E. Scuseria and G. I. Csonka, J. Chem. Phys. 123, 062201
(2005). P. Ziesche, S. Kurth and J. P. Perdew, Comp. Mat.
Sci. 11, 122 (1998).

5 T. Grabo, T. Kreibich, S. Kurth and E. K. U. Gross, in
V. I. Anisimov (Ed.), Strong Coulomb Correlations in Elec-
tronic Structure Calculations: Beyond the Local Density
Approximation (Gordon & Breach, 1999). T. Grabo and
E. K. U. Gross, Int. J. Quantum Chem. 64, 95 (1997).

T. Grabo and E. K. U. Gross, Chem. Phys. Lett. 240, 141
(1995). E. Engel and S. H. Vosko, Phys. Rev. A 47, 2800
(1993).

6 J. B. Krieger, Y. Li and G. J. Iafrate, Phys. Rev. A 45,

101 (1992); ibid 46, 5453 (1992); ibid 47 165 (1993).

7 S. K¨ummel and J. P. Perdew, Phys. Rev. B 68, 035103

(2003).

8 W. Yang and Q. Qu, Phys. Rev. Lett. 89, 143002 (2002).
9 V. N. Staroverov, G. E. Scuseria and E. R. Davidson, J.

Chem. Phys. 124, 141103 (2006).

10 R. Neumann, R. H. Nobes and N. C. Handy, Mol. Phys.

87, 1 (1996).

11 V. N. Staroverov, G. E. Scuseria, J. Tao and J. P. Perdew,

J. Chem. Phys. 119, 12129 (2003).

12 V. N. Staroverov, G. E. Scuseria, J. Tao and J. P. Perdew,

Phys. Rev. B 69, 075102 (2004).

13 M. Caﬁero and C. Gonzalez, Phys. Rev. A 71, 042505

(2005).

14 J. P. Perdew and A. Zunger, Phys. Rev. B 23, 5048 (1981).
15 J. P. Perdew, K. Burke and M. Ernzerhof, Phys. Rev.
Lett. 77, 3865 (1996). ibid 78, 1396(E) (1997). See also
V. Staroverov et al., Phys. Rev. A 74, 044501 (2006).
16 J. Tao, J. P. Perdew, V. N. Staroverov and G. E. Scuseria,

12

Phys. Rev. Lett. 91, 146401 (2003).

17 J. P. Perdew, J. Tao, V. N. Staroverov and G. E. Scuseria,

J. Chem. Phys. 120, 6898 (2004).

18 M. R. Norman and D. D. Koelling, Phys. Rev. B 30, 5530

(1984).

19 K. Sch¨onhammer, O. Gunnarsson, and R. M. Noack, Phys.

Rev. B 52, 2504 (1995).

20 N. A. Lima, M. F. Silva, L. N. Oliveira and K. Capelle,

Phys. Rev. Lett. 90, 146402 (2003).

21 G. Xianlong, M. Polini, M. P. Tosi, V. L. Campo, Jr., K.
Capelle and M. Rigol, Phys. Rev. B 73, 165120 (2006).
22 E. H. Lieb and F. Y. Wu, Phys. Rev. Lett. 20, 1445 (1968).
23 T. Ando and S. Mori, J. Phys. Soc. Jpn. 47, 1518 (1976).
24 H. J. P. Freire and J. C. Egues, Braz. J. Phys. 34, 614

(2004).

25 J. P. Perdew and Y. Wang, Phys. Rev. B 45, 13244 (1992).
26 Z. I. Alferov, Rev. Mod. Phys. 73, 767 (2001).
27 Landolt-B¨ornstein: Numerical Data and Functional Re-
lationships in Science and Technology, New Series, Vol.
17, Semiconductors, eds. O. Madelung, M. Schulz and H.
Weiss. (Springer, Berlin 1982)."
Thermodynamic Theory of Sintering and Swelling,"  The General Thermodynamic Theory of Sintering, formulated by the author in
1998 is given. This theory is applied to the problem of swelling of materials
under conditions of radiation. Driving forces, caused by the presence of the
evolution of heat in the volume of a sample (electric contact, hf, inductive
heating or penetrating radiation, e.g., neutrons could be the sources of the
heat in the bulk of a sample) are considered. The influence of these driving
forces on sintering, structure and properties is discussed. The role of mobile
and immobile dislocations, grain boundaries, and pores is regarded. Cycling and
pulsing regimes of sintering are investigated. A mesoscopic approach, described
in present paper, which had been used for years to solve sintering problems,
also could help solving problems of nucleation, decomposition, and other
problems in the theory of alloys. Described relaxation time technique could
help simplifying calculations and give more clear physical picture. Bulks
heating driving forces, important for small size objects of microelectronics
or/and heat evolving elements in nuclear reactors, are important also for the
problems of nucleation and decomposition in these objects.
",http://arxiv.org/pdf/cond-mat/0701743v1,3,"Thermodynamic Theory of Sintering and Swelling 

Yuri Kornyushin

Maître Jean Brunschvig Research Unit, 
Chalet Shalva, 
Randogne, CH-3975 

The General Thermodynamic Theory of Sintering, formulated by the author in 1998 is 
given. This theory is applied to the problem of swelling of materials under conditions 
of  radiation.  Driving  forces,  caused  by  the  presence  of  the  evolution  of  heat  in  the 
volume  of  a  sample  (electric  contact,  hf,  inductive  heating  or  penetrating  radiation, 
e.g., neutrons could be the sources of the heat in the bulk of a sample) are considered. 
The  influence  of  these  driving  forces  on  sintering,  structure  and  properties  is 
discussed. The role of mobile and immobile dislocations, grain boundaries, and pores 
is regarded. Cycling and pulsing regimes of sintering are investigated. A mesoscopic 
approach, described in present paper, which had been used for years to solve sintering 
problems,  also  could  help  solving problems  of  nucleation, decomposition,  and  other 
problems  in  the  theory  of  alloys.  Described  relaxation  time  technique  could  help 
simplifying  calculations  and  give  more  clear  physical  picture.  Bulks heating  driving 
forces,  important  for  small  size  objects  of  microelectronics  or/and  heat  evolving 
elements  in  nuclear  reactors,  are  important  also  for  the  problems  of  nucleation  and 
decomposition in these objects. 

Keywords: driving forces, bulk heating, pores, grain boundaries, dislocations. 

1. INTRODUCTION 

Directions  and  rates  of  diffusional  processes  of  mass  transfer  are  important 
constituents of the process of sintering. The thermodynamic driving forces and kinetic 
characteristics of a system determine them. Kinetic characteristics include magnitudes 
of  kinetic  coefficients,  e.g.,  diffusion  coefficient,  and  conditions  of  realization  of 
different  mass  transfer  mechanisms.  A  vacancy  mechanism  of  mass  transfer  is  a 
regular one in crystalline materials. The mean free path of the excess vacancy, which 
is  determined  by  the  defect  structure  of  a  material  and  by  the  distance  from  a  free 
surface, governs essentially the rates of diffusional processes. 

The  process  of  sintering  is  usually  considered  to  consist  of  three  parts  [1].  The 
initial  stage  of  sintering  is  usually  regarded  to  be  determined  by  the  processes  of 
connection of separate particles, and a regrouping; plastic deformation and boundary 
diffusion play a leading role during this stage, while the contribution of bulk diffusion 
is negligible. Boundary diffusion approximation is justified in the temperature interval 
where the boundary mass transfer is dominant over the one in the bulk of a crystal. 
The intermediate stage is the most complicated one. The final stage is characterized 
by the presence of isolated pores in a sample. Kinetics of a pore system in this stage is 
controlled by mass transfer along grain boundaries and dislocation lines (if available) 
at lower temperatures and by bulk mass transfer mechanisms at higher temperatures. 

 
 
 
 
 
 
 
 
 
  Remaining  after  the  final  stage,  isolated  pores  influence  physical-mechanical 
properties of a product undesirably in the majority of cases. Arising after coagulation, 
large  pores  are  usually  especially  harmful  and  their  removal  is  especially  difficult. 
Electro-physical  technologies,  such  as  electric  contact,  hf,  inductive  heating,  enable 
overcoming of such difficulties in a series of cases [2]. 

The  author  had  formulated  the  General  Thermodynamic  Theory  of  Sintering  in 
1998 [3, 4]. In the present paper the author describes this theory and applies it to the 
problem of swelling. 

2. BULK HEATING  

It was predicted theoretically that the evolution of heat in the bulk of a sample (e.g., 
Joule heat) leads to specific driving forces of diffusional processes [5, 6]. The sources 
of these driving forces are divergent temperature gradients, arising as a result of the 
bulk  heating  of  a  sample  (as  the  heat,  evolving  in  the  bulk  of  a  sample  has  to  be 
extracted  out  of  a  sample,  the  temperature,  T,  appears  to  be  higher  in  the  bulk  of  a 
sample compared to the temperature of the surface of a sample) [2, 5, 6]. Fig. 1 shows 
temperature gradients, arising during bulk heating process when average temperature 
of a sample stays unchanged. 

Fig. 1. Heat flow out of a sample during bulk heating process (the sample averaged 
temperature is assumed to be fixed). 

Fixed sample averaged temperature assumes that the amount of heat evolving in a 

sample is equal to the amount of heat being extracted out of a sample. 

2.1. Driving Forces 

The temperature gradient causes the thermal diffusion flux of vacancies, 

J = −kT (D/〈T 〉 )gradT,                                                    (1) 

where  kT  is  the  thermal  diffusion  ratio,  D  =  D(〈T〉 )  is  the  diffusion  coefficient,  and 
〈T 〉  is the temperature of a sample averaged over its volume. 

Eq.  (1)  is  a  linear  approximation,  which  is  applicable  when  the  temperature 

gradient is smooth enough and small enough, which is the case. 

 
 
 
 
 
 
 
 
 
 
Eq.  (1)  determines  the  additional  number  of  vacancies  leaving  unit  volume  of  a 

material per unit time due to the regarded driving forces: 

nt = divJ = −DkT ∆T/〈T〉 = DkT (q − cTt)/κ〈T〉,                          (2) 

where q is the heat production per unit volume of a material per unit time (in the case 
of  ohmic  heating  this  is  the  Joule  heat,  q  =  σE2,  where  σ  is  the  specific  electric 
conductivity,  E  is  the  intensity  of  the  effective  electric  field),  c  is  the  heat  capacity 
(per  unit  volume),  Tt  =  (∂T/∂t)  is  the  heating  (cooling)  rate,  and  κ  is  the  thermal 
conductivity coefficient. 

To obtain Eq. (2), the equation of the heat flow, 

κ∆T = (cTt  − q),                                                    (3) 

was used [2]. 

The thermal diffusion ratio, kT, is determined by the formula [2], 

kT = Ne(u − um)/kT,                                                 (4) 

where Ne is the mean equilibrium number of vacancies per unit volume of a material 
at  temperature  T,  u  is  the  vacancy  formation  enthalpy  for  the  given  process  of 
diffusional transport (e.g., in the case of the transport of vacancies from the cores of 
dislocations  to  the  plane  surface  of  a  sample,  u  =  ud  is  the  enthalpy  of  vacancy 
formation  on  dislocations),  um  is  the  enthalpy  of  vacancy  migration,  and  k  is 
Boltzmann constant. 

The contribution of specific driving forces, arising from bulk heating is the most 
important  at  the  isothermal  regime,  when Tt  = 0, and at large enough values of the 
power,  q,  being  introduced  into  the  bulk  of  a  material.  Such  conditions  are  readily 
fulfilled  during  sintering  of  thin  or  miniature samples, when heat emission from the 
surface contributes essentially to the heat balance. This contribution may be decisive 
during  ohmic  sintering  of  metallic  samples  thinner  than  1  mm.  In  this  case  electric 
field intensities, E, of the order of 1 V/cm and larger may be applied [7]. Under these 
conditions  healing  of  large  pores  differs  very  significantly  from  that  during 
conventional  (furnace)  sintering.  This  follows  from  the  fact  that  the  contribution  of 
the  specific  driving  forces  accordingly  to  Eq.  (2)  does  not  depend  on  the  nature  of 
defects, and, in particular, on the pore size. However, the Laplace forces increase with 
decreasing  pore  size  [1,  2],  thus  reducing  the  relative  contribution  of  bulk  heating 
driving forces to the process of pore healing. 

In  some  cases  it  is  worthwhile  to  intensify  surface  heat  emission  (to  cool  the 
surface of a sample). In this case the value of q can be increased and the time required 
to complete the diffusional process is reduced concomitantly. As a result, the energy 
required  to  complete  the  process  is  smaller  than  that  during  conventional  sintering. 
One  ought  to  take  into  account  the  advantages  of  more  compact  and  energy-saving 
equipment  in  the  case  of  ohmic  or  hf  sintering  as  compared  to  using  a  traditional 
furnace. 

2.2. Initial Stages of Bulk Heating Sintering 

 
 
 
 
 
 
 
 
 
 
 
 
 
The  very  first  stages  of  electric  sintering  are  essentially  non-stationary  ones. 
Evolution  of  Joule  heat  during  the  very  first  moments  of  electric  sintering  leads  to 
sharp temperature differences. Such an essentially non-stationary regime of heat and 
mass  transfer  can  only  be  described  by  an  essentially  non-linear  theory.  A  similar 
situation  arises  when  sintering  is  caused  by  electric  discharge  [8].  Here  we  shall 
consider early, but not the very first, stages of electric sintering [9]. The temperature 
gradients  are  considered  to  be  small,  and  linear  approximation  is  assumed  to  be 
applicable.  Boundary  diffusion  is  regarded  to  be  the  main  mechanism  of  mass 
transfer. In this case the number of atoms, leaving one contact per unit time on one 
particle, Nat, is described by the integral of (Ja,n) along the closed path, surrounding 
the contact (here Ja is the atomic flux, and n is the unit vector, perpendicular to the 
path).  The  line  integral  around  the  closed  path  can  be  transformed  to  the  surface 
integral of divJa (the integral is extended over the surface of a contact). The processes 
of  mass  transfer  during  electric  sintering  are  much  faster  than  those,  arising  due  to 
surface  tension  forces  in  the  course  of  conventional  sintering.  This  means  that  the 
influence of surface tension forces is often negligible during electric sintering. In this 
case the surface flux of the atoms, Ja, can be expressed as 

Ja = −Db(kTb/〈T 〉 )gradT,                                                 (5) 

where  Db  is  the  boundary  diffusion  coefficient,  and  kTb  is  a  boundary  thermal 
diffusion ratio for atom. 

Let us the consider Joule heating under isothermal conditions. When a component 
of the temperature gradient, perpendicular to the boundary is not taken into account, 
the number of atoms, leaving the contact area on a single grain per unit time is given 
by the following expression: 

Na = DbσE2skTb/κ〈T 〉 ,                                                 (6) 

where σ, E, κ are local electric conductivity, electric field, thermal conductivity on the 
contact, and s is the area of the contact. 

If perpendicular to the boundary component of the temperature gradient is taken 
into account, the right-hand part of Eq. (6) acquires an inessential factor of the order 
of unity. 
  As  the  current  passes  two  contacts  in  each  particle,  we  have  for  the  rate  of  the 
process: 

−Vt = 2vaNat = 2DbσE2kTbva s(t)/κ〈T 〉 ,                                (7) 

where V is the volume of a sample per number of constituting particles, and va is the 
atomic volume. 

 
 
 
 
 
 
 
 
Fig. 2. Model of a contact for the early stages of electric contact sintering. 

Let  us  consider  now  a  model  of  identical  particles  of  an  initial  radius  R0.  To 
simplify the calculations let us assume that after pressing and during the considered 
early  period  of  sintering  each  particle  is  a  cubically  symmetric  figure,  formed  by  a 
sphere  of  a  radius  R(t),  of  which  6  segments  are  cut  off  by  planes  (see  Fig.  2).  We 
assume that at the early stages of sintering s(t) is essentially smaller than R 2 , although 
in  real  powder  systems  s(t)  and  R 2   are  often  of  the  same  order  of  magnitude.  This 
model is justified, because the contribution of the regular diffusional processes to the 
sintering and to the shape of the contact is negligible. For the sake of simplicity of the 
model the anisotropy, arising due to the electric current is not taken into account. 

In the first approximation on [s(t)/R 2 ] small parameter we get that 

V = 8R0

3 − (22/π)R0s.                                                   (8) 

Eq. (7) and (8) yield 

(V0 − V ) t = A(V0 − V ) , A = πDbσE2kTbva/11R0κ〈T 〉 , V0 = 8R 0

3,            (9) 

where V0 is the initial volume of a sample per one particle. 

Eq. (9) yields 

V(t) = V0 − (22/π) R0s(0)expAt.                                    (10) 

  As follows from Eq. (10), the shrinkage kinetics equation has a form, 

[V(0) − V(t)]/V(0) ≡ δV(t)/V(0) = [33s(0)/2π 2R0

2][(expAt) − 1].         (11) 

It is worthwhile to note that Eq. (11) is applicable as far as its right-hand part is 
essentially smaller than the maximum possible value of shrinkage, which is assumed 
to  be  essentially  smaller  than  unity.  Fig.  3  shows  the  dependence  of  a  relative 
shrinkage, δV(t)/V(0), on time, t, for the early stages of electric contact sintering. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3. Sample relative shrinkage dependence on time (early stages of electric contact 
sintering) 

Eq.  (11)  was  obtained  under  the  assumption  that  parameter  A  has  not  changed 
during the regarded process. This assumption is valid when heat evolution, q, and also 
the effective electric field, E, do not change during this process. During initial stages 
2, the contribution of the contacts into electric 
of electric sintering and when s(t) « R0
resistance of a sample is the main one, and therefore the effective electric field in the 
contacts  remains  practically  unchanged  during  the  regarded  process.  Changes  in  the 
effective electric field, E, during the regarded initial stages of electric sintering could 
be  taken  into  account  by  retaining  the  second  and  higher  powers  of  the  small 
parameter, [s(t)/R0

2], when performing  calculations. 

2.3. Final Stages of Bulk Heating Sintering 

Let us consider processes determined by diffusion of vacancies through the bulk of a 
material. Let us assume that our sample contains several ensembles of sources (sinks) 
of  vacancies,  which  are  identical  in  each  given  ensemble.  Each  i-th  ensemble  is 
characterized by its own equilibrium value of vacancy concentration, Nei, an enthalpy 
of  the  vacancy  formation  on  any  source  (sink)  of  the  ensemble, ui,  and  a  relaxation 
time  of  the  number  of  vacancies  to  their  equilibrium  value,  τi.  In  this  case  in  a 
stationary regime the continuity equation for vacancies can be written as follows: 

divJ + Σi[(N − Nei)/τi] = 0,                                           (12) 

where N is the vacancy concentration, and the vacancy flux, J, is as follows: 

J = −D gradN + kTa(D/〈T〉 )gradT,                                    (13) 

where kTa is the thermal diffusion ratio for the atoms. 
  When  (ui  −  uj)  «  kT,  and  a  linear  approximation  of  the  transport  theory  is 
applicable,  the  equation  for  the  excess  vacancies  concentration,  ni  =  N  −  Nei,  is  as 
follows: 

 
 
 
 
 
 
 
 
 
 
[∆ − Σj(1/Dτj)]ni = (σE2kT /κ〈T 〉 ) + NeΣj[(uj − ui)/Dτjk〈T 〉 ],               (14) 

where the thermal diffusion ratio for the vacancies, 

kT = (Neu/k〈T 〉 ) − kTa.                                          (15) 

In a simple atomic theory [10] Eq. (4) takes place, which may be written here as 

follows: 

kT = Ne(u − u m)/k〈T 〉 .                                           (16) 

The quantity (Dτi)1/2 has the meaning of a mean free path of the excess vacancy, 

〈l〉, in the bulk of a material related to the i-th type sinks. 

The rate of the diffusional changes of the i-th type sources (sinks) is proportional 
to ni. For example, for pores, the rate of changes in the pore volume of pores of the i-
th type, (vi)t, is described by the following relationship: 

(vi)t = ni/N0npiτi ,                                             (17) 

where  N0  is  the  number  of  the  atoms  in  the  unit  volume  of  a  material,  npi  is  the 
number of pores of the i-th type in the unit volume.  

The  quantity  ni  is  proportional  to  the  right-hand  part  of  Eq.  (14),  E,  and  other 
parameters,  which  determine  the  value  and  sign  of  it.  In  the  bulk  of  a  material  the 
Laplacean  in  the  left-hand  part  of  the  Eq.  (14)  can  be  neglected  and  thus  ni  can  be 
determined without solving the differential equation of the second order. 

For a pore of the i-th type, when the pressure inside the pore and external pressure 

are neglected [1, 2], we have: 

ui = u0 − (2γ/ riN0),                                          (18) 

where  u0  is  the  enthalpy  of  the  vacancy  formation  on  the  plane  surface,  γ  is  the 
specific surface energy, and ri is the pore radius. 

The  enthalpy  of  vacancy  formation  on  smaller  sized  pores  is  lower  [1,  2]. 
According to this at E = 0 Eqs. (14) and (18) describe the process of coagulation of 
small  pores  into  large  ones  [2  –  4].  It  follows  from  Eq.  (14)  that  the  pores  of 
ensembles,  which  right-hand  part  of  Eq.  (14)  is  positive,  shrink,  and  these  are  the 
ensembles of smaller pores [2]. The condition of pore healing is as follows: 

ri < r* ≡ Σj{1/τj {[Σk′(1/rkτk)] − (σE2kTN0kD/2γκNe)}},            (19) 

where Σk′ denotes a summation over the ensembles of pores only. Only pores with a 
radius smaller than r* are being healed. 
  At kT > 0 r* increases monotonically with the increase in E, going asymptotically 
to infinity when E → E*, 

E* ≡ [2γκNeΣk′(1/rkτk)/kDσkTN0]1/2.                            (20) 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  At E ≥ E*, according to Eq. (19), no pore can grow. 

Eq. (19) can be represented in another form: 

E > Ei ≡ {(2γκNe/kDσk T N 0)⏐[Σk′(ri − rk)/ri rkτk] − (1/ri)Σk″(1/τk)⏐}1/2,      (21) 

where Σk″ denotes a summation over all ensembles of sinks and sources without the 
ensemble of pores. 
  At  kT  >  0  Eq.  (21)  determines  the  field  value,  Ei,  which  is  sufficient  to  cause 
shrinking of the pores of the i-th ensemble. 

2.3.1. The Role of the Mobile and Immobile Dislocations  
This role was considered in [11]. Eq. (14) shows that the rates of diffusional processes 
are  determined  essentially  by  the  differences  in  vacancy  formation  enthalpies  on 
different  types  of  sources  (sinks)  and  by  mean  free  paths  of  excess  vacancies  in 
respect to different ensembles of sources (sinks), (Dτi)1/2. The greater the number of 
sources  (sinks),  present  in  a  crystal,  the  smaller  the  mean  free  path  of  an  excess 
vacancy and the higher the rate of diffusional processes [12]. 
  Dislocations are typical sources (sinks) of vacancies in a crystal. However, when 
the  density  of  dislocations  increases,  many  segments  of  dislocations,  blocked  by 
intersections  with  another  dislocation  lines,  are  formed  (see  Fig.  4).  Such  segments 
cannot serve as sources (sinks) for a considerable while, as their function as sources 
(sinks) results in bending of the segments between the points of the intersections, and 
therefore  to  the  increase  in  the  enthalpy  of  vacancy  formation  on  the  regarded 
segment  of  the  dislocation  (impurity  atoms  play,  obviously,  an  important  role  in 
immobilizing of intersection points). That is why only thermally mobile dislocations 
should  be  taken  into  account  as  possible  sources  (sinks)  of  vacancies.  Now  let  us 
calculate the density of thermally mobile dislocations [11]. 

Fig. 4. Mobile and immobile dislocations. 

Let us consider randomly distributed linear dislocations, parallel to the Descartes’ 
coordinates.  Let  the  densities  of  dislocations  of  each  of  the  three  directions  be  the 
same  and  equal  to  1/3  of  the  total  density,  nd.  Let  us  approximate  a  line  of  a 

 
 
 
 
 
 
 
dislocation by a square cylinder with a base side, b, (b is of the order of magnitude of 
the  Burgers  vector),  and  a  grain  (in  the  case of a single crystal - the sample) - by a 
cube  with  a  rib,  L.  Let  us  regard  some  dislocation  and  some  intersection  point. 
Obviously, the next intersection point can be found at the distance between x and x + 
dx with the probability, 

w(x)d x  = [1 − (xb/L2)]2nd LL/3(2nd bL2d x /3L2).                     (22) 

Taking into account that 2ndL2 » 3, one can calculate the number of segments of 

the length between x and x + dx: (2/3)ndbL[exp(−2/3)ndbx](2/3)ndbdx. 

Let us assume that the segments shorter than some characteristic length, l, (x ≤ l) 
cannot serve as sources (sinks) in the regarded diffusional process. The total length of 
such segments on one dislocation can be calculated. For this the number of segments 
of the length between x and x + dx should be multiplied by x and integrated from 0 to 
l. The result is: L{1 − [1 + (2/3)ndbl ] exp[−(2/3)nd b l]}. 

The ratio of this length to the length of the dislocation, L, is a relative density of 
thermally  immobile  dislocations.  Therefore  for  the  density  of  thermally  mobile 
dislocations, nd t , we have: 

ndt = nd[1 + (2/3)ndbl ] exp[−(2/3)ndbl ] .                               (23) 

  Obviously,  ndt  ≈  nd  at  2ndbl  «  3;  then,  with  the  increase  in  ndbl,  ndt  achieves  a 
maximum at nd = nm, and after that ndt decays exponentially with further increase in 
ndbl (see Fig. 5). The value of the maximum, ntm = 1.26/bl, is achieved at nd = nm = 
2.43/bl. 

Fig. 5. Thermally mobile dislocations density, ndt, as a function of general dislocation 
density, nd. 

The density of thermally mobile dislocations, arising in the process of annealing 
of  deformed  bcc  iron,  containing  a  small  amount  of  impurities,  was  measured  (see 
[13]). At nd = 3×1011 cm−2, the mobile dislocation density, ndt, was 1011 cm−2. With 
these  data  values  Eq.  (23)  yields  bl  =  1.145×10−11  cm2.  At  b  =  3×10−8  cm  this 
corresponds  to  l  =  3.8×10−4  cm.  The  maximum  density  of  thermally  mobile 
dislocations,  ntm,  is  1.1×1011  cm−2  at  nm  =  2.22×1011  cm−2.  It  is  worthwhile  to  note 

 
 
 
 
 
 
 
 
 
 
that  in  the  regarded  case  the  maximum  is  a  rather  pronounced  one.  At  10−11nd  =  1, 
2.22, 3, and 6, 10−10ndt were 8.2, 11, 10, and 3.4. 

So,  when  the  intersection  points  of  the  dislocation  lines  are  pinned  by,  e.g., 
impurity atoms, an optimal dislocation density exists at which the density of thermally 
mobile dislocations is of a maximum value and the rates of diffusional processes also 
have maximum values. The diffusional stage of the process of sintering is one of such 
processes. 

2.3.2. Calculation of Relaxation Parameters.  
In  order  to  calculate  the  relaxation  parameters,  let  us  consider  a  case  when  there  is 
only  one  type  of  sources  (sinks)  of  vacancies  in  a  crystal  and  there  is  a 
macroscopically homogeneous excess of the vacancy concentration in a sample. It is 
assumed  that  the  vacancy  concentration  in  the  vicinity  of  the  sources  (sinks)  has  an 
equilibrium  value.  The  coordinate  dependence  of  the  vacancy  concentration  around 
the given source (sink), in the domain of its influence (drainage basin), is determined 
by  the  stationary  distribution,  that  is,  by  the  Laplace  equation.  The  relaxation 
parameter, 1/Dτ, will be further calculated for some typical sorts of sources (sinks) of 
vacancies (see, e.g., [12]). 

Fig. 6. Model of a grain and its boundary as a sink. 

Grain boundaries. Let us approximate a grain by a ball (see Fig. 6) of a diameter d, 
and a microscopic dependence of the vacancy concentration in the vicinity of a grain 
boundary, N, on the distance from the center of a grain, r, by the following equation: 

N = Ne + (a/r) − (2a/d ) ,                                             (24) 

where a is some constant. 

Then  the  vacancy  flux  near  the  grain  boundary  is  4aD/d2,  and  the  number  of 
vacancies, coming to a grain boundary per unit time, and calculated per unit volume, 
is 24aD/d  3, which, on the other hand, may be written as (〈N 〉 − Ne)/τ = a/dτ. From 
this follows that 1/Dτ = 24/d 2 for grain boundaries, which means that the mean free 
path of the excess vacancy inside a grain with respect to the grain boundary is about 
lgb = 0.2d. 

 
 
 
 
 
 
 
Fig. 7. Model of a pore as a sink. Drainage basin is plotted by a dotted line. 

Pores. Let us consider an ensemble of identical homogeneously distributed spherical 
pores  (see  Fig.  7)  of  a  radius,  r0,  and  a  pore  concentration,  np.  The  porosity  is 
assumed  to  be  small.  This  allows  us  to  approximate  a  drainage  basin  of  a  pore,  a 
volume of influence of each pore (a volume from which a given pore attracts excess 
−1/3,  and  to  approximate  a  microscopic 
vacancies),  by  a  sphere  of  a  radius  0.62np
dependence of the vacancy concentration on the distance from the center of the pore, 
r, as 

N = Ne + (a/r0) − (a/r).                                               (25) 

The  vacancy  flux  near  the  surface  of  a  pore  is  aD/r0

2,  and  the  number  of 
vacancies,  coming  to  the  surface  of  pores  per  unit  time,  and  calculated  per  unit 
volume, is 4πa Dnp, which, on the other hand, may be written as (〈N 〉 − Ne)/τ = a/r0τ. 
From this follows that 1/Dτ = 4πn pr0 for the pores. 

Let us consider a case when there are spherical pores of different radii, rk, in the 

sample, but no other defects. Then we have 

Σk(1/τk) = 4πD 〈 rp〉〈np〉, Σk(1/rkτk) = 4πD〈np〉,                         (26) 

where 〈rp〉 is the average radius of the pores and 〈np〉 is the total number of pores in 
the unit volume of a sample. 
Dislocations.  Speaking  about  dislocations,  one  should  take  into  account  that 
vacancies  are  generated  and  annihilated  by  dislocation  jogs.  When  the  averaged 
−1/2 (low jog density), the jogs could be regarded as 
distance between the jogs, lj ≥ nd t
a limiting case of pores, where the size of the Burgers vector, b, corresponds to the 
radius of a pore, r0, and so the following equation can be applied: 

1/Dτ = 4πbnd t /lj.                                               (27) 

 
 
 
 
 
 
 
 
 
 
  Here  an  interaction  between  a  vacancy  and  a  stress  field  of  dislocations  is  not 
taken into account. This interaction can be neglected when its energy is much smaller 
than kT, which is the case at ambient temperature and higher ones. At ndt = 1010 cm−2, 
lj = 10−5 cm, b = 3×10−8 cm, Eq. (27) yields 1/Dτ = 4.19×108 cm−2. 
−1/2,  almost  all  the 
  When  the  jog  density  is  very  high  (high  jog  density),  lj  «  ndt
volume  of  a  sample  can  be  approximated  by  cylinders  (see  Fig.  8),  surrounding 
−
parallel, uniformly situated dislocations. The radius of the cylinder is about 0.564ndt
1/2. The concentration of vacancies in a separate cylinder can be approximated as 

N = Ne − aln(ρ/lj),                                                 (28) 

where ρ is the distance from the dislocation axis. 

Fig. 8. Model of a dislocation as a sink for high jog density case. Drainage basin is 
plotted by a dotted line. 

It is accepted in Eq. (28) that N = Ne when ρ ≈ lj. The vacancy flux in the vicinity 
of the cylinder, where ρ ≈ lj, is −aD/lj. The number of vacancies, crossing the surface 
of the cylinder, ρ ≈ lj, in the unit time, and calculated per unit volume, is 2πaDndt. On 
the  other  hand  this  number  is  equal  to  the  number  of  vacancies,  annihilating  on 
2ndt). From this follows that 
dislocations per unit time, (〈N 〉  − Ne)/τ = −(a/2τ)ln(8.54lj
2ndt = 10−3 and ndt = 1010 cm−2 we have 1/Dτ = 
1/Dτ = −4πndt/ln(8.54lj
1.82×1010 cm−2. 

2ndt). At 8.54lj

It is worthwhile to note that relaxation parameter, 1/Dτ, in the regarded case is not 

very sensitive one to the value of lj (the dependence is a logarithmic one). 
The role of the quality of the surface. In cases when the process depends upon mass 
transfer  to  or  from  surfaces  (for  example,  pore  surfaces),  its  rate  is  determined  in 
many aspects by both the structure and quality of the surface [14]. Usually a vacancy 
concentration in a thin layer near the surface is assumed to be equal to the equilibrium 
value with respect to the vacancy formation in the given spot of the surface. This is 
valid only in the case when the time interval during which a vacancy is formed on the 
surface is considerably smaller than that during which a vacancy exists in the above 
layer. This condition is fulfilled usually in perfect crystals, where diffusional currents 

 
 
 
 
 
 
 
are  small.  Diffusional  currents  in  real  crystals  may  be  so  intense  that  equilibrium 
cannot  be  achieved.  The  rate  of  approach  of  a  vacancy  concentration  to  the 
equilibrium  one  near  the  surface  depends  on  the  density  of  sources  (sinks)  of 
vacancies  on  the  surface  (surface  defects).  When  the  density  of  these  defects  is 
sufficiently  high,  the  above  rate  is  considerable,  and  the  mass  transfer  process 
proceeds quickly. Otherwise, the rate of the surface motion is slow. 
  Calculations show [14] that the rate of the change of the isolated pore of the radius 
r has a factor v/[D〈l〉 + (D + v〈l〉)r], where v is a parameter, which characterizes the 
ability of the ensemble of surface sources to supply deficient vacancies and 〈l〉 is the 
mean free path of the excess vacancy in the bulk of a material. 

2.3.3. Theoretical Conclusions, Concerning Final Stages of Sintering  
On the basis of results, discussed above, equations, describing the kinetics of pores of 
the i-th ensemble were derived. In a general non-stationary case it has a form [3]: 

(dri/dt) = −(D/N0ri)[(6/πd 2 ) + (bndt/lj) + 〈np〉〈r p〉]−1{[kT (σE2 − cTt)/4πκ〈T 〉 ] +  

+ (Ne/k〈T 〉 )[(6/πd 2 )(ugb − u0) + (bndt/lj)(ud − u0)] + (2γNe/k〈T 〉 N0 ri)× 

×[(6/πd 2 ) + (bndt/lj) + 〈np〉 (〈rp〉 − ri)]},                            (29) 

where  ri  is  the  radius  of  a  pore,  belonging  to  the  i-th  ensemble,  ugb  and  ud  are  the 
enthalpies of vacancy formation on grain boundaries and dislocations, respectively. 
  Kinetics of the averaged pore radius is described by the following equation [3]: 

(d〈rp〉/dt) = −(D/N0)[(6/πd 2 ) + (bndt / lj) + 〈np〉〈r p〉]−1{[kT(σE 2  − cTt)/4πκ 〈T 〉 ]〈1/rp〉 + 

+ (Ne/k〈T 〉 )[(6/πd  2)(ugb − u0) + (bndt/lj)(ud − u0) − (2γN e/k〈T 〉  N0)〈np〉]〈1/rp〉 + 

+ (2γN e/k〈T 〉 N0)[(6/πd  2) + (bnd t / lj) + 〈np〉 〈rp〉]〈1/rp

2〉}.                   (30) 

  On the basis of the described theoretical results, we may conclude that the rate of 
the given diffusional process is determined by the following factors: 
Heating method. Bulk heating effectively accelerates mass transport processes when 
the production of heat in the bulk of a material, q, is high enough. This occurs when 
small or thin products, with a thickness of the order of 1 mm or thinner, are sintered. 
The structure of crystalline defects of sintered powders. The higher the concentration 
of  defects,  the  more  intense  the  mass  transport  processes  are,  as  a  rule.  But  the 
dependence  of  the  process  rate  on  the  dislocation  density  is  not  monotonic.  It  has  a 
maximum at some dislocation density, whose typical value is about 1011 cm−2. 
The  ability  of  both  the  bulk  and  surface  vacancy  sources  to  emit  or  absorb 
vacancies. As healing of large pores (larger than 1 µ in diameter) is enhanced due to 
bulk heating, the process of coagulation of small pores into large ones is impeded (in 
contrast  to  conventional  sintering).  Hence,  the  conclusion  may  be  drawn  that  the 
samples  sintered  by  bulk  heating  will  contain  a  larger  number  of  small  pores  and 
smaller  number  of  large  pores  than  found  in  the  regular  furnace  sintered  samples. 
Such  a  more  uniform  pore  structure,  consisting  mostly  of  small  pores,  tends  to 
improve mechanical and other physical properties of products. 

 
 
 
 
 
 
 
 
 
  A comparative experimental investigation of sintering of iron powder by means of 
electric  contact,  inductive,  and  conventional  furnace  sintering  was  performed  [15]. 
The results showed that electric contact sintering allows achieving of the same level 
of mechanical properties during an essentially smaller period of treatment compared 
to conventional furnace sintering. 

3. Cycling and Pulsing Regimes 

During cycling around a temperature interval of the first order phase transformation 
intensification of diffusional mass transfer processes may be observed in some cases 
(see, e.g., [3]). Such an influence takes place only when the phase transformation is of 
a  martensitic  type  [16],  as  in  this  case  every  separate  phase  transformation  is 
accompanied by some plastic deformation during which excess vacancies are formed. 
Formation of excess vacancies causes changes in sources (sinks) of vacancies, which 
is a mass transfer by itself, and this enhances the process of sintering. Vacancies are 
formed  on  locations  where  the  enthalpy  of  vacancy  formation  is  smaller.  Then  the 
excess vacancies annihilate on locations where the enthalpy of the vacancy formation 
is larger. This process contributes to a further development of process of diffusional 
sintering.  Other  processes  of  mass  transfer,  typical  for  non-isothermal  electric 
sintering, take place concomitantly and were investigated in [3]. 
  An equation, which determines time and coordinate dependence of temperature, is 
the heat flow equation, Eq. (3). At cycling or pulsing regimes, the heat production, q = 
σE 2 , varies periodically. Let us separate all the sources (sinks) of vacancies, existing 
in a sample, into two grades. Let the first grade be the one, which contributes to the 
sintering  process  directly,  and  the  second  one  does  not  contribute  to  the  sintering 
process directly [e.g., dislocations; they do not contribute immediately to the process 
of sintering (consolidation of a material) during their activity as sources (sinks)]. As 
was shown [17], all sources (sinks), which are described by parameters τi and Nei, can 
be replaced by one effective type of source (sink) with 

(1/τ) = Σi(1/τ i) and Ne = τΣ i (Nei /τi).                               (31) 

The dependence of the vacancy concentration on time and coordinates during the 

process of sintering is determined by the continuity equation: 

divJ + [(N − Ne1)/τ1] + [(N − Ne2)/τ] + (∂N/∂t) = Ntv,                (32) 

where  Ne1  and τ1  refers  to  the  first  grade  sources  (sinks),  Ne2  and τ2  refers  to  the 
second grade ones, and Ntv = (dNv/dt) is the production of vacancies per unit time in 
the  unit  volume  of  the  sample,  caused  by  direct  and  reverse  martensitic  phase 
transitions. The vacancy flux, J, is determined by Eq. (13). 

Substituting  Eq.  (13)  into  Eq.  (32),  and  taking  into  consideration  Eq.  (3),  we 
obtain  equation,  which  determines  time  and  coordinate  dependence  of  the  vacancy 
concentration: 

{D∆ − [(τ1  + τ2 )/τ1τ2 ]}(N − Ne1) = (∂N/∂t) +  

+ (DkT /κ〈T 〉 )(cTt − q) + [(Ne1 − Ne2)/τ2] − Ntv.                        (33) 

 
  
 
 
 
 
 
 
 
 
  Changes  occurring  during  time  intervals  considerably  larger  than  the  cycling 
period are of primary interest. So let us time-average Eq. (33) over the cycle period. 
Let us consider only the bulk of a material, where macroscopic inhomogeneity of the 
vacancy distribution is inessential. This inhomogeneity is essential only in a surface 
layer of the thickness of about [Dτ1τ2/(τ1 + τ2)]1/2. When time-averaged temperature 
and vacancy concentration remain unchanged (quasi-stationary regime), we obtain the 
following relationship, valid in the bulk of a sample: 

〈[(N − Ne1)/τ1 ]〉t = 〈[(Ne2 − N ) /τ2 ]〉t + 〈qDkT/κ 〈T 〉 〉 t + 〈d Nv /d t〉t.       (34) 

The left-hand part of Eq. (34) refers to first grade processes, that is, to the rate of 
the sintering process. The right-hand part of Eq. (34) represents the action of different 
sources  and  driving  forces  of  diffusional  processes.  The  first  term  represents 
conventional  sources  and  driving  forces  of  furnace  sintering.  The  second  term 
describes  the  contribution  of  divergent  thermal  diffusion  fluxes,  caused  by  the 
inhomogeneity of the temperature gradient in the bulk-heated sample. The third term 
describes  a  contribution  of  excess  vacancies,  formed  by  plastic  deformation  during 
direct  and  reverse  martensitic  transformations  during  cycling.  The  larger  the  third 
term the greater the enhancement of the sintering process is. From this follows, that 
the  cycling  and  pulsing  regimes  are  more  effective  at  higher  frequencies  (shorter 
periods). 

It is worthwhile to regard separately two following cases: 

(i)  First  of  all  let  us  consider  a  case  when  Ne1  <  N  <  Ne2.  In  this  case  sources  of  a 
second  grade  emit  vacancies,  which  annihilate  on  the  sinks  of  a  first  grade.  In  the 
early  stages  of  sintering  this  leads  in  some cases to the decrease in the curvature of 
grains and thus the process of sintering progresses. As in the regarded case N < Ne2, 
the contributions of the first and the third terms in the right-hand part of the Eq. (34) 
are  positive.  This  means  that  the  rate  of  sintering  at  the  early  stages  of  the  process 
increases monotonically with the increase in the frequency of cycling. 

The  final  stages  of  sintering  consist  in  the  healing  of  pores.  So  to  enhance  the 
process of sintering we have to create conditions when the source of a first grade (e.g., 
pores)  emits  vacancies.  But  in  the  regarded  case  first  grade  sinks  absorb  vacancies. 
Thus the sintering process (in its final stages) is impeded, and the higher the cycling 
frequency, the slower the rate of the final stages of sintering is. 
(ii) Now let us regard a case when Ne2 < N < Ne1. In this case the first grade sources 
emit vacancies, which annihilate on second grade sinks. That is why in the regarded 
case increase in the excess vacancy concentration impedes the bulk vacancy diffusion 
mechanism  of  the  activity  of  the  first  grade  sources,  thus  diminishing  a  negative 
contribution of this mechanism to the early stages of sintering. So, in the early stages, 
cycling  and  pulsing  enhances  sintering,  and  the  higher  the  frequency,  the  more 
essential the enhancement is. As in the regarded case the emission of vacancies by the 
first grade  sources is slowed down when excess vacancy concentration is increased, 
the rate of the final stages of sintering (the healing of the pores) is slowed down also, 
and the higher the cycling frequency the lower the rate of the final stages of sintering 
is. 

4. THE PROBLEM OF SWELLING 

 
 
 
 
 
 
The problem of swelling was discussed in [17, 19]. Here we shall discuss it in more 
detail [4]. Penetrating irradiation dislocates some atoms of the lattice into interstitial 
positions, leaving behind vacancies. Coagulation of vacancies leads to pore formation. 
As  a  result  of  this  process  the  material  swells.  Swelling  materials  loose  their 
mechanical and other properties and they do not function properly. Let us consider the 
process  of  swelling  analytically.  Let  us  assume  that  in  the  unit  volume  of  a  sample 
during  a  unit  time  interval  Nti  dislocated  atoms  and  Ntv  vacancies  are  created.  The 
dislocated atoms and vacancies annihilate on sinks (grain boundaries, dislocations and 
pores) as was described above [Eq. (12)]. Some of them are being driven out of the 
sample by the divergent temperature gradients as was shown above [Eq. (2)]. When 
the  quantity  of  vacancies,  driven  out  of  the  sample  by  divergent  temperature 
gradients,  achieves  the  quantity  of  vacancies,  created  in  the  sample  by  penetrating 
radiation, that is when 

q ≥ Ntvkκ〈T〉 2/[DvNev(uv − unv)],                                      (35) 

the swelling is stopped [17, 19]. Eqs. (2) and (16) were used to obtain Eq. (35). 
  Now let us take a more general look at the problem of swelling prevention. Let us 
write the balance for the stationary regime: 

Nti = (Ni/τgbi) + (Ni/τdi) + (Ni/τpi) + (DiqkTi/κ〈 T 〉 ), Ntv = [(Nv − Nev)/τgbv] + 

+ [(Nv − Nev)/τdv] + [(Nv − Nev)/τpv] + (DvqkTv/κ〈T 〉 ).                    (36) 

  Here Ni is the concentration of dislocated atoms, Nv is the vacancy concentration. 
The  first  line  refers  to  the  balance  of  dislocated  atoms;  the  second  one  refers  to  the 
balance of vacancies. The equilibrium value of interstitial atoms was neglected in Eq. 
(36),  as  it  is  very  small.  The  rate  of  annihilation  of  excess  vacancies  on  sinks  is 
assumed  to  be  proportional  to  the  excess  vacancy  concentration,  (Nv  −  Nev).  The 
relaxation parameters used in Eq. (36) were calculated in Section 2.3.2. The diffusion 
coefficients for dislocated atoms and vacancies, Di and Dv respectively, are different. 
We assume that the concentration of dislocated atoms and vacancies is not too high, 
so the process of mutual annihilation of dislocated atoms and vacancies is neglected 
in Eq. (36). This process could be described by additional terms in both lines of Eq. 
(36), containing a product of both Ni and Nv. 

Eq. (36) yields: 

Ni = [Nti − (D i q kTi /κ〈T 〉 )]/[(1/τgbi) + (1/τdi) + (1/τpi)], 

Nv − Nev = [Ntv − (DvqkTv/κ〈T 〉 )]/[(1/τgbv) + (1/τdv) + (1/τpv)].             (37) 

The condition for a pore not to grow is that the number of atoms, coming to the 
pore  prevails  upon  the  number  of  coming  vacancies.  Using  Eq.  (37),  one  can  write 
this condition in the form: 

[Nti − Ntv + (DvqkTv/κ〈T 〉 ) − (DiqkTi/κ〈T 〉 )]/[1 + (τp/τgb) + (τp/τd)] ≥ 0.      (38) 

 
 
 
 
 
 
 
 
 
 
 
 
 
It  is  worthwhile  to  note  that  (τp /τg b)  and  (τp /τd )  do  not  contain  the  diffusion 
coefficient neither for dislocated atoms, nor for vacancies. The left-hand part of Eq. 
(38) presents the rate of the change of the volume of pores in a sample. 

The  number  of  dislocated  atoms  and  vacancies  created  by  the  penetrating 

radiation are equal as a rule, that is Nti − Ntv = 0. In this case 
Eq. (38) is equivalent to 

DvkTv − DikTi ≥ 0.                                            (39) 

  When the concentration of dislocated atoms and vacancies is much larger than the 
equilibrium  concentration  of  vacancies,  kTv  =  −Nvumv/kT  and  kTi  =  Niumi/kT.  In  this 
case one can see that the inequality, described by Eq. (39) is never possible. The left-
hand part of Eq. (39) is always negative. This means that to prevent swelling we have 
to  achieve  circumstances  when  the  concentration  of  dislocated  atoms  and  the 
concentration of vacancies are close to the equilibrium concentration of vacancies. In 
this  limit  we  have  kTv  =  Nev(uv  −  umv)/kT  and  kTi  =  Niumi/kT.    Then  the  inequality, 
described by Eq. (39) is possible. To achieve this we have to introduce into a sample 
as  many  different  sinks  as  possible  (but  not  pores).  This  will  help  reducing  the 
concentration  of  dislocated  atoms  and  vacancies.  Then  the  swelling  of  a  material 
could be prevented provided uv is larger than umv [4]. 

5. DISCUSSION  

Experimental data on ohmic sintering [15, 18] show that during prolonged sintering, 
especially  at  higher  temperatures,  the  peculiarities,  caused  by  the  driving  forces 
arising due to bulk heating become more and more pronounced. This corresponds to 
the  increasing  contribution  of  stationary  stage  processes  to  the  final  structure  and 
properties  of  sintered  samples,  and  according  to  the  theory,  the  contribution  of  the 
regarded  driving  forces  are  the  largest  at the  isothermal  regimes.  After  bulk  heating 
sintering,  according  to  the  theory,  samples  have  a  specific  defect  structure:  greater 
amount of pores of smaller sizes, which improves significantly mechanical properties 
of sintered materials. 

The  best  way  to  prevent  swelling  of  materials  is  to  introduce  as  many  sinks  of 
vacancies  as  possible  (grain  boundaries,  dislocations,  etc.,  but  not  pores)  and  to  use 
materials,  where  the  enthalpy  of  vacancy  creation  is  larger  than  the  enthalpy  of 
vacancy migration. 
  A  mesoscopic  approach,  described  in  present  paper,  which  had  been  used  for 
years 
to  solve  sintering  problems,  also  could  help  solving problems  of 
nucleation, decomposition,  and  other  problems  in  the  theory  of  alloys.  Described 
relaxation  time  technique  could  help  simplifying  calculations  and  give  more  clear 
physical picture. 
  Bulks heating driving forces, important for small size objects of microelectronics 
or/and heat evolving elements in nuclear reactors, are important also for the problems 
of nucleation and decomposition in these objects. 

6. CONCLUSION 

 
 
 
 
 
 
 
 
 
A  general  phenomenological  theory  of  initial  stages  of  ohmic  sintering  and  final 
stages of a sintering process with and without bulk heating mechanisms is presented 
in this paper. The role of various sinks and sources of vacancies is analyzed. Mobile 
and immobile dislocations and their role in the sintering process are considered. The 
diffusional  relaxation  parameters  for  ensembles  of  grain  boundaries,  pores  and 
dislocations are calculated. The role of the quality of the surface is discussed. Cycling 
and  pulsing  regimes  of  sintering  are  described.  Specific  driving  forces  of  the  bulk 
heating origin are analyzed in detail. The same approach is applied to the problem of 
swelling under penetrating radiation. 

REFERENCES 

1. 
2. 

3. 

4. 
5. 
6. 
7. 
8. 

9. 
10. 
11. 
12. 

Ya. E. Geguzin, Physics of Sintering (Moscow: Nauka: 1967). 
Yu. V. Kornyushin, Transport Phenomena in Real Crystals in External Fields (Kiev: Naukova 
Dumka: 1981). 
Yu. Kornyushin, in: B. Stojanovic et al. (Eds.), Advanced Science and Technology of Sintering 
(New York: Kluwer Academic/Plenum: 1999), p. 3. 
Yu. Kornyushin, Science of Sintering, 36: 43 (2004). 
S. V. Venglinskaya, Yu. V. Kornyushin, Metallofizika, No 61: 71 (1975). 
S. V. Venglinskaya, Yu. V. Kornyushin, Fizika Metallov i Metallovedeniye, 41: 431 (1976). 
Yu. V. Kornyushin, J. Mater. Sci. (Letters), 15: 799 (1980). 
A. I. Raichenko, Mathematical Theory of Diffusion in Applications (Kiev: Naukova Dumka, 
1981). 
Yu. V. Kornyushin, Metallofizika, No 5: 116 (1983). 
Y. Adda  and J. Philibert, La Diffusion dans les Solids, V. 2 (Paris: Press. Univ. France: 1966). 
Yu. V. Kornyushin, Metallofizika, No 5: 104 (1983). 
L. O. Andrushchik, Yu. V. Kornyushin and S. P. Oshkaderov, Science of Sintering, 21: 3 
(1989). 
Yu. V. Kornyushin and L. N. Larikov, Metallofizika, No 73: 66 (1978). 
Yu. V. Kornyushin, J. Mater. Sci., 17: 3423 (1982). 

13. 
14. 
15.  W. Hermel, Yu. V. Kornyushin, S. P. Oshkaderov, S. Siegel, and V. A. Shvitai, Metallofizika, 

2: 74 (1980). 
L. N. Larikov and V. M. Falchenko, in: M. A. Krishtal (Ed.), Diffusion in Metals and Alloys 
(Tula: TPI: 1968), p. 15. 
Yu. V. Kornyushin, Metallofizika, 9: 130 (1987). 
L. O. Andrushchik, O. N. Balakshina, Yu. V. Kornyushin, S. P. Oshkaderov and V. A. Shvitai, 
Metallofizika, 9: 32 (1987). 
Yu. V. Kornyushin, Ukrainskii Fiz. Zh., 26: 2050 (1981). 

16. 

17. 
18. 

17."
Studying Thermodynamics of Metastable States,"  Simple classical thermodynamic approach to the general description of
metastable states is presented. It makes possible to calculate the explicit
dependence of the Gibbs free energy on temperature, to calculate the heat
capacity, the thermodynamic barrier, dividing metastable and more stable
states, and the thermal expansion coefficient. Thermodynamic stability under
mechanical loading is considered. The influence of the heating (cooling) rate
on the measured dynamic heat capacity is investigated. A phase shift of the
temperature oscillations of an ac heated sample is shown to be determined by
the relaxation time of the relaxation of the metastable nonequilibrium state
back to the metastable equilibrium one. This dependence allows one to calculate
the relaxation time. A general description of the metastable phase equilibrium
is proposed. Metastable states in AB3 alloys are considered. Reasons for the
change from the diffusional mechanism of the supercritical nucleus growth to
the martensitic one as the heating rate increases are discussed. The Ostwald
stage rule is derived.
",http://arxiv.org/pdf/cond-mat/0702076v1,3,"FACTA UNIVERSITATIS 
Series: Physics, Chemistry and Technology Vol. 3, No 2, 2005, pp. 115 - 128 

STUDYING THERMODYNAMICS OF METASTABLE STATES 
UDC 536.7 

Yuri Kornyushin 

Maître Jean Brunschvig Research Unit,Chalet Shalva, Randogne, CH-3975 

Abstract.  Simple  classical  thermodynamic  approach  to  the  general  description  of 
metastable  states  is  presented.  It  makes  possible  to  calculate  the  explicit 
dependence of the Gibbs free energy on temperature, to calculate the heat capacity, 
the  thermodynamic  barrier,  dividing  metastable  and  more  stable  states,  and  the 
thermal  expansion  coefficient.  Thermodynamic  stability  under  mechanical  loading 
is considered. The influence of the heating (cooling) rate on the measured dynamic 
heat capacity is investigated. A phase shift of the temperature oscillations of an ac 
heated sample is shown to be determined by the relaxation time of the relaxation of 
the  metastable  nonequilibrium  state  back  to  the  metastable  equilibrium  one.  This 
dependence allows one to calculate the relaxation time. A general description of the 
metastable  phase  equilibrium  is  proposed.  Metastable  states  in  AB3  alloys  are 
considered.  Reasons  for  the  change  from  the  diffusional  mechanism  of  the 
supercritical  nucleus  growth  to  the  martensitic  one  as  the  heating  rate  increases 
are discussed. The Ostwald stage rule is derived. 

1. INTRODUCTION 

Metastable  states  are  common  ones  in  physics,  nanophysics,  materials  science,  and 
chemistry.  Many  amorphous  materials  (including  some  amorphous  metals  and  alloys), 
superheated and supercooled phases are examples of the metastable states. 
  The  problem  of  metastable  states  is  related  to  the  problem  of  phase  transformations.  The 
common  feature  is  a  transition  from  one  phase  to  the  other  one.  But  what  is  different  here  is 
reversibility.  Phase  transformations  are  reversible  or  almost  reversible  changes.  The  second-
order transition is completely reversible. The first-order transition is often reversible in a sense 
that it is possible to transform two phases, one into another, and reversely by means of cycling 
temperature.  Direct  and  reverse  first-order  phase  transitions  almost  never  occur  at  the  same 
temperature.  Usually  a  low-temperature  phase  requires  overheating  to  be  transformed  into  a 
high-temperature  one,  and  vice  versa,  the  high-temperature  phase  requires  overcooling  at 
reverse transformation. This phenomenon is called hysteresis, and apart from this the first-order 
phase  transitions  are  usually  reversible.  On  the  contrary,  the  majority  of  transitions  from 
_________________________________ 

 Received January 17, 2005 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
116                                                        Y. KORNYUSHIN 

metastable  states  to  more  stable  ones  are  irreversible.  For  example,  a  crystallization  of 
amorphous  materials  and  transformation  of  diamond  to  graphite  are  completely  irreversible. 
The reason for the irreversibility is that in these cases the temperature of the equilibrium of the 
two  phases  does  not  exist.  The  metastable  phase  just  collapses  into  more  stable  one.  The 
transition is one from the phase with the higher Gibbs free energy (GFE) to that with the lower 
one. The jump occurs not in the first derivatives of the GFE (enthalpy and volume) like in the 
case of the first-order phase transition, but in the GFE itself. So this type of transitions could be 
called zero-order transitions (in the spirit of the P. Ehrenfest classification). 
  The aim of this paper is to formulate a classical  thermodynamic description to investigate 
the  limits  of  a  relative  stability  of  metastable  states  and  their  thermodynamic  properties.  The 
GFE will be expanded in a series of deviations of entropy, but not in the vicinity of the phase 
equilibrium (which does not exist in a general case), but in the vicinity of some starting point. 
  The author had started the classical thermodynamic description of metastable states in 1985 
[1]. Let us consider it in detail here. 
   The  GFE  is  defined  as  a  function  of  thermodynamic  variables  T  (temperature)  and  P 
(pressure) as a rule [2]. 
  Let us consider now the GFE per atom, divided by Boltzmann constant, k, as a function of 
entropy  (per  atom  and  divided  by  k)  s,  temperature  T,  and  pressure  P  (with  thermodynamic 
variables s and P): 

φ( s,P) = h(s,P) − Ts,                                                            (1) 

where h(s,P) is the enthalpy per atom and divided by k. 
   Enthalpy h is originally defined as a function of two thermodynamic variables: entropy s, and 
pressure P [2]. That is h = h(s,P ) . In a state of equilibrium enthalpy depends on T via s(T,P )  
only. To prove this let us assume the contrary: h = h(s(T,P),T,P). Then at constant pressure the 
heat  capacity  of  a  body  (per  atom  and  divided  by  k),  cP  =  (dh/dT )P  =  (∂h/∂s)P ( ∂s/∂T )P  + 
(∂h/∂T )P. As in the state of equilibrium (∂h/∂s)P = T [2], and (∂s/∂T )P = cP/T [2], we have: cP = 
cP + (∂h/∂T )P. From this follows that (∂h/∂T ) P = 0, that is h = h(S,P) and not h = h(S,T,P ) . 
  The GFE as a function of thermodynamic variables s and P has a remarkable property: in a 
state of equilibrium it has a minimum on s. Really, at fixed T and P (∂φ /∂s)P  = (∂h/∂s)P − T. In 
the state of equilibrium the right-hand part of this equation is zero:  (∂h/∂s)P − T  = 0  [2]. So 
the first condition of a minimum, (∂φ/∂s)P  = 0, is fulfilled. Now let us take into account that at 
fixed  T  and  P  (∂2φ/∂s2)P  ≡  (∂2h/∂s2)P.  According  to  [2]  in  a  state  of  equilibrium  (∂2h/∂s2)P  = 
(T/cP) > 0. So the second condition of a minimum, (∂2φ/∂s2)P > 0 is fulfilled also. 
  Here like in usual classical thermodynamics we talk about differentiation of thermodynamic 
functions like GFE, enthalpy, etc. This means that it is assumed implicitly that these functions 
are defined well enough not only in the point of equilibrium, but in some vicinity of it also. The 
same was assumed in a “configurational” model [1,3]. 
  When the GFE is regarded as a function of thermodynamic variables s and P with T and P 
being fixed, a minimum of the GFE on s corresponds to a state of equilibrium, and an equation 
of equilibrium, (∂h/∂s)P  = T, determines explicit dependence of s on T. This approach allows 
us  to  calculate  explicit  dependencies  of  the  GFE,  heat  capacity  and  other  thermodynamic 
quantities  on  T,  and  to  formulate  an  approach  for  metastable  states,  which  gives  that 
thermodynamic barrier, dividing metastable and more stable states, is proportional to (Ti − T)3/2 
(Ti is the temperature of the absolute instability). Thermodynamic instability under mechanical 
loading is considered also. 

 
 
 
Studying Thermodynamics of Metastable States                                 117 

2. APPROXIMATION 

Dependence of h on s is different for various systems. This problem is discussed in detail in 
[3]. For a metastable state, h has a minimum at some value of s, and at some other value of s it 
should have a maximum. The described barrier is a main feature of a metastable state. Here let 
us restrict ourselves with the case when h = h(s,P) can be expanded in power series in a small 
parameter, (s − s0 ) (s0 is the entropy of a system at T = 0; for stable systems s0 = 0). A case of 
an expansion about a non-zero-point entropy will be discussed later, in Sections 10 - 13 [see, 
e.g., Eq. (36)]. 
  As in this section (∂h/∂s)P  = T = 0 at s = s0, the first three terms of the series are [1] 

h(s,P) = h(s0,P ) + (T0 / 2)(s − s0)2 − (T0

2/12Ti)(s − s0)3,                               (2) 

where  T0 and Ti are some parameters, depending on P. 
  When (s − s0) is not small, Eq. (2) can be regarded as a model, describing metastable states 
also,  because  it  describes  a  situation  when  h(s,P)  goes  through  a  minimum,  and  then  a 
maximum with the increase in (s − s0), as it should be for a metastable state. 

Such  an  approach  is  applicable  for  metastable  systems,  including  disordered  (e.g., 
amorphous  [1])  ones,  and  for  systems  which  include  electrons  of  conductivity  or  disordered 
subsystems, e.g., disordered grain boundaries in polycrystals, randomly distributed dislocations 
or quenched vacancies in a crystal, solid solutions, etc. 

3. THERMODYNAMIC STABILITY 

Using Eq. (2) one can see that φ as a function of (s − s0) has a minimum at 

smin = s0  + (2Ti/T0){1 − [1 − (T /Ti)]1/2},                                           (3) 

and a maximum at 

smax = s0  + (2Ti/T0){1 + [1 − (T /Ti)]1/2}.                                          (4) 

It  will  be  shown  later  that  in  the  frames  of  expansion  into  series  (or  model),  Eq.  (2),  the 
parameter  Ti  has  a  meaning  of  a  virtual  critical  point  (the  temperature  of  the  absolute 
instability) of a metastable phase. 
  Thermodynamic barrier (per atom and divided by k), separating metastable and more stable 
states, is described as 

∆φ( T ) = φ( smax) − φ( smin) = (8/ 3)(Ti

1/2/T0)(Ti − T)3/2,                               (5) 

and smax  − smin = (4Ti /T0)[1 − (T /Ti)]1/2. 

From Eq. (5) one can see that the thermodynamic barrier vanishes at T  →  Ti. So Ti has a 
meaning of the temperature of absolute instability. But metastable system cannot exist up to T 
=  Ti  as  the  thermodynamic  barrier  becomes  too  small  when  T  approaches  Ti.  The  system 
leaves  metastable  state  when  the  temperature  reaches  some  characteristic  temperature,  Tc, 
which has a meaning of a real critical temperature. It is often essentially smaller than Ti. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
118                                                        Y. KORNYUSHIN 

In this case real critical temperature could be approximated as [1] 

Tc ≈ (8/3)Ti

2/T0.                                                             (6) 

System leaves metastable state for more stable one when T is of the order of magnitude or 
larger  than  Tc,  and  accordingly  to  the  kinetics  [4]  the  higher  the  heating  rate  the  higher  the 
temperature at which this process has a considerable rate. 

4. THERMODYNAMIC STABILITY UNDER CONDITIONS 
OF MECHANICAL LOADING 

Thermodynamic stability under conditions of mechanical loading was first discussed in [5]. 
Proposed  formalism  allows  us  to  obtain  an  expression  for  thermodynamic  barrier  [Eq.  (5)]. 
When T is essentially smaller than Ti the thermodynamic barrier does not depend on T, but it 
depends on mechanical stresses. In general case both parameters in Eq. (5), Ti and T0, depend 
on  stresses.  As  a  result  of  this,  the  barrier  itself  depends  on  stresses  also.  Expansion  of  the 
barrier in power series in the tensor of stresses, σik, for isotropic medium, yields 

k∆φ  = k∆φ( 0) − (v/3)σii − uel,                                                    (7) 

where ∆φ( 0) = gTc is ∆φ  at σik = 0 , g is some coefficient of the order of unity, exact value of 
which depends on the rate of the change in thermodynamic conditions, such as Tt /T (Tt is the 
rate  of  the  change  of  temperature),  and  on  the  temperature  at  which  the  instability  occurs. 
Parameter v represents the activation volume, σii is a spur of σik and uel is the elastic energy per 
one atom.  
  When  ∆φ ≈ gT, system leaves metastable state for more stable one. According to the given 
considerations and Eq. (5), the critical shear stress may be estimated as 

Pc ≈ [2kgG(Tc − T ) /va]1/2,                                                     (8) 

where G is the shear modulus and va is the volume per atom. 
  To estimate Pc using Eq. (8) let us take g = 1, va = 2×10−23 cm3 , G = 12×109 Pa, and 
Tc − T = 370 K. At such values of the parameters Eq. (8) yields Pc = 2.48×109 Pa. 

For the compression (elongation) we have 

Pc ≈ (|v|E/3va)[1 + 18kgva(Tc − T ) /Ev2]1/2 ± Ev/ 3va,                               (9) 

where E is the Young modulus, plus refers to compression and minus refers to elongation. 
  At v → 0 Eq. (9) yields Eq. (8) where G is replaced by E. At T → Tc Eq. (9) yields 

Pc = ± 3kg (Tc − T )/v,                                                     (10) 

where plus refers to elongation at v > 0 and minus refers to compression at v < 0.  

In the case of compression and v > 0 as well as in the case of elongation and v < 0 we have  

respectively 

Pc = ± 2vE/3va.                                                        (11) 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Studying Thermodynamics of Metastable States                                 119 

  Thermodynamic  instability  under  loading  may  often  result  in  a  fracture  because  of  the 
extreme  brittleness  or  low  strength  of  a  more  stable  phase.  This  refers  to  the  majority  of  the 
amorphous  metallic  alloys  and  other  metastable  phases,  e.g.,  diamond  (the  stable  phase, 
graphite, is of a very low strength). 

5. THERMAL PROPERTIES 

Heat capacity at constant pressure (per atom and divided by k) is given by [1] 

cP = T (∂s/∂T )P  = (T /T0 )[1 − (T /Ti)]−1/2.                                    (12) 

  This equation is derived for the metastable equilibrium phase, so it is applicable when the 
phase is still stable, i.e. for T < Tc only. 
  At T « Ti cP  = T/T0 which corresponds to a well-known result for amorphous materials [6]. 
  At T = Ti the isobaric heat capacity diverges. 
  Thermal expansion coefficient, α(T) = (∂va/∂T )P / v a0 = −k (∂s/∂P)T / va0 (va and va0 are the 
volume of the sample per atom at T > 0 and T = 0 respectively) is given by the formula [5]: 

α (T) = α 0 + C (T /Ti)[1 − (T /Ti)]−1/2 + 2(D − C){1 − [1 − (T /Ti)]1/2},                (13) 

where 

α 0 = −k (∂s0 /∂P)/va0 , C = (k/va0)(Ti/T0)(∂lnTi / ∂P)  and D = (k/va0)(Ti / T0)(∂lnT0/∂P).  (14) 

  At low temperatures, when T is essentially smaller than Ti, we have: 

α (T ) = α0 + D  (T /Ti) + (C + D)(T/2Ti)2 + (2C + D)(T/2Ti)3 + ...  .               (15) 

  Eq. (15) determines thermal expansion at low temperatures. Depending on values and signs 
of  C  and  D  there  are  three  possible  types  of  curves  for  α(T)  at  low  T:  monotonically 
increasing,  having  a  maximum  and  then  a  minimum,  and  having  only  a  minimum.  At  high  T 
the  contribution  of  metastability  may  lead  to  increase  in α(T )   if  C  <  0.  Such  non-monotonic 
dependencies of α(T) are well known in amorphous solids [6], but the best known example of a 
system with a non-monotonic thermal expansion coefficient is water. It should be noted that in 
this  case,  thermal  expansion  anomalies  occur  already  in  a  stable  region  (the  results  of  this 
section are well applicable for a stable region also). 

Thermodynamic properties, in particular, compressibility of supercooled water, heavy water 

and their mixtures were studied recently in [7,8]. 
  The results on the thermal expansion coefficient are applicable for T < Tc only, like in the 
case of the heat capacity. 

Isothermal  compressibility  is  known  to  be  proportional  to  isobaric  thermal  expansion  [2]. 
As  the  isobaric  thermal  expansion  diverges  at  T  =  Ti,  so  the  isothermal  compressibility  also 
diverges at T = Ti. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
120                                                        Y. KORNYUSHIN 

6. GENERAL CASE 

Dependence of h on s is obviously different for various systems [5]. At low T in a general 
case it may be approximated by the first term of expansion:  h(s,P) = A(P)(s − s0)a(P) (A and a 
are some constants, depending on pressure). Taking into account that  (∂h/∂s)P  = T, we get that 
at s = s0 (∂h/∂s) = 0. The only way to satisfy this condition is to restrict the range of the possible 
values  of  a(P)  :  a(P)  >  1.  As  we  shall  see  later,  the  value  of  a(P)  determines  the  low-
temperature  heat  capacity,  which  is  linear  in  T  for  conduction  electrons  [2],  as  well  as  for 
amorphous solids [6]. For such cases we have to adopt that the first term of expansion of h is 
proportional to (s − s0)2. This case was considered above. Now let us consider a more general 
case, when the first two terms of expansion of the GFE on (s − s0) are arbitrary powers (a and 
b, 1 < a < b) of (s − s0). Such two terms give us the same type of dependence of φ(s,P) on (s − 
s0)  as  regarded  in  Section  2.  That  is,  the  dependence  of φ  as  a  function  of  (s  −  s0),  having  a 
minimum  at  some  s  =  smin  and  then  having  a  maximum  at  some  s  =  smax.  From  such  type  of 
dependence,  as  it  will  be  shown  later,  it  follows  that  there  exists  a  virtual  critical  point  (the 
temperature  of  the  absolute  instability)  of  a  metastable  phase.  So  the  existence  of  the  virtual 
critical point is not an assumption of the theory discussed here, but it is a consequence of the 
chosen type of dependence of φ on (s − s0 ). Only such dependence corresponds to a metastable 
state, which loses stability at higher temperatures. 

In general case 

φ(s,P) = φ( s0,P) + [T0/a(a − 1)a − 1](s − s0)a − [T0

(b − 1)/(a − 1)/Ti

(b − a)/(a − 1)]× 

[(b − a)(b − a)/(a − 1)/b(a − 1)b − 2(b − 1)(b − 1)/(a − 1)](s − s0)b −  T(s − s0),            (16) 

where b = b(P)  is some constant, depending on pressure. 
  Condition of equilibrium, (∂φ/∂s)P = 0, yields equations for smin(T) and smax(T): 

[T0

(b − 1)/(a − 1)/Ti

(b − a)/(a − 1)][(b − a)(b − a)/(a − 1)/(a − 1)b − 2(b − 1)(b − 1)/(a − 1)](s − s0)b − 1 −  
[T0/(a − 1)a − 1](s − s0)a − 1 + T  = 0.                                         (17) 

  At T → 0 smin → s0, and Eq. (17) yields 

smin = s0 + (a − 1)(T /T0)1/(a − 1),                                               (18) 

cP = (T /T0)1/(a − 1).                                                         (19) 

  At T = 0 smin = s0 and 

smax = s0 + [(a − 1)(b − a − 1)/(b − a)(b − 1)(b − 1)/(a − 1)(b − a)/(b − a)1/(a − 1)](Ti / T0)1/(a − 1).  (20) 

  Eqs. (16) and (20) allow to calculate the height of the thermodynamic barrier at T = 0:  

(∆φ)T = 0 = [(b − 1)a(b − 1)/(a − 1)(b − a)/ab(a − 1)(2a − b)(b − a)(b − a)1/(a − 1)]× 
a/(a − 1)/T0

1/(a − 1)].                                                      (21) 

[Ti

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Studying Thermodynamics of Metastable States                                 121 

  At a = 2 and b = 3, (∆φ)T = 0 = (8/3)(Ti

2/T0) as expected. 

  At T = Ti the thermodynamic barrier vanishes, smin(Ti) = smax(Ti) = si and Eq. (17) yields 

si = s0 + (a − 1)[(b − 1)Ti/(b − a)T0]1/(a − 1).                                   (22) 

  Now  let  us  investigate  the  temperature  dependence  of  the  thermodynamic  barrier  near  Tc 
point. For this purpose let us expand (∂φ/∂s)P in power series in (si − s). The first two terms are 

(∂φ/∂s)P = (Ti − T) − {[(b − a)T0]2/(a − 1)/2(a − 1)[(b − 1)Ti](3 − a)/(a − 1)}(si − s)2.        (23) 

  Condition (∂φ/∂s)P = 0 and Eq. (23) yield 

sm = s0 + (a − 1)[(b − 1)Ti/(b − a)T0]1/(a − 1){1 ± [2/(a − 1)(b − 1)]1/2[1 − (T /Ti)]1/2},   (24) 

where m is maximum or minimum and + refers to the maximum and − refers to the minimum. 
  Eqs. (16) and (24) yield that in general case in the vicinity of Ti the barrier,  

∆φ = (25/2/3)[Ti

a/(a − 1)/T0

1/(a − 1)][(a − 1)1/2(b − 1)(3 − a)/2(a − 1)/(b − a)1/(a − 1)]× 

[1 − (T/Ti)]3/2.                                                        (25) 

  Eq. (25) shows that in the vicinity of Ti the exponent of the temperature dependence of the 
barrier in general case is 3/2, like in the simple case regarded above (the terms, proportional to  
[1 − (T /Ti)]1/2 and to [1 − (T /Ti)] annihilate). So the 3/2 rule seems to be the universal one. 
  At a = 2 and b = 3 ∆φ = (8/3)(Ti

2/T0) [1 − (T/Ti)]3/2 as expected. 

7. LIMITS OF THE VALIDITY OF THE THEORY 

As  follows  from  Eqs  (3)  and  (4)  the  expansion  performed  in  Eq.  (2)  is  valid  when  4Ti  is 
essentially  smaller  than  T0  [5].  Both  parameters,  Ti  and  T0,  ought  to  be  taken  from  the 
comparison with the experimental results. To evaluate them one may use low T heat capacity 
data.  As  an  appropriate  example  one  may  take  T0  =  50000  K  and  Ti  =  3000  K  [5].  Then  we 
have Tc about 480 K, smin − s0 ≤ 0.12 and smax − s0 ≤ 0.24. As follows from Eq. (3), in general 
case the presented theory is valid when T is essentially smaller than Ti at any rate. 
  As was mentioned above, Eq. (2) can be regarded as a model, describing metastable states 
also,  because  it  describes  a  situation,  when  h(s,P)  goes  through  a  minimum  and  then  a 
maximum with the increase in (s − s0), as it should be for a metastable state. 

8. HEAT CAPACITY AT A FINITE HEATING RATE 

Heat  capacity,  c,  is  usually  measured  in  finite  heating  (cooling)  rate  experiments.  For  the 
sake  of  simplicity  let  us  consider  a  model  of  one  relaxation  time  [5].  The  relaxation  time, τ, 
may  be  considerable  at  low  T  due  to  barriers,  dividing  different  states  of  the  system.  These 
barriers may be penetrated by the way of tunneling. The rate of the relaxation of the enthalpy h  

 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
122                                                       Y. KORNYUSHIN 

depends on the deviation of h from its equilibrium value at a given T, he(T ) . Let us consider 
small deviations, when it is possible to use a linear approximation [5]. In this case the kinetic 
equation is [5] 

(dh/dt) + (h − he)/τ = 0.                                                     (26) 

  At low T the equilibrium value of the heat capacity, ce = T /T0, he = T 2 /2T0. Eq. (26) yields 

(dh/dT) + h/Ttτ = T 2 /2T0Ttτ.                                               (27) 

  Eq.  (27)  describes  the  evolution  of  h  =  h(T)  from  the  initial  value,  h0  =  h(Tin),  at  the 
beginning of the experiment. This equation is applicable only for low T. In this case τ usually 
does not depend on T. 
  At  low  heating  rates,  when  Ttτ  is  considerably  smaller  than  T,  h  =  he  and  c  =  ce.  At  high 
heating  rates,  when  Ttτ  is  considerably  larger  than  T,  relaxation  is  slow,  h  is  considerably 
smaller  than  he  and  as  follows  from  Eq.  (27),  (dh/dT)  =  c  =  he/Ttτ.  As  an  example  let  us 
consider a case when at t = 0 T = 0. In this case we have 

h = (T 2 / 2T0 ) − (Ttτ/T0)T + (Ttτ)2[1 − exp(−T /Ttτ)]/T0.                          (28) 

  Measured dynamic heat capacity is given by the following expression 

c = (T /T0 ) − (Ttτ/T0)[1 − exp(−T /Ttτ)].                                    (29) 

  Eq.  (29)  shows  that  the  dynamic  heat  capacity,  c  <  ce.  At  low  heating  rates,  when  Ttτ  is 
considerably  smaller  than  T,  c  =  T  /T0.  At  high  heating  rates,  when  Ttτ  is  considerably  larger 
than T, c = T 2 /2T0Ttτ. Using this expression for more general case it is possible to estimate the 
relaxation  time, τ,  and  to use  it  to  calculate  the  static  heat  capacity,  T /T0, with  the  aid  of  the 
measured heat capacity, c, and Eq. (29). 

It is worthwhile to note that it was implicitly assumed in this section that the temperature T 
remains  homogeneous  throughout  the  sample  during  heating  with  finite  heating  rate.  This  is 
possible only when the temperature equilibrates throughout the sample fast enough that is when 
the sample is thin enough [9]. Otherwise the characteristic time of the temperature equilibration 
appears  in  Eqs  (26)  -  (29),  instead  of  the  relaxation  time  of  the  relaxation  of  the  metastable 
nonequilibrium state back to the metastable equilibrium one.  

The condition of the fast enough equilibration of the temperature may be difficult to fulfil. 
In this case another method to measure the relaxation time of the relaxation of the metastable 
nonequilibrium state back to the metastable equilibrium one can be applied. Let us consider this 
method in the following section [9]. 

9. PHASE SHIFT CAUSED BY THE RELAXATION 

Let us consider a bulk sample with homogeneously distributed source of heat in the bulk of 
a sample [9]. The source can be the Joule heat. Let the sample be heated by ac, I = I0 sin ωt (I0 is 
the amplitude, and ω is the angular frequency). Then the Joule heat per one atom is 

q(t) = qe − qecos2ωt,                                                          (30) 

 
 
 
 
 
 
 
 
 
 
 
 
 
Studying Thermodynamics of Metastable States                                 123 

where qe is the average Joule heat per atom divided by k. 
  Let us consider a sufficiently thick sample at a sort of isothermal regime. The heat power 
per atom and divided by k, being extracted out of the sample is qe. Averaged over the volume 
of a sample and over the period of the oscillations, temperature, 〈T 〉, does not depend on time. 
The temperature does not practically  depend on coordinates throughout the bulk of a sample, 
and  gradT  is  essential  in  a  thin  surface  layer  only.  When  frequency  is  high  enough,  the  heat 
exchange caused by the  temperature oscillations inside the bulk of a sample is negligible  and 
the energy conservation law in the bulk of a sample can be written as follows: 

[dh(t )/dt] + qecos2ωt = 0.                                                      (31) 

  Eq. (26) and (31) yield 

h(t ) − he(T(t )) = qeτsin 2ωt.                                                   (32) 

  Let us regard a case when the deviation of the temperature from its averaged value 〈T 〉 is 
small. Then in the linear approximation on this deviation 

he(T (t)) = he(〈T 〉) + ce(〈T 〉)[T(t) − 〈T〉].                                        (33) 

In this case Eqs (31) - (33) yield 

T(t) = 〈T 〉 − (qeτ/ce){[1 + (2ωτ)2]1/2/2ωτ}cos(2ωt − ϕ),                          (34) 

ϕ = arcsin[1 + (2ωτ)2]−1/2.                                                 (35) 

  The phase shift, ϕ, decreases from π/2 to 0 when ω increases from zero to the range 2ωτ » 1 
concomitantly. 
  The  best  way  to  measure  the  phase  shift  is  to  take  two  samples  of  wire  in  series,  one  of 
them of a stable phase  with zero or very small relaxation time (presumably a  copper sample) 
and  another  one  of  a  metastable  state  (e.g.,  some  metallic  glass  sample)  and  to  measure  by 
some method the temperature oscillations in both samples. The difference in the phases of the 
oscillations in two samples allows one to calculate τ, using Eq. (35). 

10. METASTABLE HOMOGENEOUS-PHASE EQUILIBRIUM 

Metastable  states,  arising  during  first-order  phase  transformations,  is  a  thoroughly 

investigated branch [10]. Here let us see what could be gained using presented approach. 

First-order  phase  transformations  occur  at  temperatures  different  from  the  equilibrium  of 
the  phases  temperature,  Te,  for  the  phases  with  fixed  compositions.  The  transition  to  higher-
temperature phase requires overheating and that to the lower-temperature one, overcooling. The 
transition may involve various mechanisms dependent on the temperature variation rate. At low 
heating  (cooling)  rates  the  diffusional  mechanism  is  a  regular  one  for  many  of  the  first-order 
transformations. While at high rates the diffusional mechanism often changes to the martensitic 
one.  The  scope  for  these  mechanisms  is  governed  by  the  thermodynamic  conditions  in  the 
superheated (supercooled) phase. It is governed by the height of the barrier, separating the state 
of an atom in equilibrium with the metastable phase from more stable state, as well as by the 
kinetic conditions: temperature variation rate, diffusion coefficients, etc. At higher rates of the  

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
124                                                        Y. KORNYUSHIN 

temperature  variation  the  overheating  increases.  This  leads  to  the  smaller  barrier  between  the 
states of a phase, facilitating martensitic mechanism of transformation. 
  Let us start with a superheated metastable phase [11]. Let us expand the enthalpy in a power 
series in the deviation of s from its equilibrium value, se, at T = Te. The first four terms of the 
series are 

h(s,P) = h(se,P) + Te(s − se) + (T0/2)(s − se)2 − [T0

2/12(Ti − Te)](s − se)3.                  (36) 

  This  expansion  is  valid  for  (s  −  se)  «  1;  in  other  cases  it  can  be  considered  as  a  model 
representation for h describing a system in a metastable state for 

s = smin = se + [2(Ti − Te)/T0]{1 − [(Ti − T )/(Ti − Te)]1/2},                            (37) 

and in unstable equilibrium for 

s = smax = se + [2(Ti − Te)/T0]{1 + [(Ti − T )/(Ti − Te)]1/2}.                          (38) 

It is worthwhile to note that smin − se ≤ 2(Ti − Te)/T0, and smax − se ≤ 4 (Ti − Te)/T0. So Eq. 

(36) is valid for 4 (Ti − Te) « T0.  
  The  first-order  transition  of  a  diffusional  type  occurs  by  the  more  stable  phase  nucleating 
and the nuclei larger than the critical ones growing by atoms in equilibrium with the metastable 
phase passing to a state of the equilibrium with the atoms in the nuclei. An atom in equilibrium 
with the metastable phase is in a potential well, bottom of which is determined by φ( smin) and 
the crest by φ( smax), so the barrier height is described by 

∆φ(T )  = φ(smax) − φ(smin) = (8/ 3)(Ti − Te)1/2 (Ti

3/2/T0)[1 − (T Ti)]3/2.              (39) 

  Eq. (39) takes into account only the barrier, separating the homogeneous metastable phase 
from more stable one. The contribution of the surface energy is not taken into account. 
  Eq. (39) shows that the height of the barrier tends to zero as T approaches Ti in accordance 
with  the  3/2  law.  The  contribution  of  the  surface  energy  is  not  important  at  that  because  the 
metastable phase itself becomes unstable. 
  Under  the  isothermal  conditions  the  transformation  can  occur  when  T  is  of  the  order  of 
magnitude or larger than ∆φ(T )  because the individual atoms overcome the barrier and attach 
to the nuclei by diffusion if the kinetic conditions allow it. At high heating (cooling) rates there 
may be a substantial superheating (supercooling). As the rate increases, T → Ti, and the barrier  
height decreases. At sufficiently high rates, the barrier height is reduced so much as to become 
unimportant and the martensitic growth replaces the diffusion-limited one. 
  Eqs  (36)  -  (39)  are  valid  for  the  supercooled  phase  also  [9].  Only  one  should  take  into 
account  that  for  the  superheated  phase  se  ≤  s,  Te  ≤  T  ≤  Ti  and  smin  ≤  smax,  while  for  the 
supercooled phase s ≤ se, Ti ≤ T ≤ Te and smax ≤ smin. 

11. METASTABLE-PHASE THERMAL PARAMETERS 

The specific heat at the constant pressure [11], 

 
 
 
 
 
 
 
 
 
 
 
 
 
Studying Thermodynamics of Metastable States                                 125 

cP = T (∂s/∂T)P = (T/T0)[(Ti − Te)/(Ti − T ) ]1/2.                                          (40) 

It has a square root singularity at Ti, which becomes more prominent as the rate increases and 
thus the actual transition temperature approaches Ti. 
  Let  us  consider  now  the  thermal  expansion  coefficient  [11].  The  thermal  expansion 
coefficient, α(T )  = (∂va/∂T )P/ v e = −k(∂s/∂P)T / ve (va and ve are the volume of the sample per 
atom at T > Te and T = Te respectively) is given by the following equation: 

α(T )  = αe + K[1 − (T/Ti)]1/2 + B[1 − (T /Ti)]−1/2,                                 (41) 

where 

αe = −(k/ve){(∂se/∂P) + 2[∂ ((Ti − Te)/T0)/∂P]}, 
K = (k/ve){2[Ti/(Ti −Te)]1/2[∂((Ti − Te)/T0)/∂P] − (1/T0)[Ti/(Ti − Te)]1/2[∂(Ti − Te)/∂P]}, 

B = (k/veT0)[(Ti − Te)/Ti]1/2 (∂Ti/∂P).                                         (42) 

  At T = Te 

α(Te) = −(k/ve)(∂se/∂P) + (k/veT0)(∂Te/∂P).                                     (43) 

that  give 

the  exponents  characterizing 

It is worthwhile to note that Eq. (40) and (41) yield well-known results. In [12] these results 
were  obtained  for  a  ferromagnet  in  the  mean-field  approximation.  In  [13]  more  general 
the  divergencies  along  several 
expressions 
thermodynamic  paths  (isothermal,  isobaric)  were  derived.  These  results  are  summarized  in 
Chapter 2 of [14]. In this particular case nothing is gained by the author’s alternative approach. 
It  just  shows  that  the  approach  discussed  here  yields  correct  results  in  this  case  also.  But  it 
should  be  mentioned  that  the  accepted  framework  allows  one  to  consider  a  series  of  other 
problems. 
  Eq. (41) shows that α(T) has a square-root singularity (like cP) as T approaches Ti. But the 
results,  obtained  in  this  section  are  derived  for  the  metastable  equilibrium  phase,  so  they  are 
applicable when the phase is still stable, i.e. for T < Tc only. 

12. METASTABLE STATES IN AB3 ALLOYS 

Let  us  consider  a  first-order  phase  transition  in  an  ordering  alloy  having  AB3  stoichiometry 
[15,11]. For Te < T < Ti, a superheated ordered phase exists in a metastable state, as is evident 
from the AB3 phase diagram, which has been examined by numerical methods in the Gorsky-
Bragg-Williams  approximation  [15].  The  part  of  the  free  energy,  F,  dependent  on  the  order 
parameter, η, is [15] 

F = −0.457NkTeη2 + 0.0625NkTf (η),                                               (44) 

where N  is the total number of atoms in the alloy and 

f(η) = 3(1 − η)ln[3(1 − η)2/16] + (1 + 3η)ln[(1 + 3η)/4 ] + 3(3 + η)ln[(3 + η)/4].        (45) 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
126                                                        Y. KORNYUSHIN 

It is possible to introduce a free parameter (another order parameter), x, as follows: 

x = [f(ηe) − f(η)]/16,                                                          (46) 

where ηe = 0.463 is the equilibrium value of η in the ordered phase at T = Te.  

For small x the last three equations yield 

F = Nk[Te(x + 0.205x2 − 1.04x3 ) − Tx].                                         (47) 

  Eq. (47) corresponds exactly to the initial equations in the general theory, Eqs (1) and (2), 
with T0 = 0.410Te and Ti = 1.0134Te, so the expression for the free energy of AB3 alloy in the 
discussed model is reduced to the initial expression in the general theory by changing variables. 
The  values  of  x  corresponding  to  the  minimum  do  not  exceed  0.0656  throughout  the 
metastable-state range, which justifies the x expansion used. The values of x corresponding to 
the maximum do not exceed 0.131. 
  The  usual  value  of  Te  for  AB3  alloys  is  hundreds  of  degrees  of  Kelvin,  so  the  metastable-
range temperature width is up to 10 degrees. 

In the AB3 systems ∆φ is very small. The maximum value of it at T = Te is 0.00118Te, as Eq. 
(39)  shows,  so  there  is  virtually  no  barrier  and  a  critical  nucleus  grows  very  rapidly,  which 
agrees with experiment [15]. 

13. SOME REMARKS ON SECOND-ORDER PHASE TRANSITIONS 

The enthalpy for the second-order phase transition should be written as follows [9]: 

h(s,P) = h(se,P) + Te(s − se) + [(1 − β)(2 − β)/(1 − β)/(2 − β)]T0(se − s)(2 − β)/(1 − β) + ...  .  (48) 

  This equation has been written for T ≤ Te, that is for s ≤ se. Eq. (48) and (∂φ/∂s) = 0 yield 

s = se − [1/(1 − β)][(Te − T)/T0]1 − β.                                          (49) 

  As  cP  =  T(∂s/∂T)P,  Eq.  (49)  yields  for  the  heat  capacity  and  the  thermal  expansion 
coefficient the following results [9] 

α(T) = −(k/ve){(∂se/∂P) + (∂lnT0/∂P)[(Te − T)/T0]1 − β − (1/T0)(∂Te/∂P )[(Te − T)/T0]−β}. (50) 

cP = (T /T0)[(Te − T)/T0]−β, 

  These  equations  show  that β  has  the  meaning  of  a  critical  index.  The  equation  for α  has 
been derived on the assumption that β does not depend on pressure. 

14. DISCUSSION 

Classical  thermodynamic  method,  described  above,  gives  explicit  T  relationships  for  the 
barrier  separating  the  states,  the  specific  heat  and  the  thermal  expansion  coefficient.  This 
approach  may  be  useful  in  other  cases.  For  example  if  there  is  a  set  of  the  intermediate 
metastable phases between the two major ones, which correspond to minima in φ with respect 
to s, in which case slow uniform heating with restricted entropy increase causes the sample to 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Studying Thermodynamics of Metastable States                                 127 

enter the corresponding minima in order of increasing entropy (and in the reverse order during 
cooling), i.e. in a sequence, corresponding to the Ostwald stage rule [11]. 
  The  approach  may  be  useful  in  other  cases  also.  The  metastable  states  in  AB3  alloys  are 
considered and the same approach is applied to the second-order transformations. 

For the dielectric materials low temperature heat capacity is determined by phonons and it 
is proportional to T 3 (the Debye T 3 law) [16]. This corresponds to a = 4/3 in Section 6. For b = 
5/3 the problem can be solved analytically [9]. In this case [9] 

sm = s0 + (8/3)(Ti/T0)3{1 ± [1 − (T/Ti)]1/2}3,                                        (51) 

where m is maximum or minimum and + refers to the maximum and − refers to the minimum. 
  The heat capacity in this case [9], 

cP = (4Ti

2/T0

3){1 − [1 − (T/Ti)]1/2}2T/[1 − (T/Ti)]1/2,                              (52) 

and the thermodynamic barrier is as follows [9]: 

∆φ( T) = (32/3)(Ti

4/T0

3){[1 − (T/Ti)]3/2 + 0.2[1 − (T/Ti)]5/2}.                     (53) 

  Eq.  (53)  shows  that  in  the  vicinity  of  Ti  the  barrier  is  proportional  to  [1  −  (T/Ti)]3/2  as 
expected. But in some cases it could be different. The dependence of φ( s,P)  has a minimum at 
s = smin and a maximum at s = smax ≥ smin. As T → Ti smin → smax and ∆φ → 0. At T = Ti there is 
no barrier, minimum and maximum merge, forming an inflection point. Let us expand φ(s,P) in 
power series in (s − si) and consider the first two non-vanishing terms of the series: 

φ( s,P) = φ( si,P) + [(∂h/∂s)si − T ] (s − si) − [Ti / (2n + 1)Q2n] (s − si)2n + 1,             (54) 

where  (∂h/∂s)si  =  Ti  as  was  shown  above,  n  is  a  positive  integer,  and  Q  is  some  coefficient. 
Then the condition ∂φ( s,P)/∂s = 0 yields 

sm = si ± Q[1 − (T/Ti)]1/2n.                                                (55) 

  Eqs (54) and (55) yield [9] 

∆φ( T) = [4nQTi /(2n + 1)][1 − (T/Ti)](2n + 1)/2n.                               (56) 

  Eq. (56) shows that only when n = 1 [the right-hand part of Eq. (54) has a linear and a cubic 
terms  only],  the  barrier  vanishes  as  [1  −  (T/Ti)]3/2  at  T  →  Ti.  In  general  case  the  temperature 
dependence of the barrier height, ∆φ(T ) , could be different [9]. 

In  summary  it  should  be  said  that  the  application  of  the  proposed  approach  yields  results 
consistent  with  standard  predictions  from  thermodynamic  stability  theory  and  allows  one  to 
consider within the framework of the same formalism a series of thermodynamic problems. 

 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
128                                                       Y. KORNYUSHIN 

REFERENCES 

[1]  Yu. V. Kornyushin, Metallofizika 7(6), (1985) 109. 
[2]  L. D. Landau and I. M. Lifshits, Statistical Physics, Pergamon Press, Oxford, 1981. 
[3]  Y. Kornyushin, J. Non-Equilib. Thermodyn., 18 (4), (1993) 353. 
[4]  E. M. Lifshits and L. P. Pitaevskii, Physical Kinetics, Pergamon Press, Oxford, 1981. 
[5]  V. V. Ne moshkalenko, A. V. Romanova, A. G. Illinski, V. V. Maslov, D. Yu. Paderno,  
Yu. V. Kornyushin et al, Amorphous Metallic Alloys, Naukova Dumka, Kiev, 1987. 

[6]  W. A. Phillips (Ed.), Amorphous Solids, Springer-Verlag, Berlin, 1981. 
[7]  S. B. Kiselev, J. Chem. Phys., 116 (13), (2002) 5657. 
[8]  S. B. Kiselev, J. Chem. Phys., 118 (2), (2003) 680. 
[9]  Y. Kornyushin, J. Non-Equilib. Thermodyn., 25 (1), (2000) 15. 
[10]  V. P. Skripov, J. Non-Equilib. Thermodyn., 17 (3), (1992) 193. 
[11]  Yu. V. Kornyushin, Metallofizika, 9 (3), (1987) 403. 
[12]  A. Compagner, Physica, 72 (1), (1974) 115. 
[13]  R. J. Speedy, J. Phys. Chem., 86 (15), (1982) 3002. 
[14]  P. G. Debenedetti, Metastable Liquids, University Press, Princeton, 1996. 
[15]  A. A. Smirnov, Molecular-Kinetic Theory of Metals, Nauka, Moscow, 1966. 
[16]  C. Kittel, Introduction to Solid State Physics, John Wiley & Sons, New York, 1966. 

COMMENT 

Theory of alloys is usually formulated in the framework of a configurational model. In this 
model a contribution of temperature is neglected, while calculating energy and entropy. This is 
justified because the contribution of temperature is many orders of magnitude smaller than the 
contribution of interatomic interactions and atomic distributions. 

In  the Theory  of  Alloys  energy  and  entropy  are  usually calculated  in  the  framework  of  a 
configurational  model  as  functions  of  the  order  parameter,  η.  Then  the  Gibbs  free  energy 
(GFE),  G(η), is extremised  on  the  order  parameter.  Maxima  and  minima  are  usually  found. 
Low maxima reduce stability. Some of the minima corresponds to stable states, the other ones 
to the metastable states (if the dividing GFE barrier, the difference between the corresponding 
maximum  and  minimum  of  the  GFE,  is  comparatively  low).  Different  phases,  different  order 
parameters, which could be defined in different ways. So we have: G(η) = H(η) − S(η)T, here 
H(η) is the Enthalpy. 

Once  I've  thought:  why  not  to  choose  a  parameter  to  minimize  the  GFE  on  as S  itself 
instead of η? As a rule S is a monotonous function of η, so it is ok as a rule. It's just a matter of 
transformation of variables, of substitution of one variable with another one. Then it is possible 
to  formulate  a  general  approach  for  the  description  of  metastable  states,  on  the  basis  of  the 
following equation:  G(S,P)  =  H(S,P)  −  ST  [by  the  way,  it  is  well  known  in  Thermodynamics 
that H is defined as H(S,P)]. These considerations had helped me to formulate my more general 
approach."
